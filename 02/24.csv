"2002.09929","Sebastian Acosta","Sebastian Acosta","Solvability for Photoacoustic Imaging with Idealized Piezoelectric
  Sensors",,"IEEE Trans. Ultrason. Ferroelectr. Freq. Control 67(11):
  2413-2422, 2020","10.1109/TUFFC.2020.3005037",,"math.AP cs.NA math.NA physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most reconstruction algorithms for photoacoustic imaging assume that the
pressure field is measured by ultrasound sensors placed on a detection surface.
However, such sensors do not measure pressure exactly due to their non-uniform
directional and frequency responses, and resolution limitations. This is the
case for piezoelectric sensors that are commonly employed for photoacoustic
imaging. In this paper, using the method of matched asymptotic expansions and
the basic constitutive relations for piezoelectricity, we propose a simple
mathematical model for piezoelectric transducers. The approach simultaneously
models how the pressure waves induce the piezoelectric measurements and how the
presence of the sensors affects the pressure waves. Using this model, we
analyze whether the data gathered by piezoelectric sensors leads to the
mathematical solvability of the photoacoustic imaging problem. We conclude that
this imaging problem is well-posed in certain normed spaces and under a
geometric assumption. We also propose an iterative reconstruction algorithm
that incorporates the model for piezoelectric measurements. A numerical
implementation of the reconstruction algorithm is presented.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:03:25 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 05:12:22 GMT""}]","2021-01-05"
"2002.09930","Jeremy Lane","Jeremy Lane","Local normal forms for multiplicity free $U(n)$ actions on coadjoint
  orbits","16 pages. Edits to correct a few minor typos","Pacific J. Math. 309 (2020) 401-419","10.2140/pjm.2020.309.401",,"math.SG math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Actions of $U(n)$ on $U(n+1)$ coadjoint orbits via embeddings of $U(n)$ into
$U(n+1)$ are an important family of examples of multiplicity free spaces. They
are related to Gelfand-Zeitlin completely integrable systems and multiplicity
free branching rules in representation theory. This paper computes the
Hamiltonian local normal forms of all such actions, at arbitrary points, in
arbitrary $U(n+1)$ coadjoint orbits. The results are described using
combinatorics of interlacing patterns; gadgets that describe the associated
Kirwan polytopes.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:04:48 GMT""},{""version"":""v2"",""created"":""Thu, 1 Oct 2020 14:34:41 GMT""}]","2021-01-20"
"2002.09931","Carlos Sarraute PhD","Mar\'ia \'Oskarsd\'ottir, Cristi\'an Bravo, Carlos Sarraute, Jan
  Vanthienen, Bart Baesens","The Value of Big Data for Credit Scoring: Enhancing Financial Inclusion
  using Mobile Phone Data and Social Network Analytics",,"Applied Soft Computing, Volume 74, January 2019, Pages 26-39","10.1016/j.asoc.2018.10.004",,"cs.SI cs.CY cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Credit scoring is without a doubt one of the oldest applications of
analytics. In recent years, a multitude of sophisticated classification
techniques have been developed to improve the statistical performance of credit
scoring models. Instead of focusing on the techniques themselves, this paper
leverages alternative data sources to enhance both statistical and economic
model performance. The study demonstrates how including call networks, in the
context of positive credit information, as a new Big Data source has added
value in terms of profit by applying a profit measure and profit-based feature
selection. A unique combination of datasets, including call-detail records,
credit and debit account information of customers is used to create scorecards
for credit card applicants. Call-detail records are used to build call networks
and advanced social network analytics techniques are applied to propagate
influence from prior defaulters throughout the network to produce influence
scores. The results show that combining call-detail records with traditional
data in credit scoring models significantly increases their performance when
measured in AUC. In terms of profit, the best model is the one built with only
calling behavior features. In addition, the calling behavior features are the
most predictive in other models, both in terms of statistical and economic
performance. The results have an impact in terms of ethical use of call-detail
records, regulatory implications, financial inclusion, as well as data sharing
and privacy.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:13:56 GMT""}]","2020-03-20"
"2002.09932","Samuele Giraudo","Camille Combe and Samuele Giraudo","Three interacting families of Fuss-Catalan posets","12 pages","Formal Power Series and Algebraic Combinatorics, S\'eminaire
  Lotharingien de Combinatoire, 84B.22, 2020",,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three families of posets depending on a nonnegative integer parameter $m$ are
introduced. The underlying sets of these posets are enumerated by the $m$-Fuss
Catalan numbers. Among these, one is a generalization of Stanley lattices and
another one is a generalization of Tamari lattices. The three families of
posets are related: they fit into a chain for the order extension relation and
they share some properties. Two associative algebras are constructed as
quotients of generalizations of the Malvenuto-Reutenauer algebra. Their
products describe intervals of our analogues of Stanley lattices and Tamari
lattices. In particular, one is a generalization of the Loday-Ronco algebra.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:14:43 GMT""},{""version"":""v2"",""created"":""Mon, 26 Apr 2021 08:11:36 GMT""}]","2021-04-27"
"2002.09933","Pietro Menotti","Pietro Menotti","Real analyticity of accessory parameters","24 pages LaTex",,,"IFUP-TH/2020","hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of the real analytic dependence of the accessory
parameters of Liouville theory on the moduli of the problem, for general
elliptic singularities. We give a simplified proof of the almost everywhere
real analyticity in the case of a single accessory parameter as it occurs e.g.
in the sphere topology with four sources or for the torus topology with a
single source by using only the general analyticity properties of the solution
of the auxiliary equation. We deal then the case of two accessory parameters.
We use the obtained result for a single accessory parameter to derive rigorous
properties of the projection of the problem on lower dimensional planes. We
derive the real analyticity result for two accessory parameters under an
assumption of irreducibility.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:22:01 GMT""}]","2020-02-27"
"2002.09934","Ji-Woo Lee","Tae Yong Kim, Hang Gon Cho, and Ji-Woo Lee","Entanglement entropy of two-species hard-core bosons in one dimension","7 pages, 9 figures",,"10.1007/s40042-021-00098-y",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the von Neumann entropy of a model for two-species hard-core bosons
in one dimension. In this model, the same-species bosons satisfy hard-core
conditions, while the different-species bosons are allowed to occupy the same
site with a local interaction U . At half-filling, by Jordan-Wigner
transformation, the model is exactly mapped to a fermionic Hubbard model. The
phase transition from superfluid U = 0 to Mott insulator U > 0 can be explained
by simple one-band theory at half-filling. We measure the von Neumann
entanglement entropy of the ground states for the half-filled case and away
from half-filling to understand quantum phase transitions. To achieve this
goal, we use a time-evolution-block decimation method with infinite-size matrix
product state and also use a density matrix renormalization group with matrix
product operators with large bond dimensions up to 300. We found strong
evidence that the local minimum point of the von Neumann entanglement entropy
is the quantum critical point for finite-bond-dimension matrix product states.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:26:55 GMT""},{""version"":""v2"",""created"":""Fri, 22 May 2020 02:15:41 GMT""},{""version"":""v3"",""created"":""Sat, 12 Sep 2020 16:23:48 GMT""},{""version"":""v4"",""created"":""Fri, 18 Sep 2020 14:54:53 GMT""}]","2021-03-17"
"2002.09935","Koji Terashi","Koji Terashi, Michiru Kaneda, Tomoe Kishimoto, Masahiko Saito, Ryu
  Sawada, Junichi Tanaka","Event Classification with Quantum Machine Learning in High-Energy
  Physics","11 pages, 11 figures, 4 tables; revised with comments from the
  journal","Comput. Softw. Big Sci. 5, 2 (2021)","10.1007/s41781-020-00047-7",,"physics.comp-ph hep-ex hep-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present studies of quantum algorithms exploiting machine learning to
classify events of interest from background events, one of the most
representative machine learning applications in high-energy physics. We focus
on variational quantum approach to learn the properties of input data and
evaluate the performance of the event classification using both simulators and
quantum computing devices. Comparison of the performance with standard
multi-variate classification techniques based on a boosted-decision tree and a
deep neural network using classical computers shows that the quantum algorithm
has comparable performance with the standard techniques at the considered
ranges of the number of input variables and the size of training samples. The
variational quantum algorithm is tested with quantum computers, demonstrating
that the discrimination of interesting events from background is feasible.
Characteristic behaviors observed during a learning process using quantum
circuits with extended gate structures are discussed, as well as the
implications of the current performance to the application in high-energy
physics experiments.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:30:33 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 12:46:51 GMT""}]","2021-01-06"
"2002.09936","Kirill Zainoulline","Martina Lanini and Kirill Zainoulline","A Riemann-Roch type theorem for twisted fibrations of moment graphs","20 pages",,,,"math.AG math.CO math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper we extend the Riemann-Roch formalism to structure
algebras of moment graphs. We introduce and study the Chern character and
pushforwards for twisted fibrations of moment graphs. We prove an analogue of
the Riemann-Roch theorem for moment graphs. As an application, we obtain the
Riemann-Roch type theorem for equivariant $K$-theory of some Kac-Moody flag
varieties.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:37:35 GMT""}]","2020-03-06"
"2002.09937","Piero Procacci","Marina Macchiagodena, Marco Pagliai, Piero Procacci","Inhibition of the Main Protease 3CL-pro of the Coronavirus Disease 19
  via Structure-Based Ligand Design and Molecular Modeling","main paper: 14 pages, 5 figures, 1 Table Supporting Information: 18
  pages, 1 table, 7 figures",,,,"q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have applied a computational strategy, based on the synergy of virtual
screening, docking and molecular dynamics techniques, aimed at identifying
possible lead compounds for the non-covalent inhibition of the main protease
3CL-pro of the SARS-Cov2 Coronavirus. Based on the recently resolved 6LU7 PDB
structure, ligands were generated using a multimodal structure-based design and
then optimally docked to the 6LU7 monomer. Docking calculations show that
ligand-binding is strikingly similar in SARS-CoV and SARS-CoV2 main proteases,
irrespectively of the protonation state of the catalytic CYS-HIS dyad. The most
potent docked ligands are found to share a common binding pattern with aromatic
moieties connected by rotatable bonds in a pseudo-linear arrangement. Molecular
dynamics calculations fully confirm the stability in the 3CL-pro binding pocket
of the most potent binder identified by docking, namely a
chlorophenyl-pyridyl-carboxamide derivative.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:47:00 GMT""},{""version"":""v2"",""created"":""Mon, 2 Mar 2020 22:13:58 GMT""}]","2020-03-04"
"2002.09938","Areg Ghazaryan","Areg Ghazaryan, Yossi Paltiel, Mikhail Lemeshko","An analytic model of chiral-induced spin selectivity","7 pages, 3 figures","J. Phys. Chem. C 124, 11716-11721 (2020)","10.1021/acs.jpcc.0c02584",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Organic materials are known to feature long spin-diffusion times, originating
in a generally small spin-orbit coupling observed in these systems. From that
perspective, chiral molecules acting as efficient spin selectors pose a puzzle,
that attracted a lot of attention during the recent years. Here we revisit the
physical origins of chiral-induced spin selectivity (CISS), and propose a
simple analytic minimal model to describe it. The model treats a chiral
molecule as an anisotropic wire with molecular dipole moments aligned
arbitrarily with respect to the wire's axes, and is therefore quite general.
Importantly, it shows that helical structure of the molecule is not necessary
to observe CISS and other chiral non-helical molecules can also be considered
as a potential candidates for CISS effect. We also show that the suggested
simple model captures the main characteristics of CISS observed in experiment,
without the need for additional constraints employed in the previous studies.
The results pave the way for understanding other related physical phenomena
where CISS effect plays an essential role.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:47:59 GMT""},{""version"":""v2"",""created"":""Mon, 1 Jun 2020 08:52:31 GMT""}]","2020-06-02"
"2002.09939","Carlo F. Barenghi","E. Rickinson, C.F. Barenghi, Y.A. Sergeev, and A.W. Baggaley","Superfluid turbulence driven by cylindrically symmetric thermal
  counterflow","7 pages, 10 figures; to be published in Phys Rev B","Phys. Rev. B 101, 134519 (2020)","10.1103/PhysRevB.101.134519",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show by direct numerical simulations that the turbulence generated by
steadily heating a long cylinder immersed in helium~II is strongly
inhomogeneous and consists of a dense turbulent layer of quantized vortices
localized around the cylinder. We analyse the properties of this superfluid
turbulence in terms of radial distribution of the vortex line density and the
anisotropy and we compare these properties to the better known properties of
homogeneous counterflow turbulence in channels.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:58:46 GMT""},{""version"":""v2"",""created"":""Thu, 16 Apr 2020 14:57:33 GMT""}]","2020-05-06"
"2002.09940","Jianxin Lu","J. X. Lu and Nan Zhang","More on the open string pair production","22 pages, expanded version, discussion improved, typos corrected",,,"USTC-ICTS/PCFT-20-05","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the recent work \cite{Lu:2019ynq} by one of the present authors,
we here report that there exist two new systems, namely, D3/(F, D1) and D3/(D3,
(F, D1)), either of which can give rise to a much larger sizable open string
pair production rate at a condition much relaxed. Here the D3 is taken as our
own (1 + 3)-dimensional world while the non-threshold bound state (F, D1) or
(D3, (F, D1)) is placed parallel nearby in the directions transverse to both
our D3 world and the non-threshold bound state considered.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:00:57 GMT""},{""version"":""v2"",""created"":""Thu, 8 Oct 2020 11:21:17 GMT""}]","2020-10-09"
"2002.09941","Soumyajit Paul","Hugo Gimbert, Soumyajit Paul and B. Srivathsan","A Bridge between Polynomial Optimization and Games with Imperfect Recall",,,,,"cs.GT cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide several positive and negative complexity results for solving games
with imperfect recall. Using a one-to-one correspondence between these games on
one side and multivariate polynomials on the other side, we show that solving
games with imperfect recall is as hard as solving certain problems of the first
order theory of reals. We establish square root sum hardness even for the
specific class of A-loss games. On the positive side, we find restrictions on
games and strategies motivated by Bridge bidding that give polynomial-time
complexity.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:06:46 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 09:35:45 GMT""}]","2020-02-26"
"2002.09942","Olivier Serre","Arnaud Carayol and Olivier Serre","How Good Is a Strategy in a Game With Nature?",,"ACM Transactions on Computational Logic, Vol. 21, No 3, Article
  21, pp. 1-39, February 2020","10.1145/3377137",,"cs.FL cs.GT cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider games with two antagonistic players --- \'Elo\""ise (modelling a
program) and Ab\'elard (modelling a byzantine environment) --- and a third,
unpredictable and uncontrollable player, that we call Nature. Motivated by the
fact that the usual probabilistic semantics very quickly leads to
undecidability when considering either infinite game graphs or
imperfect-information, we propose two alternative semantics that leads to
decidability where the probabilistic one fails: one based on counting and one
based on topology.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:18:16 GMT""}]","2020-10-14"
"2002.09944","Charles Kane","C.L. Kane, D. Giuliano, I. Affleck","Equivalent critical behavior of a helical point contact and a
  two-channel Luttinger liquid - topological superconductor junction","18 pages, 9 figures",,,,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the equivalence between two distinct Luttinger liquid impurity
problems. The first concerns a one-dimensional topological superconductor
coupled at one end to the ends of two single channel Luttinger liquids. The
second concerns a point contact in the quantum spin Hall effect, where four
helical Luttinger liquids meet at a point. Both problems have been studied
previously and exhibit several stable phases depending on the Luttinger
parameter K, that can be characterized in terms of simple conformally invariant
boundary conditions describing perfect normal (or Andreev) transmission or
reflection. In addition, both problems exhibit critical points that are
described by ""intermediate"" fixed points similar to those found in earlier
studies of an impurity in a Luttinger liquid with spin. Though these two models
have different symmetries and numbers of modes, we show they are equivalent and
are related by a duality transformation, and we show that the non-trivial
intermediate critical points are the same. In the non-interacting limit, K=1,
the duality involves two distinct free fermion representations that are related
by a non-local transformation that derives from the triality of SO(8). Using
the explicit translation between the two theories, we translate results from
one problem to the other and vice versa. This allows us to make new predictions
about the topological superconductor-Luttinger liquid junction, including
predictions about the global behavior of the critical conductance G*(K), as
well predictions for the critical exponents and universal crossover scaling
functions. In this paper we introduce both models from scratch, using a common
notation that facilitates their comparison, and we discuss in detail the
dualities that relate them, along with their free fermion limits. We close with
a discussion of open problems and future directions.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:22:54 GMT""}]","2020-02-25"
"2002.09947","Paul Thibado","P. M. Thibado, P. Kumar, Surendra Singh, M. Ruiz-Garcia, A. Lasanta,
  and L. L. Bonilla","Fluctuation-induced current from freestanding graphene: toward nanoscale
  energy harvesting","5 pages, 3 figures","Phys. Rev. E 102, 042101 (2020)","10.1103/PhysRevE.102.042101",,"cond-mat.mes-hall cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  At room temperature, micron-sized sheets of freestanding graphene are in
constant motion even in the presence of an applied bias voltage. We quantify
the out-of-plane movement by collecting the displacement current using a nearby
small-area metal electrode and present a Langevin model for the motion coupled
to a circuit containing diodes. The system reaches thermal equilibrium and the
rates of heat, work, and entropy production tend quickly to zero. However,
there is power generated by graphene which is equal to the power dissipated by
the load resistor. The exact power formula is similar to Nyquist's noise power
formula, except that the rate of change of diode resistance significantly
boosts the output power, and the movement of the graphene shifts the power
spectrum to lower frequencies.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:25:13 GMT""}]","2020-10-07"
"2002.09948","Yue Hu","Yue Hu, Ka Ho Yuen, Victor Lazarian, Ka Wai Ho, Robert A. Benjamin,
  Alex S. Hill, Felix J. Lockman, Paul F. Goldsmith, Alex Lazarian","Magnetic Field Morphology in Interstellar Clouds with the Velocity
  Gradient Technique","14 pages, 8 figures","2019NatAs...3..776H","10.1038/s41550-019-0769-0",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic fields, while ubiquitous in many astrophysical environments, are
challenging to measure observationally. Based on the properties of anisotropy
of eddies in magnetized turbulence, the Velocity Gradient Technique is a method
synergistic to dust polarimetry that is capable of tracing plane-of-the-sky
magnetic field, measuring the magnetization of interstellar media and
estimating the fraction of gravitational collapsing gas in molecular clouds
using spectral line observations. In this paper, we apply this technique to
five low-mass star-forming molecular clouds in the Gould Belt and compare the
results to the magnetic-field orientation obtained from polarized dust
emission. We find the estimates of magnetic field orientations and
magnetization for both methods are statistically similar. We estimate the
fraction of collapsing gas in the selected clouds. By means of the Velocity
Gradient Technique, we also present the plane-of-the-sky magnetic field
orientation and magnetization of the Smith cloud, for which dust polarimetry
data are unavailable.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:25:49 GMT""}]","2020-02-25"
"2002.09949","Marie Destandau","Marie Destandau, Olivier Corby, Jean-Daniel Fekete and Alain Giboin","Path Outlines: Browsing Path-Based Summaries of Knowledge Graphs","16 pages, 9 figures",,,,"cs.HC","http://creativecommons.org/licenses/by-sa/4.0/","  Knowledge Graphs have become a ubiquitous technology powering search engines,
recommender systems, connected objects, corporate knowledge management and Open
Data. They rely on small units of information named triples that can be
combined to form higher level statements across datasets following information
needs. But data producers face a problem: reconstituting chains of triples has
a high cognitive cost, which hinders them from gaining meaningful overviews of
their own datasets. We introduce path outlines: conceptual objects
characterizing sequences of triples with descriptive statistics. We interview
11 data producers to evaluate their interest. We present Path Outlines, a tool
to browse path-based summaries, based on coordinated views with 2 novel
visualisations. We compare Path Outlines with the current baseline technique in
an experiment with 36 participants. We show that it is 3 times faster, leads to
better task completion, less errors, that participants prefer it, and find
tasks easier with it.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:29:12 GMT""},{""version"":""v2"",""created"":""Fri, 6 Mar 2020 16:36:13 GMT""},{""version"":""v3"",""created"":""Mon, 13 Jul 2020 19:45:26 GMT""},{""version"":""v4"",""created"":""Thu, 8 Oct 2020 20:12:24 GMT""}]","2020-10-12"
"2002.09950","Eldar Noe Dobrea","E. Z. Noe Dobrea, R. M. E. Williams, W. E. Dietrich, A. D. Howard, J.
  C. Cawley, and R. P. Irwin III","Mineralogy of a Sulfate-rich Inverted Channel in the Atacama Desert,
  Chile: Clues to its Formation and Preservation","Submitted to Icarus Feb 22, 2020; 19 pages, 1 Table, 19 Figures",,,,"astro-ph.EP physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have performed a stratigraphic and mineralogical analysis of a vertical
transect across a ridge located at the distal end of a system of eroded
alluvial deposits in the northern Atacama Desert of Chile. The ridge, which is
interpreted to be an inverted channel, exhibits a history of sedimentary,
evaporitic, and diagenetic origin that includes groundwater mobilization and
precipitation of anhydrite cements throughout the volume of the ridge. The
ridge consists of two units: a lower one exhibiting a sedimentary and
diagenetic history, and an upper one exhibiting an evaporitic history.
Interbedded in the section are also anhydritic and gypsic paleosols. Two
mechanisms that contribute to channel preservation and inversion are identified
in this case. The first mechanism is the cementation of the volume by anhydrite
cements during early diagenesis, and the second newly identified mechanism is
the armoring of the lateral slopes of the ridge by halite-rich cement. The
slope-conforming armor formed by this second mechanism developed subsequent to
the formation of the ridge as a consequence of the remobilization of soluble
salts. Finally, we identify a series of Ca-sulfate-rich plates on the surface
of the ridge, which we interpret here to form by fracturing and subsequent
erosion of an evaporitic deposit. The plates exhibit a reticulated surface
texture, which we interpret as the result of periodic deliquescence and
reprecipitation of a thin surface film of the evaporite deposits in response to
thick morning fogs that occur in this part of the Atacama. The cross section of
the plates exhibits a thin portion of biological material, which we ascribe to
bacterial mats that take advantage of the deliquescence of the substrate to
obtain their water. This later has important implications in the search for
extant or extinct life on Mars.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:30:49 GMT""}]","2020-02-25"
"2002.09951","Rodolfo Quispe","Rodolfo Quispe, Darwin Ttito, Ad\'in Ram\'irez Rivera, Helio Pedrini","Multi-Stream Networks and Ground-Truth Generation for Crowd Counting","https://github.com/RQuispeC/multi-stream-crowd-counting-extended ,
  The International Journal of Electrical and Computer Engineering Systems 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Crowd scene analysis has received a lot of attention recently due to the wide
variety of applications, for instance, forensic science, urban planning,
surveillance and security. In this context, a challenging task is known as
crowd counting, whose main purpose is to estimate the number of people present
in a single image. A Multi-Stream Convolutional Neural Network is developed and
evaluated in this work, which receives an image as input and produces a density
map that represents the spatial distribution of people in an end-to-end
fashion. In order to address complex crowd counting issues, such as extremely
unconstrained scale and perspective changes, the network architecture utilizes
receptive fields with different size filters for each stream. In addition, we
investigate the influence of the two most common fashions on the generation of
ground truths and propose a hybrid method based on tiny face detection and
scale interpolation. Experiments conducted on two challenging datasets,
UCF-CC-50 and ShanghaiTech, demonstrate that using our ground truth generation
methods achieves superior results.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:31:48 GMT""},{""version"":""v2"",""created"":""Tue, 3 Mar 2020 01:17:40 GMT""},{""version"":""v3"",""created"":""Wed, 11 Mar 2020 20:47:00 GMT""}]","2020-03-13"
"2002.09952","Haibo Jin","Osamu Iyama, Haibo Jin","Positive Fuss-Catalan numbers and Simple-minded systems in negative
  Calabi-Yau categories","15 pages, many improvements due to referees, the algebra KQ for
  Dynkin quiver Q has been generalized to hereditary algebra H of Dynkin type,
  End(X)=k in the definition of SMC has been generalized to End(X)=a division
  k-algebra, an appendix about exceptional mutation has been added, to appear
  in International Mathematics Research Notices",,,,"math.RT math.CO math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish a bijection between $d$-simple-minded systems ($d$-SMSs) of
$(-d)$-Calabi-Yau cluster category ${\cal C_{-d}}(H)$ and silting objects of
${\cal D^{\rm b}}(H)$ contained in $\cal D^{\le 0}\cap \cal D^{\ge 1-d}$ for
hereditary algebra $H$ of Dynkin type and $d\ge 1$. We show that the number of
$d$-SMSs in ${\cal C_{-d}}(H)$ is the positive Fuss-Catalan number
$C_{d}^{+}(W)$ of the corresponding Weyl group $W$, by applying this bijection
and Buan-Reiten-Thomas' and Zhu's results on Fomin-Reading's generalized
cluster complexes. Our results are based on a refined version of
silting-$t$-structure correspondence.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:32:07 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 15:48:08 GMT""},{""version"":""v3"",""created"":""Wed, 22 Dec 2021 21:44:49 GMT""}]","2021-12-24"
"2002.09953","Jean-Luc Thiffeault","Bryan W. Oakley, Jean-Luc Thiffeault, and Charles R. Doering","On mix-norms and the rate of decay of correlations","24 pages, 4 figures. LaTeX with AMSArt document class","Nonlinearity 34(6), 3762 (2021)","10.1088/1361-6544/abdbbd",,"math.DS nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two quantitative notions of mixing are the decay of correlations and the
decay of a mix-norm -- a negative Sobolev norm -- and the intensity of mixing
can be measured by the rates of decay of these quantities. From duality,
correlations are uniformly dominated by a mix-norm; but can they decay
asymptotically faster than the mix-norm? We answer this question by
constructing an observable with correlation that comes arbitrarily close to
achieving the decay rate of the mix-norm. Therefore the mix-norm is the
sharpest rate of decay of correlations in both the uniform sense and the
asymptotic sense. Moreover, there exists an observable with correlation that
decays at the same rate as the mix-norm if and only if the rate of decay of the
mix-norm is achieved by its projection onto low-frequency Fourier modes. In
this case, the function being mixed is called q-recurrent; otherwise it is
q-transient. We use this classification to study several examples and raise
questions for future investigations.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:43:27 GMT""}]","2021-09-27"
"2002.09954","Luigi Carratino","Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, Michal
  Valko, Lorenzo Rosasco","Near-linear Time Gaussian Process Optimization with Adaptive Batching
  and Resparsification",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gaussian processes (GP) are one of the most successful frameworks to model
uncertainty. However, GP optimization (e.g., GP-UCB) suffers from major
scalability issues. Experimental time grows linearly with the number of
evaluations, unless candidates are selected in batches (e.g., using GP-BUCB)
and evaluated in parallel. Furthermore, computational cost is often prohibitive
since algorithms such as GP-BUCB require a time at least quadratic in the
number of dimensions and iterations to select each batch. In this paper, we
introduce BBKB (Batch Budgeted Kernel Bandits), the first no-regret GP
optimization algorithm that provably runs in near-linear time and selects
candidates in batches. This is obtained with a new guarantee for the tracking
of the posterior variances that allows BBKB to choose increasingly larger
batches, improving over GP-BUCB. Moreover, we show that the same bound can be
used to adaptively delay costly updates to the sparse GP approximation used by
BBKB, achieving a near-constant per-step amortized cost. These findings are
then confirmed in several experiments, where BBKB is much faster than
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:43:29 GMT""},{""version"":""v2"",""created"":""Wed, 26 Feb 2020 09:45:29 GMT""}]","2020-02-27"
"2002.09955","Xu-Dong Sun","Sun Xu-Dong and Dai Ben-Zhong","Observational constraints on dark matter decaying via gravity portals",,,"10.1088/1674-1137/abb4d5",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Global symmetry can guarantee the stability of dark matter particles (DMps).
However, the nonminimal coupling between dark matter (DM) and gravity can
destroy the global symmetry of DMps, which in turn leads to their decay. Under
the framework of nonminimal coupling between scalar singlet dark matter (ssDM)
and gravity, it is worth exploring to what extent the symmetry of ssDM is
broken. It is suggested that the total amount of decay products of ssDM cannot
exceed current observational constraints. Along these lines, the data obtained
with satellites such as Fermi-LAT and AMS-02 can limit the strength of the
global symmetry breaking of ssDM. Since the mass of many well--motivated DM
candidates may be in the GeV--TeV range, we determine a reasonable parameter
range for the lifetime in this range. We find that when the mass of the ssDM is
around the electroweak scale (246 GeV), the corresponding 3--$\sigma$ lower
limits of the lifetime of ssDM is $5.3\times10^{26}$ s. Our analysis of ssDM
around the typical electroweak scale contains the most abundant decay channels
of all mass range, so the analysis of the behaviour of ssDM under the influence
of gravity is more comprehensive.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:53:58 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 10:14:06 GMT""},{""version"":""v3"",""created"":""Mon, 13 Apr 2020 14:09:41 GMT""},{""version"":""v4"",""created"":""Wed, 13 May 2020 14:03:42 GMT""},{""version"":""v5"",""created"":""Wed, 22 Jul 2020 20:42:00 GMT""},{""version"":""v6"",""created"":""Thu, 13 Aug 2020 15:03:40 GMT""},{""version"":""v7"",""created"":""Mon, 17 Aug 2020 07:28:11 GMT""}]","2020-09-07"
"2002.09956","Yingxue Zhou","Arindam Banerjee, Tiancong Chen and Yingxue Zhou","De-randomized PAC-Bayes Margin Bounds: Applications to Non-convex and
  Non-smooth Predictors",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In spite of several notable efforts, explaining the generalization of
deterministic non-smooth deep nets, e.g., ReLU-nets, has remained challenging.
Existing approaches for deterministic non-smooth deep nets typically need to
bound the Lipschitz constant of such deep nets but such bounds are quite large,
may even increase with the training set size yielding vacuous generalization
bounds. In this paper, we present a new family of de-randomized PAC-Bayes
margin bounds for deterministic non-convex and non-smooth predictors, e.g.,
ReLU-nets. Unlike PAC-Bayes, which applies to Bayesian predictors, the
de-randomized bounds apply to deterministic predictors like ReLU-nets. A
specific instantiation of the bound depends on a trade-off between the
(weighted) distance of the trained weights from the initialization and the
effective curvature (`flatness') of the trained predictor.
  To get to these bounds, we first develop a de-randomization argument for
non-convex but smooth predictors, e.g., linear deep networks (LDNs), which
connects the performance of the deterministic predictor with a Bayesian
predictor. We then consider non-smooth predictors which for any given input
realized as a smooth predictor, e.g., ReLU-nets become some LDNs for any given
input, but the realized smooth predictors can be different for different
inputs. For such non-smooth predictors, we introduce a new PAC-Bayes analysis
which takes advantage of the smoothness of the realized predictors, e.g., LDN,
for a given input, and avoids dependency on the Lipschitz constant of the
non-smooth predictor. After careful de-randomization, we get a bound for the
deterministic non-smooth predictor. We also establish non-uniform sample
complexity results based on such bounds. Finally, we present extensive
empirical results of our bounds over changing training set size and randomness
in labels.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:54:07 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 06:56:39 GMT""},{""version"":""v3"",""created"":""Thu, 12 Nov 2020 01:29:31 GMT""}]","2020-11-13"
"2002.09957","Michele Schiavina","Kasia Rejzner, Michele Schiavina","Asymptotic symmetries in the BV-BFV formalism","Significantly improved version. Added calculation of hard scalar
  asymptotic charges, and comparison with Noether analysis. 43 pages",,"10.1007/s00220-021-04061-7",,"math-ph hep-th math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how to derive asymptotic charges for field theories on manifolds with
""asymptotic"" boundary, using the BV-BFV formalism. We also prove that the
conservation of said charges follows naturally from the vanishing of the BFV
boundary action, and show how this construction generalises Noether's
procedure. Using the BV-BFV viewpoint, we resolve the controversy present in
the literature, regarding the status of large gauge transformation as
symmetries of the asymptotic structure. We show that even though the symplectic
structure at the asymptotic boundary is not preserved under these
transformations, the failure is governed by the corner data, in agreement with
the BV-BFV philosophy. We analyse in detail the case of electrodynamics and the
interacting scalar field, for which we present a new type of duality to a
sourced two-form model.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:55:56 GMT""},{""version"":""v2"",""created"":""Thu, 6 Aug 2020 13:05:08 GMT""}]","2021-04-21"
"2002.09958","Sai Aparna Aketi","Sai Aparna Aketi, Sourjya Roy, Anand Raghunathan, Kaushik Roy","Gradual Channel Pruning while Training using Feature Relevance Scores
  for Convolutional Neural Networks","15 pages, 2 figures, 4 tables",,"10.1109/ACCESS.2020.3024992",,"cs.LG cs.CV cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The enormous inference cost of deep neural networks can be scaled down by
network compression. Pruning is one of the predominant approaches used for deep
network compression. However, existing pruning techniques have one or more of
the following limitations: 1) Additional energy cost on top of the compute
heavy training stage due to pruning and fine-tuning stages, 2) Layer-wise
pruning based on the statistics of a particular, ignoring the effect of error
propagation in the network, 3) Lack of an efficient estimate for determining
the important channels globally, 4) Unstructured pruning requires specialized
hardware for effective use. To address all the above issues, we present a
simple-yet-effective gradual channel pruning while training methodology using a
novel data-driven metric referred to as feature relevance score. The proposed
technique gets rid of the additional retraining cycles by pruning the least
important channels in a structured fashion at fixed intervals during the actual
training phase. Feature relevance scores help in efficiently evaluating the
contribution of each channel towards the discriminative power of the network.
We demonstrate the effectiveness of the proposed methodology on architectures
such as VGG and ResNet using datasets such as CIFAR-10, CIFAR-100 and ImageNet,
and successfully achieve significant model compression while trading off less
than $1\%$ accuracy. Notably on CIFAR-10 dataset trained on ResNet-110, our
approach achieves $2.4\times$ compression and a $56\%$ reduction in FLOPs with
an accuracy drop of $0.01\%$ compared to the unpruned network.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:56:18 GMT""},{""version"":""v2"",""created"":""Wed, 29 Apr 2020 15:01:47 GMT""}]","2020-10-13"
"2002.09959","Tuna Bayrakdar Bayrakdar","Tuna Bayrakdar","Sasakian structure associated with a second order ODE and Hamiltonian
  dynamical systems",,,"10.1007/s41980-021-00613-8",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a contact metric structure on the manifold corresponding to a
second order ordinary differential equation $d^2y/dx^2=f(x,y,y')$ and show that
the contact metric structure is Sasakian if and only if the 1-form
$\frac{1}{2}(dp-fdx)$ defines a Poisson structure. We consider a Hamiltonian
dynamical system defined by this Poisson structure and show that the
Hamiltonian vector field, which is a multiple of the Reeb vector field, admits
a compatible bi-Hamiltonian structure for which $f$ can be regarded as a
Hamiltonian function. As a particular case, we give a compatible bi-Hamiltonian
structure of the Reeb vector field such that the structure equations correspond
to the Maurer-Cartan equations of an invariant coframe on the Heisenberg group
and the independent variable plays the role of a Hamiltonian function. We also
show that the first Chern class of the normal bundle of an integral curve of a
multiple of the Reeb vector field vanishes iff $f_x+ff_p = \Psi (x)$ for some
$\Psi$.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:59:51 GMT""},{""version"":""v2"",""created"":""Sat, 24 Oct 2020 09:43:33 GMT""},{""version"":""v3"",""created"":""Mon, 14 Jun 2021 14:23:41 GMT""}]","2021-09-01"
"2002.09960","Mahmoud Sebtosheikh","Mahmoud Sebtosheikh, Ali Naji","Effective interactions mediated between two permeable disks in an active
  fluid","10 pages, 8 figures","Sci. Rep. 10, 15570 (2020)","10.1038/s41598-020-71209-1",,"cond-mat.soft cond-mat.stat-mech physics.bio-ph physics.chem-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study steady-state properties of a bath of active Brownian particles
(ABPs) in two dimensions in the presence of two fixed, permeable (hollow)
disklike inclusions, whose interior and exterior regions can exhibit
mismatching motility (self-propulsion) strengths for the ABPs. We show that
such a discontinuous motility field strongly affects spatial distribution of
ABPs and thus also the effective interaction mediated between the inclusions
through the active bath. Such net interactions arise from soft interfacial
repulsions between ABPs that sterically interact with and/or pass through
permeable membranes assumed to enclose the inclusions. Both regimes of
repulsion and attractive (albeit with different mechanisms) are reported and
summarized in overall phase diagrams.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:09:37 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 16:02:15 GMT""}]","2021-07-20"
"2002.09961","Mehdi Shafiei Aporvari","Mehdi Shafiei Aporvari, Mustafa Utkur, Emine Ulku Saritas, Giovanni
  Volpe, Joakim Stenhammar","Anisotropic dynamics of a self-assembled colloidal chain in an active
  bath",,"Soft Matter 16, 5609 (2020)","10.1039/d0sm00318b",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anisotropic macromolecules exposed to non-equilibrium (active) noise are very
common in biological systems, and an accurate understanding of their
anisotropic dynamics is therefore crucial. Here, we experimentally investigate
the dynamics of isolated chains assembled from magnetic microparticles at a
liquid-air interface and moving in an active bath consisting of motile E. coli
bacteria. We investigate both the internal chain dynamics and the anisotropic
center-of-mass dynamics through particle tracking. We find that both the
internal and center-of-mass dynamics are greatly enhanced compared to the
passive case, i.e., a system without bacteria, and that the center-of-mass
diffusion coefficient $D$ features a non-monotonic dependence as a function of
the chain length. Furthermore, our results show that the relationship between
the components of $D$ parallel and perpendicular with respect to the direction
of the applied magnetic field is preserved in the active bath compared to the
passive case, with a higher diffusion in the parallel direction, in contrast to
previous findings in the literature. We argue that this qualitative difference
is due to subtle differences in the experimental geometry and conditions and
the relative roles played by long-range hydrodynamic interactions and
short-range collisions.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:19:06 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 21:18:48 GMT""}]","2020-07-08"
"2002.09962","Vahid Hosseinzadeh","H. Adami, V. Hosseinzadeh, M. M. Sheikh-Jabbari","Sliding Surface Charges on AdS$_3$","14 pages, 2 figures",,"10.1016/j.physletb.2020.135503","IPM/P-2020/005","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider Einstein gravity on a patch of AdS$_3$ spacetime between two
radii $r_1, r_2$. We compute surface charges and their algebra at an arbitrary
radius $r$ such that it reduces to a given set of surface charges at $r_1,
r_2$. The $r$-dependent charges become integrable upon addition of an
appropriate boundary $Y$-term. We observe that soft excitations at each
boundary are independent of those at the other boundary. We explicitly
construct solution geometries which interpolate between these radii with
specified surface charges. The interpolation is smooth provided that the mass
and angular momentum measured at the two boundaries are equal.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:19:25 GMT""}]","2020-06-24"
"2002.09963","Matthew Almeida","Matthew Almeida, Wei Ding, Scott Crouter, Ping Chen","Mitigating Class Boundary Label Uncertainty to Reduce Both Model Bias
  and Variance",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The study of model bias and variance with respect to decision boundaries is
critically important in supervised classification. There is generally a
tradeoff between the two, as fine-tuning of the decision boundary of a
classification model to accommodate more boundary training samples (i.e.,
higher model complexity) may improve training accuracy (i.e., lower bias) but
hurt generalization against unseen data (i.e., higher variance). By focusing on
just classification boundary fine-tuning and model complexity, it is difficult
to reduce both bias and variance. To overcome this dilemma, we take a different
perspective and investigate a new approach to handle inaccuracy and uncertainty
in the training data labels, which are inevitable in many applications where
labels are conceptual and labeling is performed by human annotators. The
process of classification can be undermined by uncertainty in the labels of the
training data; extending a boundary to accommodate an inaccurately labeled
point will increase both bias and variance. Our novel method can reduce both
bias and variance by estimating the pointwise label uncertainty of the training
set and accordingly adjusting the training sample weights such that those
samples with high uncertainty are weighted down and those with low uncertainty
are weighted up. In this way, uncertain samples have a smaller contribution to
the objective function of the model's learning algorithm and exert less pull on
the decision boundary. In a real-world physical activity recognition case
study, the data presents many labeling challenges, and we show that this new
approach improves model performance and reduces model variance.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:24:04 GMT""}]","2020-02-25"
"2002.09964","Hossein Taheri","Hossein Taheri, Aryan Mokhtari, Hamed Hassani, Ramtin Pedarsani","Quantized Decentralized Stochastic Learning over Directed Graphs",,,,,"cs.DC cs.LG cs.MA cs.SY eess.SP eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a decentralized stochastic learning problem where data points are
distributed among computing nodes communicating over a directed graph. As the
model size gets large, decentralized learning faces a major bottleneck that is
the heavy communication load due to each node transmitting large messages
(model updates) to its neighbors. To tackle this bottleneck, we propose the
quantized decentralized stochastic learning algorithm over directed graphs that
is based on the push-sum algorithm in decentralized consensus optimization.
More importantly, we prove that our algorithm achieves the same convergence
rates of the decentralized stochastic learning algorithm with
exact-communication for both convex and non-convex losses. Numerical
evaluations corroborate our main theoretical results and illustrate significant
speed-up compared to the exact-communication methods.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:25:39 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 09:12:25 GMT""},{""version"":""v3"",""created"":""Mon, 6 Jul 2020 07:41:26 GMT""},{""version"":""v4"",""created"":""Tue, 21 Jul 2020 17:06:54 GMT""},{""version"":""v5"",""created"":""Mon, 28 Dec 2020 10:02:25 GMT""}]","2020-12-29"
"2002.09965","Sergei Nechaev","Alexander Vladimirov, Senya Shlosman, and Sergei Nechaev","Brownian flights over a circle","7 pages, 1 figure","Phys. Rev. E 102, 012124 (2020)","10.1103/PhysRevE.102.012124",,"math.PR cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The stationary radial distribution, $P(\rho)$, of the random walk with the
diffusion coefficient $D$, which winds with the tangential velocity $V$ around
the impenetrable disc of radius $R$ for $R\gg 1$ converges to the distribution
involving the Airy function. Typical trajectories are localized in the circular
strip $[R, R+ \delta R^{1/3}]$, where $\delta$ is the constant which depends on
the parameters $D$ and $V$ and is independent on $R$.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:35:32 GMT""},{""version"":""v2"",""created"":""Mon, 23 Mar 2020 16:51:51 GMT""}]","2020-07-15"
"2002.09966","Keegan Anderson","K.D. Anderson, C.M. Villet","Computational study of the dynamics of an asymmetric wedge billiard","22 pages, 11 figures. International Journal of Bifurcation and Chaos
  (July 2020)","International Journal of Bifurcation and Chaos vol 31, no 2 (2021)","10.1142/S0218127421300068",,"nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the asymmetric wedge billiard as a generalization of the wedge
billiard first introduced and studied by Lehtihet and Miller in 1986.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:36:07 GMT""}]","2021-03-01"
"2002.09967","Matteo Bonforte","Matteo Bonforte and Nikita Simonov","Fine properties of solutions to the Cauchy problem for a Fast Diffusion
  Equation with Caffarelli-Kohn-Nirenberg weights","43 pages, 4 figures",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate fine global properties of nonnegative, integrable solutions to
the Cauchy problem for the Fast Diffusion Equation with weights (WFDE)
$u_t=|x|^\gamma\mathrm{div}\left(|x|^{-\beta}\nabla u^m\right)$ posed on
$(0,+\infty)\times\mathbb{R}^d$, with $d\ge 3$, in the so-called good fast
diffusion range $m_c<m<1$, within the range of parameters $\gamma, \beta$,
optimal for the validity of the so-called Caffarelli-Kohn-Nirenberg
inequalities. It is a natural question to ask in which sense such solutions
behave like the Barenblatt $\mathfrak{B}$ (fundamental solution): for instance,
asymptotic convergence, i.e. $\|u(t)-\mathfrak{B}(t)\|_{{\rm
L}^p(\mathbb{R}^d)}\xrightarrow[]{t\to\infty}0$, is well known for all $1\le
p\le \infty$, while only few partial results tackle a finer analysis of the
tail behaviour. We characterize the maximal set of data $\mathcal{X}\subset{\rm
L}^1_+(\mathbb{R}^d)$ that produces solutions which are pointwise trapped
between two Barenblatt (Global Harnack Principle), and uniformly converge in
relative error (UREC), i.e. ${\rm
d}_\infty(u(t))=\|u(t)/\mathcal{B}(t)-1\|_{{\rm
L}^\infty(\mathbb{R}^d)}\xrightarrow[]{t\to\infty}0$. Such characterization is
in terms of an integral condition on $u(t=0)$. To the best of our knowledge,
analogous issues for the linear heat equation $m=1$, do not possess such clear
answers. Our characterization is also new for the classical, non-weighted, FDE.
We are able to provide minimal rates of convergence to $\mathcal{B}$ in
different norms. Such rates are almost optimal in the non weighted case, and
become optimal for radial solutions. To complete the panorama, we show that
solutions with data in ${\rm L}^1_+(\mathbb{R}^d)\setminus\mathcal{X}$,
preserve the same ""fat"" spatial tail for all times, hence UREC fails.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:48:59 GMT""},{""version"":""v2"",""created"":""Thu, 23 Apr 2020 16:04:35 GMT""}]","2020-04-24"
"2002.09968","Simone Giannerini","Kung-Sik Chan, Simone Giannerini, Greta Goracci, Howell Tong","Testing for threshold regulation in presence of measurement error with
  an application to the PPP hypothesis",,,,,"stat.ME econ.EM math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Regulation is an important feature characterising many dynamical phenomena
and can be tested within the threshold autoregressive setting, with the null
hypothesis being a global non-stationary process. Nonetheless, this setting is
debatable since data are often corrupted by measurement errors. Thus, it is
more appropriate to consider a threshold autoregressive moving-average model as
the general hypothesis. We implement this new setting with the integrated
moving-average model of order one as the null hypothesis. We derive a Lagrange
multiplier test which has an asymptotically similar null distribution and
provide the first rigorous proof of tightness pertaining to testing for
threshold nonlinearity against difference stationarity, which is of independent
interest. Simulation studies show that the proposed approach enjoys less bias
and higher power in detecting threshold regulation than existing tests when
there are measurement errors. We apply the new approach to the daily real
exchange rates of Eurozone countries. It lends support to the purchasing power
parity hypothesis, via a nonlinear mean-reversion mechanism triggered upon
crossing a threshold located in the extreme upper tail. Furthermore, we analyse
the Eurozone series and propose a threshold autoregressive moving-average
specification, which sheds new light on the purchasing power parity debate.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:54:51 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 06:17:38 GMT""},{""version"":""v3"",""created"":""Wed, 17 Nov 2021 08:32:34 GMT""}]","2021-11-18"
"2002.09969","Yurii A. Neretin","Yury A. Neretin","Groups $GL(\infty)$ over finite fields and multiplications of double
  cosets","48pp, a revised version","J. of Algebra, 2021","10.1016/j.jalgebra.2021.06.011",,"math.RT math.CT math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathbb F$ be a finite field. Consider a direct sum $V$ of an infinite
number of copies of $\mathbb F$, consider the dual space $V^\diamond$, i.~e.,
the direct product of an infinite number of copies of $\mathbb F$. Consider the
direct sum ${\mathbb V}=V\oplus V^\diamond$. The object of the paper is the
group $\mathbf{GL}$ of continuous linear operators in $\mathbb V$. We reduce
the theory of unitary representations of $\mathbf{GL}$ to projective
representations of a certain category whose morphisms are linear relations in
finite-dimensional linear spaces over $\mathbb F$. In fact we consider a
certain family $ Q_\alpha$ of subgroups in $\mathbb V$ preserving two-element
flags, show that there is a natural multiplication on spaces of double cosets
with respect to $ Q_\alpha$, and reduce this multiplication to products of
linear relations. We show that this group has type $\mathrm{I}$ and obtain an
'upper estimate' of the set of all irreducible unitary representations of
$\mathbf{GL}$.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:54:59 GMT""},{""version"":""v2"",""created"":""Sun, 1 Nov 2020 21:02:34 GMT""}]","2021-06-24"
"2002.09970","Mario Krenn","Mario Krenn, Manuel Erhard, Anton Zeilinger","Computer-inspired Quantum Experiments","Comments and suggestions for additional references are welcome!","Nature Reviews Physics 2, 649-661 (2020)","10.1038/s42254-020-0230-4",,"quant-ph cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The design of new devices and experiments in science and engineering has
historically relied on the intuitions of human experts. This credo, however,
has changed. In many disciplines, computer-inspired design processes, also
known as inverse-design, have augmented the capability of scientists. Here we
visit different fields of physics in which computer-inspired designs are
applied. We will meet vastly diverse computational approaches based on
topological optimization, evolutionary strategies, deep learning, reinforcement
learning or automated reasoning. Then we draw our attention specifically on
quantum physics. In the quest for designing new quantum experiments, we face
two challenges: First, quantum phenomena are unintuitive. Second, the number of
possible configurations of quantum experiments explodes combinatorially. To
overcome these challenges, physicists began to use algorithms for
computer-designed quantum experiments. We focus on the most mature and
\textit{practical} approaches that scientists used to find new complex quantum
experiments, which experimentalists subsequently have realized in the
laboratories. The underlying idea is a highly-efficient topological search,
which allows for scientific interpretability. In that way, some of the
computer-designs have led to the discovery of new scientific concepts and ideas
-- demonstrating how computer algorithm can genuinely contribute to science by
providing unexpected inspirations. We discuss several extensions and
alternatives based on optimization and machine learning techniques, with the
potential of accelerating the discovery of practical computer-inspired
experiments or concepts in the future. Finally, we discuss what we can learn
from the different approaches in the fields of physics, and raise several
fascinating possibilities for future research.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:59:00 GMT""}]","2020-10-28"
"2002.09971","Sabina Tomkins","Sabina Tomkins, Peng Liao, Predrag Klasnja, Serena Yeung, Susan Murphy","Rapidly Personalizing Mobile Health Treatment Policies with Limited Data",,,,,"cs.LG cs.CY stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In mobile health (mHealth), reinforcement learning algorithms that adapt to
one's context without learning personalized policies might fail to distinguish
between the needs of individuals. Yet the high amount of noise due to the in
situ delivery of mHealth interventions can cripple the ability of an algorithm
to learn when given access to only a single user's data, making personalization
challenging. We present IntelligentPooling, which learns personalized policies
via an adaptive, principled use of other users' data. We show that
IntelligentPooling achieves an average of 26% lower regret than
state-of-the-art across all generative models. Additionally, we inspect the
behavior of this approach in a live clinical trial, demonstrating its ability
to learn from even a small group of users.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 18:59:46 GMT""}]","2020-02-25"
"2002.09972","Ashwin Jacob","Ashwin Jacob, Fahad Panolan, Venkatesh Raman and Vibha Sahlot","Structural Parameterizations with Modulator Oblivion",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that problems like Vertex Cover, Feedback Vertex Set and Odd
Cycle Transversal are polynomial time solvable in the class of chordal graphs.
We consider these problems in a graph that has at most $k$ vertices whose
deletion results in a chordal graph, when parameterized by $k$. While this
investigation fits naturally into the recent trend of what are called
`structural parameterizations', here we assume that the deletion set is not
given.
  One method to solve them is to compute a $k$-sized or an approximate ($f(k)$
sized, for a function $f$) chordal vertex deletion set and then use the
structural properties of the graph to design an algorithm. This method leads to
at least $k^{\mathcal{O}(k)}n^{\mathcal{O}(1)}$ running time when we use the
known parameterized or approximation algorithms for finding a $k$-sized chordal
deletion set on an $n$ vertex graph.
  In this work, we design $2^{\mathcal{O}(k)}n^{\mathcal{O}(1)}$ time
algorithms for these problems. Our algorithms do not compute a chordal vertex
deletion set (or even an approximate solution). Instead, we construct a tree
decomposition of the given graph in time $2^{\mathcal{O}(k)}n^{\mathcal{O}(1)}$
where each bag is a union of four cliques and $\mathcal{O}(k)$ vertices. We
then apply standard dynamic programming algorithms over this special tree
decomposition. This special tree decomposition can be of independent interest.
  Our algorithms are adaptive (robust) in the sense that given an integer $k$,
they detect whether the graph has a chordal vertex deletion set of size at most
$k$ or output the special tree decomposition and solve the problem.
  We also show lower bounds for the problems we deal with under the Strong
Exponential Time Hypothesis (SETH).
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 19:00:23 GMT""}]","2020-02-25"
"2002.09973","Tommaso Dorigo","Tommaso Dorigo","Geometry Optimization of a Muon-Electron Scattering Experiment","54 pages, 25 figures",,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A high-statistics determination of the differential cross section of elastic
muon-electron scattering as a function of the transferred four-momentum
squared, $d \sigma_{el}(\mu e \to \mu e)/dq^2$, has been argued to provide an
effective constraint to the hadronic contribution to the running of the
fine-structure constant, $\Delta \alpha_{had}$, a crucial input for precise
theoretical predictions of the anomalous magnetic moment of the muon. An
experiment called ``MUonE'' is being planned at the north area of CERN for that
purpose. We consider the geometry of the detector proposed by the MUonE
collaboration and offer a few suggestions on the layout of the passive target
material and on the placement of silicon strip sensors, based on a fast
simulation of elastic muon-electron scattering events and the investigation of
a number of possible solutions for the detector geometry.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 19:11:12 GMT""}]","2020-02-25"
"2002.09974","Hamid R. Bakhtiarizadeh","Hamid R. Bakhtiarizadeh, Ghadir Jafari","Holographic complexity of Born-Infeld gravity","LaTex file, 10 pages, 1 figure, To appear in EPJC",,"10.1140/epjc/s10052-020-7766-4",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We investigate the duality conjecture ""Complexity=Action"" (CA) for
Born-Infeld (BI) gravity model and derive the growth rate of its action within
the Wheeler-DeWitt (WDW) patch, which is believed to be dual to the growth rate
of quantum complexity of holographic boundary state. In order to find the
correct on-shell action, we use direct variational procedure to find proper
boundary and corner terms. We find out that the late-time behavior of
holographic complexity is the well-known two times of energy, as expected.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 19:11:38 GMT""}]","2020-04-22"
"2002.09975","J\=anis Priede","Gerasimos Politis and J\=anis Priede","Fractality of metal pad instability threshold in rectangular cells","21 pages, 6 figures (final version; to appear in J. Fluid Mech.)","J. Fluid Mech. 915 (2021) A101","10.1017/jfm.2021.100",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyse linear stability of interfacial waves in an idealised model of an
aluminium reduction cell consisting of two stably stratified liquid layers
which carry a vertical electric current in a collinear external magnetic field.
If the product of electric current and magnetic field exceeds a certain
critical threshold depending on the cell design, the electromagnetic coupling
of gravity wave modes can give rise to a self-amplifying rotating interfacial
wave which is known as the metal pad instability. Using the eigenvalue
perturbation method, we show that, in the inviscid limit, rectangular cells of
horizontal aspect ratios $\alpha=\sqrt{m/n}$, where $m$ and $n$ are any two odd
numbers, can be destabilised by an infinitesimally weak electromagnetic
interaction while cells of other aspect ratios have finite instability
thresholds. This fractal distribution of critical aspect ratios, which form an
absolutely discontinuous dense set of points interspersed with aspect ratios
with non-zero stability thresholds, is confirmed by accurate numerical solution
of the linear stability problem. Although the fractality vanishes when viscous
friction is taken into account, the instability threshold is smoothed out
gradually and its principal structure, which is dominated by the major critical
aspect ratios corresponding to moderate values of $m$ and $n$, is
well-preserved up to relatively large dimensionless viscous friction
coefficients $\gamma\sim 0.1$. With a small viscous friction, the most stable
are cells with $\alpha^{2}\approx2.13$ which have the highest stability
threshold corresponding to the electromagnetic interaction parameter
$\beta\approx 4.7$.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 19:32:36 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 14:32:22 GMT""},{""version"":""v3"",""created"":""Thu, 4 Mar 2021 15:11:54 GMT""}]","2021-07-01"
"2002.09976","Donniell Fishkind","Donniell E. Fishkind, Avanti Athreya, Lingyao Meng, Vince Lyzinski,
  Carey E. Priebe","On a complete and sufficient statistic for the correlated Bernoulli
  random graph model",,,,,"math.ST stat.ME stat.TH","http://creativecommons.org/licenses/by-sa/4.0/","  Inference on vertex-aligned graphs is of wide theoretical and practical
importance.There are, however, few flexible and tractable statistical models
for correlated graphs, and even fewer comprehensive approaches to parametric
inference on data arising from such graphs. In this paper, we consider the
correlated Bernoulli random graph model (allowing different Bernoulli
coefficients and edge correlations for different pairs of vertices), and we
introduce a new variance-reducing technique -- called \emph{balancing} -- that
can refine estimators for model parameters. Specifically, we construct a
disagreement statistic and show that it is complete and sufficient; balancing
can be interpreted as Rao-Blackwellization with this disagreement statistic. We
show that for unbiased estimators of functions of model parameters, balancing
generates uniformly minimum variance unbiased estimators (UMVUEs). However,
even when unbiased estimators for model parameters do {\em not} exist -- which,
as we prove, is the case with both the heterogeneity correlation and the total
correlation parameters -- balancing is still useful, and lowers mean squared
error. In particular, we demonstrate how balancing can improve the efficiency
of the alignment strength estimator for the total correlation, a parameter that
plays a critical role in graph matchability and graph matching runtime
complexity.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 19:37:22 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 18:48:16 GMT""}]","2021-04-01"
"2002.09977","Tao Li","Tao E. Li, Abraham Nitzan, Joseph E. Subotnik","On the Origin of Ground-State Vacuum-Field Catalysis: Equilibrium
  Consideration",,"J. Chem. Phys. 152, 234107 (2020)","10.1063/5.0006472",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experiments suggest that vibrational strong coupling (VSC) may
significantly modify ground-state chemical reactions and their rates even
without external pumping. The intrinsic mechanism of this ""vacuum-field
catalysis"" remains largely unclear. Generally, modifications of thermal
reactions in the ground electronic states can be caused by equilibrium or
non-equilibrium effects. The former are associated with modifications of the
reactant equilibrium distribution as expressed by the transition state theory
of chemical reaction rates, while the latter stem from the dynamics of reaching
and leaving transition configurations. Here, we examine the VSC effect in a
cavity environment on chemical rates as calculated by transition state theory.
Our approach is to examine the effect of coupling to cavity mode(s) on the
potential of mean force (PMF) associated with the reaction coordinate. Within
the context of classical nuclei and classical photons, we find that while the
PMF can be affected by the cavity environment, this effect is negligible for
the usual cavities used to examine VSC situations.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 19:59:42 GMT""},{""version"":""v2"",""created"":""Wed, 6 May 2020 17:03:55 GMT""}]","2020-06-17"
"2002.09978","Priyanka Priyanka","Riya Nandi and Priyanka","One Dimensional Exclusion Process with Dynein Inspired Hops: Simulation
  and Mean Field Analysis",,"J Stat Phys 182, 29 (2021)","10.1007/s10955-021-02711-7",,"cond-mat.stat-mech nlin.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a one-dimensional non-equilibrium lattice gas model representing
the processive motion of dynein molecular motors over the microtubule. We study
both dynamical and stationary state properties for the model consisting of
hardcore particles hopping on the lattice with variable step sizes. We find
that the stationary state gap-distribution exhibits striking peaks around gap
sizes that are multiples of the maximum step size, for both open and periodic
boundary conditions. We verified this feature using a mean-field calculation.
For open boundary conditions, we observe intriguing damped oscillator-like
distribution of particles over the lattice with a periodicity equal to the
maximum step size. To characterize transient dynamics, we measure the mean
square displacement that shows weak superdiffusive growth with exponent $\gamma
\approx 1.34$ for periodic boundary and ballistic growth ($\gamma \approx 2$)
for open boundary conditions at early times. We also study the effect of
Langmuir dynamics on the density profile.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:05:15 GMT""},{""version"":""v2"",""created"":""Mon, 20 Apr 2020 19:39:04 GMT""},{""version"":""v3"",""created"":""Fri, 9 Oct 2020 03:03:23 GMT""}]","2021-02-03"
"2002.09979","Miguel Arduengo","Miguel Arduengo, Adri\`a Colom\'e, Joan Lobo-Prat, Luis Sentis and
  Carme Torras","Gaussian-Process-based Robot Learning from Demonstration","8 pages, 10 figures","Journal of Ambient Intelligence and Humanized Computing, 2023","10.1007/s12652-023-04551-7",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Endowed with higher levels of autonomy, robots are required to perform
increasingly complex manipulation tasks. Learning from demonstration is arising
as a promising paradigm for transferring skills to robots. It allows to
implicitly learn task constraints from observing the motion executed by a human
teacher, which can enable adaptive behavior. We present a novel
Gaussian-Process-based learning from demonstration approach. This probabilistic
representation allows to generalize over multiple demonstrations, and encode
variability along the different phases of the task. In this paper, we address
how Gaussian Processes can be used to effectively learn a policy from
trajectories in task space. We also present a method to efficiently adapt the
policy to fulfill new requirements, and to modulate the robot behavior as a
function of task variability. This approach is illustrated through a real-world
application using the TIAGo robot.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:06:13 GMT""},{""version"":""v2"",""created"":""Thu, 28 May 2020 19:30:05 GMT""}]","2023-02-24"
"2002.09980","Rajula Srivastava","Rajula Srivastava","Orthogonal Systems of Spline Wavelets as Unconditional Bases in Sobolev
  Spaces","21 pages, 1 figure",,,,"math.CA cs.NA math.FA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We exhibit the necessary range for which functions in the Sobolev spaces
$L^s_p$ can be represented as an unconditional sum of orthonormal spline
wavelet systems, such as the Battle-Lemari\'e wavelets. We also consider the
natural extensions to Triebel-Lizorkin spaces. This builds upon, and is a
generalization of, previous work of Seeger and Ullrich, where analogous results
were established for the Haar wavelet system.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:17:37 GMT""}]","2020-02-25"
"2002.09981","Vakhid Gani","Vakhid A. Gani, Aliakbar Moradi Marjaneh, Petr A. Blinov","Explicit kinks in higher-order field theories","25 pages, 7 figures; v2: major revision; matches the published
  version","Phys. Rev. D 101, 125017 (2020)","10.1103/PhysRevD.101.125017",,"hep-th cond-mat.mtrl-sci math-ph math.MP nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study an example of higher-order field-theoretic model with an
eighth-degree polynomial potential -- the $\varphi^8$ model. We show that for
some certain ratios of constants of the potential, the problem of finding
kink-type solutions in $(1+1)$-dimensional space-time reduces to solving
algebraic equations. For two different ratios of the constants, which determine
positions of the vacua, we obtained explicit formulas for kinks in all
topological sectors. The properties of the obtained kinks are also studied --
their masses are calculated, and the excitation spectra which could be
responsible for the appearance of resonance phenomena in kink-antikink
scattering are found.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:22:00 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 17:37:35 GMT""}]","2020-06-29"
"2002.09982","Yulong Wang","Yulong Wang and Zhijie Xiao","Estimation and Inference about Tail Features with Tail Censored Data",,,,,"econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers estimation and inference about tail features when the
observations beyond some threshold are censored. We first show that ignoring
such tail censoring could lead to substantial bias and size distortion, even if
the censored probability is tiny. Second, we propose a new maximum likelihood
estimator (MLE) based on the Pareto tail approximation and derive its
asymptotic properties. Third, we provide a small sample modification to the MLE
by resorting to Extreme Value theory. The MLE with this modification delivers
excellent small sample performance, as shown by Monte Carlo simulations. We
illustrate its empirical relevance by estimating (i) the tail index and the
extreme quantiles of the US individual earnings with the Current Population
Survey dataset and (ii) the tail index of the distribution of macroeconomic
disasters and the coefficient of risk aversion using the dataset collected by
Barro and Urs{\'u}a (2008). Our new empirical findings are substantially
different from the existing literature.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:43:24 GMT""}]","2020-02-25"
"2002.09983","Jonathan Bradley","Jonathan R. Bradley","Joint spatio-temporal analysis of multiple response types using the
  hierarchical generalized transformation model with application to coronavirus
  disease 2019 and social distancing",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social distancing can be described as an effort to maintain a physical
distance between individuals and has become a necessary public health measure
to combat cornoavirus disease 2019 (COVID-19). Social distancing is known to
weaken incidences and deaths due to COVID-19, however, there are detrimental
economic and psychological effects. This motivates us to analyze incidences
(and deaths) of COVID-19 along with a measure of the health of the US economy
(i.e., the adjusted closing price of the Dow Jones Industrial), and a measure
of the public interest in COVID-19 through Google Trends data. The model we
implement is developed to be easily adapted to a data scientist's preferred
method for continuous data, which is done to aid future analyses of this
important dataset. This dataset consists of multiple response types (e.g.,
continuous-valued, count-valued, binomial counts). Thus, we introduce a
reasonable easy-to-implement all-purpose method that ""converts"" a statistical
model for continuous responses (the preferred model) into a Bayesian model for
multi-response data sets. To do this, we transform the data such that the
continuous-valued transformed data can be reasonably modeled using the
preferred model and the transformation itself is treated as unknown. The
implementation of our approach involves two steps. The first step produces
posterior replicates of the transformed data using a latent conjugate
multivariate (LCM) model. The second step involves generating values from the
posterior distribution implied by the preferred model. We refer to our model as
the hierarchical generalized transformation (HGT) model. In a simulation, we
demonstrate the flexibility of the HGT model by incorporating two different
preferred models: Bayesian additive regression trees (BART) and the spatial
mixed effects (spatio-temporal mixed effects) models.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:43:58 GMT""},{""version"":""v2"",""created"":""Mon, 2 Mar 2020 15:00:35 GMT""},{""version"":""v3"",""created"":""Sun, 19 Apr 2020 00:53:57 GMT""}]","2020-04-21"
"2002.09984","Benjamin Miller","Rapha\""el Carroy and Benjamin D. Miller","Sigma-continuity with closed witnesses",,"Fundamenta Mathematicae 239 (2017) 29 - 42",,,"math.LO math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use variants of the $\mathbb{G}_0$ dichotomy to establish a refinement of
Solecki's basis theorem for the family of Baire-class one functions which are
not $\sigma$-continuous with closed witnesses.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:05:51 GMT""}]","2020-02-25"
"2002.09985","Onirban Islam","Onirban Islam","Relative entanglement entropy of thermal states of Klein-Gordon and
  Dirac quantum field theories","8 pages",,,,"math-ph gr-qc hep-th math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An upper bound of the relative entanglement entropy of thermal states at an
inverse temperature $\beta$ of linear, massive Klein-Gordon and Dirac quantum
field theories across two regions, separated by a nonzero distance $d$ in a
Cauchy hypersurface of an ultrastatic (spin-)spacetime has been computed. This
entanglement measure is bounded by a negative constant times $\ln | \tanh (\pi
d/ 2 \beta) |$ which signifies power law decay for asymptotic $d$ where the
exponent depends on $\beta < \infty$.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:10:02 GMT""}]","2020-02-25"
"2002.09986","Aaron Alejo","Aaron Alejo, Guillermo Marrero Samarin, Richard Warwick, Connor
  McCluskey, Giada Cantono, Tiberio Ceccotti, Sandrine Dosbosz Dufrenoy, Pascal
  Monot, Gianluca Sarri","Non-invasive characterisation of a laser-driven positron beam","7 pages, 5 figures",,"10.1088/1361-6587/ab7e81",,"physics.plasm-ph physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on an indirect and non-invasive method to simultaneously
characterise the energy-dependent emittance and source size of
ultra-relativistic positron beams generated during the propagation of a
laser-wakefield accelerated electron beam through a high-Z converter target.
The strong correlation of the geometrical emittance of the positrons with that
of the scattered electrons allows the former to be inferred, with high
accuracy, from monitoring the latter. The technique has been tested in a
proof-of-principle experiment where, for 100 MeV positrons, we infer
geometrical emittances and source sizes of the order of $\epsilon_{e^+}
\approx$ 3 $\mu$m and $D_{e^+} \approx$ 150 $\mu$m, respectively. This is
consistent with the numerically predicted possibility of achieving sub-$\mu$m
geometrical emittances and micron-scale source sizes at the GeV level.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:11:38 GMT""}]","2020-05-20"
"2002.09987","Pei  Yu","Pei Yu, Yanni Zeng","Visualization of Four Limit Cycles in Near-Integrable Quadratic
  Polynomial Systems","12 pages, 8 figures",,"10.1142/S0218127420502363",,"nlin.CD math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been known for almost $40$ years that general planar quadratic
polynomial systems can have four limit cycles. Recently, four limit cycles were
also found in near-integrable quadratic polynomial systems. To help more people
to understand limit cycles theory, the visualization of such four numerically
simulated limit cycles in quadratic systems has attracted researchers'
attention. However, for near integral systems, such visualization becomes much
more difficult due to limitation on choosing parameter values. In this paper,
we start from the simulation of the well-known quadratic systems constructed
around the end of 1979, then reconsider the simulation of a recently published
quadratic system which exhibits four big size limit cycles, and finally provide
a concrete near-integral quadratic polynomial system to show four normal size
limit cycles.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:12:47 GMT""}]","2020-12-30"
"2002.09988","Igor Bondarev PhD DSc (Habilitation)","Igor V. Bondarev, Oleg L. Berman, Roman Ya. Kezerashvili, and Yurii E.
  Lozovik","Crystal Phases of Charged Interlayer Excitons in van der Waals
  Heterostructures","34 pages, 8 figures, 57 references","Communications Physics 4, 134 (2021)","10.1038/s42005-021-00624-1",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Throughout the years, strongly correlated coherent states of excitons have
been the subject of intense theoretical and experimental studies. This topic
has recently boomed due to new emerging quantum materials such as van der Waals
(vdW) bound atomically thin layers of transition metal dichalcogenides (TMDs).
We analyze the collective properties of charged interlayer excitons observed
recently in bilayer TMD heterostructures. We predict new strongly correlated
phases - crystal and Wigner crystal - that can be selectively realized with TMD
bilayers of properly chosen electron-hole effective masses by just varying
their interlayer separation distance. Our results open up new avenues for
nonlinear coherent control, charge transport and spinoptronics applications
with quantum vdW heterostuctures.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:18:16 GMT""},{""version"":""v2"",""created"":""Tue, 5 May 2020 18:53:09 GMT""},{""version"":""v3"",""created"":""Mon, 8 Feb 2021 15:16:20 GMT""}]","2021-12-30"
"2002.09989","Tapajit Dey","Tapajit Dey, Audris Mockus","Deriving a Usage-Independent Software Quality Metric",,,"10.1007/s10664-019-09791-w",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context:The extent of post-release use of software affects the number of
faults, thus biasing quality metrics and adversely affecting associated
decisions. The proprietary nature of usage data limited deeper exploration of
this subject in the past. Objective: To determine how software faults and
software use are related and how an accurate quality measure can be designed.
Method: New users, usage intensity, usage frequency, exceptions, and release
date and duration measured for complex proprietary mobile applications for
Android and iOS. Utilized Bayesian Network and Random Forest models to explain
the interrelationships and to derive the usage independent release quality
measure. Investigated the interrelationship among various code complexity
measures, usage (downloads), and number of issues for 520 NPM packages and
derived a usage-independent quality measure from these analyses, applied it on
4430 popular NPM packages to construct timelines for comparing the perceived
quality (issues) and our derived measure of quality for these packages.Results:
We found the number of new users to be the primary factor determining the
number of exceptions, and found no direct link between the intensity and
frequency of software usage and software faults. Release quality expressed as
crashes per user was independent of other usage-related predictors, thus
serving as a usage independent measure of software quality. Usage also affected
quality in NPM, where downloads were strongly associated with numbers of
issues, even after taking the other code complexity measures into
consideration. Conclusions: We expect our result and our proposed quality
measure will help gauge release quality of a software more accurately and
inspire further research in this area.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:19:36 GMT""}]","2020-02-25"
"2002.09990","Sergey E. Mikhailov","Mirela Kohr, Sergey E. Mikhailov, Wolfgang L. Wendland","Variational approach for layer potentials of the Stokes system with
  $L_{\infty }$ symmetrically elliptic coefficient tensor and applications to
  Stokes and Navier-Stokes boundary problems","53 pages, some notations simplified and typos corrected",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The first aim of this paper is to develop a layer potential theory in
$L_2$-based weighted Sobolev spaces on Lipschitz bounded and exterior domains
of ${\mathbb R}^n$, $n\geq 3$, for the anisotropic Stokes system with
$L_{\infty }$ viscosity coefficient tensor satisfying an ellipticity condition
for symmetric matrices. To do this, we explore equivalent mixed variational
formulations and prove the well-posedness of some transmission problems for the
anisotropic Stokes system in Lipschitz domains of ${\mathbb R}^n$, with the
given data in $L_2$-based weighted Sobolev spaces. These results are used to
define the Newtonian and layer potentials and to obtain their properties. Then
we analyze well-posedness of the exterior Dirichlet, Neumann and mixed problems
for the Stokes system with $L_{\infty }$ symmetrically elliptic coefficient
tensor. Solutions of some of these problems are also represented in terms of
the anisotropic Stokes Newtonian and layer potentials. Finally, we prove the
existence of a weak solution for a transmission problem in complementary
Lipschitz domains in ${\mathbb R}^3$ for the anisotropic Navier-Stokes system
with general data in $L_2$-based weighted Sobolev spaces. The analysis relies
on an existence result for a Dirichlet problem for the anisotropic
Navier-Stokes system in a family of bounded domains, and on the Leray-Schauder
fixed point theorem.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:37:47 GMT""},{""version"":""v2"",""created"":""Fri, 27 Mar 2020 15:48:29 GMT""}]","2020-03-30"
"2002.09991","Julia Ramos Gonz\'alez","Wendy Lowen and Julia Ramos Gonz\'alez","On the tensor product of well generated dg categories",,,"10.1016/j.jpaa.2021.106843",,"math.CT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We endow the homotopy category of well generated (pretriangulated) dg
categories with a tensor product satisfying a universal property. The resulting
monoidal structure is symmetric and closed with respect to the cocontinuous
RHom of dg categories (in the sense of To\""en [26]). We give a construction of
the tensor product in terms of localisations of dg derived categories, making
use of the enhanced derived Gabriel-Popescu theorem [21]. Given a regular
cardinal alpha, we define and construct a tensor product of homotopically
alpha-cocomplete dg categories and prove that the well generated tensor product
of alpha-continuous derived dg categories (in the sense of [21]) is the
alpha-continuous dg derived category of the homotopically alpha-cocomplete
tensor product. In particular, this shows that the tensor product of well
generated dg categories preserves alpha-compactness.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:45:06 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 10:42:34 GMT""}]","2021-07-23"
"2002.09992","Thomas Machon","Thomas Machon","The Godbillon-Vey Invariant as Topological Vorticity Compression and
  Obstruction to Steady Flow in Ideal Fluids","14 pages, 2 figures. V2: Changes to discussion of local conservation
  law, non-unique $\theta$","Proc. R. Soc. A. 476, 20190851 (2020)","10.1098/rspa.2019.0851",,"math-ph math.MP physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If the vorticity field of an ideal fluid is tangent to a foliation,
additional conservation laws arise. For a class of zero-helicity vorticity
fields the Godbillon-Vey (GV) invariant of foliations is defined and is shown
to be an invariant purely of the vorticity, becoming a higher-order
helicity-type invariant of the flow. GV non-zero gives both a global
topological obstruction to steady flow and, in a particular form, a local
obstruction. GV is interpreted as helical compression and stretching of vortex
lines. Examples are given where the value of GV is determined by a set of
distinguished closed vortex lines.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:48:10 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 11:50:57 GMT""}]","2020-07-09"
"2002.09993","Hajar Ebrahim","Hajar Ebrahim and Gol-Mohammad Nafisi","Holographic Mutual Information and Critical Exponents of the Strongly
  Coupled Plasma","25 pages, 2 figures","Phys. Rev. D 102, 106007 (2020)","10.1103/PhysRevD.102.106007","IPM/P-2020/002","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This note contains discussions on the entanglement entropy and mutual
information of a strongly coupled field theory with a critical point which has
a holographic dual. We investigate analytically, in the specific regimes of
parameters, how these non-local operators behave near the critical point.
Interestingly, we observe that although the mutual information is constant at
the critical point, its slope shows a power-law divergence in the vicinity of
the critical point. We show that the leading behavior of mutual information at
and near the critical point could yield a set of critical exponents if we
regard it as an order parameter. Our result for this set of static critical
exponents is (1/2,1/2,1/2,2) which is identical to the one calculated via the
thermodynamic quantities. Hence it suggests that beside the numerous merits of
mutual information, this quantity also captures the critical behavior of the
underlying field theory and it could be used as a proper measure to probe the
phase structure associated with the strongly coupled systems.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:52:49 GMT""}]","2020-11-11"
"2002.09994","Sergei Yurchenko N","Alexander N. Smirnov, Victor G. Solomonik, Sergei N. Yurchenko and
  Jonathan Tennyson","Spectroscopy of YO from first principles",,"Phys. Chem. Chem. Phys., 21:22794-22810, 2019","10.1039/C9CP03208H",,"physics.chem-ph astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report an ab initio study on the spectroscopy of the open-shell diatomic
molecule yttrium oxide, YO. The study considers the six lowest doublet states,
$X\,{}^{2}\Sigma^{+}$, $A\,{}^{2}\Pi$, $C\,{}^{2}\Pi$, $A'\,{}^{2}\Delta$,
$B\,{}^{2}\Sigma^{+}$, $D\,{}^{2}\Sigma^{+}$ and a few higher-lying quartet
states using high levels of electronic structure theory and accurate nuclear
motion calculations. The coupled cluster singles, doubles, and perturbative
triples, CCSD(T), and multireference configuration interaction (MRCI) methods
are employed in conjunction with a relativistic pseudopotential on the yttrium
atom and a series of correlation-consistent basis sets ranging in size from
triple-$\zeta$ to quintuple-$\zeta$ quality. Core-valence correlation effects
are taken into account and complete basis set limit extrapolation is performed
for CCSD(T). Spin-orbit coupling is included through the use of both MRCI
state-interaction with spin-orbit (SI-SO) approach and four-component
relativistic equation-of-motion CCSD calculations. Using the ab initio data for
bond lengths ranging from 1.0 to 2.5 A, we compute 6 potential energy, 12
spin-orbit, 8 electronic angular momentum, 6 electric dipole moment and 12
transition dipole moment (4 parallel and 8 perpendicular) curves which provide
a complete description of the spectroscopy of the system of six lowest doublet
states. The Duo nuclear motion program is used to solve the coupled nuclear
motion Schr\""{o}dinger equation for these six electronic states. The spectra of
$^{89}$Y$^{16}$O simulated for different temperatures are compared with several
available high resolution experimental studies; good agreement is found once
minor adjustments are made to the electronic excitation energies.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 21:53:33 GMT""}]","2020-03-04"
"2002.09995","Bhargav Narayanan","Jozsef Balogh, Bela Bollobas and Bhargav Narayanan","Counting independent sets in regular hypergraphs","4 pages, submitted",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Amongst $d$-regular $r$-uniform hypergraphs on $n$ vertices, which ones have
the largest number of independent sets? While the analogous problem for graphs
(originally raised by Granville) is now well-understood, it is not even clear
what the correct general conjecture ought to be; our goal here is propose such
a generalisation. Lending credence to our conjecture, we verify it within the
class of `quasi-bipartite' hypergraphs (a generalisation of bipartite graphs
that seems natural in this context) by adopting the entropic approach of Kahn.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:01:15 GMT""}]","2020-02-25"
"2002.09996","Janis Klaise","Michael Pearce, Janis Klaise, Matthew Groves","Practical Bayesian Optimization of Objectives with Conditioning
  Variables","22 pages",,,,"stat.ML cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian optimization is a class of data efficient model based algorithms
typically focused on global optimization. We consider the more general case
where a user is faced with multiple problems that each need to be optimized
conditional on a state variable, for example given a range of cities with
different patient distributions, we optimize the ambulance locations
conditioned on patient distribution. Given partitions of CIFAR-10, we optimize
CNN hyperparameters for each partition. Similarity across objectives boosts
optimization of each objective in two ways: in modelling by data sharing across
objectives, and also in acquisition by quantifying how a single point on one
objective can provide benefit to all objectives. For this we propose a
framework for conditional optimization: ConBO. This can be built on top of a
range of acquisition functions and we propose a new Hybrid Knowledge Gradient
acquisition function. The resulting method is intuitive and theoretically
grounded, performs either similar to or significantly better than recently
published works on a range of problems, and is easily parallelized to collect a
batch of points.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:06:26 GMT""},{""version"":""v2"",""created"":""Mon, 2 Nov 2020 21:21:40 GMT""}]","2020-11-04"
"2002.09997","Christian Schilling","Mih\'aly M\'at\'e, \""Ors Legeza, Rolf Schilling, Mason Yousif,
  Christian Schilling","How creating one additional well can generate Bose-Einstein condensation","close to published version; title has been changed","Commun. Phys. 4, 29 (2021)","10.1038/s42005-021-00533-3",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The realization of Bose-Einstein condensation in ultracold trapped gases has
led to a revival of interest in that fascinating quantum phenomenon. This
experimental achievement necessitated both extremely low temperatures and
sufficiently weak interactions. Particularly in reduced spatial dimensionality
even an infinitesimal interaction immediately leads to a departure to
quasi-condensation. We propose a system of strongly interacting bosons which
overcomes those obstacles by exhibiting a number of intriguing related
features: (i) The tuning of just a single control parameter drives a transition
from quasi-condensation to complete condensation, (ii) the destructive
influence of strong interactions is compensated by the respective increased
mobility, (iii) topology plays a crucial role since a crossover from one- to
`infinite'-dimensionality is simulated, (iv) a ground state gap opens which
makes the condensation robust to thermal noise. Remarkably, all these features
can be derived by analytical and exact numerical means despite the
non-perturbative character of the system.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:08:01 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 18:59:43 GMT""}]","2021-02-22"
"2002.09998","Ayman Boustati","Ayman Boustati, \""Omer Deniz Akyildiz, Theodoros Damoulas, Adam M.
  Johansen","Generalized Bayesian Filtering via Sequential Monte Carlo",,,,,"stat.ME cs.LG stat.CO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a framework for inference in general state-space hidden Markov
models (HMMs) under likelihood misspecification. In particular, we leverage the
loss-theoretic perspective of Generalized Bayesian Inference (GBI) to define
generalised filtering recursions in HMMs, that can tackle the problem of
inference under model misspecification. In doing so, we arrive at principled
procedures for robust inference against observation contamination by utilising
the $\beta$-divergence. Operationalising the proposed framework is made
possible via sequential Monte Carlo methods (SMC), where most standard particle
methods, and their associated convergence results, are readily adapted to the
new setting. We apply our approach to object tracking and Gaussian process
regression problems, and observe improved performance over both standard
filtering algorithms and other robust filters.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:15:52 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 15:05:58 GMT""}]","2020-10-22"
"2002.09999","Delphin S\'enizergues","Delphin S\'enizergues","Growing random graphs with a preferential attachment structure","46 pages, 9 figures",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to develop a method for proving almost sure
convergence in Gromov-Hausodorff-Prokhorov topology for a class of models of
growing random graphs that generalises R\'emy's algorithm for binary trees. We
describe the obtained limits using some iterative gluing construction that
generalises the famous line-breaking construction of Aldous' Brownian tree.
  In order to do that, we develop a framework in which a metric space is
constructed by gluing smaller metric spaces, called \emph{blocks}, along the
structure of a (possibly infinite) discrete tree. Our growing random graphs
seen as metric spaces can be understood in this framework, that is, as evolving
blocks glued along a growing discrete tree structure. Their scaling limit
convergence can then be obtained by separately proving the almost sure
convergence of every block and verifying some relative compactness property for
the whole structure. For the particular models that we study, the discrete tree
structure behind the construction has the distribution of an affine
preferential attachment tree or a weighted recursive tree. We strongly rely on
results concerning those two models of random trees and their connection,
obtained in a companion paper.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:18:08 GMT""}]","2020-02-25"
"2002.10000","Wouter Castryck","Wouter Castryck, Floris Vermeulen","Lifting low-gonal curves for use in Tuitman's algorithm","18 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider a smooth projective curve $\overline{C}$ over a finite field
$\mathbb{F}_q$, equipped with a simply branched morphism $\overline{C} \to
\mathbb{P}^1$ of degree $d \leq 5$. Assume char$\, \mathbb{F}_q > 2$ if $d \leq
4$, and char$\, \mathbb{F}_q > 3$ if $d=5$. In this paper we describe how to
efficiently compute a lift of $\overline{C}$ to characteristic zero, such that
it can be fed as input to Tuitman's algorithm for computing the Hasse-Weil zeta
function of $\overline{C} / \mathbb{F}_q$. Our method relies on the
parametrizations of low rank rings due to Delone-Faddeev and Bhargava.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:30:02 GMT""},{""version"":""v2"",""created"":""Sun, 19 Jul 2020 13:10:42 GMT""},{""version"":""v3"",""created"":""Fri, 4 Sep 2020 08:43:52 GMT""}]","2020-09-07"
"2002.10001","Severin Barmeier","Severin Barmeier, Zhengfang Wang","Deformations of path algebras of quivers with relations","122 pages, 7 figures, v5 some changes in exposition and small
  correction in chapter 10",,,,"math.QA math.AG math.RA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $A = \Bbbk Q / I$ be the path algebra of any finite quiver $Q$ modulo any
two-sided ideal $I$ of relations and let $R$ be any reduction system satisfying
the diamond condition for $I$. We introduce an intrinsic notion of deformation
of reduction systems and show that there is an equivalence of deformation
problems between deformations of the associative algebra $A$ and deformations
of the reduction system $R$, the latter being controlled by a natural, explicit
L$_\infty$ algebra. It follows in particular that any formal deformation of the
associative multiplication on $A$ can, up to gauge equivalence, be given by a
combinatorially defined star product, and the approach via reduction systems
can be used to give a concrete and complete description of the deformation
theory of $A$. For the polynomial algebra in a finite number of variables, this
combinatorial star product can be described via bidifferential operators
associated to graphs, which we compare to the graphs appearing in Kontsevich's
universal quantization formula.
  Using the notion of admissible orders on the set of paths of the quiver $Q$,
we give criteria for the existence of algebraizations of formal deformations,
which we also interpret geometrically via algebraic varieties of reduction
systems. In this context the Maurer-Cartan equation of the L$_\infty$ algebra
can be viewed as a generalization of the Braverman-Gaitsgory criterion for
Poincar\'e-Birkhoff-Witt deformations of Koszul algebras.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:31:24 GMT""},{""version"":""v2"",""created"":""Fri, 24 Apr 2020 08:43:48 GMT""},{""version"":""v3"",""created"":""Mon, 14 Dec 2020 22:08:26 GMT""},{""version"":""v4"",""created"":""Sat, 10 Jul 2021 09:22:59 GMT""},{""version"":""v5"",""created"":""Sun, 16 Apr 2023 21:43:19 GMT""}]","2023-04-18"
"2002.10002","Eric Mazumdar","Eric Mazumdar, Aldo Pacchiano, Yi-an Ma, Peter L. Bartlett, Michael I.
  Jordan","On Thompson Sampling with Langevin Algorithms",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thompson sampling for multi-armed bandit problems is known to enjoy favorable
performance in both theory and practice. However, it suffers from a significant
limitation computationally, arising from the need for samples from posterior
distributions at every iteration. We propose two Markov Chain Monte Carlo
(MCMC) methods tailored to Thompson sampling to address this issue. We
construct quickly converging Langevin algorithms to generate approximate
samples that have accuracy guarantees, and we leverage novel posterior
concentration rates to analyze the regret of the resulting approximate Thompson
sampling algorithm. Further, we specify the necessary hyperparameters for the
MCMC procedure to guarantee optimal instance-dependent frequentist regret while
having low computational complexity. In particular, our algorithms take
advantage of both posterior concentration and a sample reuse mechanism to
ensure that only a constant number of iterations and a constant amount of data
is needed in each round. The resulting approximate Thompson sampling algorithm
has logarithmic regret and its computational complexity does not scale with the
time horizon of the algorithm.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:35:29 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 02:02:30 GMT""}]","2020-06-19"
"2002.10003","Maximilian Seitzer","Maximilian Seitzer","NeurIPS 2019 Disentanglement Challenge: Improved Disentanglement through
  Aggregated Convolutional Feature Maps","Disentanglement Challenge - 33rd Conference on Neural Information
  Processing Systems (NeurIPS) - NeurIPS 2019",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This report to our stage 1 submission to the NeurIPS 2019 disentanglement
challenge presents a simple image preprocessing method for training VAEs
leading to improved disentanglement compared to directly using the images. In
particular, we propose to use regionally aggregated feature maps extracted from
CNNs pretrained on ImageNet. Our method achieved the 2nd place in stage 1 of
the challenge. Code is available at
https://github.com/mseitzer/neurips2019-disentanglement-challenge.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:35:59 GMT""}]","2020-02-25"
"2002.10004","Peter Wahl","P. Wahl, U.R. Singh, V. Tsurkan, and A. Loidl","Nanoscale electronic inhomogeneity in FeSe$_{0.4}$Te$_{0.6}$ revealed
  through unsupervised machine learning","5 pages, 4 figures","Phys. Rev. B 101, 115112 (2020)","10.1103/PhysRevB.101.115112",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on an apparent low-energy nanoscale electronic inhomogeneity in
FeSe$_{0.4}$Te$_{0.6}$ due to the distribution of selenium and tellurium atoms
revealed through unsupervised machine learning. Through an unsupervised
clustering algorithm, characteristic spectra of selenium- and tellurium-rich
regions are identified. The inhomogeneity linked to these spectra can clearly
be traced in the differential conductance and is detected both at energy scales
of a few electron volts as well as within a few millielectronvolts of the Fermi
energy. By comparison with ARPES, this inhomogeneity can be linked to an
electron-like band just above the Fermi energy. It is directly correlated with
the local distribution of selenium and tellurium. There is no clear correlation
with the magnitude of the superconducting gap, however the height of the
coherence peaks shows significant correlation with the intensity with which
this band is detected, and hence with the local chemical composition.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:37:01 GMT""}]","2020-03-18"
"2002.10005","Marina Burlak","V.P. Arkhipova, M.A. Burlak, N.P. Ikonnikova, G.V. Komissarova, V.F.
  Esipov, V.I. Shenavrin","Surprising Variability of the Planetary Nebula IC 4997 = QV Sge","28 pages, 6 tables, 10 figures",,"10.1134/S1063773720020012",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the results of a new epoch of a long-term photometric monitoring
of the variable planetary nebula IC~4997. The integral $UBV$ light curves
display a continuing brightening of 0.$^{m}15$ in $V$, a slight rise
(<0.$^{m}1$) in $B$, and constancy in $U$. The $B-V$ color has got redder from
0.$^{m}4$ in 2000 to 0.$^{m}7$ in 2019, whereas the $U-B$ color has not changed
significantly. New $JHKL$ photometry was obtained in 2019. We found the source
to be fainter by 0.$^{m}4$ in $L$ and bluer by 0.$^{m}2$ in the $K-L$ color if
compared to the data of 1999-2006. The long-term brightness variations are due
mostly to the changing input of emission lines to the integral light.
Low-dispersion spectroscopic observations carried out in 2010-2019 revealed a
continuing decrease in the $\lambda4363/\lambda4340$ ratio: it decreased by a
factor of $\sim3$ in 30 years and reached the level of 1960-1970. The absolute
intensities of [OIII] nebualr lines increased by a factor of $>2$ from 1990 to
2019, whereas the [OIII] $\lambda$4363 line had weakened by a factor of 2
comparing to the maximum value observed in 2000. The variation of H$\beta$
absolute intensity in 1960-2019 was shown to be similar to that of [OIII]
nebular lines, but of smaller amplitude. The electron density in the outer part
of the nebula was estimated from the [SII] and [ClIII] lines. Basing on the
data on absolute intensities we propose a possible scenario describing the
change of $N_e,T_e$ in 1970-2019. The spectral variability of IC~4997 could be
explained by a variation of electron temperature in the nebula caused by not so
much the change in ionizing flux from the central star as the variable stellar
wind and related processes. The photometric and spectral changes observed for
IC~4997 in 1960-2019 may be interpreted as an observable consequence of a
single episode of enhanced mass loss from the variable central star.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:47:54 GMT""}]","2020-08-26"
"2002.10006","Tomer Galanti","Tomer Galanti, Lior Wolf","On the Modularity of Hypernetworks","Accepted to Advances in Neural Information Processing Systems
  (NeurIPS) 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of learning to map an input $I$ to a function
$h_I:\mathcal{X}\to \mathbb{R}$, two alternative methods are compared: (i) an
embedding-based method, which learns a fixed function in which $I$ is encoded
as a conditioning signal $e(I)$ and the learned function takes the form $h_I(x)
= q(x,e(I))$, and (ii) hypernetworks, in which the weights $\theta_I$ of the
function $h_I(x) = g(x;\theta_I)$ are given by a hypernetwork $f$ as
$\theta_I=f(I)$. In this paper, we define the property of modularity as the
ability to effectively learn a different function for each input instance $I$.
For this purpose, we adopt an expressivity perspective of this property and
extend the theory of Devore et al. 1996 and provide a lower bound on the
complexity (number of trainable parameters) of neural networks as function
approximators, by eliminating the requirements for the approximation method to
be robust. Our results are then used to compare the complexities of $q$ and
$g$, showing that under certain conditions and when letting the functions $e$
and $f$ be as large as we wish, $g$ can be smaller than $q$ by orders of
magnitude. This sheds light on the modularity of hypernetworks in comparison
with the embedding-based method. Besides, we show that for a structured target
function, the overall number of trainable parameters in a hypernetwork is
smaller by orders of magnitude than the number of trainable parameters of a
standard neural network and an embedding method.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:51:52 GMT""},{""version"":""v2"",""created"":""Mon, 2 Nov 2020 12:22:00 GMT""}]","2020-11-03"
"2002.10007","Tomer Galanti","Tomer Galanti, Ofir Nabati, Lior Wolf","A Critical View of the Structural Causal Model",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the univariate case, we show that by comparing the individual complexities
of univariate cause and effect, one can identify the cause and the effect,
without considering their interaction at all. In our framework, complexities
are captured by the reconstruction error of an autoencoder that operates on the
quantiles of the distribution. Comparing the reconstruction errors of the two
autoencoders, one for each variable, is shown to perform surprisingly well on
the accepted causality directionality benchmarks. Hence, the decision as to
which of the two is the cause and which is the effect may not be based on
causality but on complexity.
  In the multivariate case, where one can ensure that the complexities of the
cause and effect are balanced, we propose a new adversarial training method
that mimics the disentangled structure of the causal model. We prove that in
the multidimensional case, such modeling is likely to fit the data only in the
direction of causality. Furthermore, a uniqueness result shows that the learned
model is able to identify the underlying causal and residual (noise)
components. Our multidimensional method outperforms the literature methods on
both synthetic and real world datasets.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:52:28 GMT""}]","2020-02-25"
"2002.10008","Stefano Vigogna","Alessandro Lanteri, Mauro Maggioni and Stefano Vigogna","Conditional regression for single-index models",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The single-index model is a statistical model for intrinsic regression where
responses are assumed to depend on a single yet unknown linear combination of
the predictors, allowing to express the regression function as $ \mathbb{E} [ Y
| X ] = f ( \langle v , X \rangle ) $ for some unknown \emph{index} vector $v$
and \emph{link} function $f$. Conditional methods provide a simple and
effective approach to estimate $v$ by averaging moments of $X$ conditioned on
$Y$, but depend on parameters whose optimal choice is unknown and do not
provide generalization bounds on $f$. In this paper we propose a new
conditional method converging at $\sqrt{n}$ rate under an explicit parameter
characterization. Moreover, we prove that polynomial partitioning estimates
achieve the $1$-dimensional min-max rate for regression of H\""older functions
when combined to any $\sqrt{n}$-convergent index estimator. Overall this yields
an estimator for dimension reduction and regression of single-index models that
attains statistical optimality in quasilinear time.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:52:49 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 17:34:40 GMT""},{""version"":""v3"",""created"":""Fri, 27 May 2022 11:03:26 GMT""}]","2022-05-30"
"2002.10009","Matthew Nance Hall","Matthew Hall, Ramakrishnan Durairajan, Vyas Sekar","Fighting Fire with Light: A Case for Defending DDoS Attacks Using the
  Optical Layer","6 pages, 4 figures",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The DDoS attack landscape is growing at an unprecedented pace. Inspired by
the recent advances in optical networking, we make a case for optical
layer-aware DDoS defense (O-LAD) in this paper. Our approach leverages the
optical layer to isolate attack traffic rapidly via dynamic reconfiguration of
(backup) wavelengths using ROADMs---bridging the gap between (a) evolution of
the DDoS attack landscape and (b) innovations in the optical layer (e.g.,
reconfigurable optics). We show that the physical separation of traffic
profiles allows finer-grained handling of suspicious flows and offers better
performance for benign traffic in the face of an attack. We present preliminary
results modeling throughput and latency for legitimate flows while scaling the
strength of attacks. We also identify a number of open problems for the
security, optical, and systems communities: modeling diverse DDoS attacks
(e.g., fixed vs. variable rate, detectable vs. undetectable), building a
full-fledged defense system with optical advancements (e.g., OpenConfig), and
optical layer-aware defenses for a broader class of attacks (e.g., network
reconnaissance).
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:54:30 GMT""}]","2020-02-25"
"2002.10010","Joshua Gardner","Josh Gardner, Jawad Mroueh, Natalia Jenuwine, Noah Weaverdyck, Samuel
  Krassenstein, Arya Farahi, Danai Koutra","Driving with Data in the Motor City: Mining and Modeling Vehicle Fleet
  Maintenance Data",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The City of Detroit maintains an active fleet of over 2500 vehicles, spending
an annual average of over \$5 million on purchases and over \$7.7 million on
maintenance. Modeling patterns and trends in this data is of particular
importance to a variety of stakeholders, particularly as Detroit emerges from
Chapter 9 bankruptcy, but the structure in such data is complex, and the city
lacks dedicated resources for in-depth analysis. The City of Detroit's
Operations and Infrastructure Group and the University of Michigan initiated a
collaboration which seeks to address this unmet need by analyzing data from the
City of Detroit's vehicle fleet. This work presents a case study and provides
the first data-driven benchmark, demonstrating a suite of methods to aid in
data understanding and prediction for large vehicle maintenance datasets. We
present analyses to address three key questions raised by the stakeholders,
related to discovering multivariate maintenance patterns over time; predicting
maintenance; and predicting vehicle- and fleet-level costs. We present a novel
algorithm, PRISM, for automating multivariate sequential data analyses using
tensor decomposition. This work is a first of its kind that presents both
methodologies and insights to guide future civic data research.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 23:06:54 GMT""},{""version"":""v2"",""created"":""Mon, 21 Sep 2020 21:34:21 GMT""}]","2020-09-23"
"2002.10011","Francisco G. Montoya","Francisco Gil Montoya, Alfredo Alcayde, Francisco Arrabal-Campos, Raul
  Ba\~nos and Javier Rold\'an-P\'erez","Geometric Algebra Power Theory (GAPoT): Revisiting Apparent Power under
  Non-Sinusoidal Conditions",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional power theories and one of their most important concepts
--apparent power-- are still a source of debate and, as shown in the
literature, they present several flaws that misinterpret the power-transfer
phenomena under distorted grid conditions. In recent years, advanced
mathematical tools such as geometric algebra (GA) have been applied to address
these issues. However, the application of GA to electrical circuits requires
more consensus, improvements and refinement. In this paper, power theories
based on GA are revisited. Several drawbacks and inconsistencies of previous
works are identified and modifications to the so-called geometric algebra power
theory (GAPoT) are presented. This theory takes into account power components
generated by cross-products between current and voltage harmonics in the
frequency domain. Compared to other theories based on GA, it is compatible with
the traditional definition of apparent power calculated as the product of RMS
voltage and current. Also, mathematical developments are done in a
multi-dimensional Euclidean space where the energy conservation principle is
satisfied. The paper includes a basic example and experimental results in which
measurements from a utility supply are analysed. Finally, suggestions for the
extension to three-phase systems are drawn.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 23:10:21 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 06:05:37 GMT""},{""version"":""v3"",""created"":""Fri, 1 May 2020 23:11:09 GMT""}]","2020-05-05"
"2002.10012","Rafa{\l} R. Suszek","Rafa{\l} R. Suszek","The square root of the vacuum I. Equivariance for the $\kappa$-symmetry
  superdistribution","102 pages, the discussion of the enhanced gauge-symmetry
  superdistribution refined, extra (achirality) constraints on superbackgrounds
  introduced and a physically relevant chiral departure from them studied,
  conventions for the super-Minkowskian superbackground and various typos
  corrected",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A complete and natural geometric and physical interpretation of the
tangential gauge supersymmetry, also known as $\kappa$-symmetry, of a large
class of Green-Schwarz(-type) super-$\sigma$-models for the super-$p$-brane in
a homogeneous space of a (supersymmetry) Lie supergroup is established in the
convenient setting of the topological Hughes-Polchinski formulation of the
super-$\sigma$-model and illustrated on a number of physical examples. The
supersymmetry is identified as an odd superdistribution in the tangent sheaf of
the supertarget of the super-$\sigma$-model, generating - through its weak
derived flag - the vacuum foliation of the supertarget. It is also demonstrated
to canonically lift to the vacuum restriction of the extended Hughes-Polchinski
$p$-gerbe associated with the superbackground of the field theory, and that in
the form of a canonical linearised equivariant structure thereon, canonically
compatible with the residual global supersymmetry of the vacuum.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 23:21:09 GMT""},{""version"":""v2"",""created"":""Sun, 8 Mar 2020 08:07:19 GMT""}]","2020-03-10"
"2002.10013","J.F. Jardine","J.F. Jardine","Persistent homotopy theory","21 pages. This is a new version of this preprint. The proof of Lemma
  19 of the previous version had an error that rendered the proof of the former
  Theorem 23 invalid. No statement of that form is now claimed",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vietoris-Rips and degree Rips complexes are represented as homotopy types by
their underlying posets of simplices, and basic homotopy stability theorems are
recast in these terms. These homotopy types are viewed as systems (or
functors), which are defined on a parameter space. The category of systems of
spaces admits a partial homotopy theory that is based on controlled
equivalences, suitably defined, that are the output of homotopy stability
results.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 23:34:40 GMT""},{""version"":""v2"",""created"":""Thu, 30 Apr 2020 17:11:16 GMT""},{""version"":""v3"",""created"":""Mon, 26 Oct 2020 18:49:57 GMT""}]","2020-10-28"
"2002.10014","Peter Bradshaw","Peter Bradshaw","Transversals and bipancyclicity in bipartite graph families","14 pages, 6 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A bipartite graph is called bipancyclic if it contains cycles of every even
length from four up to the number of vertices in the graph. A theorem of
Schmeichel and Mitchem states that for $n \geq 4$, every balanced bipartite
graph on $2n$ vertices in which each vertex in one color class has degree
greater than $\frac{n}{2}$ and each vertex in the other color class has degree
at least $\frac{n}{2}$ is bipancyclic. We prove a generalization of this
theorem in the setting of graph transversals. Namely, we show that given a
family $\mathcal{G}$ of $2n$ bipartite graphs on a common set $X$ of $2n$
vertices with a common balanced bipartition, if each graph of $\mathcal G$ has
minimum degree greater than $\frac{n}{2}$ in one color class and minimum degree
at least $\frac{n}{2}$ in the other color class, then there exists a cycle on
$X$ of each even length $4 \leq \ell \leq 2n$ that uses at most one edge from
each graph of $\mathcal G$. We also show that given a family $\mathcal G$ of
$n$ bipartite graphs on a common set $X$ of $2n$ vertices meeting the same
degree conditions, there exists a perfect matching on $X$ that uses exactly one
edge from each graph of $\mathcal G$.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 23:43:54 GMT""},{""version"":""v2"",""created"":""Fri, 27 Mar 2020 00:30:32 GMT""},{""version"":""v3"",""created"":""Thu, 2 Apr 2020 21:08:43 GMT""},{""version"":""v4"",""created"":""Thu, 21 May 2020 17:59:10 GMT""},{""version"":""v5"",""created"":""Mon, 25 Jan 2021 05:17:37 GMT""}]","2021-01-26"
"2002.10015","Eric Mart\'inez-Pascual","M. A. L\'opez-Osorio, E. Mart\'inez-Pascual, G. I. N\'apoles-Ca\~nedo,
  J. J. Toscano","One-loop order effects from one universal extra dimension on
  $\lambda\phi^{4}$ theory","20 pages, 6 figures, submitted to J. Phys. G: Nucl. Part. Phys",,,,"hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The self-interacting $\lambda\phi^{4}$ scalar field theory is a warhorse in
quantum field theory. Here we explore the one-loop order impact from one
universal extra dimension, $S^{1}/\mathbb{Z}_{2}$, to the self-energy and four
point vertex functions associated to this theory. Such effects come as an
infinite number of UV divergences corresponding to an infinite superposition of
excited KK particles around the loop. We show that dimensional regularisation
is adequate enough to control them in terms of the product of the one
dimensional inhomogenous Epstein zeta function times the gamma function. From
the analytical properties of these functions, the UV divergences are extracted
and the counterterms defined; the latter turn out to be of canonical dimension
four at the Lagrangian level. We use both, the MS-scheme and a mass-dependent
subtraction scheme to remove divergences. Only the latter manifestly satisfy
the decoupling theorem.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 23:48:38 GMT""}]","2020-02-25"
"2002.10016","Hadi Abdi Khojasteh","Hadi Abdi Khojasteh (1), Ebrahim Ansari (1 and 2), Parvin Razzaghi (1
  and 3), Akbar Karimi (4) ((1) Institute for Advanced Studies in Basic
  Sciences (IASBS), Zanjan, Iran, (2) Faculty of Mathematics and Physics,
  Institute of Formal and Applied Linguistics, Charles University, Czechia, (3)
  Institute for Research in Fundamental Sciences (IPM), Tehran, Iran, (4) IMP
  Lab, Department of Engineering and Architecture, University of Parma, Parma,
  Italy)","Deep Multimodal Image-Text Embeddings for Automatic Cross-Media
  Retrieval","6 pages and 2 figures, Learn more about this project at
  https://iasbs.ac.ir/~ansari/deeptwitter",,,,"cs.IR cs.AI cs.CL cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers the task of matching images and sentences by learning a
visual-textual embedding space for cross-modal retrieval. Finding such a space
is a challenging task since the features and representations of text and image
are not comparable. In this work, we introduce an end-to-end deep multimodal
convolutional-recurrent network for learning both vision and language
representations simultaneously to infer image-text similarity. The model learns
which pairs are a match (positive) and which ones are a mismatch (negative)
using a hinge-based triplet ranking. To learn about the joint representations,
we leverage our newly extracted collection of tweets from Twitter. The main
characteristic of our dataset is that the images and tweets are not
standardized the same as the benchmarks. Furthermore, there can be a higher
semantic correlation between the pictures and tweets contrary to benchmarks in
which the descriptions are well-organized. Experimental results on MS-COCO
benchmark dataset show that our model outperforms certain methods presented
previously and has competitive performance compared to the state-of-the-art.
The code and dataset have been made available publicly.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 23:58:04 GMT""}]","2020-02-28"
"2002.10017","Aidan Gibbs","Aidan Gibbs, Alex Bixel, Benjamin Rackham, Daniel Apai, Martin
  Schlecker, Nestor Espinoza, Luigi Mancini, Wen-Ping Chen, Thomas Henning,
  Paul Gabor, Richard Boyle, Jose Perez Chavez, Allie Mousseau, Jeremy
  Dietrich, Quentin Jay Socia, Wing Ip, Chow-Choong Ngeow, Anli Tsai, Asmita
  Bhandare, Victor Marian, Hans Baehr, Samantha Brown, Maximilian Haberle,
  Miriam Keppler, Karan Molaverdikhani, Paula Sarkis","EDEN: Sensitivity Analysis and Transiting Planet Detection Limits for
  Nearby Late Red Dwarfs","Accepted to AJ",,"10.3847/1538-3881/ab7926",,"astro-ph.EP astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Small planets are common around late-M dwarfs and can be detected through
highly precise photometry by the transit method. Planets orbiting nearby stars
are particularly important as they are often the best-suited for future
follow-up studies. We present observations of three nearby M-dwarfs referred to
as EIC-1, EIC-2, and EIC-3, and use them to search for transits and set limits
on the presence of planets. On most nights our observations are sensitive to
Earth-sized transiting planets, and photometric precision is similar to or
better than TESS for faint late-M dwarfs of the same magnitude (I=15 mag). We
present our photometry and transit search pipeline, which utilizes simple
median detrending in combination with transit least squares based transit
detection (Hippke & Heller 2019).For these targets, and transiting planets
between one and two Earth radii, we achieve an average transit detection
probability of 60% between periods of 0.5 and 2 days, 30% between 2 and 5
days,and 10% between 5 and 10 days. These sensitivities are conservative
compared to visual searches.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:04:39 GMT""}]","2020-04-01"
"2002.10018","Ami Paz","Pierre Fraigniaud, Fran\c{c}ois Le Gall, Harumichi Nishimura, Ami Paz","Distributed Quantum Proofs for Replicated Data","To be presented in ITCS 2021","Proceedings of the 12th Innovations in Theoretical Computer
  Science Conference (ITCS2021), pp. 28:1-28:20, 2021","10.4230/LIPIcs.ITCS.2021.28",,"cs.DC quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper tackles the issue of $\textit{checking}$ that all copies of a large
data set replicated at several nodes of a network are identical. The fact that
the replicas may be located at distant nodes prevents the system from verifying
their equality locally, i.e., by having each node consult only nodes in its
vicinity. On the other hand, it remains possible to assign
$\textit{certificates}$ to the nodes, so that verifying the consistency of the
replicas can be achieved locally. However, we show that, as the data set is
large, classical certification mechanisms, including distributed Merlin-Arthur
protocols, cannot guarantee good completeness and soundness simultaneously,
unless they use very large certificates. The main result of this paper is a
distributed $\textit{quantum}$ Merlin-Arthur protocol enabling the nodes to
collectively check the consistency of the replicas, based on small
certificates, and in a single round of message exchange between neighbors, with
short messages. In particular, the certificate-size is logarithmic in the size
of the data set, which gives an exponential advantage over classical
certification mechanisms.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:09:55 GMT""},{""version"":""v2"",""created"":""Tue, 17 Nov 2020 09:16:19 GMT""}]","2021-10-05"
"2002.10019","Leonid Koralov","Mark Freidlin, Leonid Koralov","Averaging in the case of multiple invariant measures for the fast system",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the averaging principle for deterministic or stochastic systems
with a fast stochastic component (family of continuous-time Markov chains
depending on the state of the system as a parameter). We show that, due to
bifurcations in the simplex of invariant probability measures of the chains,
the limiting system should be considered on a graph or on an open book with
certain gluing conditions in the vertices of the graph (or on the bifurcation
surface).
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:13:52 GMT""}]","2020-02-25"
"2002.10020","Seyyedali Hosseinalipour","Seyyedali Hosseinalipour, Ali Rahmati, Huaiyu Dai","Optimal Jammer Placement in UAV-assisted Relay Networks","6 pages, 6 figures","IEEE International Conference on Communications (ICC), 2020","10.1109/ICC40277.2020.9148754",,"eess.SP cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the relaying application of unmanned aerial vehicles (UAVs), in
which UAVs are placed between two transceivers (TRs) to increase the throughput
of the system. Instead of studying the placement of UAVs as pursued in existing
literature, we focus on investigating the placement of a jammer or a major
source of interference on the ground to effectively degrade the performance of
the system, which is measured by the maximum achievable data rate of
transmission between the TRs. We demonstrate that the optimal placement of the
jammer is in general a non-convex optimization problem, for which obtaining the
solution directly is intractable. Afterward, using the inherent characteristics
of the signal-to-interference ratio (SIR) expressions, we propose a tractable
approach to find the optimal position of the jammer. Based on the proposed
approach, we investigate the optimal positioning of the jammer in both dual-hop
and multi-hop UAV relaying settings. Numerical simulations are provided to
evaluate the performance of our proposed method.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:19:48 GMT""}]","2020-09-01"
"2002.10021","Jacob Tyo","Jacob Tyo and Zachary Lipton","How Transferable are the Representations Learned by Deep Q Agents?",,,,,"cs.LG stat.ML","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we consider the source of Deep Reinforcement Learning (DRL)'s
sample complexity, asking how much derives from the requirement of learning
useful representations of environment states and how much is due to the sample
complexity of learning a policy. While for DRL agents, the distinction between
representation and policy may not be clear, we seek new insight through a set
of transfer learning experiments. In each experiment, we retain some fraction
of layers trained on either the same game or a related game, comparing the
benefits of transfer learning to learning a policy from scratch. Interestingly,
we find that benefits due to transfer are highly variable in general and
non-symmetric across pairs of tasks. Our experiments suggest that perhaps
transfer from simpler environments can boost performance on more complex
downstream tasks and that the requirements of learning a useful representation
can range from negligible to the majority of the sample complexity, based on
the environment. Furthermore, we find that fine-tuning generally outperforms
training with the transferred layers frozen, confirming an insight first noted
in the classification setting.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:23:47 GMT""}]","2020-02-25"
"2002.10022","Amir Mosavi Prof","Shahab Shamshirband, Amir Mosavi, Narjes Nabipour, Kwok-wing Chau","Application of ERA5 and MENA simulations to predict offshore wind energy
  potential","21 pages, 12 figures",,,,"physics.ao-ph cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  This study explores wind energy resources in different locations through the
Gulf of Oman and also their future variability due climate change impacts. In
this regard, EC-EARTH near surface wind outputs obtained from CORDEX-MENA
simulations are used for historical and future projection of the energy. The
ERA5 wind data are employed to assess suitability of the climate model.
Moreover, the ERA5 wave data over the study area are applied to compute sea
surface roughness as an important variable for converting near surface wind
speeds to those of wind speed at turbine hub-height. Considering the power
distribution, bathymetry and distance from the coats, some spots as tentative
energy hotspots to provide detailed assessment of directional and temporal
variability and also to investigate climate change impact studies. RCP8.5 as a
common climatic scenario is used to project and extract future variation of the
energy in the selected sites. The results of this study demonstrate that the
selected locations have a suitable potential for wind power turbine plan and
constructions.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:25:29 GMT""}]","2020-02-25"
"2002.10023","Amir Shakouri","Amir Shakouri, M. Reza Emami","Suboptimal Control of Unknown Second-order Nonlinear Systems with
  Guaranteed Global Convergence","6 pages, 4 figures, accepted for publication in IEEE Control Systems
  Letters",,"10.1109/LCSYS.2022.3184647",,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  A suboptimal active disturbance rejection controller (S-ADRC) is proposed for
second-order systems with unknown time-varying nonlinear dynamics. The
output-feedback controller guarantees a global convergence to the vicinity of
an optimal solution by means of dynamic control gains, based on the estimated
main and extended state variables obtained through a high-gain observer. Three
numerical examples compare the performance of the proposed control scheme
applied to linear and nonlinear systems with that of a fixed-gain conventional
ADRC as well as several model-based optimal and suboptimal controllers.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:34:28 GMT""},{""version"":""v2"",""created"":""Sun, 22 Mar 2020 15:15:29 GMT""},{""version"":""v3"",""created"":""Sun, 26 Apr 2020 23:35:32 GMT""},{""version"":""v4"",""created"":""Mon, 20 Jun 2022 07:44:09 GMT""}]","2022-06-22"
"2002.10024","Leonid Gurvits","J.G. Bij de Vaate, L.I. Gurvits, S.V. Pogrebenko and C.G.M. van t
  Klooster","Spacecraft Tracking Applications of the Square Kilometre Array","9 pages, 5 tables, 2 figures","Proceedings of the 3rd International Workshop on Tracking,
  Telemetry and Command Systems for Space Applications, ESA-ESOC, Darmstadt,
  Germany, 2004",,,"astro-ph.IM astro-ph.EP physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Square Kilometre Array (SKA) is the next generation radio telescope
distinguished by a superb sensitivity due to its large aperture (about one
square kilometre) and advanced instrumentation. It will cover a broad range of
observing bands including those used for tracking of and communications to deep
space missions. While spacecraft tracking is not a main application defining
the technical specifications of the SKA, this facility might play a role in
tracking deep space probes as a backup to the ``dedicated'' deep space tracking
networks. This paper presents possible applications of the SKA as a deep space
tracking facility and major related technical specifications of various
concepts of the SKA. It was presented at the 3rd International Workshop on
Tracking, Telemetry and Command Systems for Space Applications, ESA-ESOC,
Darmstadt, Germany, 7-9 September 2004. Over the past years, the SKA concept
has developed to a much higher level of detalisation and is currently at the
implementation phase. A number of specific considerations in this presentation
no longer correspond to the actual status of the SKA project. However, the
overall concept of the SKA applications for communication and tracking of
interplanetary spacecraft remain topical, and some approaches presented here
remain of interest for prospective deep space missions.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:35:58 GMT""}]","2020-02-25"
"2002.10025","Ting-Kueu Hu","Ting-Kuei Hu, Tianlong Chen, Haotao Wang, Zhangyang Wang","Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by
  Enabling Input-Adaptive Inference","Published on ICLR 2020",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep networks were recently suggested to face the odds between accuracy (on
clean natural images) and robustness (on adversarially perturbed images)
(Tsipras et al., 2019). Such a dilemma is shown to be rooted in the inherently
higher sample complexity (Schmidt et al., 2018) and/or model capacity
(Nakkiran, 2019), for learning a high-accuracy and robust classifier. In view
of that, give a classification task, growing the model capacity appears to help
draw a win-win between accuracy and robustness, yet at the expense of model
size and latency, therefore posing challenges for resource-constrained
applications. Is it possible to co-design model accuracy, robustness and
efficiency to achieve their triple wins? This paper studies multi-exit networks
associated with input-adaptive efficient inference, showing their strong
promise in achieving a ""sweet point"" in cooptimizing model accuracy, robustness
and efficiency. Our proposed solution, dubbed Robust Dynamic Inference Networks
(RDI-Nets), allows for each input (either clean or adversarial) to adaptively
choose one of the multiple output layers (early branches or the final one) to
output its prediction. That multi-loss adaptivity adds new variations and
flexibility to adversarial attacks and defenses, on which we present a
systematical investigation. We show experimentally that by equipping existing
backbones with such robust adaptive inference, the resulting RDI-Nets can
achieve better accuracy and robustness, yet with over 30% computational
savings, compared to the defended original models.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:40:22 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 03:27:42 GMT""}]","2020-02-26"
"2002.10026","Benjamin Dozier","Benjamin Dozier","Measure bound for translation surfaces with short saddle connections","57 pages, 9 figures. Added Remark 1.5 concerning the opposite
  inequality. Various minor changes throughout. To appear in GAFA",,,,"math.DS math.AG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that any ergodic $SL_2(R)$-invariant probability measure on a
stratum of translation surfaces satisfies strong regularity: the measure of the
set of surfaces with two non-parallel saddle connections of length at most
$\epsilon_1, \epsilon_2$ is $O(\epsilon_1^2 \epsilon_2^2)$. We prove a more
general theorem which works for any number of short saddle connections. The
proof uses the multi-scale compactification of strata recently introduced by
Bainbridge-Chen-Gendron-Grushevsky-M\""oller and the algebraicity result of
Filip.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:54:53 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 21:58:52 GMT""}]","2023-02-28"
"2002.10027","Van Sergio Alves","Luis Fern\'andez, Van S\'ergio Alves, Leandro O. Nascimento, Francisco
  Pe\~na, M. Gomes and E. C. Marino","Renormalization of the band gap in 2D materials through the competition
  between electromagnetic and four-fermion interactions","10 pages, 7 figures","Phys. Rev. D 102, 016020 (2020)","10.1103/PhysRevD.102.016020",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently the renormalization of the band gap $m$, in both WSe$_2$ and
MoS$_2$, has been experimentally measured as a function of the carrier
concentration $n$. The main result establishes a decreasing of hundreds of meV,
in comparison with the bare band gap, as the carrier concentration increases.
These materials are known as transition metal dichalcogenides and their
low-energy excitations are, approximately, described by the massive Dirac
equation. Using Pseudo Quantum Electrodynamics (PQED) to describe the
electromagnetic interaction between these quasiparticles and from
renormalization group analysis, we obtain that the renormalized mass describes
the band gap renormalization with a function given by
$m(n)/m_0=(n/n_0)^{C_\lambda/2}$, where $m_0=m(n_0)$ and $C_\lambda$ is a
function of the coupling constant $\lambda$. We compare our theoretical results
with the experimental findings for WSe$_2$ and MoS$_2$, and we conclude that
our approach is in agreement with these experimental results for reasonable
values of $\lambda$. In addition we introduced a Gross-Neveu (GN) interaction
which could simulate an disorder/impurity-like microscopic interaction. In this
case, we show that there exists a critical coupling constant, namely,
$\lambda_c \approx 0,66$ in which the beta function of the mass vanishes,
providing a stable fixed point in the ultraviolet limit. For
$\lambda>\lambda_c$, the renormalized mass decreases while for
$\lambda<\lambda_c$ it increases with the carrier concentration.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:05:21 GMT""},{""version"":""v2"",""created"":""Mon, 2 Mar 2020 20:10:13 GMT""}]","2020-08-05"
"2002.10028","Richard C. Brower","Richard C. Brower, David Berenstein and Hiroki Kawai","Lattice Gauge Theory for a Quantum Computer","7 pages , 5 figures, 37th International Symposium on Lattice Field
  Theory - Lattice2019, 16-22 June 2019, Wuhan, China","PoS(LATTICE2019)112",,,"hep-lat quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quantum link~\cite{Brower:1997ha} Hamiltonian was introduced two decades
ago as an alternative to Wilson's Euclidean lattice QCD with gauge fields
represented by bi-linear fermion/anti-fermion operators. When generalized this
new microscopic representation of lattice field theories is referred as {\tt
D-theory}~\cite{Brower:2003vy}. Recast as a Hamiltonian in Minkowski space for
real time evolution, D-theory leads naturally to quantum Qubit algorithms. Here
to explore digital quantum computing for gauge theories, the simplest example
of U(1) compact QED on triangular lattice is defined and gauge invariant
kernels for the Suzuki-Trotter expansions are expressed as Qubit circuits
capable of being tested on the IBM-Q and other existing Noisy Intermediate
Scale Quantum (NISQ) hardware. This is a modest step in exploring the quantum
complexity of D-theory to guide future applications to high energy physics and
condensed matter quantum field theories.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:16:49 GMT""}]","2020-02-25"
"2002.10029","Tal Friedman","Tal Friedman and Guy Van den Broeck","Symbolic Querying of Vector Spaces: Probabilistic Databases Meets
  Relational Embeddings",,,,,"cs.AI cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose unifying techniques from probabilistic databases and relational
embedding models with the goal of performing complex queries on incomplete and
uncertain data. We formalize a probabilistic database model with respect to
which all queries are done. This allows us to leverage the rich literature of
theory and algorithms from probabilistic databases for solving problems. While
this formalization can be used with any relational embedding model, the lack of
a well-defined joint probability distribution causes simple query problems to
become provably hard. With this in mind, we introduce \TO, a relational
embedding model designed to be a tractable probabilistic database, by
exploiting typical embedding assumptions within the probabilistic framework.
Using a principled, efficient inference algorithm that can be derived from its
definition, we empirically demonstrate that \TOs is an effective and general
model for these querying tasks.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:17:25 GMT""},{""version"":""v2"",""created"":""Sat, 27 Jun 2020 20:01:49 GMT""}]","2020-06-30"
"2002.10030","Abidin Kaya","Joe Gildea, Abidin Kaya, Adrian Korban, Bahattin Yildiz","New Extremal binary self-dual codes of length 68 from a novel approach
  to neighbors",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we introduce the concept of distance between self-dual codes,
which generalizes the concept of a neighbor for self-dual codes. Using the
k-neighbors, we are able to construct extremal binary self-dual codes of length
68 with new weight enumerators. We construct 143 extremal binary self-dual
codes of length 68 with new weight enumerators including 42 codes with gamma=8
in their W_{68,2} and 40 with gamma=9 in their W_{68,2}. These examples are the
first in the literature for these gamma values. This completes the theoretical
list of possible values for gamma in W_{68,2}.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:22:26 GMT""}]","2020-02-25"
"2002.10031","Tetu Makino","Tetu Makino","On Incompressible Vibrations of the Stratified Atmosphere on the Flat
  Earth",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the vibrations and waves in the atmosphere under the gravitation
on the flat earth. The stratified density distribution of the back ground
equilibrium is supposed to touch the vacuum at the finite height of the
stratosphere. We show that incompressible motions are possible to create
vibrations or progressive waves with countably many time frequencies of the
vibrations or speeds of the wave propagation which accumulate to 0, say, of
countably infinitely many slow and slow modes.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:33:21 GMT""}]","2020-02-25"
"2002.10032","Mohammad Akbari","Mohammad Akbari and Jie Liang and Jingning Han and Chengjie Tu","Generalized Octave Convolutions for Learned Multi-Frequency Image
  Compression","13 pages, 10 figures, 5 tables; Extended version of the paper
  accepted to AAAI 2021",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learned image compression has recently shown the potential to outperform the
standard codecs. State-of-the-art rate-distortion (R-D) performance has been
achieved by context-adaptive entropy coding approaches in which hyperprior and
autoregressive models are jointly utilized to effectively capture the spatial
dependencies in the latent representations. However, the latents are feature
maps of the same spatial resolution in previous works, which contain some
redundancies that affect the R-D performance. In this paper, we propose the
first learned multi-frequency image compression and entropy coding approach
that is based on the recently developed octave convolutions to factorize the
latents into high and low frequency (resolution) components, where the low
frequency is represented by a lower resolution. Therefore, its spatial
redundancy is reduced, which improves the R-D performance. Novel generalized
octave convolution and octave transposed-convolution architectures with
internal activation layers are also proposed to preserve more spatial structure
of the information. Experimental results show that the proposed scheme not only
outperforms all existing learned methods as well as standard codecs such as the
next-generation video coding standard VVC (4:2:0) on the Kodak dataset in both
PSNR and MS-SSIM. We also show that the proposed generalized octave convolution
can improve the performance of other auto-encoder-based computer vision tasks
such as semantic segmentation and image denoising.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:35:29 GMT""},{""version"":""v2"",""created"":""Wed, 14 Oct 2020 18:22:26 GMT""},{""version"":""v3"",""created"":""Thu, 31 Dec 2020 06:34:00 GMT""}]","2021-01-01"
"2002.10033","Eamon Duede","Misha Teplitskiy, Eamon Duede, Michael Menietti, Karim R. Lakhani","Status drives how we cite: Evidence from thousands of authors","Heavily revised narrative in this version including new title,
  figures, abstract, and narrative structure. Central empirical findings
  unchanged",,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Researchers cite works for a variety of reasons, including some having
nothing to do with acknowledging influence. The distribution of different
citation types in the literature, and which papers attract which types, is
poorly understood. We investigate high-influence and low-influence citations
and the mechanisms producing them using 17,154 ground-truth citation types
provided via survey by 9,380 authors systematically sampled across academic
fields. Overall, 54% of citations denote little-to-no influence and these
citations are concentrated among low status (lightly cited) papers. In
contrast, high-influence citations are concentrated among high status (highly
cited) papers through a number of steps that resemble a pipeline. Authors
discover highly cited papers earlier in their projects, more often through
social contacts, and read them more closely. Papers' status, above and beyond
any quality differences, directly helps determine their pipeline:
experimentally revealing or hiding citation counts during the survey shows that
low counts cause lowered perceptions of quality. Accounting for citation types
thus reveals a ""double status effect"": in addition to affecting how often a
work is cited, status affects how meaningfully it is cited. Consequently,
highly cited papers are even more influential than their raw citation counts
suggest.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:37:28 GMT""},{""version"":""v2"",""created"":""Mon, 31 Aug 2020 19:07:32 GMT""}]","2020-09-02"
"2002.10034","Sema Candemir","Sema Candemir, Xuan V. Nguyen, Luciano M. Prevedello, Matthew T.
  Bigelow, Richard D.White, Barbaros S. Erdal (for the Alzheimer's Disease
  Neuroimaging Initiative)","Predicting Rate of Cognitive Decline at Baseline Using a Deep Neural
  Network with Multidata Analysis",,,,,"q-bio.QM cs.LG eess.IV q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Purpose: This study investigates whether a machine-learning-based system can
predict the rate of cognitive decline in mildly cognitively impaired patients
by processing only the clinical and imaging data collected at the initial
visit.
  Approach: We built a predictive model based on a supervised hybrid neural
network utilizing a 3-Dimensional Convolutional Neural Network to perform
volume analysis of Magnetic Resonance Imaging and integration of non-imaging
clinical data at the fully connected layer of the architecture. The experiments
are conducted on the Alzheimers Disease Neuroimaging Initiative dataset.
  Results: Experimental results confirm that there is a correlation between
cognitive decline and the data obtained at the first visit. The system achieved
an area under the receiver operator curve (AUC) of 0.70 for cognitive decline
class prediction.
  Conclusion: To our knowledge, this is the first study that predicts slowly
deteriorating/stable or rapidly deteriorating classes by processing routinely
collected baseline clinical and demographic data (Baseline MRI, Baseline MMSE,
Scalar Volumetric data, Age, Gender, Education, Ethnicity, and Race). The
training data is built based on MMSE-rate values. Unlike the studies in the
literature that focus on predicting Mild Cognitive Impairment-to-Alzheimer`s
disease conversion and disease classification, we approach the problem as an
early prediction of cognitive decline rate in MCI patients.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:39:17 GMT""},{""version"":""v2"",""created"":""Mon, 8 Jun 2020 05:40:42 GMT""},{""version"":""v3"",""created"":""Mon, 5 Oct 2020 23:14:23 GMT""}]","2020-10-07"
"2002.10035","Xianmang He","Xianmang He, Yindong Chen, Zusheng Zhang","Improving the Linkage Construction with Echelon-Ferrers for
  Constant-Dimension Codes",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Echelon-Ferrers is an important method to improve lower bounds for
constant-dimension codes, which can be applied on various parameters. Fagang Li
[12] combined the linkage construction and echelon-Ferrers to obtain some new
lower bounds of constant-dimension codes. In this letter, we generalize this
linkage construction to obtain new lower bounds.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:57:57 GMT""},{""version"":""v2"",""created"":""Fri, 6 Mar 2020 16:43:18 GMT""},{""version"":""v3"",""created"":""Thu, 30 Jul 2020 17:58:14 GMT""}]","2020-07-31"
"2002.10036","Hong Liu","Hong Liu, Weizhe Edward Liu, Stefano Chesi, Robert Joynt and Dimitrie
  Culcer","Phase diagram of the interacting persistent spin-helix state","9 pages, 7 figures, 2 tables","Phys. Rev. B 102, 205410 (2020)","10.1103/PhysRevB.102.205410","PHYSICAL REVIEW B 102, 205410 (2020)","cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the phase diagram of the interacting two-dimensional electron gas
(2DEG) with equal Rashba and Dresselhaus spin-orbit coupling, which for weak
coupling gives rise to the well-known persistent spin-helix phase. We construct
the full Hartree-Fock phase diagram using a classical Monte-Carlo method
analogous to that used in Phys.Rev.B 96, 235425 (2017). For the 2DEG with only
Rashba spin-orbit coupling, it was found that at intermediate values of the
Wigner-Seitz radius rs the system is characterized by a single Fermi surface
with an out-of-plane spin polarization, while at slightly larger values of rs
it undergoes a transition to a state with a shifted Fermi surface and an
in-plane spin polarization. The various phase transitions are first-order, and
this shows up in discontinuities in the conductivity and the appearance of
anisotropic resistance in the in-plane polarized phase. In this work, we show
that the out-of-plane spin-polarized region shrinks as the strength of the
Dresselhaus spin-orbit interaction increases, and entirely vanishes when the
Rashba and Dresselhaus spin-orbit coupling strengths are equal. At this point,
the system can be mapped onto a 2DEG without spin-orbit coupling, and this
transformation reveals the existence of an in-plane spin-polarized phase with a
single, displaced Fermi surface beyond rs > 2.01. This is confirmed by
classical Monte-Carlo simulations. We discuss experimental observation and
useful applications of the novel phase, as well as caveats of using the
classical Monte-Carlo method.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:59:55 GMT""}]","2020-11-19"
"2002.10037","Takeshi Suzuki","Takeshi Suzuki, Yasushi Shinohara, Yangfan Lu, Mari Watanabe, Jiadi
  Xu, Kenichi L. Ishikawa, Hide Takagi, Minoru Nohara, Naoyuki Katayama,
  Hiroshi Sawa, Masami Fujisawa, Teruto Kanai, Jiro Itatani, Takashi Mizokawa,
  Shik Shin, and Kozo Okazaki","Detecting electron-phonon couplings during photo-induced phase
  transition",,"Phys. Rev. B 103, 121105 (2021)","10.1103/PhysRevB.103.L121105",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photo-induced phase transitions have been intensively studied owing to the
ability to control a material of interest in the ultrafast manner, which can
induce exotic phases unable to be attained at equilibrium. However, the key
mechanisms are still under debate, and it has currently been a central issue
how the couplings between the electron, lattice, and spin degrees of freedom
are evolving during photo-induced phase transitions. Here, we develop a new
analysis method, frequency-domain angle-resolved photoemission spectroscopy, to
gain precise insight into electron-phonon couplings during photo-induced
insulator-to-metal transitions for Ta$_2$NiSe$_5$. We demonstrate that multiple
coherent phonons generated by displacive excitations show band-selective
coupling to the electrons. Furthermore, we find that the lattice modulation
corresponding to the 2 THz phonon mode, where Ta lattice is sheared along the
a-axis, is the most relevant for the photo-induced semimetallic state.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:06:29 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2020 01:56:52 GMT""}]","2021-03-17"
"2002.10038","Han Lin Shang","Han Lin Shang","Bayesian bandwidth estimation and semi-metric selection for a functional
  partial linear model with unknown error density","27 pages, 10 figures, to appear in Journal of Applied Statistics","Journal of Applied Statistics (2020)","10.1080/02664763.2020.1736527",,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study examines the optimal selections of bandwidth and semi-metric for a
functional partial linear model. Our proposed method begins by estimating the
unknown error density using a kernel density estimator of residuals, where the
regression function, consisting of parametric and nonparametric components, can
be estimated by functional principal component and functional Nadayara-Watson
estimators. The estimation accuracy of the regression function and error
density crucially depends on the optimal estimations of bandwidth and
semi-metric. A Bayesian method is utilized to simultaneously estimate the
bandwidths in the regression function and kernel error density by minimizing
the Kullback-Leibler divergence. For estimating the regression function and
error density, a series of simulation studies demonstrate that the functional
partial linear model gives improved estimation and forecast accuracies compared
with the functional principal component regression and functional nonparametric
regression. Using a spectroscopy dataset, the functional partial linear model
yields better forecast accuracy than some commonly used functional regression
models. As a by-product of the Bayesian method, a pointwise prediction interval
can be obtained, and marginal likelihood can be used to select the optimal
semi-metric.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:15:34 GMT""}]","2020-11-17"
"2002.10039","Karine Chubarian","Karine Chubarian and Anastasios Sidiropoulos","Computing Bi-Lipschitz Outlier Embeddings into the Line",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of computing a bi-Lipschitz embedding of a graphical metric into
the line with minimum distortion has received a lot of attention. The
best-known approximation algorithm computes an embedding with distortion
$O(c^2)$, where $c$ denotes the optimal distortion [B\u{a}doiu \etal~2005]. We
present a bi-criteria approximation algorithm that extends the above results to
the setting of \emph{outliers}.
  Specifically, we say that a metric space $(X,\rho)$ admits a
$(k,c)$-embedding if there exists $K\subset X$, with $|K|=k$, such that
$(X\setminus K, \rho)$ admits an embedding into the line with distortion at
most $c$. Given $k\geq 0$, and a metric space that admits a $(k,c)$-embedding,
for some $c\geq 1$, our algorithm computes a $({\mathsf p}{\mathsf o}{\mathsf
l}{\mathsf y}(k, c, \log n), {\mathsf p}{\mathsf o}{\mathsf l}{\mathsf
y}(c))$-embedding in polynomial time. This is the first algorithmic result for
outlier bi-Lipschitz embeddings. Prior to our work, comparable outlier
embeddings where known only for the case of additive distortion.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:22:06 GMT""}]","2020-02-25"
"2002.10040","Susan G. Williams","Daniel S. Silver and Susan G. Williams","Links in Surfaces and Laplacian Modules","14 pages, 15 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Laplacian matrices of weighted graphs in surfaces $S$ are used to define
module and polynomial invariants of $Z/2$-homologically trivial links in $S
\times [0,1]$. Information about virtual genus is obtained.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:22:27 GMT""}]","2020-02-25"
"2002.10041","Jinyong Ma","Jinyong Ma, Jiayi Qin, Geoff T. Campbell, Ruvi Lecamwasam, Kabilan
  Sripathy, Joe Hope, Ben C. Buchler, Ping Koy Lam","Photothermally Induced Transparency","14 pages, 6 figures","Sci. Adv. 6, eaax8256 (2020)","10.1126/sciadv.aax8256",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Induced transparency is a common but remarkable effect in optics. It occurs
when a strong driving field is used to render an otherwise opaque material
transparent. The effect is known as electromagnetically induced transparency in
atomic media and optomechanically induced transparency in systems that consist
of coupled optical and mechanical resonators. In this work, we introduce the
concept of photothermally induced transparency (PTIT). It happens when an
optical resonator exhibits non-linear behavior due to optical heating of the
resonator or its mirrors. Similar to the established mechanisms for induced
transparency, PTIT can suppress the coupling between an optical resonator and a
traveling optical field. We further show that the dispersion of the resonator
can be modified to exhibit slow or fast light. Because of the relatively slow
thermal response, we observe the bandwidth of the PTIT to be $2\pi\times15.9$
Hz which theoretically suggests a group velocity of as low as $5$ m/s.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:24:46 GMT""}]","2020-02-25"
"2002.10042","Akio Kawasaki","Akio Kawasaki, Boris Braverman, Edwin Pedrozo-Pe\~nafiel, Chi Shu,
  Simone Colombo, Zeyang Li, Vladan Vuleti\'c","Trapping $^{171}$Yb Atoms into a One-Dimensional Optical Lattice with a
  Small Waist","9 pages, 8 figures","Phys. Rev. A 102, 013114 (2020)","10.1103/PhysRevA.102.013114",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In most experiments with atoms trapped in optical lattices, the transverse
size of the optical lattice beams is on the order of tens of micrometers, and
loading many atoms into smaller optical lattices has not been carefully
investigated. We report trapping 1500 $^{171}$Yb atoms in a one-dimensional
optical lattice generated by a narrow cavity mode at a distance of 0.14 mm from
a mirror surface. The simplest approach of loading atoms from a mirror
magneto-optical trap overlapped with the cavity mode allows the adjustment of
the loading position by tuning a uniform bias magnetic field. The number of
atoms trapped in the optical lattice exhibits two local maxima for different
lattice depths, with a global maximum in the deeper lattice. These results open
a way to quantum mechanical manipulation of atoms based on strong interaction
with a tightly focused light field.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:27:16 GMT""},{""version"":""v2"",""created"":""Tue, 4 Aug 2020 02:47:42 GMT""},{""version"":""v3"",""created"":""Thu, 6 Aug 2020 19:24:10 GMT""}]","2020-08-10"
"2002.10043","Yifei Shen","Yifei Shen, Ye Xue, Jun Zhang, Khaled B. Letaief, and Vincent Lau","Complete Dictionary Learning via $\ell_p$-norm Maximization","accepted by UAI 2020",,,,"cs.LG cs.IT eess.SP math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dictionary learning is a classic representation learning method that has been
widely applied in signal processing and data analytics. In this paper, we
investigate a family of $\ell_p$-norm ($p>2,p \in \mathbb{N}$) maximization
approaches for the complete dictionary learning problem from theoretical and
algorithmic aspects. Specifically, we prove that the global maximizers of these
formulations are very close to the true dictionary with high probability, even
when Gaussian noise is present. Based on the generalized power method (GPM), an
efficient algorithm is then developed for the $\ell_p$-based formulations. We
further show the efficacy of the developed algorithm: for the population GPM
algorithm over the sphere constraint, it first quickly enters the neighborhood
of a global maximizer, and then converges linearly in this region. Extensive
experiments will demonstrate that the $\ell_p$-based approaches enjoy a higher
computational efficiency and better robustness than conventional approaches and
$p=3$ performs the best.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:33:01 GMT""},{""version"":""v2"",""created"":""Wed, 26 Feb 2020 13:07:36 GMT""},{""version"":""v3"",""created"":""Wed, 15 Jul 2020 11:58:45 GMT""}]","2020-07-16"
"2002.10044","James Quach Dr","James Q. Quach and William J. Munro","Using dark states to charge and stabilise open quantum batteries","8 pages, 6 figures, comments are welcome","Phys. Rev. Applied 14, 024092 (2020)","10.1103/PhysRevApplied.14.024092",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce an open quantum battery protocol using dark states to achieve
both superextensive capacity and power density, with non-interacting spins
coupled to a reservoir. Further, our power density actually scales with the of
number of spins $N$ in the battery. We show that the enhanced capacity and
power is correlated with entanglement. Whilst connected to the charger, the
charged state of the battery is a steady state, stabilized through quantum
interference in the open system.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:34:59 GMT""},{""version"":""v2"",""created"":""Tue, 1 Sep 2020 02:24:36 GMT""}]","2020-09-02"
"2002.10045","Shuran Zheng","Shuran Zheng and Yiling Chen","Optimal Advertising for Information Products",,,"10.1145/3465456.3467649",,"cs.GT econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When selling information products, the seller can provide some free partial
information to change people's valuations so that the overall revenue can
possibly be increased. We study the general problem of advertising information
products by revealing partial information. We consider buyers who are
decision-makers. The outcomes of the decision problems depend on the state of
the world that is unknown to the buyers. The buyers can make their own
observations and thus can hold different personal beliefs about the state of
the world. There is an information seller who has access to the state of the
world. The seller can promote the information by revealing some partial
information. We assume that the seller chooses a long-term advertising strategy
and then commits to it. The seller's goal is to maximize the expected revenue.
We study the problem in two settings. (1) The seller targets buyers of a
certain type. In this case, finding the optimal advertising strategy is
equivalent to finding the concave closure of a simple function. The function is
a product of two quantities, the likelihood ratio and the cost of uncertainty.
Based on this observation, we prove some properties of the optimal mechanism,
which allow us to solve for the optimal mechanism by a finite-size convex
program. The convex program will have a polynomial-size if the state of the
world has a constant number of possible realizations or the buyers face a
decision problem with a constant number of options. For the general problem, we
prove that it is NP-hard to find the optimal mechanism. (2) When the seller
faces buyers of different types and only knows the distribution of their types,
we provide an approximation algorithm when it is not too hard to predict the
possible type of buyers who will make the purchase. For the general problem, we
prove that it is NP-hard to find a constant-factor approximation.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:36:22 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 02:08:00 GMT""},{""version"":""v3"",""created"":""Mon, 22 Mar 2021 01:06:35 GMT""},{""version"":""v4"",""created"":""Sun, 6 Jun 2021 17:04:33 GMT""},{""version"":""v5"",""created"":""Thu, 23 Sep 2021 01:45:10 GMT""}]","2021-09-24"
"2002.10046","Anderson Winkler","Anderson M. Winkler, Olivier Renaud, Stephen M. Smith, Thomas E.
  Nichols","Permutation Inference for Canonical Correlation Analysis","49 pages, 2 figures, 10 tables, 3 algorithms, 119 references",,,,"stat.ME math.ST stat.AP stat.CO stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Canonical correlation analysis (CCA) has become a key tool for population
neuroimaging, allowing investigation of associations between many imaging and
non-imaging measurements. As other variables are often a source of variability
not of direct interest, previous work has used CCA on residuals from a model
that removes these effects, then proceeded directly to permutation inference.
We show that such a simple permutation test leads to inflated error rates. The
reason is that residualisation introduces dependencies among the observations
that violate the exchangeability assumption. Even in the absence of nuisance
variables, however, a simple permutation test for CCA also leads to excess
error rates for all canonical correlations other than the first. The reason is
that a simple permutation scheme does not ignore the variability already
explained by previous canonical variables. Here we propose solutions for both
problems: in the case of nuisance variables, we show that transforming the
residuals to a lower dimensional basis where exchangeability holds results in a
valid permutation test; for more general cases, with or without nuisance
variables, we propose estimating the canonical correlations in a stepwise
manner, removing at each iteration the variance already explained, while
dealing with different number of variables in both sides. We also discuss how
to address the multiplicity of tests, proposing an admissible test that is not
conservative, and provide a complete algorithm for permutation inference for
CCA.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:47:01 GMT""},{""version"":""v2"",""created"":""Sat, 14 Mar 2020 22:45:59 GMT""},{""version"":""v3"",""created"":""Tue, 26 May 2020 18:23:36 GMT""},{""version"":""v4"",""created"":""Thu, 18 Jun 2020 01:15:58 GMT""}]","2020-06-19"
"2002.10047","Jessica Shi","Jessica Shi and Laxman Dhulipala and Julian Shun","Parallel Clique Counting and Peeling Algorithms",,,,,"cs.DS cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new parallel algorithm for $k$-clique counting/listing that has
polylogarithmic span (parallel time) and is work-efficient (matches the work of
the best sequential algorithm) for sparse graphs. Our algorithm is based on
computing low out-degree orientations, which we present new linear-work and
polylogarithmic-span algorithms for computing in parallel. We also present new
parallel algorithms for producing unbiased estimations of clique counts using
graph sparsification. Finally, we design two new parallel work-efficient
algorithms for approximating the $k$-clique densest subgraph, the first of
which is a $1/k$-approximation and the second of which is a
$1/(k(1+\epsilon))$-approximation and has polylogarithmic span. Our first
algorithm does not have polylogarithmic span, but we prove that it solves a
P-complete problem.
  In addition to the theoretical results, we also implement the algorithms and
propose various optimizations to improve their practical performance. On a
30-core machine with two-way hyper-threading, our algorithms achieve
13.23--38.99x and 1.19--13.76x self-relative parallel speedup for $k$-clique
counting and $k$-clique densest subgraph, respectively. Compared to the
state-of-the-art parallel $k$-clique counting algorithms, we achieve up to
9.88x speedup, and compared to existing implementations of $k$-clique densest
subgraph, we achieve up to 11.83x speedup. We are able to compute the
$4$-clique counts on the largest publicly-available graph with over two hundred
billion edges for the first time.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:48:47 GMT""},{""version"":""v2"",""created"":""Wed, 2 Sep 2020 02:28:06 GMT""},{""version"":""v3"",""created"":""Sat, 13 Mar 2021 02:13:51 GMT""},{""version"":""v4"",""created"":""Fri, 16 Jul 2021 17:30:15 GMT""}]","2021-07-19"
"2002.10048","Baishan Hu","B. S. Hu, Q. Wu, Q. Yuan, Y. Z. Ma, X. Q. Yan, and F. R. Xu","Nuclear multipole responses from chiral effective field theory
  interaction","Accepted by PHYSICAL REVIEW C",,"10.1103/PhysRevC.101.044309",,"nucl-th nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We probe nuclear multipole resonances in the framework of the random-phase
approximation by using the interaction obtained from the chiral effective field
theory. The three-nucleon force is included in a form of the in-medium
two-nucleon interaction which was derived from the chiral three-nucleon force.
The isoscalar monopole, isoscalar dipole, isovector dipole and isoscalar
quadrupole resonances of the closed-shell $^{56,68,78}$Ni have been
investigated. The calculations reasonably reproduce the experimental multipole
resonances of $^{56,68}$Ni, and well describe the pygmy dipole resonance and
dipole polarizability measured in $^{68}$Ni. The multipole resonances of
$^{78}$Ni, including pygmy dipole resonance and dipole polarizability, are
predicted. The detailed effects of the tensor force and three-body force are
analyzed by dissecting the chiral interaction. We find that in general the
tensor force effect on electric giant resonances is not as significant as the
effect from the three-body force, although the tensor force provides more than
half of the binding energy. The effect from three-body force is strong in light
nuclei. Particularly, three-body force is crucial for the formation of the
pygmy resonance in calculations.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:51:06 GMT""}]","2020-05-20"
"2002.10049","Himadri Pathak","Himadri Pathak, Sudip Sasmal, Kaushik Talukdar, Malaya K. Nayak,
  Nayana Vaval, and Sourav Pal","Relativistic double-ionization equation-of-motion coupled-cluster
  method: Application to low-lying doubly ionized states","8 page",,"10.1063/1.5140988",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The article deals with the extension of the relativistic double-ionization
equation-of-motion coupled-cluster (DI-EOMCC) method [H. Pathak et al. Phys.
Rev. A 90, 010501(R) (2014)] for the molecular systems. The Dirac-Coulomb (DC)
Hamiltonian with four-component spinors is considered to take care of the
relativistic effects. The implemented method is employed to compute a few
low-lying doubly ionized states of noble gas atoms (Ar, Kr, Xe, and Rn) and Cl
2 , Br 2 , HBr, and HI. Additionally, we presented results with two
intermediate schemes in the four-component relativistic DI-EOMCC framework to
understand the role of electron correlation. The computed double ionization
spectra for the atomic systems are compared with the values from the
non-relativistic DI-EOMCC method with spin-orbit coupling (SOC) [Z. Wang et al.
J. Chem. Phys. 142, 144109 (2015)] and the values from the National Institute
of Science and Technology (NIST) database. Our atomic results are found to be
in good agreement with the NIST values. Further, the obtained results for the
molecular systems agree well with the available experimental values.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:56:28 GMT""}]","2020-04-22"
"2002.10050","Ivan Limonchenko","Ivan Limonchenko, Dmitry Millionshchikov","Higher order Massey products and applications","36 pages, 1 figure; minor changes, misprints corrected",,,,"math.AT math.AC math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this survey, we discuss two research areas related to Massey's higher
operations. The first direction is connected with the cohomology of Lie
algebras and the theory of representations. The second main theme is at the
intersection of toric topology, homotopy theory of polyhedral products, and the
homology theory of local rings, Stanley-Reisner rings of simplicial complexes.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:57:52 GMT""},{""version"":""v2"",""created"":""Sun, 26 Apr 2020 23:51:40 GMT""}]","2020-04-28"
"2002.10051","Sebastian Meuren","Sebastian Meuren, Phil H. Bucksbaum, Nathaniel J. Fisch, Frederico
  Fi\'uza, Siegfried Glenzer, Mark J. Hogan, Kenan Qu, David A. Reis, Glen
  White, Vitaly Yakimenko","On Seminal HEDP Research Opportunities Enabled by Colocating
  Multi-Petawatt Laser with High-Density Electron Beams","11 pages, 1 figure, 1 table",,,,"physics.plasm-ph hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The scientific community is currently witnessing an expensive and worldwide
race to achieve the highest possible light intensity. Within the next decade
this effort is expected to reach nearly $10^{24}\,\mathrm{W}/\mathrm{cm^2}$ in
the lab frame by focusing of 100 PW, near-infrared lasers. A major driving
force behind this effort is the possibility to study strong-field vacuum
breakdown and an accompanying electron-positron pair plasma via a quantum
electrodynamic (QED) cascade [Edwin Cartlidge, ""The light fantastic"", Science
359, 382 (2018)]. Whereas Europe is focusing on all-optical 10 PW-class laser
facilities (e.g., Apollon and ELI), China is already planning on co-locating a
100 PW laser system with a 25 keV superconducting XFEL and thus implicitly also
a high-quality electron beam [Station of Extreme Light (SEL) at the Shanghai
Superintense-Ultrafast Lasers Facility (SULF)]. This white paper elucidates the
seminal scientific opportunities facilitated by colliding dense, multi-GeV
electron beams with multi-PW optical laser pulses. Such a multi-beam facility
would enable the experimental exploration of extreme HEDP environments by
generating electron-positron pair plasmas with unprecedented densities and
temperatures, where the interplay between strong-field quantum and collective
plasma effects becomes decisive.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 02:59:53 GMT""}]","2020-02-25"
"2002.10052","Jinyong Ma","Jinyong Ma, Jinghui Gan, Giovanni Guccione, Geoff T. Campbell, Ben C.
  Buchler, Xinyou L\""u, Ying Wu, and Ping Koy Lam","Optomechanically induced carrier-envelope-phase dependent effects and
  their analytical solutions","8 pages, 3 figures","Phys. Rev. A 95, 063802 (2017)","10.1103/PhysRevA.95.063802",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To date, investigations of carrier-envelope-phase (CEP) dependent effects
have been limited to optical pulses with few cycles and high intensity, and
have not been reported for other types of pulses. Optomechanical systems are
shown to have the potential to go beyond these limits. We present an approach
using optomechanics to extend the concept of the traditional CEP in the
few-cycle regime to mechanical pulses and develop a two-step model to give a
physical insight. By adding an auxiliary continuous optical field, we show that
a CEP-dependent effect appears even in the multi-cycle regime of mechanical
pulses. We obtain the approximated analytical solutions providing full
understanding for these optomechanically induced CEP-dependent effects. In
addition, our findings show that one can draw on the optomechanical interaction
to revive the CEP-dependent effects on optical pulses with an arbitrary number
of cycles and without specific intensity requirements. The effects of CEP,
broadly extended to encompass few- and multi-cycle optical and mechanical
pulses, may stimulate a variety of applications in the preparation of a
CEP-stabilized pulse, the generation of ultrasonic pulses with a desired shape,
the linear manipulation of optical combs, and more.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:03:14 GMT""}]","2020-02-25"
"2002.10053","Gyu-Boong Jo","Bo Song, Chengdong He, Zejian Ren, Entong Zhao, Jeongwon Lee and
  Gyu-Boong Jo","Effective statistical fringe removal algorithm for high-sensitivity
  imaging of ultracold atoms","6 pages, 5 figures, supplementary materials","Phys. Rev. Applied 14, 034006 (2020)","10.1103/PhysRevApplied.14.034006",,"cond-mat.quant-gas eess.IV physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-sensitivity imaging of ultracold atoms is often challenging when
interference patterns are imprinted on the imaging light. Such image noises
result in low signal-to-noise ratio and limit the capability to extract subtle
physical quantities. Here we demonstrate an advanced fringe removal algorithm
for absorption imaging of ultracold atoms, which efficiently suppresses
unwanted fringe patterns using a small number of sample images without taking
additional reference images. The protocol is based on an image decomposition
and projection method with an extended image basis. We apply this scheme to raw
absorption images of degenerate Fermi gases for the measurement of atomic
density fluctuations and temperatures. The quantitative analysis shows that
image noises can be efficiently removed with only tens of reference images,
which manifests the efficiency of our protocol. Our algorithm would be of
particular interest for the quantum emulation experiments in which several
physical parameters need to be scanned within a limited time duration.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:03:17 GMT""}]","2020-09-09"
"2002.10054","Jialong Deng","Jialong Deng","Metric topology on the moduli space",,"Applied General Topology 22(1) 2021, 11-15","10.4995/agt.2021.13066",,"math.GN math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define the smooth Lipschitz topology on the moduli space and show that
each conformal class is dense in the moduli space endowed with Gromov-Hausdorff
topology, which offers an answer to the Tuschmann's question.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:05:14 GMT""}]","2021-04-08"
"2002.10055","Alireza Partovi","Alireza Partovi, Wei Zheng, Taeho Jung, and Hai Lin","Ensuring Privacy in Location-Based Services: A Model-based Approach",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, the widespread of mobile devices equipped with GPS and
communication chips has led to the growing use of location-based services (LBS)
in which a user receives a service based on his current location. The
disclosure of user's location, however, can raise serious concerns about user
privacy in general, and location privacy in particular which led to the
development of various location privacy-preserving mechanisms aiming to enhance
the location privacy while using LBS applications. In this paper, we propose to
model the user mobility pattern and utility of the LBS as a Markov decision
process (MDP), and inspired by probabilistic current state opacity notation, we
introduce a new location privacy metric, namely $\epsilon-$privacy, that
quantifies the adversary belief over the user's current location. We exploit
this dynamic model to design a LPPM that while it ensures the utility of
service is being fully utilized, independent of the adversary prior knowledge
about the user, it can guarantee a user-specified privacy level can be achieved
for an infinite time horizon. The overall privacy-preserving framework,
including the construction of the user mobility model as a MDP, and design of
the proposed LPPM, are demonstrated and validated with real-world experimental
data.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:07:08 GMT""}]","2020-02-25"
"2002.10056","Cihan Karabulut","Jorge Fl\'orez, Cihan Karabulut, Elkin Quintero Vanegas","The distribution of the generalized greatest common divisor and
  visibility of lattice points",,"INTEGERS, Volume 20 (2020), #A6",,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a fixed $b\in \mathbb{N}=\{1,2,3,\dots\}$, Goins et al. \cite{Harris}
defined the concept of $b$-visibility for a lattice point $(r,s)$ in
$L=\mathbb{N}\times \mathbb{N}$ which states that $(r,s)$ is $b$-visible from
the origin if it lies on the graph of $f(x)=ax^b$, for some positive $a\in
\mathbb{Q}$, and no other lattice point in $L$ lies on this graph between
$(0,0)$ and $(r,s)$. Furthermore, to study the density of $b$-visible points in
$L$ Goins et al. defined a generalization of greatest common divisor, denoted
by $\gcd_b$, and proved that the proportion of $b$-visible lattice points in
$L$ is given by $1/\zeta(b+1)$, where $\zeta(s)$ is the Riemann zeta function.
In this paper we study the mean values of arithmetic functions $\Lambda:L\to
\mathbb{ C}$ defined using $\gcd_b$ and recover the main result of
\cite{Harris} as a consequence of the more general results of this paper. We
also investigate a generalization of a result in \cite{Harris} that asserts
that there are arbitrarily large rectangular arrangements of $b$-visible points
in the lattice $L$ for a fixed $b$, more specifically, we give necessary and
sufficient conditions for an arbitrary rectangular arrangement containing
$b$-visible and $b$-invisible points to be realizable in the lattice $L$. Our
result is inspired by the work of Herzog and Stewart \cite{Herzog} who proved
this in the case $b=1$.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:16:45 GMT""}]","2020-02-25"
"2002.10057","Talwinder Singh","Talwinder Singh, Tae K. Kim, Nikolai V. Pogorelov and Charles N. Arge","Application of a Modified Spheromak Model to Simulations of Coronal Mass
  Ejection in the Inner Heliosphere",,,"10.1029/2019SW002405",,"physics.space-ph astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The magnetic fields of interplanetary coronal mass ejections (ICMEs), which
originate close to the Sun in the form of a flux rope, determine their
geoeffectiveness. Therefore, robust flux rope-based models of CMEs are required
to perform magnetohydrodynamic (MHD) simulations aimed at space weather
predictions. We propose a modified spheromak model and demonstrate its
applicability to CME simulations. In this model, such properties of a simulated
CME as the poloidal and toroidal magnetic fluxes, and the helicity sign can be
controlled with a set of input parameters. We propose a robust technique for
introducing CMEs with an appropriate speed into a background, MHD solution
describing the solar wind in the inner heliosphere. Through a parametric study,
we find that the speed of a CME is much more dependent on its poloidal flux
than on the toroidal flux. We also show that the CME speed increases with its
total energy, giving us control over its initial speed. We further demonstrate
the applicability of this model to simulations of CME-CME collisions. Finally,
we use this model to simulate the 12 July 2012 CME and compare the plasma
properties at 1 AU with observations. The predicted CME properties agree
reasonably with observational data.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:24:31 GMT""}]","2020-06-24"
"2002.10058","Simion Breaz","Simion Breaz","A mixed version for a Fuchs' Lemma","10 pages",,,,"math.GR math.AC math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a version for mixed groups for a Fuchs' result about connections
between the cancellation property of a group and the unit lifting property of
its (Walk-)endomorphism rings.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:26:28 GMT""}]","2020-02-25"
"2002.10059","Chengzhi Yuan","Xiaonan Dong, Paolo Stegagno, Chengzhi Yuan, Wei Zeng","Cooperative Adaptive Learning Control for A Group of Nonholonomic UGVs
  by Output Feedback",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A high-gain observer-based cooperative deterministic learning (CDL) control
algorithm is proposed in this chapter for a group of identical unicycle-type
unmanned ground vehicles (UGVs) to track over desired reference trajectories.
For the vehicle states, the positions of the vehicles can be measured, while
the velocities are estimated using the high-gain observer. For the trajectory
tracking controller, the radial basis function (RBF) neural network (NN) is
used to online estimate the unknown dynamics of the vehicle, and the NN weight
convergence and estimation accuracy is guaranteed by CDL. The major challenge
and novelty of this chapter is to track the reference trajectory using this
observer-based CDL algorithm without the full knowledge of the vehicle state
and vehicle model. In addition, any vehicle in the system is able to learn the
knowledge of unmodeled dynamics along the union of trajectories experienced by
all vehicle agents, such that the learned knowledge can be re-used to follow
any reference trajectory defined in the learning phase. The learning-based
tracking convergence and consensus learning results, as well as using learned
knowledge for tracking experienced trajectories, are shown using the Lyapunov
method. Simulation is given to show the effectiveness of this algorithm.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:28:53 GMT""}]","2020-02-25"
"2002.10060","Wu Lin","Wu Lin, Mark Schmidt, Mohammad Emtiyaz Khan","Handling the Positive-Definite Constraint in the Bayesian Learning Rule","Fixed typos and updated the abstract (ICML 2020)",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Bayesian learning rule is a natural-gradient variational inference
method, which not only contains many existing learning algorithms as special
cases but also enables the design of new algorithms. Unfortunately, when
variational parameters lie in an open constraint set, the rule may not satisfy
the constraint and requires line-searches which could slow down the algorithm.
In this work, we address this issue for positive-definite constraints by
proposing an improved rule that naturally handles the constraints. Our
modification is obtained by using Riemannian gradient methods, and is valid
when the approximation attains a \emph{block-coordinate natural
parameterization} (e.g., Gaussian distributions and their mixtures). We propose
a principled way to derive Riemannian gradients and retractions from scratch.
Our method outperforms existing methods without any significant increase in
computation. Our work makes it easier to apply the rule in the presence of
positive-definite constraints in parameter spaces.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:29:39 GMT""},{""version"":""v10"",""created"":""Thu, 23 Jul 2020 16:19:52 GMT""},{""version"":""v11"",""created"":""Mon, 17 Aug 2020 15:52:27 GMT""},{""version"":""v12"",""created"":""Fri, 4 Sep 2020 05:37:10 GMT""},{""version"":""v13"",""created"":""Sun, 25 Oct 2020 04:28:55 GMT""},{""version"":""v2"",""created"":""Wed, 26 Feb 2020 09:13:54 GMT""},{""version"":""v3"",""created"":""Sun, 8 Mar 2020 10:19:13 GMT""},{""version"":""v4"",""created"":""Fri, 3 Apr 2020 19:44:16 GMT""},{""version"":""v5"",""created"":""Mon, 11 May 2020 15:43:05 GMT""},{""version"":""v6"",""created"":""Mon, 8 Jun 2020 04:35:11 GMT""},{""version"":""v7"",""created"":""Tue, 30 Jun 2020 06:59:14 GMT""},{""version"":""v8"",""created"":""Thu, 2 Jul 2020 11:16:36 GMT""},{""version"":""v9"",""created"":""Tue, 21 Jul 2020 16:01:35 GMT""}]","2020-10-27"
"2002.10061","Wensi Tang","Wensi Tang, Guodong Long, Lu Liu, Tianyi Zhou, Michael Blumenstein,
  Jing Jiang","Omni-Scale CNNs: a simple and effective kernel size configuration for
  time series classification","Accepted by ICLR 2022","The Tenth International Conference on Learning
  Representations(ICLR 2022)",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Receptive Field (RF) size has been one of the most important factors for
One Dimensional Convolutional Neural Networks (1D-CNNs) on time series
classification tasks. Large efforts have been taken to choose the appropriate
size because it has a huge influence on the performance and differs
significantly for each dataset. In this paper, we propose an Omni-Scale block
(OS-block) for 1D-CNNs, where the kernel sizes are decided by a simple and
universal rule. Particularly, it is a set of kernel sizes that can efficiently
cover the best RF size across different datasets via consisting of multiple
prime numbers according to the length of the time series. The experiment result
shows that models with the OS-block can achieve a similar performance as models
with the searched optimal RF size and due to the strong optimal RF size capture
ability, simple 1D-CNN models with OS-block achieves the state-of-the-art
performance on four time series benchmarks, including both univariate and
multivariate data from multiple domains. Comprehensive analysis and discussions
shed light on why the OS-block can capture optimal RF sizes across different
datasets. Code available [https://github.com/Wensi-Tang/OS-CNN]
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:33:58 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 00:28:30 GMT""},{""version"":""v3"",""created"":""Fri, 17 Jun 2022 07:56:18 GMT""}]","2022-06-20"
"2002.10062","Casey Blacker","Casey Blacker","Reduction of multisymplectic manifolds","31 pages",,"10.1007/s11005-021-01408-y",,"math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the Marsden-Weinstein-Meyer symplectic reduction theorem to the
setting of multisymplectic manifolds. In this context, we investigate the
dependence of the reduced space on the reduction parameters. With respect to a
distinguished class of multisymplectic moment maps, an exact stationary phase
approximation and nonabelian localization theorem are also obtained.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:39:21 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 11:42:38 GMT""}]","2021-05-14"
"2002.10063","Alexander Yom Din","Alexander Yom Din","A Paley-Wiener theorem for spherical $p$-adic spaces and Bernstein
  morphisms","Reupload - mostly due to addition of a section describing Bernstein
  morphisms via the approach of the article",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be (the rational points of) a connected reductive group over a local
non-archimedean field $F$. In this article we formulate and prove a property of
an $F$-spherical homogeneous $G$-space (which in addition satisfies the finite
multiplicity property, which is expected to hold for all $F$-spherical
homogeneous $G$-spaces) which we call the Paley-Wiener property. This is much
more elementary, but also contains much less information, than the recent
relevant work of Delorme, Harinck and Sakellaridis (however, it holds for a
wider class of spaces). The property results from a parallel categorical
property. We also discuss how to define Bernstein morphisms via this approach.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:39:50 GMT""},{""version"":""v2"",""created"":""Fri, 8 May 2020 19:58:41 GMT""}]","2020-05-12"
"2002.10064","Abhronil Sengupta","Sen Lu, Abhronil Sengupta","Exploring the Connection Between Binary and Spiking Neural Networks",,,"10.3389/fnins.2020.00535",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On-chip edge intelligence has necessitated the exploration of algorithmic
techniques to reduce the compute requirements of current machine learning
frameworks. This work aims to bridge the recent algorithmic progress in
training Binary Neural Networks and Spiking Neural Networks - both of which are
driven by the same motivation and yet synergies between the two have not been
fully explored. We show that training Spiking Neural Networks in the extreme
quantization regime results in near full precision accuracies on large-scale
datasets like CIFAR-$100$ and ImageNet. An important implication of this work
is that Binary Spiking Neural Networks can be enabled by ""In-Memory"" hardware
accelerators catered for Binary Neural Networks without suffering any accuracy
degradation due to binarization. We utilize standard training techniques for
non-spiking networks to generate our spiking networks by conversion process and
also perform an extensive empirical analysis and explore simple design-time and
run-time optimization techniques for reducing inference latency of spiking
networks (both for binary and full-precision models) by an order of magnitude
over prior work.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:46:51 GMT""},{""version"":""v2"",""created"":""Fri, 24 Apr 2020 19:49:59 GMT""},{""version"":""v3"",""created"":""Thu, 21 May 2020 21:53:42 GMT""}]","2020-10-28"
"2002.10065","Ranjeet Kumar","Ranjeet Kumar, Michael J. Wenzel, Mohammad N. ElBsat, Michael J.
  Risbeck, Kirk H. Drees, Victor M. Zavala","Stochastic Model Predictive Control for Central HVAC Plants","34 pages, 15 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a stochastic model predictive control (MPC) framework for central
heating, ventilation, and air conditioning (HVAC) plants. The framework uses
real data to forecast and quantify uncertainty of disturbances affecting the
system over multiple timescales (electrical loads, heating/cooling loads, and
energy prices). We conduct detailed closed-loop simulations and systematic
benchmarks for the central HVAC plant of a typical university campus. Results
demonstrate that deterministic MPC fails to properly capture disturbances and
that this translates into economic penalties associated with peak demand
charges and constraint violations in thermal storage capacity (overflow and/or
depletion). Our results also demonstrate that stochastic MPC provides a more
systematic approach to mitigate uncertainties and that this ultimately leads to
cost savings of up to 7.5% and to mitigation of storage constraint violations.
Benchmark results also indicate that these savings are close to ideal savings
(9.6%) obtained under MPC with perfect information.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:53:32 GMT""}]","2020-02-25"
"2002.10066","Yonadav Shavit","Yonadav Shavit, Benjamin Edelman, Brian Axelrod","Causal Strategic Linear Regression","18 pages; published at ICML 2020",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many predictive decision-making scenarios, such as credit scoring and
academic testing, a decision-maker must construct a model that accounts for
agents' propensity to ""game"" the decision rule by changing their features so as
to receive better decisions. Whereas the strategic classification literature
has previously assumed that agents' outcomes are not causally affected by their
features (and thus that strategic agents' goal is deceiving the
decision-maker), we join concurrent work in modeling agents' outcomes as a
function of their changeable attributes. As our main contribution, we provide
efficient algorithms for learning decision rules that optimize three distinct
decision-maker objectives in a realizable linear setting: accurately predicting
agents' post-gaming outcomes (prediction risk minimization), incentivizing
agents to improve these outcomes (agent outcome maximization), and estimating
the coefficients of the true underlying model (parameter estimation). Our
algorithms circumvent a hardness result of Miller et al. (2020) by allowing the
decision maker to test a sequence of decision rules and observe agents'
responses, in effect performing causal interventions through the decision
rules.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:57:22 GMT""},{""version"":""v2"",""created"":""Thu, 3 Sep 2020 22:24:19 GMT""},{""version"":""v3"",""created"":""Thu, 25 Aug 2022 07:42:33 GMT""}]","2022-08-26"
"2002.10067","Yanhao Tang","Yanhao Tang, Jie Gu, Song Liu, Kenji Watanabe, Takashi Taniguchi,
  James Hone, Kin Fai Mak, Jie Shan","Spatially mixed moir\'e excitons in two-dimensional van der Waals
  superlattices","16 pages, 8 figures",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Moir\'e superlattices open an unprecedented opportunity for tailoring
interactions between quantum particles and their coupling to electromagnetic
fields. Strong superlattice potential generates moir\'e minibands of excitons
-- bound pairs of electrons and holes that reside either in a single layer
(intralayer excitons) or two separate layers (interlayer excitons). The
twist-angle-controlled interlayer hybridization of carriers can also mix the
two types of excitons to combine the strengths of both. Here, we report a
direct observation of spatially mixed moir\'e excitons in angle-aligned
WSe2/WS2 and MoSe2/WS2 superlattices by optical reflectance spectroscopy. The
strongly interacting interlayer and intralayer moir\'e excitons in WSe2/WS2
manifest energy level anticrossing and oscillator strength redistribution under
a vertical electric field. We also observe doping-dependent exciton miniband
renormalization and mixing near half filling of the first electron miniband of
WS2. Our findings have significant implications for emerging correlated states
in two-dimensional semiconductors, such as exciton condensates and Bose-Hubbard
models, and optoelectronic applications of these materials.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:57:59 GMT""}]","2020-02-25"
"2002.10068","Kai Wang","Han Xiaobo, Wang Kai, Jiang Yanan, Xing Xiangyuan, Li Shujin, Li Fang,
  Liu Weiwei, Wang Bing, Lu Peixiang","Real-time Exciton-Manipulation of Plexcitonic Coupling in a WS2-Ag
  nanocavity","5 pages, 4 figures",,,,"physics.optics cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the real-time exciton-manipulation of plexcitonic coupling in
monolayer WS2 coupled to a plasmonic nanocavity by immersing into a mixed
solution of dichloromethane (DCM) and ethanol. By adjusting the mixture ratio,
a continuous tuning of the Rabi splitting energy ranged from 178 meV (in
ethanol) to 266 meV (in DCM) is achieved. The results are mainly attributed to
the remarkable increase of the proportion of neutral exciton in the monolayer
WS2 (from 59% to 100%) as the concentration of DCM is increased. It offers an
important stepping stone towards a further study of plexcitonic coupling in
layered materials, along with potential applications in quantum information
processing and nonlinear optical materials.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:58:03 GMT""}]","2020-02-25"
"2002.10069","Benjamin Gravell","Benjamin Gravell and Tyler Summers","Robust Learning-Based Control via Bootstrapped Multiplicative Noise",,,,,"cs.LG cs.SY eess.SY math.DS math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite decades of research and recent progress in adaptive control and
reinforcement learning, there remains a fundamental lack of understanding in
designing controllers that provide robustness to inherent non-asymptotic
uncertainties arising from models estimated with finite, noisy data. We propose
a robust adaptive control algorithm that explicitly incorporates such
non-asymptotic uncertainties into the control design. The algorithm has three
components: (1) a least-squares nominal model estimator; (2) a bootstrap
resampling method that quantifies non-asymptotic variance of the nominal model
estimate; and (3) a non-conventional robust control design method using an
optimal linear quadratic regulator (LQR) with multiplicative noise. A key
advantage of the proposed approach is that the system identification and robust
control design procedures both use stochastic uncertainty representations, so
that the actual inherent statistical estimation uncertainty directly aligns
with the uncertainty the robust controller is being designed against. We show
through numerical experiments that the proposed robust adaptive controller can
significantly outperform the certainty equivalent controller on both expected
regret and measures of regret risk.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 04:12:52 GMT""},{""version"":""v2"",""created"":""Fri, 15 May 2020 19:26:35 GMT""},{""version"":""v3"",""created"":""Wed, 11 Aug 2021 22:21:56 GMT""}]","2021-08-13"
"2002.10070","Jongho Park","Jongho Park","An Overlapping Domain Decomposition Framework without Dual Formulation
  for Variational Imaging Problems","27 pages, 7 figures","Adv. Comput. Math. 46 (2020) 57","10.1007/s10444-020-09799-7",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel overlapping domain decomposition method
that can be applied to various problems in variational imaging such as total
variation minimization. Most of recent domain decomposition methods for total
variation minimization adopt the Fenchel--Rockafellar duality, whereas the
proposed method is based on the primal formulation. Thus, the proposed method
can be applied not only to total variation minimization but also to those with
complex dual problems such as higher order models. In the proposed method, an
equivalent formulation of the model problem with parallel structure is
constructed using a custom overlapping domain decomposition scheme with the
notion of essential domains. As a solver for the constructed formulation, we
propose a decoupled augmented Lagrangian method for untying the coupling of
adjacent subdomains. Convergence analysis of the decoupled augmented Lagrangian
method is provided. We present implementation details and numerical examples
for various model problems including total variation minimizations and higher
order models.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 04:12:55 GMT""},{""version"":""v2"",""created"":""Thu, 9 Apr 2020 02:59:40 GMT""}]","2020-06-23"
"2002.10071","Dao Nguyen","Anh Duc Doan, Xin Dang, Dao Nguyen","Black-box sampling for weakly smooth Langevin Monte Carlo using
  p-generalized Gaussian smoothing",,,,,"stat.CO","http://creativecommons.org/licenses/by/4.0/","  Discretization of continuous-time diffusion processes is a widely recognized
method for sampling. However, the canonical Euler-Maruyama discretization of
the Langevin diffusion process, also named as Langevin Monte Carlo (LMC),
studied mostly in the context of smooth (gradient-Lipschitz) and strongly
log-concave densities, a significant constraint for its deployment in many
sciences, including computational statistics and statistical learning. In this
paper, we establish several theoretical contributions to the literature on such
sampling methods. Particularly, we generalize the Gaussian smoothing,
approximate the gradient using p-generalized Gaussian smoothing and take
advantage of it in the context of black-box sampling. We first present a
non-strongly concave and weakly smooth black-box LMC algorithm, ideal for
practical applicability of sampling challenges in a general setting.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 04:18:15 GMT""},{""version"":""v2"",""created"":""Mon, 5 Oct 2020 15:04:24 GMT""}]","2020-10-06"
"2002.10072","Chongwen Huang","Chongwen Huang, Ronghong Mo and Chau Yuen","Reconfigurable Intelligent Surface Assisted Multiuser MISO Systems
  Exploiting Deep Reinforcement Learning","12 pages. Accepted by IEEE JSAC special issue on Multiple Antenna
  Technologies for Beyond 5G","in IEEE Journal on Selected Areas in Communications, vol. 38, no.
  8, pp. 1839-1850, Aug. 2020","10.1109/JSAC.2020.3000835.",,"cs.IT cs.LG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the reconfigurable intelligent surface (RIS), benefited from the
breakthrough on the fabrication of programmable meta-material, has been
speculated as one of the key enabling technologies for the future six
generation (6G) wireless communication systems scaled up beyond massive
multiple input multiple output (Massive-MIMO) technology to achieve smart radio
environments. Employed as reflecting arrays, RIS is able to assist MIMO
transmissions without the need of radio frequency chains resulting in
considerable reduction in power consumption. In this paper, we investigate the
joint design of transmit beamforming matrix at the base station and the phase
shift matrix at the RIS, by leveraging recent advances in deep reinforcement
learning (DRL). We first develop a DRL based algorithm, in which the joint
design is obtained through trial-and-error interactions with the environment by
observing predefined rewards, in the context of continuous state and action.
Unlike the most reported works utilizing the alternating optimization
techniques to alternatively obtain the transmit beamforming and phase shifts,
the proposed DRL based algorithm obtains the joint design simultaneously as the
output of the DRL neural network. Simulation results show that the proposed
algorithm is not only able to learn from the environment and gradually improve
its behavior, but also obtains the comparable performance compared with two
state-of-the-art benchmarks. It is also observed that, appropriate neural
network parameter settings will improve significantly the performance and
convergence rate of the proposed algorithm.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 04:28:44 GMT""}]","2022-06-23"
"2002.10073","Lin He","Yu Zhang, Zhe Hou, Ya-Xin Zhao, Zi-Han Guo, Yi-Wen Liu, Si-Yu Li,
  Ya-Ning Ren, Qing-Feng Sun, and Lin He","Electron interactions in strain-induced zero-energy flat band in twisted
  bilayer graphene near the magic angle",,,,,"cond-mat.str-el cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the vicinity of the magic angle in twisted bilayer graphene (TBG), the two
low-energy van Hove singularities (VHSs) become exceedingly narrow1-10 and many
exotic correlated states, such as superconductivity, ferromagnetism, and
topological phases, are observed11-16. Heterostrain, which is almost
unavoidable in the TBG, can modify its single-particle band structure and lead
to novel properties of the TBG that have never been considered so far. Here, we
show that heterostrain in a TBG near the magic angle generates a new
zero-energy flat band between the two VHSs. Doping the TBG to partially fill
the zero-energy flat band, we observe a correlation-induced gap of about 10 meV
that splits the flat band. By applying perpendicular magnetic fields, a large
and linear response of the gap to magnetic fields is observed, attributing to
the emergence of large orbital magnetic moments in the TBG when valley
degeneracy of the flat band is lifted by electron-electron interactions. The
orbital magnetic moment per moire supercell is measured as about 15 uB in the
TBG.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 04:38:22 GMT""}]","2020-02-25"
"2002.10074","Yongguan Ke","Yongguan Ke, Janet Zhong, Alexander V. Poshakinskiy, Yuri S. Kivshar,
  Alexander N. Poddubny, Chaohong Lee","Radiative topological biphoton states in modulated qubit arrays","Any comments and suggestions are welcome","Phys. Rev. Research 2, 033190 (2020)","10.1103/PhysRevResearch.2.033190",,"quant-ph physics.atom-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study topological properties of bound pairs of photons in
spatially-modulated qubit arrays (arrays of two-level atoms) coupled to a
waveguide. While bound pairs behave like Bloch waves, they are topologically
nontrivial in the parameter space formed by the center-of-mass momentum and the
modulation phase, where the latter plays the role of a synthetic dimension. In
a superlattice where each unit cell contains three two-level atoms (qubits), we
calculate the Chern numbers for the bound-state photon bands, which are found
to be $(1,-2,1)$. For open boundary condition, we find exotic topological
bound-pair edge states with radiative losses. Unlike the conventional case of
the bulk-edge correspondence, these novel edge modes not only exist in gaps
separating the bound-pair bands, but they also may merge with and penetrate
into the bands. By joining two structures with different spatial modulations,
we find long-lived interface states which may have applications in storage and
quantum information processing.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 04:44:12 GMT""}]","2020-08-12"
"2002.10075","Kang Young Lee","Dong-Won Jung, Soo-hyeon Nam, Chaehyun Yu, Yeong Gyun Kim and Kang
  Young Lee","Singlet Fermionic Dark Matter with Dark $Z$","10 pages, 3 figures","Eur.Phys.J.C 80 (6) 513 (2020)","10.1140/epjc/s10052-020-8080-x",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a fermionic dark matter model mediated by the hidden gauge boson.
We assume the QED-like hidden sector which consists of a Dirac fermion and
U(1)$_X$ gauge symmetry, and introduce an additional scalar electroweak doublet
field with the U(1)$_X$ charge as a mediator. The hidden U(1)$_X$ symmetry is
spontaneously broken by the electroweak symmetry breaking and there exists a
massive extra neutral gauge boson in this model which is the mediator between
the hidden and visible sectors. Due to the U(1)$_X$ charge, the additional
scalar doublet does not couple to the Standard Model fermions, which leads to
the Higgs sector of type I two Higgs doublet model. The new gauge boson couples
to the Standard Model fermions with couplings proportional to those of the
ordinary $Z$ boson but very suppressed, thus we call it the dark $Z$ boson. We
study the phenomenology of the dark $Z$ boson and the Higgs sector, and show
the hidden fermion can be the dark matter candidate.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 04:55:42 GMT""},{""version"":""v2"",""created"":""Wed, 26 Feb 2020 03:43:02 GMT""},{""version"":""v3"",""created"":""Wed, 29 Apr 2020 13:34:43 GMT""}]","2020-12-16"
"2002.10076","Sanjaya Paudel","Sanjaya Paudel Chandreyee Sengupta, Suk-Jin Yoon, and Daya Nidhi
  Chhatkuli","MCG+07-20-052: Interacting dwarf pair in a group environment","Accepted for publication in AJ",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an observational study of the interacting pair of dwarf galaxies,
MCG+07-20-052, in the vicinity of Milky Way mass spiral galaxy NGC 2998.
MCG+07-20-052 is located at a sky-projected distance of 105 kpc from NGC 2998
and the two have a relative line-of-sight velocity of 60 kms. We observed tidal
tail-like extensions on both members (D1 and D2) of the interacting pair
MCG+07-20-052. The interacting dwarf galaxies, D1 and D2, have B-band absolute
magnitudes of $-$17.17 and $-$17.14 mag, respectively, and D2 is significantly
bluer than D1. We obtained HI 21 cm line data of the NGC 2998 system using the
Giant Metrewave Radio Telescope (GMRT) to get a more detailed view of the
neutral hydrogen (HI) emission in the interacting dwarf galaxies and in the
galaxy members of the NGC 2998 group. Evidence of a merger between the dwarf
galaxies in the MCG+07-20-052 is also present in the HI kinematics and
morphology where we find that the HI is mostly concentrated around D2, which
also shows a higher level of star-forming activity and bluer $g-r$ color index
compared to D1. In addition, we detect extended tenuous HI emission around
another member galaxy, NGC 3006, located close to the MCG+07-20-052-pair at a
sky-projected distance of 41 kpc. We compare here our results from the
MCG+07-20-052 pair-NGC 2998 system with other known LMC-SMC-Milky Way type
systems and discuss the possible origin of the dwarf-dwarf interaction.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:06:06 GMT""}]","2020-02-25"
"2002.10077","Zachary Izzo","Zachary Izzo, Mary Anne Smart, Kamalika Chaudhuri, James Zou","Approximate Data Deletion from Machine Learning Models","20 pages, 1 figure, accepted for publication at AISTATS 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deleting data from a trained machine learning (ML) model is a critical task
in many applications. For example, we may want to remove the influence of
training points that might be out of date or outliers. Regulations such as EU's
General Data Protection Regulation also stipulate that individuals can request
to have their data deleted. The naive approach to data deletion is to retrain
the ML model on the remaining data, but this is too time consuming. In this
work, we propose a new approximate deletion method for linear and logistic
models whose computational cost is linear in the the feature dimension $d$ and
independent of the number of training data $n$. This is a significant gain over
all existing methods, which all have superlinear time dependence on the
dimension. We also develop a new feature-injection test to evaluate the
thoroughness of data deletion from ML models.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:12:03 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 18:56:03 GMT""}]","2021-02-24"
"2002.10078","Chuan Guo","Chuan Guo, Ruihan Wu, Kilian Q. Weinberger","On Hiding Neural Networks Inside Neural Networks",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Modern neural networks often contain significantly more parameters than the
size of their training data. We show that this excess capacity provides an
opportunity for embedding secret machine learning models within a trained
neural network. Our novel framework hides the existence of a secret neural
network with arbitrary desired functionality within a carrier network. We prove
theoretically that the secret network's detection is computationally infeasible
and demonstrate empirically that the carrier network does not compromise the
secret network's disguise. Our paper introduces a previously unknown
steganographic technique that can be exploited by adversaries if left
unchecked.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:18:29 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 17:27:10 GMT""},{""version"":""v3"",""created"":""Sat, 22 May 2021 00:27:12 GMT""}]","2021-05-25"
"2002.10079","Yicheng Zhang","Yicheng Zhang","A Distributed Architecture for Real-time Hybrid Traffic Light Control in
  Urban Transportation Networks","This is a brief summary of the talk presented during the IEEE ITSS
  Young Professionals Workshop affiliated with IEEE Intelligent Transportation
  Systems Conference 2019 at Auckland, New Zealand",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A macroscopic model is proposed to depict the traffic dynamics involved in
urban traffic systems. The link dynamics are described based on the
cell-transmission model and bounded by the link capacities, while the flow
dynamics are proposed based on the discharge headways and saturation flow at
intersections. To fulfill the requirement of a closed-loop traffic light
control strategy, an approach to estimate the branching ratios at intersections
is proposed and simulations show that the convergence would be achieved under
constant cyclic flow profiles. Furthermore, a system partitioning approach is
proposed based congestion level identification, which is achieved via a machine
learning method and a hybrid traffic network control strategy is proposed to
integrate different traffic light control schemes together.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:20:45 GMT""}]","2020-02-25"
"2002.10080","Xiangyu Yang","Xiangyu Yang, Sheng Hua, Yuanming Shi, Hao Wang, Jun Zhang, Khaled B.
  Letaief","Sparse Optimization for Green Edge AI Inference","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.IT cs.LG eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the rapid upsurge of deep learning tasks at the network edge, effective
edge artificial intelligence (AI) inference becomes critical to provide
low-latency intelligent services for mobile users via leveraging the edge
computing capability. In such scenarios, energy efficiency becomes a primary
concern. In this paper, we present a joint inference task selection and
downlink beamforming strategy to achieve energy-efficient edge AI inference
through minimizing the overall power consumption consisting of both computation
and transmission power consumption, yielding a mixed combinatorial optimization
problem. By exploiting the inherent connections between the set of task
selection and group sparsity structural transmit beamforming vector, we
reformulate the optimization as a group sparse beamforming problem. To solve
this challenging problem, we propose a log-sum function based three-stage
approach. By adopting the log-sum function to enhance the group sparsity, a
proximal iteratively reweighted algorithm is developed. Furthermore, we
establish the global convergence analysis and provide the ergodic worst-case
convergence rate for this algorithm. Simulation results will demonstrate the
effectiveness of the proposed approach for improving energy efficiency in edge
AI inference systems.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:21:58 GMT""},{""version"":""v2"",""created"":""Fri, 13 Mar 2020 13:11:12 GMT""}]","2020-03-16"
"2002.10081","Tamir Bendory","Tamir Bendory and Dan Edidin","Toward a mathematical theory of the crystallographic phase retrieval
  problem",,,,,"cs.IT math.AG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the X-ray crystallography technology to determine the atomic
structure of biological molecules, we study the crystallographic phase
retrieval problem, arguably the leading and hardest phase retrieval setup. This
problem entails recovering a K-sparse signal of length N from its Fourier
magnitude or, equivalently, from its periodic auto-correlation. Specifically,
this work focuses on the fundamental question of uniqueness: what is the
maximal sparsity level K/N that allows unique mapping between a signal and its
Fourier magnitude, up to intrinsic symmetries. We design a systemic
computational technique to affirm uniqueness for any specific pair (K,N), and
establish the following conjecture: the Fourier magnitude determines a generic
signal uniquely, up to intrinsic symmetries, as long as K<=N/2. Based on
group-theoretic considerations and an additional computational technique, we
formulate a second conjecture: if K<N/2, then for any signal the set of
solutions to the crystallographic phase retrieval problem has measure zero in
the set of all signals with a given Fourier magnitude. Together, these
conjectures constitute the first attempt to establish a mathematical theory for
the crystallographic phase retrieval problem.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:31:11 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jul 2020 19:55:15 GMT""}]","2020-07-06"
"2002.10082","Hidetoshi Taya","ExHIC-P Collaboration, Hidetoshi Taya, Aaron Park, Sungtae Cho,
  Philipp Gubler, Koichi Hattori, Juhee Hong, Xu-Guang Huang, Su Houng Lee,
  Akihiko Monnai, Akira Ohnishi, Makoto Oka, Di-Lun Yang","Signatures of the vortical quark-gluon plasma in hadron yields","6 pages, 2 figures; v2: summary and discussions improved, references
  updated, to be published in PRC","Phys. Rev. C 102, 021901 (2020)","10.1103/PhysRevC.102.021901","YITP-20-07","nucl-th hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the hadron production from the vortical quark-gluon plasma
created in heavy-ion collisions. Based on the quark-coalescence and statistical
hadronization models, we show that total hadron yields summed over the spin
components are enhanced by the local vorticity with quadratic dependence. The
enhancement factor amounts to be a few percent and may be detectable within
current experimental sensitivities. We also show that the effect is stronger
for hadrons with larger spin, and thus propose a new signature of the local
vorticity, which may be detected by the yield ratio of distinct hadron species
having different spins such as $\phi$ and $\eta'$. The vorticity dependence of
hadron yields seems robust, with consistent predictions in both of the hadron
production mechanisms for reasonable values of the vorticity strength estimated
for heavy-ion collisions.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:36:53 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jul 2020 17:40:57 GMT""}]","2020-08-12"
"2002.10083","Oguz Selvitopi","Oguz Selvitopi, Md Taufique Hussain, Ariful Azad, Ayd{\i}n Bulu\c{c}","Optimizing High Performance Markov Clustering for Pre-Exascale
  Architectures",,"34th IEEE International Parallel and Distributed Processing
  Symposium (IPDPS), 2020",,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  HipMCL is a high-performance distributed memory implementation of the popular
Markov Cluster Algorithm (MCL) and can cluster large-scale networks within
hours using a few thousand CPU-equipped nodes. It relies on sparse matrix
computations and heavily makes use of the sparse matrix-sparse matrix
multiplication kernel (SpGEMM). The existing parallel algorithms in HipMCL are
not scalable to Exascale architectures, both due to their communication costs
dominating the runtime at large concurrencies and also due to their inability
to take advantage of accelerators that are increasingly popular.
  In this work, we systematically remove scalability and performance
bottlenecks of HipMCL. We enable GPUs by performing the expensive expansion
phase of the MCL algorithm on GPU. We propose a CPU-GPU joint distributed
SpGEMM algorithm called pipelined Sparse SUMMA and integrate a probabilistic
memory requirement estimator that is fast and accurate. We develop a new
merging algorithm for the incremental processing of partial results produced by
the GPUs, which improves the overlap efficiency and the peak memory usage. We
also integrate a recent and faster algorithm for performing SpGEMM on CPUs. We
validate our new algorithms and optimizations with extensive evaluations. With
the enabling of the GPUs and integration of new algorithms, HipMCL is up to
12.4x faster, being able to cluster a network with 70 million proteins and 68
billion connections just under 15 minutes using 1024 nodes of ORNL's Summit
supercomputer.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:39:51 GMT""}]","2020-02-26"
"2002.10084","Matthew Roos","Matthew J. Roos","Utilizing a null class to restrict decision spaces and defend against
  neural network adversarial attacks","15 pages, 19 figures",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite recent progress, deep neural networks generally continue to be
vulnerable to so-called adversarial examples--input images with small
perturbations that can result in changes in the output classifications, despite
no such change in the semantic meaning to human viewers. This is true even for
seemingly simple challenges such as the MNIST digit classification task. In
part, this suggests that these networks are not relying on the same set of
object features as humans use to make these classifications. In this paper we
examine an additional, and largely unexplored, cause behind this
phenomenon--namely, the use of the conventional training paradigm in which the
entire input space is parcellated among the training classes. Owing to this
paradigm, learned decision spaces for individual classes span excessively large
regions of the input space and include images that have no semantic similarity
to images in the training set. In this study, we train models that include a
null class. That is, models may ""opt-out"" of classifying an input image as one
of the digit classes. During training, null images are created through a
variety of methods, in an attempt to create tighter and more semantically
meaningful decision spaces for the digit classes. The best performing models
classify nearly all adversarial examples as nulls, rather than mistaking them
as a member of an incorrect digit class, while simultaneously maintaining high
accuracy on the unperturbed test set. The use of a null class and the training
paradigm presented herein may provide an effective defense against adversarial
attacks for some applications. Code for replicating this study will be made
available at https://github.com/mattroos/null_class_adversarial_defense .
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:47:08 GMT""}]","2020-02-25"
"2002.10085","Wenrui Zhang","Wenrui Zhang, Peng Li","Temporal Spike Sequence Learning via Backpropagation for Deep Spiking
  Neural Networks","Accepted for spotlight presentation of NeurIPS (Neural Information
  Processing System) 2020:
  https://proceedings.neurips.cc/paper/2020/hash/8bdb5058376143fa358981954e7626b8-Abstract.html",,,,"cs.NE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spiking neural networks (SNNs) are well suited for spatio-temporal learning
and implementations on energy-efficient event-driven neuromorphic processors.
However, existing SNN error backpropagation (BP) methods lack proper handling
of spiking discontinuities and suffer from low performance compared with the BP
methods for traditional artificial neural networks. In addition, a large number
of time steps are typically required to achieve decent performance, leading to
high latency and rendering spike-based computation unscalable to deep
architectures. We present a novel Temporal Spike Sequence Learning
Backpropagation (TSSL-BP) method for training deep SNNs, which breaks down
error backpropagation across two types of inter-neuron and intra-neuron
dependencies and leads to improved temporal learning precision. It captures
inter-neuron dependencies through presynaptic firing times by considering the
all-or-none characteristics of firing activities and captures intra-neuron
dependencies by handling the internal evolution of each neuronal state in time.
TSSL-BP efficiently trains deep SNNs within a much shortened temporal window of
a few steps while improving the accuracy for various image classification
datasets including CIFAR10.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:49:37 GMT""},{""version"":""v2"",""created"":""Sat, 20 Jun 2020 07:41:13 GMT""},{""version"":""v3"",""created"":""Fri, 23 Oct 2020 21:42:18 GMT""},{""version"":""v4"",""created"":""Mon, 7 Jun 2021 06:24:25 GMT""}]","2021-06-08"
"2002.10086","Damir Yeliussizov","Damir Yeliussizov","Dual Grothendieck polynomials via last-passage percolation",,,,,"math.CO math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ring of symmetric functions has a basis of dual Grothendieck polynomials
that are inhomogeneous $K$-theoretic deformations of Schur polynomials. We
prove that dual Grothendieck polynomials determine column distributions for a
directed last-passage percolation model.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:51:36 GMT""}]","2020-02-25"
"2002.10087","Kartick Adhikari","Kartick Adhikari, Subhroshekhar Ghosh, Joel L. Lebowitz","Fluctuation and Entropy in Spectrally Constrained random fields","39 pages","Communications in Mathematical Physics 386 (2021), no. 2, 749-780","10.1007/s00220-021-04150-7",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the statistical properties of translation invariant random
fields (including point processes) on Euclidean spaces (or lattices) under
constraints on their spectrum or structure function. An important class of
models that motivate our study are hyperuniform and stealthy hyperuniform
systems, which are characterised by the vanishing of the structure function at
the origin (resp., vanishing in a neighbourhood of the origin). We show that
many key features of two classical statistical mechanical measures of
randomness - namely, fluctuations and entropy, are governed only by some
particular local aspects of their structure function. We obtain exponents for
the fluctuations of the local mass in domains of growing size, and show that
spatial geometric considerations play an important role - both the shape of the
domain and the mode of spectral decay. In doing so, we unveil intriguing
oscillatory behaviour of spatial correlations of local masses in adjacent box
domains. We describe very general conditions under which we show that the field
of local masses exhibit Gaussian asymptotics, with an explicitly described
limit. We further demonstrate that stealthy hyperuniform systems with joint
densities exhibit degeneracy in their asymptotic entropy per site. In fact, our
analysis shows that entropic degeneracy sets in under much milder conditions
than stealthiness, as soon as the structure function fails to be
logarithmically integrable.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:05:23 GMT""},{""version"":""v2"",""created"":""Fri, 4 Feb 2022 07:38:28 GMT""}]","2022-02-07"
"2002.10088","Huajun Huang Dr","Ming-Cheng Tsai, Meaza Bogale, Huajun Huang","On triangular similarity of nilpotent triangular matrices","Corresponding author: Huajun Huang",,,,"math.RT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $B_n$ (resp. $U_n$, $N_n$) be the set of $n\times n$ nonsingular (resp.
unit, nilpotent) upper triangular matrices. We use a novel approach to explore
the $B_n$-similarity orbits in $N_n$. The Belitski\u{\i}'s canonical form of
$A\in N_n$ under $B_n$-similarity is in $QU_n$ where $Q$ is the subpermutation
such that $A\in B_n QB_n$. Using graph representations and $U_n$-similarity
actions stablizing $QU_n$, we obtain new properties of the Belitski\u{\i}'s
canonical forms and present an efficient algorithm to find the Belitski\u{\i}'s
canonical forms in $N_n$. As consequences, we construct new Belitski\u{\i}'s
canonical forms in all $N_n$'s, list all Belitski\u{\i}'s canonical forms for
$n=7, 8$, and show examples of 3-nilpotent Belitski\u{\i}'s canonical forms in
$N_n$ with arbitrary numbers of parameters up to $\operatorname{O}(n^2)$.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:11:32 GMT""}]","2020-02-25"
"2002.10089","Giorgio Gubbiotti","G. Gubbiotti and N. Joshi","Space of initial values of a map with a quartic invariant","10 pages, 1 figures",,,,"nlin.SI math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compactify and regularize the space of initial values of a planar map with
a quartic invariant and use this construction to prove its integrability in the
sense of algebraic entropy. The system turns out to have certain unusual
properties, including a sequence of points of indeterminacy in $\mathbb
P^1\cross \mathbb P^1$. These indeterminacy points are shown to lie on a
singular fibre of the mapping to a corresponding QRT system and provide the
existence of a one-parameter family of special solutions.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:21:37 GMT""},{""version"":""v2"",""created"":""Tue, 2 Jun 2020 04:20:39 GMT""}]","2020-06-03"
"2002.10090","Junfei Zhang","Junfei Zhang, Yimiao Huang, Guowei Ma, Brett Nener","Multi-objective beetle antennae search algorithm","5 figures and 1 table",,,,"cs.NE math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In engineering optimization problems, multiple objectives with a large number
of variables under highly nonlinear constraints are usually required to be
simultaneously optimized. Significant computing effort are required to find the
Pareto front of a nonlinear multi-objective optimization problem. Swarm
intelligence based metaheuristic algorithms have been successfully applied to
solve multi-objective optimization problems. Recently, an individual
intelligence based algorithm called beetle antennae search algorithm was
proposed. This algorithm was proved to be more computationally efficient.
Therefore, we extended this algorithm to solve multi-objective optimization
problems. The proposed multi-objective beetle antennae search algorithm is
tested using four well-selected benchmark functions and its performance is
compared with other multi-objective optimization algorithms. The results show
that the proposed multi-objective beetle antennae search algorithm has higher
computational efficiency with satisfactory accuracy.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:34:32 GMT""},{""version"":""v2"",""created"":""Wed, 5 Aug 2020 00:23:00 GMT""}]","2020-08-06"
"2002.10091","Debo Cheng","Debo Cheng (1), Jiuyong Li (1), Lin Liu (1), Kui Yu (2), Thuc Duy Lee
  (1), Jixue Liu (1) ((1) School of Information Technology and Mathematical
  Sciences, University of South Australia (2) School of Computer Science and
  Information Engineering, Hefei University of Technology)","Towards unique and unbiased causal effect estimation from data with
  hidden variables","12 pages,8 figures",,,,"stat.ME cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Causal effect estimation from observational data is a crucial but challenging
task. Currently, only a limited number of data-driven causal effect estimation
methods are available. These methods either provide only a bound estimation of
the causal effect of a treatment on the outcome, or generate a unique
estimation of the causal effect, but making strong assumptions on data and
having low efficiency. In this paper, we identify a practical problem setting
and propose an approach to achieving unique and unbiased estimation of causal
effects from data with hidden variables. For the approach, we have developed
the theorems to support the discovery of the proper covariate sets for
confounding adjustment (adjustment sets). Based on the theorems, two algorithms
are proposed for finding the proper adjustment sets from data with hidden
variables to obtain unbiased and unique causal effect estimation. Experiments
with synthetic datasets generated using five benchmark Bayesian networks and
four real-world datasets have demonstrated the efficiency and effectiveness of
the proposed algorithms, indicating the practicability of the identified
problem setting and the potential of the proposed approach in real-world
applications.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:42:32 GMT""},{""version"":""v2"",""created"":""Sat, 7 Nov 2020 23:28:15 GMT""}]","2020-11-10"
"2002.10092","Ankit Kumar","Ankit Kumar, Amit Jash, Tsuyoshi Tamegai, S. S. Banerjee","Imaging the effect of drive on the low-field vortex melting phenomenon
  in Ba0.6K0.4Fe2As2 single crystal","13 pages, 6 figures including Supplementary Information","Phys. Rev. B 101, 184516 (2020)","10.1103/PhysRevB.101.184516",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-field imaging of current distribution in Ba0.6K0.4Fe2As2 superconductor
is used to study the effect of drive on the low-field vortex solid to liquid
melting phase transformation. At low fields, the current induced drive on the
vortices aids in thermally destabilizing the vortex state thereby shifting the
low field melting phase boundary. We show that the current induced drive shifts
solid-liquid boundaries and prepones the vortex melting phenomenon compared to
the equilibrium situation. The analysis shows that for currents above 50 mA,
Joule heating effects shift the melting line while below 50 mA, an effective
temperature concept for driven system viz., a drive dependent shaking
temperature, explains the shift. The observation of a transformation from
inhomogeneous to homogeneous current flow in the sample at low fields as a
function of the driving force is reconciled via an inverse dependence of the
shaking temperature on vortex velocity, which is incorporated in our analysis.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:43:37 GMT""}]","2020-05-27"
"2002.10093","Niladri Modak","Niladri Modak, Athira B S, Ankit Kumar Singh, Nirmalya Ghosh","A Generalized framework of weak value amplification in path interference
  of polarized light for the enhancement of all possible polarization
  anisotropy effects",,"Phys. Rev. A 103, 053518 (2021)","10.1103/PhysRevA.103.053518",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the profound interferometric philosophy of weak value amplification, we
propose a simple, general and a robust polarization method for the
amplification and quantification of small magnitudes of all possible
polarization anisotropy effects in a single experimental embodiment. The
approach is experimentally realized by introducing a weak coupling between the
polarization degree of freedom of light and the path degree of freedom in a
Mach-Zehnder interferometer in the presence of a weak anisotropy effect. Real
and imaginary weak value amplifications of different polarization anisotropy
effects are manifested as characteristic changes in relevant Stokes vector
elements at the exit port of the interferometer, which follow orthogonal
trajectories in the Poincare sphere. The proof of concept experiment
demonstrates that using this scheme, one can faithfully extract and quantify
anisotropy parameter that is smaller than the typical sensitivity of
measurement of a given Stokes parameter of a traditional polarimeter by a large
weak value amplification factor. This opens up possibility of a sample
measuring weak value polarimeter for studying rich variety of fundamental
optical effects and for materials characterization and precision metrology.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:45:30 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 09:20:53 GMT""}]","2021-06-09"
"2002.10094","Naresh Emani","Saurabh Kishen, Jinal Tapar and Naresh Kumar Emani","Enhanced light emission from gap plasmons in nano-strip MIM tunnel
  junctions","This is the version of the article before peer review or editing, as
  submitted by an author to IoP Journal of Optics. IOP Publishing Ltd is not
  responsible for any errors or omissions in this version of the manuscript or
  any version derived from it. The Version of Record is available online at
  https://doi.org/10.1088/2040-8986/ababe7","J. Opt. 22 095006 (2020)","10.1088/2040-8986/ababe7",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electrical excitation of light using inelastic electron tunneling is a
promising approach for the realization of ultra-compact on-chip optical sources
with high modulation bandwidth. However, the practical implementation of these
nanoscale light sources presents a challenge due to the low electron-to-photon
transduction efficiencies. Here, we investigate designs for the enhancement of
light generation and out-coupling in a periodic Ag-SiO2-Ag tunnel junction due
to inelastic electron tunneling. The structure presents a unique advantage of a
simple fabrication procedure as compared to the other reported structures. By
efficiently coupling the gap plasmon mode and the lattice resonance, we achieve
a resonant enhancement in the local density of optical states up to three
orders of magnitude and enhanced radiative efficiency of ~0.53, 30% higher as
compared to the uncoupled structure.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:46:53 GMT""},{""version"":""v2"",""created"":""Thu, 10 Sep 2020 19:32:36 GMT""}]","2020-09-14"
"2002.10095","Uicheol Jang","Uicheol Jang and Hongsu Kim","Toward practical/realistic Randall-Sundrum Brane world scenario",,,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Randall- Sundrum brane world scenario is mostly preserved and still
secure as we realized that the graviton trap is still safely guaranteed. We
would like to empathize here that such necessary but rich elaboration doesn't
cost a fortune as the Ricci flatness condition effectively accommodates the
realistic structure of our universe on the one hand, while still sustaining the
4-dimensional graviton trap on the other.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:05:11 GMT""}]","2020-02-25"
"2002.10096","Marian D\""ork","Philipp Geuder, Marie Claire Leidinger, Martin von Lupin, Marian
  D\""ork, Tobias Schr\""oder","Emosaic: Visualizing Affective Content of Text at Varying Granularity","9 pages, 7 figures",,,,"cs.HC cs.CL cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents Emosaic, a tool for visualizing the emotional tone of
text documents, considering multiple dimensions of emotion and varying levels
of semantic granularity. Emosaic is grounded in psychological research on the
relationship between language, affect, and color perception. We capitalize on
an established three-dimensional model of human emotion: valence (good, nice
vs. bad, awful), arousal (calm, passive vs. exciting, active) and dominance
(weak, controlled vs. strong, in control). Previously, multi-dimensional models
of emotion have been used rarely in visualizations of textual data, due to the
perceptual challenges involved. Furthermore, until recently most text
visualizations remained at a high level, precluding closer engagement with the
deep semantic content of the text. Informed by empirical studies, we introduce
a color mapping that translates any point in three-dimensional affective space
into a unique color. Emosaic uses affective dictionaries of words annotated
with the three emotional parameters of the valence-arousal-dominance model to
extract emotional meanings from texts and then assigns to them corresponding
color parameters of the hue-saturation-brightness color space. This approach of
mapping emotion to color is aimed at helping readers to more easily grasp the
emotional tone of the text. Several features of Emosaic allow readers to
interactively explore the affective content of the text in more detail; e.g.,
in aggregated form as histograms, in sequential form following the order of
text, and in detail embedded into the text display itself. Interaction
techniques have been included to allow for filtering and navigating of text and
visualizations.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:25:01 GMT""}]","2020-02-25"
"2002.10097","Leo Schwinn","Leo Schwinn, Ren\'e Raab, Bj\""orn Eskofier","Towards Rapid and Robust Adversarial Training with One-Step Attacks","16 pages, 5 figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial training is the most successful empirical method for increasing
the robustness of neural networks against adversarial attacks. However, the
most effective approaches, like training with Projected Gradient Descent (PGD)
are accompanied by high computational complexity. In this paper, we present two
ideas that, in combination, enable adversarial training with the
computationally less expensive Fast Gradient Sign Method (FGSM). First, we add
uniform noise to the initial data point of the FGSM attack, which creates a
wider variety of adversaries, thus prohibiting overfitting to one particular
perturbation bound. Further, we add a learnable regularization step prior to
the neural network, which we call Pixelwise Noise Injection Layer (PNIL).
Inputs propagated trough the PNIL are resampled from a learned Gaussian
distribution. The regularization induced by the PNIL prevents the model form
learning to obfuscate its gradients, a factor that hindered prior approaches
from successfully applying one-step methods for adversarial training. We show
that noise injection in conjunction with FGSM-based adversarial training
achieves comparable results to adversarial training with PGD while being
considerably faster. Moreover, we outperform PGD-based adversarial training by
combining noise injection and PNIL.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:28:43 GMT""},{""version"":""v2"",""created"":""Tue, 3 Mar 2020 14:32:31 GMT""},{""version"":""v3"",""created"":""Mon, 16 Mar 2020 06:41:20 GMT""},{""version"":""v4"",""created"":""Tue, 17 Mar 2020 07:52:57 GMT""}]","2020-03-18"
"2002.10098","Nikhil Bharadwaj Gosala","Nikhil Bharadwaj Gosala and Xiaoli Meng","An RLS-Based Instantaneous Velocity Estimator for Extended Radar
  Tracking","8 pages, 11 figures, accepted at the International Conference on
  Intelligent Robots and Systems (IROS) 2020, for accompanying video visit
  https://www.youtube.com/watch?v=B5SPXXkZpz8",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radar sensors have become an important part of the perception sensor suite
due to their long range and their ability to work in adverse weather
conditions. However, several shortcomings such as large amounts of noise and
extreme sparsity of the point cloud result in them not being used to their full
potential. In this paper, we present a novel Recursive Least Squares (RLS)
based approach to estimate the instantaneous velocity of dynamic objects in
real-time that is capable of handling large amounts of noise in the input data
stream. We also present an end-to-end pipeline to track extended objects in
real-time that uses the computed velocity estimates for data association and
track initialisation. The approaches are evaluated using several real-world
inspired driving scenarios that test the limits of these algorithms. It is also
experimentally proven that our approaches run in real-time with frame execution
time not exceeding 30 ms even in dense traffic scenarios, thus allowing for
their direct implementation on autonomous vehicles.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:30:46 GMT""},{""version"":""v2"",""created"":""Sun, 23 Aug 2020 08:42:28 GMT""}]","2020-08-25"
"2002.10099","Amos Gropp","Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, Yaron Lipman","Implicit Geometric Regularization for Learning Shapes","37th International Conference on Machine Learning, Vienna, Austria,
  2020",,,,"cs.LG cs.CV cs.GR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Representing shapes as level sets of neural networks has been recently proved
to be useful for different shape analysis and reconstruction tasks. So far,
such representations were computed using either: (i) pre-computed implicit
shape representations; or (ii) loss functions explicitly defined over the
neural level sets. In this paper we offer a new paradigm for computing high
fidelity implicit neural representations directly from raw data (i.e., point
clouds, with or without normal information). We observe that a rather simple
loss function, encouraging the neural network to vanish on the input point
cloud and to have a unit norm gradient, possesses an implicit geometric
regularization property that favors smooth and natural zero level set surfaces,
avoiding bad zero-loss solutions. We provide a theoretical analysis of this
property for the linear case, and show that, in practice, our method leads to
state of the art implicit neural representations with higher level-of-details
and fidelity compared to previous methods.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:36:32 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 12:32:45 GMT""}]","2020-07-10"
"2002.10100","Quan Huu Cap","Quan Huu Cap, Hiroyuki Uga, Satoshi Kagiwada, and Hitoshi Iyatomi","LeafGAN: An Effective Data Augmentation Method for Practical Plant
  Disease Diagnosis","Accepted as a regular paper in the IEEE Transactions on Automation
  Science and Engineering (T-ASE)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many applications for the automated diagnosis of plant disease have been
developed based on the success of deep learning techniques. However, these
applications often suffer from overfitting, and the diagnostic performance is
drastically decreased when used on test datasets from new environments. In this
paper, we propose LeafGAN, a novel image-to-image translation system with own
attention mechanism. LeafGAN generates a wide variety of diseased images via
transformation from healthy images, as a data augmentation tool for improving
the performance of plant disease diagnosis. Thanks to its own attention
mechanism, our model can transform only relevant areas from images with a
variety of backgrounds, thus enriching the versatility of the training images.
Experiments with five-class cucumber disease classification show that data
augmentation with vanilla CycleGAN cannot help to improve the generalization,
i.e., disease diagnostic performance increased by only 0.7% from the baseline.
In contrast, LeafGAN boosted the diagnostic performance by 7.4%. We also
visually confirmed the generated images by our LeafGAN were much better quality
and more convincing than those generated by vanilla CycleGAN. The code is
available publicly at: https://github.com/IyatomiLab/LeafGAN.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:36:56 GMT""},{""version"":""v2"",""created"":""Fri, 27 Nov 2020 13:34:44 GMT""}]","2020-11-30"
"2002.10101","Rongxiang Weng","Rongxiang Weng, Haoran Wei, Shujian Huang, Heng Yu, Lidong Bing,
  Weihua Luo, Jiajun Chen","GRET: Global Representation Enhanced Transformer","Accepted by AAAI 2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer, based on the encoder-decoder framework, has achieved
state-of-the-art performance on several natural language generation tasks. The
encoder maps the words in the input sentence into a sequence of hidden states,
which are then fed into the decoder to generate the output sentence. These
hidden states usually correspond to the input words and focus on capturing
local information. However, the global (sentence level) information is seldom
explored, leaving room for the improvement of generation quality. In this
paper, we propose a novel global representation enhanced Transformer (GRET) to
explicitly model global representation in the Transformer network.
Specifically, in the proposed model, an external state is generated for the
global representation from the encoder. The global representation is then fused
into the decoder during the decoding process to improve generation quality. We
conduct experiments in two text generation tasks: machine translation and text
summarization. Experimental results on four WMT machine translation tasks and
LCSTS text summarization task demonstrate the effectiveness of the proposed
approach on natural language generation.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:37:17 GMT""}]","2020-02-25"
"2002.10102","Wallace Michel Pinto Lira","Wallace Lira, Johannes Merz, Daniel Ritchie, Daniel Cohen-Or, Hao
  Zhang","GANHopper: Multi-Hop GAN for Unsupervised Image-to-Image Translation","To be presented at ECCV 2020. Code is available at
  https://github.com/wallacemplira/ganhopper",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce GANHopper, an unsupervised image-to-image translation network
that transforms images gradually between two domains, through multiple hops.
Instead of executing translation directly, we steer the translation by
requiring the network to produce in-between images that resemble weighted
hybrids between images from the input domains. Our network is trained on
unpaired images from the two domains only, without any in-between images. All
hops are produced using a single generator along each direction. In addition to
the standard cycle-consistency and adversarial losses, we introduce a new
hybrid discriminator, which is trained to classify the intermediate images
produced by the generator as weighted hybrids, with weights based on a
predetermined hop count. We also add a smoothness term to constrain the
magnitude of each hop, further regularizing the translation. Compared to
previous methods, GANHopper excels at image translations involving
domain-specific image features and geometric variations while also preserving
non-domain-specific features such as general color schemes.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:41:07 GMT""},{""version"":""v2"",""created"":""Sat, 29 Feb 2020 20:24:57 GMT""},{""version"":""v3"",""created"":""Thu, 11 Jun 2020 07:21:41 GMT""},{""version"":""v4"",""created"":""Thu, 16 Jul 2020 20:24:44 GMT""},{""version"":""v5"",""created"":""Wed, 29 Jul 2020 02:28:42 GMT""}]","2020-07-30"
"2002.10103","Jean Clerouin","Jean Clerouin, Philippe Arnault, Benoit-Joseph Grea, Sebastien
  Guisset, Marc Vandenboomgaerde, Alexander J. White, Lee A. Collins, Joel D.
  Kress, and Christopher Ticknor","Static and dynamic properties of multi-ionic plasma mixtures","17 pages, 10 Figures","Phys. Rev. E 101, 033207 (2020)","10.1103/PhysRevE.101.033207",,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Complex plasma mixtures with three or more components are often encountered
in astrophysics or in inertial confinement fusion (ICF) experiments. For
mixtures containing species with large differences in atomic number Z, the
modeling needs to consider at the same time the kinetic theory for low-Z
elements combined with the theory of strongly coupled plasma for high-Z
elements, as well as all the intermediate situations that can appear in
multi-component systems. For such cases, we study the pair distribution
functions, self-diffusions, mutual diffusion and viscosity for ternary mixtures
at extreme conditions. These quantities can be produced from first principles
using orbital free molecular dynamics at the computational expense of very
intensive simulations to reach good statistics. Utilizing the first-principles
results as reference data, we assess the merit of a global analytic model for
transport coefficients, Pseudo-Ions in Jellium (PIJ), based on an
iso-electronic assumption ( iso-n e ). With a multi-component hypernetted-chain
integral equation, we verify the quality of the iso-n e prescription for
describing the static structure of the mixtures. This semi-analytical modeling
compares well with the simulation results and allows one to consider plasma
mixtures not accessible to simulations. Applications are given for the mix of
materials in ICF experiments. A reduction of a multicomponent mixture to an
effective binary mixture is also established in the hydrodynamic limit and
compared with PIJ estimations for ICF relevant mixtures.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:43:44 GMT""}]","2020-11-19"
"2002.10104","Nikolaos Efremidis","Michael Goutsoulas, Domenico Bongiovanni, Denghui Li, Zhigang Chen,
  and Nikolaos K. Efremidis","Tunable self-similar Bessel-like beams of arbitrary order",,,"10.1364/OL.387115",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We predict that Bessel-like beams of arbitrary integer order can exhibit a
tunable self-similar behavior (that take an invariant form under suitable
stretching transformations). Specifically, by engineering the amplitude and the
phase on the input plane in real space, we show that it is possible to generate
higher-order vortex Bessel-like beams with fully controllable radius of the
hollow core and maximum intensity during propagation. In addition, using a
similar approach, we show that it is also possible to generate zeroth order
Bessel-like beams with controllable beam width and maximum intensity. Our
numerical results are in excellent agreement with our theoretical predictions.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:46:11 GMT""}]","2020-04-22"
"2002.10105","Qiang Wang","Qiang Wang, Shaohuai Shi, Canhui Wang, Xiaowen Chu","Communication Contention Aware Scheduling of Multiple Deep Learning
  Training Jobs",,,,,"cs.DC cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributed Deep Learning (DDL) has rapidly grown its popularity since it
helps boost the training performance on high-performance GPU clusters.
Efficient job scheduling is indispensable to maximize the overall performance
of the cluster when training multiple jobs simultaneously. However, existing
schedulers do not consider the communication contention of multiple
communication tasks from different distributed training jobs, which could
deteriorate the system performance and prolong the job completion time. In this
paper, we first establish a new DDL job scheduling framework which organizes
DDL jobs as Directed Acyclic Graphs (DAGs) and considers communication
contention between nodes. We then propose an efficient algorithm, LWF-$\kappa$,
to balance the GPU utilization and consolidate the allocated GPUs for each job.
When scheduling those communication tasks, we observe that neither avoiding all
the contention nor blindly accepting them is optimal to minimize the job
completion time. We thus propose a provable algorithm, AdaDUAL, to efficiently
schedule those communication tasks. Based on AdaDUAL, we finally propose
Ada-SRSF for the DDL job scheduling problem. Simulations on a 64-GPU cluster
connected with 10 Gbps Ethernet show that LWF-$\kappa$ achieves up to
$1.59\times$ improvement over the classical first-fit algorithms. More
importantly, Ada-SRSF reduces the average job completion time by $20.1\%$ and
$36.7\%$, as compared to the SRSF(1) scheme (avoiding all the contention) and
the SRSF(2) scheme (blindly accepting all of two-way communication contention)
respectively.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:50:56 GMT""}]","2020-02-25"
"2002.10106","Laurent Labonte","Dorian Oser, S\'ebastien Tanzilli, Florent Mazeas, Carlos
  Alonso-Ramos, Xavier Le Roux, Gr\'egory Sauder, Xin Hua, Olivier Alibart,
  Laurent Vivien, \'Eric Cassan and Laurent Labont\'e","High-quality photonic entanglement based on a silicon chip","11 pages, 6 figures","npj Quantum Inf. 6, 31 (2020)","10.1038/s41534-020-0263-7",,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fruitful association of quantum and integrated photonics holds the
promise to produce, manipulate, and detect quantum states of light using
compact and scalable systems. Integrating all the building-blocks necessary to
produce high-quality photonic entanglement in the telecom wavelength range out
of a single chip remains a major challenge, mainly due to the limited
performance of on-chip light rejection filters. We report a stand-alone,
telecom-compliant, device that integrates, on a single substrate, a nonlinear
photon-pair generator and a passive pump rejection filter. Using standard
channel-grid fiber demultiplexers, we demonstrate the first entanglement
quantification of such a integrated circuit, showing the highest raw quantum
interference visibility for energy-time entangled photons over two
telecom-wavelength bands. Genuinely pure maximally entangled states can
therefore be generated thanks to the high-level of noise suppression obtained
with the pump filter. These results will certainly further promote the
development of more advanced and scalable photonic-integrated quantum systems
compliant with telecommunication standards.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:54:46 GMT""}]","2020-07-07"
"2002.10107","Issa Annamoradnejad","Issa Annamoradnejad, Mohammadamin Fazli, Jafar Habibi","Predicting Subjective Features of Questions of QA Websites using BERT","5 pages, 4 figures, 2 tables","2020 6th International Conference on Web Research (ICWR), Tehran,
  Iran, 2020, pp. 240-244","10.1109/ICWR49608.2020.9122318",,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Community Question-Answering websites, such as StackOverflow and Quora,
expect users to follow specific guidelines in order to maintain content
quality. These systems mainly rely on community reports for assessing contents,
which has serious problems such as the slow handling of violations, the loss of
normal and experienced users' time, the low quality of some reports, and
discouraging feedback to new users. Therefore, with the overall goal of
providing solutions for automating moderation actions in Q&A websites, we aim
to provide a model to predict 20 quality or subjective aspects of questions in
QA websites. To this end, we used data gathered by the CrowdSource team at
Google Research in 2019 and a fine-tuned pre-trained BERT model on our problem.
Based on the evaluation by Mean-Squared-Error (MSE), the model achieved a value
of 0.046 after 2 epochs of training, which did not improve substantially in the
next ones. Results confirm that by simple fine-tuning, we can achieve accurate
models in little time and on less amount of data.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:56:02 GMT""},{""version"":""v2"",""created"":""Wed, 25 Mar 2020 08:10:16 GMT""},{""version"":""v3"",""created"":""Tue, 30 Jun 2020 13:22:04 GMT""},{""version"":""v4"",""created"":""Wed, 28 Oct 2020 14:37:39 GMT""}]","2020-10-29"
"2002.10108","Vendula Maulerova","Vendula Maulerova, Kalliopi Kanaki, Peter Kadletz, Robin Woracek,
  Thomas Wilpert, Kevin Fissum, Alessio Laloni, Nicholai Mauritzson, Fatima
  Issa, Richard Hall-Wilton","Vanadium-based neutron Beam Monitor",,"Phys. Rev. Accel. Beams 23, 072901 (2020)","10.1103/PhysRevAccelBeams.23.072901",,"physics.ins-det","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A prototype quasi-parasitic thermal neutron beam monitor based on isotropic
neutron scattering from a thin natural vanadium foil and standard $^3$He
proportional counters is conceptualized, designed, simulated, calibrated, and
commissioned. The European Spallation Source designed to deliver the highest
integrated neutron flux originating from a pulsed source is currently under
construction in Lund, Sweden. The effort to investigate a vanadium-based
neutron beam monitor was triggered by a list of requirements for Beam Monitors
permanently placed in the ESS neutron beams in order to provide reliable
monitoring at complex beamlines: low attenuation, linear response over a wide
range of neutron fluxes, near to constant efficiency for neutron wavelengths in
a range of 0.6-10 \r{A}, calibration stability and the possibility to place the
system in vacuum are all desirable characteristics. The scattering-based
prototype, employing a natural vanadium foil and standard $^3$He proportional
counters, was investigated at the V17 and V20 neutron beamlines of the
Helmholtz-Zentrum in Berlin, Germany, in several different geometrical
configurations of the $^3$He proportional counters around the foil. Response
linearity is successfully demonstrated for foil thicknesses ranging from 0.04
mm to 3.15 mm. Attenuation lower than 1% for thermal neutrons is demonstrated
for the 0.04 mm and 0.125 mm foils. The geometries used for the experiment were
simulated allowing for absolute flux calibration and establishing the possible
range of efficiencies for various designs of the prototype. The operational
flux limits for the beam monitor prototype were established as a dependency of
the background radiation and prototype geometry. The herein demonstrated
prototype monitors can be employed for neutron fluxes ranging from
$10^3-10^{10}$ n/s/cm$^2$.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:57:56 GMT""}]","2020-07-15"
"2002.10109","Yuping Gao","Jieru Feng, Yuping Gao, Jianliang Wu","The edge colorings of $K_{5}$-minor free graphs","14 pages, 1 figure",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 1965, Vizing proved that every planar graph $G$ with maximum degree
$\Delta\geq 8$ is edge $\Delta$-colorable. It is also proved that every planar
graph $G$ with maximum degree $\Delta=7$ is edge $\Delta$-colorable by Sanders
and Zhao, independently by Zhang. In this paper, we extend the above results by
showing that every $K_5$-minor free graph with maximum degree $\Delta$ at least
seven is edge $\Delta$-colorable.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:02:16 GMT""}]","2020-02-25"
"2002.10110","Huan Li","Huan Li and Zhouchen Lin","Revisiting EXTRA for Smooth Distributed Optimization",,,,,"math.NA cs.LG cs.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  EXTRA is a popular method for dencentralized distributed optimization and has
broad applications. This paper revisits EXTRA. First, we give a sharp
complexity analysis for EXTRA with the improved
$O\left(\left(\frac{L}{\mu}+\frac{1}{1-\sigma_2(W)}\right)\log\frac{1}{\epsilon(1-\sigma_2(W))}\right)$
communication and computation complexities for $\mu$-strongly convex and
$L$-smooth problems, where $\sigma_2(W)$ is the second largest singular value
of the weight matrix $W$. When the strong convexity is absent, we prove the
$O\left(\left(\frac{L}{\epsilon}+\frac{1}{1-\sigma_2(W)}\right)\log\frac{1}{1-\sigma_2(W)}\right)$
complexities. Then, we use the Catalyst framework to accelerate EXTRA and
obtain the $O\left(\sqrt{\frac{L}{\mu(1-\sigma_2(W))}}\log\frac{
L}{\mu(1-\sigma_2(W))}\log\frac{1}{\epsilon}\right)$ communication and
computation complexities for strongly convex and smooth problems and the
$O\left(\sqrt{\frac{L}{\epsilon(1-\sigma_2(W))}}\log\frac{1}{\epsilon(1-\sigma_2(W))}\right)$
complexities for non-strongly convex ones. Our communication complexities of
the accelerated EXTRA are only worse by the factors of
$\left(\log\frac{L}{\mu(1-\sigma_2(W))}\right)$ and
$\left(\log\frac{1}{\epsilon(1-\sigma_2(W))}\right)$ from the lower complexity
bounds for strongly convex and non-strongly convex problems, respectively.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:07:08 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 04:38:13 GMT""}]","2020-06-19"
"2002.10111","Zechen Liu","Zechen Liu, Zizhang Wu, Roland T\'oth","SMOKE: Single-Stage Monocular 3D Object Detection via Keypoint
  Estimation","8 pages, 6 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Estimating 3D orientation and translation of objects is essential for
infrastructure-less autonomous navigation and driving. In case of monocular
vision, successful methods have been mainly based on two ingredients: (i) a
network generating 2D region proposals, (ii) a R-CNN structure predicting 3D
object pose by utilizing the acquired regions of interest. We argue that the 2D
detection network is redundant and introduces non-negligible noise for 3D
detection. Hence, we propose a novel 3D object detection method, named SMOKE,
in this paper that predicts a 3D bounding box for each detected object by
combining a single keypoint estimate with regressed 3D variables. As a second
contribution, we propose a multi-step disentangling approach for constructing
the 3D bounding box, which significantly improves both training convergence and
detection accuracy. In contrast to previous 3D detection techniques, our method
does not require complicated pre/post-processing, extra data, and a refinement
stage. Despite of its structural simplicity, our proposed SMOKE network
outperforms all existing monocular 3D detection methods on the KITTI dataset,
giving the best state-of-the-art result on both 3D object detection and Bird's
eye view evaluation. The code will be made publicly available.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:15:36 GMT""}]","2020-02-25"
"2002.10112","Samith Abeywickrama","Samith Abeywickrama, Rui Zhang, Qingqing Wu, Chau Yuen","Intelligent Reflecting Surface: Practical Phase Shift Model and
  Beamforming Optimization","submitted for possible journal publication (Part of this work will be
  presented in the IEEE International Conference on Communications (ICC),
  Dublin, Ireland, 2020 Available: arXiv:1907.06002)",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intelligent reflecting surface (IRS) that enables the control of wireless
propagation environment has recently emerged as a promising cost-effective
technology for boosting the spectrum and energy efficiency in future wireless
communication systems. Prior works on IRS are mainly based on the ideal phase
shift model assuming the full signal reflection by each of the elements
regardless of its phase shift, which, however, is practically difficult to
realize. In contrast, we propose in this paper the practical phase shift model
that captures the phase-dependent amplitude variation in the element-wise
reflection coefficient. Based on the proposed model and considering an
IRS-aided multiuser system with an IRS deployed to assist in the downlink
communications from a multi-antenna access point (AP) to multiple
single-antenna users, we formulate an optimization problem to minimize the
total transmit power at the AP by jointly designing the AP transmit beamforming
and the IRS reflect beamforming, subject to the users' individual
signal-to-interference-plus-noise ratio (SINR) constraints. Iterative
algorithms are proposed to find suboptimal solutions to this problem
efficiently by utilizing the alternating optimization (AO) or penalty-based
optimization technique. Moreover, we analyze the asymptotic performance loss of
the IRS-aided system that employs practical phase shifters but assumes the
ideal phase shift model for beamforming optimization, as the number of IRS
elements goes to infinity. Simulation results unveil substantial performance
gains achieved by the proposed beamforming optimization based on the practical
phase shift model as compared to the conventional ideal model.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:20:14 GMT""}]","2020-02-25"
"2002.10113","Alex Tong Lin","Alex Tong Lin, Samy Wu Fung, Wuchen Li, Levon Nurbekyan, Stanley J.
  Osher","Alternating the Population and Control Neural Networks to Solve
  High-Dimensional Stochastic Mean-Field Games",,,"10.1073/pnas.2024713118",,"cs.LG cs.MA math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present APAC-Net, an alternating population and agent control neural
network for solving stochastic mean field games (MFGs). Our algorithm is geared
toward high-dimensional instances of MFGs that are beyond reach with existing
solution methods. We achieve this in two steps. First, we take advantage of the
underlying variational primal-dual structure that MFGs exhibit and phrase it as
a convex-concave saddle point problem. Second, we parameterize the value and
density functions by two neural networks, respectively. By phrasing the problem
in this manner, solving the MFG can be interpreted as a special case of
training a generative adversarial network (GAN). We show the potential of our
method on up to 100-dimensional MFG problems.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:24:52 GMT""},{""version"":""v2"",""created"":""Fri, 19 Jun 2020 17:23:39 GMT""},{""version"":""v3"",""created"":""Thu, 18 Feb 2021 23:36:31 GMT""}]","2022-06-08"
"2002.10114","M Akbari Moghanjoughi","M. Akbari-Moghanjoughi, Alireza Abdikian and Arash Phirouznia","Ground State Energy of Hydrogen-Like Ions in Quantum Plasmas",,,"10.1063/5.0004857",,"cond-mat.quant-gas physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the asymptotic iteration method (AIM) we investigate the variation in
the 1s energy levels of hydrogen and helium-like static ions in fully
degenerate electron gas. The semiclassical Thomas-Fermi (TF), Shukla-Eliasson
(SE) and corrected Shukla-Eliasson (cSE) models are compared. It is remarked
that these models merge into the vacuum level for hydrogen and helium-like ions
in the dilute classical electron gas regime. While in the TF model hydrogen
ground state level lifts monotonically towards the continuum limit with
increase in the electron concentration, in the SE and cSE models universal
bound stabilization valley through the energy minimization occurs at a
particular electron concentration range for the hydrogen-like ion which for cSE
model closely matches the electron concentrations in typical metals. The later
stabilizing mechanism appears to be due to the interaction between plasmon
excitations and the Fermi lengthscales in metallic density regime. In the case
of helium-like ions, however, no such stability mechanism is found. The
application of cSE model with electron exchange and correlation effects reveals
that cSE model qualitatively accounts for the number-density and lattice
parameters of elemental metals within the framework of free electron
assumption. According to the cSE model of static charge screening a simple
metal-insulator transition criterion is defined. Current investigation may
further elucidate the underlying physical mechanisms in the formation and
dielectric properties of metallic compounds.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:25:29 GMT""}]","2020-04-22"
"2002.10115","Jade Powell","Jade Powell and Bernhard M\""uller","Three-dimensional core-collapse supernova simulations of massive and
  rotating progenitors",,,"10.1093/mnras/staa1048",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present three-dimensional simulations of the core-collapse of massive
rotating and non-rotating progenitors performed with the general relativistic
neutrino hydrodynamics code CoCoNuT-FMT and analyse their explosion properties
and gravitational-wave signals. The progenitor models include Wolf-Rayet stars
with initial helium star masses of $39\,M_{\odot}$ and $20\,M_{\odot}$, and an
$18\,M_{\odot}$ red supergiant. The $39\,M_{\odot}$ model is a rapid rotator,
whereas the two other progenitors are non-rotating. Both Wolf-Rayet models
produce healthy neutrino-driven explosions, whereas the red supergiant model
fails to explode. By the end of the simulations, the explosion energies have
already reached $1.1\times 10^{51}\,\mathrm{erg}$ and $0.6\times
10^{51}\,\mathrm{erg}$ for the $39\,M_{\odot}$ and $20\,M_{\odot}$ model,
respectively. The explosions produce neutron stars of relatively high mass, but
with modest kicks. Due to the alignment of the bipolar explosion geometry with
the rotation axis, there is a relatively small misalignment of $30^\circ$
between the spin and the kick in the $39\,M_{\odot}$ model. In terms of
gravitational-wave signals, the massive and rapidly rotating $39\,M_{\odot}$
progenitor stands out by large gravitational-wave amplitudes that would make it
detectable out to almost 2 Mpc by the Einstein Telescope. For this model, we
find that rotation significantly changes the dependence of the characteristic
gravitational-wave frequency of the f-mode on the proto-neutron star parameters
compared to the non-rotating case. The other two progenitors have considerably
smaller detection distances, despite significant low-frequency emission in the
most sensitive frequency band of current gravitational-wave detectors due to
the standing accretion shock instability in the $18\,M_{\odot}$ model.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:33:39 GMT""}]","2020-05-06"
"2002.10116","\c{S}aziye Bet\""ul \""Ozate\c{s}","\c{S}aziye Bet\""ul \""Ozate\c{s} (1), Arzucan \""Ozg\""ur (1), Tunga
  G\""ung\""or (1), Balk{\i}z \""Ozt\""urk (2) ((1) Department of Computer
  Engineering, Bo\u{g}azi\c{c}i University, (2) Department of Linguistics,
  Bo\u{g}azi\c{c}i University)","A Hybrid Approach to Dependency Parsing: Combining Rules and Morphology
  with Deep Learning","25 pages, 7 figures",,"10.1109/ACCESS.2022.3202947",,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fully data-driven, deep learning-based models are usually designed as
language-independent and have been shown to be successful for many natural
language processing tasks. However, when the studied language is low-resourced
and the amount of training data is insufficient, these models can benefit from
the integration of natural language grammar-based information. We propose two
approaches to dependency parsing especially for languages with restricted
amount of training data. Our first approach combines a state-of-the-art deep
learning-based parser with a rule-based approach and the second one
incorporates morphological information into the parser. In the rule-based
approach, the parsing decisions made by the rules are encoded and concatenated
with the vector representations of the input words as additional information to
the deep network. The morphology-based approach proposes different methods to
include the morphological structure of words into the parser network.
Experiments are conducted on the IMST-UD Treebank and the results suggest that
integration of explicit knowledge about the target language to a neural parser
through a rule-based parsing system and morphological analysis leads to more
accurate annotations and hence, increases the parsing performance in terms of
attachment scores. The proposed methods are developed for Turkish, but can be
adapted to other languages as well.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:34:33 GMT""}]","2022-09-21"
"2002.10117","Ningyuan Yao","Ningyuan Yao","On Dimensions, Standard Part Maps, and $p$-Adically Closed Fields",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to study the dimensions and standard part maps
between the field of $p$-adic numbers ${{\mathbb Q}_p}$ and its elementary
extension $K$ in the language of rings $L_r$. We show that for any
$K$-definable set $X\subseteq K^m$, $\text{dim}_K(X)\geq \text{dim}_{{\mathbb
Q}_p}(X\cap {{\mathbb Q}_p}^m)$. Let $V\subseteq K$ be convex hull of $K$ over
${{\mathbb Q}_p}$, and $\text{\st}: V\rightarrow {{\mathbb Q}_p}$ be the
standard part map. We show that for any $K$-definable function
$f:K^m\rightarrow K$, there is definable subset $D\subseteq{{\mathbb Q}_p}^m$
such that ${{\mathbb Q}_p}^m\backslash D$ has no interior, and for all $x\in
D$, either $f(x)\in V$ and $\text{st}(f(\text{st}^{-1}(x)))$ is constant, or
$f(\text{st}^{-1}(x))\cap V=\emptyset$. We also prove that $\text{dim}_K(X)\geq
\text{dim}_{{\mathbb Q}_p}(\text{st}(X\cap V^m))$ for every definable
$X\subseteq K^m$.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:47:24 GMT""}]","2020-02-25"
"2002.10118","Agustinus Kristiadi","Agustinus Kristiadi, Matthias Hein, Philipp Hennig","Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks","ICML 2020",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The point estimates of ReLU classification networks---arguably the most
widely used neural network architecture---have been shown to yield arbitrarily
high confidence far away from the training data. This architecture, in
conjunction with a maximum a posteriori estimation scheme, is thus not
calibrated nor robust. Approximate Bayesian inference has been empirically
demonstrated to improve predictive uncertainty in neural networks, although the
theoretical analysis of such Bayesian approximations is limited. We
theoretically analyze approximate Gaussian distributions on the weights of ReLU
networks and show that they fix the overconfidence problem. Furthermore, we
show that even a simplistic, thus cheap, Bayesian approximation, also fixes
these issues. This indicates that a sufficient condition for a calibrated
uncertainty on a ReLU network is ""to be a bit Bayesian"". These theoretical
results validate the usage of last-layer Bayesian approximation and motivate a
range of a fidelity-cost trade-off. We further validate these findings
empirically via various standard experiments using common deep ReLU networks
and Laplace approximations.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:52:06 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jul 2020 15:04:19 GMT""}]","2020-07-20"
"2002.10119","Ruben Tolosana","Ruben Tolosana, Ruben Vera-Rodriguez, Julian Fierrez and Javier
  Ortega-Garcia","DeepSign: Deep On-Line Signature Verification",,"IEEE Transactions on Biometrics, Behavior, and Identity Science,
  2021","10.1109/TBIOM.2021.3054533",,"cs.CV cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Deep learning has become a breathtaking technology in the last years,
overcoming traditional handcrafted approaches and even humans for many
different tasks. However, in some tasks, such as the verification of
handwritten signatures, the amount of publicly available data is scarce, what
makes difficult to test the real limits of deep learning. In addition to the
lack of public data, it is not easy to evaluate the improvements of novel
proposed approaches as different databases and experimental protocols are
usually considered.
  The main contributions of this study are: i) we provide an in-depth analysis
of state-of-the-art deep learning approaches for on-line signature
verification, ii) we present and describe the new DeepSignDB on-line
handwritten signature biometric public database, iii) we propose a standard
experimental protocol and benchmark to be used for the research community in
order to perform a fair comparison of novel approaches with the state of the
art, and iv) we adapt and evaluate our recent deep learning approach named
Time-Aligned Recurrent Neural Networks (TA-RNNs) for the task of on-line
handwritten signature verification. This approach combines the potential of
Dynamic Time Warping and Recurrent Neural Networks to train more robust systems
against forgeries. Our proposed TA-RNN system outperforms the state of the art,
achieving results even below 2.0% EER when considering skilled forgery
impostors and just one training signature per user.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:53:11 GMT""},{""version"":""v2"",""created"":""Tue, 8 Sep 2020 08:44:11 GMT""},{""version"":""v3"",""created"":""Fri, 22 Jan 2021 15:53:57 GMT""}]","2021-01-26"
"2002.10120","Xiangtai Li","Xiangtai Li, Ansheng You, Zhen Zhu, Houlong Zhao, Maoke Yang, Kuiyuan
  Yang, Yunhai Tong","Semantic Flow for Fast and Accurate Scene Parsing","accepted by ECCV 2020(oral)",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we focus on designing effective method for fast and accurate
scene parsing. A common practice to improve the performance is to attain high
resolution feature maps with strong semantic representation. Two strategies are
widely used -- atrous convolutions and feature pyramid fusion, are either
computation intensive or ineffective. Inspired by the Optical Flow for motion
alignment between adjacent video frames, we propose a Flow Alignment Module
(FAM) to learn Semantic Flow between feature maps of adjacent levels, and
broadcast high-level features to high resolution features effectively and
efficiently. Furthermore, integrating our module to a common feature pyramid
structure exhibits superior performance over other real-time methods even on
light-weight backbone networks, such as ResNet-18. Extensive experiments are
conducted on several challenging datasets, including Cityscapes, PASCAL
Context, ADE20K and CamVid. Especially, our network is the first to achieve
80.4\% mIoU on Cityscapes with a frame rate of 26 FPS. The code is available at
\url{https://github.com/lxtGH/SFSegNets}.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:53:18 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jul 2020 12:53:21 GMT""},{""version"":""v3"",""created"":""Mon, 29 Mar 2021 08:43:13 GMT""}]","2021-03-30"
"2002.10121","Mohsen Bayati","Mohsen Bayati, Nima Hamidi, Ramesh Johari, Khashayar Khosravi","The Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed
  Bandit with Many Arms",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a Bayesian $k$-armed bandit problem in many-armed regime, when $k
\geq \sqrt{T}$, with $T$ the time horizon. We first show that subsampling is
critical for designing optimal policies. Specifically, the standard UCB
algorithm is sub-optimal while a subsampled UCB (SS-UCB), which samples
$\Theta(\sqrt{T})$ arms and executes UCB on that subset, is rate-optimal.
Despite theoretically optimal regret, SS-UCB numerically performs worse than a
greedy algorithm that pulls the current empirically best arm each time. These
empirical insights hold in a contextual setting as well, using simulations on
real data. These results suggest a new form of free exploration in the
many-armed regime that benefits greedy algorithms. We theoretically show that
this source of free exploration is deeply connected to the distribution of a
tail event for the prior distribution of arm rewards. This is a fundamentally
distinct phenomenon from free exploration due to variation in covariates, as
discussed in the recent literature on contextual bandits. Building on this
result, we prove that the subsampled greedy algorithm is rate-optimal for
Bernoulli bandits in many armed regime, and achieves sublinear regret with more
general distributions. Taken together, our results suggest that practitioners
may benefit from using greedy algorithms in the many-armed regime.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:59:34 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 16:56:39 GMT""},{""version"":""v3"",""created"":""Wed, 23 Mar 2022 00:44:50 GMT""}]","2022-03-24"
"2002.10122","Luciano Abadias","Luciano Abadias, Jos\'e E. Gal\'e, Carlos Lizama","Poisson equation and discrete one-sided Hilbert transform for
  $(C,\alpha)$-bounded operators",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We characterize the solutions of the Poisson equation and the domain of its
associated one-sided Hilbert transform for Ces\`aro bounded operators of
fractional order. The results obtained fairly generalize the corresponding ones
for power-bounded operators. In passing, we give an extension of the mean
ergodic theorem. Examples are given to illustrate the theory.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:02:12 GMT""}]","2020-02-25"
"2002.10123","Ahmet Karak\""u\c{c}\""uk","Ahmet G\""okhan Poyraz, Ahmet Emir Dirik, Ahmet Karak\""u\c{c}\""uk,
  Nasir Memon","Fusion of Camera Model and Source Device Specific Forensic Methods for
  Improved Tamper Detection","13 pages",,,,"eess.IV cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  PRNU based camera recognition method is widely studied in the image forensic
literature. In recent years, CNN based camera model recognition methods have
been developed. These two methods also provide solutions to tamper localization
problem. In this paper, we propose their combination via a Neural Network to
achieve better small-scale tamper detection performance. According to the
results, the fusion method performs better than underlying methods even under
high JPEG compression. For forgeries as small as 100$\times$100 pixel size, the
proposed method outperforms the state-of-the-art, which validates the
usefulness of fusion for localization of small-size image forgeries. We believe
the proposed approach is feasible for any tamper-detection pipeline using the
PRNU based methodology.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:02:12 GMT""},{""version"":""v2"",""created"":""Tue, 5 May 2020 14:41:47 GMT""}]","2020-05-06"
"2002.10124","Gerd Wachsmuth","Felix Harder, Patrick Mehlitz, Gerd Wachsmuth","Reformulation of the M-stationarity conditions as a system of
  discontinuous equations and its solution by a semismooth Newton method",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the Mordukhovich-stationarity system associated with a
mathematical program with complementarity constraints (MPCC) can be
equivalently written as a system of discontinuous equations which can be
tackled with a semismooth Newton method. We show that the resulting algorithm
can be interpreted as an active set strategy for MPCCs. Local fast convergence
of the method is guaranteed under validity of an MPCC-tailored version of LICQ
and a suitable second-order condition. In case of linear-quadratic MPCCs, the
LICQ-type constraint qualification can be replaced by a weaker condition which
depends on the underlying multipliers. We discuss a suitable globalization
strategy for our method. Some numerical results are presented in order to
illustrate our theoretical findings.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:04:23 GMT""},{""version"":""v2"",""created"":""Mon, 2 Nov 2020 09:24:03 GMT""}]","2020-11-03"
"2002.10125","Damiano Francesco Giuseppe Fiorillo","Damiano F. G. Fiorillo, Gennaro Miele, Stefano Morisi, Ninetta Saviano","Cosmogenic neutrino fluxes under the effect of active-sterile secret
  interactions","10 pages, 3 figures","Phys. Rev. D 101, 083024 (2020)","10.1103/PhysRevD.101.083024",,"hep-ph astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultra High Energy cosmogenic neutrinos may represent a unique opportunity to
unveil possible new physics interactions once restricted to the neutrino sector
only. In the present paper we study the observable effects of a secret
active-sterile interactions, mediated by a pseudoscalar, on the expected flux
of cosmogenic neutrinos. The results show that for masses of sterile neutrinos
and pseudoscalars of hundreds MeV, necessary to evade cosmological,
astrophysical and elementary particle constraints, the presence of such new
interactions can significantly change the energy spectrum of cosmogenic
neutrinos at Earth in the energy range from PeV to ZeV. Interestingly, the
distortion of the spectrum results to be detectable at GRAND apparatus if the
scalar mediator mass is around 250 MeV and the UHECRs are dominated by the
proton component. Larger mediator masses or a chemical composition of UHECRs
dominated by heavier nuclei would require much larger cosmic rays apparatus
which might be available in future.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:05:34 GMT""},{""version"":""v2"",""created"":""Tue, 12 May 2020 09:41:20 GMT""}]","2020-05-13"
"2002.10126","Insoon Yang","Subin Huh, Insoon Yang","Safe reinforcement learning for probabilistic reachability and safety
  specifications: A Lyapunov-based approach",,,,,"cs.RO cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Emerging applications in robotics and autonomous systems, such as autonomous
driving and robotic surgery, often involve critical safety constraints that
must be satisfied even when information about system models is limited. In this
regard, we propose a model-free safety specification method that learns the
maximal probability of safe operation by carefully combining probabilistic
reachability analysis and safe reinforcement learning (RL). Our approach
constructs a Lyapunov function with respect to a safe policy to restrain each
policy improvement stage. As a result, it yields a sequence of safe policies
that determine the range of safe operation, called the safe set, which
monotonically expands and gradually converges. We also develop an efficient
safe exploration scheme that accelerates the process of identifying the safety
of unexamined states. Exploiting the Lyapunov shielding, our method regulates
the exploratory policy to avoid dangerous states with high confidence. To
handle high-dimensional systems, we further extend our approach to deep RL by
introducing a Lagrangian relaxation technique to establish a tractable
actor-critic algorithm. The empirical performance of our method is demonstrated
through continuous control benchmark problems, such as a reaching task on a
planar robot arm.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:20:03 GMT""}]","2020-02-25"
"2002.10127","Ahmad Mel","Ahmad Mel, Bo Kang, Jefrey Lijffijt, Tijl De Bie","FONDUE: A Framework for Node Disambiguation Using Network Embeddings","11 pages, 3 figures",,,,"cs.LG cs.CL stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-world data often presents itself in the form of a network. Examples
include social networks, citation networks, biological networks, and knowledge
graphs. In their simplest form, networks represent real-life entities (e.g.
people, papers, proteins, concepts) as nodes, and describe them in terms of
their relations with other entities by means of edges between these nodes. This
can be valuable for a range of purposes from the study of information diffusion
to bibliographic analysis, bioinformatics research, and question-answering.
  The quality of networks is often problematic though, affecting downstream
tasks. This paper focuses on the common problem where a node in the network in
fact corresponds to multiple real-life entities. In particular, we introduce
FONDUE, an algorithm based on network embedding for node disambiguation. Given
a network, FONDUE identifies nodes that correspond to multiple entities, for
subsequent splitting. Extensive experiments on twelve benchmark datasets
demonstrate that FONDUE is substantially and uniformly more accurate for
ambiguous node identification compared to the existing state-of-the-art, at a
comparable computational cost, while less optimal for determining the best way
to split ambiguous nodes.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:34:18 GMT""}]","2020-02-25"
"2002.10128","Sanjoy Kumar Jhawar","Srikanth K. Iyer and Sanjoy Kr. Jhawar","Poisson Approximation and Connectivity in a Scale-free Random Connection
  Model","21 pages, calculations are simplified significantly and results are
  proved under much weaker conditions","Electron. J. Probab. 26(none): 1-23 (2021)","10.1214/21-EJP651",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study an inhomogeneous random connection model in the connectivity regime.
The vertex set of the graph is a homogeneous Poisson point process
$\mathcal{P}_s$ of intensity $s>0$ on the unit cube
$S=\left(-\frac{1}{2},\frac{1}{2}\right]^{d},$ $d \geq 2$ . Each vertex is
endowed with an independent random weight distributed as $W$, where
$P(W>w)=w^{-\beta}1_{[1,\infty)}(w)$, $\beta>0$. Given the vertex set and the
weights an edge exists between $x,y\in \mathcal{P}_s$ with probability $\left(1
- \exp\left( - \frac{\eta W_xW_y}{\left(d(x,y)/r\right)^{\alpha}}
\right)\right),$ independent of everything else, where $\eta, \alpha > 0$,
$d(\cdot, \cdot)$ is the toroidal metric on $S$ and $r > 0$ is a scaling
parameter. We derive conditions on $\alpha, \beta$ such that under the scaling
$r_s(\xi)^d= \frac{1}{c_0 s} \left( \log s +(k-1) \log\log s
+\xi+\log\left(\frac{\alpha\beta}{k!d} \right)\right),$ $\xi \in \mathbb{R}$,
the number of vertices of degree $k$ converges in total variation distance to a
Poisson random variable with mean $e^{-\xi}$ as $s \to \infty$, where $c_0$ is
an explicitly specified constant that depends on $\alpha, \beta, d$ and $\eta$
but not on $k$. In particular, for $k=0$ we obtain the regime in which the
number of isolated nodes stabilizes, a precursor to establishing a threshold
for connectivity. We also derive a sufficient condition for the graph to be
connected with high probability for large $s$. The Poisson approximation result
is derived using the Stein's method.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:38:18 GMT""},{""version"":""v2"",""created"":""Thu, 5 Mar 2020 13:23:45 GMT""},{""version"":""v3"",""created"":""Mon, 30 Mar 2020 11:42:46 GMT""},{""version"":""v4"",""created"":""Mon, 3 Aug 2020 06:22:49 GMT""}]","2021-06-23"
"2002.10129","Javier Falc\'o","Javier Falc\'o and Paul M. Gauthier","Approximation in measure: Dirichlet problem, universality and the
  Riemann hypothesis",,,"10.1070/IM9033",,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Approximation in measure is employed to solve an asymptotic Dirichlet problem
on arbitrary open sets and to show that many functions, including the Riemann
zeta-function, are universal in measure. Connections with the Riemann
Hypothesis are suggested.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:43:59 GMT""}]","2021-08-11"
"2002.10130","Abel Lucido","Abel G. Lucido, Robert J. Smith, Angelyn R. Lao","Periodic culling outperforms isolation and vaccination strategies in
  controlling Influenza A H5N6 outbreaks in the Philippines","27 pages, 14 figures",,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Highly Pathogenic Avian Influenza A H5N6 is a mutated virus of Influenza A
H5N1 and a new emerging infection that recently caused an outbreak in the
Philippines. The 2017 H5N6 outbreak resulted in a depopulation of 667,184
domestic birds. In this study, we incorporate half-saturated incidence in our
mathematical models and investigate three intervention strategies against H5N6:
isolation with treatment, vaccination and modified culling. We determine the
direction of the bifurcation when $\mathcal{R}_0 = 1$ and show that all the
models exhibit forward bifurcation. We administer optimal control and perform
numerical simulations to compare the consequences and implementation cost of
utilizing different intervention strategies in the poultry population. Despite
the challenges of applying each control strategy, we show that culling both
infected and susceptible birds is a better control strategy in prohibiting an
outbreak and avoiding further recurrence of the infection from the population
compared to confinement and vaccination.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:44:01 GMT""}]","2020-02-25"
"2002.10131","Chrysoula Terizi","Chrysoula Terizi, Despoina Chatzakou, Evaggelia Pitoura, Panayiotis
  Tsaparas and Nicolas Kourtellis","Modeling Aggression Propagation on Social Media","13 pages, 5 figures, 3 tables","Online Social Networks and Media 24 (2021): 100137","10.1016/j.osnem.2021.100137",,"cs.SI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cyberaggression has been studied in various contexts and online social
platforms, and modeled on different data using state-of-the-art machine and
deep learning algorithms to enable automatic detection and blocking of this
behavior. Users can be influenced to act aggressively or even bully others
because of elevated toxicity and aggression in their own (online) social
circle. In effect, this behavior can propagate from one user and neighborhood
to another, and therefore, spread in the network. Interestingly, to our
knowledge, no work has modeled the network dynamics of aggressive behavior. In
this paper, we take a first step towards this direction by studying propagation
of aggression on social media using opinion dynamics. We propose ways to model
how aggression may propagate from one user to another, depending on how each
user is connected to other aggressive or regular users. Through extensive
simulations on Twitter data, we study how aggressive behavior could propagate
in the network. We validate our models with crawled and annotated ground truth
data, reaching up to 80% AUC, and discuss the results and implications of our
work.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:50:49 GMT""},{""version"":""v2"",""created"":""Thu, 21 May 2020 21:13:00 GMT""},{""version"":""v3"",""created"":""Fri, 25 Jun 2021 09:13:40 GMT""}]","2021-06-28"
"2002.10132","Karel Prokes","K. Prokes, M. Bartkowiak, D. I. Gorbunov, O. Prokhnenko, O. Rivin, and
  P. Smeibidl","Noncollinear magnetic structure in U2Pd2In at high magnetic fields","6 Figures","Phys. Rev. Research 2, (2020) 013137","10.1103/PhysRevResearch.2.013137",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report an unexpected magnetic-field-driven magnetic structure in the
5f-electron Shastry- Sutherland system U2Pd2In. This phase develops at low
temperatures from a noncollinear antiferromagnetic ground state above the
critical field of 25.8 T applied along the a-axis. All U moments have a net
magnetic moment in the direction of the applied field, described by a
ferromagnetic propagation vector qF = (0 0 0) and an antiferromagnetic
component described by a propagation vector qAF = (0 0.30 1/2 ) due to a
modulation in the direction perpendicular to the applied field. We conclude
that this surprising noncollinear magnetic structure is due to a competition
between the single-ion anisotropy trying to keep moments, similar to the ground
state, along the [110]-type directions, Dzyaloshinskii-Moryia interaction
forcing them to be perpendicular to each other and application of the external
magnetic field attempting to align them along the field direction.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:51:55 GMT""}]","2020-02-25"
"2002.10133","Markus Kantner","Markus Kantner and Thomas Koprucki","Non-isothermal Scharfetter-Gummel scheme for electro-thermal transport
  simulation in degenerate semiconductors",,"Finite Volumes for Complex Applications IX, pp. 173-182 (2020)","10.1007/978-3-030-43651-3_14",,"physics.comp-ph cond-mat.other cs.NA math.NA physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electro-thermal transport phenomena in semiconductors are described by the
non-isothermal drift-diffusion system. The equations take a remarkably simple
form when assuming the Kelvin formula for the thermopower. We present a novel,
non-isothermal generalization of the Scharfetter-Gummel finite volume
discretization for degenerate semiconductors obeying Fermi-Dirac statistics,
which preserves numerous structural properties of the continuous model on the
discrete level. The approach is demonstrated by 2D simulations of a
heterojunction bipolar transistor.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:54:04 GMT""}]","2020-08-21"
"2002.10134","Yihan Chen","Yihan Chen and Bicheng Zhang","P_k and C_k structure and substructure connectivity of hypercubes","15 pages, 9 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hypercube is one of the most important networks to interconnect processors in
multiprocessor computer systems. Different kinds of connectivities are
important parameters to measure the fault tolerability of networks. Lin et
al.\cite{LinStructure} introduced the concept of $H$-structure connectivity
$\kappa(Q_n;H)$ (resp. $H$-substructure connectivity $\kappa^s(Q_n;H)$) as the
minimum cardinality of $F=\{H_1,\dots,H_m\}$ such that $H_i (i=1,\dots,m)$ is
isomorphic to $H$ (resp. $F=\{H'_1,\dots,H'_m\}$ such that $H'_i (i=1,\dots,m)$
is isomorphic to connected subgraphs of $H$) such that $Q_n-V(F)$ is
disconnected or trivial. In this paper, we discuss $\kappa(Q_n;H)$ and
$\kappa^s(Q_n;H)$ for hypercubes $Q_n$ with $n\geq 3$ and $H\in \{P_k,C_k|3\leq
k\leq 2^{n-1}\}$. As a by-product, we solve the problem mentioned in
\cite{ManeStructure}.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:55:26 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 05:04:05 GMT""}]","2020-06-17"
"2002.10135","Alexander McNeil","Alexander J. McNeil","Modelling volatile time series with v-transforms and copulas",,,,,"q-fin.RM stat.ME","http://creativecommons.org/licenses/by-nc-sa/4.0/","  An approach to the modelling of volatile time series using a class of
uniformity-preserving transforms for uniform random variables is proposed.
V-transforms describe the relationship between quantiles of the stationary
distribution of the time series and quantiles of the distribution of a
predictable volatility proxy variable. They can be represented as copulas and
permit the formulation and estimation of models that combine arbitrary marginal
distributions with copula processes for the dynamics of the volatility proxy.
The idea is illustrated using a Gaussian ARMA copula process and the resulting
model is shown to replicate many of the stylized facts of financial return
series and to facilitate the calculation of marginal and conditional
characteristics of the model including quantile measures of risk. Estimation is
carried out by adapting the exact maximum likelihood approach to the estimation
of ARMA processes and the model is shown to be competitive with standard GARCH
in an empirical application to Bitcoin return data.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:00:38 GMT""},{""version"":""v2"",""created"":""Fri, 27 Mar 2020 16:51:52 GMT""},{""version"":""v3"",""created"":""Fri, 30 Oct 2020 14:28:00 GMT""},{""version"":""v4"",""created"":""Tue, 24 Nov 2020 17:08:22 GMT""},{""version"":""v5"",""created"":""Tue, 12 Jan 2021 18:10:08 GMT""}]","2021-01-13"
"2002.10136","Yao Zhang","Bo Lei, Yao Zhang and Yixin Yang","GLRT-based Detection in Bistatic Sonar under Strong Direct Blast with
  Multipath Propagation",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Direct blast is a strong interference in bistatic sonar and difficult to
suppress due to multipath propagation for blasts and signals. A generalized
likelihood ratio test (GLRT) based detection scheme in the frequency domain of
the received signals is proposed in this study, and the unknown parameters are
estimated using Maximum Likelihood Estimates and Weighted Fourier Transform and
Relaxation in a multipath environment. The distributions of the test statistic
of detectors for known and unknown noise power are given in theory, and the
detection probability is determined. The performance of the detector decreases
by 4 dB when the noise power is evaluated with maximum likelihood estimates.
Simulations show the effectiveness of the detector under a forward scattering
detection configuration with a low signal-to-direct blast ratio. The
sensitivity of many factors is discussed, and robustness is achieved.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:01:13 GMT""}]","2020-02-25"
"2002.10137","Ran Yi","Ran Yi, Zipeng Ye, Juyong Zhang, Hujun Bao, Yong-Jin Liu","Audio-driven Talking Face Video Generation with Learning-based
  Personalized Head Pose","12 pages, 9 figures",,,,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-world talking faces often accompany with natural head movement. However,
most existing talking face video generation methods only consider facial
animation with fixed head pose. In this paper, we address this problem by
proposing a deep neural network model that takes an audio signal A of a source
person and a very short video V of a target person as input, and outputs a
synthesized high-quality talking face video with personalized head pose (making
use of the visual information in V), expression and lip synchronization (by
considering both A and V). The most challenging issue in our work is that
natural poses often cause in-plane and out-of-plane head rotations, which makes
synthesized talking face video far from realistic. To address this challenge,
we reconstruct 3D face animation and re-render it into synthesized frames. To
fine tune these frames into realistic ones with smooth background transition,
we propose a novel memory-augmented GAN module. By first training a general
mapping based on a publicly available dataset and fine-tuning the mapping using
the input short video of target person, we develop an effective strategy that
only requires a small number of frames (about 300 frames) to learn personalized
talking behavior including head pose. Extensive experiments and two user
studies show that our method can generate high-quality (i.e., personalized head
movements, expressions and good lip synchronization) talking face videos, which
are naturally looking with more distinguishing head movement effects than the
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:02:10 GMT""},{""version"":""v2"",""created"":""Thu, 5 Mar 2020 10:06:22 GMT""}]","2020-03-06"
"2002.10138","Michael Golosovsky","Michael Golosovsky","Universality of citation distributions and its explanation","23 pages, 9 figures",,,,"physics.soc-ph cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Universality or near-universality of citation distributions was found
empirically a decade ago but its theoretical justification has been lacking so
far. Here, we systematically study citation distributions for different
disciplines in order to characterize this putative universality and to
understand it theoretically. Using our calibrated model of citation dynamics,
we find microscopic explanation of the universality of citation distributions
and explain deviations therefrom. We demonstrate that citation count of the
paper is determined, on the one hand, by its fitness -- the attribute which,
for most papers, is set at the moment of publication. The fitness distributions
for different disciplines are very similar and can be approximated by the
log-normal distribution. On another hand, citation dynamics of a paper is
related to the mechanism by which the knowledge about it spreads in the
scientific community. This viral propagation is non-universal and
discipline-specific. Thus, universality of citation distributions traces its
origin to the fitness distribution, while deviations from universality are
associated with the discipline-specific citation dynamics of papers.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:02:49 GMT""}]","2020-02-25"
"2002.10139","Abolfazl Tarizadeh","Abolfazl Tarizadeh","Some results on pure ideals and trace ideals of projective modules","9 pages",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $R$ be a commutative ring with the unit element. It is shown that an
ideal $I$ in $R$ is pure if and only if Ann$(f)+I=R$ for all $f\in I$. If $J$
is the trace of a projective $R$-module $M$, we prove that $J$ is generated by
the ``coordinates"" of $M$ and $JM = M$. These lead to a few new results and
alternative proofs for some known results.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:04:05 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 13:29:20 GMT""}]","2021-07-14"
"2002.10140","Alexander Schmeding","Rafael Dahmen, W. Steven Gray, Alexander Schmeding","Continuity of Chen-Fliess Series for Applications in System
  Identification and Machine Learning","17 pages, 1 figure, 24th International Symposium on Mathematical
  Theory of Networks and Systems, (MTNS 2020)",,"10.1016/j.ifacol.2021.06.080",,"math.OC math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model continuity plays an important role in applications like system
identification, adaptive control, and machine learning. This paper provides
sufficient conditions under which input-output systems represented by locally
convergent Chen-Fliess series are jointly continuous with respect to their
generating series and as operators mapping a ball in an $L_p$-space to a ball
in an $L_q$-space, where $p$ and $q$ are conjugate exponents. The starting
point is to introduce a class of topological vector spaces known as Silva
spaces to frame the problem and then to employ the concept of a direct limit to
describe convergence. The proof of the main continuity result combines elements
of proofs for other forms of continuity appearing in the literature to produce
the desired conclusion.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:08:21 GMT""}]","2021-09-08"
"2002.10141","Asuka Takatsu","Kazuhiro Ishige, Paolo Salani, Asuka Takatsu","Power concavity for elliptic and parabolic boundary value problems on
  rotationally symmetric domains","24 pages. Comments are welcome!",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study power concavity of rotationally symmetric solutions to elliptic and
parabolic boundary value problems on rotationally symmetric domains in
Riemannian manifolds. As applications of our results to the hyperbolic space
${\bf H}^N$ we have:
  $\bullet$ The first Dirichlet eigenfunction on a ball in ${\bf H}^N$ is
strictly positive power concave;
  $\bullet$ Let $\Gamma$ be the heat kernel on ${\bf H}^N$. Then
$\Gamma(\cdot,y,t)$ is strictly log-concave on ${\bf H}^N$ for $y\in {\bf H}^N$
and $t>0$.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:13:47 GMT""}]","2020-02-25"
"2002.10142","Stefan Neumann","Monika Henzinger, Stefan Neumann, Andreas Wiese","Explicit and Implicit Dynamic Coloring of Graphs with Bounded Arboricity",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph coloring is a fundamental problem in computer science. We study the
fully dynamic version of the problem in which the graph is undergoing edge
insertions and deletions and we wish to maintain a vertex-coloring with small
update time after each insertion and deletion.
  We show how to maintain an $O(\alpha \lg n)$-coloring with polylogarithmic
update time, where $n$ is the number of vertices in the graph and $\alpha$ is
the current arboricity of the graph. This improves upon a result by Solomon and
Wein (ESA'18) who maintained an $O(\alpha_{\max}\lg^2 n)$-coloring, where
$\alpha_{\max}$ is the maximum arboricity of the graph over all updates.
  Furthermore, motivated by a lower bound by Barba et al. (Algorithmica'19), we
initiate the study of implicit dynamic colorings. Barba et al. showed that
dynamic algorithms with polylogarithmic update time cannot maintain an
$f(\alpha)$-coloring for any function $f$ when the vertex colors are stored
explicitly, i.e., for each vertex the color is stored explicitly in the memory.
Previously, all dynamic algorithms maintained explicit colorings. Therefore, we
propose to study implicit colorings, i.e., the data structure only needs to
offer an efficient query procedure to return the color of a vertex (instead of
storing its color explicitly). We provide an algorithm which breaks the lower
bound and maintains an implicit $2^{O(\alpha)}$-coloring with polylogarithmic
update time. In particular, this yields the first dynamic $O(1)$-coloring for
graphs with constant arboricity such as planar graphs or graphs with bounded
tree-width, which is impossible using explicit colorings.
  We also show how to dynamically maintain a partition of the graph's edges
into $O(\alpha)$ forests with polylogarithmic update time. We believe this data
structure is of independent interest and might have more applications in the
future.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:18:44 GMT""}]","2020-02-25"
"2002.10143","Florian Zaruba","Florian Zaruba, Fabian Schuiki, Torsten Hoefler, and Luca Benini","Snitch: A tiny Pseudo Dual-Issue Processor for Area and Energy Efficient
  Execution of Floating-Point Intensive Workloads",,,"10.1109/TC.2020.3027900",,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data-parallel applications, such as data analytics, machine learning, and
scientific computing, are placing an ever-growing demand on floating-point
operations per second on emerging systems. With increasing integration density,
the quest for energy efficiency becomes the number one design concern. While
dedicated accelerators provide high energy efficiency, they are
over-specialized and hard to adjust to algorithmic changes. We propose an
architectural concept that tackles the issues of achieving extreme energy
efficiency while still maintaining high flexibility as a general-purpose
compute engine. The key idea is to pair a tiny 10kGE control core, called
Snitch, with a double-precision FPU to adjust the compute to control ratio.
While traditionally minimizing non-FPU area and achieving high floating-point
utilization has been a trade-off, with Snitch, we achieve them both, by
enhancing the ISA with two minimally intrusive extensions: stream semantic
registers (SSR) and a floating-point repetition instruction (FREP). SSRs allow
the core to implicitly encode load/store instructions as register reads/writes,
eliding many explicit memory instructions. The FREP extension decouples the
floating-point and integer pipeline by sequencing instructions from a
micro-loop buffer. These ISA extensions significantly reduce the pressure on
the core and free it up for other tasks, making Snitch and FPU effectively
dual-issue at a minimal incremental cost of 3.2%. The two low overhead ISA
extensions make Snitch more flexible than a contemporary vector processor lane,
achieving a $2\times$ energy-efficiency improvement. We have evaluated the
proposed core and ISA extensions on an octa-core cluster in 22nm technology. We
achieve more than $5\times$ multi-core speed-up and a $3.5\times$ gain in
energy efficiency on several parallel microkernels.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:19:23 GMT""},{""version"":""v2"",""created"":""Thu, 8 Oct 2020 12:31:43 GMT""}]","2020-10-09"
"2002.10144","Vincent D\'emery","Antoine Lagarde, No\'emie Dag\`es, Takahiro Nemoto, Vincent D\'emery,
  Denis Bartolo, Thomas Gibaud","Colloidal transport in bacteria suspensions: from bacteria scattering to
  anomalous and enhanced diffusion",,"Soft Matter, 2020, 16, 7503","10.1039/D0SM00309C",,"cond-mat.soft cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Colloids coupled to a bath of swimming cells generically display enhanced
diffusion. This transport dynamics stems from a subtle interplay between the
active and passive particles that still resists our understanding despite
decades of intense research. Here, we tackle the root of the problem by
providing a quantitative characterisation of the single scattering events
between a colloid and a bacterium. Based on our experiments, we build a minimal
model that quantitatively predicts the geometry of the scattering trajectories,
and enhanced colloidal diffusion at long times. This quantitative confrontation
between theory and experiments elucidates the microscopic origin of enhanced
transport. Collisions are solely ruled by stochastic contact interactions
responsible both for genuine anomalous diffusion at short times and enhanced
diffusion at long times with no ballistic regime at any scale.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:24:12 GMT""}]","2021-03-25"
"2002.10145","Armin Wei{\ss}","Armin Wei{\ss}","Hardness of equations over finite solvable groups under the exponential
  time hypothesis",,,"10.4230/LIPIcs.ICALP.2020.102",,"cs.CC math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Goldmann and Russell (2002) initiated the study of the complexity of the
equation satisfiability problem in finite groups by showing that it is in P for
nilpotent groups while it is NP-complete for non-solvable groups. Since then,
several results have appeared showing that the problem can be solved in
polynomial time in certain solvable groups of Fitting length two. In this work,
we present the first lower bounds for the equation satisfiability problem in
finite solvable groups: under the assumption of the exponential time
hypothesis, we show that it cannot be in P for any group of Fitting length at
least four and for certain groups of Fitting length three. Moreover, the same
hardness result applies to the equation identity problem.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:26:34 GMT""},{""version"":""v2"",""created"":""Mon, 26 Oct 2020 15:45:23 GMT""}]","2020-10-27"
"2002.10146","Rajat Kanti Nath","Walaa Nabil Taha Fasfous and Rajat Kanti Nath","Spectrum and energy of non-commuting graphs of finite groups","22 pages",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be a finite non-abelian group and ${\Gamma}_{nc}(G)$ be its
non-commuting graph. In this paper, we compute spectrum and energy of
${\Gamma}_{nc}(G)$ for certain classes of finite groups. As a consequence of
our results we construct infinite families of integral complete $r$-partite
graphs. We compare energy and Laplacian energy (denoted by
$E({\Gamma}_{nc}(G))$ and $LE({\Gamma}_{nc}(G))$ respectively) of
${\Gamma}_{nc}(G)$ and conclude that $E({\Gamma}_{nc}(G)) \leq
LE({\Gamma}_{nc}(G))$ for those groups except for some non-abelian groups of
order $pq$. This shows that the conjecture posed in [Gutman, I., Abreu, N. M.
M., Vinagre, C. T.M., Bonifacioa, A. S and Radenkovic, S. Relation between
energy and Laplacian energy, MATCH Commun. Math. Comput. Chem., 59: 343--354,
(2008)] does not hold for non-commuting graphs of certain finite groups, which
also produces new families of counter examples to the above mentioned
conjecture.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:27:04 GMT""}]","2020-02-25"
"2002.10147","Abhijit Gadde","Abhijit Gadde, Trakshu Sharma","Constraining Conformal Theories in Large Dimensions","26 pages, 9 figures",,,"TIFR/TH/20-6","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we analyze the constraints imposed by unitarity and crossing
symmetry on conformal theories in large dimensions. In particular, we show that
in a unitary conformal theory in large dimension $D$, the four-point function
of identical scalar operators $\phi$ with scaling dimension $\Delta_\phi$ such
that $\Delta_\phi/D<3/4$, is necessarily that of the generalized free field
theory. This result follows only from crossing symmetry and unitarity. In
particular, we do not impose the existence of a conserved spin two operator
(stress tensor). We also present an argument to extend the applicability of
this result to a larger range of conformal dimensions, namely to
$\Delta_\phi/D<1$. This extension requires some reasonable assumptions about
the spectrum of light operators. Together, these results suggest that if there
is a non-trivial conformal theory in large dimensions, not necessarily having a
stress tensor, then its relevant operators must be exponentially weakly coupled
with the rest.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:27:40 GMT""}]","2020-02-25"
"2002.10148","Markus Sch\""oberl","Markus Sch\""oberl, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis","Embedded-physics machine learning for coarse-graining and collective
  variable discovery without data",,,,,"cs.LG physics.chem-ph physics.comp-ph stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel learning framework that consistently embeds underlying
physics while bypassing a significant drawback of most modern, data-driven
coarse-grained approaches in the context of molecular dynamics (MD), i.e., the
availability of big data. The generation of a sufficiently large training
dataset poses a computationally demanding task, while complete coverage of the
atomistic configuration space is not guaranteed. As a result, the explorative
capabilities of data-driven coarse-grained models are limited and may yield
biased ""predictive"" tools. We propose a novel objective based on reverse
Kullback-Leibler divergence that fully incorporates the available physics in
the form of the atomistic force field. Rather than separating model learning
from the data-generation procedure - the latter relies on simulating atomistic
motions governed by force fields - we query the atomistic force field at sample
configurations proposed by the predictive coarse-grained model. Thus, learning
relies on the evaluation of the force field but does not require any MD
simulation. The resulting generative coarse-grained model serves as an
efficient surrogate model for predicting atomistic configurations and
estimating relevant observables. Beyond obtaining a predictive coarse-grained
model, we demonstrate that in the discovered lower-dimensional representation,
the collective variables (CVs) are related to physicochemical properties, which
are essential for gaining understanding of unexplored complex systems. We
demonstrate the algorithmic advances in terms of predictive ability and the
physical meaning of the revealed CVs for a bimodal potential energy function
and the alanine dipeptide.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:28:41 GMT""}]","2020-02-25"
"2002.10149","Emmanuelle-Anna Dietz Saldanha","Emmanuelle-Anna Dietz Saldanha, Antonis Kakas","Cognitive Argumentation and the Suppression Task",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the challenge of modeling human reasoning, within a new
framework called Cognitive Argumentation. This framework rests on the
assumption that human logical reasoning is inherently a process of dialectic
argumentation and aims to develop a cognitive model for human reasoning that is
computational and implementable. To give logical reasoning a human cognitive
form the framework relies on cognitive principles, based on empirical and
theoretical work in Cognitive Science, to suitably adapt a general and abstract
framework of computational argumentation from AI. The approach of Cognitive
Argumentation is evaluated with respect to Byrne's suppression task, where the
aim is not only to capture the suppression effect between different groups of
people but also to account for the variation of reasoning within each group.
Two main cognitive principles are particularly important to capture human
conditional reasoning that explain the participants' responses: (i) the
interpretation of a condition within a conditional as sufficient and/or
necessary and (ii) the mode of reasoning either as predictive or explanatory.
We argue that Cognitive Argumentation provides a coherent and cognitively
adequate model for human conditional reasoning that allows a natural
distinction between definite and plausible conclusions, exhibiting the
important characteristics of context-sensitive and defeasible reasoning.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:30:39 GMT""}]","2020-02-25"
"2002.10150","Dan Burghelea","Dan Burghelea","Witten deformation and the spectral package of a Riemannian manifold","18 pages; few misprints in the previous version corrected",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Witten deformation associated to a Morse function on a closed Riemannian
manifold, via Rellich-Kato theorem, relates analytically the spectral package
of the Riemannian manifold (eigenvalues and eigenforms) to the Morse complex
defined by the pair (Morse function, Riemannian metric) coupled with the
""multivariable harmonic oscillators"" associated to the critical points of the
Morse function. We survey this relation and discuss some implications,
including the finite subset of the spectral package referred to as the
""virtually small spectral package"" .
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:30:45 GMT""},{""version"":""v2"",""created"":""Tue, 10 Mar 2020 10:24:44 GMT""}]","2020-03-11"
"2002.10151","Hanna Furmanczyk","Janusz Dybizba\'nski, Hanna Furma\'nczyk, Vahan Mkrtchyan","Vizing-Goldberg type bounds for the equitable chromatic number of block
  graphs","21 pages, 12 figures",,,,"cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An equitable coloring of a graph $G$ is a proper vertex coloring of $G$ such
that the sizes of any two color classes differ by at most one. In the paper, we
pose a conjecture that offers a gap-one bound for the smallest number of colors
needed to equitably color every block graph. In other words, the difference
between the upper and the lower bounds of our conjecture is at most one. Thus,
in some sense, the situation is similar to that of chromatic index, where we
have the classical theorem of Vizing and the Goldberg conjecture for
multigraphs. The results obtained in the paper support our conjecture. More
precisely, we verify it in the class of well-covered block graphs, which are
block graphs in which each vertex belongs to a maximum independent set. We also
show that the conjecture is true for block graphs, which contain a vertex that
does not lie in an independent set of size larger than two. Finally, we verify
the conjecture for some symmetric-like block graphs. In order to derive our
results we obtain structural characterizations of block graphs from these
classes.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:33:53 GMT""},{""version"":""v2"",""created"":""Wed, 29 Apr 2020 15:24:50 GMT""}]","2020-04-30"
"2002.10152","Matthew Gadd","Will Maddern, Geoffrey Pascoe, Matthew Gadd, Dan Barnes, Brian
  Yeomans, Paul Newman","Real-time Kinematic Ground Truth for the Oxford RobotCar Dataset","Dataset website: https://robotcar-dataset.robots.ox.ac.uk/",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the release of reference data towards a challenging long-term
localisation and mapping benchmark based on the large-scale Oxford RobotCar
Dataset. The release includes 72 traversals of a route through Oxford, UK,
gathered in all illumination, weather and traffic conditions, and is
representative of the conditions an autonomous vehicle would be expected to
operate reliably in. Using post-processed raw GPS, IMU, and static GNSS base
station recordings, we have produced a globally-consistent centimetre-accurate
ground truth for the entire year-long duration of the dataset. Coupled with a
planned online benchmarking service, we hope to enable quantitative evaluation
and comparison of different localisation and mapping approaches focusing on
long-term autonomy for road vehicles in urban environments challenged by
changing weather.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:34:31 GMT""}]","2020-02-25"
"2002.10153","Yun Hui Lin","Yun Hui Lin and Dongdong He and Yuan Wang and Loo Hay Lee","Last-mile Delivery: Optimal Locker Location Under Multinomial Logit
  Choice Model",,,,,"math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  One innovative solution to the last-mile delivery problem is the self-service
locker system. Motivated by a real case in Singapore, we consider a POP-Locker
Alliance who operates a set of POP-stations and wishes to improve the last-mile
delivery by opening new locker facilities. We propose a quantitative approach
to determine the optimal locker location with the objective to maximize the
overall service provided by the alliance. Customer's choices regarding the use
of facilities are explicitly considered. They are predicted by a multinomial
logit model. We then formulate the location problem as a multi-ratio
linear-fractional 0-1 program and provide two solution approaches. The first
one is to reformulate the original problem as a mixed-integer linear program,
which is further strengthened using conditional McCormick inequalities. This
approach is an exact method, developed for small-scale problems. For
large-scale problems, we propose a Suggest-and-Improve framework with two
embedded algorithms. Numerical studies indicated that our framework is an
efficient approach that yields high-quality solutions. Finally, we conducted a
case study. The results highlighted the importance of considering the
customers' choices. Under different parameter values of the multinomial logit
model, the decisions could be completely different. Therefore, the parameter
value should be carefully estimated in advance.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:36:01 GMT""}]","2020-02-25"
"2002.10154","Jean-Eric Campagne","Jean-Eric Campagne","Adversarial training applied to Convolutional Neural Network for
  photometric redshift predictions","12 pages, 6 figures",,,,"astro-ph.IM eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of Convolutional Neural Networks (CNN) to estimate the galaxy
photometric redshift probability distribution by analysing the images in
different wavelength bands has been developed in the recent years thanks to the
rapid development of the Machine Learning (ML) ecosystem. Authors have set-up
CNN architectures and studied their performances and some sources of
systematics using standard methods of training and testing to ensure the
generalisation power of their models. So far so good, but one piece was missing
: does the model generalisation power is well measured? The present article
shows clearly that very small image perturbations can fool the model completely
and opens the Pandora's box of \textit{adversarial} attack. Among the different
techniques and scenarios, we have chosen to use the Fast Sign Gradient one-step
Method and its Projected Gradient Descent iterative extension as adversarial
generator tool kit. However, as unlikely as it may seem these adversarial
samples which fool not only a single model, reveal a weakness both of the model
and the classical training. A revisited algorithm is shown and applied by
injecting a fraction of adversarial samples during the training phase.
Numerical experiments have been conducted using a specific CNN model for
illustration although our study could be applied to other models - not only CNN
ones - and in other contexts - not only redshift measurements - as it deals
with the complexity of the boundary decision surface.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:44:26 GMT""}]","2020-02-25"
"2002.10155","John Barrow","John D. Barrow","Non-Euclidean Newtonian Cosmology","11 pages, no figures","Classical and Quantum Gravity 37, 125007 (2020)","10.1088/1361-6382/ab8437",,"gr-qc astro-ph.CO physics.hist-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We formulate and solve the problem of Newtonian cosmology under the
assumption that the absolute space of Newton is non-Euclidean. In particular,
we focus on the negatively-curved hyperbolic space, H3. We point out the
inequivalence between the curvature term that arises in the Friedmann equation
in Newtonian cosmology in Euclidean space and the role of curvature in the H3
space. We find the generalisation of the inverse-square law and the solutions
of the Newtonian cosmology that follow from it. We find the generalisations of
the Euclidean Michell 'black hole' in H3 and show that it leads to different
maximum force and area results to those we have found in general relativity. We
show how to add the counterpart of the cosmological constant to the
gravitational potential in H3 and explore the solutions and asymptotes of the
cosmological models that result. We also discuss the problems of introducing
compact topologies in Newtonian cosmologies with non-negative spatial
curvature.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:47:23 GMT""}]","2020-06-17"
"2002.10156","Vladimir P. Mineev","V.P. Mineev","Upper critical field in ferromagnetic metals with triplet pairing","The paper targeted for the AoP special issue in honour of
  G.M.Eliashberg 90 jubilee (9pages,1figure)",,"10.1016/j.aop.2020.168139",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The theory of triplet superconductivity in ferromagnetic metals based on
electron-electron interaction by spin fluctuation exchange is developed. The
equations for the upper critical field temperature dependence are derived. In
contrast to the similar equations for the superconductivity in two band metals
they contain the pairing amplitudes and the Fermi velocities depending on
magnetic field. The critical field behaviour near the critical temperature and
at T = 0 is established analytically.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:49:34 GMT""},{""version"":""v2"",""created"":""Wed, 26 Feb 2020 15:17:13 GMT""},{""version"":""v3"",""created"":""Fri, 20 Mar 2020 10:52:52 GMT""}]","2020-06-24"
"2002.10157","Victor Marx","Victor Marx (JAD)","Infinite-dimensional regularization of McKean-Vlasov equation with a
  Wasserstein diffusion",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Much effort has been spent in recent years on restoring uniqueness of
McKean-Vlasov SDEs with non-smooth coefficients. As a typical instance, the
velocity field is assumed to be bounded and measurable in its space variable
and Lipschitz-continuous with respect to the distance in total variation in its
measure variable, see [Jourdain, Mishura-Veretennikov]. In contrast with those
works, we consider in this paper a Fokker-Planck equation driven by an
infinite-dimensional noise, inspired by the diffusion models on the Wasserstein
space studied in [Konarovskyi, Marx]. We prove that well-posedness of that
equation holds for a drift function that might be only bounded and measurable
in its measure argument, provided that a trade-off is respected between the
regularity in the finite-dimensional component and the regularity in the
measure argument. In this regard, we show that the higher the regularity of b
with respect to its space variable is, the lower regularity we have to assume
on b with respect to its measure variable in order to restore uniqueness.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:50:35 GMT""}]","2020-02-25"
"2002.10158","Zhi Yan Dr.","Zhi Yan and Simon Schreiberhuber and Georg Halmetschlager and Tom
  Duckett and Markus Vincze and Nicola Bellotto","Robot Perception of Static and Dynamic Objects with an Autonomous Floor
  Scrubber","15 pages, 16 figures, submitted to Intelligent Service Robotics",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents the perception system of a new professional cleaning
robot for large public places. The proposed system is based on multiple sensors
including 3D and 2D lidar, two RGB-D cameras and a stereo camera. The two
lidars together with an RGB-D camera are used for dynamic object (human)
detection and tracking, while the second RGB-D and stereo camera are used for
detection of static objects (dirt and ground objects). A learning and reasoning
module for spatial-temporal representation of the environment based on the
perception pipeline is also introduced. Furthermore, a new dataset collected
with the robot in several public places, including a supermarket, a warehouse
and an airport, is released. Baseline results on this dataset for further
research and comparison are provided. The proposed system has been fully
implemented into the Robot Operating System (ROS) with high modularity, also
publicly available to the community.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:53:01 GMT""}]","2020-02-25"
"2002.10159","David Hague","David A. Hague","Adaptive Transmit Waveform Design using Multi-Tone Sinusoidal Frequency
  Modulation","Revised version of manuscript 23JUL2020. Paper has been accepted for
  publication, will share journal and paper info when paper is published","IEEE Transactions on Aerospace and Electronic Systems, vol. 57,
  no. 2, pp. 1274-1287, April 2021","10.1109/TAES.2020.3046086",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an adaptive waveform design method using Multi-Tone
Sinusoidal Frequency Modulation (MTSFM). The MTSFM waveform's modulation
function is represented as a finite Fourier series expansion. The Fourier
coefficients are utilized as a discrete set of design parameters that may be
modified to adapt the waveform's properties. The MTSFM's design parameters are
adjusted to shape the spectrum, Auto-Correlation Function (ACF), and Ambiguity
Function (AF) shapes of the waveform. The MTSFM waveform model naturally
possesses the constant envelope and spectrally compact waveforms that make it
well suited for transmission on practical radar/sonar transmitters which
utilize high power amplifiers. The MTSFM has an exact mathematical definition
for its time-series using Generalized Bessel Functions which allow for deriving
closed-form analytical expressions for its spectrum, AF, and ACF. These
expressions allow for establishing well-defined optimization problems that
finely tune the MTSFM's properties. This adaptive waveform design model is
demonstrated by optimizing MTSFM waveforms that initially possess a
""thumbtack-like"" AF shape. The resulting optimized designs possess
substantially improved sidelobe levels over specified regions in the
range-Doppler plane without increasing the Time-Bandwidth Product (TBP) that
the initialized waveforms possessed. Simulations additionally demonstrate that
the optimized thumbtack-like MTSFM waveforms are competitive with
thumbtack-like phase-coded waveforms derived from design algorithms available
in the published literature.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:53:17 GMT""},{""version"":""v2"",""created"":""Mon, 23 Mar 2020 12:01:53 GMT""},{""version"":""v3"",""created"":""Fri, 21 Aug 2020 19:12:29 GMT""}]","2021-05-04"
"2002.10160","Michael Golosovsky","Michael Golosovsky","Uncited papers are not unread","11 pages, 3 figures",,,,"physics.soc-ph cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study citation dynamics of the Physics, Economics, and Mathematics papers
published in 1984 and focus on the fraction of uncited papers in these three
collections. Our model of citation dynamics, which considers citation process
as an inhomogeneous Poisson process, captures this uncitedness ratio fairly
well. It should be noted that all parameters and variables in our model are
related to citations and their dynamics, while uncited papers appear as a
byproduct of the citation process and this is the Poisson statistics which
makes the cited and uncited papers inseparable. This indicates that the most
part of uncited papers constitute the inherent part of the scientific
enterprise, namely, uncited papers are not unread.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:54:04 GMT""}]","2020-02-25"
"2002.10161","Saroj Chhatoi","Saroj Prasad Chhatoi and S. Kalyana Rama","Non singular, bouncing M theory universe","Latex file. 19 pages, 7 figures",,,,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a set of equations as a simple model for non singular evolutions
of a $10 + 1$ dimensional M theory universe. Our model uses ideas from Loop
Quantum Cosmology and offers a solution to the important problem of singularity
resolutions. We solve the equations numerically and find that an M theory
universe in this model evolves non singularly and with a bounce : going back in
time, its density reaches a maximum and decreases thereafter whereas its
physical size reaches a non vanishing minimum and increases thereafter. Taking
the constituents of the universe to be the most entropic ones (which are four
sets of intersecting M branes) leads to an effectively $3 + 1$ dimensional
spacetime as the M theory universe expands, both in the infinite past and
future.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:54:40 GMT""}]","2020-02-25"
"2002.10162","Charalambos Charalambides","Charalambos A. Charalambides","Multivariate q-Polya and inverse q-Polya distributions","22 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An urn containing specified numbers of balls of distinct ordered colors is
considered. A multiple q-Polya urn model is introduced by assuming that the
probability of q-drawing a ball of a specific color from the urn varies
geometrically, with rate q, both with the number of drawings and the number of
balls of the specific color, together with the total number of balls of the
preceded colors, drawn in the previous q-drawings. Then, the joint
distributions of the numbers of balls of distinct colors drawn (a) in a
specific number of q-drawings and (b) until the occurrence of a specific number
of balls of a certain color, are derived. These two distributions turned out to
be q-analogues of the multivariate Polya and inverse Polya distributions,
respectively. Also, the limiting distributions of the multivariate q-Polya and
inverse q-Polya distributions, as the initial total number of balls in the urn
tends to infinity, are shown to be q-multinomial and negative q-multinomial
distributions, respectively.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:57:43 GMT""}]","2020-02-25"
"2002.10163","Isabel Del \'Aguila","Isabel M. del \'Aguila, Jos\'e del Sagrado and Joaqu\'in Ca\~nadas","Software Engineering Timeline: major areas of interest and
  multidisciplinary trends","Technical report University of Almer\'ia",,,"http://hdl.handle.net/10835/7274","cs.SE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Society today cannot run without software and by extension, without Software
Engineering. Since this discipline emerged in 1968, practitioners have learned
valuable lessons that have contributed to current practices. Some have become
outdated but many are still relevant and widely used. From the personal and
incomplete perspective of the authors, this paper not only reviews the major
milestones and areas of interest in the Software Engineering timeline helping
software engineers to appreciate the state of things, but also tries to give
some insights into the trends that this complex engineering will see in the
near future.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:57:45 GMT""}]","2020-02-25"
"2002.10164","Arnaud Gloter","Arnaud Gloter (LaMME), Nakahiro Yoshida","Adaptive and non-adaptive estimation for degenerate diffusion processes",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss parametric estimation of a degenerate diffusion system from
time-discrete observations. The first component of the degenerate diffusion
system has a parameter $\theta_1$ in a non-degenerate diffusion coefficient and
a parameter $\theta_2$ in the drift term. The second component has a drift term
parameterized by $\theta_3$ and no diffusion term. Asymptotic normality is
proved in three different situations for an adaptive estimator for $\theta_3$
with some initial estimators for ($\theta_1$ , $\theta_2$), an adaptive
one-step estimator for ($\theta_1$ , $\theta_2$ , $\theta_3$) with some initial
estimators for them, and a joint quasi-maximum likelihood estimator for
($\theta_1$ , $\theta_2$ , $\theta_3$) without any initial estimator. Our
estimators incorporate information of the increments of both components. Thanks
to this construction, the asymptotic variance of the estimators for $\theta_1$
is smaller than the standard one based only on the first component. The
convergence of the estimators for $\theta_3$ is much faster than the other
parameters. The resulting asymptotic variance is smaller than that of an
estimator only using the increments of the second component.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:58:34 GMT""}]","2020-02-25"
"2002.10165","Anatoliy Petravchuk Petrovich","Ie.Yu.Chapovskyi, L.Z.Mashchenko, A.P.Petravchuk","Nilpotent Lie algebras of derivations with the center of small corank",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathbb K$ be a field of characteristic zero, $A$ an integral domain
over $\mathbb K$ with the field of fractions $R = \text{Frac}(A),$ and
$\text{Der}_{\mathbb{K}}A$ the Lie algebra of all $\mathbb K$-derivations on
$A$.
  Let $W(A):=R\text{Der}_{\mathbb{K}} A$ and $L$ a nilpotent subalgebra of rank
$n$ over $R$ of the Lie algebra $W(A).$ We prove that if the center $Z=Z(L)$ is
of rank $\geq n-2$ over $R$ and $F=F(L)$ is the field of constants for $L$ in
$R,$ then the Lie algebra $FL$ is contained in a locally nilpotent subalgebra
of $ W(A)$ of rank $n$ over $R$ with a natural basis over the field $R.$ It is
also also proved that the Lie algebra $FL$ can be isomorphically embedded (as
an abstract Lie algebra) into the triangular Lie algebra $u_n(F)$ which was
studied early by other authors.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:02:08 GMT""}]","2020-02-25"
"2002.10166","Mohammed Bachir","M Bachir, G. Flores (DIM)","Index of symmetry and topological classification of asymmetric normed
  spaces",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let X, Y be asymmetric normed spaces and Lc(X, Y) the convex cone of all
linear continuous operators from X to Y. It is known that in general, Lc(X, Y)
is not a vector space. The aim of this note is to prove, using the Baire
category theorem, that if Lc(X, Y) is a vector space for some asymmetric normed
space Y , then X is isomorphic to its associated normed space (the converse is
true for every asymmetric normed space Y and is easy to establish). For this,
we introduce an index of symmetry of the space X denoted c(X) $\in$ [0, 1] and
we give the link between the index c(X) and the fact that Lc(X, Y) is in turn
an asymmetric normed space for every asymmetric normed space Y. Our study leads
to a topological classification of asymmetric normed spaces.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:05:11 GMT""},{""version"":""v2"",""created"":""Wed, 10 Jun 2020 15:47:24 GMT""}]","2020-06-11"
"2002.10167","Tarik Kazaz","Tarik Kazaz, Mario Coutino, Gerard J. M. Janssen and Alle-Jan van der
  Veen","Joint blind calibration and time-delay estimation for multiband ranging","4 pages, 45th International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP 2020)",,,,"eess.SP cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we focus on the problem of blind joint calibration of
multiband transceivers and time-delay (TD) estimation of multipath channels. We
show that this problem can be formulated as a particular case of covariance
matching. Although this problem is severely ill-posed, prior information about
radio-frequency chain distortions and multipath channel sparsity is used for
regularization. This approach leads to a biconvex optimization problem, which
is formulated as a rank-constrained linear system and solved by a simple group
Lasso algorithm.Numerical experiments show that the proposed algorithm provides
better calibration and higher resolution for TD estimation than current
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:10:50 GMT""},{""version"":""v2"",""created"":""Tue, 24 Mar 2020 12:11:16 GMT""}]","2020-03-25"
"2002.10168","Dominic Blosser","Dominic Blosser, Leonardo Facheris, Andrey Zheludev","Miniature capacitive Faraday force magnetometer for magnetization
  measurements at low temperatures and high magnetic fields",,"Review of Scientific Instruments 91, 073905 (2020)","10.1063/5.0005850",,"cond-mat.mtrl-sci cond-mat.str-el physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Faraday force magnetometer is presented for measurements of magnetization
at temperatures down to 100~mK and in magnetic fields up to 14~T. The specimen
is mounted on a flexible cantilever forming a force-sensing capacitor in
combination with a fixed back plate. Two different cantilever designs are
presented. A torsion resistant cantilever allows to measure magnetization of
highly anisotropic single crystal samples. Measurements of the metal organic
quantum magnets (C$_5$H$_{12}$N)$_2$CuBr$_4$ (BPCB) and NiCl$_2$$\cdot$4
SC(NH$_2$)$_2$ (DTN) demonstrate the device's capabilities. Routinely, a
specimen's magnetic moment is measured with a resolution better than $10^{-7}$
A$\,$m$^2$ ($10^{-4}$ emu). The device in miniaturized to fit is almost any
cryostat.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:11:53 GMT""}]","2020-07-22"
"2002.10169","Simon Spannagel","Simon Spannagel","Silicon Vertex & Tracking Detectors for the Compact Linear Collider","VERTEX2019 proceedings, 10 pages, 6 figures",,"10.22323/1.373.0044","CLICdp-Conf-2019-013","physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  CLIC is a proposed linear $e^+e^-$ collider with center-of-mass energies of
up to 3 TeV. Its main objectives are precise top quark, Higgs boson and Beyond
Standard Model physics. In addition to spatial resolutions of a few micrometers
and a very low material budget, the vertex and tracking detectors also require
timing capabilities with a precision of a few nanoseconds to allow suppression
of beam-induced background particles. Different technologies using hybrid
silicon detectors are explored for the vertex detectors, such as dedicated 65
nm readout ASICs, small-pitch sensors as well as bonding using anisotropic
conductive films. Monolithic sensors are the current choice for the tracking
detector, and a prototype using a 180 nm high-resistivity CMOS process has been
designed and produced, and is currently under evaluation. Different designs
using a silicon-on-insulator process are under investigation for both vertex
and tracking detector. All prototypes are tested in laboratory and beam tests,
and newly developed simulation tools combining Geant4 and TCAD are used to
assess and optimize their performance. This contribution gives an overview of
the R&D program for the CLIC vertex and tracking detectors, highlighting new
results from the prototypes.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:15:49 GMT""}]","2021-03-10"
"2002.10170","Detlev Koester","D. Koester, S.O. Kepler, A.W. Irwin","New white dwarf envelope models and diffusion. Application to DQ white
  dwarfs","accepted by Astronomy & Astrophysics",,"10.1051/0004-6361/202037530",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies of the atmospheres of carbon-rich (DQ) white dwarfs have
demonstrated the existence of two different populations that are distinguished
by the temperature range, but more importantly, by the extremely high masses of
the hotter group. The classical DQ below 10000 K are well understood as the
result of dredge-up of carbon by the expanding helium convection zone. The
high-mass group poses several problems regarding their origin and also an
unexpected correlation of effective temperature with mass. We propose to study
the envelopes of these objects to determine the total hydrogen and helium
masses as possible clues to their evolution. We developed new codes for
envelope integration and diffusive equilibrium that are adapted to the unusual
chemical composition, which is not necessarily dominated by hydrogen and
helium. Using the new results for the atmospheric parameters, in particular,
the masses obtained using Gaia parallaxes, we confirm that the narrow sequence
of carbon abundances with Teff in the cool classical DQ is indeed caused by an
almost constant helium to total mass fraction, as found in earlier studies.
This mass fraction is smaller than predicted by stellar evolution calculations.
For the warm DQ above 10000 K, which are thought to originate from double white
dwarf mergers, we obtain extremely low hydrogen and helium masses. The
correlation of mass with Teff remains unexplained, but another possible
correlation of helium layer masses with Teff as well as the gravitational
redshifts casts doubt on the reality of both and suggests possible shortcomings
of current models.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:25:36 GMT""}]","2020-03-25"
"2002.10171","Haris Aziz","Haris Aziz","A Probabilistic Approach to Voting, Allocation, Matching, and Coalition
  Formation","Preprint for book chapter in ""The Future of Economic Design: The
  Continuing Development of a Field as Envisioned by Its Researchers""",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Randomisation and time-sharing are some of the oldest methods to achieve
fairness. I make a case that applying these approaches to social choice
settings constitutes a powerful paradigm that deserves an extensive and
thorough examination. I discuss challenges and opportunities in applying these
approaches to settings including voting, allocation, matching, and coalition
formation.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:27:19 GMT""}]","2020-02-25"
"2002.10172","Iain Johnston","Iain G. Johnston","Optimal strategies in the Fighting Fantasy gaming system: influencing
  stochastic dynamics by gambling with limited resource","Keyword: stochastic game; Markov decision problem; stochastic
  simulation; dynamic programming; resource allocation; stochastic optimal
  control; Bellman equation",,,,"cs.AI cs.MA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fighting Fantasy is a popular recreational fantasy gaming system worldwide.
Combat in this system progresses through a stochastic game involving a series
of rounds, each of which may be won or lost. Each round, a limited resource
(`luck') may be spent on a gamble to amplify the benefit from a win or mitigate
the deficit from a loss. However, the success of this gamble depends on the
amount of remaining resource, and if the gamble is unsuccessful, benefits are
reduced and deficits increased. Players thus dynamically choose to expend
resource to attempt to influence the stochastic dynamics of the game, with
diminishing probability of positive return. The identification of the optimal
strategy for victory is a Markov decision problem that has not yet been solved.
Here, we combine stochastic analysis and simulation with dynamic programming to
characterise the dynamical behaviour of the system in the absence and presence
of gambling policy. We derive a simple expression for the victory probability
without luck-based strategy. We use a backward induction approach to solve the
Bellman equation for the system and identify the optimal strategy for any given
state during the game. The optimal control strategies can dramatically enhance
success probabilities, but take detailed forms; we use stochastic simulation to
approximate these optimal strategies with simple heuristics that can be
practically employed. Our findings provide a roadmap to improving success in
the games that millions of people play worldwide, and inform a class of
resource allocation problems with diminishing returns in stochastic games.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:31:25 GMT""}]","2020-02-25"
"2002.10173","Dario Bercioux","D. Perconte, K. Seurre, V. Humbert, C. Ulysse, A. Sander, J. Trastoy,
  V. Zatko, F. Godel, P. R. Kidambi, S. Hofmann, X. P. Zhang, D. Bercioux, F.
  S. Bergeret, B. Dlubak, P. Seneor and Javier E. Villegas","Long-Range Propagation and Interference of $d$-wave Superconducting
  Pairs in Graphene","4 pages with 4 figure","Phys. Rev. Lett. 125, 087002 (2020)","10.1103/PhysRevLett.125.087002",,"cond-mat.supr-con cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experiments have shown that proximity with high-temperature
superconductors induces unconventional superconducting correlations in
graphene. Here we demonstrate that those correlations propagate hundreds of
nanometer, allowing for the unique observation of $d$-wave Andreev pair
interferences in YBa$_2$Cu$_3$O$_7$-graphene devices that behave as a
Fabry-P\'erot cavity. The interferences show as a series of pronounced
conductance oscillations analogous to those originally predicted by de
Gennes--Saint-James for conventional metal-superconductor junctions. The
present work is pivotal to the study of exotic directional effects expected for
nodal superconductivity in Dirac materials.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:34:00 GMT""},{""version"":""v2"",""created"":""Tue, 8 Sep 2020 09:18:11 GMT""}]","2020-09-09"
"2002.10174","Runmin Wu","Runmin Wu, Kunyao Zhang, Lijun Wang, Yue Wang, Pingping Zhang, Huchuan
  Lu, Yizhou Yu","When Relation Networks meet GANs: Relation GANs with Triplet Loss","13 pages",,,,"cs.CV cs.LG eess.IV","http://creativecommons.org/publicdomain/zero/1.0/","  Though recent research has achieved remarkable progress in generating
realistic images with generative adversarial networks (GANs), the lack of
training stability is still a lingering concern of most GANs, especially on
high-resolution inputs and complex datasets. Since the randomly generated
distribution can hardly overlap with the real distribution, training GANs often
suffers from the gradient vanishing problem. A number of approaches have been
proposed to address this issue by constraining the discriminator's capabilities
using empirical techniques, like weight clipping, gradient penalty, spectral
normalization etc. In this paper, we provide a more principled approach as an
alternative solution to this issue. Instead of training the discriminator to
distinguish real and fake input samples, we investigate the relationship
between paired samples by training the discriminator to separate paired samples
from the same distribution and those from different distributions. To this end,
we explore a relation network architecture for the discriminator and design a
triplet loss which performs better generalization and stability. Extensive
experiments on benchmark datasets show that the proposed relation discriminator
and new loss can provide significant improvement on variable vision tasks
including unconditional and conditional image generation and image translation.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:35:28 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 07:35:13 GMT""},{""version"":""v3"",""created"":""Tue, 17 Mar 2020 03:28:57 GMT""}]","2020-03-18"
"2002.10175","Panagiotis Batakidis","Panagiotis Batakidis, Fani Petalidou","Dorfman connections of Courant algebroids and the Atiyah class of Manin
  pairs","New extended version, comments are welcome",,,,"math.DG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The aim of this work is to introduce the Atiyah class of Manin pairs. For
this we construct an algebra of polydifferential operators on tensor products
of a Courant algebroid $E$ with values in the endomorphism bundle of a smooth
vector bundle $B$, predual of $E$, extending the construction and standard
complex of the Courant-Dorfman algebra of $E$. It is shown that the Cartan
calculus, curvatures of induced connections and basic differential geometric
identities of a Dorfman connection of $E$ on $B$ make sense in this algebra.
Starting from a flat Dorfman connection of a Dirac subbundle $L\subset E$ on
$B$, we define compatible extensions to a Dorfman connection of $E$ on $B$ and
construct an Atiyah class measuring the obstruction to compatibility. The
Atiyah classes of foliations, Lie bialgebras and complex manifolds are shown to
be contained in this construction.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:35:47 GMT""},{""version"":""v2"",""created"":""Mon, 13 Sep 2021 14:50:05 GMT""},{""version"":""v3"",""created"":""Tue, 20 Dec 2022 14:54:56 GMT""}]","2022-12-21"
"2002.10176","Tadej Rojac Dr.","J. Schulthei{\ss}, S. Checchia, H. Ur\v{s}i\v{c}, T. Fr\""omling, J. E.
  Daniels, B. Mali\v{c}, T. Rojac, and J. Koruza","Domain wall-grain boundary interactions in polycrystalline
  Pb(Zr0.7Ti0.3)O3 piezoceramics","27 pages, 7 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interactions between grain boundaries and domain walls were extensively
studied in ferroelectric films and bicrystals. This knowledge, however, has not
been transferred to polycrystalline ceramics, in which the grain size
represents a powerful tool to tailor the dielectric and electromechanical
response. Here, we relate changes in dielectric and electromechanical
properties of a bulk polycrystalline Pb(Zr0.7Ti0.3)O3 to domain wall
interactions with grain boundaries. Samples with grain sizes in the range of
3.9 - 10.4 micrometers were prepared and their microstructure, crystal
structure, and dielectric/electromechanical properties were investigated. A
decreasing grain size was accompanied by a reduction in large-signal
electromechanical properties and an increase in small-signal dielectric
permittivity. High-energy diffraction analysis revealed increasing microstrains
upon decreasing the grain size, while piezoresponse force microscopy indicated
an increased local coercive voltage near grain boundaries. The changes in
properties were thus related to strained material volume close to the grain
boundaries exhibiting reduced domain wall dynamics.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:43:59 GMT""}]","2020-02-25"
"2002.10177","Ioan Marius Bilasco PhD","Pierre Falez and Pierre Tirilly and Ioan Marius Bilasco","Improving STDP-based Visual Feature Learning with Whitening",,,"10.1109/IJCNN48605.2020.9207373",,"cs.CV cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, spiking neural networks (SNNs) emerge as an alternative to
deep neural networks (DNNs). SNNs present a higher computational efficiency
using low-power neuromorphic hardware and require less labeled data for
training using local and unsupervised learning rules such as spike
timing-dependent plasticity (STDP). SNN have proven their effectiveness in
image classification on simple datasets such as MNIST. However, to process
natural images, a pre-processing step is required. Difference-of-Gaussians
(DoG) filtering is typically used together with on-center/off-center coding,
but it results in a loss of information that is detrimental to the
classification performance. In this paper, we propose to use whitening as a
pre-processing step before learning features with STDP. Experiments on CIFAR-10
show that whitening allows STDP to learn visual features that are closer to the
ones learned with standard neural networks, with a significantly increased
classification performance as compared to DoG filtering. We also propose an
approximation of whitening as convolution kernels that is computationally
cheaper to learn and more suited to be implemented on neuromorphic hardware.
Experiments on CIFAR-10 show that it performs similarly to regular whitening.
Cross-dataset experiments on CIFAR-10 and STL-10 also show that it is fairly
stable across datasets, making it possible to learn a single whitening
transformation to process different datasets.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:48:22 GMT""}]","2020-12-22"
"2002.10178","Sara Kristin Schmidt","Sara Kristin Schmidt, Max Wornowizki, Roland Fried and Herold Dehling","An Asymptotic Test for Constancy of the Variance under Short-Range
  Dependence",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel approach to test for heteroscedasticity of a
non-stationary time series that is based on Gini's mean difference of
logarithmic local sample variances. In order to analyse the large sample
behaviour of our test statistic, we establish new limit theorems for
U-statistics of dependent triangular arrays. We derive the asymptotic
distribution of the test statistic under the null hypothesis of a constant
variance and show that the test is consistent against a large class of
alternatives, including multiple structural breaks in the variance. Our test is
applicable even in the case of non-stationary processes, assuming a locally
stationary mean function. The performance of the test and its comparatively low
computation time are illustrated in an extensive simulation study. As an
application, we analyse Google Trends data, monitoring the relative search
interest for the topic ""global warming.""
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:48:24 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 16:23:17 GMT""}]","2021-05-24"
"2002.10179","Mingbao Lin","Mingbao Lin, Rongrong Ji, Yan Wang, Yichen Zhang, Baochang Zhang,
  Yonghong Tian, Ling Shao","HRank: Filter Pruning using High-Rank Feature Map",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural network pruning offers a promising prospect to facilitate deploying
deep neural networks on resource-limited devices. However, existing methods are
still challenged by the training inefficiency and labor cost in pruning
designs, due to missing theoretical guidance of non-salient network components.
In this paper, we propose a novel filter pruning method by exploring the High
Rank of feature maps (HRank). Our HRank is inspired by the discovery that the
average rank of multiple feature maps generated by a single filter is always
the same, regardless of the number of image batches CNNs receive. Based on
HRank, we develop a method that is mathematically formulated to prune filters
with low-rank feature maps. The principle behind our pruning is that low-rank
feature maps contain less information, and thus pruned results can be easily
reproduced. Besides, we experimentally show that weights with high-rank feature
maps contain more important information, such that even when a portion is not
updated, very little damage would be done to the model performance. Without
introducing any additional constraints, HRank leads to significant improvements
over the state-of-the-arts in terms of FLOPs and parameters reduction, with
similar accuracies. For example, with ResNet-110, we achieve a 58.2%-FLOPs
reduction by removing 59.2% of the parameters, with only a small loss of 0.14%
in top-1 accuracy on CIFAR-10. With Res-50, we achieve a 43.8%-FLOPs reduction
by removing 36.7% of the parameters, with only a loss of 1.17% in the top-1
accuracy on ImageNet. The codes can be available at
https://github.com/lmbxmu/HRank.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:50:09 GMT""},{""version"":""v2"",""created"":""Mon, 16 Mar 2020 23:50:13 GMT""}]","2020-03-18"
"2002.10180","Magdalena Birowska","Magdalena Birowska, Joanna Urban, Micha{\l} Baranowski, Duncan K
  Maude, Paulina Plochocka and Nevill Gonzalez Szwacki","The impact of hexagonal boron nitride encapsulation on the structural
  and vibrational properties of few layer black phosphorus","8 pages, 5 figures, 1 table","Nanotechnology 30 (2019) 195201","10.1088/1361-6528/ab0332",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The encapsulation of two-dimensional layered materials such as black
phosphorus is of paramount importance for their stability in air. However, the
encapsulation poses several questions, namely, how it affects, via the weak van
der Waals forces, the properties of the black phosphorus and whether these
properties can be tuned on demand. Prompted by these questions, we have
investigated the impact of hexagonal boron nitride encapsulation on the
structural and vibrational properties of few layer black phosphorus, using a
first-principles method in the framework of density functional theory. We
demonstrate that the encapsulation with hexagonal boron nitride imposes biaxial
strain on the black phosphorus material, flattening its puckered structure, by
decreasing the thickness of the layers via the increase of the puckered angle
and the intra-layer P-P bonds. This work exemplifies the evolution of
structural parameters in layered materials after the encapsulation process. We
find that after encapsulation, phosphorene (single layer black phosphorous)
contracts by 1.1% in the armchair direction and stretches by 1.3% in the zigzag
direction, whereas few layer black phosphorus mainly expands by up to 3% in the
armchair direction. However, these relatively small strains induced by the
hexagonal BN, lead to significant changes in the vibrational properties of
black phosphorus, with the redshifts of up to 10 cm$^{-1}$ of the high
frequency optical mode $A_g^1$. In general, structural changes induced by the
encapsulation process open the door to substrate controlled strain engineering
in two-dimensional crystals.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:54:33 GMT""}]","2020-02-25"
"2002.10181","Gong Cheng","Shuxin Li, Gong Cheng, Chengkai Li","Relaxing Relationship Queries on Graph Data","16 pages, accepted to JoWS",,,,"cs.IR cs.DB","http://creativecommons.org/licenses/by/4.0/","  In many domains we have witnessed the need to search a large entity-relation
graph for direct and indirect relationships between a set of entities specified
in a query. A search result, called a semantic association (SA), is typically a
compact (e.g., diameter-constrained) connected subgraph containing all the
query entities. For this problem of SA search, efficient algorithms exist but
will return empty results if some query entities are distant in the graph. To
reduce the occurrence of failing query and provide alternative results, we
study the problem of query relaxation in the context of SA search. Simply
relaxing the compactness constraint will sacrifice the compactness of an SA,
and more importantly, may lead to performance issues and be impracticable.
Instead, we focus on removing the smallest number of entities from the original
failing query, to form a maximum successful sub-query which minimizes the loss
of result quality caused by relaxation. We prove that verifying the success of
a sub-query turns into finding an entity (called a certificate) that satisfies
a distance-based condition about the query entities. To efficiently find a
certificate of the success of a maximum sub-query, we propose a best-first
search algorithm that leverages distance-based estimation to effectively prune
the search space. We further improve its performance by adding two fine-grained
heuristics: one based on degree and the other based on distance. Extensive
experiments over popular RDF datasets demonstrate the efficiency of our
algorithm, which is more scalable than baselines.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:55:24 GMT""}]","2020-02-25"
"2002.10182","Tanmoy Bar","Tanmoy Bar, Chinmay Basu, Mithun Das, Apurba Kumar Santra, Swarnendu
  Sen","Simulation of heat transfer and dissipation in targets used in nuclear
  astrophysics experiments",,,"10.1016/j.nimb.2019.04.064",,"physics.ins-det nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents time-dependent numerical calculations of heat generation
and dissipation in targets used in high ion-beam current nuclear astrophysics
experiments. The simulation is beneficial for choosing the thickness of
targets, maximum ion-beam current and design setup for cooling of such targets.
It is found that for the very thin target ($^{27}Al(p,p),^{12}C(p,p)$) heat
generation inside target is relatively low and a fair amount of high current
(few $\mu$A)can be used without any melting issue. But in case of thick targets
($^{27}Al(p,\gamma),^{12}C(p,\gamma)$) cooling became essential for the
survival of reaction target.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:56:16 GMT""}]","2020-02-25"
"2002.10183","Wojciech Krzemien","Wojciech Krzemien and Aleksander Gajos and Krzysztof Kacprzak and
  Kamil Rakoczy and Grzegorz Korcyl","J-PET Framework: Software platform for PET tomography data
  reconstruction and analysis","14 pages, 5 figures","SoftwareX 11 (2020) 100487","10.1016/j.softx.2020.100487",,"physics.ins-det cs.SE physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  J-PET Framework is an open-source software platform for data analysis,
written in C++ and based on the ROOT package. It provides a common environment
for implementation of reconstruction, calibration and filtering procedures, as
well as for user-level analyses of Positron Emission Tomography data. The
library contains a set of building blocks that can be combined by users with
even little programming experience, into chains of processing tasks through a
convenient, simple and well-documented API. The generic input-output interface
allows processing the data from various sources: low-level data from the
tomography acquisition system or from diagnostic setups such as digital
oscilloscopes, as well as high-level tomography structures e.g. sinograms or a
list of lines-of-response. Moreover, the environment can be interfaced with
Monte Carlo simulation packages such as GEANT and GATE, which are commonly used
in the medical scientific community.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:57:42 GMT""},{""version"":""v2"",""created"":""Wed, 27 May 2020 12:40:14 GMT""}]","2020-05-28"
"2002.10184","Clara Velte","Preben Buchhave and Clara Marika Velte","Understanding developing turbulence by a study of the nonlinear energy
  transfer in the Navier-Stokes equation",,,"10.1088/1402-4896/aca9a1",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present work, we investigate a numerical one-dimensional solver to the
Navier-Stokes equation that retains all terms, including both pressure and
dissipation. Solutions to simple examples that illustrate the actions of the
nonlinear term are presented and discussed. The calculations take the full 4D
flow as its starting point and continuously projects the forces acting on the
fluid at a fixed Eulerian point in a stationary coordinate system onto the
direction of the instantaneous velocity. Pressure is included through modeling.
Adhering to the requirement that time must in general be considered an
independent variable, the time development of the time records and power
spectra of the velocity fluctuations are studied. It is found that the actions
of the nonlinear term in the Navier-Stokes equation manifests itself by
generating sharp pulses in the time traces, where the sharpness is bounded by
the finite viscosity. In the spectral domain, the sharp gradients in the pulses
generate energy contributions at high frequencies that yields a $-2$ slope
across the inertial range. The $-2$ (or $-6/3$) slope is explained through a
simple example and the classically expected $-5/3$ slope in the inertial range
can be recovered from the pressure fluctuations from the full flow field that
can be considered a noise contribution at the point considered. We also observe
that the spectrum can in principle keep spreading to higher frequencies or
wavenumbers without upper bound, as the viscosity is approaching the zero
limit.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 11:59:41 GMT""},{""version"":""v2"",""created"":""Sun, 22 Mar 2020 10:38:48 GMT""},{""version"":""v3"",""created"":""Mon, 30 Mar 2020 11:44:12 GMT""},{""version"":""v4"",""created"":""Mon, 8 Feb 2021 14:39:09 GMT""},{""version"":""v5"",""created"":""Mon, 20 Jun 2022 10:19:32 GMT""}]","2023-03-30"
"2002.10185","Lasse Peters","Lasse Peters, Zachary N. Sunberg","iLQGames.jl: Rapidly Designing and Solving Differential Games in Julia",,,,,"cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many problems that involve multiple decision making agents, optimal
choices for each agent depend on the choices of others. Differential game
theory provides a principled formalism for expressing these coupled
interactions and recent work offers efficient approximations to solve these
problems to non-cooperative equilibria. iLQGames.jl is a framework for
designing and solving differential games, built around the iterative
linear-quadratic method. It is written in the Julia programming language to
allow flexible prototyping and integration with other research software, while
leveraging the high-performance nature of the language to allow real-time
execution. The open-source software package can be found at
https://github.com/lassepe/iLQGames.jl.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:01:05 GMT""},{""version"":""v2"",""created"":""Mon, 6 Apr 2020 13:59:49 GMT""}]","2020-04-07"
"2002.10186","Panayiotis Tsokanas","Theodoros Loutas, Panayiotis Tsokanas, Vassilis Kostopoulos, Peter
  Nijhuis, Wouter M. van den Brink","Mode I fracture toughness of asymmetric metal-composite adhesive joints","10 pages, 6 figures, conference proceedings",,"10.1016/j.matpr.2020.03.075",,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In this work, the mode I fracture toughness of dissimilar metal-composite
adhesive joints is experimentally investigated using the double cantilever beam
(DCB) test. The particular joint under study is resulted by the adhesive
joining of a thin titanium sheet with a thin carbon fiber reinforced plastic
(CFRP) laminate and is envisioned to be implemented in the hybrid laminar flow
control system of future aircraft. Four different industrial technologies for
the joining of the titanium and CFRP adherents are evaluated/compared;
co-bonding with and without adhesive and secondary bonding using either
thermoset or thermoplastic CFRP. The vacuum-assisted resin transfer molding
(VARTM) technique is employed for the manufacturing of the panels. After
manufacturing, the panels are cut into test specimens that, because they are
too thin (approximately 2.4 mm thick), needed to be stiffened from both
titanium and composite sides with two aluminum backing beams to ensure the
non-yielding of the titanium during the subsequent DCB tests. Towards the
determination of the fracture toughness of the joint from the experimental
data, an analytical model recently developed by the authors, that considers the
bending-extension coupling of both sub-laminates constituting the test specimen
as well as the manufacturing-induced residual thermal stresses, is applied. For
the four manufacturing options (MO) investigated, the load-displacement
behaviors, failure patterns, and fracture toughness performances are presented
and compared.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:01:10 GMT""},{""version"":""v2"",""created"":""Thu, 7 May 2020 21:07:47 GMT""}]","2020-05-11"
"2002.10187","Zetong Yang","Zetong Yang, Yanan Sun, Shu Liu, Jiaya Jia","3DSSD: Point-based 3D Single Stage Object Detector",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Currently, there have been many kinds of voxel-based 3D single stage
detectors, while point-based single stage methods are still underexplored. In
this paper, we first present a lightweight and effective point-based 3D single
stage object detector, named 3DSSD, achieving a good balance between accuracy
and efficiency. In this paradigm, all upsampling layers and refinement stage,
which are indispensable in all existing point-based methods, are abandoned to
reduce the large computation cost. We novelly propose a fusion sampling
strategy in downsampling process to make detection on less representative
points feasible. A delicate box prediction network including a candidate
generation layer, an anchor-free regression head with a 3D center-ness
assignment strategy is designed to meet with our demand of accuracy and speed.
Our paradigm is an elegant single stage anchor-free framework, showing great
superiority to other existing methods. We evaluate 3DSSD on widely used KITTI
dataset and more challenging nuScenes dataset. Our method outperforms all
state-of-the-art voxel-based single stage methods by a large margin, and has
comparable performance to two stage point-based methods as well, with inference
speed more than 25 FPS, 2x faster than former state-of-the-art point-based
methods.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:01:58 GMT""}]","2020-02-25"
"2002.10188","Aleksi Vuorinen","Jacopo Ghiglieri, Aleksi Kurkela, Michael Strickland, and Aleksi
  Vuorinen","Perturbative Thermal QCD: Formalism and Applications","137 pages, 44 figures. v4: Version published in Physics Reports; two
  typographical errors corrected from v3","Phys. Rept. 880 (2020) 1-73","10.1016/j.physrep.2020.07.004","CERN-TH-2020-029, HIP-2020-6/TH","hep-ph hep-th nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this review article, we discuss the current status and future prospects of
perturbation theory as a means of studying the equilibrium thermodynamic and
near-equilibrium transport properties of deconfined QCD matter. We begin with a
brief introduction to the general topic, after which we review in some detail
the foundations and modern techniques of the real- and imaginary-time
formalisms of thermal field theory, covering e.g. the different bases used in
the real-time formalism and the resummations required to deal with soft and
collinear contributions. After this, we discuss the current status of
applications of these techniques, including topics such as electromagnetic
rates, transport coefficients, jet quenching, heavy quarks and quarkonia, and
the Equations of State of hot quark-gluon plasma as well as cold and dense
quark matter. Finally, we conclude with our view of the future directions of
the field, i.e. how we anticipate perturbative calculations to contribute to
our collective understanding of strongly interacting matter in the coming
years.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:08:02 GMT""},{""version"":""v2"",""created"":""Sat, 29 Feb 2020 11:51:18 GMT""},{""version"":""v3"",""created"":""Mon, 13 Jul 2020 13:58:44 GMT""},{""version"":""v4"",""created"":""Tue, 13 Oct 2020 14:09:03 GMT""}]","2020-10-14"
"2002.10189","Hao Wei","Da-Chun Qiang, Hao Wei","Reconstructing the Fraction of Baryons in the Intergalactic Medium with
  Fast Radio Bursts via Gaussian Processes","14 pages, 6 figures, revtex4; v2: discussions added, JCAP in press;
  v3: published version","JCAP 2004 (2020) 023","10.1088/1475-7516/2020/04/023",,"astro-ph.CO astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fast radio bursts (FRBs) are a promising new probe for astronomy and
cosmology. Thanks to their extragalactic and cosmological origin, FRBs could be
used to study the intergalactic medium (IGM) and the cosmic expansion. It is
expected that numerous FRBs with identified redshifts will be available in the
near future through the identification of their host galaxies or counterparts.
$\rm DM_{IGM}$, the contribution from IGM to the observed dispersion measure
(DM) of FRB, carries the key information about IGM and the cosmic expansion
history. We can thus study the evolution of the universe by using FRBs with
identified redshifts. In the present work, we are interested in the fraction of
baryon mass in the IGM, $f_{\rm IGM}$, which is useful to study the cosmic
expansion and the problem of the ""missing baryons"". We propose to reconstruct
the evolution of $f_{\rm IGM}$ as a function of redshift $z$ with FRBs via a
completely model-independent method, namely Gaussian processes. Since there is
not a large sample of FRBs with identified redshifts, we use simulated FRBs
instead. Through various simulations, we show that this methodology works well.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:11:00 GMT""},{""version"":""v2"",""created"":""Tue, 24 Mar 2020 16:00:00 GMT""},{""version"":""v3"",""created"":""Mon, 20 Apr 2020 16:41:00 GMT""}]","2020-04-21"
"2002.10190","Sona Davtyan","S. Davtyan, Y. Chen, M. H. Frosz, P. ST.J. Russell and D. Novoa","Robust excitation and Raman conversion of guided vortices in chiral
  gas-filled photonic crystal fiber",,,"10.1364/OL.383760",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unique ring-shaped intensity patterns and helical phase fronts of optical
vortices make them useful in many applications. Here we report for the first
time efficient Raman frequency conversion between vortex modes in twisted
hydrogen-filled single-ring hollow core photonic crystal fiber (SR-PCF). High
fidelity transmission of optical vortices in untwisted SR-PCF becomes more and
more difficult as the orbital angular momentum (OAM) order increases, due to
scattering at structural imperfections in the fiber microstructure. In
helically twisted SR-PCF, however, the degeneracy between left- and
right-handed versions of the same mode is lifted, with the result that they are
topologically protected from such scattering. With launch efficiencies of ~75%,
a high damage threshold and broadband guidance, these fibers are ideal for
performing nonlinear experiments that require the polarization state and
azimuthal order of the interacting modes to be preserved over long distances.
Vortex coherence waves (VCW) of internal molecular motion, carrying angular
momentum, are excited in the gas, permitting the polarization and orbital
angular momentum of the Raman bands to be tailored, even in spectral regions
where conventional solid-core waveguides are opaque or susceptible to optical
damage.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:13:56 GMT""}]","2020-04-22"
"2002.10191","Peiqin Zhuang","Peiqin Zhuang, Yali Wang, Yu Qiao","Learning Attentive Pairwise Interaction for Fine-Grained Classification","Accepted at AAAI-2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fine-grained classification is a challenging problem, due to subtle
differences among highly-confused categories. Most approaches address this
difficulty by learning discriminative representation of individual input image.
On the other hand, humans can effectively identify contrastive clues by
comparing image pairs. Inspired by this fact, this paper proposes a simple but
effective Attentive Pairwise Interaction Network (API-Net), which can
progressively recognize a pair of fine-grained images by interaction.
Specifically, API-Net first learns a mutual feature vector to capture semantic
differences in the input pair. It then compares this mutual vector with
individual vectors to generate gates for each input image. These distinct gate
vectors inherit mutual context on semantic differences, which allow API-Net to
attentively capture contrastive clues by pairwise interaction between two
images. Additionally, we train API-Net in an end-to-end manner with a score
ranking regularization, which can further generalize API-Net by taking feature
priorities into account. We conduct extensive experiments on five popular
benchmarks in fine-grained classification. API-Net outperforms the recent SOTA
methods, i.e., CUB-200-2011 (90.0%), Aircraft(93.9%), Stanford Cars (95.3%),
Stanford Dogs (90.3%), and NABirds (88.1%).
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:17:56 GMT""}]","2020-02-25"
"2002.10192","Takefumi Nosaka","Takefumi Nosaka","Twisted Alexander invariants of knot group representations","I revised minor errors",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a homomorphism from a knot group to a fixed group, we introduce an
element of a $K_1$-group, which is a generalization of (twisted) Alexander
polynomials. We compare this $K_1$-class with other Alexander polynomials. In
terms of semi-local rings, we compute the $K_1$-classes of some knots and show
their non-triviality. We also introduce metabelian Alexander polynomials.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:20:57 GMT""},{""version"":""v2"",""created"":""Sun, 29 Mar 2020 06:38:09 GMT""},{""version"":""v3"",""created"":""Mon, 23 Nov 2020 08:18:31 GMT""}]","2020-11-24"
"2002.10193","Pablo Rodriguez-Gil","P. Rodr\'iguez-Gil, T. Shahbaz, M. A. P. Torres, B. T. G\""ansicke, P.
  Izquierdo, O. Toloza, A. \'Alvarez-Hern\'andez, D. Steeghs, L. van Spaandonk,
  D. Koester, D. Rodr\'iguez","When the disc's away, the stars will play: dynamical masses in the
  nova-like variable KR Aur with a pinch of accretion","18 pages, 17 figures, 6 tables, accepted for publication in MNRAS
  (2020 Feb 19)",,"10.1093/mnras/staa612",,"astro-ph.SR astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtained time-resolved optical photometry and spectroscopy of the
nova-like variable KR Aurigae in the low state. The spectrum reveals a DAB
white dwarf and a mid-M dwarf companion. Using the companion star's $i$-band
ellipsoidal modulation we refine the binary orbital period to be $P = 3.906519
\pm 0.000001$ h. The light curve and the spectra show flaring activity due to
episodic accretion. One of these events produced brightness oscillations at a
period of 27.4 min, that we suggest to be related with the rotation period of a
possibly magnetic white dwarf at either 27.4 or 54.8 min. Spectral modelling
provided a spectral type of M4-5 for the companion star and $T_{1}=27148 \pm
496$ K, $\log g=8.90 \pm 0.07$, and $\log (\mathrm{He/H})=
-0.79^{+0.07}_{-0.08}~~$ for the white dwarf. By simultaneously fitting
absorption- and emission-line radial velocity curves and the ellipsoidal light
curve, we determined the stellar masses to be $M_1 = 0.94^{+0.15}_{-0.11}~$
$M_\odot$ and $M_2 = 0.37^{+0.07}_{-0.07}~$ $M_\odot$ for the white dwarf and
the M-dwarf, respectively, and an orbital inclination of $47^{+1^{\rm
o}}_{-2^{\rm o}}$. Finally, we analyse time-resolved spectroscopy acquired when
the system was at an $i$-band magnitude of 17.1, about 1.3 mag brighter than it
was in the low state. In this intermediate state the line profiles contain an
emission S-wave delayed by $\simeq 0.2$ orbital cycle relative to the motion of
the white dwarf, similar to what is observed in SW Sextantis stars in the high
state.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:21:00 GMT""}]","2020-04-08"
"2002.10194","Len Patrick Dominic Garces","Len Patrick Dominic M. Garces and Gerald H. L. Cheang","A Put-Call Transformation of the Exchange Option Problem under
  Stochastic Volatility and Jump Diffusion Dynamics","42 pages, 2 figures, 1 table",,,,"q-fin.MF q-fin.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We price European and American exchange options where the underlying asset
prices are modelled using a Merton (1976) jump-diffusion with a common Heston
(1993) stochastic volatility process. Pricing is performed under an equivalent
martingale measure obtained by setting the second asset yield process as the
numeraire asset, as suggested by Bjerskund and Stensland (1993). Such a choice
for the numeraire reduces the exchange option pricing problem, a
two-dimensional problem, to pricing a call option written on the ratio of the
yield processes of the two assets, a one-dimensional problem. The joint
transition density function of the asset yield ratio process and the
instantaneous variance process is then determined from the corresponding
Kolmogorov backward equation via integral transforms. We then determine
integral representations for the European exchange option price and the early
exercise premium and state a linked system of integral equations that
characterizes the American exchange option price and the associated early
exercise boundary. Properties of the early exercise boundary near maturity are
also discussed.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:21:26 GMT""}]","2020-02-25"
"2002.10195","Antonio Garufi","Antonio Garufi, Linda Podio, Claudio Codella, Kazi Rygl, Francesca
  Bacciotti, Stefano Facchini, Davide Fedele, Anna Miotello, Richard Teague,
  and Leonardo Testi","ALMA chemical survey of disk-outflow sources in Taurus (ALMA-DOT): I.
  CO, CS, CN, and H2CO around DG Tau B","13 pages, 6 figures, accepted by A&A","A&A 636, A65 (2020)","10.1051/0004-6361/201937247",,"astro-ph.SR astro-ph.EP astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The chemical composition of planets is inherited by the distribution of the
various molecular species in the protoplanetary disk at thetime of their
formation. As of today, only a handful of disks has been imaged in multiple
spectral lines with high spatial resolution. As part of a small campaign
devoted to the chemical characterization of disk-outflow sources in Taurus, we
report on new ALMA Band 6 observations with 20 au resolution toward the
embedded young star DG Tau B. Images of the continuum emission reveals a dust
disk with rings and, putatively, a leading spiral arm. The disk, as well as the
prominent outflow cavities, are detected in CO, H2CO, CS, and CN while they
remain undetected in SO2, HDO, and CH3OH. From the absorption of the back-side
outflow, we inferred that the disk emission is optically thick in the inner 50
au. This morphology explains why no line emission is detected from this inner
region and poses some limitations toward the calculation of the dust mass and
the characterization of the inner gaseous disk. The H2CO and CS emission from
the inner 200 au is mostly from the disk and their morphology is very similar.
The CN emission significantly differs from the other two molecules as it is
observed only beyond 150 au. This ring-like morphology is consistent with
previous observations and the predictions of thermochemical disk models.
Finally, we constrained the disk-integrated column density of all molecules. In
particular, we found that the CH3OH/H2CO ratio must be smaller than 2, making
the methanol non-detection still consistent with the only such a ratio
available from the literature (1.27 in TW Hya).
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:21:46 GMT""},{""version"":""v2"",""created"":""Tue, 3 Mar 2020 13:53:36 GMT""}]","2020-04-22"
"2002.10196","Boris Dolgonosov","Boris M. Dolgonosov","A knowledge-based model of civilization under climate change","46 pages, 20 figures, 3 tables, 37 references",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Civilization produces knowledge, which acts as the driving force of its
development. A macro-model of civilization that accounts for the effect of
knowledge production on population, energy consumption and environmental
conditions is developed. The model includes dynamic equations for world
population, amount of knowledge circulating in civilization, the share of
fossil fuels in total energy consumption, atmospheric CO2 concentration, and
global mean surface temperature. Energy dissipation in knowledge production and
direct loss of knowledge are taken into account. The model is calibrated using
historical data for each variable. About 90 scenarios were calculated. It was
shown that there are two control parameters - sensitivity of the population to
temperature rise and coefficient of knowledge loss - which determine the future
of civilization. In the two-dimensional space of these parameters, there is an
area of sustainable development and an area of loss of stability. Calculations
show that civilization is located just on the critical curve separating these
areas, that is, at the edge of stability. A small deviation can ultimately lead
either to a steady state of 10+ billion people or to the complete extinction of
civilization. There are no intermediate steady states.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:25:15 GMT""}]","2020-02-25"
"2002.10197","Matteo Lugli","Matteo Lugli and Paolo Perinotti and Alessandro Tosini","Fermionic state discrimination by local operations and classical
  communication","8 pages, 1 figure","Phys. Rev. Lett. 125, 110403 (2020)","10.1103/PhysRevLett.125.110403",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of local operations and classical communication
(LOCC) discrimination between two bipartite pure states of fermionic systems.
We show that, contrary to the case of quantum systems, for fermionic systems it
is generally not possible to achieve the ideal state discrimination
performances through LOCC measurements. On the other hand, we show that an
ancillary system made of two fermionic modes in a maximally entangled state is
a sufficient additional resource to attain the ideal performances via LOCC
measurements. The stability of the ideal results is studied when the
probability of preparation of the two states is perturbed, and a tight bound on
the discrimination error is derived.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:25:36 GMT""},{""version"":""v2"",""created"":""Thu, 10 Sep 2020 22:08:00 GMT""}]","2020-09-14"
"2002.10198","Wei Ye","Wei Ye, Rui Xie, Jinglei Zhang, Tianxiang Hu, Xiaoyin Wang, Shikun
  Zhang","Leveraging Code Generation to Improve Code Retrieval and Summarization
  via Dual Learning","Published at The Web Conference (WWW) 2020, full paper",,"10.1145/3366423.3380295",,"cs.IR cs.CL cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Code summarization generates brief natural language description given a
source code snippet, while code retrieval fetches relevant source code given a
natural language query. Since both tasks aim to model the association between
natural language and programming language, recent studies have combined these
two tasks to improve their performance. However, researchers have yet been able
to effectively leverage the intrinsic connection between the two tasks as they
train these tasks in a separate or pipeline manner, which means their
performance can not be well balanced. In this paper, we propose a novel
end-to-end model for the two tasks by introducing an additional code generation
task. More specifically, we explicitly exploit the probabilistic correlation
between code summarization and code generation with dual learning, and utilize
the two encoders for code summarization and code generation to train the code
retrieval task via multi-task learning. We have carried out extensive
experiments on an existing dataset of SQL and Python, and results show that our
model can significantly improve the results of the code retrieval task over
the-state-of-art models, as well as achieve competitive performance in terms of
BLEU score for the code summarization task.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:26:11 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 08:49:11 GMT""}]","2020-02-26"
"2002.10199","Tuomo Alasalmi","Tuomo Alasalmi, Jaakko Suutala, Heli Koskim\""aki, and Juha R\""oning","Better Classifier Calibration for Small Data Sets",,"ACM Transactions on Knowledge Discovery from Data, 14(3), Article
  34 (May 2020)","10.1145/3385656",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classifier calibration does not always go hand in hand with the classifier's
ability to separate the classes. There are applications where good classifier
calibration, i.e. the ability to produce accurate probability estimates, is
more important than class separation. When the amount of data for training is
limited, the traditional approach to improve calibration starts to crumble. In
this article we show how generating more data for calibration is able to
improve calibration algorithm performance in many cases where a classifier is
not naturally producing well-calibrated outputs and the traditional approach
fails. The proposed approach adds computational cost but considering that the
main use case is with small data sets this extra computational cost stays
insignificant and is comparable to other methods in prediction time. From the
tested classifiers the largest improvement was detected with the random forest
and naive Bayes classifiers. Therefore, the proposed approach can be
recommended at least for those classifiers when the amount of data available
for training is limited and good calibration is essential.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:27:21 GMT""},{""version"":""v2"",""created"":""Mon, 25 May 2020 09:15:03 GMT""}]","2020-05-26"
"2002.10200","Chunhua Shen","Yuliang Liu, Hao Chen, Chunhua Shen, Tong He, Lianwen Jin, Liangwei
  Wang","ABCNet: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network","Accepted to Proc. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR) 2020",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Scene text detection and recognition has received increasing research
attention. Existing methods can be roughly categorized into two groups:
character-based and segmentation-based. These methods either are costly for
character annotation or need to maintain a complex pipeline, which is often not
suitable for real-time applications. Here we address the problem by proposing
the Adaptive Bezier-Curve Network (ABCNet). Our contributions are three-fold:
1) For the first time, we adaptively fit arbitrarily-shaped text by a
parameterized Bezier curve. 2) We design a novel BezierAlign layer for
extracting accurate convolution features of a text instance with arbitrary
shapes, significantly improving the precision compared with previous methods.
3) Compared with standard bounding box detection, our Bezier curve detection
introduces negligible computation overhead, resulting in superiority of our
method in both efficiency and accuracy. Experiments on arbitrarily-shaped
benchmark datasets, namely Total-Text and CTW1500, demonstrate that ABCNet
achieves state-of-the-art accuracy, meanwhile significantly improving the
speed. In particular, on Total-Text, our realtime version is over 10 times
faster than recent state-of-the-art methods with a competitive recognition
accuracy. Code is available at https://tinyurl.com/AdelaiDet
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:27:31 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 08:02:28 GMT""}]","2020-02-26"
"2002.10201","Meng Chang","Meng Chang, Chenwei Yang, Huajun Feng, Zhihai Xu, Qi Li","Beyond Camera Motion Blur Removing: How to Handle Outliers in Deblurring",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Camera motion deblurring is an important low-level vision task for achieving
better imaging quality. When a scene has outliers such as saturated pixels, the
captured blurred image becomes more difficult to restore. In this paper, we
propose a novel method to handle camera motion blur with outliers. We first
propose an edge-aware scale-recurrent network (EASRN) to conduct deblurring.
EASRN has a separate deblurring module that removes blur at multiple scales and
an upsampling module that fuses different input scales. Then a salient edge
detection network is proposed to supervise the training process and constraint
the edges restoration. By simulating camera motion and adding various light
sources, we can generate blurred images with saturation cutoff. Using the
proposed data generation method, our network can learn to deal with outliers
effectively. We evaluate our method on public test datasets including the GoPro
dataset, Kohler's dataset and Lai's dataset. Both objective evaluation indexes
and subjective visualization show that our method results in better deblurring
quality than other state-of-the-art approaches.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:32:04 GMT""},{""version"":""v2"",""created"":""Wed, 22 Apr 2020 09:34:08 GMT""},{""version"":""v3"",""created"":""Tue, 27 Apr 2021 06:55:28 GMT""}]","2021-04-28"
"2002.10202","Len Patrick Dominic Garces","Gerald H. L. Cheang and Len Patrick Dominic M. Garces","Representation of Exchange Option Prices under Stochastic Volatility
  Jump-Diffusion Dynamics","45 pages, 1 figure","Quantitative Finance 20(2), 291-310","10.1080/14697688.2019.1655785",,"q-fin.MF q-fin.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we provide representations of European and American exchange
option prices under stochastic volatility jump-diffusion (SVJD) dynamics
following models by Merton (1976), Heston (1993), and Bates (1996). A
Radon-Nikodym derivative process is also introduced to facilitate the shift
from the objective market measure to other equivalent probability measures,
including the equivalent martingale measure. Under the equivalent martingale
measure, we derive the integro-partial differential equation that characterizes
the exchange option prices. We also derive representations of the European
exchange option price using the change-of-numeraire technique proposed by Geman
et al. (1995) and the Fourier inversion formula derived by Caldana and Fusai
(2013), and show that these two representations are comparable. Lastly, we show
that the American exchange option price can be decomposed into the price of the
European exchange option and an early exercise premium.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:32:17 GMT""}]","2020-02-25"
"2002.10203","Yasuhiro Ishitsuka","Yasuhiro Ishitsuka, Tetsushi Ito, Tatsuya Ohshita, Takashi Taniguchi
  and Yukihiro Uchida","The local-global property for bitangents of plane quartics","13 pages",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the arithmetic of bitangents of smooth quartics over global fields.
With the aid of computer algebra systems and using Elsenhans--Jahnel's results
on the inverse Galois problem for bitangents, we show that, over any global
field of characteristic different from $2$, there exist smooth quartics which
have bitangents over every local field, but do not have bitangents over the
global field. We give an algorithm to find such quartics explicitly, and give
an example over $\mathbb{Q}$. We also discuss a similar problem concerning
symmetric determinantal representations. This paper is a summary of the first
author's talk at the JSIAM JANT workshop on algorithmic number theory in March
2019. Details will appear elsewhere.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:39:49 GMT""},{""version"":""v2"",""created"":""Mon, 2 Mar 2020 15:24:57 GMT""},{""version"":""v3"",""created"":""Tue, 3 Mar 2020 01:48:00 GMT""},{""version"":""v4"",""created"":""Wed, 11 Mar 2020 03:14:33 GMT""},{""version"":""v5"",""created"":""Mon, 20 Apr 2020 18:05:05 GMT""}]","2020-04-22"
"2002.10204","Mordehai Milgrom","Mordehai Milgrom","Fast-rotating galaxies do not depart from the MOND mass-asymptotic-speed
  relation","4 pages",,,,"astro-ph.GA gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ogle et al. have fallaciously argued recently that fast-rotating disc
galaxies break with the predictions of MOND: the 6 fastest rotators of the 23
galaxies in their sample appear to have higher rotational speeds than is
consistent with the MOND relation between the baryonic mass of a galaxy, $M$,
and its `rotational speed', $V$. They interpret this departure as a break in
the observed $M-V$ relation from a logarithmic slope near the MOND-predicted
$4$, to a shallow slope of $\approx 0$. However, Ogle et al. use the MAXIMAL
rotational speed of the galaxies, $V_{max}$, not the ASYMPTOTIC one,
$V_\infty$, which appears in the MOND prediction, $V_\infty^4=MGa_0$. Plotting
their $M$ vs. $V_{max}$ pairs on an $M$ vs. $V_\infty$ plot from Lelli et al.
(2016), they arrive erroneously at the above tension with MOND. The $H_\alpha$
rotation curves used by Ogle et al. are far too short reaching to probe the
asymptotic regime, and determine $V_\infty$. However, it is well documented for
fast rotators with observed, extended, HI rotation curves, that they can have
$V_{max}$ considerably larger than the MOND-relevant $V_\infty$ [Noordermeer
and Verheijen (NV) (2007) and others]. E.g., the fastest rotator in the NV
sample has $V_{max}\approx 490{\rm ~km/s}$, but $V_\infty\approx 250{\rm
~km/s}$. NV also show that in a (MOND-irrelevant) $M-V_{max}$ plot the
high-speed galaxies fall off the power-law line defined by the lower-speed
ones, creating a break in the $M$ vs. $V$ relation, in just the way claimed by
Ogle et al. But, when plotting the MOND-relevant $M$ vs. $V_\infty$ all
galaxies fall near the same power-law relation, without a break.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:47:15 GMT""}]","2020-02-25"
"2002.10205","Yacine Chitour","Mehdi Benallegue and Abdelaziz Benallegue and Rafael Cisneros, and
  Yacine Chitour","Velocity-aided IMU-based Attitude Estimation",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the problem of estimating the attitude of a rigid body,
which is subject to high accelerations and equipped with inertial measurement
unit (IMU) and sensors providing the body velocity (expressed in the reference
frame attached to the body). That issue can be treated differently depending on
the level of confidence in the measurements of the magnetometer of the IMU,
particularly with regard to the observation of the inclination component with
respect to the vertical direction, rendering possible to describe the
interaction with gravity. Two cases are then studied: either (i) the
magnetometer is absent and only the inclination can be estimated, (ii) the
magnetometer is present, giving redundancy and full attitude observability. In
the latter case, the presented observer allows to tune how much the inclination
estimation is influenced by the magnetometer. All state estimators are proposed
with proof of almost global asymptotic stability and local exponential
convergence. Finally, these estimators are compared with state-of-the-art
solutions in clean and noisy simulations, allowing recommended solutions to be
drawn for each case.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:47:16 GMT""}]","2020-02-25"
"2002.10206","C\'onall Kelly","C\'onall Kelly, Gabriel Lord, Heru Maulana","The role of adaptivity in a numerical method for the Cox-Ingersoll-Ross
  model","25 pages, 4 figures, 2 tables. This version submitted to the Journal
  of Computational and Applied Mathematics",,,,"q-fin.CP cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the effectiveness of an adaptive explicit Euler method for the
approximate solution of the Cox-Ingersoll-Ross model. This relies on a class of
path-bounded timestepping strategies which work by reducing the stepsize as
solutions approach a neighbourhood of zero. The method is hybrid in the sense
that a convergent backstop method is invoked if the timestep becomes too small,
or to prevent solutions from overshooting zero and becoming negative. Under
parameter constraints that imply Feller's condition, we prove that such a
scheme is strongly convergent, of order at least 1/2. Control of the strong
error is important for multi-level Monte Carlo techniques. Under Feller's
condition we also prove that the probability of ever needing the backstop
method to prevent a negative value can be made arbitrarily small. Numerically,
we compare this adaptive method to fixed step implicit and explicit schemes,
and a novel semi-implicit adaptive variant. We observe that the adaptive
approach leads to methods that are competitive in a domain that extends beyond
Feller's condition, indicating suitability for the modelling of stochastic
volatility in Heston-type asset models.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:47:36 GMT""},{""version"":""v2"",""created"":""Mon, 24 Jan 2022 10:58:04 GMT""}]","2022-01-25"
"2002.10207","Zhucheng Zhang","Zhucheng Zhang, Yi-Ping Wang, and Xiaoguang Wang","$\mathcal{PT}$-symmetry-breaking enhanced cavity optomechanical
  magnetometry","6 pages, 5 figures","Phys. Rev. A 102, 023512 (2020)","10.1103/PhysRevA.102.023512",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  $\mathcal{PT}$-symmetry-breaking enhanced cavity optomechanical magnetometer
is proposed, which is achieved by monitoring the change of intensity of a
nonlinear four-wave mixing (FWM) process in a gain-cavity-assisted cavity
optomechanical system (COMS). Compared with the traditional single loss COMS,
the FWM intensity can be enhanced by two orders of magnitude when the
gain-cavity-assisted COMS operates at the $\mathcal{PT}$-symmetry-breaking
phase. Meanwhile, the sensitivity of magnetic field sensing can be increased
from $10^{-9}$T to $10^{-11}$T. This originally comes from the fact that the
effective detuning and decay of loss-cavity can be effectively modified in the
$\mathcal{PT}$-symmetry-breaking phase. Our work shows that an
ultrahigh-sensitivity magnetometer can be achieved in the
$\mathcal{PT}$-symmetry-breaking COMS, which will have wide applications in the
field of quantum sensing.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:49:27 GMT""},{""version"":""v2"",""created"":""Tue, 17 Mar 2020 08:38:03 GMT""}]","2020-08-12"
"2002.10208","Abhishake Rastogi","Abhishake Rastogi and Peter Math\'e","Inverse learning in Hilbert scales",,,,,"math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the linear ill-posed inverse problem with noisy data in the
statistical learning setting. Approximate reconstructions from random noisy
data are sought with general regularization schemes in Hilbert scale. We
discuss the rates of convergence for the regularized solution under the prior
assumptions and a certain link condition. We express the error in terms of
certain distance functions. For regression functions with smoothness given in
terms of source conditions the error bound can then be explicitly established.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:49:54 GMT""}]","2020-02-25"
"2002.10209","Yong Shi","Yong Shi (NJU), Junzhi Wang (SHAO), Zhi-Yu Zhang (NJU), Qizhou Zhang
  (CfA), Yu Gao (XMU), Luwenjia Zhou (NJU), Qiusheng Gu (NJU), Keping Qiu
  (NJU), Xiao-Yang Xia (TJNU), Cai-Na Hao (TJNU), and Yanmei Chen (NJU)","Over-sized gas clumps in an extremely-metal-poor molecular cloud
  revealed by ALMA's pc-scale maps","ApJ in press, 8 figures",,"10.3847/1538-4357/ab7a12",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metals are thought to have profound effects on the internal structures of
molecular clouds in which stars are born. The absence of metals is expected to
prevent gas from efficient cooling and fragmentation in theory. However, this
effect has not yet been observed at low metallicity environments, such as in
the early Universe and local dwarf galaxies, because of the lack of high
spatial resolution maps of gas. We carried out ALMA observations of the carbon
monoxide (CO) J=2-1 emission line at 1.4-parsec resolutions of a molecular
cloud in DDO 70 at 7% solar metallicity, the most metal-poor galaxy currently
known with a CO detection. In total, five clumps have been identified and they
are found to follow more or less the Larson's law. Since the CO emission exists
in regions with visual extinction A_V around 1.0, we converted this A_V to the
gas mass surface density using a gas-to-dust ratio of 4,594+-2,848 for DDO 70.
We found that the CO clumps in DDO 70 exhibit significantly larger (on average
four times) sizes than those at the same gas mass surface densities in massive
star-formation regions of the Milky Way. The existence of such large clumps
appears to be consistent with theoretical expectations that gas fragmentation
in low metallicity clouds is suppressed. While our observation is only for one
cloud in the galaxy, if it is representative, the above result implies
suppressed gas fragmentation during the cloud collapse and star formation in
the early Universe.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:50:36 GMT""}]","2020-04-15"
"2002.10210","Yibo Sun","Xiaocheng Feng, Yawei Sun, Bing Qin, Heng Gong, Yibo Sun, Wei Bi,
  Xiaojiang Liu, Ting Liu","Learning to Select Bi-Aspect Information for Document-Scale Text Content
  Manipulation","accepted by AAAI2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we focus on a new practical task, document-scale text content
manipulation, which is the opposite of text style transfer and aims to preserve
text styles while altering the content. In detail, the input is a set of
structured records and a reference text for describing another recordset. The
output is a summary that accurately describes the partial content in the source
recordset with the same writing style of the reference. The task is
unsupervised due to lack of parallel data, and is challenging to select
suitable records and style words from bi-aspect inputs respectively and
generate a high-fidelity long document. To tackle those problems, we first
build a dataset based on a basketball game report corpus as our testbed, and
present an unsupervised neural model with interactive attention mechanism,
which is used for learning the semantic relationship between records and
reference texts to achieve better content transfer and better style
preservation. In addition, we also explore the effectiveness of the
back-translation in our task for constructing some pseudo-training pairs.
Empirical results show superiority of our approaches over competitive methods,
and the models also yield a new state-of-the-art result on a sentence-level
dataset.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:52:10 GMT""}]","2020-02-25"
"2002.10211","Yaoyao Liu","Yaoyao Liu, Yuting Su, An-An Liu, Bernt Schiele, Qianru Sun","Mnemonics Training: Multi-Class Incremental Learning without Forgetting","Experiment results updated (different from the conference version).
  Code is available at https://github.com/yaoyao-liu/mnemonics-training",,"10.1109/CVPR42600.2020.01226",,"cs.CV stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Multi-Class Incremental Learning (MCIL) aims to learn new concepts by
incrementally updating a model trained on previous concepts. However, there is
an inherent trade-off to effectively learning new concepts without catastrophic
forgetting of previous ones. To alleviate this issue, it has been proposed to
keep around a few examples of the previous concepts but the effectiveness of
this approach heavily depends on the representativeness of these examples. This
paper proposes a novel and automatic framework we call mnemonics, where we
parameterize exemplars and make them optimizable in an end-to-end manner. We
train the framework through bilevel optimizations, i.e., model-level and
exemplar-level. We conduct extensive experiments on three MCIL benchmarks,
CIFAR-100, ImageNet-Subset and ImageNet, and show that using mnemonics
exemplars can surpass the state-of-the-art by a large margin. Interestingly and
quite intriguingly, the mnemonics exemplars tend to be on the boundaries
between different classes.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:55:25 GMT""},{""version"":""v2"",""created"":""Wed, 26 Feb 2020 07:35:05 GMT""},{""version"":""v3"",""created"":""Thu, 7 May 2020 01:46:46 GMT""},{""version"":""v4"",""created"":""Sun, 23 Aug 2020 12:49:51 GMT""},{""version"":""v5"",""created"":""Tue, 15 Sep 2020 19:44:51 GMT""},{""version"":""v6"",""created"":""Sun, 4 Apr 2021 12:24:40 GMT""}]","2021-04-06"
"2002.10212","Arve Gengelbach","Johannes {\AA}man Pohjola, Arve Gengelbach","A Mechanised Semantics for HOL with Ad-hoc Overloading","19 pages, accepted at LPAR 2020",,"10.29007/413d",,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Isabelle/HOL augments classical higher-order logic with ad-hoc overloading of
constant definitions---that is, one constant may have several definitions for
non-overlapping types. In this paper, we present a mechanised proof that HOL
with ad-hoc overloading is consistent. All our results have been formalised in
the HOL4 theorem prover.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:57:42 GMT""},{""version"":""v2"",""created"":""Mon, 25 May 2020 07:14:50 GMT""}]","2020-05-29"
"2002.10213","Martin Monperrus","Javier Cabrera-Arteaga, Shrinish Donde, Jian Gu, Orestis Floros, Lucas
  Satabin, Benoit Baudry and Martin Monperrus","Superoptimization of WebAssembly Bytecode","4 pages, 3 figures. Proceedings of MoreVMs: Workshop on Modern
  Language Runtimes, Ecosystems, and VMs (2020)","Proceedings of MoreVMs: Workshop on Modern Language Runtimes,
  Ecosystems, and VMs (2020)","10.1145/3397537.3397567",,"cs.PL cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the fast adoption of WebAssembly, we propose the first
functional pipeline to support the superoptimization of WebAssembly bytecode.
Our pipeline works over LLVM and Souper. We evaluate our superoptimization
pipeline with 12 programs from the Rosetta code project. Our pipeline improves
the code section size of 8 out of 12 programs. We discuss the challenges faced
in superoptimization of WebAssembly with two case studies.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:58:25 GMT""},{""version"":""v2"",""created"":""Wed, 23 Nov 2022 13:43:05 GMT""}]","2022-11-24"
"2002.10214","Andrea Borghesi","Andrea Borghesi, Federico Baldo, Michele Lombardi, Michela Milano","Injective Domain Knowledge in Neural Networks for Transprecision
  Computing",,"Nicosia G. et al. (eds) Machine Learning, Optimization, and Data
  Science. LOD 2020. Lecture Notes in Computer Science, vol 12565. Springer,
  Cham","10.1007/978-3-030-64583-0_52",,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine Learning (ML) models are very effective in many learning tasks, due
to the capability to extract meaningful information from large data sets.
Nevertheless, there are learning problems that cannot be easily solved relying
on pure data, e.g. scarce data or very complex functions to be approximated.
Fortunately, in many contexts domain knowledge is explicitly available and can
be used to train better ML models. This paper studies the improvements that can
be obtained by integrating prior knowledge when dealing with a non-trivial
learning task, namely precision tuning of transprecision computing
applications. The domain information is injected in the ML models in different
ways: I) additional features, II) ad-hoc graph-based network topology, III)
regularization schemes. The results clearly show that ML models exploiting
problem-specific information outperform the purely data-driven ones, with an
average accuracy improvement around 38%.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:58:56 GMT""}]","2021-01-29"
"2002.10215","Chunhua Shen","Xinyu Wang, Yuliang Liu, Chunhua Shen, Chun Chet Ng, Canjie Luo,
  Lianwen Jin, Chee Seng Chan, Anton van den Hengel, Liangwei Wang","On the General Value of Evidence, and Bilingual Scene-Text Visual
  Question Answering","Accepted to Proc. IEEE Conf. Computer Vision and Pattern Recognition
  2020",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Visual Question Answering (VQA) methods have made incredible progress, but
suffer from a failure to generalize. This is visible in the fact that they are
vulnerable to learning coincidental correlations in the data rather than deeper
relations between image content and ideas expressed in language. We present a
dataset that takes a step towards addressing this problem in that it contains
questions expressed in two languages, and an evaluation process that co-opts a
well understood image-based metric to reflect the method's ability to reason.
Measuring reasoning directly encourages generalization by penalizing answers
that are coincidentally correct. The dataset reflects the scene-text version of
the VQA problem, and the reasoning evaluation can be seen as a text-based
version of a referring expression challenge. Experiments and analysis are
provided that show the value of the dataset.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:02:31 GMT""},{""version"":""v2"",""created"":""Wed, 26 Feb 2020 04:59:18 GMT""}]","2020-02-27"
"2002.10216","Hongde Yu","Hongde Yu and Dong Wang","Metal-free magnetism in chemically doped covalent organic frameworks","10 pages, 4 figures","J. Am. Chem. Soc. 2020,","10.1021/jacs.0c02254",,"physics.chem-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Organic and molecule-based magnets are not easily attainable, because to
introduce stable paramagnetic centers to pure organic systems is challenging.
Crystalline covalent organic frameworks (COFs) with high designability and
chemical diversity constitute ideal platforms to access intriguing magnetic
phenomena of organic materials. In this work, we proposed a general approach to
attain unpaired electron spin and metal-free magnetism in narrow-band COFs by
chemical doping. By using density functional theory calculations, we found that
dopants with energy-matched frontier orbitals to COFs not only inject charges
to them but also further localize the charges through orbital hybridization and
formation of supramolecular charge-transfer complex. The localized states
enable stable paramagnetic centers introduced to nonmagnetic COFs. Based on
this discovery, we designed two new COFs with narrow valence band, which show
prospective magnetism after doping with iodine. Further, we unraveled magnetic
anisotropy in two-dimensional COFs and showed that both spin-conduction and
magnetic interactions can be modulated by manipulating the building blocks of
COFs. Our work highlights a practical scenario to attain magnetism in COFs and
other organic materials, which hold great promise for applications in organic
spintronic devices.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:07:50 GMT""},{""version"":""v2"",""created"":""Mon, 2 Mar 2020 13:46:15 GMT""}]","2020-06-09"
"2002.10217","Levente Hajder","Levente Hajder and Tekla T\'oth and Zolt\'an Pusztai","Automatic Estimation of Sphere Centers from Images of Calibrated Cameras",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Calibration of devices with different modalities is a key problem in robotic
vision. Regular spatial objects, such as planes, are frequently used for this
task. This paper deals with the automatic detection of ellipses in camera
images, as well as to estimate the 3D position of the spheres corresponding to
the detected 2D ellipses. We propose two novel methods to (i) detect an ellipse
in camera images and (ii) estimate the spatial location of the corresponding
sphere if its size is known. The algorithms are tested both quantitatively and
qualitatively. They are applied for calibrating the sensor system of autonomous
cars equipped with digital cameras, depth sensors and LiDAR devices.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:12:08 GMT""}]","2020-02-25"
"2002.10218","Tianxiang Mao","Tian-Xiang Mao, Jie Wang, Baojiu Li, Yan-Chuan Cai, Bridget Falck,
  Mark Neyrinck and Alex Szalay","Baryon acoustic oscillations reconstruction using convolutional neural
  networks","Accepted for publication in MNRAS","MNRAS, 501, 1499-1510 (2021)","10.1093/mnras/staa3741",,"astro-ph.CO cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new scheme to reconstruct the baryon acoustic oscillations (BAO)
signal, which contains key cosmological information, based on deep
convolutional neural networks (CNN). Trained with almost no fine-tuning, the
network can recover large-scale modes accurately in the test set: the
correlation coefficient between the true and reconstructed initial conditions
reaches $90\%$ at $k\leq 0.2 h\mathrm{Mpc}^{-1}$, which can lead to significant
improvements of the BAO signal-to-noise ratio down to
$k\simeq0.4h\mathrm{Mpc}^{-1}$. Since this new scheme is based on the
configuration-space density field in sub-boxes, it is local and less affected
by survey boundaries than the standard reconstruction method, as our tests
confirm. We find that the network trained in one cosmology is able to
reconstruct BAO peaks in the others, i.e. recovering information lost to
non-linearity independent of cosmology. The accuracy of recovered BAO peak
positions is far less than that caused by the difference in the cosmology
models for training and testing, suggesting that different models can be
distinguished efficiently in our scheme. It is very promising that Our scheme
provides a different new way to extract the cosmological information from the
ongoing and future large galaxy surveys.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:18:31 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 08:12:25 GMT""},{""version"":""v3"",""created"":""Thu, 3 Dec 2020 08:41:49 GMT""}]","2021-02-09"
"2002.10219","Masoumeh Izadparast","M. Izadparast and S. Habib Mazharimousavi","Generalized Extended Momentum Operator","7 pages 2 figures","Phys. Scr. 95 075220 (2020)","10.1088/1402-4896/ab97cf",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study and generalize the momentum operator satisfying the extended
uncertainty principle relation (EUP). This generalized extended momentum
operator (GEMO) consists of an arbitrary auxiliary function of position
operator, $\mu \left( x\right) $, in such a combination that not only GEMO
satisfies the EUP relation but also it is Hermitian. Next, we apply the GEMO to
construct the generalized one-dimensional Schr\""{o}dinger equation. Upon using
the so called point canonical transformation (PCT), we transform the
generalized Schr\""{o}dinger equation from $x$-space to $z$-space where in terms
of the transformed coordinate, $z$, it is of the standard form of the
Schr\""{o}dinger equation. In continuation, we study two illustrative examples
and solve the corresponding equations analytically to find the energy spectrum.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:19:01 GMT""}]","2020-12-09"
"2002.10220","Luigi Brugnano","Pierluigi Amodio, Luigi Brugnano, Felice Iavernaro, Francesca Mazzia","On the use of the Infinity Computer architecture to set up a dynamic
  precision floating-point arithmetic","11 pages, 2 figures, 6 tables","Soft Computing 24 (2020) 17589-17600","10.1007/s00500-020-05220-z",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We devise a variable precision floating-point arithmetic by exploiting the
framework provided by the Infinity Computer. This is a computational platform
implementing the Infinity Arithmetic system, a positional numeral system which
can handle both infinite and infinitesimal quantities symbolized by the
positive and negative finite powers of the radix grossone. The computational
features offered by the Infinity Computer allows us to dynamically change the
accuracy of representation and floating-point operations during the flow of a
computation. When suitably implemented, this possibility turns out to be
particularly advantageous when solving ill-conditioned problems. In fact,
compared with a standard multi-precision arithmetic, here the accuracy is
improved only when needed, thus not affecting that much the overall
computational effort. An illustrative example about the solution of a nonlinear
equation is also presented.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:20:33 GMT""}]","2022-03-28"
"2002.10224","Kristin Gru{\ss}mayer","Kristin S. Grussmayer, Tomas Lukes, Theo Lasser, Aleksandra Radenovic","Self-blinking Dyes unlock High-order and Multi-plane Super-resolution
  Optical Fluctuation Imaging","main: 3 figures, SI: 9 figures",,,,"physics.optics physics.bio-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffraction unlimited super-resolution imaging critically depends on the
switching of fluorophores between at least two states, often induced using
intense laser light and special buffers. The high illumination power or UV
light required for appropriate blinking kinetics is currently hindering
live-cell experiments. Recently, so-called self-blinking dyes that switch
spontaneously between an open, fluorescent ""on""-state and a closed colorless
""off""-state were introduced. Here we exploit the synergy between
super-resolution optical fluctuation imaging (SOFI) and spontaneously switching
fluorophores for 2D functional and for volumetric imaging. SOFI tolerates high
labeling densities, on-time ratios, and low signal-to-noise by analyzing
higher-order statistics of a few hundred to thousand frames of stochastically
blinking fluorophores. We demonstrate 2D imaging of fixed cells with a uniform
resolution up to 50-60 nm in 6th order SOFI and characterize changing
experimental conditions. We extend multiplane cross-correlation analysis to 4th
order using biplane and 8-plane volumetric imaging achieving up to 29 (virtual)
planes. The low laser excitation intensities needed for self-blinking SOFI are
ideal for live-cell imaging. We show proof-of-principal time-resolved imaging
by observing slow membrane movements in cells. Self-blinking SOFI provides a
route for easy-to-use 2D and 3D high-resolution functional imaging that is
robust against artefacts and suitable for live-cell imaging.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:25:20 GMT""}]","2020-02-25"
"2002.10230","Yasuhiro Shimizu","Naoyuki Haba, Yasuhiro Shimizu, Toshifumi Yamada","Muon and Electron $g-2$ and the Origin of Fermion Mass Hierarchy","11 pages, 1 figure, accepted for publication in PTEP","Prog Theor Exp Phys (2020)","10.1093/ptep/ptaa098",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a model that gives a natural explanation to the charged lepton
mass hierarchy and study the contributions to the electron and the muon $g-2$.
In the model, we introduce lepton-flavor-dependent $U(1)_F$ symmetry and three
additional Higgs doublets with $U(1)_F$ charges, to realize that each
generation of charged leptons couples to one of the three additional Higgs
doublets. The $U(1)_F$ symmetry is softly broken by $+1$ charges, and the
smallness of the soft breaking naturally gives rise to the hierarchy of the
Higgs VEVs, which then accounts for the charged lepton mass hierarchy. Since
electron and muon couple to different scalar particles, each scalar contributes
to the electron and the muon $g-2$ differently. We survey the space of
parameters of the Higgs sector and find that there are sets of parameters that
explain the muon $g-2$ discrepancy. On the other hand, we cannot find the
parameter sets that can explain $g-2$ discrepancy within 2$\sigma$. Here the
$U(1)_F$ symmetry suppresses charged lepton flavor violation.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:28:38 GMT""},{""version"":""v2"",""created"":""Thu, 27 Feb 2020 03:33:09 GMT""},{""version"":""v3"",""created"":""Wed, 24 Jun 2020 04:23:56 GMT""}]","2020-09-16"
"2002.10232","Daniel Ingebretson","Daniel Ingebretson","Quantitative distortion and the Hausdorff dimension of continued
  fractions","14 pages",,,,"math.NT math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a quantitative distortion theorem for iterated function systems that
generate sets of continued fractions. As a consequence, we obtain upper and
lower bounds on the Hausdorff dimension of any set of real or complex continued
fractions. These bounds are solutions to Moran-type equations in the
convergents that can be easily implemented in a computer algebra system.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:32:26 GMT""}]","2020-02-25"
"2002.10234","Yuji Roh","Yuji Roh, Kangwook Lee, Steven Euijong Whang, Changho Suh","FR-Train: A Mutual Information-Based Approach to Fair and Robust
  Training",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trustworthy AI is a critical issue in machine learning where, in addition to
training a model that is accurate, one must consider both fair and robust
training in the presence of data bias and poisoning. However, the existing
model fairness techniques mistakenly view poisoned data as an additional bias
to be fixed, resulting in severe performance degradation. To address this
problem, we propose FR-Train, which holistically performs fair and robust model
training. We provide a mutual information-based interpretation of an existing
adversarial training-based fairness-only method, and apply this idea to
architect an additional discriminator that can identify poisoned data using a
clean validation set and reduce its influence. In our experiments, FR-Train
shows almost no decrease in fairness and accuracy in the presence of data
poisoning by both mitigating the bias and defending against poisoning. We also
demonstrate how to construct clean validation sets using crowdsourcing, and
release new benchmark datasets.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:37:29 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 07:46:37 GMT""}]","2020-07-06"
"2002.10235","Xuhui Fan","Yaqiong Li, Xuhui Fan, Ling Chen, Bin Li, Zheng Yu, Scott A. Sisson","Recurrent Dirichlet Belief Networks for Interpretable Dynamic Relational
  Data Modelling","7 pages, 3 figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Dirichlet Belief Network~(DirBN) has been recently proposed as a
promising approach in learning interpretable deep latent representations for
objects. In this work, we leverage its interpretable modelling architecture and
propose a deep dynamic probabilistic framework -- the Recurrent Dirichlet
Belief Network~(Recurrent-DBN) -- to study interpretable hidden structures from
dynamic relational data. The proposed Recurrent-DBN has the following merits:
(1) it infers interpretable and organised hierarchical latent structures for
objects within and across time steps; (2) it enables recurrent long-term
temporal dependence modelling, which outperforms the one-order Markov
descriptions in most of the dynamic probabilistic frameworks. In addition, we
develop a new inference strategy, which first upward-and-backward propagates
latent counts and then downward-and-forward samples variables, to enable
efficient Gibbs sampling for the Recurrent-DBN. We apply the Recurrent-DBN to
dynamic relational data problems. The extensive experiment results on
real-world data validate the advantages of the Recurrent-DBN over the
state-of-the-art models in interpretable latent structure discovery and
improved link prediction performance.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:40:24 GMT""},{""version"":""v2"",""created"":""Wed, 29 Apr 2020 10:54:50 GMT""}]","2020-04-30"
"2002.10236","David Chinellato D","Andr\'e Vieira da Silva, Willian Matioli Serenone, David Dobrigkeit
  Chinellato, Jun Takahashi, Christian Bierlich","Studies of heavy-ion collisions using PYTHIA Angantyr and UrQMD","13 pages, 14 figures, extra content",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we show predictions from a new QGP-free, no-equilibration,
improved baseline model for heavy-ion collisions. It is comprised of the PYTHIA
Angantyr event generator coupled to UrQMD, as a hadronic cascade simulator, and
compared to ALICE and CMS data from Pb-Pb collisions at $\sqrt{s_{\rm{NN}}}$ =
2.76 TeV. This coupling is made possible due to a new implementation of the
hadron vertex model in PYTHIA Angantyr. Hadronic rescattering in UrQMD is shown
to lead to a significant suppression of mid- to high-$p_\perp$ particle yields
that is qualitatively consistent with measurements of nuclear modification
factors. We further study the effect of hadronic rescatterings on
high-$p_\perp$ particles by using two-particle correlations and show that some
suppression of away-side jets occurs in the hadronic phase even without any
partonic energy loss. Finally, the decorrelation of dijet structures at high
momenta also leads to a reduction of the elliptic flow coefficient
$v_{2}\{2\}$. These findings suggest that significant jet-quenching-like
effects may still originate in the hadronic, as opposed to the partonic phase
and prove that the usual Pb-Pb baseline, composed of a superposition of
incoherent pp collisions, ignores coherent phenomena that are not strictly
related to the QGP but may still be highly relevant.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:40:45 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 13:16:06 GMT""},{""version"":""v3"",""created"":""Sun, 29 Nov 2020 20:11:53 GMT""}]","2020-12-01"
"2002.10242","Zhiyuan Jiang","Fei Peng, Zhiyuan Jiang, Shunqing Zhang, Shugong Xu","Age of Information Optimized MAC in V2X Sidelink via Piggyback-Based
  Collaboration","Submitted to IEEE TWC for possible publication",,,,"cs.IT cs.NI math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-time status update in future vehicular networks is vital to enable
control-level cooperative autonomous driving. Cellular Vehicle-to-Everything
(C-V2X), as one of the most promising vehicular wireless technologies, adopts a
Semi-Persistent Scheduling (SPS) based Medium-Access-Control (MAC) layer
protocol for its sidelink communications. Despite the recent and ongoing
efforts to optimize SPS, very few work has considered the status update
performance of SPS. In this paper, Age of Information (AoI) is first leveraged
to evaluate the MAC layer performance of C-V2X sidelink. Critical issues of
SPS, i.e., persistent packet collisions and Half-Duplex (HD) effects, are
identified to hinder its AoI performance. Therefore, a piggyback-based
collaboration method is proposed accordingly, whereby vehicles collaborate to
inform each other of potential collisions and collectively afford HD errors,
while entailing only a small signaling overhead. Closed-form AoI performance is
derived for the proposed scheme, optimal configurations for key parameters are
hence calculated, and the convergence property is proved for decentralized
implementation. Simulation results show that compared with the standardized SPS
and its state-of-the-art enhancement schemes, the proposed scheme shows
significantly better performance, not only in terms of AoI, but also of
conventional metrics such as transmission reliability.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:43:43 GMT""},{""version"":""v2"",""created"":""Mon, 13 Apr 2020 12:13:46 GMT""}]","2020-04-14"
"2002.10243","Tianyu Cui","Tianyu Cui, Aki Havulinna, Pekka Marttinen, Samuel Kaski","Informative Bayesian Neural Network Priors for Weak Signals","25 pages, 8 figures, 4 tables",,"10.1214/21-BA1291",,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Encoding domain knowledge into the prior over the high-dimensional weight
space of a neural network is challenging but essential in applications with
limited data and weak signals. Two types of domain knowledge are commonly
available in scientific applications: 1. feature sparsity (fraction of features
deemed relevant); 2. signal-to-noise ratio, quantified, for instance, as the
proportion of variance explained (PVE). We show how to encode both types of
domain knowledge into the widely used Gaussian scale mixture priors with
Automatic Relevance Determination. Specifically, we propose a new joint prior
over the local (i.e., feature-specific) scale parameters that encodes knowledge
about feature sparsity, and a Stein gradient optimization to tune the
hyperparameters in such a way that the distribution induced on the model's PVE
matches the prior distribution. We show empirically that the new prior improves
prediction accuracy, compared to existing neural network priors, on several
publicly available datasets and in a genetics application where signals are
weak and sparse, often outperforming even computationally intensive
cross-validation for hyperparameter tuning.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:43:44 GMT""},{""version"":""v2"",""created"":""Thu, 7 Jan 2021 14:55:29 GMT""}]","2023-03-31"
"2002.10257","Roozbeh Yousefzadeh","Roozbeh Yousefzadeh","Using Wavelets to Analyze Similarities in Image-Classification Datasets",,,,,"eess.IV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning image classifiers usually rely on huge training sets and their
training process can be described as learning the similarities and differences
among training images. But, images in large training sets are not usually
studied from this perspective and fine-level similarities and differences among
images is usually overlooked. This is due to lack of fast and efficient
computational methods to analyze the contents of these datasets. Some studies
aim to identify the influential and redundant training images, but such methods
require a model that is already trained on the entire training set. Here, using
image processing and numerical analysis tools we develop a practical and fast
method to analyze the similarities in image classification datasets. We show
that such analysis can provide valuable insights about the datasets and the
classification task at hand, prior to training a model. Our method uses wavelet
decomposition of images and other numerical analysis tools, with no need for a
pre-trained model. Interestingly, the results we obtain corroborate the
previous results in the literature that analyzed the similarities using
pre-trained CNNs. We show that similar images in standard datasets (such as
CIFAR) can be identified in a few seconds, a significant speed-up compared to
alternative methods in the literature. By removing the computational speed
obstacle, it becomes practical to gain new insights about the contents of
datasets and the models trained on them. We show that similarities between
training and testing images may provide insights about the generalization of
models. Finally, we investigate the similarities between images in relation to
decision boundaries of a trained model.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:46:28 GMT""},{""version"":""v2"",""created"":""Mon, 18 May 2020 01:42:54 GMT""}]","2020-05-19"
"2002.10258","Suzhi Bi","Yuegui Chen, Suzhi Bi, Xian Li, Xiaohui Lin, and Hui Wang","Computation Rate Maximization in Wireless Powered MEC with Spread
  Spectrum Multiple Access","The paper has been accepted for publication by Proc. IEEE ITOEC 2020",,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The integration of mobile edge computing (MEC) and wireless power transfer
(WPT) technologies has recently emerged as an effective solution for extending
battery life and increasing the computing power of wireless devices. In this
paper, we study the resource allocation problem of a multi-user wireless
powered MEC system, where the users share the wireless channel via direct
sequence code division multiple access (DS-CDMA). In particular, we are
interested in jointly optimizing the task offloading decisions and resource
allocation, to maximize the weighted sum computation rate of all the users in
the network. The optimization problem is formulated as a mixed integer
non-linear programming (MINLP). For a given offloading user set, we implement
an efficient Fractional Programming (FP) approach to mitigate the multi-user
interference in the uplink task offloading. On top of that, we then propose a
Stochastic Local Search algorithm to optimize the offloading decisions.
Simulation results show that the proposed method can effectively enhance the
computing performance of a wireless powered MEC with spread spectrum multiple
access compared to other representative benchmark methods.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:50:57 GMT""}]","2020-02-25"
"2002.10259","Ondrej Kuzelka","Ondrej Kuzelka","Complex Markov Logic Networks: Expressivity and Liftability","Fixed typos in Lemma 1 and Section 7. Paper accepted to UAI 2020",,,,"cs.AI cs.LG cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study expressivity of Markov logic networks (MLNs). We introduce complex
MLNs, which use complex-valued weights, and we show that, unlike standard MLNs
with real-valued weights, complex MLNs are fully expressive. We then observe
that discrete Fourier transform can be computed using weighted first order
model counting (WFOMC) with complex weights and use this observation to design
an algorithm for computing relational marginal polytopes which needs
substantially less calls to a WFOMC oracle than a recent algorithm.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:50:59 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 13:04:58 GMT""}]","2020-07-17"
"2002.10260","Alessandro Raganato","Alessandro Raganato, Yves Scherrer and J\""org Tiedemann","Fixed Encoder Self-Attention Patterns in Transformer-Based Machine
  Translation","Accepted to Findings of EMNLP 2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer-based models have brought a radical change to neural machine
translation. A key feature of the Transformer architecture is the so-called
multi-head attention mechanism, which allows the model to focus simultaneously
on different parts of the input. However, recent works have shown that most
attention heads learn simple, and often redundant, positional patterns. In this
paper, we propose to replace all but one attention head of each encoder layer
with simple fixed -- non-learnable -- attentive patterns that are solely based
on position and do not require any external knowledge. Our experiments with
different data sizes and multiple language pairs show that fixing the attention
heads on the encoder side of the Transformer at training time does not impact
the translation quality and even increases BLEU scores by up to 3 points in
low-resource scenarios.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:53:06 GMT""},{""version"":""v2"",""created"":""Tue, 28 Apr 2020 18:36:07 GMT""},{""version"":""v3"",""created"":""Mon, 5 Oct 2020 16:10:31 GMT""}]","2020-10-06"
"2002.10261","Zayd Hammoudeh","Zayd Hammoudeh and Daniel Lowd","Learning from Positive and Unlabeled Data with Arbitrary Positive Shift","Accepted at NeurIPS'20",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Positive-unlabeled (PU) learning trains a binary classifier using only
positive and unlabeled data. A common simplifying assumption is that the
positive data is representative of the target positive class. This assumption
rarely holds in practice due to temporal drift, domain shift, and/or
adversarial manipulation. This paper shows that PU learning is possible even
with arbitrarily non-representative positive data given unlabeled data from the
source and target distributions. Our key insight is that only the negative
class's distribution need be fixed. We integrate this into two statistically
consistent methods to address arbitrary positive bias - one approach combines
negative-unlabeled learning with unlabeled-unlabeled learning while the other
uses a novel, recursive risk estimator. Experimental results demonstrate our
methods' effectiveness across numerous real-world datasets and forms of
positive bias, including disjoint positive class-conditional supports.
Additionally, we propose a general, simplified approach to address PU risk
estimation overfitting.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:53:22 GMT""},{""version"":""v2"",""created"":""Sun, 14 Jun 2020 00:48:59 GMT""},{""version"":""v3"",""created"":""Thu, 18 Jun 2020 02:00:34 GMT""},{""version"":""v4"",""created"":""Mon, 9 Nov 2020 12:20:05 GMT""}]","2020-11-10"
"2002.10270","Marc Schneble","Marc Schneble and G\""oran Kauermann","Intensity Estimation on Geometric Networks with Penalized Splines","23 pages, 8 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past decades, the growing amount of network data has lead to many
novel statistical models. In this paper we consider so called geometric
networks. Typical examples are road networks or other infrastructure networks.
But also the neurons or the blood vessels in a human body can be interpreted as
a geometric network embedded in a three-dimensional space. In all these
applications a network specific metric rather than the Euclidean metric is
usually used, which makes the analyses on network data challenging. We consider
network based point processes and our task is to estimate the intensity (or
density) of the process which allows to detect high- and low- intensity regions
of the underlying stochastic processes. Available routines that tackle this
problem are commonly based on kernel smoothing methods. However, kernel based
estimation in general exhibits some drawbacks such as suffering from boundary
effects and the locality of the smoother. In an Euclidean space, the
disadvantages of kernel methods can be overcome by using penalized spline
smoothing. We here extend penalized spline smoothing towards smooth intensity
estimation on geometric networks and apply the approach to both, simulated and
real world data. The results show that penalized spline based intensity
estimation is numerically efficient and outperforms kernel based methods.
Furthermore, our approach easily allows to incorporate covariates, which allows
to respect the network geometry in a regression model framework.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:04:14 GMT""}]","2020-02-25"
"2002.10271","Wittawat Jitkrittum","Wittawat Jitkrittum, Heishiro Kanagawa, Bernhard Sch\""olkopf","Testing Goodness of Fit of Conditional Density Models with Kernels","In UAI 2020. http://auai.org/uai2020/accepted.php",,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose two nonparametric statistical tests of goodness of fit for
conditional distributions: given a conditional probability density function
$p(y|x)$ and a joint sample, decide whether the sample is drawn from
$p(y|x)r_x(x)$ for some density $r_x$. Our tests, formulated with a Stein
operator, can be applied to any differentiable conditional density model, and
require no knowledge of the normalizing constant. We show that 1) our tests are
consistent against any fixed alternative conditional model; 2) the statistics
can be estimated easily, requiring no density estimation as an intermediate
step; and 3) our second test offers an interpretable test result providing
insight on where the conditional model does not fit well in the domain of the
covariate. We demonstrate the interpretability of our test on a task of
modeling the distribution of New York City's taxi drop-off location given a
pick-up point. To our knowledge, our work is the first to propose such
conditional goodness-of-fit tests that simultaneously have all these desirable
properties.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:04:37 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 15:27:09 GMT""}]","2020-07-01"
"2002.10272","Himanshu Parihar","Jaydeep Kumar Basak, Vinay Malvimat, Himanshu Parihar, Boudhayan Paul
  and Gautam Sengupta","On minimal entanglement wedge cross section for holographic entanglement
  negativity","4 figures, 14 pages",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an alternate construction to compute the minimal entanglement
wedge cross section (EWCS) for a single interval in a $(1+1)$ dimensional
holographic conformal field theory at a finite temperature, dual to a bulk
planar BTZ black hole geometry. Utilizing this construction we compute the
holographic entanglement negativity for the above mixed state configuration
from a recent conjecture in the literature. Our results exactly reproduce the
corresponding replica technique results in the large central charge limit and
resolves the issue of the missing thermal term for the holographic entanglement
negativity computed earlier in the literature. In this context we compare the
results for the holographic entanglement negativity utilizing the minimum EWCS
and an alternate earlier proposal involving an algebraic sum of the lengths of
the geodesics homologous to specific combinations of appropriate intervals.
From our analysis we conclude that the two quantities are proportional in the
context of the $AdS_3/CFT_2$ scenario and this possibly extends to the higher
dimensional $AdS_{d+1}/CFT_d$ framework.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:05:52 GMT""}]","2020-02-25"
"2002.10273","Donglun Wu","Dong-Lun Wu and Hongxia Lin","Multiple solutions for superlinear Klein-Gordon-Maxwell equations",,"Math. Nachr. (2020) 1-9","10.1002/mana.201900129",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the following Klein-Gordon-Maxwell equations
\begin{eqnarray*} \left\{ \begin{array}{ll} -\Delta u+ V(x)u-(2\omega+\phi)\phi
u=f(x,u)+h(x)&\mbox{in $\mathbb{R}^{3}$},\\ -\Delta \phi+ \phi u^2=-\omega
u^2&\mbox{in $\mathbb{R}^{3}$}, \end{array} \right. \end{eqnarray*} where
$\omega>0$ is a constant, $u$, $\phi : \mathbb{R}^{3}\rightarrow \mathbb{R}$,
$V : \mathbb{R}^{3} \rightarrow\mathbb{R}$ is a potential function. By assuming
the coercive condition on $V$ and some new superlinear conditions on $f$, we
obtain two nontrivial solutions when $h$ is nonzero and infinitely many
solutions when $f$ is odd in $u$ and $h\equiv0$ for above equations.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:06:00 GMT""}]","2020-09-29"
"2002.10274","Florian Huber","Florian Huber, Gary Koop, Michael Pfarrhofer","Bayesian Inference in High-Dimensional Time-varying Parameter Models
  using Integrated Rotated Gaussian Approximations",,,,,"econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Researchers increasingly wish to estimate time-varying parameter (TVP)
regressions which involve a large number of explanatory variables. Including
prior information to mitigate over-parameterization concerns has led to many
using Bayesian methods. However, Bayesian Markov Chain Monte Carlo (MCMC)
methods can be very computationally demanding. In this paper, we develop
computationally efficient Bayesian methods for estimating TVP models using an
integrated rotated Gaussian approximation (IRGA). This exploits the fact that
whereas constant coefficients on regressors are often important, most of the
TVPs are often unimportant. Since Gaussian distributions are invariant to
rotations we can split the the posterior into two parts: one involving the
constant coefficients, the other involving the TVPs. Approximate methods are
used on the latter and, conditional on these, the former are estimated with
precision using MCMC methods. In empirical exercises involving artificial data
and a large macroeconomic data set, we show the accuracy and computational
benefits of IRGA methods.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:07:50 GMT""}]","2020-02-25"
"2002.10275","We-Fu Chang","We-Fu Chang and Jiajun Liao","Constraints on light singlet fermion interactions from coherent elastic
  neutrino-nucleus scattering","23 pages, 4 figures, References added. To match the published version","Phys. Rev. D 102, 075004 (2020)","10.1103/PhysRevD.102.075004",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exotic singlet fermions $\chi$, with a mass $m_\chi\lesssim 50$ MeV,
could be produced at the coherent elastic neutrino-nucleus scattering
(CE$\nu$NS) experiments through the $\nu {\mathcal N} \rightarrow \chi
{\mathcal N}$ process. Due to the coherent enhancement, it offers a unique way
to study how $\chi$ interacts with the Standard Model (SM) sector. Based on the
most general dimension-6 effective Lagrangian, we perform a comprehensive study
on the relevant interaction between $\chi$ and the SM sector. From the current
and future COHERENT and future CONUS experiments, we obtain the upper bounds on
the Wilson coefficients for the dipole, scalar, vector, and tensor
interactions. For $m_\chi $ below 10 MeV, future CONUS data has the best
sensitivity, while for $m_\chi$ between 10 MeV$-50$ MeV, the current and future
COHERENT bounds dominate. These limits are complementary to those from neutrino
oscillation and collider searches. Moreover, the bounds do not depend on the
charge conjugation property of $\chi$, nor whether $\chi$ is dark matter or
not.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:09:02 GMT""},{""version"":""v2"",""created"":""Thu, 5 Mar 2020 01:46:31 GMT""},{""version"":""v3"",""created"":""Thu, 8 Oct 2020 15:27:00 GMT""}]","2020-10-14"
"2002.10276","Siu Tat Chui","Ruijie Qian, S. T. Chui, Zhenghua An, y Hongtao Xu, Zhifang Lin, Zian
  Ji, and Wei Lu","Hidden information in fluctuation in small systems",,"Phys. Rev. B 104, 064301 (2021)","10.1103/PhysRevB.104.064301",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exploration of the rich dynamics of electrons is a frontier in
fundamental nano-physics. The dynamical behavior of electrons is dominated by
random and chaotic thermal motion with ultrafast ($\approx$ ps) and nanoscale
scatterings. This generates fluctuating electromagnetic fields in close
vicinity of the moving electrons. W studied this fluctuation in small
structures and found that its spatial distribution is not uniform, the
magnitude of the fluctuation depends on external parameters such as the size (
~1 $\mu m$) and the shape of the structure and changes can occur by an order of
magnitude. Our work opens the possibility of improving the signal to noise
ratio in small devices and in manipulating microscopic electron kinematics
through nano-optical techniques and to applications in thermal detectors and
photothermal photovoltaics.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:10:01 GMT""}]","2021-08-11"
"2002.10277","Yue Qian","Yue Qian, Junhui Hou, Sam Kwong, Ying He","PUGeo-Net: A Geometry-centric Network for 3D Point Cloud Upsampling","17 pages, 10 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the problem of generating uniform dense point clouds to
describe the underlying geometric structures from given sparse point clouds.
Due to the irregular and unordered nature, point cloud densification as a
generative task is challenging. To tackle the challenge, we propose a novel
deep neural network based method, called PUGeo-Net, that learns a $3\times 3$
linear transformation matrix $\bf T$ for each input point. Matrix $\mathbf T$
approximates the augmented Jacobian matrix of a local parameterization and
builds a one-to-one correspondence between the 2D parametric domain and the 3D
tangent plane so that we can lift the adaptively distributed 2D samples (which
are also learned from data) to 3D space. After that, we project the samples to
the curved surface by computing a displacement along the normal of the tangent
plane. PUGeo-Net is fundamentally different from the existing deep learning
methods that are largely motivated by the image super-resolution techniques and
generate new points in the abstract feature space. Thanks to its
geometry-centric nature, PUGeo-Net works well for both CAD models with sharp
features and scanned models with rich geometric details. Moreover, PUGeo-Net
can compute the normal for the original and generated points, which is highly
desired by the surface reconstruction algorithms. Computational results show
that PUGeo-Net, the first neural network that can jointly generate vertex
coordinates and normals, consistently outperforms the state-of-the-art in terms
of accuracy and efficiency for upsampling factor $4\sim 16$.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:13:29 GMT""},{""version"":""v2"",""created"":""Sat, 7 Mar 2020 16:02:05 GMT""}]","2020-03-10"
"2002.10278","Zlil Sela","Koji Fujiwara and Zlil Sela","The rates of growth in a hyperbolic group",,,,,"math.GR math.LO math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the countable set of rates of growth of a hyperbolic group with
respect to all its finite generating sets. We prove that the set is
well-ordered, and that every real number can be the rate of growth of at most
finitely many generating sets up to automorphism of the group. We prove that
the ordinal of the set of rates of growth is at least $\omega^\omega$, and in
case the group is a limit group (e.g., free and surface groups), it is
$\omega^\omega$.
  We further study the rates of growth of all the finitely generated subgroups
of a hyperbolic group with respect to all their finite generating sets. This
set is proved to be well-ordered as well, and every real number can be the rate
of growth of at most finitely many isomorphism classes of finite generating
sets of subgroups of a given hyperbolic group. Finally, we strengthen our
results to include rates of growth of all the finite generating sets of all the
subsemigroups of a hyperbolic group.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:14:32 GMT""},{""version"":""v2"",""created"":""Tue, 7 Mar 2023 07:03:31 GMT""}]","2023-03-08"
"2002.10279","Parham Dehghani","Parham Dehghani, Kourosh Nozari","IR-deformed thermodynamics of quantum bouncers and the issue of
  dimensional reduction","15 pages, 7 figures, 1 table",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We probe the low-temperature behavior of a system of quantum bouncers as a
theoretical model for ultracold neutrons within a low energy modified version
of the standard quantum mechanics, due to the gravitational effects. Working in
one dimension, the energy spectrum and bound states of a deformed quantum
bouncer are obtained using the first-order WKB approximation, granted the very
low energy regime of the particle. In this manner, we can study energy levels
of a system of ultracold neutrons as an informative probe towards exploring the
low energy manifestation of semi-classical quantum gravitational effects. Our
calculated energy levels of ultracold neutrons are in accordance with the
observed energy levels, as obtained in the famous Nesvizhevsky \emph{et al.}
experiment, with a negative constant deformation, as dependent on the
deformation parameter. In advance, we tackle modified thermodynamics of a
system of quantum bouncers in the infrared regime via an ensemble theory both
in one dimension and also three dimensions, to seek for any trace of an
effective, thermodynamic dimensional reduction in this low energy regime of
semi-classical quantum gravity. While the issue of dimensional reduction has
been essentially assigned to the high energy regime, here we show that there is
a trace of an effective, thermodynamic dimensional reduction in infrared regime
with one important difference: in the high energy regime, the dimensional
reduction effectively occurs from $D=3$ to $D=1$, but here, in this low energy
regime, there is a trace of thermodynamic dimensional reduction from $D=3$ to
$D=2$.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:17:09 GMT""},{""version"":""v2"",""created"":""Thu, 30 Apr 2020 20:38:10 GMT""}]","2020-05-04"
"2002.10280","Boris Shapiro","Boris Shapiro and Guillaume Tahar","On existence of quasi-Strebel structures for meromorphic k-differentials","16 tages, 8 figures",,,,"math.AG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, motivated by the classical notion of a Strebel quadratic
differential on a compact Riemann surfaces without boundary we introduce the
notion of a quasi-Strebel structure for a meromorphic differential of an
arbitrary order. It turns out that every differential of even order k exceeding
2 satisfying certain natural conditions at its singular points admits such a
structure. The case of differentials of odd order is quite different and our
existence result involves some arithmetic conditions. We discuss the set of
quasi-Stebel structures associated to a given differential and introduce the
subclass of positive k-differentials. Finally, we provide a family of examples
of positive rational differentials and explain their connection with the
classical Heine-Stieltjes theory of linear differential equations with
polynomial coefficients.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:32:26 GMT""}]","2020-02-25"
"2002.10281","Thorsten Dickhaus","Nico Steffen and Thorsten Dickhaus","Optimizing effective numbers of tests by vine copula modeling",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the multiple testing context, we utilize vine copulae for optimizing the
effective number of tests. It is well known that for the calibration of
multiple tests (for control of the family-wise error rate) the dependencies
between the marginal tests are of utmost importance. It has been shown in
previous work, that positive dependencies between the marginal tests can be
exploited in order to derive a relaxed Sidak-type multiplicity correction. This
correction can conveniently be expressed by calculating the corresponding
""effective number of tests"" for a given (global) significance level. This
methodology can also be applied to blocks of test statistics so that the
effective number of tests can be calculated by the sum of the effective numbers
of tests for each block. In the present work, we demonstrate how the power of
the multiple test can be optimized by taking blocks with high inner-block
dependencies. The determination of those blocks will be performed by means of
an estimated vine copula model. An algorithm is presented which uses the
information of the estimated vine copula to make a data-driven choice of
appropriate blocks in terms of (estimated) dependencies. Numerical experiments
demonstrate the usefulness of the proposed approach.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:34:08 GMT""}]","2020-02-25"
"2002.10282","Marco Padovani","Marco Padovani (1), Alexei V. Ivlev (2), Daniele Galli (1), Stella S.
  R. Offner (3), Nick Indriolo (4), Donna Rodgers-Lee (5), Alexandre Marcowith
  (6), Philipp Girichidis (7), Andrei M. Bykov (8), J. M. Diederik Kruijssen
  (9) ((1) INAF-OAA - Italy, (2) MPE - Germany, (3) U. Texas - USA, (4)
  ALMA-NAOJ-NINS - Japan, (5) U. Dublin - Ireland, (6) LUPM - France, (7) AIP -
  Germany, (8) Ioffe Institute - Russian Federation, (9) ARI-ZAH - Germany)","Impact of low-energy cosmic rays on star formation","Submitted to Space Science Reviews topical collection Star formation",,"10.1007/s11214-020-00654-1",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, exciting developments have taken place in the identification
of the role of cosmic rays in star-forming environments. Observations from
radio to infrared wavelengths and theoretical modelling have shown that
low-energy cosmic rays (<1 TeV) play a fundamental role in shaping the chemical
richness of the interstellar medium, determining the dynamical evolution of
molecular clouds. In this review we summarise in a coherent picture the main
results obtained by observations and by theoretical models of propagation and
generation of cosmic rays, from the smallest scales of protostars and
circumstellar discs, to young stellar clusters, up to Galactic and
extragalactic scales. We also discuss the new fields that will be explored in
the near future thanks to new generation instruments, such as: CTA, for the
$\gamma$-ray emission from high-mass protostars; SKA and precursors, for the
synchrotron emission at different scales; and ELT/HIRES, JWST, and ARIEL, for
the impact of cosmic rays on exoplanetary atmospheres and habitability.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:34:47 GMT""}]","2020-03-12"
"2002.10283","Sven Hertling","Sven Hertling, Heiko Paulheim","The Knowledge Graph Track at OAEI -- Gold Standards, Baselines, and the
  Golden Hammer Bias",,,,,"cs.DB cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Ontology Alignment Evaluation Initiative (OAEI) is an annual evaluation
of ontology matching tools. In 2018, we have started the Knowledge Graph track,
whose goal is to evaluate the simultaneous matching of entities and schemas of
large-scale knowledge graphs. In this paper, we discuss the design of the track
and two different strategies of gold standard creation. We analyze results and
experiences obtained in first editions of the track, and, by revealing a hidden
task, we show that all tools submitted to the track (and probably also to other
tracks) suffer from a bias which we name the golden hammer bias.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:35:02 GMT""}]","2020-02-25"
"2002.10285","Alexander Spies","Alexander Spies","Poisson-geometric analogues of Kitaev models","49 pages. v2: Revised Lemma 3.17 (i). v3: Revised introduction; fixed
  oversight in proof of Theorem 3.29; improved Remark 3.11; fixed typos and
  improved wording in several places","Commun. Math. Phys. 383(1) (2021) 345-400","10.1007/s00220-021-03992-5",,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define Poisson-geometric analogues of Kitaev's lattice models. They are
obtained from a Kitaev model on an embedded graph $\Gamma$ by replacing its
Hopf algebraic data with Poisson data for a Poisson-Lie group G.
  Each edge is assigned a copy of the Heisenberg double $\mathcal H(G)$. Each
vertex (face) of $\Gamma$ defines a Poisson action of $G$ (of $G^*$) on the
product of these Heisenberg doubles. The actions for a vertex and adjacent face
form a Poisson action of the double Poisson-Lie group $D(G)$. We define Poisson
counterparts of vertex and face operators and relate them via the Poisson
bracket to the vector fields generating the actions of $D(G)$.
  We construct an isomorphism of Poisson $D(G)$-spaces between this
Poisson-geometrical Kitaev model and Fock and Rosly's Poisson structure for the
graph $\Gamma$ and the Poisson-Lie group $D(G)$. This decouples the latter and
represents it as a product of Heisenberg doubles. It also relates the
Poisson-geometrical Kitaev model to the symplectic structure on the moduli
space of flat $D(G)$-bundles on an oriented surface with boundary constructed
from $\Gamma$.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:38:21 GMT""},{""version"":""v2"",""created"":""Mon, 9 Mar 2020 09:37:51 GMT""},{""version"":""v3"",""created"":""Mon, 23 Nov 2020 16:11:03 GMT""}]","2021-03-30"
"2002.10286","Idan Amir","Idan Amir, Idan Attias, Tomer Koren, Roi Livni, Yishay Mansour","Prediction with Corrupted Expert Advice","NeurIPS 2020 Camera Ready","Conference on Neural Information Processing Systems 2020",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the fundamental problem of prediction with expert advice, in a
setting where the environment is benign and generates losses stochastically,
but the feedback observed by the learner is subject to a moderate adversarial
corruption. We prove that a variant of the classical Multiplicative Weights
algorithm with decreasing step sizes achieves constant regret in this setting
and performs optimally in a wide range of environments, regardless of the
magnitude of the injected corruption. Our results reveal a surprising disparity
between the often comparable Follow the Regularized Leader (FTRL) and Online
Mirror Descent (OMD) frameworks: we show that for experts in the corrupted
stochastic regime, the regret performance of OMD is in fact strictly inferior
to that of FTRL.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:39:55 GMT""},{""version"":""v2"",""created"":""Tue, 20 Oct 2020 20:17:11 GMT""}]","2021-07-05"
"2002.10287","Olivier Berne","Olivier Bern\'e, Alexia Hilaire","Inequalities faced by women in access to permanent positions in
  astronomy in France",,"Nature astronomy, 4, 296-298, 2020","10.1038/s41550-020-1068-5",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate inequalities in access to permanent positions in professional
astronomy in France, focusing on the hiring stage. We use results from a
national survey conducted on behalf of the French society of astronomy and
astrophysics (SF2A) aimed at young astronomers holding a PhD obtained in
France, and answered by over 300 researchers. We find that women are nearly two
times less likely than men to be selected by the (national or local) committees
attributing permanent positions ($p=0.06$). We also find that applicants who
did their undergraduate studies in an elite school (""Grande \'Ecole""), where
women are largely under-represented, rather than in a university, are nearly
three times more likely to succeed in obtaining a position ($p=0.0026$). Our
analysis suggests the existence of two biases in committees attributing
permanent positions in astronomy in France: a gender bias, and a form of
elitism. These biases against women in their professional life impacts their
personal life as our survey shows that a larger fraction of them declare that
having children can have a negative effect on their careers. They are half as
many as men having children in the sample. National committees (such as the
CNRS) have acknowledged this issue for several years now, hence one can hope
that changes will be seen in the next decade.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:40:00 GMT""},{""version"":""v2"",""created"":""Tue, 14 Apr 2020 08:24:22 GMT""},{""version"":""v3"",""created"":""Sat, 23 Jan 2021 13:11:18 GMT""}]","2021-01-26"
"2002.10289","Alberto Sonnino","Zhiyi Zhang, Micha{\l} Kr\'ol, Alberto Sonnino, Lixia Zhang, Etienne
  Rivi\`ere","EL PASSO: Privacy-preserving, Asynchronous Single Sign-On",,"Privacy Enhancing Technologies Symposium (PETS); 2021 (2): 70-87","10.2478/popets-2021-0018",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce EL PASSO, a privacy-preserving, asynchronous Single Sign-On
(SSO) system. It enables personal authentication while protecting users'
privacy against both identity providers and relying parties, and allows
selective attribute disclosure. EL PASSO is based on anonymous credentials, yet
it supports users' accountability. Selected authorities may recover the
identity of allegedly misbehaving users, and users can prove properties about
their identity without revealing it in the clear. EL PASSO does not require
specific secure hardware or a third party (other than existing participants in
SSO). The generation and use of authentication credentials are asynchronous,
allowing users to sign on when identity providers are temporarily unavailable.
We evaluate EL PASSO in a distributed environment and prove its low
computational cost, yielding faster sign-on operations than OIDC from a regular
laptop, one-second user-perceived latency from a low-power device, and scaling
to more than 50 sign-on operations per second at a relying party using a single
4-core server in the cloud.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:40:48 GMT""},{""version"":""v2"",""created"":""Wed, 3 Jun 2020 08:49:21 GMT""}]","2021-06-15"
"2002.10290","Alessandro Pastore","Marco Carnini and Alessandro Pastore","Trees and Forests in Nuclear Physics",,,"10.1088/1361-6471/ab92e3",,"nucl-th cs.LG nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a simple introduction to the decision tree algorithm using some
examples from nuclear physics. We show how to improve the accuracy of the
classical liquid drop nuclear mass model by performing Feature Engineering with
a decision tree. Finally, we apply the method to the Duflo-Zuker model showing
that, despite their simplicity, decision trees are capable of improving the
description of nuclear masses using a limited number of free parameters.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:47:33 GMT""},{""version"":""v2"",""created"":""Thu, 7 May 2020 12:55:26 GMT""}]","2020-08-26"
"2002.10292","Parna Sabeti","Parna Sabeti, Arman Farhang, Irene Macaluso, Nicola Marchetti and
  Linda Doyle","Blind Channel Estimation for Massive MIMO: A Deep Learning Assisted
  Approach","6 pages and 4 figures",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large scale multiple-input multiple-output (MIMO) or Massive MIMO is one of
the pivotal technologies for future wireless networks. However, the performance
of massive MIMO systems heavily relies on accurate channel estimation. While
the acquisition of channel state information (CSI) in such systems requires an
increasingly large amount of training overhead as the number of users grows. To
tackle this issue, in this paper, we propose a deep learning assisted blind
channel estimation technique for orthogonal frequency division multiplexing
(OFDM) based massive MIMO systems. We prove that by exploiting the asymptotic
orthogonality of the massive MIMO channels, the channel distortion can be
averaged out without the prior knowledge of channel impulse responses, and
after some mathematical manipulation, different users transmitted data symbols
can be extracted. Thus, by deploying a denoising convolutional neural network
algorithm (DnCNN), we mitigate a remaining channel and noise effect to
accurately detect the transmitted data symbols at the channel sounding stage.
Using the detected data symbols as virtual pilots, we estimate the CSI of all
the users at each BS antennas. Our simulation results testify the efficacy of
our proposed technique and demonstrate that it can provide a mean square error
(MSE) performance which coincides with that of the data-aided channel
estimation technique.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:49:19 GMT""}]","2020-02-25"
"2002.10293","T. H. Lenagan","T H Lenagan and L Rigal","Generalised quantum determinantal rings are maximal orders","14 pages",,,,"math.QA math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalised quantum determinantal rings are the analogue in quantum matrices
of Schubert varieties. Maximal orders are the noncommutative version of
integrally closed rings. In this paper, we show that generalised quantum
determinantal rings are maximal orders. The cornerstone of the proof is a
description of generalised quantum determinantal rings, up to a localisation,
as skew polynomial extensions.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:52:58 GMT""}]","2020-02-25"
"2002.10294","Fateh Boucenna","Fateh Boucenna","Semantic, Efficient, and Secure Search over Encrypted Cloud Data","180 pages, PhD Thesis, University of Sciences and Technology Houari
  Boumediene (USTHB) Algiers Algeria, searchable encryption, cloud computing,
  semantic search, homomorphic encryption, data privacy, weighting formula",,,"01/2020-D/INF","cs.CR cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Companies and individuals demand more and more storage space and computing
power. For this purpose, several new technologies have been designed and
implemented, such as the cloud computing. This technology provides its users
with storage space and computing power according to their needs in a flexible
and personalized way. However, the outsourced data such as emails, electronic
health records, and company reports are sensitive and confidential. Therefore,
It is primordial to protect the outsourced data against possible external
attacks and the cloud server itself. That is why it is highly recommended to
encrypt the sensitive data before being outsourced to a remote server. To
perform searches over outsourced data, it is no longer possible to exploit
traditional search engines given that these data are encrypted. Consequently,
lots of searchable encryption (SE) schemes have been proposed in the
literature. Three major research axes of searchable encryption area have been
studied in the literature. The first axis consists in ensuring the security of
the search approach. Indeed, the search process should be performed without
decryption any data and without causing any sensitive information leakage. The
second axis consists in studying the search performance. In fact, the encrypted
indexes are less efficient than the plaintext indexes, which makes the
searchable encryption schemes very slow in practice. More the approach is
secure, less it is efficient, thus, the challenge consists in finding the best
compromise between security and performance. Finally, the third research axis
consists in the quality of the returned results in terms of relevance and
recall. The problem is that the encryption of the index causes the degradation
of the recall and the precision. Therefore, the goal is to propose a technique
that is able to obtain almost the same result obtained in the traditional
search.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:53:57 GMT""}]","2020-02-25"
"2002.10295","David P\""atzel","Michael Heider and David P\""atzel and J\""org H\""ahner","SupRB: A Supervised Rule-based Learning System for Continuous Problems","Submitted to the Genetic and Evolutionary Computation Conference 2020
  (GECCO 2020)",,,,"cs.LG cs.AI cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose the SupRB learning system, a new Pittsburgh-style learning
classifier system (LCS) for supervised learning on multi-dimensional continuous
decision problems. SupRB learns an approximation of a quality function from
examples (consisting of situations, choices and associated qualities) and is
then able to make an optimal choice as well as predict the quality of a choice
in a given situation. One area of application for SupRB is parametrization of
industrial machinery. In this field, acceptance of the recommendations of
machine learning systems is highly reliant on operators' trust. While an
essential and much-researched ingredient for that trust is prediction quality,
it seems that this alone is not enough. At least as important is a
human-understandable explanation of the reasoning behind a recommendation.
While many state-of-the-art methods such as artificial neural networks fall
short of this, LCSs such as SupRB provide human-readable rules that can be
understood very easily. The prevalent LCSs are not directly applicable to this
problem as they lack support for continuous choices. This paper lays the
foundations for SupRB and shows its general applicability on a simplified model
of an additive manufacturing problem.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:54:54 GMT""}]","2020-02-25"
"2002.10296","Bal\'azs Gul\'acsi","Bal\'azs Gul\'acsi, Markus Heyl and Bal\'azs D\'ora","Geometrical quench and dynamical quantum phase transition in the
  $\alpha-T_3$ lattice","8 pages, 4 figures","Phys. Rev. B 101, 205135 (2020)","10.1103/PhysRevB.101.205135",,"cond-mat.quant-gas cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate quantum quenches and the Loschmidt echo in the two
dimensional, three band $\alpha-T_3$ model, a close descendant of the dice
lattice. By adding a chemical potential to the central site, the integral of
the Berry curvature of the bands in different valleys is continously tunable by
the ratio of the hopping integrals between the sublattices. By investigating
one and two filled bands, we find that dynamical quantum phase transition
(DQPT), i.e. nonanalytical temporal behaviour in the rate function of the
return amplitude, occurs for a certain range of parameters, independent of the
band filling. By focusing on the effective low energy description of the model,
we find that DQPTs happen not only in the time derivative of the rate function,
which is a common feature in two dimensional models, but in the rate function
itself. This feature is not related to the change of topological properties of
the system during the quench, but rather follows from population inversion for
all momenta. This is accompanied by the appearance of dynamical vortices in the
time-momentum space of the Pancharatnam geometric phase. The positions of the
vortices form an infinite vortex ladder, i.e. a macroscopic phase structure,
which allows us to identify the dynamical phases that are separated by the
DQPT.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:57:00 GMT""},{""version"":""v2"",""created"":""Tue, 28 Apr 2020 07:26:13 GMT""}]","2020-05-27"
"2002.10297","Yachin Ivry Prof.","Mohammad Suleiman, Emanuele G. Dalla Torre and Yachin Ivry","Flexible Amorphous Superconducting Materials and Quantum Devices with
  Unexpected Tunability","25 pages, 14 figures, 3 tables",,,,"cond-mat.supr-con cond-mat.mes-hall cond-mat.mtrl-sci quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In superconductivity, electrons exhibit unique macroscopic collective quantum
behavior that is the key for many modern quantum technologies. This electron
behavior stems vastly from coupling to a correlated motion of atoms in the
material, as well as from synchronized directional movement that screens
external magnetic fields perfectly. Hence, the inter-atomic distance and
material geometry are expected to affect fundamental superconductive
characteristics. These parameters are tunable with strain, but strain
application is hindered by the rigidity of superconductors, which in turn
increases at device-relevant temperatures. Here, we present flexible, foldable
and transferable superconducting materials, and functional quantum
nanostructures by depositing superconductive amorphous-alloy films on a
flexible adhesive tape. Specifically, flexible superconducting films, nanowires
and quantum interference devices (SQUIDs) were fabricated and characterized
under variable magnetic-field, current, temperature and flexure conditions. The
SQUID interference periodicity, which represents a single flux quantum,
exhibits unexpected tunability with folding curvature. This tunability raises a
need for a relook at the fundamentals of superconductivity, mainly with respect
to effects of geometry, magnetic-field inhomogeneity and strain. Our work paves
the way for novel magnetic devices and quantum-technology platforms with local
tunability.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:58:37 GMT""},{""version"":""v2"",""created"":""Thu, 19 Mar 2020 13:02:06 GMT""}]","2020-03-20"
"2002.10298","Bo Li","Bo Li and David Saad and Andrey Y. Lokhov","Reducing urban traffic congestion due to localized routing decisions",,"Phys. Rev. Research 2, 032059 (2020)","10.1103/PhysRevResearch.2.032059",,"physics.soc-ph math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Balancing traffic flow by influencing drivers' route choices to alleviate
congestion is becoming increasingly more appealing in urban traffic planning.
Here, we introduce a discrete dynamical model comprising users who make their
own routing choices on the basis of local information and those who consider
routing advice based on localized inducement. We identify the formation of
traffic patterns, develop a scalable optimization method for identifying
control values used for user guidance, and test the effectiveness of these
measures on synthetic and real-world road networks.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:58:39 GMT""},{""version"":""v2"",""created"":""Thu, 3 Sep 2020 20:58:25 GMT""}]","2020-09-09"
"2002.10299","Nicol\`o Maccaferri","Joel Kuttruff, Denis Garoli, Jonas Allerbeck, Roman Krahne, Antonio De
  Luca, Daniele Brida, Vincenzo Caligiuri and Nicol\`o Maccaferri","Ultrafast all-optical switching enabled by epsilon-near-zero modes in
  metal-insulator nanocavities",,,"10.1038/s42005-020-0379-2",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Ultrafast control of light-matter interactions constitutes a crucial feature
in view of new technological frontiers of information processing. However,
conventional optical elements are either static or feature switching speeds
that are extremely low with respect to the timescales at which it is possible
to control light. Here, we exploit high-quality-factor engineered
epsilon-near-zero (ENZ) modes of a metal-insulator-metal nanocavity to realize
an all-optical ultrafast modulation of the reflectance of light at a tailored
wavelength. Our approach is based on the presence of the two, spectrally
separated, ENZ absorption resonances of the cavity. Optical pumping of the
system at its high energy ENZ mode leads to a strong red-shift of the low
energy mode because of the transient increase of the local dielectric function,
which leads to a sub-3-ps control of the reflectance at a specific wavelength
with a relative modulation depth approaching 120%.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:04:40 GMT""},{""version"":""v2"",""created"":""Tue, 24 Mar 2020 14:31:42 GMT""},{""version"":""v3"",""created"":""Fri, 24 Apr 2020 08:56:39 GMT""}]","2020-10-01"
"2002.10300","Fran\c{c}ois Legrand","Gil Alon, Fran\c{c}ois Legrand, Elad Paran","Galois groups over rational function fields over skew fields",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $H$ be a skew field of finite dimension over its center $k$. We solve the
Inverse Galois Problem over the field of fractions $H(X)$ of the ring of
polynomial functions over $H$ in the variable $X$, if $k$ contains an ample
field.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:10:39 GMT""}]","2020-02-25"
"2002.10301","Adithya M Devraj","Adithya M. Devraj and Sean P. Meyn","Q-learning with Uniformly Bounded Variance: Large Discounting is Not a
  Barrier to Fast Learning","33 pages, 4 figures",,,,"cs.LG cs.SY eess.SY stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sample complexity bounds are a common performance metric in the Reinforcement
Learning literature. In the discounted cost, infinite horizon setting, all of
the known bounds have a factor that is a polynomial in $1/(1-\gamma)$, where
$\gamma < 1$ is the discount factor. For a large discount factor, these bounds
seem to imply that a very large number of samples is required to achieve an
$\varepsilon$-optimal policy. The objective of the present work is to introduce
a new class of algorithms that have sample complexity uniformly bounded for all
$\gamma < 1$. One may argue that this is impossible, due to a recent min-max
lower bound. The explanation is that this previous lower bound is for a
specific problem, which we modify, without compromising the ultimate objective
of obtaining an $\varepsilon$-optimal policy. Specifically, we show that the
asymptotic covariance of the Q-learning algorithm with an optimized step-size
sequence is a quadratic function of $1/(1-\gamma)$; an expected, and
essentially known result. The new relative Q-learning algorithm proposed here
is shown to have asymptotic covariance that is a quadratic in $1/(1- \rho^*
\gamma)$, where $1 - \rho^* > 0$ is an upper bound on the spectral gap of an
optimal transition matrix.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:12:41 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 21:58:23 GMT""}]","2020-07-09"
"2002.10302","Xiang Xu Dr.","Yu Chen, Jin Cheng, Xiaoying Jiang and Xiang Xu","The Reconstruction and Prediction Algorithm of the Fractional TDD for
  the Local Outbreak of COVID-19",,,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  From late December, 2019, the novel Corona-Virus began to spread in the
mainland of China. For predicting the trend of the Corona Virus spread, several
time delay dynamic systems (TDD) are proposed. In this paper, we establish a
novel fractional time delay dynamic system (FTDD) to describe the local
outbreak of COVID-19. The fractional derivative is introduced to account for
the sub-diffusion process of the confirmed and cured peoples growth. Based on
the public health data by the government, we propose a stable reconstruction
algorithm of the coefficients. The reconstructed coefficients are used to
predict the trend of the Corona-Virus. The numerical results are in good
agreement with the public data.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:14:17 GMT""}]","2020-02-25"
"2002.10303","Giovanna D'Agostino","Jarno Alanko and Giovanna D'Agostino and Alberto Policriti and Nicola
  Prezza","Wheeler Languages",,,,,"cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recently introduced class of Wheeler graphs, inspired by the
Burrows-Wheeler Transform (BWT) of a given string, admits an efficient index
data structure for searching for subpaths with a given path label, and lifts
the applicability of the Burrows-Wheeler transform from strings to languages.
In this paper we study the regular languages accepted by automata having a
Wheeler graph as transition function, and prove results on determination,
Myhill_Nerode characterization, decidability, and closure properties for this
class of languages.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:20:33 GMT""}]","2020-02-25"
"2002.10304","Bruno Grenet","Pascal Giorgi, Bruno Grenet, Daniel S. Roche","Fast In-place Algorithms for Polynomial Operations: Division,
  Evaluation, Interpolation",,"Proc. ISSAC'20, pp 210-217, ACM, 2020","10.1145/3373207.3404061",,"cs.SC cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider space-saving versions of several important operations on
univariate polynomials, namely power series inversion and division, division
with remainder, multi-point evaluation, and interpolation. Now-classical
results show that such problems can be solved in (nearly) the same asymptotic
time as fast polynomial multiplication. However, these reductions, even when
applied to an in-place variant of fast polynomial multiplication, yield
algorithms which require at least a linear amount of extra space for
intermediate results. We demonstrate new in-place algorithms for the
aforementioned polynomial computations which require only constant extra space
and achieve the same asymptotic running time as their out-of-place
counterparts. We also provide a precise complexity analysis so that all
constants are made explicit, parameterized by the space usage of the underlying
multiplication algorithms.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:27:58 GMT""},{""version"":""v2"",""created"":""Thu, 14 May 2020 16:08:18 GMT""},{""version"":""v3"",""created"":""Tue, 9 Jun 2020 13:04:27 GMT""}]","2020-09-01"
"2002.10305","Bhupendra Karki","B. Karki, A. Alfailakawi, Benjamin A. Frandsen, M. S. Everett, J. C.
  Neuefeind, Binjie Xu, Hangdong Wang, Minghu Fang, B. Freelon","Local Structure of Mott Insulating Iron Oxychalcogenides
  La$_{2}$O$_{2}$Fe$_{2}$O$M$$_{2}$ ($M$ = S, Se)",,"Phys. Rev. B 104, 064101 (2021)","10.1103/PhysRevB.104.064101",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the local structural properties of the iron oxychalcogenides,
La$_2$O$_2$Fe$_2$O$M_2$ ($M$ = S, Se), by using pair distribution function
(PDF) analysis applied to total scattering data. Our results of neutron powder
diffraction show that $M$ = S and Se possess similar nuclear structure at low
and room temperatures. The local crystal structures were studied by
investigating deviations in atomic positions and the extent of the formation of
orthorhombicity. Analysis of the total scattering data suggests that buckling
of the Fe$_2$O plane occurs below 100 K. The buckling may occur concomitantly
with a change in octahedral height. Furthermore, within a typical range of 1-2
nm, we observed short-range orthorhombic-like structure suggestive of nematic
fluctuations in both of these materials.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:30:37 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jul 2021 03:04:21 GMT""}]","2021-08-11"
"2002.10306","Indro Spinelli","Indro Spinelli, Simone Scardapane, Aurelio Uncini","Adaptive Propagation Graph Convolutional Network","Published in IEEE Transaction on Neural Networks and Learning Systems","IEEE Transactions on Neural Networks and Learning Systems, 2020","10.1109/TNNLS.2020.3025110",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph convolutional networks (GCNs) are a family of neural network models
that perform inference on graph data by interleaving vertex-wise operations and
message-passing exchanges across nodes. Concerning the latter, two key
questions arise: (i) how to design a differentiable exchange protocol (e.g., a
1-hop Laplacian smoothing in the original GCN), and (ii) how to characterize
the trade-off in complexity with respect to the local updates. In this paper,
we show that state-of-the-art results can be achieved by adapting the number of
communication steps independently at every node. In particular, we endow each
node with a halting unit (inspired by Graves' adaptive computation time) that
after every exchange decides whether to continue communicating or not. We show
that the proposed adaptive propagation GCN (AP-GCN) achieves superior or
similar results to the best proposed models so far on a number of benchmarks,
while requiring a small overhead in terms of additional parameters. We also
investigate a regularization term to enforce an explicit trade-off between
communication and accuracy. The code for the AP-GCN experiments is released as
an open-source library.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:31:16 GMT""},{""version"":""v2"",""created"":""Mon, 15 Jun 2020 18:28:25 GMT""},{""version"":""v3"",""created"":""Mon, 28 Sep 2020 09:28:34 GMT""}]","2020-09-29"
"2002.10307","Giovanni Comoretto","Gianni Comoretto, Riccardo Chiello, Matt Roberts, Rob Halsall,
  Kristian Zarb Adami, Monica Alderighi, Amin Aminaei, Jeremy Baker, Carolina
  Belli, Simone Chiarucci, Sergio D'Angelo, Andrea De Marco, Gabriele Dalle
  Mura, Alessio Magro, Andrea Mattana, Jader Monari, Giovanni Naldi, Sandro
  Pastore, Federico Perini, Marco Poloni, Giuseppe Pupillo, Simone Rusticelli,
  Marco Schiaffino, Francesco Schillir\`o, Emanuele Zaccaro","Signal Processing Firmware for the Low Frequency Aperture Array","19 pages","Journal of Astronomical Instrumentation, Vol. 06, No. 01, 1641015
  (2017)","10.1142/S2251171716410154",,"astro-ph.IM physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The signal processing firmware that has been developed for the Low Frequency
Aperture Array component of the Square Kilometre Array is described. The
firmware is implemented on a dual FPGA board, that is capable of processing the
streams from 16 dual polarization antennas. Data processing includes
channelization of the sampled data for each antenna, correction for
instrumental response and for geometric delays and formation of one or more
beams by combining the aligned streams. The channelizer uses an oversampling
polyphase filterbank architecture, allowing a frequency continuous processing
of the input signal without discontinuities between spectral channels. Each
board processes the streams from 16 antennas, as part of larger beamforming
system, linked by standard Ethernet interconnections. There are envisaged to be
8192 of these signal processing platforms in the first phase of the Square
Kilometre array so particular attention has been devoted to ensure the design
is low cost and low power.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:32:52 GMT""}]","2020-02-25"
"2002.10308","Roman Kezerashvili","S. B. Dubovichenko, R. Ya. Kezerashvili, N. A. Burkova, A. V.
  Dzhazairov-Kakhramanov, and B. Beisenov","Reanalysis of $^{13}$N($p,\gamma $)$^{14}$O reaction and its role in
  stellar CNO cycle","19 pages, 8 figures","Phys. Rev. C 102, 045805","10.1103/PhysRevC.102.045805",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the framework of the modified potential cluster model with forbidden
states, the $^{13}$N($p,\gamma $)$^{14}$O reaction rate and the astrophysical
$S$-factor are considered. It is shown that the first $p^{13}$% N resonance
determines the $S$-factor and contributions of the $M1$ and $E2$ transitions
are negligible at energies $E<1$ MeV, but are significant at high energies. The
$S$-factor strongly depends on the $^{3}S_{1}$ resonance parameters. The
influence of the width of \ the $^{3}S_{1}$ resonance on $S$% -factor is
demonstrated. The reaction rate is calculated and an analytical approximation
for the reaction rate is proposed. A comparison of our calculation with
existing data is addressed. Results of our calculations for the
$^{13}$N($p,\gamma )^{14}$O reaction rate provide the contribution to the
steadily improving reaction rate database libraries. Our calculations of the $%
^{13}$N($p,\gamma )^{14}$O reaction rate along with results for the rates of
$^{14}$N($% p,\gamma )^{15}$O and $^{12}$C$(p,\gamma )^{13}$N processes provide
the temperature range $0.13<T_{9}<0.97$ for the conversion of CNO cycle to the
HCNO cycle. Our results demonstrate that at early stages of a nova explosion at
temperatures about $0.1$ $T_{9}$ and at late stages of evolution of
supermassive stars at temperatures about $1.0$ $T_{9}$ the ignition of the HCNO
cycle could occur at much lower densities of a stellar medium.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:35:16 GMT""},{""version"":""v2"",""created"":""Mon, 10 Aug 2020 14:54:24 GMT""}]","2020-10-19"
"2002.10310","Ayan Kumar Bhunia","Ayan Kumar Bhunia, Yongxin Yang, Timothy M. Hospedales, Tao Xiang,
  Yi-Zhe Song","Sketch Less for More: On-the-Fly Fine-Grained Sketch Based Image
  Retrieval","IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2020
  [Oral Presentation] Code:
  https://github.com/AyanKumarBhunia/on-the-fly-FGSBIR",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fine-grained sketch-based image retrieval (FG-SBIR) addresses the problem of
retrieving a particular photo instance given a user's query sketch. Its
widespread applicability is however hindered by the fact that drawing a sketch
takes time, and most people struggle to draw a complete and faithful sketch. In
this paper, we reformulate the conventional FG-SBIR framework to tackle these
challenges, with the ultimate goal of retrieving the target photo with the
least number of strokes possible. We further propose an on-the-fly design that
starts retrieving as soon as the user starts drawing. To accomplish this, we
devise a reinforcement learning-based cross-modal retrieval framework that
directly optimizes rank of the ground-truth photo over a complete sketch
drawing episode. Additionally, we introduce a novel reward scheme that
circumvents the problems related to irrelevant sketch strokes, and thus
provides us with a more consistent rank list during the retrieval. We achieve
superior early-retrieval efficiency over state-of-the-art methods and
alternative baselines on two publicly available fine-grained sketch retrieval
datasets.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:36:02 GMT""},{""version"":""v2"",""created"":""Thu, 5 Mar 2020 15:23:37 GMT""},{""version"":""v3"",""created"":""Sat, 11 Apr 2020 17:54:10 GMT""},{""version"":""v4"",""created"":""Mon, 11 May 2020 18:32:08 GMT""}]","2020-05-13"
"2002.10311","Chih-Whi Chen","Chih-Whi Chen, Yung-Ning Peng","Parabolic category $\mathcal O^{\mathfrak p}$ for periplectic Lie
  superalgebras $\mathfrak{pe}(n)$","v2, 25 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a linkage principle in an arbitrary parabolic category $\mathcal
O^{\mathfrak p}$ for the periplectic Lie superalgebras $\mathfrak{pe}(n)$. As
an application, we classify indecomposable blocks in $\mathcal O^{\mathfrak
p}$. We classify indecomposable tilting modules in $\mathcal O^{\mathfrak p}$
whose characters are controlled by the Kazhdan-Lusztig polynomials of type $\bf
A$ Lie algebras. We establish the complete list of characters of indecomposable
tilting modules in $\mathcal O^{\mathfrak p}$ for $\mathfrak{pe}(3)$.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:36:03 GMT""},{""version"":""v2"",""created"":""Fri, 6 Mar 2020 09:37:55 GMT""}]","2020-03-09"
"2002.10312","Anian Ruoss","Anian Ruoss, Mislav Balunovi\'c, Marc Fischer, and Martin Vechev","Learning Certified Individually Fair Representations","Conference Paper at NeurIPS 2020",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fair representation learning provides an effective way of enforcing fairness
constraints without compromising utility for downstream users. A desirable
family of such fairness constraints, each requiring similar treatment for
similar individuals, is known as individual fairness. In this work, we
introduce the first method that enables data consumers to obtain certificates
of individual fairness for existing and new data points. The key idea is to map
similar individuals to close latent representations and leverage this latent
proximity to certify individual fairness. That is, our method enables the data
producer to learn and certify a representation where for a data point all
similar individuals are at $\ell_\infty$-distance at most $\epsilon$, thus
allowing data consumers to certify individual fairness by proving
$\epsilon$-robustness of their classifier. Our experimental evaluation on five
real-world datasets and several fairness constraints demonstrates the
expressivity and scalability of our approach.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:41:34 GMT""},{""version"":""v2"",""created"":""Sat, 28 Nov 2020 18:17:25 GMT""}]","2020-12-01"
"2002.10313","Maria Karyda","Maria Karyda, Merja Ry\""oppy, Jacob Buur and Andr\'es Lucero","Imagining Data-Objects for Reflective Self-Tracking",,,,,"cs.HC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  While self-tracking data is typically captured real-time in a lived
experience, the data is often stored in a manner detached from the context
where it belongs. Research has shown that there is a potential to enhance
people's lived experiences with data-objects (artifacts representing
contextually relevant data), for individual and collective reflections through
a physical portrayal of data. This paper expands that research by studying how
to design contextually relevant data-objects based on people's needs. We
conducted a participatory research project with five households using object
theater as a core method to encourage participants to speculate upon
combinations of meaningful objects and personal data archives. In this paper,
we detail three aspects that seem relevant for designing data-objects: social
sharing, contextual ambiguity and interaction with the body. We show how an
experience-centric view on data-objects can contribute with the contextual,
social and bodily interplay between people, data and objects.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:42:28 GMT""}]","2020-02-25"
"2002.10314","Anne Wijffels","Joeri Van der Veken and Anne Wijffels","Lagrangian submanifolds of the complex hyperbolic quadric",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the complex hyperbolic quadric ${Q^*}^n$ as a complex
hypersurface of complex anti-de Sitter space. Shape operators of this
submanifold give rise to a family of local almost product structures on
${Q^*}^n$, which are then used to define local angle functions on any
Lagrangian submanifold of ${Q^*}^n$. We prove that a Lagrangian immersion into
${Q^*}^n$ can be seen as the Gauss map of a spacelike hypersurface of (real)
anti-de Sitter space and relate the angle functions to the principal curvatures
of this hypersurface. We also give a formula relating the mean curvature of the
Lagrangian immersion to these principal curvatures. The theorems are
illustrated with several examples of spacelike hypersurfaces of anti-de Sitter
space and their Gauss maps. Finally, we classify some families of minimal
Lagrangian submanifolds of ${Q^*}^n$: those with parallel second fundamental
form and those for which the induced sectional curvature is constant. In both
cases, the Lagrangian submanifold is forced to be totally geodesic.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:42:31 GMT""}]","2020-02-25"
"2002.10315","Rafael Potrie","Thomas Barthelm\'e, Sergio Fenley, Steven Frankel, Rafael Potrie","Dynamical incoherence for a large class of partially hyperbolic
  diffeomorphisms","18 pages, 1 figure",,,,"math.DS math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that if a partially hyperbolic diffeomorphism of a Seifert manifold
induces a map in the base which has a pseudo-Anosov component then it cannot be
dynamically coherent. This extends work of Bonatti, Gogolev, Hammerlindl and
Potrie to the whole isotopy class. We relate the techniques with the study of
certain partially hyperbolic diffeomorphisms in hyperbolic 3-manifolds
performed in the previous paper by the authors. The appendix reviews some
consequences of the Nielsen-Thurston classification of surface homeomorphisms
to the dynamics of lifts of such maps to the universal cover.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:42:34 GMT""}]","2020-02-25"
"2002.10316","Wei Tang","Wei Tang, Chien-Ju Ho, Yang Liu","Bandit Learning with Delayed Impact of Actions",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a stochastic multi-armed bandit (MAB) problem with delayed impact
of actions. In our setting, actions taken in the past impact the arm rewards in
the subsequent future. This delayed impact of actions is prevalent in the real
world. For example, the capability to pay back a loan for people in a certain
social group might depend on historically how frequently that group has been
approved loan applications. If banks keep rejecting loan applications to people
in a disadvantaged group, it could create a feedback loop and further damage
the chance of getting loans for people in that group. In this paper, we
formulate this delayed and long-term impact of actions within the context of
multi-armed bandits. We generalize the bandit setting to encode the dependency
of this ""bias"" due to the action history during learning. The goal is to
maximize the collected utilities over time while taking into account the
dynamics created by the delayed impacts of historical actions. We propose an
algorithm that achieves a regret of $\tilde{\mathcal{O}}(KT^{2/3})$ and show a
matching regret lower bound of $\Omega(KT^{2/3})$, where $K$ is the number of
arms and $T$ is the learning horizon. Our results complement the bandit
literature by adding techniques to deal with actions with long-term impacts and
have implications in designing fair algorithms.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:43:03 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 17:13:13 GMT""},{""version"":""v3"",""created"":""Fri, 19 Feb 2021 19:28:48 GMT""},{""version"":""v4"",""created"":""Sun, 31 Oct 2021 17:56:24 GMT""}]","2021-11-02"
"2002.10318","Guy C. David","Guy C. David and Raanan Schul","Quantitative decompositions of Lipschitz mappings into metric spaces","53 pages, 1 figure. This version adds an important reference to a
  paper of David-Semmes that we previously overlooked. Remark 1.11 explains
  further",,,,"math.MG math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the quantitative properties of Lipschitz mappings from Euclidean
spaces into metric spaces. We prove that it is always possible to decompose the
domain of such a mapping into pieces on which the mapping ""behaves like a
projection mapping"" along with a ""garbage set"" that is arbitrarily small in an
appropriate sense. Moreover, our control is quantitative, i.e., independent of
both the particular mapping and the metric space it maps into. This improves a
theorem of Azzam-Schul from the paper ""Hard Sard"", and answers a question left
open in that paper. The proof uses ideas of quantitative differentiation, as
well as a detailed study of how to supplement Lipschitz mappings by additional
coordinates to form bi-Lipschitz mappings.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:47:07 GMT""},{""version"":""v2"",""created"":""Mon, 2 Mar 2020 18:29:47 GMT""},{""version"":""v3"",""created"":""Tue, 12 May 2020 19:06:34 GMT""}]","2020-05-14"
"2002.10319","Lang Huang","Lang Huang, Chao Zhang, Hongyang Zhang","Self-Adaptive Training: beyond Empirical Risk Minimization","To appear in NeurIPS 2020",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose self-adaptive training---a new training algorithm that dynamically
corrects problematic training labels by model predictions without incurring
extra computational cost---to improve generalization of deep learning for
potentially corrupted training data. This problem is crucial towards robustly
learning from data that are corrupted by, e.g., label noises and
out-of-distribution samples. The standard empirical risk minimization (ERM) for
such data, however, may easily overfit noises and thus suffers from sub-optimal
performance. In this paper, we observe that model predictions can substantially
benefit the training process: self-adaptive training significantly improves
generalization over ERM under various levels of noises, and mitigates the
overfitting issue in both natural and adversarial training. We evaluate the
error-capacity curve of self-adaptive training: the test error is monotonously
decreasing w.r.t. model capacity. This is in sharp contrast to the
recently-discovered double-descent phenomenon in ERM which might be a result of
overfitting of noises. Experiments on CIFAR and ImageNet datasets verify the
effectiveness of our approach in two applications: classification with label
noise and selective classification. We release our code at
https://github.com/LayneH/self-adaptive-training.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:47:10 GMT""},{""version"":""v2"",""created"":""Wed, 30 Sep 2020 09:14:50 GMT""}]","2020-10-01"
"2002.10320","Erik Torrontegui","J. J. Garc\'ia-Ripoll, A. Ruiz-Chamorro, and E. Torrontegui","Quantum control of frequency tunable transmon superconducting qubits","11 pages, 8 figures","Phys. Rev. Applied 14, 044035 (2020)","10.1103/PhysRevApplied.14.044035",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we analyze the implementation of a control-phase gate through
the resonance between the $|11\rangle$ and $|20\rangle$ states of two
statically coupled transmons. We find that there are many different controls
for the transmon frequency that implement the same gate with fidelities around
$99.8\%$ ($T_1=T_2^{*}=17$ $\mu$s) and $99.99\%$ ($T_1=T_2^{*}=300$ $\mu$s)
within a time that approaches the theoretical limit. All controls can be
brought to this accuracy by calibrating the waiting time and the destination
frequency near the $|11\rangle-|20\rangle$ resonance. However, some controls,
such as those based on the theory of dynamical invariants, are particularly
attractive due to reduced leakage, robustness against decoherence, and their
limited bandwidth.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:47:11 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 12:59:11 GMT""},{""version"":""v3"",""created"":""Mon, 20 Jul 2020 12:26:11 GMT""}]","2020-10-28"
"2002.10322","Tianlang Chen","Tianlang Chen, Chen Fang, Xiaohui Shen, Yiheng Zhu, Zhili Chen, Jiebo
  Luo","Anatomy-aware 3D Human Pose Estimation with Bone-based Pose
  Decomposition","Accepted by IEEE Transactions on Circuits and Systems for Video
  Technology. Our code is available at
  https://github.com/sunnychencool/Anatomy3D",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we propose a new solution to 3D human pose estimation in
videos. Instead of directly regressing the 3D joint locations, we draw
inspiration from the human skeleton anatomy and decompose the task into bone
direction prediction and bone length prediction, from which the 3D joint
locations can be completely derived. Our motivation is the fact that the bone
lengths of a human skeleton remain consistent across time. This promotes us to
develop effective techniques to utilize global information across all the
frames in a video for high-accuracy bone length prediction. Moreover, for the
bone direction prediction network, we propose a fully-convolutional propagating
architecture with long skip connections. Essentially, it predicts the
directions of different bones hierarchically without using any time-consuming
memory units e.g. LSTM). A novel joint shift loss is further introduced to
bridge the training of the bone length and bone direction prediction networks.
Finally, we employ an implicit attention mechanism to feed the 2D keypoint
visibility scores into the model as extra guidance, which significantly
mitigates the depth ambiguity in many challenging poses. Our full model
outperforms the previous best results on Human3.6M and MPI-INF-3DHP datasets,
where comprehensive evaluation validates the effectiveness of our model.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:49:37 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 18:40:45 GMT""},{""version"":""v3"",""created"":""Tue, 17 Mar 2020 14:54:50 GMT""},{""version"":""v4"",""created"":""Sun, 24 Jan 2021 18:32:28 GMT""},{""version"":""v5"",""created"":""Tue, 26 Jan 2021 17:08:11 GMT""}]","2021-01-27"
"2002.10323","Francesco Fournier Facio","Francesco Fournier-Facio","Infinite sums of Brooks quasimorphisms and cup products in bounded
  cohomology","66 pages, 3 figures",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a class of quasimorphisms of the free group that can be expressed as
infinite sums of Brooks quasimorphisms with some nice properties. We then
review Heuer's framework of decompositions developed in arXiv:1710.03193, and
put these quasimorphisms in that context. This allows us to prove triviality of
a number of cup products in the bounded cohomology of the free group with
trivial real coefficients. Finally, we introduce free products of
decompositions and relate them to Rolli's quasimorphisms of free products. A
technical result concerning these, which remains an open question, implies a
strong triviality result for the cup product.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:50:06 GMT""}]","2021-06-28"
"2002.10324","JungHwan Park","Paolo Aceto, Jeffrey Meier, Allison N. Miller, Maggie Miller, JungHwan
  Park, Andr\'as I. Stipsicz","Branched covers bounding rational homology balls","19 pages, 5 figures, Version 2: Minor changes to abstract and
  introduction. Added references on knots that are not concordant to their
  reverses","Algebr. Geom. Topol. 21 (2021) 3569-3599","10.2140/agt.2021.21.3569",,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prime power fold cyclic branched covers along smoothly slice knots all bound
rational homology balls. This phenomenon, however, does not characterize slice
knots. In this paper, we give a new construction of non-slice knots that have
the above property. The sliceness obstruction comes from computing twisted
Alexander polynomials, and we introduce new techniques to simplify their
calculation.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:52:48 GMT""},{""version"":""v2"",""created"":""Fri, 17 Apr 2020 23:13:54 GMT""}]","2022-01-05"
"2002.10325","Sumit Roy","Sumit Roy","Hitchin fibration on moduli of symplectic and orthogonal parabolic Higgs
  bundles",,,"10.1007/s11040-020-09366-y",,"math.AG math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X$ be a compact Riemann surface of genus $g \geq 2$, and let $D \subset
X$ be a fixed finite subset. Let $\mathcal{M}(r,d,\alpha)$ denote the moduli
space of stable parabolic $G$-bundles (where $G$ is a complex orthogonal or
symplectic group) of rank $r$, degree $d$ and weight type $\alpha$ over $X$.
Hitchin discovered that the cotangent bundle of the moduli space of stable
bundles on an algebraic curve is an algebraically completely integrable system
fibered, over a space of invariant polynomials, either by a Jacobian or a Prym
variety of spectral curves. In this paper we study the Hitchin fibers for
$\mathcal{M}(r,d,\alpha)$.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:53:57 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 17:44:12 GMT""}]","2020-12-02"
"2002.10326","Chelsea Carlson","Chelsea Carlson, Andreas Knorr, Stephen Hughes","Screening of the quantum dot F\""orster coupling at small distances","5 pages, 2 figures",,"10.1364/OL.391466",,"physics.optics cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the near-field energy transfer rates between two finite size quantum
dot disks, generalizing the result of F\""orster coupling between two point
dipoles. In particular, we derive analytical results for the envelope of the
electronic wavefunction for model potentials at the boundaries of quantum dot
disks and demonstrate how the F\""orster interaction is screened as the size of
the dots becomes comparable to the dot-dot separation.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:54:18 GMT""}]","2020-06-30"
"2002.10327","Shuai Wang","Shuai Wang, Miaowen Wen, Minghua Xia, Rui Wang, Qi Hao, and Yik-Chung
  Wu","Angle Aware User Cooperation for Secure Massive MIMO in Rician Fading
  Channel","14 pages, 12 figures, to appear in IEEE Journal on Selected Areas in
  Communications",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Massive multiple-input multiple-output communications can achieve high-level
security by concentrating radio frequency signals towards the legitimate users.
However, this system is vulnerable in a Rician fading environment if the
eavesdropper positions itself such that its channel is highly ""similar"" to the
channel of a legitimate user. To address this problem, this paper proposes an
angle aware user cooperation (AAUC) scheme, which avoids direct transmission to
the attacked user and relies on other users for cooperative relaying. The
proposed scheme only requires the eavesdropper's angle information, and adopts
an angular secrecy model to represent the average secrecy rate of the attacked
system. With this angular model, the AAUC problem turns out to be nonconvex,
and a successive convex optimization algorithm, which converges to a
Karush-Kuhn-Tucker solution, is proposed. Furthermore, a closed-form solution
and a Bregman first-order method are derived for the cases of large-scale
antennas and large-scale users, respectively. Extension to the intelligent
reflecting surfaces based scheme is also discussed. Simulation results
demonstrate the effectiveness of the proposed successive convex optimization
based AAUC scheme, and also validate the low-complexity nature of the proposed
large-scale optimization algorithms.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:54:59 GMT""},{""version"":""v2"",""created"":""Sun, 26 Apr 2020 11:36:02 GMT""}]","2020-04-28"
"2002.10328","Liqin Ke","Phuong-Vu Ong, Tae-Hoon Kim, Haijun Zhao, Brandt A. Jensen, Lin Zhou,
  Liqin Ke","Deterministic strain-control of stability and current-induced motion of
  skyrmions in chiral magnets","12 pages, 7 figures",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  External magnetic field, temperature, and spin-polarized current are usually
employed to create and control nanoscale vortex-like spin configurations such
as magnetic skyrmions. Although these methods have proven successful, they are
not energy-efficient due to high power consumption and dissipation. Coupling
between magnetic properties and mechanical deformation, the magnetoelastic
(MEL) effect, offers a novel approach to energy-efficient control of magnetism
at the nanoscale. It is of great interest in the context of ever-decreasing
length scales of electronic and spintronic devices. Therefore, it is desirable
to establish a comprehensive framework capable of predicting the effects of
mechanical stress and enabling deterministic control of magnetic textures and
skyrmions. In this work, using an advanced scheme of multiscale simulations and
Lorentz transmission electron microscopy measurements we demonstrate
deterministic control of topological magnetic textures and skyrmion creation in
thin films and racetracks of chiral magnets. Our investigation considers not
only uniaxial but also biaxial stress, which is ubiquitous in thin-film
devices. The biaxial stress, rather than the uniaxial one, was shown to be more
efficient to create or annihilate skyrmions when the MEL coefficient and strain
have the same or opposite signs, respectively. It was also demonstrated to be a
viable way to stabilize skyrmions and to control their current-induced motion
in racetrack memory. Our results open prospects for deployment of mechanical
stress to create novel topological spin textures, including merons, and in
control and optimization of skyrmion-based devices.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:55:11 GMT""}]","2020-02-25"
"2002.10329","Christoph Wernhard","Jana Kittelmann, Christoph Wernhard","KBSET -- Knowledge-Based Support for Scholarly Editing and Text
  Processing with Declarative LaTeX Markup and a Core Written in SWI-Prolog","To appear in DECLARE 2019 Revised Selected Papers",,"10.1007/978-3-030-46714-2_12",,"cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  KBSET is an environment that provides support for scholarly editing in two
flavors: First, as a practical tool KBSET/Letters that accompanies the
development of editions of correspondences (in particular from the 18th and
19th century), completely from source documents to PDF and HTML presentations.
Second, as a prototypical tool KBSET/NER for experimentally investigating novel
forms of working on editions that are centered around automated named entity
recognition. KBSET can process declarative application-specific markup that is
expressed in LaTeX notation and incorporate large external fact bases that are
typically provided in RDF. KBSET includes specially developed LaTeX styles and
a core system that is written in SWI-Prolog, which is used there in many roles,
utilizing that it realizes the potential of Prolog as a unifying language.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:57:41 GMT""}]","2020-05-12"
"2002.10330","Francisco Arag\'on-Roy\'on","F. Arag\'on-Roy\'on, A. Jim\'enez-V\'ilchez, A. Arauzo-Azofra, J. M.
  Ben\'itez","FSinR: an exhaustive package for feature selection","17 pages, 6 figures, 2 tables",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feature Selection (FS) is a key task in Machine Learning. It consists in
selecting a number of relevant variables for the model construction or data
analysis. We present the R package, FSinR, which implements a variety of widely
known filter and wrapper methods, as well as search algorithms. Thus, the
package provides the possibility to perform the feature selection process,
which consists in the combination of a guided search on the subsets of features
with the filter or wrapper methods that return an evaluation measure of those
subsets. In this article, we also present some examples on the usage of the
package and a comparison with other packages available in R that contain
methods for feature selection.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:59:45 GMT""}]","2020-02-25"
"2002.10456","Benjamin Miller","Benjamin D. Miller","Lacunary sets for actions of tsi groups",,,,,"math.LO math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Under a mild definability assumption, we characterize the family of Borel
actions $\Gamma \curvearrowright X$ of tsi Polish groups on Polish spaces that
can be decomposed into countably-many actions admitting complete Borel sets
that are lacunary with respect to an open neighborhood of $1_\Gamma$. In the
special case that $\Gamma$ is non-archimedean, it follows that there is such a
decomposition if and only if there is no continuous embedding of
$\mathbb{E}_0^{\mathbb{N}}$ into $E_\Gamma^X$.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:53:31 GMT""}]","2020-02-26"
"2002.10457","Benjamin Miller","Rapha\""el Carroy and Benjamin D. Miller","Bases for functions beyond the first Baire class",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a finite basis for the class of Borel functions that are not in
the first Baire class, as well as the class of Borel functions that are not
$\sigma$-continuous with closed witnesses.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:59:48 GMT""}]","2020-02-26"
"2002.10458","Narciso Roman-Roy","Jordi Gaset, Xavier Gr\`acia, Miguel C. Mu\~noz-Lecanda, Xavier Rivas,
  Narciso Rom\'an-Roy","A $k$-contact Lagrangian formulation for nonconservative field theories","arXiv admin note: text overlap with arXiv:1905.07354",,"10.1016/S0034-4877(21)00041-0",,"math-ph hep-th math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a geometric Lagrangian formulation for first-order field theories
with dissipation. This formulation is based on the $k$-contact geometry
introduced in a previous paper, and gathers contact Lagrangian mechanics with
$k$-symplectic Lagrangian field theory together. We also study the symmetries
and dissipation laws for these nonconservative theories, and analyze some
examples.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:09:05 GMT""}]","2021-07-14"
"2002.10459","Tirion Roberts","Tirion G. Roberts, Simon J. Cox","An analytic velocity profile for pressure-driven flow of a Bingham fluid
  in a curved channel","arXiv admin note: substantial text overlap with arXiv:1909.06173","JNNFM 2020","10.1016/j.jnnfm.2020.104278",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive an expression for the velocity profile of a pressure-driven
yield-stress fluid flow-ing around a two-dimensional concentric annulus. This
result allows the prediction of the effects of channel curvature on the
pressure gradient required to initiate flow for given yield stress, and for the
width of the plug region and the flux through the channel at different
curvatures. We use it to validate numerical simulations of the flow from a
straight channel into a curved channel which show how the fluid first yields
everywhere before reaching the predicted velocity profile.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:58:42 GMT""}]","2020-04-30"
"2002.10879","Jen\H{o} Szirmai","Mikl\'os Eper and Jen\H{o} Szirmai","Coverings with horo- and hyperballs generated by simply truncated
  orthoschemes","23 pages, 5 figures. arXiv admin note: substantial text overlap with
  arXiv:1505.03338",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After having investigated the packings derived by horo- and hyperballs
related to simple frustum Coxeter orthoscheme tilings we consider the
corresponding covering problems (briefly hyp-hor coverings) in $n$-dimensional
hyperbolic spaces $\mathbb{H}^n$ ($n=2,3$).
  We construct in the $2-$ and $3-$dimensional hyperbolic spaces hyp-hor
coverings that are generated by simply truncated Coxeter orthocheme tilings and
we determine their thinnest covering configurations and their densities.
  We prove that in the hyperbolic plane ($n=2$) the density of the above
thinnest hyp-hor covering arbitrarily approximate the universal lower bound of
the hypercycle or horocycle covering density $\frac{\sqrt{12}}{\pi}$ and in
$\mathbb{H}^3$ the optimal configuration belongs to the $\{7,3,6\}$ Coxeter
tiling with density $\approx 1.27297$ that is less than the previously known
famous horosphere covering density $1.280$ due to L.~Fejes T\'oth and
K.~B\""or\""oczky.
  Moreover, we study the hyp-hor coverings in truncated orthosche\-mes
$\{p,3,6\}$ $(6< p < 7, ~ p\in \mathbb{R})$ whose density function attains its
minimum at parameter $p\approx 6.45962$ with density $\approx 1.26885$. That
means that this locally optimal hyp-hor configuration provide smaller covering
density than the former determined $\approx 1.27297$ but this hyp-hor packing
configuration can not be extended to the entirety of hyperbolic space
$\mathbb{H}^3$.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:20:03 GMT""}]","2020-02-26"
"2002.10880","Charlie Nash","Charlie Nash, Yaroslav Ganin, S. M. Ali Eslami, Peter W. Battaglia","PolyGen: An Autoregressive Generative Model of 3D Meshes",,,,,"cs.GR cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polygon meshes are an efficient representation of 3D geometry, and are of
central importance in computer graphics, robotics and games development.
Existing learning-based approaches have avoided the challenges of working with
3D meshes, instead using alternative object representations that are more
compatible with neural architectures and training approaches. We present an
approach which models the mesh directly, predicting mesh vertices and faces
sequentially using a Transformer-based architecture. Our model can condition on
a range of inputs, including object classes, voxels, and images, and because
the model is probabilistic it can produce samples that capture uncertainty in
ambiguous scenarios. We show that the model is capable of producing
high-quality, usable meshes, and establish log-likelihood benchmarks for the
mesh-modelling task. We also evaluate the conditional models on surface
reconstruction metrics against alternative methods, and demonstrate competitive
performance despite not training directly on this task.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 17:16:34 GMT""}]","2020-02-26"
"2002.10881","YangGon Kim","YangGon Kim","Conjectures on the representations of modular Lie algebras",,,,,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have already seen simple representations of modular Lie algebras of
$A_l$-type and $C_l$-type. We shall further investigate simple representations
of $B_l$ type, which turn out to be very similar in methodology as those types
except for roots. So we may consider some conjectures relating to the
representations of classical type modular Lie algebras.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 00:23:48 GMT""},{""version"":""v2"",""created"":""Sat, 29 Feb 2020 12:30:17 GMT""},{""version"":""v3"",""created"":""Wed, 18 Mar 2020 23:39:07 GMT""}]","2020-03-20"
"2002.10882","James Tee","James Tee and Desmond P. Taylor","A Quantized Representation of Intertemporal Choice in the Brain","9 pages, 19 figures. arXiv admin note: substantial text overlap with
  arXiv:1805.01631",,,,"q-bio.NC stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Value [4][5] is typically modeled using a continuous representation (i.e., a
Real number). A discrete representation of value has recently been postulated
[6]. A quantized representation of probability in the brain was also posited
and supported by experimental data [7]. Value and probability are inter-related
via Prospect Theory [4][5]. In this paper, we hypothesize that intertemporal
choices may also be quantized. For example, people may treat (or discount) 16
days indifferently to 17 days. To test this, we analyzed an intertemporal task
by using 2 novel models: quantized hyperbolic discounting, and quantized
exponential discounting. Our work here is a re-examination of the behavioral
data previously collected for an fMRI study [8]. Both quantized hyperbolic and
quantized exponential models were compared using AIC and BIC tests. We found
that 13/20 participants were best fit to the quantized exponential model, while
the remaining 7/20 were best fit to the quantized hyperbolic model. Overall,
15/20 participants were best fit to models with a 5-bit precision (i.e., 2^5 =
32 steps). In conclusion, regardless of hyperbolic or exponential, quantized
versions of these models are better fit to the experimental data than their
continuous forms. We finally outline some potential applications of our
findings.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 03:24:08 GMT""},{""version"":""v2"",""created"":""Mon, 10 Aug 2020 00:40:49 GMT""},{""version"":""v3"",""created"":""Tue, 15 Sep 2020 22:54:03 GMT""}]","2020-09-17"
"2002.10883","Guosheng Yin","Guosheng Yin and Haolun Shi","Demystify Lindley's Paradox by Interpreting P-value as Posterior
  Probability","arXiv admin note: text overlap with arXiv:1809.08503",,,,"stat.ME stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the hypothesis testing framework, p-value is often computed to determine
rejection of the null hypothesis or not. On the other hand, Bayesian approaches
typically compute the posterior probability of the null hypothesis to evaluate
its plausibility. We revisit Lindley's paradox (Lindley, 1957) and demystify
the conflicting results between Bayesian and frequentist hypothesis testing
procedures by casting a two-sided hypothesis as a combination of two one-sided
hypotheses along the opposite directions. This can naturally circumvent the
ambiguities of assigning a point mass to the null and choices of using local or
non-local prior distributions. As p-value solely depends on the observed data
without incorporating any prior information, we consider non-informative prior
distributions for fair comparisons with p-value. The equivalence of p-value and
the Bayesian posterior probability of the null hypothesis can be established to
reconcile Lindley's paradox. Extensive simulation studies are conducted with
multivariate normal data and random effects models to examine the relationship
between the p-value and posterior probability.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:18:03 GMT""}]","2020-02-26"
"2002.10884","Yingxun Zhang","Yingxun Zhang, Min Liu, Cheng-Jun Xia, Zhuxia Li and Subrata Kumar
  Biswal","Constraints on the symmetry energy and its associated parameters from
  nuclei to neutron stars","10 pages, 11 figures, 2 tables, accepted by Phys.Rev.C. This article
  draws heavily from arXiv:1911.05380. In the v1 version, we modified two typos
  in Table II",,"10.1103/PhysRevC.101.034303",,"nucl-th astro-ph.HE nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The symmetry energy obtained with the effective Skyrme energy density
functional is related to the values of isoscalar effective mass and isovector
effective mass, which is also indirectly related to the incompressibility of
symmetric nuclear matter. In this work, we analyze the values of symmetry
energy and its related nuclear matter parameters in five-dimensional parameter
space by describing the heavy ion collision data, such as isospin diffusion
data at 35 MeV/u and 50 MeV/u, neutron skin of $^{208}$Pb, and tidal
deformability and maximum mass of neutron star. We obtain the parameter sets
which can describe the isospin diffusion, neutron skin, tidal deformability and
maximum mass of neutron star, and give the incompressibility
$K_0$=250.23$\pm$20.16 MeV, symmetry energy coefficient $S_0$=31.35$\pm$2.08
MeV, the slope of symmetry energy $L$=59.57$\pm$10.06 MeV, isoscalar effective
mass $m_s^*/m$=0.75$\pm$0.05 and quantity related to effective mass splitting
$f_I$=0.005$\pm$0.170. At two times normal density, the symmetry energy we
obtained is in 35-55 MeV. To reduce the large uncertainties of $f_I$, more
critical works in heavy ion collisions at different beam energies are needed.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:31:19 GMT""},{""version"":""v2"",""created"":""Tue, 3 Mar 2020 02:52:13 GMT""}]","2020-04-22"
"2002.10885","Uicheol Jang","Uicheol Jang and Yu Yi and Hongsu Kim","Thick accretion disk and Its super Eddington luminosity around spinning
  blackholes",,,"10.5140/JASS.2021.38.1.39",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the general accretion disk model theory, the accretion disk surrounding an
astronomical object comprises fluid rings obeying Keplerian motion. However, we
should consider relativistic and rotational effects as we close in toward the
center of accretion disk surrounding spinning compact massive objects such as a
black hole or a neutron star. In this study, we explore the geometry of the
inner portion of the accretion disk in the context of Mukhopadhyay's pseudo
Newtonian potential approximation for the full general relativity theory. We
found that the shape of the accretion disk ""puffs up"" or becomes thicker and
the luminosity of the disk could exceed the Eddington luminosity near the
surface of the compact spinning black hole.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:37:05 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 07:31:20 GMT""}]","2021-05-12"
"2002.10886","Igor Shevkunov","Igor Shevkunov, Vladimir Katkovnik, and Karen Egiazarian","Lensless hyperspectral imaging by Fourier transform spectroscopy for
  broadband visible light: phase retrieval technique","12 pages, 8 figures",,"10.1364/OE.393009",,"eess.IV physics.optics","http://creativecommons.org/licenses/by/4.0/","  A novel phase retrieval algorithm for broadband hyperspectral phase imaging
from noisy intensity observations is proposed. It utilizes advantages of the
Fourier Transform spectroscopy in the self-referencing optical setup and
provides, additionally beyond spectral intensity distribution, reconstruction
of the investigated object's phase. The noise amplification Fellgett's
disadvantage is relaxed by the application of sparse wavefront noise filtering
embedded in the proposed algorithm. The algorithm reliability is proved by
simulation tests and results of physical experiments on transparent objects
which demonstrate precise phase imaging and object depth (profile)
reconstructions.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:03:53 GMT""},{""version"":""v2"",""created"":""Mon, 16 Mar 2020 07:27:41 GMT""}]","2020-06-03"
"2002.10887","Jonas Oppenlaender","Jonas Oppenlaender, Aku Visuri, Kristy Milland, Panos Ipeirotis, Simo
  Hosio","What do crowd workers think about creative work?","4 pages, accepted at the Workshop on Worker-centered Design (CHI
  '20). arXiv admin note: text overlap with arXiv:2001.06798",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Crowdsourcing platforms are a powerful and convenient means for recruiting
participants in online studies and collecting data from the crowd. As
information work is being more and more automated by Machine Learning
algorithms, creativity $-$ that is, a human's ability for divergent and
convergent thinking $-$ will play an increasingly important role on online
crowdsourcing platforms. However, we lack insights into what crowd workers
think about creative work. In studies in Human-Computer Interaction (HCI), the
ability and willingness of the crowd to participate in creative work seems to
be largely unquestioned. Insights into the workers' perspective are rare, but
important, as they may inform the design of studies with higher validity. Given
that creativity will play an increasingly important role in crowdsourcing, it
is imperative to develop an understanding of how workers perceive creative
work. In this paper, we summarize our recent worker-centered study of creative
work on two general-purpose crowdsourcing platforms (Amazon Mechanical Turk and
Prolific). Our study illuminates what creative work is like for crowd workers
on these two crowdsourcing platforms. The work identifies several archetypal
types of workers with different attitudes towards creative work, and discusses
common pitfalls with creative work on crowdsourcing platforms.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 08:56:51 GMT""}]","2020-02-26"
"2002.10888","Thomas Seiller","Luc Pellissier (LACL), Thomas Seiller (CNRS, LIPN)","Lower bounds for algebraic machines, semantically","arXiv admin note: substantial text overlap with arXiv:1811.06787",,,,"cs.CC cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a new semantic method for proving lower bounds in
computational complexity. We use it to prove that maxflow, a PTIME complete
problem, is not computable in polylogarithmic time on parallel random access
machines (PRAMs) working with integers, showing that NCZ \neq PTIME, where NCZ
is the complexity class defined by such machines, and PTIME is the standard
class of polynomial time computable problems (on, say, a Turing machine). On
top of showing this new separation result, we show our method captures previous
lower bounds results from the literature: Steele and Yao's lower bounds for
algebraic decision trees, Ben-Or's lower bounds for algebraic computation
trees, Cucker's proof that NC is not equal to PTIME on the reals, and
Mulmuley's lower bounds for ""PRAMs without bit operations"".
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:48:00 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 08:21:20 GMT""}]","2021-02-05"
"2002.10890","Andrea Borghesi","Andrea Borghesi, Giuseppe Tagliavini, Michele Lombardi, Luca Benini,
  Michela Milano","Combining Learning and Optimization for Transprecision Computing",,"Proceedings of the 17th ACM International Conference on Computing
  Frontiers, May 2020, Pages 10-18","10.1145/3387902.3392615",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The growing demands of the worldwide IT infrastructure stress the need for
reduced power consumption, which is addressed in so-called transprecision
computing by improving energy efficiency at the expense of precision. For
example, reducing the number of bits for some floating-point operations leads
to higher efficiency, but also to a non-linear decrease of the computation
accuracy. Depending on the application, small errors can be tolerated, thus
allowing to fine-tune the precision of the computation. Finding the optimal
precision for all variables in respect of an error bound is a complex task,
which is tackled in the literature via heuristics. In this paper, we report on
a first attempt to address the problem by combining a Mathematical Programming
(MP) model and a Machine Learning (ML) model, following the Empirical Model
Learning methodology. The ML model learns the relation between variables
precision and the output error; this information is then embedded in the MP
focused on minimizing the number of bits. An additional refinement phase is
then added to improve the quality of the solution. The experimental results
demonstrate an average speedup of 6.5\% and a 3\% increase in solution quality
compared to the state-of-the-art. In addition, experiments on a hardware
platform capable of mixed-precision arithmetic (PULPissimo) show the benefits
of the proposed approach, with energy savings of around 40\% compared to
fixed-precision.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:52:15 GMT""}]","2020-07-30"
"2002.10891","Yuri I. Ozhigov","Yuri Ozhigov","Quantum gates on asynchronous atomic excitations","8 pages, Latex, 2 figures, some corrections, paragraph 4 added",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The article proposes the implementation of a universal system of quantum
gates on asynchronous excitations of two-level atoms in optical cavities. The
entangling operator of the CSign type is implemented without beam splitters,
approximately, based on the incommensurability of the periods of Rabi
oscillations in a cavity with single and double excitations.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:15:16 GMT""},{""version"":""v2"",""created"":""Mon, 27 Apr 2020 14:47:16 GMT""},{""version"":""v3"",""created"":""Mon, 1 Jun 2020 13:02:22 GMT""}]","2020-06-02"
"2002.10915","Yu Zhang","Haowei Deng, Yu Zhang and Quanxi Li","CODAR: A Contextual Duration-Aware Qubit Mapping for Various NISQ
  Devices","arXiv admin note: substantial text overlap with arXiv:2001.06887","2020 57th ACM/IEEE Design Automation Conference (DAC)","10.1109/DAC18072.2020.9218561",,"quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Quantum computing devices in the NISQ era share common features and
challenges like limited connectivity between qubits. Since two-qubit gates are
allowed on limited qubit pairs, quantum compilers must transform original
quantum programs to fit the hardware constraints. Previous works on qubit
mapping assume different gates have the same execution duration, which limits
them to explore the parallelism from the program. To address this drawback, we
propose a Multi-architecture Adaptive Quantum Abstract Machine (maQAM) and a
COntext-sensitive and Duration-Aware Remapping algorithm (CODAR). The CODAR
remapper is aware of gate duration difference and program context, enabling it
to extract more parallelism from programs and speed up the quantum programs by
1.23 in simulation on average in different architectures and maintain the
fidelity of circuits when running on Origin Quantum noisy simulator.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 04:30:05 GMT""}]","2020-12-18"
"2002.10929","Yosuke Morimoto","Yosuke Morimoto","Duality Between Quantization and Measurement","6 pages",,,,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the known duality between events and states, we establish the fact that
there is a duality between quantization of events and measurement of states.
With this duality, we will show a generalized system of imprimitivity and a
covariant measurement are in a dual relation. We also propose a novel
quantization scheme as a dual of a measurement model.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:26:39 GMT""},{""version"":""v2"",""created"":""Wed, 26 Feb 2020 14:58:51 GMT""}]","2020-02-27"
"2002.11018","Mathilde Guillemot","Mathilde Guillemot, Catherine Heusele, Rodolphe Korichi, Sylvianne
  Schnebert, Liming Chen","Breaking Batch Normalization for better explainability of Deep Neural
  Networks through Layer-wise Relevance Propagation",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The lack of transparency of neural networks stays a major break for their
use. The Layerwise Relevance Propagation technique builds heat-maps
representing the relevance of each input in the model s decision. The relevance
spreads backward from the last to the first layer of the Deep Neural Network.
Layer-wise Relevance Propagation does not manage normalization layers, in this
work we suggest a method to include normalization layers. Specifically, we
build an equivalent network fusing normalization layers and convolutional or
fully connected layers. Heatmaps obtained with our method on MNIST and CIFAR 10
datasets are more accurate for convolutional layers. Our study also prevents
from using Layerwise Relevance Propagation with networks including a
combination of connected layers and normalization layer.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:06:55 GMT""}]","2020-02-26"
"2002.11020","Ekrem Aksoy","Ekrem Aksoy, Ahmet Yaz{\i}c{\i}, Mahmut Kasap","See, Attend and Brake: An Attention-based Saliency Map Prediction Model
  for End-to-End Driving",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual perception is the most critical input for driving decisions. In this
study, our aim is to understand relationship between saliency and driving
decisions. We present a novel attention-based saliency map prediction model for
making braking decisions This approach constructs a holistic model to the
driving task and can be extended for other driving decisions like steering and
acceleration. The proposed model is a deep neural network model that feeds
extracted features from input image to a recurrent neural network with an
attention mechanism. Then predicted saliency map is used to make braking
decision. We trained and evaluated using driving attention dataset BDD-A, and
saliency dataset CAT2000.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 06:01:35 GMT""}]","2020-02-26"
"2002.11038","Pepijn Cox","Pepijn B. Cox, Wim L. van Rossum","Analysing Multibeam, Cooperative, Ground Based Radar in a Bistatic
  Configuration","6 pages, 7 figures, errata of Fig. 7 added as supplement","Proceedings of the 2020 IEEE International RADAR Conference, pp
  912-917, Washington DC, USA, May 2020","10.1109/RADAR42522.2020.9114620",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in digital beam forming for phased arrays in combination with
digital signal processing should enable the development of multibeam radar in a
bistatic configuration. In the bistatic setting, the pulse travelling outward
from the transmitter should be followed or ""chased"" by the receiver. During
transmission, depending on the location of the transmitter, receiver, and
pulse, the number of digital beams and their location at the transmitter vary.
In this paper, we analyse the geometrically depending number of digital beams
and the beam switching rate of the receiver needed for pulse chasing. In
addition, we derive the pulse repetition frequency (PRF) for the bistatic
configuration based on the desired detection range. It is shown that the PRF in
the bistatic case can be increased compared to its monostatic counterpart when
the distance between the transmitter and the receiver is increased. Our results
are applied on the scenario of an air traffic control radar to show the
feasibility of a multibeam, ground based bistatic surveillance radar. It will
be demonstrated that the maximum PRF can almost be doubled and an adaptive
sensing and tracking paradigm can lead to a maximum of 64 simultaneous receiver
beams for the bistatic surveillance and tracking setting.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 12:18:42 GMT""},{""version"":""v2"",""created"":""Fri, 4 Sep 2020 08:46:51 GMT""},{""version"":""v3"",""created"":""Fri, 30 Oct 2020 14:24:32 GMT""}]","2020-11-02"
"2002.11193","Santiago Andr\'es Azcoitia","Santiago Andr\'es Azcoitia, Marius Paraschiv, Nikolaos Laoutaris","Computing the Relative Value of Spatio-Temporal Data in Wholesale and
  Retail Data Marketplaces",,,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spatio-temporal information is used for driving a plethora of intelligent
transportation, smart-city, and crowd-sensing applications. Since data is now
considered a valuable production factor, data marketplaces have appeared to
help individuals and enterprises bring it to market to satisfy the ever-growing
demand. In such marketplaces, several sources may need to combine their data in
order to meet the requirements of different applications. In this paper we
study the problem of estimating the relative value of different spatio-temporal
datasets combined in wholesale and retail marketplaces for the purpose of
predicting demand in metropolitan areas. Using as case studies large datasets
of taxi rides from Chicago and New York, we ask questions such as ""When does it
make sense for different taxi companies to combine their data?"", and ""How
should different companies be compensated for the data that they share?"". We
then turn our attention to the even harder problem of establishing the relative
value of the data brought to retail marketplaces by individual drivers.
Overall, we show that simplistic but popular approaches for estimating the
relative value of data, such as using volume, or the ``leave-one-out''
heuristic, are inaccurate. Instead, more complex notions of value from
economics and game-theory, such as the Shapley value need to be employed if one
wishes to capture the complex effects of mixing different datasets on the
accuracy of forecasting algorithms. Applying the Shapley value to large
datasets from many sources is, of course, computationally challenging. We
resort to structured sampling and manage to compute accurately the importance
of thousands of data sources. We show that the relative value of the data held
by different taxi companies and drivers may differ substantially, and that its
relative ranking may change from district to district within a metropolitan
area.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 09:56:58 GMT""},{""version"":""v2"",""created"":""Fri, 29 May 2020 16:45:59 GMT""}]","2020-06-02"
"2002.11197","Chad Peters","Chad Peters, Babak Esfandiari, Mohamad Zalat and Robert West","Behavior Cloning in OpenAI using Case Based Reasoning",,,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning from Observation (LfO), also known as Behavioral Cloning, is an
approach for building software agents by recording the behavior of an expert
(human or artificial) and using the recorded data to generate the required
behavior. jLOAF is a platform that uses Case-Based Reasoning to achieve LfO. In
this paper we interface jLOAF with the popular OpenAI Gym environment. Our
experimental results show how our approach can be used to provide a baseline
for comparison in this domain, as well as identify the strengths and weaknesses
when dealing with environmental complexity.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 22:41:56 GMT""}]","2020-02-27"
"2002.11639","Young-Gu Ju","Young-Gu Ju, Hyeon-Jun Kim and Young-Min Ko","Microscope Projection Photolithography Based on Liquid Crystal
  Microdisplay","14 pages, 8 figures, 6 tables","2020 Eur. J. Phys. 41 055301","10.1088/1361-6404/ab988f",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We developed a microdisplay-based microscope projection photolithography
(MDMPP) technique in which a liquid crystal (LC) microdisplay is used as a
reconfigurable photomask for a microscope projector. The LC microdisplay
provides a significant advantage in terms of cost and speed since patterns can
be generated through software instead of redesigning and fabricating glass
photomasks. The constructed MDMPP system could produce line patterns as narrow
as 2.4 um, smaller than that specified by the diffraction limit, with the aid
of a 4X objective lens. The achievement of a linewidth smaller than the
theoretical limit may be ascribed to a combination of overexposure and the
underetching effect, in addition to the good optical performance of the system.
In a diffraction experiment performed with fabricated slits, the application of
the MDMPP technique helped provide various patterns of the slits, demonstrating
the potential usefulness of the MDMPP system in undergraduate optics courses.
We expect that MDMPP can contribute to the field of physics education and
various areas of research, such as chemistry and biology, in the future.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 05:23:29 GMT""}]","2022-03-23"
"2002.11702","Milad Roohi","Milad Roohi, Eric M. Hernandez","Performance-based Post-earthquake Decision-making for Instrumented
  Buildings","Under Review in Journal of Civil Structural Health Monitoring",,,,"eess.SP cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper presents a framework for decision-making regarding post-earthquake
assessment of instrumented buildings in a manner consistent with
performance-based design criteria. This framework is achieved by simultaneously
combining and advancing existing knowledge from seismic structural health
monitoring and performance-based earthquake engineering paradigms and consists
of 1) optimal sensor placement, 2) dynamic response reconstruction, 3) damage
estimation, and 4) performance-assessment and decision-making. In particular,
the main objective is to reconstruct inter-story drifts with a probabilistic
measure of exceeding performance-based acceptance limits and determining the
post-earthquake re-occupancy classification of the instrumented building of
interest. Since the proposed framework is probabilistic, the outcome can be
used to obtain the probability of losses based on the defined decision
variables and be integrated into a risk-based decision-making process by city
officials, building owners, and emergency managers. The framework is
illustrated using data from the Van Nuys hotel testbed, a seven-story
reinforced concrete building instrumented by the California Strong Motion
Instrumentation Program (Station 24386).
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:56:00 GMT""}]","2020-02-27"
"2002.12138","Noemie Globus","Noemie Globus, Roger D. Blandford","The Chiral Puzzle of Life","18 pages, 6 figures, accepted for publication in The Astrophysical
  Journal Letters. arXiv admin note: text overlap with arXiv:1911.02525",,"10.3847/2041-8213/ab8dc6",,"q-bio.OT astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Biological molecules chose one of two structurally, chiral systems which are
related by reflection in a mirror. It is proposed that this choice was made,
causally, by magnetically polarized and physically chiral cosmic-rays, which
are known to have a large role in mutagenesis. It is shown that the cosmic rays
can impose a small, but persistent, chiral bias in the rate at which they
induce structural changes in simple, chiral monomers that are the building
blocks of biopolymers. A much larger effect should be present with helical
biopolymers, in particular, those that may have been the progenitors of RNA and
DNA. It is shown that the interaction can be both electrostatic, just involving
the molecular electric field, and electromagnetic, also involving a magnetic
field. It is argued that this bias can lead to the emergence of a single,
chiral life form over an evolutionary timescale. If this mechanism dominates,
then the handedness of living systems should be universal. Experiments are
proposed to assess the efficacy of this process.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:02:56 GMT""},{""version"":""v2"",""created"":""Fri, 1 May 2020 18:13:41 GMT""}]","2022-07-11"
"2002.12144","George Cevora","George Cevora","Fair Adversarial Networks",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-sa/4.0/","  The influence of human judgement is ubiquitous in datasets used across the
analytics industry, yet humans are known to be sub-optimal decision makers
prone to various biases. Analysing biased datasets then leads to biased
outcomes of the analysis. Bias by protected characteristics (e.g. race) is of
particular interest as it may not only make the output of analytical process
sub-optimal, but also illegal. Countering the bias by constraining the
analytical outcomes to be fair is problematic because A) fairness lacks a
universally accepted definition, while at the same time some definitions are
mutually exclusive, and B) the use of optimisation constraints ensuring
fairness is incompatible with most analytical pipelines. Both problems are
solved by methods which remove bias from the data and returning an altered
dataset. This approach aims to not only remove the actual bias variable (e.g.
race), but also alter all proxy variables (e.g. postcode) so the bias variable
is not detectable from the rest of the data. The advantage of using this
approach is that the definition of fairness as a lack of detectable bias in the
data (as opposed to the output of analysis) is universal and therefore solves
problem (A). Furthermore, as the data is altered to remove bias the problem (B)
disappears because the analytical pipelines can remain unchanged. This approach
has been adopted by several technical solutions. None of them, however, seems
to be satisfactory in terms of ability to remove multivariate, non-linear and
non-binary biases. Therefore, in this paper I propose the concept of Fair
Adversarial Networks as an easy-to-implement general method for removing bias
from data. This paper demonstrates that Fair Adversarial Networks achieve this
aim.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 16:39:38 GMT""}]","2020-02-28"
"2002.12762","Maxwell Siegel","Maxwell C. Siegel","Fourier Analysis of the Parity-Vector Parameterization of the
  Generalized Collatz px+1 maps",,,,,"math.GM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Let p be an odd prime, and consider the map H_p which sends an integer x to
either x/2 or (px+1)/2 depending on whether x is even or odd. The values at x=0
of arbitrary composition sequences of the maps x/2 and (px+1)/2 can be
parameterized over the 2-adic integers (Z2) leading to a continuous function
from Z2 to Zp which the author calls the ""characteristic function"" (or ""numen"")
of H_p. Lipschitz-type estimates are given for the characteristic function when
p-1 is a power of 2 and 2 is a primitive root mod p, and it is shown that the
set of periodic points of H_p is equal to the set of (rational) integer values
attained by the characteristic function over Z2. Additionally, although the
pre-image of R under the characteristic function has zero Haar measure in the
Z2, by pre-composing the characteristic function with an appropriately selected
self-embedding of Z2, one can perform Fourier analysis of the aforementioned
composite. Using this approach, explicit upper bounds are computed for the
absolute value of a periodic point of H_p whose parity vector contains at least
ceil(ln(p)/ln2)-1 zeroes between any two consecutive ones
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 01:46:41 GMT""}]","2020-03-02"
"2003.00869","Fateme Sarkohaki","Fatemeh Sarkohaki, Reza Fotohi, Vahab Ashrafian","An Efficient Routing Protocol in Mobile Ad-hoc Networks by using
  Artificial Immune System","8 pages, 10 figures, journal","International Journal of Advanced Computer Science and
  Applications (IJACSA), 8(4), 554-561 (2017)","10.14569/IJACSA.2017.080473",,"cs.NI cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Characteristics of the mobile ad-hoc networks such as nodes high mobility and
limited energy are regarded as the routing challenges in these networks. OLSR
protocol is one of the routing protocols in mobile ad hoc network that selects
the shortest route between source and destination through Dijkstra's algorithm.
However, OLSR suffers from a major problem. It does not consider parameters
such as nodes energy level and links length in its route processing. This paper
employs the artificial immune system (AIS) to enhance efficiency of OLSR
routing protocol. The proposed algorithm, called AIS-OLSR, considers hop count,
remaining energy in the intermediate nodes, and distance among node, which is
realized by negative selection and ClonalG algorithms of AIS. Widespread packet
- level simulation in ns-2 environment, shows that AIS-OLSR outperforms OLSR
and EA-OLSR in terms of packet delivery ratio, throughput, end-end delay and
lifetime.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:56:08 GMT""}]","2020-03-03"
"2003.00872","Yunchao Wei","Zilong Huang and Yunchao Wei and Xinggang Wang and Wenyu Liu and
  Thomas S. Huang and Humphrey Shi","AlignSeg: Feature-Aligned Segmentation Networks","Accepted by TPAMI 2021",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aggregating features in terms of different convolutional blocks or contextual
embeddings has been proven to be an effective way to strengthen feature
representations for semantic segmentation. However, most of the current popular
network architectures tend to ignore the misalignment issues during the feature
aggregation process caused by 1) step-by-step downsampling operations, and 2)
indiscriminate contextual information fusion. In this paper, we explore the
principles in addressing such feature misalignment issues and inventively
propose Feature-Aligned Segmentation Networks (AlignSeg). AlignSeg consists of
two primary modules, i.e., the Aligned Feature Aggregation (AlignFA) module and
the Aligned Context Modeling (AlignCM) module. First, AlignFA adopts a simple
learnable interpolation strategy to learn transformation offsets of pixels,
which can effectively relieve the feature misalignment issue caused by
multiresolution feature aggregation. Second, with the contextual embeddings in
hand, AlignCM enables each pixel to choose private custom contextual
information in an adaptive manner, making the contextual embeddings aligned
better to provide appropriate guidance. We validate the effectiveness of our
AlignSeg network with extensive experiments on Cityscapes and ADE20K, achieving
new state-of-the-art mIoU scores of 82.6% and 45.95%, respectively. Our source
code will be made available.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 10:00:58 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 04:34:05 GMT""}]","2021-03-03"
"2003.00873","Xiaojie Wu","Xiaojie Wu, Michael Lindsey, Tiangang Zhou, Yu Tong and Lin Lin","Enhancing robustness and efficiency of density matrix embedding theory
  via semidefinite programming and local correlation potential fitting","36 pages, 9 figures","Phys. Rev. B 102, 085123 (2020)","10.1103/PhysRevB.102.085123",,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Density matrix embedding theory (DMET) is a powerful quantum embedding method
for solving strongly correlated quantum systems. Theoretically, the performance
of a quantum embedding method should be limited by the computational cost of
the impurity solver. However, the practical performance of DMET is often
hindered by the numerical stability and the computational time of the
correlation potential fitting procedure, which is defined on a single-particle
level. Of particular difficulty are cases in which the effective
single-particle system is gapless or nearly gapless. To alleviate these issues,
we develop a semidefinite programming (SDP) based approach that can
significantly enhance the robustness of the correlation potential fitting
procedure compared to the traditional least squares fitting approach. We also
develop a local correlation potential fitting approach, which allows one to
identify the correlation potential from each fragment independently in each
self-consistent field iteration, avoiding any optimization at the global level.
We prove that the self-consistent solutions of DMET using this local
correlation potential fitting procedure are equivalent to those of the original
DMET with global fitting. We find that our combined approach, called L-DMET, in
which we solve local fitting problems via semidefinite programming, can
significantly improve both the robustness and the efficiency of DMET
calculations. We demonstrate the performance of L-DMET on the 2D Hubbard model
and the hydrogen chain. We also demonstrate with theoretical and numerical
evidence that the use of a large fragment size can be a fundamental source of
numerical instability in the DMET procedure.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 07:57:34 GMT""}]","2020-08-19"
"2003.02966","Yusuke Fujita","Yusuke Fujita, Shinji Watanabe, Shota Horiguchi, Yawen Xue, Kenji
  Nagamatsu","End-to-End Neural Diarization: Reformulating Speaker Diarization as
  Simple Multi-label Classification","Submission to IEEE TASLP. This article draws from our previous
  conference papers: arxiv:1909.06247 and arxiv:1909.05952",,,,"eess.AS cs.CL cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The most common approach to speaker diarization is clustering of speaker
embeddings. However, the clustering-based approach has a number of problems;
i.e., (i) it is not optimized to minimize diarization errors directly, (ii) it
cannot handle speaker overlaps correctly, and (iii) it has trouble adapting
their speaker embedding models to real audio recordings with speaker overlaps.
To solve these problems, we propose the End-to-End Neural Diarization (EEND),
in which a neural network directly outputs speaker diarization results given a
multi-speaker recording. To realize such an end-to-end model, we formulate the
speaker diarization problem as a multi-label classification problem and
introduce a permutation-free objective function to directly minimize
diarization errors. Besides its end-to-end simplicity, the EEND method can
explicitly handle speaker overlaps during training and inference. Just by
feeding multi-speaker recordings with corresponding speaker segment labels, our
model can be easily adapted to real conversations. We evaluated our method on
simulated speech mixtures and real conversation datasets. The results showed
that the EEND method outperformed the state-of-the-art x-vector
clustering-based method, while it correctly handled speaker overlaps. We
explored the neural network architecture for the EEND method, and found that
the self-attention-based neural network was the key to achieving excellent
performance. In contrast to conditioning the network only on its previous and
next hidden states, as is done using bidirectional long short-term memory
(BLSTM), self-attention is directly conditioned on all the frames. By
visualizing the attention weights, we show that self-attention captures global
speaker characteristics in addition to local speech activity dynamics, making
it especially suitable for dealing with the speaker diarization problem.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 14:53:32 GMT""}]","2020-03-09"
"2003.04802","Nikos Prantzos","Nikos Prantzos","A probabilistic analysis of the Fermi paradox in terms of the Drake
  formula: the role of the L factor","A few typos corrected, matches published version",,"10.1093/mnras/staa512",,"physics.pop-ph astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In evaluating the number of technological civilizations N in the Galaxy
through the Drake formula, emphasis is mostly put on the astrophysical and
biotechnological factors describing the emergence of a civilization and much
less on its the lifetime, which is intimately related to its demise. It is
argued here that this factor is in fact the most important regarding the
practical implications of the Drake formula, because it determines the maximal
extent of the ""sphere of influence"" of any technological civilization. The
Fermi paradox is studied in the terms of a simplified version of the Drake
formula, through Monte Carlo simulations of N civilizations expanding in the
Galaxy during their space faring lifetime L. In the framework of that scheme,
the probability of ""direct contact"" is determined as the fraction of the
Galactic volume occupied collectively by the ""spheres of influence"" of N
civilizations. The results of the analysis are used to determine regions in the
parameter space where the Fermi paradox holds. It is argued that in a large
region of the diagram the corresponding parameters suggest rather a ""weak""
Fermi paradox. Future research may reveal whether a ""strong"" paradox holds in
some part of the parameter space. Finally, it is argued that the value of N is
not bound by N=1 from below, contrary to what is usually assumed, but it may
have a statistical interpretation.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 15:36:15 GMT""},{""version"":""v2"",""created"":""Tue, 22 Sep 2020 12:57:51 GMT""}]","2020-09-23"
"2003.11637","Pravin Game","Pravin S Game, Dr. Vinod Vaze, Dr. Emmanuel M","Bio-inspired Optimization: metaheuristic algorithms for optimization",,"pp. 1-9, (17-18 January 2020)",,"ISBN- 978-819-20113-4-9","cs.NE cs.AI cs.MA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In today's day and time solving real-world complex problems has become
fundamentally vital and critical task. Many of these are combinatorial
problems, where optimal solutions are sought rather than exact solutions.
Traditional optimization methods are found to be effective for small scale
problems. However, for real-world large scale problems, traditional methods
either do not scale up or fail to obtain optimal solutions or they end-up
giving solutions after a long running time. Even earlier artificial
intelligence based techniques used to solve these problems could not give
acceptable results. However, last two decades have seen many new methods in AI
based on the characteristics and behaviors of the living organisms in the
nature which are categorized as bio-inspired or nature inspired optimization
algorithms. These methods, are also termed meta-heuristic optimization methods,
have been proved theoretically and implemented using simulation as well used to
create many useful applications. They have been used extensively to solve many
industrial and engineering complex problems due to being easy to understand,
flexible, simple to adapt to the problem at hand and most importantly their
ability to come out of local optima traps. This local optima avoidance property
helps in finding global optimal solutions. This paper is aimed at understanding
how nature has inspired many optimization algorithms, basic categorization of
them, major bio-inspired optimization algorithms invented in recent time with
their applications.
","[{""version"":""v1"",""created"":""Mon, 24 Feb 2020 13:26:34 GMT""}]","2020-03-27"
"2003.13393","Venkatasubramanian Viswanathan","Ying Yuan and Gregory Houchins and Pin-Wen Guan and Venkatasubramanian
  Viswanathan","Uncertainty Quantification of First Principles Computational Phase
  Diagram Predictions of Li-Si System Via Bayesian Sampling","10 pages, 5 figures with Supplementary Materials of 7 pages, 13
  figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, an assessment of the CALPHAD method trained on only density
functional theory (DFT) data is performed for the Li-Si binary system, as a
case study. Using a parameter sampling approach based on the Bayesian Error
Estimation Functional (BEEF-vdW) exchange-correlation potential. By using
built-in ensemble of functionals from BEEF-vdW, the uncertainties of the Gibbs
Free Energy fitting parameters are obtained and can be propagated to the
resulting phase diagram. To find the best fitting form of the CALPHAD model, we
implement a model selection step using the Bayesian information criterion
(BIC). Applying the best selected CALPHAD model from the DFT calculation, to
other sampled BEEF functionals, an ensemble of CALPHAD models is generated
leading to an ensemble of phase diagram predictions. The resulting phase
diagrams are then compiled into a single-phase diagram representing the most
probable phase predicted as well as a quantitative metric of confidence for the
prediction. This treatment of uncertainty resulting from DFT provides a
rigorous way to ensure the correlated errors of DFT is accounted for in the
estimation of uncertainty. From the phase diagram, we have determined
intercalation voltages for lithiated silicon. In combination, we can generate a
better understanding of the phase transitions and voltage profile to make a
more analysis-informed prediction for experiments and the performance of
Si-anodes within batteries.
","[{""version"":""v1"",""created"":""Sun, 23 Feb 2020 20:36:42 GMT""}]","2020-03-31"
