"2012.06847","Zana Bu\c{c}inca","Zana Bucinca, Yucel Yemez, Engin Erzin, Metin Sezgin","AffectON: Incorporating Affect Into Dialog Generation",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Due to its expressivity, natural language is paramount for explicit and
implicit affective state communication among humans. The same linguistic
inquiry (e.g., How are you?) might induce responses with different affects
depending on the affective state of the conversational partner(s) and the
context of the conversation. Yet, most dialog systems do not consider affect as
constitutive aspect of response generation. In this paper, we introduce
AffectON, an approach for generating affective responses during inference. For
generating language in a targeted affect, our approach leverages a
probabilistic language model and an affective space. AffectON is language model
agnostic, since it can work with probabilities generated by any language model
(e.g., sequence-to-sequence models, neural language models, n-grams). Hence, it
can be employed for both affective dialog and affective language generation. We
experimented with affective dialog generation and evaluated the generated text
objectively and subjectively. For the subjective part of the evaluation, we
designed a custom user interface for rating and provided recommendations for
the design of such interfaces. The results, both subjective and objective
demonstrate that our approach is successful in pulling the generated language
toward the targeted affect, with little sacrifice in syntactic coherence.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:02:08 GMT""}]","2020-12-15"
"2012.06848","Arnaud Liehrmann","Arnaud Liehrmann, Guillem Rigaill and Toby Dylan Hocking","Increased peak detection accuracy in over-dispersed ChIP-seq data with
  supervised segmentation models","20 pages, 8 figures; updated broken citations and references",,,,"q-bio.QM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivation: Histone modification constitutes a basic mechanism for the
genetic regulation of gene expression. In early 2000s, a powerful technique has
emerged that couples chromatin immunoprecipitation with high-throughput
sequencing (ChIP-seq). This technique provides a direct survey of the DNA
regions associated to these modifications. In order to realize the full
potential of this technique, increasingly sophisticated statistical algorithms
have been developed or adapted to analyze the massive amount of data it
generates. Many of these algorithms were built around natural assumptions such
as the Poisson one to model the noise in the count data. In this work we start
from these natural assumptions and show that it is possible to improve upon
them. Results: The results of our comparisons on seven reference datasets of
histone modifications (H3K36me3 and H3K4me3) suggest that natural assumptions
are not always realistic under application conditions. We show that the
unconstrained multiple changepoint detection model, with alternative noise
assumptions and a suitable setup, reduces the over-dispersion exhibited by
count data and turns out to detect peaks more accurately than algorithms which
rely on these natural assumptions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:03:27 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 12:34:48 GMT""}]","2020-12-16"
"2012.06849","Sedigheh Jahedi","Sedigheh Jahedi and Vahid Keshavarz","Approximate Generalized Additive-Quadratic Functional Equations on
  Ternary Banach Algebras",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce the concept of j-hom-derivation, $j\in\{1,2\}$
and solve the new generalized additive-quadratic functional equations in the
sense of ternary Banach algebras. Moreover, using the fixed point method, we
prove its Hyers-Ulam stability.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:03:49 GMT""}]","2020-12-15"
"2012.06850","Yifan Xu","Yifan Xu and Pan Xu","Trading the System Efficiency for the Income Equality of Drivers in
  Rideshare","Accepted by IJCAI2020
  (http://static.ijcai.org/2020-accepted_papers.html) and SOLE copyright holder
  is IJCAI (International Joint Conferences on Artificial Intelligence), all
  rights reserved","IJCAI 2020","10.24963/ijcai.2020/580",,"cs.AI cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several scientific studies have reported the existence of the income gap
among rideshare drivers based on demographic factors such as gender, age, race,
etc. In this paper, we study the income inequality among rideshare drivers due
to discriminative cancellations from riders, and the tradeoff between the
income inequality (called fairness objective) with the system efficiency
(called profit objective). We proposed an online bipartite-matching model where
riders are assumed to arrive sequentially following a distribution known in
advance. The highlight of our model is the concept of acceptance rate between
any pair of driver-rider types, where types are defined based on demographic
factors. Specially, we assume each rider can accept or cancel the driver
assigned to her, each occurs with a certain probability which reflects the
acceptance degree from the rider type towards the driver type. We construct a
bi-objective linear program as a valid benchmark and propose two LP-based
parameterized online algorithms. Rigorous online competitive ratio analysis is
offered to demonstrate the flexibility and efficiency of our online algorithms
in balancing the two conflicting goals, promotions of fairness and profit.
Experimental results on a real-world dataset are provided as well, which
confirm our theoretical predictions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:04:06 GMT""}]","2020-12-17"
"2012.06851","Juan Saenz","J. A. Saenz, D. Aslangil and D. Livescu","Filtering, averaging and scale dependency in homogeneous variable
  density turbulence",,,"10.1063/5.0040337","LA-UR-20-29879","physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We investigate relationships between statistics obtained from filtering and
from ensemble or Reynolds-averaging turbulence flow fields as a function of
length scale. Generalized central moments in the filtering approach are
expressed as inner products of generalized fluctuating quantities,
$q'(\xi,x)=q(\xi)-\overline q(x)$, representing fluctuations of a field
$q(\xi)$, at any point $\xi$, with respect to its filtered value at $x$. For
positive-definite filter kernels, these expressions provide a scale-resolving
framework, with statistics and realizability conditions at any length scale. In
the small-scale limit, scale-resolving statistics become zero. In the
large-scale limit, scale-resolving statistics and realizability conditions are
the same as in the Reynolds-averaged description. Using direct numerical
simulations (DNS) of homogeneous variable density turbulence, we diagnose
Reynolds stresses, $\mathcal{T}_{ij}$, resolved kinetic energy, $k_r$,
turbulent mass-flux velocity, $a_i$, and density-specific volume covariance,
$b$, defined in the scale-resolving framework. These variables, and terms in
their governing equations, vary smoothly between zero and their
Reynolds-averaged definitions at the small and large scale limits,
respectively. At intermediate scales, the governing equations exhibit
interactions between terms that are not active in the Reynolds-averaged limit.
For example, in the Reynolds-averaged limit, $b$ follows a decaying process
driven by a destruction term; at intermediate length scales it is a balance
between production, redistribution, destruction, and transport, where $b$ grows
as the density spectrum develops, and then decays when mixing becomes strong
enough. This work supports the notion of a generalized, length-scale adaptive
model that converges to DNS at high resolutions, and to Reynolds-averaged
statistics at coarse resolutions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:10:15 GMT""}]","2021-03-17"
"2012.06852","Junliang Yu","Xin Xia, Hongzhi Yin, Junliang Yu, Qinyong Wang, Lizhen Cui,
  Xiangliang Zhang","Self-Supervised Hypergraph Convolutional Networks for Session-based
  Recommendation","9 pages, 4 figures, accepted by AAAI'21. Correct some typos in the
  previous version",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Session-based recommendation (SBR) focuses on next-item prediction at a
certain time point. As user profiles are generally not available in this
scenario, capturing the user intent lying in the item transitions plays a
pivotal role. Recent graph neural networks (GNNs) based SBR methods regard the
item transitions as pairwise relations, which neglect the complex high-order
information among items. Hypergraph provides a natural way to capture
beyond-pairwise relations, while its potential for SBR has remained unexplored.
In this paper, we fill this gap by modeling session-based data as a hypergraph
and then propose a hypergraph convolutional network to improve SBR. Moreover,
to enhance hypergraph modeling, we devise another graph convolutional network
which is based on the line graph of the hypergraph and then integrate
self-supervised learning into the training of the networks by maximizing mutual
information between the session representations learned via the two networks,
serving as an auxiliary task to improve the recommendation task. Since the two
types of networks both are based on hypergraph, which can be seen as two
channels for hypergraph modeling, we name our model \textbf{DHCN} (Dual Channel
Hypergraph Convolutional Networks). Extensive experiments on three benchmark
datasets demonstrate the superiority of our model over the SOTA methods, and
the results validate the effectiveness of hypergraph modeling and
self-supervised task. The implementation of our model is available at
https://github.com/xiaxin1998/DHCN
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:19:49 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 03:33:02 GMT""},{""version"":""v3"",""created"":""Wed, 3 Mar 2021 04:09:09 GMT""},{""version"":""v4"",""created"":""Mon, 15 Mar 2021 07:45:25 GMT""},{""version"":""v5"",""created"":""Mon, 28 Feb 2022 10:25:49 GMT""}]","2022-03-01"
"2012.06853","Saleh Rahimi-Keshari","Saleh Rahimi-Keshari, Mohammad Mehboudi, Dario De Santis, Daniel
  Cavalcanti, Antonio Ac\'in","Verification of joint measurability using phase-space quasiprobability
  distributions","9 pages, 1 figure, 1 table",,"10.1103/PhysRevA.104.042212",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measurement incompatibility is a distinguishing property of quantum physics
and an essential resource for many quantum information processing tasks. We
introduce an approach to verify the joint measurability of measurements based
on phase-space quasiprobability distributions. Our results therefore establish
a connection between two notions of non-classicality, namely the negativity of
quasiprobability distributions and measurement incompatibility. We show how our
approach can be applied to the study of incompatibility-breaking channels and
derive incompatibility-breaking sufficient conditions for bosonic systems and
Gaussian channels. In particular, these conditions provide useful tools for
investigating the effects of errors and imperfections on the incompatibility of
measurements in practice. To illustrate our method, we consider all classes of
single-mode Gaussian channels. We show that pure lossy channels with 50% or
more losses break the incompatibility of all measurements that can be
represented by non-negative Wigner functions, which includes the set of
Gaussian measurements.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:21:36 GMT""}]","2021-10-27"
"2012.06854","Samaneh Esfandiarpour","Samaneh Esfandiarpour, J. Todd Hastings","Limiting Regimes for Electron-Beam Induced Deposition of Copper from
  Aqueous Solutions Containing Surfactants","19 pages, 9 figures, submitted to Nanotechnology IOP Science",,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Focused electron beam induced deposition of pure materials from aqueous
solutions has been of interest in recent years. However, controlling the liquid
film in partial vacuum is challenging. Here we modify the substrate to increase
control over the liquid layer in order to conduct a parametric study of copper
deposition in an environmental SEM. We identified the transition from electron
to mass-transport limited deposition as well as two additional regimes
characterized by aggregated and high-aspect ratio deposits. We observe a high
deposition efficiency of 1 to 10 copper atoms per primary electron that is
consistent with a radiation chemical model of the deposition process.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:29:02 GMT""}]","2020-12-15"
"2012.06855","Sarah Allahmoradi","Sarah Allahmoradi (Student Member, IEEE), Mohsen Parsa Moghaddam
  (Senior Member, IEEE), Salah Bahramara (Member, IEEE), and Pouria
  Sheikhahmadi","Flexibility-constrained Operation Scheduling of Active Distribution
  Networks with Microgrids",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Regarding the variability of renewable energy sources (RESs), especially in
the operation time periods, their high penetration faces the net load pattern
of the power system with a major ramp rate challenge. Although employing a
market-based mechanism by the independent system operator (ISO) can address
this challenge, it may not be possible to handle this challenge in all
networks. In such networks, the required flexibility can be supplied by
decreasing the ramp rate of the purchased power of distribution companies
(Discos) from the market since their net load has an important impact on the
system's netload. Therefore, a flexibility-constrained operation problem for
the distribution networks with distributed energy resources (DERs) and
microgrids (MGs) is proposed in this paper to decrease the ramp-rate of the
Disco's purchased power from the market. This problem is formulated using a
bi-level two-stage stochastic model where the problem of the Disco and the MGs
are modeled as the upper-level and lower-level problems, respectively. The
proposed model is applied to the IEEE 33-bus standard test network with three
MGs. The results show the effectiveness of the proposed model to decrease the
ramp-rate of the Disco's purchased power from the market.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:36:02 GMT""}]","2020-12-15"
"2012.06856","Leonidas Karakatsanis","Ioannis P. Antoniades, Leonidas P. Karakatsanis, Evgenios G. Pavlos","Dynamical Characteristics of Global Stock Markets Based on Time
  Dependent Tsallis Non-Extensive Statistics and Generalized Hurst Exponents","30 pages, 6 figures",,"10.1016/j.physa.2021.126121",,"q-fin.ST","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform non-linear analysis on stock market indices using time-dependent
extended Tsallis statistics. Specifically, we evaluate the q-triplet for
particular time periods with the purpose of demonstrating the temporal
dependence of the extended characteristics of the underlying market dynamics.
We apply the analysis on daily close price timeseries of four major global
markets (S&P 500, Tokyo-NIKKEI, Frankfurt-DAX, London-LSE). For comparison, we
also compute time-dependent Generalized Hurst Exponents (GHE) Hq using the GHE
method, thus estimating the temporal evolution of the multiscaling
characteristics of the index dynamics. We focus on periods before and after
critical market events such as stock market bubbles (2000 dot.com bubble,
Japanese 1990 bubble, 2008 US real estate crisis) and find that the temporal
trends of q-triplet values significantly differ among these periods indicating
that in the rising period before a bubble break, the underlying extended
statistics of the market dynamics strongly deviates from purely stochastic
behavior, whereas, after the breakdown, it gradually converges to the
Gaussian-like behavior which is a characteristic of an efficient market. We
also conclude that relative temporal variation patterns of the Tsallis
q-triplet can be connected to different aspects of market dynamics and reveals
useful information about market conditions especially those underlying the
development of a stock market bubble. We found specific temporal patterns and
trends in the relative variation of the indices in the q-triplet that
distinguish periods just before and just after a stock-market bubble break.
Differences between endogenous and exogenous stock market crises are also
captured by the temporal changes in the Tsallis q-triplet. Finally, we
introduce two new time-dependent empirical metrics (Q-metrics) that are
functions of the Tsallis q-triplet.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:36:41 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 18:29:32 GMT""}]","2021-06-30"
"2012.06857","Ho Sang Chan","H-S. Chan, M-C. Chu, S-C. Leung, L-M. Lin","Delayed Detonation Thermonuclear Supernovae With An Extended Dark Matter
  Component","17 pages, 17 figures",,"10.3847/1538-4357/abfd32",,"astro-ph.HE astro-ph.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present simulations of thermonuclear supernovae admixed with an extended
component of fermionic cold dark matter. We consider the explosion of a
Chandrasekhar-mass white dwarf using the deflagration model with
deflagration-detonation transition with spherical symmetry. The dark matter
component is comparable in size with that of the normal matter, and so the
system is described by two-fluid, one-dimensional Eulerian hydrodynamics. The
explosion leaves all the dark matter trapped as a remnant compact dark star in
all of our considered models. The presence of dark matter lengthens the
deflagration phase to produce more thermo-neutrinos and similar amounts of
iron-group elements compared to those of ordinary explosions with no dark
matter admixture. The dark matter admixed models produce dimmer and broader
light curves, which challenge the role of thermonuclear supernovae as standard
candles in cosmic distance measurement. Our results also suggest a formation
path of dark compact objects which mimic sub-solar-mass black holes as dark
gravitational sources, through near-solar-mass dark matter admixed
thermonuclear supernovae.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:46:26 GMT""}]","2021-06-30"
"2012.06858","David Mallas\'en Quintana","David Mallas\'en Quintana, Alberto Antonio del Barrio Garc\'ia and
  Manuel Prieto Mat\'ias","LiveChess2FEN: a Framework for Classifying Chess Pieces based on CNNs","The complete source code of the LiveChess2FEN framework is publicly
  available with an open-source license in our GitHub repository:
  https://github.com/davidmallasen/LiveChess2FEN",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic digitization of chess games using computer vision is a significant
technological challenge. This problem is of much interest for tournament
organizers and amateur or professional players to broadcast their
over-the-board (OTB) games online or analyze them using chess engines. Previous
work has shown promising results, but the recognition accuracy and the latency
of state-of-the-art techniques still need further enhancements to allow their
practical and affordable deployment. We have investigated how to implement them
on an Nvidia Jetson Nano single-board computer effectively. Our first
contribution has been accelerating the chessboard's detection algorithm.
Subsequently, we have analyzed different Convolutional Neural Networks for
chess piece classification and how to map them efficiently on our embedded
platform. Notably, we have implemented a functional framework that
automatically digitizes a chess position from an image in less than 1 second,
with 92% accuracy when classifying the pieces and 95% when detecting the board.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:48:40 GMT""}]","2020-12-15"
"2012.06859","Savas Ozkan","Savas Ozkan, Gozde Bozdagi Akar","Spectral Unmixing With Multinomial Mixture Kernel and Wasserstein
  Generative Adversarial Loss","AI for Earth Sciences Workshop at NeurIPS 2020",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This study proposes a novel framework for spectral unmixing by using 1D
convolution kernels and spectral uncertainty. High-level representations are
computed from data, and they are further modeled with the Multinomial Mixture
Model to estimate fractions under severe spectral uncertainty. Furthermore, a
new trainable uncertainty term based on a nonlinear neural network model is
introduced in the reconstruction step. All uncertainty models are optimized by
Wasserstein Generative Adversarial Network (WGAN) to improve stability and
capture uncertainty. Experiments are performed on both real and synthetic
datasets. The results validate that the proposed method obtains
state-of-the-art performance, especially for the real datasets compared to the
baselines. Project page at: https://github.com/savasozkan/dscn.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:49:01 GMT""}]","2020-12-15"
"2012.06860","Chen-Feng Liu","Yung-Lin Hsu, Chen-Feng Liu, Sumudu Samarakoon, Hung-Yu Wei, Mehdi
  Bennis","Age-Optimal Power Allocation in Industrial IoT: A Risk-Sensitive
  Federated Learning Approach","Accepted in IEEE PIMRC 2021 with 6 pages and 8 figures",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work studies a real-time environment monitoring scenario in the
industrial Internet of things, where wireless sensors proactively collect
environmental data and transmit it to the controller. We adopt the notion of
risk-sensitivity in financial mathematics as the objective to jointly minimize
the mean, variance, and other higher-order statistics of the network energy
consumption subject to the constraints on the age of information (AoI)
threshold violation probability and the AoI exceedances over a pre-defined
threshold. We characterize the extreme AoI staleness using results in extreme
value theory and propose a distributed power allocation approach by weaving in
together principles of Lyapunov optimization and federated learning (FL).
Simulation results demonstrate that the proposed FL-based distributed solution
is on par with the centralized baseline while consuming 28.50% less system
energy and outperforms the other baselines.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 16:53:59 GMT""},{""version"":""v2"",""created"":""Sun, 13 Jun 2021 06:40:37 GMT""}]","2021-06-15"
"2012.06861","Paolo Lipari","Paolo Lipari","The spectra and composition of Ultra High Energy Cosmic Rays and the
  measurement of the proton-air cross section","39 pages, 19 figures","Phys. Rev. D 103, 103009 (2021)","10.1103/PhysRevD.103.103009",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The shape of the longitudinal development of the showers generated in the
atmosphere by very high energy cosmic ray particles encodes information about
the mass composition of the flux, and about the properties of hadronic
interactions that control the shower development. Studies of the energy
dependence of the average and width of the depth of maximum distribution of
showers with $E \gtrsim 10^{17.3}$ eV measured by the Pierre Auger Observatory,
suggest, on the basis of a comparison with current models, that the composition
of the cosmic ray flux undergoes a very important evolution, first becoming
lighter and then rapidly heavier. These conclusions, if confirmed, would have
profound and very surprising implications for our understanding of the high
energy astrophysical sources. Studies of the shape of the depth of maximum
distribution in the same energy range have been used by Auger and by the
Telescope Array Collaboration to measure the interaction length of protons in
air, a quantity that allows to estimate the $pp$ cross sections for values of
$\sqrt{s}$ well above the LHC range. In this paper we argue that it is
desirable to combine the studies of the cosmic ray composition with those aimed
at the measurement of the $p$--air cross section. The latter allow to obtain
estimates for the fraction of protons in the flux that can be of great help in
decoding the composition and its energy dependence. Studies that consider
multiple parameters to characterize the depth of maximum distributions also
offer the possibility to perform more sensitive tests of the validity of the
models used to describe high energy showers.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:03:35 GMT""}]","2021-05-19"
"2012.06862","Kenneth Harris","Kenneth D. Harris","A Shift Test for Independence in Generic Time Series",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  We describe a family of conservative statistical tests for independence of
two autocorrelated time series. The series may take values in any sets, and one
of them must be stationary. A user-specified function quantifying the
association of a segment of the two series is compared to an ensemble obtained
by time-shifting the stationary series -N to N steps. If the series are
independent, the unshifted value is in the top m shifted values with
probability at most m/(N+1). For large N, the probability approaches m/(2N+1).
A conservative test rejects independence at significance {\alpha} if the
unshifted value is in the top {\alpha}(N+1), and has half the power of an
approximate test valid in the large N limit. We illustrate this framework with
a test for correlation of autocorrelated categorical time series.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:09:13 GMT""}]","2020-12-15"
"2012.06863","Francesco De Lellis","Francesco De Lellis, Giovanni Russo, Mario di Bernardo","Tutoring Reinforcement Learning via Feedback Control",,,"10.23919/ECC54610.2021.9654881",,"math.OC cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We introduce a control-tutored reinforcement learning (CTRL) algorithm. The
idea is to enhance tabular learning algorithms by means of a control strategy
with limited knowledge of the system model. By tutoring the learning process,
the learning rate can be substantially reduced. We use the classical problem of
stabilizing an inverted pendulum as a benchmark to numerically illustrate the
advantages and disadvantages of the approach.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:13:22 GMT""}]","2022-04-14"
"2012.06864","Volodymyr Takhistov","Volodymyr Takhistov (for the Super-Kamiokande Collaboration)","Review of Atmospheric Neutrino Results from Super-Kamiokande","6 pages, 3 figures, proceedings of 40th International Conference on
  High Energy Physics (ICHEP-2020), July 28 - August 6, 2020, Prague, Czech
  Republic",,,"IPMU20-0129","hep-ex astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While neutrino physics enters precision era, several important unknowns
remain. Atmospheric neutrinos allow to simultaneously test key oscillation
parameters, with Super-Kamiokande experiment playing a central role. We discuss
results from atmospheric neutrino oscillation analysis of the full dataset from
Super-Kamiokande I-IV phases. Further, we discuss tests of non-standard
neutrino interactions with atmospheric neutrinos in Super-Kamiokande.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:13:24 GMT""}]","2020-12-15"
"2012.06865","Falco J. Bargagli Stoffi","Francesca Dominici and Falco J. Bargagli-Stoffi and Fabrizia Mealli","From controlled to undisciplined data: estimating causal effects in the
  era of data science using a potential outcome framework",,"Harvard Data Science Review (2021)","10.1162/99608f92.8102afed",,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  This paper discusses the fundamental principles of causal inference - the
area of statistics that estimates the effect of specific occurrences,
treatments, interventions, and exposures on a given outcome from experimental
and observational data. We explain the key assumptions required to identify
causal effects, and highlight the challenges associated with the use of
observational data. We emphasize that experimental thinking is crucial in
causal inference. The quality of the data (not necessarily the quantity), the
study design, the degree to which the assumptions are met, and the rigor of the
statistical analysis allow us to credibly infer causal effects. Although we
advocate leveraging the use of big data and the application of machine learning
(ML) algorithms for estimating causal effects, they are not a substitute of
thoughtful study design. Concepts are illustrated via examples.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:15:46 GMT""}]","2021-12-03"
"2012.06866","Alexandr Polujan","Wilfried Meidl and Alexandr A. Polujan and Alexander Pott","Linear codes and incidence structures of bent functions and their
  generalizations","This is the authors' version of the published manuscript. The main
  difference to the previous version is the updated sections 2.1 and 2.2","Discrete Mathematics, Volume 346, Issue 1, January 2023, 113157",,,"cs.IT math.CO math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper we consider further applications of $(n,m)$-functions for the
construction of 2-designs. For instance, we provide a new application of the
extended Assmus-Mattson theorem, by showing that linear codes of APN functions
with the classical Walsh spectrum support 2-designs. On the other hand, we use
linear codes and combinatorial designs in order to study important properties
of $(n,m)$-functions. In particular, we give a new design-theoretic
characterization of $(n,m)$-plateaued and $(n,m)$-bent functions and provide a
coding-theoretic as well as a design-theoretic interpretation of the
extendability problem for $(n,m)$-bent functions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:20:02 GMT""},{""version"":""v2"",""created"":""Wed, 10 May 2023 08:44:24 GMT""}]","2023-05-11"
"2012.06867","Arsha Nagrani","Arsha Nagrani, Joon Son Chung, Jaesung Huh, Andrew Brown, Ernesto
  Coto, Weidi Xie, Mitchell McLaren, Douglas A Reynolds and Andrew Zisserman","VoxSRC 2020: The Second VoxCeleb Speaker Recognition Challenge",,,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by/4.0/","  We held the second installment of the VoxCeleb Speaker Recognition Challenge
in conjunction with Interspeech 2020. The goal of this challenge was to assess
how well current speaker recognition technology is able to diarise and
recognize speakers in unconstrained or `in the wild' data. It consisted of: (i)
a publicly available speaker recognition and diarisation dataset from YouTube
videos together with ground truth annotation and standardised evaluation
software; and (ii) a virtual public challenge and workshop held at Interspeech
2020. This paper outlines the challenge, and describes the baselines, methods
used, and results. We conclude with a discussion of the progress over the first
installment of the challenge.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:20:57 GMT""}]","2020-12-15"
"2012.06868","Amit Kanigel","A. Almoalem, I. Silber, S. Sandik, M. Lotem, A. Ribak, Y. Nitzav,
  A.Yu. Kuntsevich, O.A. Sobolevskiy, Yu.G. Selivanov, V.A. Prudkoglyad, M.Shi,
  L. Petaccia, M. Goldstein, Y. Dagan and A. Kanigel","Link between superconductivity and a Lifshitz transition in intercalated
  Bi$_2$Se$_3$",,"Phys. Rev. B 103, 174518 (2021)","10.1103/PhysRevB.103.174518",,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Topological superconductivity is an exotic phase of matter in which the fully
gapped superconducting bulk hosts gapless Majorana surface states protected by
topology. Intercalation of copper, strontium or niobium between the quintuple
layers of the topological insulator Bi$_2$Se$_3$ increases the carrier density
and leads to superconductivity that is suggested to be topological. Here we
study the electronic structure of strontium-intercalated Bi$_2$Se$_3$ using
angle resolved photoemission spectroscopy (ARPES) and Shubnikov-de Haas (SdH)
oscillations. Despite the apparent low Hall number of $\sim2 \times 10
^{19}$cm$^{-3}$, we show that the Fermi surface is shaped as an open cylinder
with a larger carrier density of $\sim 10 ^{20}$cm$^{-3}$. We suggest that
superconductivity in intercalated Bi$_2$Se$_3$ emerges with the appearance of a
quasi-2D open Fermi surface.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:25:37 GMT""},{""version"":""v2"",""created"":""Sat, 19 Dec 2020 10:42:08 GMT""}]","2021-06-02"
"2012.06869","Grigoris Panotopoulos","Grigoris Panotopoulos, Ilidio Lopes and Angel Rincon","Lagrangian formulation for an extended cosmological equation-of-state","6 pages, 3 figures","Phys. Dark Univ. 31 (2021) 100751","10.1016/j.dark.2020.100751",,"gr-qc astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the extended cosmological equation-of-state developed starting
from a Chaplygin equation-of-state, recently applied to stellar modeling, is a
viable dark energy model consistent with standard scalar potentials. Moreover
we find a Lagrangian formulation based on a canonical scalar field with the
appropriate self-interaction potential. Finally, we fit the scalar potential
obtained numerically with concrete functions well studied in the literature.
Our results may be of interest to model builders and particle physicists.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:28:41 GMT""}]","2020-12-15"
"2012.06870","Ludvig af Klinteberg","Ludvig af Klinteberg, Chiara Sorgentone, Anna-Karin Tornberg","Quadrature error estimates for layer potentials evaluated near curved
  surfaces in three dimensions",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quadrature error associated with a regular quadrature rule for evaluation
of a layer potential increases rapidly when the evaluation point approaches the
surface and the integral becomes nearly singular. Error estimates are needed to
determine when the accuracy is insufficient and a more costly special
quadrature method should be utilized.
  The final result of this paper are such quadrature error estimates for the
composite Gauss-Legendre rule and the global trapezoidal rule, when applied to
evaluate layer potentials defined over smooth curved surfaces in R^3. The
estimates have no unknown coefficients and can be efficiently evaluated given
the discretization of the surface, invoking a local one-dimensional
root-finding procedure. They are derived starting with integrals over curves,
using complex analysis involving contour integrals, residue calculus and branch
cuts. By complexifying the parameter plane, the theory can be used to derive
estimates also for curves in in R^3. These results are then used in the
derivation of the estimates for integrals over surfaces. In this procedure, we
also obtain error estimates for layer potentials evaluated over curves in R^2.
Such estimates combined with a local root-finding procedure for their
evaluation were earlier derived for the composite Gauss-Legendre rule for layer
potentials written on complex form [4]. This is here extended to provide
quadrature error estimates for both complex and real formulations of layer
potentials, both for the Gauss-Legendre and the trapezoidal rule.
  Numerical examples are given to illustrate the performance of the quadrature
error estimates. The estimates for integration over curves are in many cases
remarkably precise, and the estimates for curved surfaces in R^3 are also
sufficiently precise, with sufficiently low computational cost, to be
practically useful.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:34:09 GMT""},{""version"":""v2"",""created"":""Tue, 18 Jan 2022 20:17:04 GMT""}]","2022-01-20"
"2012.06871","Shivam Kumar Mishra","Shivam Kumar Mishra, Sudip Sengupta","Exact Solution of Hartemann-Luhmann Equation of Motion for a Charged
  Particle interacting with an Intense Electromagnetic Wave/Pulse","21 pages, 7 figures",,"10.1140/epjs/s11734-021-00260-4",,"physics.plasm-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  We report an exact solution of the Hartemann-Luhmann equation of motion for a
charged particle interacting with an intense electromagnetic wave/pulse. It is
found that the radiation reaction force has a significant affect on the charged
particle dynamics and the particle shows, on average, a net energy gain over a
period of time. Further, using a MATHEMATICA based single particle code, the
net energy gained by the particle is compared with that obtained using
Landau-Lifshitz and Ford-O'connell equation of motion, for different
polarizations of the electromagnetic wave. It is found that the average energy
gain is independent of both the chosen model equation and polarization of the
electromagnetic wave. Our results thus show, that the simpler and hence
analytically tractable Hartemann-Luhmann equation of motion ( as compared to
Landau-Lifshitz and Ford-O'connell equation of motion) is adequate for
calculations of practical use (for e.g. energy calculation).
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:41:18 GMT""}]","2021-09-01"
"2012.06872","Kevin Lannon","Reza Goldouzian (1), Jeong Han Kim (1 and 2), Kevin Lannon (1), Adam
  Martin (1), Kelci Mohrman (1), Andrew Wightman (1) ((1) University of Notre
  Dame, (2) Chungbuk National University)","Matching in $pp \to t \bar{t} W/Z/h +$ jet SMEFT studies","35 pages, 16 figures","JHEP 06 (2021) 151","10.1007/JHEP06(2021)151",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper, we explore the impact of extra radiation on predictions of $pp
\to t\bar{t}X, X = h/W^{\pm}/Z$ processes within the dimension-6 SMEFT
framework. While full next-to-leading order calculations are of course
preferred, they are not always practical, and so it is useful to be able to
capture the impacts of extra radiation using leading-order matrix elements
matched to the parton shower. While a matched leading-order calculation for
$t\bar{t}X$ is not expected to reproduce the next-to-leading order inclusive
cross section precisely, we show that it does capture the relative impact of
the EFT effects by considering the ratio of matched SMEFT inclusive cross
sections to Standard Model values, $\sigma_{\rm SMEFT}(t\bar{t}Xj)/\sigma_{\rm
SM}(t\bar{t}Xj) \equiv \mu$. Furthermore, we compare leading order calculations
with and without extra radiation and find several cases, such as the effect of
the operator $(\varphi^{\dagger}i\!\overleftrightarrow{D}_{\!\mu}\varphi)
(\bar{t}\gamma^\mu t)$ on $t\bar{t}h$ and $t\bar{t}W$, for which the relative
cross section prediction increases by more than $10\%$ -- significantly larger
than the uncertainty derived by varying the input scales in the calculation,
including the additional scales required for matching. Being leading order at
heart, matching has the benefit that it can be applied to all operators and
processes relevant to $pp \to t\bar{t}X, X = h/W^{\pm}/Z +$ jet, is
computationally fast and not susceptible to negative weights. Therefore, it is
a useful approach in $t\bar{t}X+$ jet studies where complete next-to-leading
order results are currently unavailable or unwieldy.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:43:48 GMT""},{""version"":""v2"",""created"":""Tue, 18 Jan 2022 20:35:00 GMT""}]","2022-01-20"
"2012.06873","Chun-Hung Chao","Chun-Hung Chao, Hsien-Tzu Cheng, Tsung-Ying Ho, Le Lu, and Min Sun","Interactive Radiotherapy Target Delineation with 3D-Fused Context
  Propagation",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Gross tumor volume (GTV) delineation on tomography medical imaging is crucial
for radiotherapy planning and cancer diagnosis. Convolutional neural networks
(CNNs) has been predominated on automatic 3D medical segmentation tasks,
including contouring the radiotherapy target given 3D CT volume. While CNNs may
provide feasible outcome, in clinical scenario, double-check and prediction
refinement by experts is still necessary because of CNNs' inconsistent
performance on unexpected patient cases. To provide experts an efficient way to
modify the CNN predictions without retrain the model, we propose 3D-fused
context propagation, which propagates any edited slice to the whole 3D volume.
By considering the high-level feature maps, the radiation oncologists would
only required to edit few slices to guide the correction and refine the whole
prediction volume. Specifically, we leverage the backpropagation for activation
technique to convey the user editing information backwardly to the latent space
and generate new prediction based on the updated and original feature. During
the interaction, our proposed approach reuses the extant extracted features and
does not alter the existing 3D CNN model architectures, avoiding the
perturbation on other predictions. The proposed method is evaluated on two
published radiotherapy target contouring datasets of nasopharyngeal and
esophageal cancer. The experimental results demonstrate that our proposed
method is able to further effectively improve the existing segmentation
prediction from different model architectures given oncologists' interactive
inputs.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:46:20 GMT""}]","2020-12-15"
"2012.06874","Franz J. Brandenburg","Franz J. Brandenburg","Book Embeddings of k-Map Graphs",,,,,"cs.CG","http://creativecommons.org/licenses/by/4.0/","  A map is a partition of the sphere into regions that are labeled as countries
or holes. The vertices of a map graph are the countries of a map. There is an
edge if and only if the countries are adjacent and meet in at least one point.
For a k-map graph, at most k countries meet in a point. A graph is k-planar if
it can be drawn in the plane with at most k crossings per edge. A p-page book
embedding of a graph is a linear ordering of the vertices and an assignment of
the edges to p pages, so that there is no conflict for edges assigned to the
same page. The minimum number of pages is the book thickness of a graph, also
known as stack number or page number. We show that every k-map graph has a book
embedding in $6\lfloor k/2 \rfloor+5$ pages, which, for n-vertex graphs, can be
computed in O(kn) time from its map. Our result improves the best known upper
bound. Towards a lower bound, it is shown that some k-map graphs need $\lfloor
3k/4 \rfloor$ pages. In passing, we obtain an improved upper bound of eleven
pages for 1-planar graphs, which are subgraphs of 4-map graphs, and of 17 pages
for optimal 2-planar graphs.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:49:12 GMT""}]","2020-12-15"
"2012.06875","Jianan Chen","Jianan Chen, Helen M. C. Cheung, Laurent Milot, Anne L. Martel","AMINN: Autoencoder-based Multiple Instance Neural Network Improves
  Outcome Prediction of Multifocal Liver Metastases","Early accepted by MICCAI 2021",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Colorectal cancer is one of the most common and lethal cancers and colorectal
cancer liver metastases (CRLM) is the major cause of death in patients with
colorectal cancer. Multifocality occurs frequently in CRLM, but is relatively
unexplored in CRLM outcome prediction. Most existing clinical and imaging
biomarkers do not take the imaging features of all multifocal lesions into
account. In this paper, we present an end-to-end autoencoder-based multiple
instance neural network (AMINN) for the prediction of survival outcomes in
multifocal CRLM patients using radiomic features extracted from
contrast-enhanced MRIs. Specifically, we jointly train an autoencoder to
reconstruct input features and a multiple instance network to make predictions
by aggregating information from all tumour lesions of a patient. Also, we
incorporate a two-step normalization technique to improve the training of deep
neural networks, built on the observation that the distributions of radiomic
features are almost always severely skewed. Experimental results empirically
validated our hypothesis that incorporating imaging features of all lesions
improves outcome prediction for multifocal cancer. The proposed AMINN framework
achieved an area under the ROC curve (AUC) of 0.70, which is 11.4% higher than
the best baseline method. A risk score based on the outputs of AMINN achieved
superior prediction in our multifocal CRLM cohort. The effectiveness of
incorporating all lesions and applying two-step normalization is demonstrated
by a series of ablation studies. A Keras implementation of AMINN is released.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:52:14 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 21:04:00 GMT""}]","2021-07-13"
"2012.06876","Utkarsh Uppal","Utkarsh Uppal, Bharat Giddwani","Normalized Label Distribution: Towards Learning Calibrated, Adaptable
  and Efficient Activation Maps","Accepted in AAAI 2021 Workshop on ""Towards Robust, Secure and
  Efficient Machine Learning""",,,,"cs.LG cs.AI cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The vulnerability of models to data aberrations and adversarial attacks
influences their ability to demarcate distinct class boundaries efficiently.
The network's confidence and uncertainty play a pivotal role in weight
adjustments and the extent of acknowledging such attacks. In this paper, we
address the trade-off between the accuracy and calibration potential of a
classification network. We study the significance of ground-truth distribution
changes on the performance and generalizability of various state-of-the-art
networks and compare the proposed method's response to unanticipated attacks.
Furthermore, we demonstrate the role of label-smoothing regularization and
normalization in yielding better generalizability and calibrated probability
distribution by proposing normalized soft labels to enhance the calibration of
feature maps. Subsequently, we substantiate our inference by translating
conventional convolutions to padding based partial convolution to establish the
tangible impact of corrections in reinforcing the performance and convergence
rate. We graphically elucidate the implication of such variations with the
critical purpose of corroborating the reliability and reproducibility for
multiple datasets.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:54:01 GMT""}]","2020-12-15"
"2012.06877","Tom McClain Ph.D.","Tom McClain","Obstacles to the quantization of general relativity using symplectic
  structures","10 pages. Based on a presentation at the Second Hermann Minkowski
  Meeting on the Foundations of Spacetime Physics. Appears in ""Spacetime: 1909
  - 2019."" Reinoud Jan Slagter and Zoltan Keresztes (Editors). Minkowski
  Institute Press, 2020",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper I give overviews of the polysymplectic approach to covariant
Hamiltonian field theory and the simplest geometric quantization of classical
particle theories. I then give a synopsis of a recently proposed toy model for
applying this geometric quantization map to polysymplectic field theory. I show
that no special difficulties arise when this toy model is applied to general
relativity. I then sketch the reasons why the standard tools of covariant
Hamiltonian field theory are not up to the challenge of GR, so that the
resulting quantum theory cannot be taken seriously. A few remarks are given
about prospects for future work.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:58:06 GMT""}]","2020-12-15"
"2012.06878","Fernando Almeida","Fernando Dar\'io Almeida Garc\'ia, Andrea Carolina Flores Rodriguez,
  Gustavo Fraidenraich","Highly accurate closed-form approximation for the probability of
  detection of Weibull fluctuating targets in non-coherent detectors","10 pages, 12 figures. To appear in IEEE TRANSACTIONS ON AEROSPACE AND
  ELECTRONIC SYSTEMS",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we derive a highly accurate approximation for the probability
of detection (PD) of a non-coherent detector operating with Weibull fluctuation
targets. To do so, we assume a pulse-to-pulse decorrelation during the coherent
processing interval (CPI). Specifically, the proposed approximation is given in
terms of: i) a closed-form expression derived in terms of the Fox's H-function,
for which we also provide a portable and efficient MATHEMATICA routine; and ii)
a fast converging series obtained through a comprehensive calculus of residues.
Both solutions are fast and provide very accurate results. In particular, our
series representation, besides being a more tractable solution, also exhibits
impressive savings in computational load and computation time compared to
previous studies. Numerical results and Monte-Carlo simulations corroborated
the validity of our expressions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 18:02:55 GMT""}]","2020-12-15"
"2012.06879","Cihan Unal","Ismail Aydin, Cihan Unal","On some general multiplying solutions results of a Robin problem","10 pages",,,,"math.AP math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By applying Ricceri's variational principle, we demonstrate the existence of
solutions for the following Robin problem
  \begin{equation*}\left\{ \begin{array}{cc}-\func{div}\left( \omega
_{1}(x)\left\vert \nabla u\right\vert^{p(x)-2}\nabla u\right) =\lambda \omega
_{2}(x)f(x,u), & x\in \Omega \\ \omega _{1}(x)\left\vert \nabla u\right\vert
^{p(x)-2}\frac{\partial u}{ \partial \upsilon }+\beta (x)\left\vert
u\right\vert ^{p(x)-2}u=0, & x\in \partial \Omega , \end{array} \right.
\end{equation*}
  in $W_{\omega _{1},\omega _{2}}^{1,p(.)}\left( \Omega \right) $ under some
appropriate conditions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 18:06:08 GMT""}]","2020-12-15"
"2012.06880","Alexander Studenikin","Alexey Lichkunov, Artem Popov, Alexander Studenikin","Neutrino eigenstates and flavour, spin and spin-flavour oscillations in
  a constant magnetic field","4 pages and 2 figures in Latex, presented at the the European
  Physical Society Conference on High Energy Physics, Ghent, Belgium, 10-17
  July, 2019","PoS(EPS-HEP2019)429",,,"hep-ph astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We develop the approach to the problem of neutrino oscillations in a magnetic
field introduced in \cite{Popov:2019nkr} and extend it to the case of three
neutrino generations. The theoretical framework suitable for computation of the
Dirac neutrino spin, flavour and spin-flavour oscillations probabilities in a
magnetic field is given. It is shown that there is an entanglement between
neutrino flavour and spin oscillations and in the general case it is not
possible to consider these two types of neutrino oscillations separately. The
closed analytic expressions for the probabilities of oscillations are obtained
accounting for the normal and inverted hierarchies and the possible effect of
CP violation. In particular, it is shown that the probabilities of the
conversions without neutrino flavor change, i.e. $\nu_e^L \rightarrow \nu_e^L$
and $\nu_e^L \rightarrow \nu_e^R$, do not exhibit the dependence on the CP
phase, while the other neutrino conversions are affected by the CP phase. In
general, the neutrino oscillation probabilities exhibit quite a complicated
interplay of oscillations on the magnetic $\mu_{\nu} B$ and vacuum frequencies.
The obtained results are of interest in applications to neutrino oscillations
under the influence of extreme astrophysical environments, for example peculiar
to magnetars and supernovas, as well as in studying neutrino propagation in
interstellar magnetic fields.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 18:21:56 GMT""}]","2020-12-15"
"2012.06881","Muhammad Fayaz","Muhammad Fayaz, Wenqiang Yi, Yuanwei Liu, and Arumugam Nallanathan","Transmit Power Pool Design for Grant-Free NOMA-IoT Networks via Deep
  Reinforcement Learning",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Grant-free non-orthogonal multiple access (GF-NOMA) is a potential multiple
access framework for short-packet internet-of-things (IoT) networks to enhance
connectivity. However, the resource allocation problem in GF-NOMA is
challenging due to the absence of closed-loop power control. We design a
prototype of transmit power pool (PP) to provide open-loop power control. IoT
users acquire their transmit power in advance from this prototype PP solely
according to their communication distances. Firstly, a multi-agent deep
Q-network (DQN) aided GF-NOMA algorithm is proposed to determine the optimal
transmit power levels for the prototype PP. More specifically, each IoT user
acts as an agent and learns a policy by interacting with the wireless
environment that guides them to select optimal actions. Secondly, to prevent
the Q-learning model overestimation problem, double DQN based GF-NOMA algorithm
is proposed. Numerical results confirm that the double DQN based algorithm
finds out the optimal transmit power levels that form the PP. Comparing with
the conventional online learning approach, the proposed algorithm with the
prototype PP converges faster under changing environments due to limiting the
action space based on previous learning. The considered GF-NOMA system
outperforms the networks with fixed transmission power, namely all the users
have the same transmit power and the traditional GF with orthogonal multiple
access techniques, in terms of throughput.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 18:26:55 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 10:05:13 GMT""}]","2021-06-04"
"2012.06882","Luca Visinelli","Nicklas Ramberg, Luca Visinelli","The QCD Axion and Gravitational Waves in light of NANOGrav results","8 pages, 1 figure. Based on work presented in 1904.05707. Matches
  published version","Phys. Rev. D 103, 063031 (2021)","10.1103/PhysRevD.103.063031","MITP-20-077","astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The North American Nanohertz Observatory for Gravitational Waves (NANOGrav)
collaboration has recently reported strong evidence for a stochastic process
affecting the 12.5 yr dataset of pulsar timing residuals. We show that the
signal can be interpreted in terms of a stochastic gravitational wave
background emitted from a network of axionic strings in the early Universe. The
spontaneous breaking of the Peccei-Quinn symmetry originate the axionic string
network and the QCD axion, the dark matter particle in the model. We explore a
non-standard cosmological model driven by an exotic scalar field $\phi$ which
evolves under the influence of a self-interacting potential; the axion field
starts to oscillate during the modified cosmology, and provides the dark matter
observed. For an equation of state $w_\phi < 1/3$, the QCD axion mass is
smaller than expected in the standard cosmology and the GW spectrum from
axionic strings is larger. We assess the parameter space of the model which is
consistent with the NANOGrav-$12.5\,$yr detection, which can be explained
within 95\% limit by a QCD axion field evolving in a dust-like scenario, as
well as within 68\% limit in a cosmology with $w_\phi < 0$.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 18:29:44 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 16:22:47 GMT""}]","2021-03-25"
"2012.06883","Mohammad Murshed","Mohammad N. Murshed, Zarin Subah, M. Monir Uddin","Data Assimilation: Two Different Perspectives Based on the
  Initial-Condition Dependence","5 pages",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data Assimilation (DA) is a computational tool that uses value from the model
and the real measurement to arrive to an optimally acceptable value. Rather,
this technique relies on the idea of Kalman gain. We point out that DA has two
different perspectives based on the type of problem. In this paper, we look
into two problem types: one that does not rely on the initial condition, and
the other that is initial condition dependent. Data Assimilation is
demonstrated on two examples: runoff monitoring and forecasting in the city of
Dhaka (initial condition independent) and convection in the atmosphere (initial
condition dependent). We show that standard DA works well for problems with no
initial condition dependence and piecewise DA is to be utilized when the
problem has initial condition dependence. In the first example, we exploited
standard Data Assimilation to arrive at values that are more realistic than the
ones from the model and the observations. The second example is where we
devised a method to find the dynamics of the system in a piecewise manner in
Data Assimilation framework and noticed that the data assimilated dynamics
(even due to noisy initial condition) is in good agreement with the true
dynamics for a reasonable extent of time in future.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 18:35:09 GMT""}]","2020-12-15"
"2012.06884","Mordechai Guri","Mordechai Guri","AIR-FI: Generating Covert Wi-Fi Signals from Air-Gapped Computers",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we show that attackers can exfiltrate data from air-gapped
computers via Wi-Fi signals. Malware in a compromised air-gapped computer can
generate signals in the Wi-Fi frequency bands. The signals are generated
through the memory buses - no special hardware is required. Sensitive data can
be modulated and secretly exfiltrated on top of the signals. We show that
nearby Wi-Fi capable devices (e.g., smartphones, laptops, IoT devices) can
intercept these signals, decode them, and send them to the attacker over the
Internet. To extract the signals, we utilize the physical layer information
exposed by the Wi-Fi chips. We implement the transmitter and receiver and
discuss design considerations and implementation details. We evaluate this
covert channel in terms of bandwidth and distance and present a set of
countermeasures. Our evaluation shows that data can be exfiltrated from
air-gapped computers to nearby Wi-Fi receivers located a distance of several
meters away.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 18:36:21 GMT""}]","2020-12-15"
"2012.06885","Angela Bonaccorso Dr.","Jin Lei, Angela Bonaccorso","Comparison of semiclassical transfer to continuum model with
  Ichimura-Austern-Vincent model in medium energy knockout reactions","8 pages, 3 figures, supplementary material. Accepted for publication
  on Phys. Lett. B",,"10.1016/j.physletb.2020.136032",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The full quantum mechanical (QM) model of inclusive breakup of
Ichimura-Austern-Vincent (IAV) is implemented in this paper to calculate
breakup from heavy radioactive nuclei on a $^9$Be target at intermediate
energies. So far it had been implemented and applied only to low energy
reactions with light projectiles. The IAV model is successful in predicting
absolute cross sections among other observables. In order to get insight on the
content of the model in the case of the complicated heavy-ion reactions,
results are compared with those of the semiclassical transfer to the continuum
(TC) model. Because the TC is based on analytical formulae the dynamics of the
breakup as it is contained in the rather involved IAV formalism will become
more transparent. Heavy-ion reactions at high energies ($>$50A.MeV) are
demanding from the computational point of view because of the high number of
partial waves involved, typically around 100. The TC constitutes a useful
alternative to the full QM calculations whenever predictions and/or estimates
are necessary. It allows also for a systematic, fast evaluation of breakup
observables. In the applications of both methods we use state-of-the art
optical potentials and structure information. Excellent agreement is found
between the calculated results of both methods and with available experimental
data which shows that the qualitative and quantitative understanding of most
aspects of one nucleon breakup is well under control.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 18:36:33 GMT""}]","2021-02-03"
"2012.06886","Gleb Fedorovich","G. Fedorovich, D. Kornovan, A. Poddubny, M. Petrov","Chirality-driven delocalization in disordered waveguide-coupled quantum
  arrays",,,,,"cond-mat.dis-nn quant-ph","http://creativecommons.org/licenses/by/4.0/","  We study theoretically the competition between directional asymmetric
coupling and disorder in a one-dimensional array of quantum emitters chirally
coupled through a waveguide mode. Our calculation reveals highly nontrivial
phase diagram for the eigenstates spatial profile, nonmonotonously depending on
the disorder and directionality strength. The increase of the coupling
asymmetry drives the transition from Anderson localization in the bulk through
delocalized states to chirality-induced localization at the array edge.
Counterintuitively, this transition is not smeared by strong disorder but
becomes sharper instead. Our findings could be important for the rapidly
developing field of the waveguide quantum electrodynamics, where the chiral
interactions and disorder play crucial roles.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 18:40:44 GMT""},{""version"":""v2"",""created"":""Sat, 8 Oct 2022 21:07:22 GMT""}]","2022-10-11"
"2012.06887","Ali Rejali","Mitra Amiri, Ali Rejali","The Bochner-Schoenberg-Eberlein Property for Fr\'echet C*-algebras and
  uniform Fr\'echet Algebras","8 pages",,,,"math.FA math.AC math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Takahasi and Hatori introduced a class of commutative Banach algebras which
satisfy a Bochner-Schoenberg-Eberlein-type inequality. Baised on their results
we introduced a class of commutative Fr\'echet algebras which satisfy this
property. We show that Fr\'echet C*-algebras and uniform Fr\'echet algebras are
BSE-algebras.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 18:42:21 GMT""}]","2020-12-29"
"2012.06888","The CMS Collaboration","CMS Collaboration","Electron and photon reconstruction and identification with the CMS
  experiment at the CERN LHC","Replaced with the published version. Added the journal reference and
  the DOI. All the figures and tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/EGM-17-001
  (CMS Public Pages)","JINST 16 (2021) P05014","10.1088/1748-0221/16/05/P05014","CMS-EGM-17-001, CERN-EP-2020-219","hep-ex physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  The performance is presented of the reconstruction and identification
algorithms for electrons and photons with the CMS experiment at the LHC. The
reported results are based on proton-proton collision data collected at a
center-of-mass energy of 13 TeV and recorded in 2016-2018, corresponding to an
integrated luminosity of 136 fb$^{-1}$. Results obtained from lead-lead
collision data collected at $\sqrt{s_\mathrm{NN}} =$ 5.02 TeV are also
presented. Innovative techniques are used to reconstruct the electron and
photon signals in the detector and to optimize the energy resolution. Events
with electrons and photons in the final state are used to measure the energy
resolution and energy scale uncertainty in the recorded events. The measured
energy resolution for electrons produced in Z boson decays in proton-proton
collision data ranges from 2 to 5%, depending on electron pseudorapidity and
energy loss through bremsstrahlung in the detector material. The energy scale
in the same range of energies is measured with an uncertainty smaller than 0.1
(0.3)% in the barrel (endcap) region in proton-proton collisions and better
than 1 (3)% in the barrel (endcap) region in heavy ion collisions. The timing
resolution for electrons from Z boson decays with the full 2016-2018
proton-proton collision data set is measured to be 200 ps.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:08:13 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 23:09:51 GMT""}]","2021-05-19"
"2012.06889","Miguel A. Barja","Miguel A. Barja","Higher Dimensional Slope Inequalities for Irregular fibrations","19 pages Minor revisions and corrections. References added",,,,"math.AG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We prove the equivalence between Clifford-Severi inequalities for good
classes of varieties of maximal Albanese dimension and Slope Inequalities for
fibrations of such varieties over curves. This provides a big set of new Slope
Inequalities and characterizes the limit cases. It also gives a machinery to
automatically obtain other higher dimensional Slope and Clifford-Severi
inequalities from inequalities in low dimension. For this, we construct a
continuous version of Xiao's method for irregular fibrations.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:08:39 GMT""},{""version"":""v2"",""created"":""Mon, 28 Dec 2020 10:30:25 GMT""}]","2020-12-29"
"2012.06890","Jaroslav Ilnytskyi Dr.","J.M.Ilnytskyi","SEIRS epidemiology model for the COVID-19 pandemy in the extreme case of
  no acquired immunity","32 pages, 14 figures",,,,"q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  We consider the SEIRS compartment epidemiology model suitable for predicting
the evolution of the COVID-19 pandemy in the extreme limiting case of no
acquired immunity. The disease-free and endemic fixed points are found and
their stability is analysed. The expression for the basic reproduction ratio is
obtained and discussed, emphasizing on its dependence on the model parameters.
The threshold contact ratio is found which determines the possibility for a
stable disease-free fixed point existence. Numeric solution for the pandemy
evolution is also undertaken together with the approximate analytic solutions
for the early stage of the disease spread as well as as for its decay after the
rapid measures are undertaken. We analysed several possible scenarios for
introducing and relaxing the quarantine measures. The cyclic ""quarantine on""
and ""quarantine off"" strategy at fixed identification and isolation ratios fail
to reduce the lowering of the second and the consecutive waves, whereas this
goal is possible to achieve if the flexible increase of the identification and
isolation ratios is also involved.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:12:34 GMT""}]","2020-12-15"
"2012.06891","Reza Rastegar","Toufik Mansour and Reza Rastegar","Fixed points of a random restricted growth sequence","Final version. A few typos are fixed and the presentation is
  improved. arXiv admin note: text overlap with arXiv:1912.05060",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We call $i$ a fixed point of a given sequence if the value of that sequence
at the $i$-th position coincides with $i$. Here, we enumerate fixed points in
the class of restricted growth sequences. The counting process is conducted by
calculation of generating functions and leveraging a probabilistic sampling
method.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:14:36 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 17:53:51 GMT""}]","2021-06-25"
"2012.06892","Jozsef Cserti","R\'obert N\'emeth, Zolt\'an Kaufmann, J\'ozsef Cserti","Current distribution in magnetically confined 2DEG: semiclassical and
  quantum mechanical treatment","21 pages, 18 figures",,"10.1088/1751-8121/abfffd",,"cond-mat.mes-hall quant-ph","http://creativecommons.org/licenses/by/4.0/","  In the ballistic regime we study both semiclassically and quantum
mechanically the electron's dynamics in two-dimensional electron gas (2DEG) in
the presence of an inhomogeneous magnetic field applied perpendicular to the
plane. The magnetic field is constant inside four separate circular regions
which are located at the four corners of a square of side length larger than
the diameter of the circles, while outside the circles the magnetic field is
zero. We carry out the stability analysis of the periodic orbits and for given
initial conditions numerically calculate the two-dimensional invariant torus
embedded in the four-dimensional phase space. Applying the Bohr--Sommerfeld and
the Einstein--Brillouin--Keller semiclassical quantization methods we obtain
the energy levels for different magnetic field strengths. We also perform exact
quantum calculations solving numerically the discretized version of the
Schr\""odinger equation. In our calculations, we consider only those bound
states that are localized to the neighborhood of the four magnetic disks. We
show that the semiclassical results are in good agreement with those found from
our quantum calculations. Moreover, the current distribution and the phase of
the different wave functions enable us to deduce the two quantum numbers $n_1$
and $n_2$ characterizing the energy levels in the semiclassical methods.
Finally, we present two examples in which the quantum state shows a similar
structure to the previous states, but these are special in the following sense.
One of them is a scar state localized to the neighborhood of the periodic orbit
while this orbit is already unstable. In the case of the other state, the
current density is circulating in two rings in opposite direction. Thus, it is
not consistent with the classical motion in the neighborhood of the periodic
orbit.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:18:55 GMT""}]","2021-07-07"
"2012.06893","Sven Serneels","Emmanuel Jordy Menvouta and Sven Serneels and Tim Verdonck","Sparse dimension reduction based on energy and ball statistics",,,,,"stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  As its name suggests, sufficient dimension reduction (SDR) targets to
estimate a subspace from data that contains all information sufficient to
explain a dependent variable. Ample approaches exist to SDR, some of the most
recent of which rely on minimal to no model assumptions. These are defined
according to an optimization criterion that maximizes a nonparametric measure
of association. The original estimators are nonsparse, which means that all
variables contribute to the model. However, in many practical applications, an
SDR technique may be called for that is sparse and as such, intrinsically
performs sufficient variable selection (SVS). This paper examines how such a
sparse SDR estimator can be constructed. Three variants are investigated,
depending on different measures of association: distance covariance, martingale
difference divergence and ball covariance. A simulation study shows that each
of these estimators can achieve correct variable selection in highly nonlinear
contexts, yet are sensitive to outliers and computationally intensive. The
study sheds light on the subtle differences between the methods. Two examples
illustrate how these new estimators can be applied in practice, with a slight
preference for the option based on martingale difference divergence in the
bioinformatics example.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:23:36 GMT""}]","2020-12-15"
"2012.06894","Vincent Corlay","Vincent Corlay, Joseph J. Boutros, Philippe Ciblat, and Lo\""ic Brunel","On the decoding of lattices constructed via a single parity check","Submitted to IEEE Transactions on Information Theory",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the decoding of a remarkable set of lattices: We
treat in a unified framework the Leech lattice in dimension 24, the Nebe
lattice in dimension 72, and the Barnes-Wall lattices. A new interesting
lattice is constructed as a simple application of single parity-check principle
on the Leech lattice. The common aspect of these lattices is that they can be
obtained via a single parity check or via the k-ing construction. We exploit
these constructions to introduce a new efficient paradigm for decoding. This
leads to efficient list decoders and quasi-optimal decoders on the Gaussian
channel. Both theoretical and practical performance (point error probability
and complexity) of the new decoders are provided.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:24:13 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 14:34:22 GMT""}]","2021-10-11"
"2012.06895","Kazem Azizi","K. Azizi, U. \""Ozdem","Gravitational form factors of $N(1535)$ in QCD","12 Pages, 2 Figures and 3 Tables",,"10.1016/j.nuclphysa.2021.122296",,"hep-ph hep-ex hep-lat","http://creativecommons.org/licenses/by/4.0/","  We calculate the gravitational form factors of the excited $N(1535)$ state
with the quantum numbers $I(J^P)=\frac{1}{2}(\frac{1}{2}^-)$ via light cone QCD
sum rules (LCSR). To this end, we consider the quark part of the
energy-momentum tensor (EMT) current and use the general form of the nucleon's
interpolating field as well as the distribution amplitudes (DAs) of $N(1535)$.
As both the nucleon and $N(1535)$ couple to the same current, the $N(1535)
\rightarrow N$ gravitational transition form factors are entered to the
calculations as the main input parameters. First we revisit the transitional
gravitational form factors of $N(1535) \rightarrow N$, then extract the values
of the form factors of the $N(1535)$ excited state. We observe that the
gravitational form factors of $N(1535)$ in terms of $Q^2$ are well described by
the multipole fit function. As a byproduct, we also calculate the pressure and
energy density at the center of $N(1535)$ and estimate its mechanical radius.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:38:16 GMT""},{""version"":""v2"",""created"":""Wed, 28 Jul 2021 18:55:35 GMT""}]","2021-09-15"
"2012.06896","Mufan Sang","Mufan Sang, Wei Xia, John H.L. Hansen","DEAAN: Disentangled Embedding and Adversarial Adaptation Network for
  Robust Speaker Representation Learning","Accepted to ICASSP 2021",,,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite speaker verification has achieved significant performance improvement
with the development of deep neural networks, domain mismatch is still a
challenging problem in this field. In this study, we propose a novel framework
to disentangle speaker-related and domain-specific features and apply domain
adaptation on the speaker-related feature space solely. Instead of performing
domain adaptation directly on the feature space where domain information is not
removed, using disentanglement can efficiently boost adaptation performance. To
be specific, our model's input speech from the source and target domains is
first encoded into different latent feature spaces. The adversarial domain
adaptation is conducted on the shared speaker-related feature space to
encourage the property of domain-invariance. Further, we minimize the mutual
information between speaker-related and domain-specific features for both
domains to enforce the disentanglement. Experimental results on the VOiCES
dataset demonstrate that our proposed framework can effectively generate more
speaker-discriminative and domain-invariant speaker representations with a
relative 20.3% reduction of EER compared to the original ResNet-based system.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:46:56 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 22:25:01 GMT""}]","2021-02-24"
"2012.06897","Mikhail Ignatyev","Mikhail Ignatyev","Reconstruction formula for differential systems with a singularity",,,,,"math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our studies concern some aspects of scattering theory of the singular
differential systems $ y'-x^{-1}Ay-q(x)y=\rho By, \ x>0 $ with $n\times n$
matrices $A,B, q(x), x\in(0,\infty)$, where $A,B$ are constant and $\rho$ is a
spectral parameter. We concentrate on the important special case when
$q(\cdot)$ is smooth and $q(0)=0$ and derive a formula that express such
$q(\cdot)$ in the form of some special contour integral, where the kernel can
be written in terms of the Weyl - type solutions of the considered differential
system. Formulas of such a type play an important role in constructive solution
of inverse scattering problems: use of such formulas, where the terms in their
right-hand sides are previously found from the so-called main equation,
provides a final step of the solution procedure. In order to obtain the
above-mentioned reconstruction formula we establish first the asymptotical
expansions for the Weyl - type solutions as $\rho\to\infty$ with
$o\left(\rho^{-1}\right)$ rate remainder estimate.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:56:51 GMT""}]","2020-12-15"
"2012.06898","Jonathan Frankle","Jonathan Frankle","Revisiting ""Qualitatively Characterizing Neural Network Optimization
  Problems""","Workshop on Deep Learning and Information Geometry (NeurIPS 2020)",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit and extend the experiments of Goodfellow et al. (2014), who showed
that - for then state-of-the-art networks - ""the objective function has a
simple, approximately convex shape"" along the linear path between
initialization and the trained weights. We do not find this to be the case for
modern networks on CIFAR-10 and ImageNet. Instead, although loss is roughly
monotonically non-increasing along this path, it remains high until close to
the optimum. In addition, training quickly becomes linearly separated from the
optimum by loss barriers. We conclude that, although Goodfellow et al.'s
findings describe the ""relatively easy to optimize"" MNIST setting, behavior is
qualitatively different in modern settings.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 20:01:33 GMT""}]","2020-12-15"
"2012.06899","Ksenia Konyushkova","Ksenia Konyushkova, Konrad Zolna, Yusuf Aytar, Alexander Novikov,
  Scott Reed, Serkan Cabi, Nando de Freitas","Semi-supervised reward learning for offline reinforcement learning","Accepted to Offline Reinforcement Learning Workshop at Neural
  Information Processing Systems (2020)",,,,"cs.LG cs.AI cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In offline reinforcement learning (RL) agents are trained using a logged
dataset. It appears to be the most natural route to attack real-life
applications because in domains such as healthcare and robotics interactions
with the environment are either expensive or unethical. Training agents usually
requires reward functions, but unfortunately, rewards are seldom available in
practice and their engineering is challenging and laborious. To overcome this,
we investigate reward learning under the constraint of minimizing human reward
annotations. We consider two types of supervision: timestep annotations and
demonstrations. We propose semi-supervised learning algorithms that learn from
limited annotations and incorporate unlabelled data. In our experiments with a
simulated robotic arm, we greatly improve upon behavioural cloning and closely
approach the performance achieved with ground truth rewards. We further
investigate the relationship between the quality of the reward model and the
final policies. We notice, for example, that the reward models do not need to
be perfect to result in useful policies.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 20:06:15 GMT""}]","2020-12-15"
"2012.06900","Henri Jaffres Pr.","T. H. Dang, J. Hawecker, E. Rongione, G. Baez Flores, D. Q. To, J. C.
  Rojas-Sanchez, H. Nong, J. Mangeney, J. Tignon, F. Godel, S. Collin, P.
  Seneor, M. Bibes, A. Fert, M. Anane, J.-M. George, L. Vila, M.
  Cosset-Cheneau, D.Dolfi, R. Lebrun, P. Bortolotti, K. Belashchenko, S.
  Dhillon, and H. Jaffr\`es","Ultrafast spin-currents and charge conversion at 3d-5d interfaces probed
  by time-domain terahertz spectroscopy","20 pages","Applied Physics Reviews 7, 041409 (2020)","10.1063/5.0022369",,"physics.app-ph cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spintronic structures are extensively investigated for their spin orbit
torque properties, required for magnetic commutation functionalities. Current
progress in these materials is dependent on the interface engineering for the
optimization of spin transmission. Here, we advance the analysis of ultrafast
spin-charge conversion phenomena at ferromagnetic-transition metal interfaces
due to their inverse spin-Hall effect properties. In particular the intrinsic
inverse spin Hall effect of Pt-based systems and extrinsic inverse spin-Hall
effect of Au:W and Au:Ta in NiFe/Au:(W,Ta) bilayers are investigated. The
spin-charge conversion is probed by complementary techniques -- ultrafast THz
time domain spectroscopy in the dynamic regime for THz pulse emission and
ferromagnetic resonance spin-pumping measurements in the GHz regime in the
steady state -- to determine the role played by the material properties,
resistivities, spin transmission at metallic interfaces and spin-flip rates.
These measurements show the correspondence between the THz time domain
spectroscopy and ferromagnetic spin-pumping for the different set of samples in
term of the spin mixing conductance. The latter quantity is a critical
parameter, determining the strength of the THz emission from spintronic
interfaces. This is further supported by ab-initio calculations, simulations
and analysis of the spin-diffusion and spin relaxation of carriers within the
multilayers in the time domain, permitting to determine the main trends and the
role of spin transmission at interfaces. This work illustrates that time domain
spectroscopy for spin-based THz emission is a powerful technique to probe
spin-dynamics at active spintronic interfaces and to extract key material
properties for spin-charge conversion.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 20:07:24 GMT""}]","2020-12-15"
"2012.06901","Yao Zhou","Yao Zhou, Jianpeng Xu, Jun Wu, Zeinab Taghavi Nasrabadi, Evren
  Korpeoglu, Kannan Achan, Jingrui He","GAN-based Recommendation with Positive-Unlabeled Sampling","12 pages",,,,"cs.IR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender systems are popular tools for information retrieval tasks on a
large variety of web applications and personalized products. In this work, we
propose a Generative Adversarial Network based recommendation framework using a
positive-unlabeled sampling strategy. Specifically, we utilize the generator to
learn the continuous distribution of user-item tuples and design the
discriminator to be a binary classifier that outputs the relevance score
between each user and each item. Meanwhile, positive-unlabeled sampling is
applied in the learning procedure of the discriminator. Theoretical bounds
regarding positive-unlabeled sampling and optimalities of convergence for the
discriminators and the generators are provided. We show the effectiveness and
efficiency of our framework on three publicly accessible data sets with eight
ranking-based evaluation metrics in comparison with thirteen popular baselines.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 20:08:51 GMT""}]","2020-12-15"
"2012.06902","Riccardo Falcone","Riccardo Falcone, Daniela D. Doneva, Kostas D. Kokkotas, Stoytcho S.
  Yazadjiev","Non-linear stability of soliton solutions for massive
  tensor-multi-scalar-theories",,"Phys. Rev. D 104, 064045 (2021)","10.1103/PhysRevD.104.064045",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to study the stability of soliton-like static
solutions via non-linear simulations in the context of a special class of
massive tensor-multi-scalar-theories of gravity whose target space metric
admits Killing field(s) with a periodic flow. We focused on the case with two
scalar fields and maximally symmetric target space metric, as the simplest
configuration where solitonic solutions can exist. In the limit of zero
curvature of the target space $\kappa = 0$ these solutions reduce to the
standard boson stars, while for $\kappa \ne 0$ significant deviations can be
observed, both qualitative and quantitative. By evolving these solitonic
solutions in time, we show that they are stable for low values of the central
scalar field $\psi_c$ while instability kicks in with the increase of $\psi_c$.
Specifically, in the stable region, the models oscillate with a characteristic
frequency related to the fundamental mode. Such frequency tends to zero with
the approach of the unstable models and eventually becomes imaginary when the
solitonic solutions lose stability. As expected from the study of the
equilibrium models, the change of stability occurs exactly at the maximum mass
point, which was checked numerically with a very good accuracy.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 20:12:26 GMT""}]","2021-09-22"
"2012.06903","Jason Garver","Jason Garver","History Of Rigor: A Review Of 20th Century Science Education","5 pages, 3 figures",,,,"physics.ed-ph physics.hist-ph","http://creativecommons.org/licenses/by-sa/4.0/","  ""Rigor"" is an often sought after but ill-defined concept in education. This
work reviews several models of rigor from current literature before proposing a
tool which is used to analyze science education throughout history. The
20\textsuperscript{th} century science education in the United States was
subject to changing sociopolitical motivations about the use of science both in
general and for students. These factors as well as developments in theory of
learning and broad education reforms had changing affects on the level of rigor
in science education. This work analyzes the theoretical level of rigor of
science education in the US based on two main motivating factors for science
education; science as a social endeavor and science as a discipline, throughout
the 20\textsuperscript{th} century.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 20:16:27 GMT""}]","2020-12-15"
"2012.06904","O. I. Morozov","Oleg I. Morozov","Isospectral deformation of the reduced quasi-classical self-dual
  Yang--Mills equation","arXiv admin note: text overlap with arXiv:1904.00259,
  arXiv:1812.03338",,,,"nlin.SI","http://creativecommons.org/licenses/by/4.0/","  We derive new four-dimensional partial differential equation with the
isospectral Lax representation by shrinking the symmetry algebra of the reduced
quasi-classical self-dual Yang--Mills equation. Then we find a recursion
operator for the obtained equation and construct B{\""a}cklund transformations
between this equation and the reduced quasi-classical self-dual Yang--Mills
equation as well as the four-dimensional Mart{\'{\i}}nez Alonso--Shabat
equation
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 20:23:09 GMT""}]","2020-12-15"
"2012.06905","O. I. Morozov","Oleg I. Morozov","Integrability structures of the generalized Hunter--Saxton equation",,,,,"nlin.SI","http://creativecommons.org/licenses/by/4.0/","  We consider integrability structures of the generalized Hunter--Saxton
equation. In particular, we obtain the Lax representation with nonremovable
spectral parameter, find local recursion operators for symmetries and
cosymmetries, generate an infinite-dimensional Lie algebra of higher
symmetries, and prove existence of infinite number of cosymmetries of higher
order. Further, we give an example of employing the higher order symmetry to
constructing exact globally defined solutions for the generalized
Hunter--Saxton equation.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 20:30:32 GMT""}]","2020-12-15"
"2012.06906","Lat\'evi Mohamed Lawson","Lat\'evi M. Lawson","Minimal and maximal lengths from position-dependent noncommutativity","25 pages","J. Phys. A: Math. Theor. 53 (2020) 115303","10.1088/1751-8121/ab7497",,"hep-th math-ph math.MP quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Fring and al in their paper entitled ""Strings from position-dependent
noncommutativity"" have introduced a new set of noncommutative space commutation
relations in two space dimensions. It had been shown that any fundamental
objects introduced in this space-space non-commutativity are string-like.
Taking this result into account, we generalize the seminal work of Fring and al
to the case that there is also a maximal length from position-dependent
noncommutativity and minimal momentum arising from generalized versions of
Heisenberg's uncertainty relations. The existence of maximal length is related
to the presence of an extra, first order term in particle's length that
provides the basic difference of our analysis with theirs. This maximal length
breaks up the well known singularity problem of space time. We establish
different representations of this noncommutative space and finally we study
some basic and interesting quantum mechanical systems in these new variables.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 20:43:44 GMT""}]","2020-12-15"
"2012.06907","Wang Zhou","Wang Zhou, Levente J. Klein, Siyuan Lu","PAIRS AutoGeo: an Automated Machine Learning Framework for Massive
  Geospatial Data",,"IEEE International Conference on Big Data (IEEE BigData 2020)",,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An automated machine learning framework for geospatial data named PAIRS
AutoGeo is introduced on IBM PAIRS Geoscope big data and analytics platform.
The framework simplifies the development of industrial machine learning
solutions leveraging geospatial data to the extent that the user inputs are
minimized to merely a text file containing labeled GPS coordinates. PAIRS
AutoGeo automatically gathers required data at the location coordinates,
assembles the training data, performs quality check, and trains multiple
machine learning models for subsequent deployment. The framework is validated
using a realistic industrial use case of tree species classification.
Open-source tree species data are used as the input to train a random forest
classifier and a modified ResNet model for 10-way tree species classification
based on aerial imagery, which leads to an accuracy of $59.8\%$ and $81.4\%$,
respectively. This use case exemplifies how PAIRS AutoGeo enables users to
leverage machine learning without extensive geospatial expertise.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 21:12:41 GMT""}]","2020-12-15"
"2012.06908","Tianlong Chen","Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang,
  Michael Carbin, Zhangyang Wang","The Lottery Tickets Hypothesis for Supervised and Self-supervised
  Pre-training in Computer Vision Models","CVPR 2021",,,,"cs.LG cs.CV cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The computer vision world has been re-gaining enthusiasm in various
pre-trained models, including both classical ImageNet supervised pre-training
and recently emerged self-supervised pre-training such as simCLR and MoCo.
Pre-trained weights often boost a wide range of downstream tasks including
classification, detection, and segmentation. Latest studies suggest that
pre-training benefits from gigantic model capacity. We are hereby curious and
ask: after pre-training, does a pre-trained model indeed have to stay large for
its downstream transferability?
  In this paper, we examine supervised and self-supervised pre-trained models
through the lens of the lottery ticket hypothesis (LTH). LTH identifies highly
sparse matching subnetworks that can be trained in isolation from (nearly)
scratch yet still reach the full models' performance. We extend the scope of
LTH and question whether matching subnetworks still exist in pre-trained
computer vision models, that enjoy the same downstream transfer performance.
Our extensive experiments convey an overall positive message: from all
pre-trained weights obtained by ImageNet classification, simCLR, and MoCo, we
are consistently able to locate such matching subnetworks at 59.04% to 96.48%
sparsity that transfer universally to multiple downstream tasks, whose
performance see no degradation compared to using full pre-trained weights.
Further analyses reveal that subnetworks found from different pre-training tend
to yield diverse mask structures and perturbation sensitivities. We conclude
that the core LTH observations remain generally relevant in the pre-training
paradigm of computer vision, but more delicate discussions are needed in some
cases. Codes and pre-trained models will be made available at:
https://github.com/VITA-Group/CV_LTH_Pre-training.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 21:53:55 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 18:13:06 GMT""}]","2021-03-31"
"2012.06909","Ivan L. Andronov","Ivan L. Andronov, Kateryna D. Andrych, Lidia L. Chinarova, Dmytro E.
  Tvardovskyi","Astroinformatics: Statistically Optimal Approximations of Near-Extremal
  Parts with Application to Variable Stars",,"Communications of the Byurakan Astrophysical Observatory (ComBAO),
  Volume 67, Issue 2, December 2020, pp. 251-258,
  https://www.aras.am/combao/2020/251-256.pdf",,,"astro-ph.SR astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The software MAVKA is described, which was elaborated for statistically
optimal determination of the characteristics of the extrema of 1000+ variable
stars of different types, mainly eclipsing and pulsating. The approximations
are phenomenological, but not physical. As often, the discovery of a new
variable star is made on time series of a single-filter (single-channel) data,
and there is no possibility to determine parameters needed for physical
modelling (e.g. temperature, radial velocities, mass ratio of binaries).
Besides classical polynomial approximation ""AP"" (we limited the degree of the
polynomial from 2 to 9), there are realized symmetrical approximations
(symmetrical polynomials ""SP"", ""wall-supported"" horizontal line ""WSL"" and
parabola ""WSP"", restricted polynomials of non-integer order based on
approximations of the functions proposed by Andronov (2012) and Mikulasek
(2015) and generally asymmetric functions (asymptotic parabola ""AP"", parabolic
spline ""PS"", generalized hyperbolic secant function ""SECH"" and
""log-normal-like"" ""BSK""). This software is a successor of the ""Observation
Obscurer"" with some features for the variable star research, including a block
for ""running parabola"" ""RP"" scalegram and approximation. Whereas the RP is
oriented on approximation of the complete data set. MAVKA is pointed to parts
of the light curve close to extrema (including total eclipses and transits of
stars and exoplanets). The functions for wider intervals, covering the eclipse
totally, were discussed in 2017Ap.....60...57A . Global and local
approximations are reviewed in 2020kdbd.book..191A . The software is available
at http://uavso.org.ua/mavka and https://katerynaandrych.wixsite.com/mavka. We
have analyzed the data from own observations, as well as from monitoring
obtained at ground-based and space (currently, mainly, TESS) observatories. It
may be used for signals of any nature.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 22:01:20 GMT""}]","2021-01-05"
"2012.06910","Massih-Reza Amini","Aleksandra Burashnikova, Marianne Clausel, Charlotte Laclau, Frack
  Iutzeller, Yury Maximov, Massih-Reza Amini","Learning over no-Preferred and Preferred Sequence of items for Robust
  Recommendation","21 pages, 9 figures. arXiv admin note: substantial text overlap with
  arXiv:1902.08495",,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a theoretically founded sequential strategy for
training large-scale Recommender Systems (RS) over implicit feedback, mainly in
the form of clicks. The proposed approach consists in minimizing pairwise
ranking loss over blocks of consecutive items constituted by a sequence of
non-clicked items followed by a clicked one for each user. We present two
variants of this strategy where model parameters are updated using either the
momentum method or a gradient-based approach. To prevent from updating the
parameters for an abnormally high number of clicks over some targeted items
(mainly due to bots), we introduce an upper and a lower threshold on the number
of updates for each user. These thresholds are estimated over the distribution
of the number of blocks in the training set. The thresholds affect the decision
of RS and imply a shift over the distribution of items that are shown to the
users. Furthermore, we provide a convergence analysis of both algorithms and
demonstrate their practical efficiency over six large-scale collections, both
regarding different ranking measures and computational time.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 22:10:15 GMT""}]","2020-12-15"
"2012.06911","Luigi Delle Rose","Luigi Delle Rose, Shaaban Khalil, Stefano Moretti","Explaining electron and muon $g-2$ anomalies in an Aligned 2-Higgs
  Doublet Model with Right-Handed Neutrinos","9 pages, 4 figures",,"10.1016/j.physletb.2021.136216",,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explain anomalies currently present in various data samples used for the
measurement of the anomalous magnetic moment of electron ($a_e$) and muon
($a_\mu$) in terms of an Aligned 2-Higgs Doublet Model with right-handed
neutrinos. The explanation is driven by one and two-loop topologies wherein a
very light CP-odd neutral Higgs state ($A$) contributes significantly to
$a_\mu$ but negligibly to $a_e$, so as to revert the sign of the new physics
corrections in the former case with respect to the latter, wherein the dominant
contribution is due to a charged Higgs boson ($H^\pm$) and heavy neutrinos with
mass at the electroweak scale. For the region of parameter space of our new
physics model which explains the aforementioned anomalies we also predict an
almost background-free smoking-gun signature of it, consisting of $H^\pm A$
production followed by Higgs boson decays yielding multi-$\tau$ final states,
which can be pursued at the Large Hadron Collider.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 22:19:47 GMT""}]","2021-03-24"
"2012.06912","Nicolae Strungaru","Nicolae Strungaru","Model sets with precompact Borel windows","49 pages",,,,"math.DS math-ph math.CA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a cut and project scheme and a pre-compact Borel window we show that
almost surely all positions of the window give rise to point sets with
Besicovitch almost periodic Dirac combs. In particular, all those positions
lead to pure point diffractive point sets with autocorrelation given by the
covariogram of the window and diffraction given by the square of the Fourier
transform of the window. Moreover the Fourier--Bohr coefficients exist and the
intensity of the Bragg peaks is given by their absolute value square. We show
the existence of an ergodic measure with pure point dynamical spectrum such
that all those window positions give rise to point sets which are generic for
this measure. We complete the paper by reanalysing the class of weak model sets
of maximal density.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 22:21:46 GMT""}]","2020-12-15"
"2012.06913","Anne-Florence Bitbol","Lo\""ic Marrec, Irene Lamberti and Anne-Florence Bitbol","Toward a universal model for spatially structured populations","30 pages, 12 figures","Phys. Rev. Lett. 127(21): 218102 (2021)","10.1103/PhysRevLett.127.218102",,"q-bio.PE physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A key question in evolution is how likely a mutant is to take over. This
depends on natural selection and on stochastic fluctuations. Population spatial
structure can impact mutant fixation probabilities. We introduce a model for
structured populations on graphs that generalizes previous ones by making
migrations independent of birth and death. We demonstrate that by tuning
migration asymmetry, the star graph transitions from amplifying to suppressing
natural selection. The results from our model are universal in the sense that
they do not hinge on a modeling choice of microscopic dynamics or update rules.
Instead, they depend on migration asymmetry, which can be experimentally tuned
and measured.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 22:24:44 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 15:00:48 GMT""},{""version"":""v3"",""created"":""Thu, 4 Nov 2021 11:46:55 GMT""}]","2021-11-23"
"2012.06914","Yinan Wang","Yinan Wang, Kaiwen Wang, Wenjun Cai, Xiaowei Yue","NP-ODE: Neural Process Aided Ordinary Differential Equations for
  Uncertainty Quantification of Finite Element Analysis","40 pages",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finite element analysis (FEA) has been widely used to generate simulations of
complex and nonlinear systems. Despite its strength and accuracy, the
limitations of FEA can be summarized into two aspects: a) running high-fidelity
FEA often requires significant computational cost and consumes a large amount
of time; b) FEA is a deterministic method that is insufficient for uncertainty
quantification (UQ) when modeling complex systems with various types of
uncertainties. In this paper, a physics-informed data-driven surrogate model,
named Neural Process Aided Ordinary Differential Equation (NP-ODE), is proposed
to model the FEA simulations and capture both input and output uncertainties.
To validate the advantages of the proposed NP-ODE, we conduct experiments on
both the simulation data generated from a given ordinary differential equation
and the data collected from a real FEA platform for tribocorrosion. The
performances of the proposed NP-ODE and several benchmark methods are compared.
The results show that the proposed NP-ODE outperforms benchmark methods. The
NP-ODE method realizes the smallest predictive error as well as generates the
most reasonable confidence interval having the best coverage on testing data
points.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 22:38:16 GMT""}]","2020-12-15"
"2012.06915","Piotr Fr\k{a}ckiewicz","Piotr Fr\k{a}ckiewicz","Nonclassical rules in quantum games",,,"10.3390/e23050604",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the last twenty years of research on quantum game theory have given us
many ideas of how quantum games could be played. One of the most prominent
ideas in the field is a model of quantum playing a 2x2 game introduced by J.
Eisert, M. Wilkens and M. Lewenstein. The scheme assumes that players'
strategies are unitary operations the players act on the maximally entangled
two-qubit state. The quantum nature of the scheme has been under discussion
since the article by Eisert et al. came out. The aim of our paper is to
identify some of non-classical features of the quantum scheme.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 22:41:19 GMT""}]","2021-05-26"
"2012.06916","Kungang Zhang","Kungang Zhang, Anh T. Bui, Daniel W. Apley","Concept Drift Monitoring and Diagnostics of Supervised Learning Models
  via Score Vectors",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supervised learning models are one of the most fundamental classes of models.
Viewing supervised learning from a probabilistic perspective, the set of
training data to which the model is fitted is usually assumed to follow a
stationary distribution. However, this stationarity assumption is often
violated in a phenomenon called concept drift, which refers to changes over
time in the predictive relationship between covariates $\mathbf{X}$ and a
response variable $Y$ and can render trained models suboptimal or obsolete. We
develop a comprehensive and computationally efficient framework for detecting,
monitoring, and diagnosing concept drift. Specifically, we monitor the Fisher
score vector, defined as the gradient of the log-likelihood for the fitted
model, using a form of multivariate exponentially weighted moving average,
which monitors for general changes in the mean of a random vector. In spite of
the substantial performance advantages that we demonstrate over popular
error-based methods, a score-based approach has not been previously considered
for concept drift monitoring. Advantages of the proposed score-based framework
include applicability to any parametric model, more powerful detection of
changes as shown in theory and experiments, and inherent diagnostic
capabilities for helping to identify the nature of the changes.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 22:52:45 GMT""},{""version"":""v2"",""created"":""Tue, 13 Sep 2022 03:45:44 GMT""}]","2022-09-14"
"2012.06917","Aditya Singh","Aditya Singh, Alessandro Bay and Andrea Mirabile","Assessing The Importance Of Colours For CNNs In Object Recognition",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Humans rely heavily on shapes as a primary cue for object recognition. As
secondary cues, colours and textures are also beneficial in this regard.
Convolutional neural networks (CNNs), an imitation of biological neural
networks, have been shown to exhibit conflicting properties. Some studies
indicate that CNNs are biased towards textures whereas, another set of studies
suggests shape bias for a classification task. However, they do not discuss the
role of colours, implying its possible humble role in the task of object
recognition. In this paper, we empirically investigate the importance of
colours in object recognition for CNNs. We are able to demonstrate that CNNs
often rely heavily on colour information while making a prediction. Our results
show that the degree of dependency on colours tend to vary from one dataset to
another. Moreover, networks tend to rely more on colours if trained from
scratch. Pre-training can allow the model to be less colour dependent. To
facilitate these findings, we follow the framework often deployed in
understanding role of colours in object recognition for humans. We evaluate a
model trained with congruent images (images in original colours eg. red
strawberries) on congruent, greyscale, and incongruent images (images in
unnatural colours eg. blue strawberries). We measure and analyse network's
predictive performance (top-1 accuracy) under these different stylisations. We
utilise standard datasets of supervised image classification and fine-grained
image classification in our experiments.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 22:55:06 GMT""}]","2020-12-15"
"2012.06918","Gilad Gour","Kuntal Sengupta, Rana Zibakhsh, Eric Chitambar, Gilad Gour","Quantum Bell Nonlocality is Entanglement","12 pages (main text) + 3 pages (appendix), 11 Figures, comments are
  welcome!","Phys. Rev. A 104, 052208 (2021)","10.1103/PhysRevA.104.052208",,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  Bell nonlocality describes a manifestation of quantum mechanics that cannot
be explained by any local hidden variable model. Its origin lies in the nature
of quantum entanglement, although understanding the precise relationship
between nonlocality and entanglement has been a notorious open problem. In this
paper, we resolve this problem by developing a dynamical framework in which
quantum Bell nonlocality emerges as special form of entanglement, and both are
unified as resources under local operations and classical communication (LOCC).
Our framework is built on the notion of quantum processes, which are abstract
quantum channels mapping elements between fixed intervals in space and time.
Entanglement is then identified as a quantum process that cannot be generated
by LOCC while Bell nonlocality is the subset of these processes that have an
instantaneous input-output delay time. LOCC pre-processing is a natural set of
free operations in this theory, thereby enabling all entangled states to
activate some form of Bell nonlocality. In addition, we generalize the CHSH
witnesses from the state domain to the domain of entangled quantum
measurements, and provide a systematic method to quantify the Bell nonlocality
of a bipartite quantum channel.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 23:02:06 GMT""}]","2022-01-03"
"2012.06919","Mengjiao Yang","Mengjiao Yang, Bo Dai, Ofir Nachum, George Tucker, Dale Schuurmans","Offline Policy Selection under Uncertainty",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The presence of uncertainty in policy evaluation significantly complicates
the process of policy ranking and selection in real-world settings. We formally
consider offline policy selection as learning preferences over a set of policy
prospects given a fixed experience dataset. While one can select or rank
policies based on point estimates of their policy values or high-confidence
intervals, access to the full distribution over one's belief of the policy
value enables more flexible selection algorithms under a wider range of
downstream evaluation metrics. We propose BayesDICE for estimating this belief
distribution in terms of posteriors of distribution correction ratios derived
from stochastic constraints (as opposed to explicit likelihood, which is not
available). Empirically, BayesDICE is highly competitive to existing
state-of-the-art approaches in confidence interval estimation. More
importantly, we show how the belief distribution estimated by BayesDICE may be
used to rank policies with respect to any arbitrary downstream policy selection
metric, and we empirically demonstrate that this selection procedure
significantly outperforms existing approaches, such as ranking policies
according to mean or high-confidence lower bound value estimates.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 23:09:21 GMT""}]","2020-12-15"
"2012.06920","Junjun Yin","Junjun Yin and Guangqing Chi","Characterizing People's Daily Activity Patterns in the Urban
  Environment: A Mobility Network Approach with Geographic Context-Aware
  Twitter Data","39 pages, 9 figures",,,,"cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  People's daily activities in the urban environment are complex and vary by
individuals. Existing studies using mobile phone data revealed distinct and
recurrent transitional activity patterns, known as mobility motifs, in people's
daily lives. However, the limitation in using only a few inferred activity
types hinders our ability to examine general patterns in detail. We proposed a
mobility network approach with geographic context-aware Twitter data to
investigate granular daily activity patterns in the urban environment. We first
utilized publicly accessible geo-located tweets to track the movements of
individuals in two major U.S. cities: Chicago and Greater Boston, where each
recorded location is associated with its closest land use parcel to enrich its
geographic context. A direct mobility network represents the daily location
history of the selected active users, where the nodes are physical places with
semantically labeled activity types, and the edges represent the transitions.
Analyzing the isomorphic structure of the mobility networks uncovered 16 types
of location-based motifs, which describe over 83% of the networks in both
cities and are comparable to those from previous studies. With detailed and
semantically labeled transitions between every two activities, we further
dissected the general location-based motifs into activity-based motifs, where
16 common activity-based motifs describe more than 57% transitional behaviors
in the daily activities in the two cities. The integration of geographic
context from the synthesis of geo-located Twitter data with land use parcels
enables us to reveal unique activity motifs that form the fundamental elements
embedded in complex urban activities.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 23:28:10 GMT""}]","2020-12-15"
"2012.06921","Gang Chen","Gang Chen","Learning Symbolic Expressions via Gumbel-Max Equation Learner Networks",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most of the neural networks (NNs) learned via state-of-the-art machine
learning techniques are black-box models. For a widespread success of machine
learning in science and engineering, it is important to develop new NN
architectures to effectively extract high-level mathematical knowledge from
complex datasets. Motivated by this understanding, this paper develops a new NN
architecture called the Gumbel-Max Equation Learner (GMEQL) network. Different
from previously proposed Equation Learner (EQL) networks, GMEQL applies
continuous relaxation to the network structure via the Gumbel-Max trick and
introduces two types of trainable parameters: structure parameters and
regression parameters. This paper also proposes a two-stage training process
with new techniques to train structure parameters in both online and offline
settings based on an elite repository. On 8 benchmark symbolic regression
problems, GMEQL is experimentally shown to outperform several cutting-edge
machine learning approaches.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 23:36:20 GMT""},{""version"":""v2"",""created"":""Fri, 14 May 2021 03:41:28 GMT""}]","2021-05-17"
"2012.06922","Yuguang Wang","Xuebin Zheng, Bingxin Zhou, Yu Guang Wang, Xiaosheng Zhuang","Decimated Framelet System on Graphs and Fast G-Framelet Transforms","69 pages, 10 figures, Published in JMLR",,,,"cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph representation learning has many real-world applications, from
super-resolution imaging, 3D computer vision to drug repurposing, protein
classification, social networks analysis. An adequate representation of graph
data is vital to the learning performance of a statistical or machine learning
model for graph-structured data. In this paper, we propose a novel multiscale
representation system for graph data, called decimated framelets, which form a
localized tight frame on the graph. The decimated framelet system allows
storage of the graph data representation on a coarse-grained chain and
processes the graph data at multi scales where at each scale, the data is
stored at a subgraph. Based on this, we then establish decimated G-framelet
transforms for the decomposition and reconstruction of the graph data at multi
resolutions via a constructive data-driven filter bank. The graph framelets are
built on a chain-based orthonormal basis that supports fast graph Fourier
transforms. From this, we give a fast algorithm for the decimated G-framelet
transforms, or FGT, that has linear computational complexity O(N) for a graph
of size N. The theory of decimated framelets and FGT is verified with numerical
examples for random graphs. The effectiveness is demonstrated by real-world
applications, including multiresolution analysis for traffic network, and graph
neural networks for graph classification tasks.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 23:57:17 GMT""},{""version"":""v2"",""created"":""Thu, 16 Dec 2021 05:43:02 GMT""}]","2021-12-17"
"2012.06923","Marko Kabi\'c","Marko Kabi\'c, Gabriel Duque L\'opez, Daniel Keller","A Refined SVD Algorithm for Collaborative Filtering",,,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collaborative filtering tries to predict the ratings of a user over some
items based on opinions of other users with similar taste. The ratings are
usually given in the form of a sparse matrix, the goal being to find the
missing entries (i.e. ratings). Various approaches to collaborative filtering
exist, some of the most popular ones being the Singular Value Decomposition
(SVD) and K-means clustering. One of the challenges in the SVD approach is
finding a good initialization of the unknown ratings. A possible initialization
is suggested by [1]. In this paper we explain how K-means approach can be used
to achieve the further refinement of this initialization for SVD. We show that
our technique outperforms both initialization techniques used separately.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:04:11 GMT""}]","2020-12-15"
"2012.06924","Benjamin  Webb PhD","Camille Carter, Jacob Murri, David Reber, and Benjamin Webb","Stability of Stochastically Switched and Stochastically Time-Delayed
  Systems",,,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  In this paper we introduce the notion of a patient first-mean stable system.
Such systems are switched systems that are first-mean stable meaning that they
converge to a globally attracting fixed point on average. They are also patient
so that they do not lose their first-mean stability when time-delays are
introduced into the system. As time-delays are, in general, a source of
instability and poor performance patient first-mean stability is a much
stronger condition than first-mean stability. This notion of patient stability
allows one to design systems that cannot be destabilized via time-delays. It
also significantly reduces the difficulty of modeling such systems since in
patient systems time-delays can, to a large extent, be safely ignored. The
paper's main focus is on giving a sufficient criteria under which a system is
patient first-mean stable and we give a number of examples that demonstrate the
simplicity of this criteria.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:05:43 GMT""}]","2020-12-15"
"2012.06925","Leighton Wilson","Leighton Wilson, Nathan Vaughn, and Robert Krasny","A GPU-Accelerated Fast Summation Method Based on Barycentric Lagrange
  Interpolation and Dual Tree Traversal","31 pages, 36 figures",,"10.1016/j.cpc.2021.108017",,"physics.comp-ph cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present the barycentric Lagrange dual tree traversal (BLDTT) fast
summation method for particle interactions. The scheme replaces well-separated
particle-particle interactions by adaptively chosen particle-cluster,
cluster-particle, and cluster-cluster approximations given by barycentric
Lagrange interpolation at proxy particles on a Chebyshev grid in each cluster.
The BLDTT is kernel-independent and the approximations can be efficiently
mapped onto GPUs, where target particles provide an outer level of parallelism
and source particles provide an inner level of parallelism. We present an
OpenACC GPU implementation of the BLDTT with MPI remote memory access for
distributed memory parallelization. The performance of the GPU-accelerated
BLDTT is demonstrated for calculations with different problem sizes, particle
distributions, geometric domains, and interaction kernels, as well as for
unequal target and source particles. Comparison with our earlier
particle-cluster barycentric Lagrange treecode (BLTC) demonstrates the superior
performance of the BLDTT. In particular, on a single GPU for problem sizes
ranging from $N$=1E5 to 1E8, the BLTC has $O(N\log N)$ scaling, while the BLDTT
has $O(N)$ scaling. In addition, MPI strong scaling results are presented for
the BLTC and BLDTT using $N$=64E6 particles on up to 32 GPUs.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:09:10 GMT""}]","2021-06-02"
"2012.06926","Ilyas Khan","Ilyas Khan","The Structure of Translating Surfaces with Finite Total Curvature","26 Pages, significantly expanded: new results include asymptotic
  estimates and removal of conditions on area ratios. More detailed exposition,
  includes 2 new figures",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we prove that any mean curvature flow translator $\Sigma^2
\subset \mathbb{R}^3$ with finite total curvature and one end must be a plane.
We also prove that if the translator $\Sigma$ has multiple ends, they are
asymptotic to a plane $\Pi$ containing the direction of translation and can be
written as graphs over $\Pi$. Finally, we determine that the ends of $\Sigma$
are strongly asymptotic to $\Pi$ and obtain quantitative estimates for their
asymptotic behavior.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:13:22 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 17:04:33 GMT""}]","2021-06-22"
"2012.06927","Alexandra Tetarenko","Alexandra J. Tetarenko, Harriet Parsons, Sarah Graves, Jessica Dempsey","Automated Project Completion Forecasting","12 pages, 9 figures, SPIE Astronomical Telescopes + Instrumentation
  2020, Paper Number: 11449-51","SPIE Proceedings, Volume 11449, Observatory Operations:
  Strategies, Processes, and Systems VIII, 1144919 (2020)","10.1117/12.2561634",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the age of Large Programs and Big Data a key component in project planning
for ground-based astronomical observatories is understanding how to balance
users demands and telescope capabilities. In particular, future planning for
operations requires us to asses the impact of a complex set of parameters, such
as right ascension, instrument, and sky condition pressures over coming
semesters. Increased understanding of these parameters can provide: improved
scientific output, better management of user expectations, more accurate
advertised/allocated time under a Call for Proposals, and improved scheduling
for instrumental commissioning and engineering work. We present ongoing efforts
by staff at the James Clerk Maxwell Telescope (JCMT) to build a tool to provide
automated completion forecasting of Large Programs undertaken at this
telescope, which make up 50% of the observing time available at the JCMT.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:29:17 GMT""}]","2021-01-11"
"2012.06928","William Erickson","Mark Colarusso, William Q. Erickson, Jeb F. Willenbring","Contingency tables and the generalized Littlewood-Richardson
  coefficients","15 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Littlewood-Richardson coefficients $c^{\lambda}_{\mu\nu}$ give the
multiplicity of an irreducible polynomial ${\rm GL}_n$-representation
$F^{\lambda}_n$ in the tensor product of polynomial representations
$F^{\mu}_n\otimes F^{\nu}_n$. In this paper, we generalize these coefficients
to an $r$-fold tensor product of rational representations, and give a new
method for computing them using an analogue of statistical contingency tables.
We demonstrate special cases in which our method reduces to counting
statistical contingency tables with prescribed margins. Finally, we extend our
result from the general linear group to both the orthogonal and symplectic
groups.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:30:19 GMT""}]","2020-12-15"
"2012.06929","Radostin Simitev","Luis Silva, Parag Gupta, David MacTaggart and Radostin D. Simitev","Effects of shell thickness on cross-helicity generation in
  convection-driven spherical dynamos","Fluids (ISSN 2311-5521; CODEN: FLUICM); Accepted 2020-12-12","Fluids. 2020; 5(4):245","10.3390/fluids5040245",,"physics.flu-dyn astro-ph.SR physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The relative importance of the helicity and cross-helicity electromotive
dynamo effects for self-sustained magnetic field generation by chaotic thermal
convection in rotating spherical shells is investigated as a function of shell
thickness. Two distinct branches of dynamo solutions are found to coexist in
direct numerical simulations for shell aspect ratios between 0.25 and 0.6 - a
mean-field dipolar regime and a fluctuating dipolar regime. The properties
characterising the coexisting dynamo attractors are compared and contrasted,
including differences in temporal behavior and spatial structures of both the
magnetic field and rotating thermal convection. The helicity $\alpha$-effect
and the cross-helicity $\gamma$-effect are found to be comparable in intensity
within the fluctuating dipolar dynamo regime, where their ratio does not vary
significantly with the shell thickness. In contrast, within the mean-field
dipolar dynamo regime the helicity $\alpha$-effect dominates by approximately
two orders of magnitude and becomes stronger with decreasing shell thickness.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:37:12 GMT""}]","2020-12-18"
"2012.06930","Guillermo Terren-Serrano","Guillermo Terr\'en-Serrano, Manel Mart\'inez-Ram\'on","Comparative Analysis of Methods for Cloud Segmentation in Ground-Based
  Infrared Images",,,"10.1016/j.renene.2021.04.141",,"eess.IV eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increasing penetration of photovoltaic systems in the power grid makes it
vulnerable to cloud shadow projection. Real-time cloud segmentation in
ground-based infrared images is important to reduce the noise in intra-hour
global solar irradiance forecasting. We present a comparison between
discriminative and generative models for cloud segmentation. The performances
of supervised and unsupervised learning methods in cloud segmentation are
evaluated. The discriminative models are solved in the primal formulation to
make them feasible in real-time applications. The performances are compared
using the j-statistic. Infrared image preprocessing to remove stationary
artifacts increases the overall performance in the analyzed methods. The
inclusion of features from neighboring pixels in the feature vectors leads to a
performance improvement in some of the cases. Markov Random Fields achieve the
best performance in both unsupervised and supervised generative models.
Discriminative models solved in the primal yield a dramatically lower computing
time along with high performance in the segmentation. Generative and
discriminative models are comparable when preprocessing is applied to the
infrared images.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:41:47 GMT""},{""version"":""v2"",""created"":""Fri, 26 Feb 2021 16:36:56 GMT""},{""version"":""v3"",""created"":""Tue, 20 Apr 2021 04:13:46 GMT""}]","2021-05-28"
"2012.06931","Roger Casals","Roger Casals, Eugene Gorsky, Mikhail Gorsky, Jos\'e Simental","Algebraic Weaves and Braid Varieties","62 pages",,,,"math.RT math.AG math.SG","http://creativecommons.org/licenses/by/4.0/","  In this manuscript we study braid varieties, a class of affine algebraic
varieties associated to positive braids. Several geometric constructions are
presented, including certain torus actions on braid varieties and holomorphic
symplectic structures on their respective quotients. We also develop a
diagrammatic calculus for correspondences between braid varieties and use these
correspondences to obtain interesting stratifications of braid varieties and
their quotients. It is shown that the maximal charts of these stratifications
are exponential Darboux charts for the holomorphic symplectic structures, and
we relate these strata to exact Lagrangian fillings of Legendrian links.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:45:39 GMT""}]","2020-12-15"
"2012.06932","Masahiro Nomura","Masahiro Nomura, Shuhei Watanabe, Youhei Akimoto, Yoshihiko Ozaki,
  Masaki Onishi","Warm Starting CMA-ES for Hyperparameter Optimization","accepted at AAAI2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hyperparameter optimization (HPO), formulated as black-box optimization
(BBO), is recognized as essential for automation and high performance of
machine learning approaches. The CMA-ES is a promising BBO approach with a high
degree of parallelism, and has been applied to HPO tasks, often under parallel
implementation, and shown superior performance to other approaches including
Bayesian optimization (BO). However, if the budget of hyperparameter
evaluations is severely limited, which is often the case for end users who do
not deserve parallel computing, the CMA-ES exhausts the budget without
improving the performance due to its long adaptation phase, resulting in being
outperformed by BO approaches. To address this issue, we propose to transfer
prior knowledge on similar HPO tasks through the initialization of the CMA-ES,
leading to significantly shortening the adaptation time. The knowledge transfer
is designed based on the novel definition of task similarity, with which the
correlation of the performance of the proposed approach is confirmed on
synthetic problems. The proposed warm starting CMA-ES, called WS-CMA-ES, is
applied to different HPO tasks where some prior knowledge is available, showing
its superior performance over the original CMA-ES as well as BO approaches with
or without using the prior knowledge.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:50:26 GMT""}]","2020-12-15"
"2012.06933","Jian Zhou","Xingchi Mu and Jian Zhou","Pure Bulk Orbital and Spin Photocurrent in Two-Dimensional Ferroelectric
  Materials","6 figures, under peer review","npj Computational Materials 7, 61 (2021)","10.1038/s41524-021-00531-7",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We elucidate light-induced orbital and spin current through nonlinear
response theory, which generalizes the well-known bulk photovoltaic effect in
centrosymmetric broken materials from charge to the spin and orbital degrees of
freedom. We use two-dimensional nonmagnetic ferroelectric materials (such as
GeS and its analogues) to illustrate this bulk orbital/spin photovoltaic
effect, through first-principles calculations. These materials possess a
vertical mirror symmetry and time-reversal symmetry but lack of inversion
symmetry. We reveal that in addition to the conventional photocurrent that
propagates parallel to the mirror plane (under linearly polarized light), the
symmetric forbidden current perpendicular to the mirror actually contains
electron flows, which carry angular momentum information and move oppositely.
One could observe a pure orbital moment current with zero electric charge
current. This hidden photo-induced orbital current leads to a pure spin current
via spin-orbit coupling interactions. Therefore, a four-terminal device can be
designed to detect and measure photo-induced charge, orbital, and spin currents
simultaneously. All these currents couple with electric polarization $P$, hence
their amplitude and direction can be manipulated through ferroelectric phase
transition. Our work provides a route to generalizing nanoscale devices from
their photo-induced electronics to orbitronics and spintronics.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 00:54:45 GMT""}]","2021-08-30"
"2012.06934","Rohan Pattnaik","R. Pattnaik, K. Sharma, K. Alabarta, D. Altamirano, M. Chakraborty, A.
  Kembhavi, M. Mendez and J.K. Orwat-Kapola","A Machine Learning Approach For Classifying Low-mass X-ray Binaries
  Based On Their Compact Object Nature","16 pages, 10 figures, 7 tables, Accepted for publication in MNRAS
  main journal",,"10.1093/mnras/staa3899",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low Mass X-ray binaries (LMXBs) are binary systems where one of the
components is either a black hole or a neutron star and the other is a less
massive star. It is challenging to unambiguously determine whether a LMXB hosts
a black hole or a neutron star. In the last few decades, multiple observational
works have tried, with different levels of success, to address this problem. In
this paper, we explore the use of machine learning to tackle this observational
challenge. We train a random forest classifier to identify the type of compact
object using the energy spectrum in the energy range 5-25 keV obtained from the
Rossi X-ray Timing Explorer archive. We report an average accuracy of 87+/-13
in classifying the spectra of LMXB sources. We further use the trained model
for predicting the classes for LMXB systems with unknown or ambiguous
classification. With the ever-increasing volume of astronomical data in the
X-ray domain from present and upcoming missions (e.g., SWIFT, XMM-Newton, XARM,
ATHENA, NICER), such methods can be extremely useful for faster and robust
classification of X-ray sources and can also be deployed as part of the data
reduction pipeline.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 01:08:18 GMT""}]","2021-01-06"
"2012.06935","Yuya Kurebayashi","Yuya Kurebayashi, Hiroki Oshiyama, Naokazu Shibata","Ground-state phase diagram of the one-dimensional $t$-$J_s$-$J_{\tau}$
  model at quarter filling","5 pages, 8 figures","Phys. Rev. B 103, 165115 (2021)","10.1103/PhysRevB.103.165115",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the ground state of the one-dimensional ""$t$-$J_s$-$J_{\tau}$
model,"" which is a variant of the $t$-$J$ model with additional channel degree
of freedom. The model is not only a generalization of the $t$-$J$ model but
also an effective model of the two-channel Kondo lattice model in the
strong-coupling region. The low-energy excitations and correlation functions
are systematically calculated by the density matrix renormalization group
method, and the ground-state phase diagram at quarter filling consisting of a
Tomonaga-Luttinger liquid, spin-gap state, channel-gap state, insulator, and
phase separation is determined. We find that weak channel fluctuations
stabilize the spin-gap state, while strong channel fluctuations lead to the
transition to the insulator.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 01:22:50 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 15:08:55 GMT""}]","2021-04-16"
"2012.06936","Linhua Jiang","Linhua Jiang, Nobunari Kashikawa, Shu Wang, Gregory Walth, Luis C. Ho,
  Zheng Cai, Eiichi Egami, Xiaohui Fan, Kei Ito, Yongming Liang, Daniel
  Schaerer, and Daniel P. Stark","Evidence for GN-z11 as a luminous galaxy at redshift 10.957","Published in Nature Astronomy on Dec 14, 2020; 21 pages; authors'
  version",,"10.1038/s41550-020-01275-y",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  GN-z11 was photometrically selected as a luminous star-forming galaxy
candidate at redshift z > 10 based on Hubble Space Telescope (HST) imaging
data. Follow-up HST near-infrared grism observations detected a continuum break
that was explained as the Ly-alpha break corresponding to z = 11.09
(+0.08-0.12). However, its accurate redshift remained unclear. Here we report a
probable detection of three ultraviolet (UV) emission lines from GN-z11, which
can be interpreted as the [C III] 1907, C III] 1909 doublet and O III] 1666 at
z = 10.957+/-0.001 (when the Universe was only ~420 Myr old, or ~3% of its
current age). This is consistent with the redshift of the previous grism
observations, supporting GN-z11 as the most distant galaxy known to date. Its
UV lines likely originate from dense ionized gas that is rarely seen at low
redshifts, and its strong [C III] and C III] emission is partly due to an
active galactic nucleus (AGN) or enhanced carbon abundance. GN-z11 is luminous
and young, yet moderately massive, implying a rapid build-up of stellar mass in
the past. Future facilities will be able to find the progenitors of such
galaxies at higher redshift and probe the cosmic epoch in the beginning of
re-ionization.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 01:26:18 GMT""}]","2020-12-15"
"2012.06937","Linhua Jiang","Linhua Jiang, Shu Wang, Bing Zhang, Nobunari Kashikawa, Luis C. Ho,
  Zheng Cai, Eiichi Egami, Gregory Walth, Yi-Si Yang, Bin-Bin Zhang, Hai-Bin
  Zhao","A possible bright ultraviolet flash from a galaxy at redshift z ~ 11","Published in Nature Astronomy on Dec 14, 2020; 19 pages; authors'
  version",,"10.1038/s41550-020-01266-z",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the optical sky, minutes-duration transients from cosmological distances
are rare. Known objects that give rise to such transients include gamma-ray
bursts (GRBs), the most luminous explosions in the universe that have been
detected at redshift as high as z ~ 9.4. These high-redshift GRBs and their
associated emission can be used to probe the star formation and reionization
history in the era of cosmic dawn. Here we report a near-infrared transient
with an observed duration shorter than 245 s coincident with the luminous
star-forming galaxy GN-z11 at z ~ 11. The telluric absorption shown in the
near-infrared spectrum indicates its origin from above the atmosphere. We can
rule out the possibility of known man-made objects or moving objects in the
Solar system based on the observational information and our current
understanding of the properties of these objects. Since some long-duration GRBs
are associated with a bright ultraviolet (UV) or optical flash, we investigate
the possibility that the detected signal arose from a rest-frame UV flash
associated with a long GRB from GN-z11. Despite the very low probability of
being a GRB, we find that the spectrum, brightness, and duration of the
transient are consistent with such an interpretation. Our result may suggest
that long GRBs can be produced as early as 420 million years after the Big
Bang.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 01:26:57 GMT""}]","2020-12-15"
"2012.06938","V. N. Krishnachandran","V. N. Krishnachandran","Differential Equations: A Historical Refresher",,,,,"math.HO","http://creativecommons.org/licenses/by-sa/4.0/","  This paper presents a brief account of the important milestones in the
historical development of the theory of differential equations. The paper
begins with a discussion on the date of birth of differential equations and
then touches upon Newton's approach to differential equations. Then the
development of the various methods for solving the first order differential
equations and the second order linear differential equations are discussed. The
paper concludes with a brief mention of the series solutions of differential
equations and the qualitative study of differential equations.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 01:28:18 GMT""}]","2020-12-15"
"2012.06939","Ohkyung Kwon","Jonathan W. Richardson, Ohkyung Kwon, H. Richard Gustafson, Craig
  Hogan, Brittany L. Kamai, Lee P. McCuller, Stephan S. Meyer, Chris Stoughton,
  Raymond E. Tomlin, and Rainer Weiss","Interferometric Constraints on Spacelike Coherent Rotational
  Fluctuations","9 pages, 4 figures. PRL accepted manuscript","Phys. Rev. Lett. 126, 241301 (2021)","10.1103/PhysRevLett.126.241301","FERMILAB-PUB-20-558-E","gr-qc hep-ex physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Precision measurements are reported of the cross-spectrum of
rotationally-induced differential position displacements in a pair of colocated
39 m long, high power Michelson interferometers. One arm of each interferometer
is bent $90^{\circ}$ near its midpoint to obtain sensitivity to rotations about
an axis normal to the plane of the instrument. The instrument achieves
quantum-limited sensing of spatially-correlated signals in a broad frequency
band extending beyond the 3.9 MHz inverse light travel time of the apparatus.
For stationary signals with bandwidth $\Delta f > 10\;\mathrm{kHz}$, the
sensitivity to rotation-induced strain $h$ of classical or exotic origin
surpasses $\mathrm{CSD}_{\delta h} < t_P / 2$, where $t_P = 5.39 \times
10^{-44}\;\mathrm{s}$ is the Planck time. This measurement is used to constrain
a semiclassical model of nonlocally coherent rotational degrees of freedom of
spacetime, which have been conjectured to emerge in holographic quantum
geometry but are not present in a classical metric.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 01:28:49 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 16:49:15 GMT""}]","2021-06-21"
"2012.06940","Jinsong Zhang","Jinsong Zhang, Xingzi Liu, Kun Li","Human Pose Transfer by Adaptive Hierarchical Deformation","13 pages, 10 figures. Code is available at
  https://github.com/Zhangjinso/PINet_PG","Computer Graphics Forum (2020), Volume 39, Issue 7",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human pose transfer, as a misaligned image generation task, is very
challenging. Existing methods cannot effectively utilize the input information,
which often fail to preserve the style and shape of hair and clothes. In this
paper, we propose an adaptive human pose transfer network with two hierarchical
deformation levels. The first level generates human semantic parsing aligned
with the target pose, and the second level generates the final textured person
image in the target pose with the semantic guidance. To avoid the drawback of
vanilla convolution that treats all the pixels as valid information, we use
gated convolution in both two levels to dynamically select the important
features and adaptively deform the image layer by layer. Our model has very few
parameters and is fast to converge. Experimental results demonstrate that our
model achieves better performance with more consistent hair, face and clothes
with fewer parameters than state-of-the-art methods. Furthermore, our method
can be applied to clothing texture transfer.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 01:49:26 GMT""}]","2020-12-15"
"2012.06941","Jean-Pierre Magnot","Jean-Pierre Magnot","On a class of closed cocycles for algebras of non-formal, possibly
  unbounded, pseudodifferential operators","A result deleted in this new shorter version. arXiv admin note: text
  overlap with arXiv:2007.00387",,,,"math.FA math-ph math.KT math.MP math.OA","http://creativecommons.org/licenses/by/4.0/","  In this article, we consider algebras $\mathcal{A}$ of non-formal
pseudodifferential operators over $S^1$ which contain $C^\infty(S^1),$
understood as multiplication operators. We apply a construction of Chern-Weil
type forms in order to get $2k-$closed cocycles. For $k=1,$ we obtain a cocycle
on the algebra of (maybe non classical) pseudodifferential operators with the
same cohomology class as the Schwinger cocycle on the algebra of Classical
pseudodifferential operators, previously extended and studied by the author on
algebras of the same type.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 02:10:04 GMT""},{""version"":""v2"",""created"":""Sat, 23 Jul 2022 08:04:15 GMT""},{""version"":""v3"",""created"":""Thu, 29 Dec 2022 12:46:33 GMT""}]","2023-01-02"
"2012.06942","Filander Sequeira","Fil\'ander A. Sequeira and Helen Guill\'en-Oviedo","Some aspects on the computational implementation of diverse terms
  arising in mixed virtual element formulations",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In the present paper we describe the computational implementation of some
integral terms that arise from mixed virtual element methods (mixed-VEM) in
two-dimensional pseudostress-velocity formulations. The implementation
presented here consider any polynomial degree $k \geq 0$ in a natural way by
building several local matrices of small size through the matrix multiplication
and the Kronecker product. In particular, we apply the foregoing mentioned
matrices to the Navier-Stokes equations with Dirichlet boundary conditions,
whose mixed-VEM formulation was originally proposed and analyzed in a recent
work using virtual element subspaces for $H(\text{div})$ and $H^1$,
simultaneously. In addition, an algorithm is proposed for the assembly of the
associated global linear system for the Newton's iteration. Finally, we present
a numerical example in order to illustrate the performance of the mixed-VEM
scheme and confirming the expected theoretical convergence rates.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 02:24:54 GMT""}]","2020-12-15"
"2012.06943","Snehasish Mukherjee","Snehasish Mukherjee, Phaniram Sayapaneni, Shankar Subramanya","Discriminative Pre-training for Low Resource Title Compression in
  Conversational Grocery","To be published in Proceedings of ACM SIGIR Workshop on eCommerce
  (SIGIR eCom 20) 2020",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The ubiquity of smart voice assistants has made conversational shopping
commonplace. This is especially true for low consideration segments like
grocery. A central problem in conversational grocery is the automatic
generation of short product titles that can be read out fast during a
conversation. Several supervised models have been proposed in the literature
that leverage manually labeled datasets and additional product features to
generate short titles automatically. However, obtaining large amounts of
labeled data is expensive and most grocery item pages are not as feature-rich
as other categories. To address this problem we propose a pre-training based
solution that makes use of unlabeled data to learn contextual product
representations which can then be fine-tuned to obtain better title compression
even in a low resource setting. We use a self-attentive BiLSTM encoder network
with a time distributed softmax layer for the title compression task. We
overcome the vocabulary mismatch problem by using a hybrid embedding layer that
combines pre-trained word embeddings with trainable character level
convolutions. We pre-train this network as a discriminator on a replaced-token
detection task over a large number of unlabeled grocery product titles.
Finally, we fine tune this network, without any modifications, with a small
labeled dataset for the title compression task. Experiments on Walmart's online
grocery catalog show our model achieves performance comparable to
state-of-the-art models like BERT and XLNet. When fine tuned on all of the
available training data our model attains an F1 score of 0.8558 which lags the
best performing model, BERT-Base, by 2.78% and XLNet by 0.28% only, while using
55 times lesser parameters than both. Further, when allowed to fine tune on 5%
of the training data only, our model outperforms BERT-Base by 24.3% in F1
score.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 02:34:56 GMT""}]","2020-12-15"
"2012.06944","Tiago Saraiva","T. A. Sobral, V. H. de Holanda, F. C. B. Leal, T. T. Saraiva","Deformation of loops in 2D packing of flexible rods",,,"10.1088/1361-6463/abf226",,"cond-mat.soft","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The injection of a long flexible rod into a two-dimensional domain yields a
complex pattern commonly studied through elasticity theory, packing analysis,
and fractal geometries. ""Loop"" is a one-vertex entity that is naturally formed
in this system. The role of the elastic features of each loop in 2D packing has
not yet been discussed. In this work, we point out how the shape of a given
loop in the complex structure allows estimating local deformations and forces.
First, we build sets of symmetric free loops and performed compression
experiments. Then, tight packing configurations are analyzed by using image
processing. We found that the dimensions of the loops, confined or not, obey
the same dependence on the deformation. The result is consistent with a simple
model based on 2D elastic theory for filaments, where the rod adopts the shape
of Euler's elasticas between its contact points. The force and the stored
energy are obtained from numerical integration of the analytic expressions. In
an additional experiment, we obtain that the compression force for deformed
loops corroborates the theoretical findings. The importance of the shape of the
loop is discussed and we hope that the theoretical curves may allow statistical
considerations in future investigations.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 02:41:35 GMT""},{""version"":""v2"",""created"":""Thu, 25 Mar 2021 00:12:03 GMT""}]","2021-03-29"
"2012.06945","Sibasish Laha","Sibasish Laha (NASA/GSFC), Christopher S. Reynolds, James Reeves,
  Gerard Kriss, Matteo Guainazzi, Randall Smith, Sylvain Veilleux, and Daniel
  Proga","Ionized outflows from active galactic nuclei as the essential elements
  of feedback","An invited Review Article published in Nature Astronomy:
  https://www.nature.com/articles/s41550-020-01255-2",,"10.1038/s41550-020-01255-2",,"astro-ph.GA astro-ph.HE astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Outflows from active galactic nuclei (AGN) are one of the fundamental
mechanisms by which the central supermassive black hole interacts with its host
galaxy. Detected in $\ge 50\%$ of nearby AGN, these outflows have been found to
carry kinetic energy that is a significant fraction of AGN power, and thereby
give negative feedback to their host galaxies. To understand the physical
processes that regulate them, it is important to have a robust estimate of
their physical and dynamical parameters. In this review we summarize our
current understanding on the physics of the ionized outflows detected in
absorption in the UV and X-ray wavelength bands. We discuss the most relevant
observations and our current knowledge and uncertainties in the measurements of
the outflow parameters. We also discuss their origin and acceleration
mechanisms. The commissioning and concept studies of large telescope missions
with high resolution spectrographs in UV/optical and X-rays along with rapid
advancements in simulations offer great promise for discoveries in this field
over the next decade.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 02:57:45 GMT""}]","2020-12-15"
"2012.06946","Jianfeng Wang","Jianfeng Wang and Xiaowei Hu and Pengchuan Zhang and Xiujun Li and
  Lijuan Wang and Lei Zhang and Jianfeng Gao and Zicheng Liu","MiniVLM: A Smaller and Faster Vision-Language Model",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent vision-language (VL) studies have shown remarkable progress by
learning generic representations from massive image-text pairs with transformer
models and then fine-tuning on downstream VL tasks. While existing research has
been focused on achieving high accuracy with large pre-trained models, building
a lightweight model is of great value in practice but is less explored. In this
paper, we propose a smaller and faster VL model, MiniVLM, which can be
finetuned with good performance on various downstream tasks like its larger
counterpart. MiniVLM consists of two modules, a vision feature extractor and a
transformer-based vision-language fusion module. We design a Two-stage
Efficient feature Extractor (TEE), inspired by the one-stage EfficientDet
network, to significantly reduce the time cost of visual feature extraction by
$95\%$, compared to a baseline model. We adopt the MiniLM structure to reduce
the computation cost of the transformer module after comparing different
compact BERT models. In addition, we improve the MiniVLM pre-training by adding
$7M$ Open Images data, which are pseudo-labeled by a state-of-the-art
captioning model. We also pre-train with high-quality image tags obtained from
a strong tagging model to enhance cross-modality alignment. The large models
are used offline without adding any overhead in fine-tuning and inference. With
the above design choices, our MiniVLM reduces the model size by $73\%$ and the
inference time cost by $94\%$ while being able to retain $94-97\%$ of the
accuracy on multiple VL tasks. We hope that MiniVLM helps ease the use of the
state-of-the-art VL research for on-the-edge applications.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 03:02:06 GMT""},{""version"":""v2"",""created"":""Mon, 9 Aug 2021 20:06:03 GMT""}]","2021-08-11"
"2012.06947","Bai Cui","Bai Cui and Ahmed Zamzam and Andrey Bernstein","Network-Cognizant Time-Coupled Aggregate Flexibility of Distribution
  Systems Under Uncertainties","6 pages, 1 figure, to be published in IEEE Control Systems Letters",,"10.1109/LCSYS.2020.3045080",,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Increasing integration of distributed energy resources (DERs) within
distribution feeders provides unprecedented flexibility at the
distribution-transmission interconnection. To exploit this flexibility and to
use the capacity potential of aggregate DERs, feasible substation power
injection trajectories need to be efficiently characterized. This paper
provides an ellipsoidal inner approximation of the set of feasible power
injection trajectories at the substation such that for any point in the set,
there exists a feasible disaggregation strategy of DERs for any load
uncertainty realization. The problem is formulated as one of finding the robust
maximum volume ellipsoid inside the flexibility region under uncertainty.
Though the problem is NP-hard even in the deterministic case, this paper
derives novel approximations of the resulting adaptive robust optimization
problem based on optimal second-stage policies. The proposed approach yields
less conservative flexibility characterization than existing flexibility region
approximation formulations. The efficacy of the proposed method is demonstrated
on a realistic distribution feeder.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 03:09:06 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 03:38:10 GMT""}]","2020-12-16"
"2012.06948","Michael Zhang","Michael Zhang, Xiaotian Cheng, Daniel Copeland, Arjun Desai, Melody Y.
  Guan, Gabriel A. Brat, and Serena Yeung","Using Computer Vision to Automate Hand Detection and Tracking of Surgeon
  Movements in Videos of Open Surgery","AMIA 2020 Annual Symposium",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Open, or non-laparoscopic surgery, represents the vast majority of all
operating room procedures, but few tools exist to objectively evaluate these
techniques at scale. Current efforts involve human expert-based visual
assessment. We leverage advances in computer vision to introduce an automated
approach to video analysis of surgical execution. A state-of-the-art
convolutional neural network architecture for object detection was used to
detect operating hands in open surgery videos. Automated assessment was
expanded by combining model predictions with a fast object tracker to enable
surgeon-specific hand tracking. To train our model, we used publicly available
videos of open surgery from YouTube and annotated these with spatial bounding
boxes of operating hands. Our model's spatial detections of operating hands
significantly outperforms the detections achieved using pre-existing
hand-detection datasets, and allow for insights into intra-operative movement
patterns and economy of motion.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 03:10:09 GMT""}]","2020-12-15"
"2012.06949","Fernanda D. de Melo Hernandez","Fernanda D. de Melo Hernandez, C\'esar A. Hern\'andez Melo, Horacio
  Tapia-Recillas","Fermat's Little Theorem and Euler's Theorem in a class of rings","arXiv admin note: text overlap with arXiv:1911.07743",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Considering $\mathbb{Z}_n$ the ring of integers modulo $n$, the classical
Fermat-Euler theorem establishes the existence of a specific natural number
$\varphi(n)$ satisfying the following property: $
x^{\varphi(n)}=1%\hspace{1.0cm}\text{for all}\hspace{0.2cm}x\in \mathbb{Z}_n^*,
$ for all $x$ belonging to the group of units of $\mathbb{Z}_n$. In this
manuscript, this result is extended to a class of rings that satisfies some
mild conditions.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 03:12:47 GMT""}]","2020-12-15"
"2012.06950","Kerem Camsari","Kerem Y. Camsari, Mustafa Mert Torunbalci, William A. Borders, Hideo
  Ohno and Shunsuke Fukami","Double Free-Layer Magnetic Tunnel Junctions for Probabilistic Bits",,"Phys. Rev. Applied 15, 044049 (2021)","10.1103/PhysRevApplied.15.044049",,"cond-mat.mes-hall cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Naturally random devices that exploit ambient thermal noise have recently
attracted attention as hardware primitives for accelerating probabilistic
computing applications. One such approach is to use a low barrier nanomagnet as
the free layer of a magnetic tunnel junction (MTJ) whose magnetic fluctuations
are converted to resistance fluctuations in the presence of a stable fixed
layer. Here, we propose and theoretically analyze a magnetic tunnel junction
with no fixed layers but two free layers that are circularly shaped disk
magnets. We use an experimentally benchmarked model that accounts for finite
temperature magnetization dynamics, bias-dependent charge and spin-polarized
currents as well as the dipolar coupling between the free layers. We obtain
analytical results for statistical averages of fluctuations that are in good
agreement with the numerical model. We find that the free layers with low
diameters fluctuate to randomize the resistance of the MTJ in an approximately
bias-independent manner. We show how such MTJs can be used to build a binary
stochastic neuron (or a p-bit) in hardware. Unlike earlier stochastic MTJs that
need to operate at a specific bias point to produce random fluctuations, the
proposed design can be random for a wide range of bias values, independent of
spin-transfer-torque pinning. Moreover, in the absence of a carefully optimized
stabled fixed layer, the symmetric double-free layer stack can be manufactured
using present day Magnetoresistive Random Access Memory (MRAM) technology by
minimal changes to the fabrication process. Such devices can be used as
hardware accelerators in energy-efficient computing schemes that require a
large throughput of tunably random bits.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 03:21:24 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 17:02:00 GMT""}]","2021-05-05"
"2012.06951","Qi Qi","Qi Qi, Yi Xu, Rong Jin, Wotao Yin, Tianbao Yang","Attentional-Biased Stochastic Gradient Descent","29 pages","Transanctions on Machine Learning Research, 2023",,,"cs.LG cs.CV math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a simple yet effective provable method (named
ABSGD) for addressing the data imbalance or label noise problem in deep
learning. Our method is a simple modification to momentum SGD where we assign
an individual importance weight to each sample in the mini-batch. The
individual-level weight of sampled data is systematically proportional to the
exponential of a scaled loss value of the data, where the scaling factor is
interpreted as the regularization parameter in the framework of
distributionally robust optimization (DRO). Depending on whether the scaling
factor is positive or negative, ABSGD is guaranteed to converge to a stationary
point of an information-regularized min-max or min-min DRO problem,
respectively. Compared with existing class-level weighting schemes, our method
can capture the diversity between individual examples within each class.
Compared with existing individual-level weighting methods using meta-learning
that require three backward propagations for computing mini-batch stochastic
gradients, our method is more efficient with only one backward propagation at
each iteration as in standard deep learning methods. ABSGD is flexible enough
to combine with other robust losses without any additional cost. Our empirical
studies on several benchmark datasets demonstrate the effectiveness of the
proposed method.\footnote{Code is available
at:\url{https://github.com/qiqi-helloworld/ABSGD/}}
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 03:41:52 GMT""},{""version"":""v2"",""created"":""Sun, 18 Apr 2021 02:29:33 GMT""},{""version"":""v3"",""created"":""Sun, 10 Oct 2021 06:45:56 GMT""},{""version"":""v4"",""created"":""Sun, 25 Dec 2022 18:39:33 GMT""},{""version"":""v5"",""created"":""Thu, 8 Jun 2023 05:58:43 GMT""}]","2023-06-09"
"2012.06952","Chen Wang","Chen Wang","An overview of SPSA: recent development and applications",,,,,"math.OC","http://creativecommons.org/publicdomain/zero/1.0/","  There is an increasing need in solving high-dimensional optimization problems
under non-deterministic environment. The simultaneous perturbation stochastic
approximation (SPSA) algorithm has recently attracted considerable attention
for solving high-dimensional optimization problems where the analytical formula
cannot be attained. SPSA is designed to estimate the gradient by applying
perturbation on a random subset of dimensions at each iteration. SPSA can be
easily implemented and is highly efficient in that that it relies on
measurements of the objective function, not on measurements of the gradient of
the objective function. Since its invention, SPSA has been implemented in
various fields such as reinforcement learning, production optimization etc. The
paper briefly discuss the recent development of SPSA and its applications.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 03:45:25 GMT""}]","2020-12-15"
"2012.06953","Richard Schwartz","Richard Evan Schwartz","Paper Moebius bands with T Patterns","you should probably read this after reading the first paper. arXiv
  admin note: text overlap with arXiv:2008.11610",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this pape, which is a sequel to my paper ""An improved lower bound for the
optimal paper Moebius band"", we geometric estimates for immersed paper Moebius
bands having an additional geometric feature called a $T$ pattern. These
results, in particular, give bounds on the geometry of embedded paper Moebius
bands of sufficiently small aspect ratio.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 03:58:17 GMT""}]","2020-12-15"
"2012.06954","Dmitry Kazhdan","Dmitry Kazhdan, Botty Dimanov, Mateja Jamnik, Pietro Li\`o","MEME: Generating RNN Model Explanations via Model Extraction","Presented at the HAMLETS workshop at the 34th Conference on Neural
  Information Processing Systems (NeurIPS 2020)",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recurrent Neural Networks (RNNs) have achieved remarkable performance on a
range of tasks. A key step to further empowering RNN-based approaches is
improving their explainability and interpretability. In this work we present
MEME: a model extraction approach capable of approximating RNNs with
interpretable models represented by human-understandable concepts and their
interactions. We demonstrate how MEME can be applied to two multivariate,
continuous data case studies: Room Occupation Prediction, and In-Hospital
Mortality Prediction. Using these case-studies, we show how our extracted
models can be used to interpret RNNs both locally and globally, by
approximating RNN decision-making via interpretable concept interactions.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 04:00:08 GMT""}]","2021-04-15"
"2012.06955","M Ghanashyam Krishna","Y. Rajesh, M.S.S. Bharati, S. Venugopal Rao, and M. Ghanashyam Krishna","ZnO Nanowire Arrays Decorated with Titanium Nitride Nanoparticles as
  Surface Enhanced Raman Scattering Substrates",,,"10.1007/s00339-021-04424-w",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In this work, ZnO nanowire arrays decorated with titanium nitride (TiN)
nanoparticles as surface enhanced Raman scattering (SERS) substrates is
demonstrated. ZnO nanowires were grown by hydrothermal synthesis while ~100 nm
TiN nanoparticles were obtained by grinding commercial powders for several
hours. They were then decorated on the ZnO nanowire arrays using acetone as the
medium. Scanning electron microscopy confirmed the presence of TiN
nanoparticles on the ZnO nanowires. TiN nanoparticles exhibited localized
surface plasmon resonances at 430, 520 and 600 nm. SERS experiments using Nile
Blue and Methylene Blue as the analyte molecules showed significant enhancement
in the Raman signals. It is shown that the origin of the SERS effect is
chemical in nature, due to charge transfer between the analyte molecule and the
TiN nanoparticles. The current work, thus, represents a simple, cost-effective
and facile method for the fabrication of TiN based surface enhanced Raman
scattering substrates.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 04:04:29 GMT""}]","2021-04-07"
"2012.06956","Zifeng Wang","Zifeng Wang, Tong Jian, Kaushik Chowdhury, Yanzhi Wang, Jennifer Dy,
  Stratis Ioannidis","Learn-Prune-Share for Lifelong Learning","Accepted to the IEEE International Conference on Data Mining 2020
  (ICDM'20)",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In lifelong learning, we wish to maintain and update a model (e.g., a neural
network classifier) in the presence of new classification tasks that arrive
sequentially. In this paper, we propose a learn-prune-share (LPS) algorithm
which addresses the challenges of catastrophic forgetting, parsimony, and
knowledge reuse simultaneously. LPS splits the network into task-specific
partitions via an ADMM-based pruning strategy. This leads to no forgetting,
while maintaining parsimony. Moreover, LPS integrates a novel selective
knowledge sharing scheme into this ADMM optimization framework. This enables
adaptive knowledge sharing in an end-to-end fashion. Comprehensive experimental
results on two lifelong learning benchmark datasets and a challenging
real-world radio frequency fingerprinting dataset are provided to demonstrate
the effectiveness of our approach. Our experiments show that LPS consistently
outperforms multiple state-of-the-art competitors.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 04:05:16 GMT""}]","2020-12-15"
"2012.06957","Zifeng Wang","Zifeng Wang, Batool Salehi, Andrey Gritsenko, Kaushik Chowdhury,
  Stratis Ioannidis, Jennifer Dy","Open-World Class Discovery with Kernel Networks","Accepted to the IEEE International Conference on Data Mining 2020
  (ICDM'20); Best paper candidate",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study an Open-World Class Discovery problem in which, given labeled
training samples from old classes, we need to discover new classes from
unlabeled test samples. There are two critical challenges to addressing this
paradigm: (a) transferring knowledge from old to new classes, and (b)
incorporating knowledge learned from new classes back to the original model. We
propose Class Discovery Kernel Network with Expansion (CD-KNet-Exp), a deep
learning framework, which utilizes the Hilbert Schmidt Independence Criterion
to bridge supervised and unsupervised information together in a systematic way,
such that the learned knowledge from old classes is distilled appropriately for
discovering new classes. Compared to competing methods, CD-KNet-Exp shows
superior performance on three publicly available benchmark datasets and a
challenging real-world radio frequency fingerprinting dataset.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 04:21:39 GMT""}]","2020-12-15"
"2012.06958","Justin Solomon","Justin Solomon, Kristjan Greenewald, Haikady N. Nagaraja","$k$-Variance: A Clustered Notion of Variance",,,,,"math.ST cs.LG cs.NA math.NA stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce $k$-variance, a generalization of variance built on the
machinery of random bipartite matchings. $K$-variance measures the expected
cost of matching two sets of $k$ samples from a distribution to each other,
capturing local rather than global information about a measure as $k$
increases; it is easily approximated stochastically using sampling and linear
programming. In addition to defining $k$-variance and proving its basic
properties, we provide in-depth analysis of this quantity in several key cases,
including one-dimensional measures, clustered measures, and measures
concentrated on low-dimensional subsets of $\mathbb R^n$. We conclude with
experiments and open problems motivated by this new way to summarize
distributional shape.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 04:25:32 GMT""}]","2020-12-15"
"2012.06959","Chenhao Xie","Chenhao Xie, Jieyang Chen, Jesun S Firoz, Jiajia Li, Shuaiwen Leon
  Song, Kevin Barker, Mark Raugas, Ang Li","Fast and Scalable Sparse Triangular Solver for Multi-GPU Based HPC
  Architectures",,,,,"cs.DC cs.AR","http://creativecommons.org/publicdomain/zero/1.0/","  Designing efficient and scalable sparse linear algebra kernels on modern
multi-GPU based HPC systems is a daunting task due to significant irregular
memory references and workload imbalance across the GPUs. This is particularly
the case for Sparse Triangular Solver (SpTRSV) which introduces additional
two-dimensional computation dependencies among subsequent computation steps.
Dependency information is exchanged and shared among GPUs, thus warrant for
efficient memory allocation, data partitioning, and workload distribution as
well as fine-grained communication and synchronization support. In this work,
we demonstrate that directly adopting unified memory can adversely affect the
performance of SpTRSV on multi-GPU architectures, despite linking via fast
interconnect like NVLinks and NVSwitches. Alternatively, we employ the latest
NVSHMEM technology based on Partitioned Global Address Space programming model
to enable efficient fine-grained communication and drastic synchronization
overhead reduction. Furthermore, to handle workload imbalance, we propose a
malleable task-pool execution model which can further enhance the utilization
of GPUs. By applying these techniques, our experiments on the NVIDIA multi-GPU
supernode V100-DGX-1 and DGX-2 systems demonstrate that our design can achieve
on average 3.53x (up to 9.86x) speedup on a DGX-1 system and 3.66x (up to
9.64x) speedup on a DGX-2 system with 4-GPUs over the Unified-Memory design.
The comprehensive sensitivity and scalability studies also show that the
proposed zero-copy SpTRSV is able to fully utilize the computing and
communication resources of the multi-GPU system.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 04:35:29 GMT""}]","2020-12-15"
"2012.06960","Fengge Zhang","Fengge Zhang, Yungui Gong, Jiong Lin, Yizhou Lu, and Zhu Yi","Primordial Non-Gaussianity from G-inflation","16 pages, 3 figures","JCAP 04 (2021) 045","10.1088/1475-7516/2021/04/045",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Enormous information about interactions is contained in the non-Gaussianities
of the primordial curvature perturbations, which are essential to break the
degeneracy of inflationary models. We study the primordial bispectra for
G-inflation models predicting both sharp and broad peaks in the primordial
scalar power spectrum. We calculate the non-Gaussianity parameter
$f_{\mathrm{NL}}$ in the equilateral limit and squeezed limit numerically, and
confirm that the consistency relation holds in these models. Even though
$f_{\mathrm{NL}}$ becomes large at the scales before the power spectrum reaches
the peak and the scales where there are wiggles in the power spectrum, it
remains to be small at the peak scales. Therefore, the contributions of
non-Gaussianity to the scalar induced secondary gravitational waves and
primordial black hole abundance are expected to be negligible.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 04:38:27 GMT""},{""version"":""v2"",""created"":""Tue, 20 Apr 2021 12:13:42 GMT""}]","2021-04-21"
"2012.06961","Jiashuo Jiang","Jiashuo Jiang, Xiaocheng Li, Jiawei Zhang","Online Stochastic Optimization with Wasserstein Based Non-stationarity",,,,,"cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  We consider a general online stochastic optimization problem with multiple
budget constraints over a horizon of finite time periods. In each time period,
a reward function and multiple cost functions are revealed, and the decision
maker needs to specify an action from a convex and compact action set to
collect the reward and consume the budget. Each cost function corresponds to
the consumption of one budget. In each period, the reward and cost functions
are drawn from an unknown distribution, which is non-stationary across time.
The objective of the decision maker is to maximize the cumulative reward
subject to the budget constraints. This formulation captures a wide range of
applications including online linear programming and network revenue
management, among others. In this paper, we consider two settings: (i) a
data-driven setting where the true distribution is unknown but a prior estimate
(possibly inaccurate) is available; (ii) an uninformative setting where the
true distribution is completely unknown. We propose a unified
Wasserstein-distance based measure to quantify the inaccuracy of the prior
estimate in setting (i) and the non-stationarity of the system in setting (ii).
We show that the proposed measure leads to a necessary and sufficient condition
for the attainability of a sublinear regret in both settings. For setting (i),
we propose a new algorithm, which takes a primal-dual perspective and
integrates the prior information of the underlying distributions into an online
gradient descent procedure in the dual space. The algorithm also naturally
extends to the uninformative setting (ii). Under both settings, we show the
corresponding algorithm achieves a regret of optimal order. In numerical
experiments, we demonstrate how the proposed algorithms can be naturally
integrated with the re-solving technique to further boost the empirical
performance.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 04:47:37 GMT""},{""version"":""v2"",""created"":""Wed, 23 Dec 2020 06:24:13 GMT""},{""version"":""v3"",""created"":""Mon, 25 Jul 2022 00:17:45 GMT""}]","2022-07-26"
"2012.06962","Jae Bem You Dr.","Jia Meng, Jae Bem You, Gilmar F. Arends, Hao Hao, Xiaoli Tan, Xuehua
  Zhang","Microfluidic device coupled with total internal reflection microscopy
  for in situ observation of precipitation","Preprint submitted to The European Physical Journal E",,,,"cond-mat.soft physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  In situ observation of precipitation or phase separation induced by solvent
addition is important in studying its dynamics. Combined with optical and
fluorescence microscopy, microfluidic devices have been leveraged in studying
the phase separation in various materials including biominerals, nanoparticles,
and inorganic crystals. However, strong scattering from the subphases in the
mixture is problematic for in situ study of phase separation with high temporal
and spatial resolution. In this work, we present a quasi-2D microfluidic device
combined with total internal reflection microscopy as an approach for in situ
observation of phase separation. The quasi-2D microfluidic device comprises of
a shallow main channel and a deep side channel. Mixing between a solution in
the main channel (solution A) and another solution (solution B) in the side
channel is predominantly driven by diffusion due to high fluid resistance from
the shallow height of the main channel, which is confirmed using fluorescence
microscopy. Moreover, relying on diffusive mixing, we can control the
composition of the mixture in the main channel by tuning the composition of
solution B. We demonstrate the application of our method for in situ
observation of asphaltene precipitation and beta-alanine crystallization.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:15:23 GMT""}]","2020-12-15"
"2012.06963","Joel Schiff","Joel L. Schiff","The Arithmetic Fourier Transform","23 pages. Dedicated to my colleague Wayne J. Walker (1944-2019).
  Together we uncovered some of the beautiful aspects of the AFT",,,,"math.CV math.NT","http://creativecommons.org/licenses/by/4.0/","  The Arithmetic Fourier Transform is a numerical formulation for computing
Fourier series and Taylor series coefficients. It competes with the Fast
Fourier Transform in terms of speed and efficiency, requiring only addition
operations and can be performed by parallel processing. The AFT has some deep
connections with the Prime Number Theorem and its rich history is discussed in
this expository article.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:20:12 GMT""}]","2020-12-15"
"2012.06964","Bolin Lai","Bolin Lai, Yuhsuan Wu, Xiaoyu Bai, Xiao-Yun Zhou, Peng Wang, Jinzheng
  Cai, Yuankai Huo, Lingyun Huang, Yong Xia, Jing Xiao, Le Lu, Heping Hu, Adam
  Harrison","Fully-Automated Liver Tumor Localization and Characterization from
  Multi-Phase MR Volumes Using Key-Slice ROI Parsing: A Physician-Inspired
  Approach","14 pages",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using radiological scans to identify liver tumors is crucial for proper
patient treatment. This is highly challenging, as top radiologists only achieve
F1 scores of roughly 80% (hepatocellular carcinoma (HCC) vs. others) with only
moderate inter-rater agreement, even when using multi-phase magnetic resonance
(MR) imagery. Thus, there is great impetus for computer-aided diagnosis (CAD)
solutions. A critical challenge is to robustly parse a 3D MR volume to localize
diagnosable regions of interest (ROI), especially for edge cases. In this
paper, we break down this problem using a key-slice parser (KSP), which
emulates physician workflows by first identifying key slices and then
localizing their corresponding key ROIs. To achieve robustness, the KSP also
uses curve-parsing and detection confidence re-weighting. We evaluate our
approach on the largest multi-phase MR liver lesion test dataset to date (430
biopsy-confirmed patients). Experiments demonstrate that our KSP can localize
diagnosable ROIs with high reliability: 87% patients have an average 3D overlap
of >= 40% with the ground truth compared to only 79% using the best tested
detector. When coupled with a classifier, we achieve an HCC vs. others F1 score
of 0.801, providing a fully-automated CAD performance comparable to top human
physicians.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:23:33 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 19:47:40 GMT""},{""version"":""v3"",""created"":""Fri, 9 Apr 2021 04:04:47 GMT""}]","2021-04-12"
"2012.06965","Sabirat Rubya","Sabirat Rubya, Joseph Numainville, Svetlana Yarosh","Comparing Generic and Community-Situated Crowdsourcing for Data
  Validation in the Context of Recovery from Substance Use Disorders","Accepted at ACM CHI 2021",,,,"cs.HC cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Targeting the right group of workers for crowdsourcing often achieves better
quality results. One unique example of targeted crowdsourcing is seeking
community-situated workers whose familiarity with the background and the norms
of a particular group can help produce better outcome or accuracy. These
community-situated crowd workers can be recruited in different ways from
generic online crowdsourcing platforms or from online recovery communities. We
evaluate three different approaches to recruit generic and community-situated
crowd in terms of the time and the cost of recruitment, and the accuracy of
task completion. We consider the context of Alcoholics Anonymous (AA), the
largest peer support group for recovering alcoholics, and the task of
identifying and validating AA meeting information. We discuss the benefits and
trade-offs of recruiting paid vs. unpaid community-situated workers and provide
implications for future research in the recovery context and relevant domains
of HCI, and for design of crowdsourcing ICT systems.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:25:04 GMT""}]","2020-12-15"
"2012.06966","Zhixin Qi","Zhixin Qi, Hongzhi Wang, Haoran Zhang","A Dual-Store Structure for Knowledge Graphs",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To effectively manage increasing knowledge graphs in various domains, a hot
research topic, knowledge graph storage management, has emerged. Existing
methods are classified to relational stores and native graph stores. Relational
stores are able to store large-scale knowledge graphs and convenient in
updating knowledge, but the query performance weakens obviously when the
selectivity of a knowledge graph query is large. Native graph stores are
efficient in processing complex knowledge graph queries due to its index-free
adjacent property, but they are inapplicable to manage a large-scale knowledge
graph due to limited storage budgets or inflexible updating process. Motivated
by this, we propose a dual-store structure which leverages a graph store to
accelerate the complex query process in the relational store. However, it is
challenging to determine what data to transfer from relational store to graph
store at what time. To address this problem, we formulate it as a Markov
Decision Process and derive a physical design tuner DOTIL based on
reinforcement learning. With DOTIL, the dual-store structure is adaptive to
dynamic changing workloads. Experimental results on real knowledge graphs
demonstrate that our proposed dual-store structure improves query performance
up to average 43.72% compared with the most commonly used relational stores.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:33:19 GMT""}]","2020-12-15"
"2012.06967","Bo-Qiang Ma","Hao Li, Bo-Qiang Ma","Light speed variation from active galactic nuclei","10 latex pages, 3 figures","Science Bulletin 65 (2020) 262-266","10.1016/j.scib.2019.11.024",,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies on the high-energy photons from gamma-ray bursts~(GRBs)
suggested a light speed variation $v(E)=c(1-E/E_{\mathrm{LV}})$ with
$E_\mathrm{LV}=3.6\times 10^{17}$ GeV. We check this speed variation from
previous observations on light curves of three active galactic nuclei (AGNs),
namely Markarian 421 (Mrk 421), Markarian 501 (Mrk 501) and PKS 2155-304. We
show that several phenomena related to the light curves of these AGNs can serve
as the supports for the light speed variation determined from GRBs.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:38:27 GMT""}]","2020-12-17"
"2012.06968","Kai Zhang","Kai Zhang, Hao Qian, Qing Cui, Qi Liu, Longfei Li, Jun Zhou, Jianhui
  Ma, Enhong Chen","Multi-Interactive Attention Network for Fine-grained Feature Learning in
  CTR Prediction","9 pages, 6 figures, WSDM2021, accepted",,,,"cs.IR cs.AI","http://creativecommons.org/licenses/by/4.0/","  In the Click-Through Rate (CTR) prediction scenario, user's sequential
behaviors are well utilized to capture the user interest in the recent
literature. However, despite being extensively studied, these sequential
methods still suffer from three limitations. First, existing methods mostly
utilize attention on the behavior of users, which is not always suitable for
CTR prediction, because users often click on new products that are irrelevant
to any historical behaviors. Second, in the real scenario, there exist numerous
users that have operations a long time ago, but turn relatively inactive in
recent times. Thus, it is hard to precisely capture user's current preferences
through early behaviors. Third, multiple representations of user's historical
behaviors in different feature subspaces are largely ignored. To remedy these
issues, we propose a Multi-Interactive Attention Network (MIAN) to
comprehensively extract the latent relationship among all kinds of fine-grained
features (e.g., gender, age and occupation in user-profile). Specifically, MIAN
contains a Multi-Interactive Layer (MIL) that integrates three local
interaction modules to capture multiple representations of user preference
through sequential behaviors and simultaneously utilize the fine-grained
user-specific as well as context information. In addition, we design a Global
Interaction Module (GIM) to learn the high-order interactions and balance the
different impacts of multiple features. Finally, Offline experiment results
from three datasets, together with an Online A/B test in a large-scale
recommendation system, demonstrate the effectiveness of our proposed approach.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:46:19 GMT""},{""version"":""v2"",""created"":""Sun, 7 Mar 2021 13:29:34 GMT""},{""version"":""v3"",""created"":""Wed, 3 Nov 2021 06:15:23 GMT""}]","2021-11-04"
"2012.06969","Vamshi Chowdary Madala","Abhejit Rajagopal, Vamshi C. Madala, Shivkumar Chandrasekaran, Peder
  E. Z. Larson","Predicting Generalization in Deep Learning via Local Measures of
  Distortion","Added preprint footnote",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  We study generalization in deep learning by appealing to complexity measures
originally developed in approximation and information theory. While these
concepts are challenged by the high-dimensional and data-defined nature of deep
learning, we show that simple vector quantization approaches such as PCA, GMMs,
and SVMs capture their spirit when applied layer-wise to deep extracted
features giving rise to relatively inexpensive complexity measures that
correlate well with generalization performance. We discuss our results in 2020
NeurIPS PGDL challenge.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:46:46 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 02:22:46 GMT""}]","2020-12-17"
"2012.06970","Ivan Yurievich Mogilnykh","I. Yu. Mogilnykh","Completely regular codes in Johnson and Grassmann graphs with small
  covering radii",,,,,"math.CO cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let L be a Desarguesian 2-spread in the Grassmann graph $J_q(n,2)$. We prove
that the collection of the 4-subspaces, which do not contain subspaces from L
is a completely regular code in $J_q(n,4)$. Similarly, we construct a
completely regular code in the Johnson graph $J(n,6)$ from the Steiner
quadruple system of the extended Hamming code. We obtain several new completely
regular codes covering radius 1 in the Grassmann graph $J_2(6,3)$ using binary
linear programming.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:47:59 GMT""}]","2020-12-15"
"2012.06971","Song Changhe","Changhe Song, Jingbei Li, Yixuan Zhou, Zhiyong Wu, Helen Meng","Syntactic representation learning for neural network based TTS with
  syntactic parse tree traversal","This paper was submitted to ICASSP2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Syntactic structure of a sentence text is correlated with the prosodic
structure of the speech that is crucial for improving the prosody and
naturalness of a text-to-speech (TTS) system. Nowadays TTS systems usually try
to incorporate syntactic structure information with manually designed features
based on expert knowledge. In this paper, we propose a syntactic representation
learning method based on syntactic parse tree traversal to automatically
utilize the syntactic structure information. Two constituent label sequences
are linearized through left-first and right-first traversals from constituent
parse tree. Syntactic representations are then extracted at word level from
each constituent label sequence by a corresponding uni-directional gated
recurrent unit (GRU) network. Meanwhile, nuclear-norm maximization loss is
introduced to enhance the discriminability and diversity of the embeddings of
constituent labels. Upsampled syntactic representations and phoneme embeddings
are concatenated to serve as the encoder input of Tacotron2. Experimental
results demonstrate the effectiveness of our proposed approach, with mean
opinion score (MOS) increasing from 3.70 to 3.82 and ABX preference exceeding
by 17% compared with the baseline. In addition, for sentences with multiple
syntactic parse trees, prosodic differences can be clearly perceived from the
synthesized speeches.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:52:07 GMT""}]","2020-12-15"
"2012.06972","Anand Joshi","Anand A. Joshi, Soyoung Choi, Haleh Akrami, Richard M. Leahy","fMRI-Kernel Regression: A Kernel-based Method for Pointwise Statistical
  Analysis of rs-fMRI for Population Studies",,,,,"eess.SP cs.LG eess.IV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Due to the spontaneous nature of resting-state fMRI (rs-fMRI) signals,
cross-subject comparison and therefore, group studies of rs-fMRI are
challenging. Most existing group comparison methods use features extracted from
the fMRI time series, such as connectivity features, independent component
analysis (ICA), and functional connectivity density (FCD) methods. However, in
group studies, especially in the case of spectrum disorders, distances to a
single atlas or a representative subject do not fully reflect the differences
between subjects that may lie on a multi-dimensional spectrum. Moreover, there
may not exist an individual subject or even an average atlas in such cases that
is representative of all subjects. Here we describe an approach that measures
pairwise distances between the synchronized rs-fMRI signals of pairs of
subjects instead of to a single reference point. We also present a method for
fMRI data comparison that leverages this generated pairwise feature to
establish a radial basis function kernel matrix. This kernel matrix is used in
turn to perform kernel regression of rs-fMRI to a clinical variable such as a
cognitive or neurophysiological performance score of interest. This method
opens a new pointwise analysis paradigm for fMRI data. We demonstrate the
application of this method by performing a pointwise analysis on the cortical
surface using rs-fMRI data to identify cortical regions associated with
variability in ADHD index. While pointwise analysis methods are common in
anatomical studies such as cortical thickness analysis and voxel- and
tensor-based morphometry and its variants, such a method is lacking for rs-fMRI
and could improve the utility of rs-fMRI for group studies. The method
presented in this paper is aimed at filling this gap.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:53:53 GMT""}]","2020-12-15"
"2012.06973","Chirag Kyal","Chirag Kyal","Spontaneous Emotion Recognition from Facial Thermal Images",,,,,"cs.CV cs.HC eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  One of the key research areas in computer vision addressed by a vast number
of publications is the processing and understanding of images containing human
faces. The most often addressed tasks include face detection, facial landmark
localization, face recognition and facial expression analysis. Other, more
specialized tasks such as affective computing, the extraction of vital signs
from videos or analysis of social interaction usually require one or several of
the aforementioned tasks that have to be performed. In our work, we analyze
that a large number of tasks for facial image processing in thermal infrared
images that are currently solved using specialized rule-based methods or not
solved at all can be addressed with modern learning-based approaches. We have
used USTC-NVIE database for training of a number of machine learning algorithms
for facial landmark localization.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 05:55:19 GMT""}]","2020-12-15"
"2012.06974","Bekir Sait Ciftler","Noor Ali Al-Athba Al-Marri, Bekir Sait Ciftler, Mohamed Abdallah","Federated Mimic Learning for Privacy Preserving Intrusion Detection","6 pages, 6 figures, accepted to Blackseacom 2020",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Internet of things (IoT) devices are prone to attacks due to the limitation
of their privacy and security components. These attacks vary from exploiting
backdoors to disrupting the communication network of the devices. Intrusion
Detection Systems (IDS) play an essential role in ensuring information privacy
and security of IoT devices against these attacks. Recently, deep
learning-based IDS techniques are becoming more prominent due to their high
classification accuracy. However, conventional deep learning techniques
jeopardize user privacy due to the transfer of user data to a centralized
server. Federated learning (FL) is a popular privacy-preserving decentralized
learning method. FL enables training models locally at the edge devices and
transferring local models to a centralized server instead of transferring
sensitive data. Nevertheless, FL can suffer from reverse engineering ML attacks
that can learn information about the user's data from model. To overcome the
problem of reverse engineering, mimic learning is another way to preserve the
privacy of ML-based IDS. In mimic learning, a student model is trained with the
public dataset, which is labeled with the teacher model that is trained by
sensitive user data. In this work, we propose a novel approach that combines
the advantages of FL and mimic learning, namely federated mimic learning to
create a distributed IDS while minimizing the risk of jeopardizing users'
privacy, and benchmark its performance compared to other ML-based IDS
techniques using NSL-KDD dataset. Our results show that we can achieve 98.11%
detection accuracy with federated mimic learning.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 06:09:11 GMT""}]","2020-12-15"
"2012.06975","Luke Barnes","Luke A. Barnes and Geraint F. Lewis","Under an Iron Sky: On the Entropy at the Start of the Universe","22 pages, 6 figures. Published in Publications of the Astronomical
  Society of Australia",,"10.1017/pasa.2021.54",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Curiously, our Universe was born in a low entropy state, with abundant free
energy to power stars and life. The form that this free energy takes is usually
thought to be gravitational: the Universe is almost perfectly smooth, and so
can produce sources of energy as matter collapses under gravity. It has
recently been argued that a more important source of low-entropy energy is
nuclear: the Universe expands too fast to remain in nuclear statistical
equilibrium (NSE), effectively shutting off nucleosynthesis in the first few
minutes, providing leftover hydrogen as fuel for stars. Here, we fill in the
astrophysical details of this scenario, and seek the conditions under which a
Universe will emerge from early nucleosynthesis as almost-purely iron. In so
doing, we identify a hitherto-overlooked character in the story of the origin
of the second law: matter-antimatter asymmetry.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 06:19:52 GMT""},{""version"":""v2"",""created"":""Sat, 27 Nov 2021 01:39:41 GMT""}]","2021-11-30"
"2012.06976","Genie Jhang","G. Jhang, J. Estee, J. Barney, G. Cerizza, M. Kaneko, J. W. Lee, W. G.
  Lynch, T. Isobe, M. Kurata-Nishimura, T. Murakami, C. Y .Tsang, M. B. Tsang,
  R. Wang, D. S. Ahn, L. Atar, T. Aumann, H. Baba, K. Boretzky, J. Brzychczyk,
  N. Chiga, N. Fukuda, I. Gasparic, B. Hong, A. Horvat, K. Ieki, N. Inabe, Y.
  J. Kim, T. Kobayashi, Y. Kondo, P. Lasko, H. S. Lee, Y. Leifels, J.
  {\L}ukasik, J. Manfredi, A. B. McIntosh, P. Morfouace, T. Nakamura, N.
  Nakatsuka, S. Nishimura, R. Olsen, H. Otsu, P. Paw{\l}owski, K. Pelczar, D.
  Rossi, H. Sakurai, C. Santamaria, H. Sato, H. Scheit, R. Shane, Y. Shimizu,
  H. Simon, A. Snoch, A. Sochocka, Z. Sosin, T. Sumikama, H. Suzuki, D. Suzuki,
  H. Takeda, S. Tangwancharoen, H. Toernqvist, Y. Togano, Z. G. Xiao, S. J.
  Yennello, J. Yurkon, Y. Zhang (the S{\pi}RIT Collaboration), Maria Colonna,
  Dan Cozma, Pawe{\l} Danielewicz, Hannah Elfner, Natsumi Ikeno, Che Ming Ko,
  Justin Mohs, Dmytro Oliinychenko, Akira Ono, Jun Su, Yong Jia Wang, Hermann
  Wolter, Jun Xu, Ying-Xun Zhang, Zhen Zhang (the TMEP collaboration)","Symmetry energy investigation with pion production from Sn+Sn systems","8 pages, 4 figures, 1 table (accepted for publication in PLB)","Physics Letters B 813 (2021) 136016","10.1016/j.physletb.2020.136016",,"nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past two decades, pions created in the high density regions of heavy
ion collisions have been predicted to be sensitive at high densities to the
symmetry energy term in the nuclear equation of state, a property that is key
to our understanding of neutron stars. In a new experiment designed to study
the symmetry energy, the multiplicities of negatively and positively charged
pions have been measured with high accuracy for central $^{132}$Sn+$^{124}$Sn,
$^{112}$Sn+$^{124}$Sn, and $^{108}$Sn+$^{112}$Sn collisions at
$E/A=270~\mathrm{MeV}$ with the S$\pi$RIT Time Projection Chamber. While the
uncertainties of individual pion multiplicities are measured to 4\%, those of
the charged pion multiplicity ratios are measured to 2\%. We compare these data
to predictions from seven major transport models. The calculations reproduce
qualitatively the dependence of the multiplicities and their ratios on the
total neutron to proton number in the colliding systems. However, the
predictions of the transport models from different codes differ too much to
allow extraction of reliable constraints on the symmetry energy from the data.
This finding may explain previous contradictory conclusions on symmetry energy
constraints obtained from pion data in Au+Au system. These new results call for
better understanding of the differences among transport codes, and new
observables that are more sensitive to the density dependence of the symmetry
energy.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 06:32:08 GMT""}]","2020-12-23"
"2012.06977","Wenhao Wu","Wenhao Wu, Dongliang He, Tianwei Lin, Fu Li, Chuang Gan, Errui Ding","MVFNet: Multi-View Fusion Network for Efficient Video Recognition","Accepted by AAAI2021",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventionally, spatiotemporal modeling network and its complexity are the
two most concentrated research topics in video action recognition. Existing
state-of-the-art methods have achieved excellent accuracy regardless of the
complexity meanwhile efficient spatiotemporal modeling solutions are slightly
inferior in performance. In this paper, we attempt to acquire both efficiency
and effectiveness simultaneously. First of all, besides traditionally treating
H x W x T video frames as space-time signal (viewing from the Height-Width
spatial plane), we propose to also model video from the other two Height-Time
and Width-Time planes, to capture the dynamics of video thoroughly. Secondly,
our model is designed based on 2D CNN backbones and model complexity is well
kept in mind by design. Specifically, we introduce a novel multi-view fusion
(MVF) module to exploit video dynamics using separable convolution for
efficiency. It is a plug-and-play module and can be inserted into off-the-shelf
2D CNNs to form a simple yet effective model called MVFNet. Moreover, MVFNet
can be thought of as a generalized video modeling framework and it can
specialize to be existing methods such as C2D, SlowOnly, and TSM under
different settings. Extensive experiments are conducted on popular benchmarks
(i.e., Something-Something V1 & V2, Kinetics, UCF-101, and HMDB-51) to show its
superiority. The proposed MVFNet can achieve state-of-the-art performance with
2D CNN's complexity.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 06:34:18 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 06:09:48 GMT""}]","2021-01-06"
"2012.06978","Hee-Kap Ahn","Taekang Eom and Seungjun Lee and Hee-Kap Ahn","Largest similar copies of convex polygons amidst polygonal obstacles",,,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a convex polygon $P$ with $k$ vertices and a polygonal domain $Q$
consisting of polygonal obstacles with total size $n$ in the plane, we study
the optimization problem of finding a largest similar copy of $P$ that can be
placed in $Q$ without intersecting the obstacles. We improve the time
complexity for solving the problem to $O(k^2n^2\lambda_4(k)\log{n})$. This is
progress of improving the previously best known results by Chew and Kedem
[SoCG89, CGTA93] and Sharir and Toledo [SoCG91, CGTA94] on the problem in more
than 25 years.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 06:40:03 GMT""}]","2020-12-15"
"2012.06979","Sivan Sabato","Shachar Schnapp and Sivan Sabato","Active Feature Selection for the Mutual Information Criterion","To appear in AAAI-21","Proceedings of the AAAI Conference on Artificial Intelligence
  (AAAI), 35(11), 9497-9504, 2021",,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  We study active feature selection, a novel feature selection setting in which
unlabeled data is available, but the budget for labels is limited, and the
examples to label can be actively selected by the algorithm. We focus on
feature selection using the classical mutual information criterion, which
selects the $k$ features with the largest mutual information with the label. In
the active feature selection setting, the goal is to use significantly fewer
labels than the data set size and still find $k$ features whose mutual
information with the label based on the \emph{entire} data set is large. We
explain and experimentally study the choices that we make in the algorithm, and
show that they lead to a successful algorithm, compared to other more naive
approaches. Our design draws on insights which relate the problem of active
feature selection to the study of pure-exploration multi-armed bandits
settings. While we focus here on mutual information, our general methodology
can be adapted to other feature-quality measures as well. The code is available
at the following url: https://github.com/ShacharSchnapp/ActiveFeatureSelection.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 06:40:35 GMT""}]","2021-12-30"
"2012.06980","Xiaojuan Qi","Xiaojuan Qi, Zhengzhe Liu, Renjie Liao, Philip H.S. Torr, Raquel
  Urtasun, Jiaya Jia","GeoNet++: Iterative Geometric Neural Network with Edge-Aware Refinement
  for Joint Depth and Surface Normal Estimation","TPAMI 2020. Code available: https://github.com/xjqi/GeoNet",,"10.1109/TPAMI.2020.3020800",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a geometric neural network with edge-aware
refinement (GeoNet++) to jointly predict both depth and surface normal maps
from a single image. Building on top of two-stream CNNs, GeoNet++ captures the
geometric relationships between depth and surface normals with the proposed
depth-to-normal and normal-to-depth modules. In particular, the
""depth-to-normal"" module exploits the least square solution of estimating
surface normals from depth to improve their quality, while the
""normal-to-depth"" module refines the depth map based on the constraints on
surface normals through kernel regression. Boundary information is exploited
via an edge-aware refinement module. GeoNet++ effectively predicts depth and
surface normals with strong 3D consistency and sharp boundaries resulting in
better reconstructed 3D scenes. Note that GeoNet++ is generic and can be used
in other depth/normal prediction frameworks to improve the quality of 3D
reconstruction and pixel-wise accuracy of depth and surface normals.
Furthermore, we propose a new 3D geometric metric (3DGM) for evaluating depth
prediction in 3D. In contrast to current metrics that focus on evaluating
pixel-wise error/accuracy, 3DGM measures whether the predicted depth can
reconstruct high-quality 3D surface normals. This is a more natural metric for
many 3D application domains. Our experiments on NYUD-V2 and KITTI datasets
verify that GeoNet++ produces fine boundary details, and the predicted depth
can be used to reconstruct high-quality 3D surfaces. Code has been made
publicly available.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 06:48:01 GMT""}]","2020-12-15"
"2012.06981","Stephen Macke","Stephen Macke, Hongpu Gong, Doris Jung-Lin Lee, Andrew Head, Doris
  Xin, Aditya Parameswaran","Fine-Grained Lineage for Safer Notebook Interactions",,,,,"cs.SE cs.DB cs.HC cs.PL","http://creativecommons.org/licenses/by/4.0/","  Computational notebooks have emerged as the platform of choice for data
science and analytical workflows, enabling rapid iteration and exploration. By
keeping intermediate program state in memory and segmenting units of execution
into so-called ""cells"", notebooks allow users to execute their workflows
interactively and enjoy particularly tight feedback. However, as cells are
added, removed, reordered, and rerun, this hidden intermediate state
accumulates in a way that is not necessarily correlated with the notebook's
visible code, making execution behavior difficult to reason about, and leading
to errors and lack of reproducibility. We present NBSafety, a custom Jupyter
kernel that uses runtime tracing and static analysis to automatically manage
lineage associated with cell execution and global notebook state. NBSafety
detects and prevents errors that users make during unaided notebook
interactions, all while preserving the flexibility of existing notebook
semantics. We evaluate NBSafety's ability to prevent erroneous interactions by
replaying and analyzing 666 real notebook sessions. Of these, NBSafety
identified 117 sessions with potential safety errors, and in the remaining 549
sessions, the cells that NBSafety identified as resolving safety issues were
more than $7\times$ more likely to be selected by users for re-execution
compared to a random baseline, even though the users were not using NBSafety
and were therefore not influenced by its suggestions.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 06:50:31 GMT""},{""version"":""v2"",""created"":""Sat, 19 Jun 2021 20:20:44 GMT""}]","2021-06-22"
"2012.06982","Tohid Khalili","Arash Moradzadeh, Kazem Pourhossein, Behnam Mohammadi-Ivatloo, Tohid
  Khalili, Ali Bidram","Radial Deformation Emplacement in Power Transformers Using Long
  Short-Term Memory Networks","5 pages, 10 figures, IEEE PES ISGT NA 2021",,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A power transformer winding is usually subject to mechanical stress and
tension because of improper transportation or operation. Radial deformation
(RD) is an example of mechanical stress that can impact power transformer
operation through short circuit faults and insulation damages. Frequency
response analysis (FRA) is a well-known method to diagnose mechanical defects
in transformers. Despite the precision of FRA, the interpretation of the
calculated frequency response curves is not straightforward and requires
complex calculations. In this paper, a deep learning algorithm called long
short-term memory (LSTM) is used as a feature extraction technique to locate RD
faults in their early stages. The experimental results verify the effectiveness
of the proposed method in the diagnosis and locating of RD defects.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 06:55:05 GMT""}]","2020-12-15"
"2012.06983","Yi Zhang","Yi Zhang, Hu Chen, Wenjun Xia, Yang Chen, Baodong Liu, Yan Liu,
  Huaiqiang Sun, and Jiliu Zhou","LEARN++: Recurrent Dual-Domain Reconstruction Network for Compressed
  Sensing CT","10 pages, 11 figures",,,,"physics.med-ph cs.CV","http://creativecommons.org/licenses/by/4.0/","  Compressed sensing (CS) computed tomography has been proven to be important
for several clinical applications, such as sparse-view computed tomography
(CT), digital tomosynthesis and interior tomography. Traditional compressed
sensing focuses on the design of handcrafted prior regularizers, which are
usually image-dependent and time-consuming. Inspired by recently proposed deep
learning-based CT reconstruction models, we extend the state-of-the-art LEARN
model to a dual-domain version, dubbed LEARN++. Different from existing
iteration unrolling methods, which only involve projection data in the data
consistency layer, the proposed LEARN++ model integrates two parallel and
interactive subnetworks to perform image restoration and sinogram inpainting
operations on both the image and projection domains simultaneously, which can
fully explore the latent relations between projection data and reconstructed
images. The experimental results demonstrate that the proposed LEARN++ model
achieves competitive qualitative and quantitative results compared to several
state-of-the-art methods in terms of both artifact reduction and detail
preservation.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:00:50 GMT""}]","2020-12-15"
"2012.06984","Peter Nekrasov","Peter Nekrasov, Jessica Freeze, and Victor Batista","Using Restricted Boltzmann Machines to Model Molecular Geometries","Preliminary manuscript, subject to change",,,,"physics.chem-ph cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Precise physical descriptions of molecules can be obtained by solving the
Schrodinger equation; however, these calculations are intractable and even
approximations can be cumbersome. Force fields, which estimate interatomic
potentials based on empirical data, are also time-consuming. This paper
proposes a new methodology for modeling a set of physical parameters by taking
advantage of the restricted Boltzmann machine's fast learning capacity and
representational power. By training the machine on ab initio data, we can
predict new data in the distribution of molecular configurations matching the
ab initio distribution. In this paper we introduce a new RBM based on the Tanh
activation function, and conduct a comparison of RBMs with different activation
functions, including sigmoid, Gaussian, and (Leaky) ReLU. Finally we
demonstrate the ability of Gaussian RBMs to model small molecules such as water
and ethane.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:02:32 GMT""}]","2020-12-15"
"2012.06985","Raviteja Vemulapalli","Xiangyun Zhao, Raviteja Vemulapalli, Philip Mansfield, Boqing Gong,
  Bradley Green, Lior Shapira, Ying Wu","Contrastive Learning for Label-Efficient Semantic Segmentation","International Conference on Computer Vision (ICCV), 2021",,,,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Collecting labeled data for the task of semantic segmentation is expensive
and time-consuming, as it requires dense pixel-level annotations. While recent
Convolutional Neural Network (CNN) based semantic segmentation approaches have
achieved impressive results by using large amounts of labeled training data,
their performance drops significantly as the amount of labeled data decreases.
This happens because deep CNNs trained with the de facto cross-entropy loss can
easily overfit to small amounts of labeled data. To address this issue, we
propose a simple and effective contrastive learning-based training strategy in
which we first pretrain the network using a pixel-wise, label-based contrastive
loss, and then fine-tune it using the cross-entropy loss. This approach
increases intra-class compactness and inter-class separability, thereby
resulting in a better pixel classifier. We demonstrate the effectiveness of the
proposed training strategy using the Cityscapes and PASCAL VOC 2012
segmentation datasets. Our results show that pretraining with the proposed
contrastive loss results in large performance gains (more than 20% absolute
improvement in some settings) when the amount of labeled data is limited. In
many settings, the proposed contrastive pretraining strategy, which does not
use any additional data, is able to match or outperform the widely-used
ImageNet pretraining strategy that uses more than a million additional labeled
images.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:05:39 GMT""},{""version"":""v2"",""created"":""Wed, 23 Dec 2020 05:00:28 GMT""},{""version"":""v3"",""created"":""Tue, 6 Apr 2021 00:33:07 GMT""},{""version"":""v4"",""created"":""Wed, 18 Aug 2021 19:48:24 GMT""}]","2021-08-20"
"2012.06986","Ilyas Haouam","Ilyas Haouam","Two-dimensional pauli equation in noncommutative phase-space","arXiv admin note: text overlap with arXiv:2006.00881","Ukrainian Journal of Physics, 2021","10.15407/ujpe66.9.771",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigated the Pauli equation in a two-dimensional
noncommutative phase-space by considering a constant magnetic field
perpendicular to the plane. We mapped the noncommutative problem to the
equivalent commutative one through a set of two-dimensional Bopp-shift
transformation. The energy spectrum and the wave function of the
two-dimensional noncommutative Pauli equation are found, where the problem in
question has been mapped to the Landau problem. Further, within the classical
limit, we have derived the noncommutative semi-classical partition function of
the two-dimensional Pauli system of one-particle and N-particle systems.
Consequently, we have studied its thermodynamic properties, i.e. the Helmholtz
free energy, mean energy, specific heat and entropy in noncommutative and
commutative phase-spaces. The impact of the phase-space noncommutativity on the
Pauli system is successfully examined.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:05:50 GMT""},{""version"":""v2"",""created"":""Sun, 7 Feb 2021 19:47:10 GMT""}]","2021-10-11"
"2012.06987","Sepanta Zeighami","Sepanta Zeighami, Cyrus Shahabi, John Krumm","Estimating Spread of Contact-Based Contagions in a Population Through
  Sub-Sampling",,"Proc. VLDB Endow. 14, 9, 1557-1569 (2021)","10.14778/3461535.3461544",,"cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Physical contacts result in the spread of various phenomena such as viruses,
gossips, ideas, packages and marketing pamphlets across a population. The
spread depends on how people move and co-locate with each other, or their
mobility patterns. How far such phenomena spread has significance for both
policy making and personal decision making, e.g., studying the spread of
COVID-19 under different intervention strategies such as wearing a mask. In
practice, mobility patterns of an entire population is never available, and we
usually have access to location data of a subset of individuals. In this paper,
we formalize and study the problem of estimating the spread of a phenomena in a
population, given that we only have access to sub-samples of location visits of
some individuals in the population. We show that simple solutions such as
estimating the spread in the sub-sample and scaling it to the population, or
more sophisticated solutions that rely on modeling location visits of
individuals do not perform well in practice, the former because it ignores
contacts between unobserved individuals and sampled ones and the latter because
it yields inaccurate modeling of co-locations. Instead, we directly model the
co-locations between the individuals. We introduce PollSpreader and
PollSusceptible, two novel approaches that model the co-locations between
individuals using a contact network, and infer the properties of the contact
network using the subsample to estimate the spread of the phenomena in the
entire population. We show that our estimates provide an upper bound and a
lower bound on the spread of the disease in expectation. Finally, using a large
high-resolution real-world mobility dataset, we experimentally show that our
estimates are accurate, while other methods that do not correctly account for
co-locations between individuals result in wrong observations (e.g, premature
herd-immunity).
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:13:24 GMT""}]","2021-12-20"
"2012.06988","Jinping Zhang Dr.","Jinping Zhang and Kouji Yano","Remarks on martingale representation theorem for set-valued martingales","9",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Martingale representation theorem for set-valued martingales was proposed by
M. Kisielewicz [J. Math. Anal. Appl. 2014]. We shall prove that the result
holds only for very special case: the set-valued martingale degenerates to the
point-valued one. A revised representation theorem for a special kind of
non-degenerate set-valued martingales is presented.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:18:52 GMT""}]","2020-12-15"
"2012.06989","Furqan Khan","Anees Al-Najjar, Furqan Hameed Khan, Marius Portmann","Network Traffic Control for Multi-homed End-hosts via SDN","13 pages, 26 Figures",,,,"cs.NI cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Software Defined Networking (SDN) is an emerging technology of efficiently
controlling and managing computer networks, such as in data centres, Wide Area
Networks (WANs), as well as in ubiquitous communication. In this paper, we
explore the idea of embedding the SDN components, represented by SDN controller
and virtual switch, in end-hosts to improve network performance. In particular,
we consider load balancing across multiple network interfaces on end-hosts with
different link capacity scenarios. We have explored and implemented different
SDN-based load balancing approaches based on OpenFlow software switches, and
have demonstrated the feasibility and the potential of this approach. The
proposed system has been evaluated with multipath transmission control protocol
(MPTCP). Our results demonstrated the potential of applying the SDN concepts on
multi-homed devices resulting in an increase in achieved throughput of 55\%
compared to the legacy single network approach and 10\% compared to the MPTCP.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:25:37 GMT""}]","2020-12-15"
"2012.06990","Jean Honorio","Siya Goel and Clark Gedney and Jean Honorio","A Novel Tool for the Accurate and Affordable Early Diagnosis of
  Pancreatic Cancer via Machine Learning and Bioinformatics",,,,,"q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pancreatic cancer (PC) is the fourth leading cause of cancer death in the
United States due to its five-year survival rate of 10%. Late diagnosis,
affiliated with the asymptomatic nature in early stages and the location of the
cancer with respect to the pancreas, makes current widely-accepted screening
methods unavailable. Prior studies have achieved low (70-75%) diagnostic
accuracy, possibly because 80% of PC cases are associated with diabetes,
leading to misdiagnosis. To address the problems of frequent late diagnosis and
misdiagnosis, we developed an accessible, accurate and affordable diagnostic
tool for PC, by analyzing the expression of nineteen genes in PC and diabetes.
First, machine learning algorithms were trained on four groups of subjects,
depending on the occurrence of PC and Diabetes. The models were analyzed with
400 PC subjects at varying stages to ensure validity. Naive Bayes, Neural
Network and K-Nearest Neighbors models achieved the highest testing accuracy of
around 92.6%. Second, the biological implication of the nineteen genes was
investigated using bioinformatics tools. It was found that these genes were
significantly involved in regulating the cytoplasm, cytoskeleton and nuclear
receptor activity in the pancreas, specifically in acinar and ductal cells. Our
novel tool is the first in the literature that achieves a PC diagnostic
accuracy of above 90%, having the potential to significantly improve the
detection of PC in the background of diabetes and increase the five-year
survival rate.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:25:50 GMT""}]","2020-12-15"
"2012.06991","Maitrayee Saha","Maitrayee Saha and Samudra Roy and Shailendra K. Varshney","Intra-cavity field dynamics near avoided mode crossing in concentric
  silicon nitride ring resonator",,"Phys. Rev. A 104, 033514 (2021)","10.1103/PhysRevA.104.033514",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Understanding the intra-cavity field dynamics in passive microresonator
systems has already been intriguing. It becomes fascinating when the system is
complex, such as a concentric dual microring resonator that exhibit avoided
mode crossing (AMC). In this work, we present a systematic study of
intra-cavity oscillatory field dynamics near AMC in a concentric silicon
nitride microring resonator with the help of the coupled Lugiato-Lefever
equation (LLE). We identify two regions viz. weakly coupled region (WCR) and
strongly coupled region (SCR) based on eigenfrequency separation of the
two-hybrid modes, which originate from mode coupling near AMC. In WCR, the mode
coupling effect is dominant, leading to intra-cavity power oscillation between
these two modes in a periodic manner and non-identical variation of their
phases. In SCR, the mode coupling effect reduces gradually with nearly
identical characteristics of both the modes. We further verify our numerical
findings with the semi-analytical variational method, leading to an in-depth
understanding of the mode coupling induced dynamics. We finally analyze the
polarization evolving state, and the polarization locked state with the help of
Stokes parameters and Jones vectors in WCR and SCR, respectively.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:26:17 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 14:27:59 GMT""}]","2021-09-22"
"2012.06992","Bo Yang","Bo Yang, Xuelin Cao, Kai Xiong, Chau Yuen, Yong Liang Guan, Supeng
  Leng, Lijun Qian, and Zhu Han","Edge Intelligence for Autonomous Driving in 6G Wireless System: Design
  Challenges and Solutions",,,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  In a level-5 autonomous driving system, the autonomous driving vehicles (AVs)
are expected to sense the surroundings via analyzing a large amount of data
captured by a variety of onboard sensors in near-real-time. As a result,
enormous computing costs will be introduced to the AVs for processing the tasks
with the deployed machine learning (ML) model, while the inference accuracy may
not be guaranteed. In this context, the advent of edge intelligence (EI) and
sixth-generation (6G) wireless networking are expected to pave the way to more
reliable and safer autonomous driving by providing multi-access edge computing
(MEC) together with ML to AVs in close proximity. To realize this goal, we
propose a two-tier EI-empowered autonomous driving framework. In the
autonomous-vehicles tier, the autonomous vehicles are deployed with the shallow
layers by splitting the trained deep neural network model. In the
edge-intelligence tier, an edge server is implemented with the remaining layers
(also deep layers) and an appropriately trained multi-task learning (MTL)
model. In particular, obtaining the optimal offloading strategy (including the
binary offloading decision and the computational resources allocation) can be
formulated as a mixed-integer nonlinear programming (MINLP) problem, which is
solved via MTL in near-real-time with high accuracy. On another note, an
edge-vehicle joint inference is proposed through neural network segmentation to
achieve efficient online inference with data privacy-preserving and less
communication delay. Experiments demonstrate the effectiveness of the proposed
framework, and open research topics are finally listed.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:28:18 GMT""}]","2020-12-15"
"2012.06993","Xinying Ma","Xinying Ma, Zhi Chen, Longfei Yan, Chong Han, and Qiye Wen","Joint Hardware Design and Capacity Analysis for Intelligent Reflecting
  Surface Enabled Terahertz MIMO Communications",,,,,"cs.IT cs.ET eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  Terahertz (THz) communications have been envisioned as a promising enabler to
provide ultra-high data transmission for sixth generation (6G) wireless
networks. To tackle the blockage vulnerability brought by severe path
attenuation and poor diffraction of THz waves, an intelligent reflecting
surface (IRS) is put forward to smartly control the incident THz waves by
adjusting the phase shifts. In this paper, we firstly design an efficient
hardware structure of graphene-based IRS with phase response up to 306.82
degrees. Subsequently, to characterize the capacity of the IRS-enabled THz
multiple-input multiple-output (MIMO) system, an adaptive gradient descent
(A-GD) algorithm is developed by dynamically updating the step size during the
iterative process, which is determined by the second-order Taylor expansion
formulation. In contrast with conventional gradient descent (C-GD) algorithm
with fixed step size, the A-GD algorithm evidently improves the achievable rate
performance. However, both A-GD algorithm and C-GD algorithm inherit the
unacceptable complexity. Then a low complexity alternating optimization (AO)
algorithm is proposed by alternately optimizing the precoding matrix by a
column-by-column (CBC) algorithm and the phase shift matrix of the IRS by a
linear search algorithm. Ultimately, the numerical results demonstrate the
effectiveness of the designed hardware structure and the considered algorithms.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:28:55 GMT""},{""version"":""v2"",""created"":""Tue, 12 Oct 2021 21:28:23 GMT""}]","2021-10-14"
"2012.06994","David Wu","David H. Wu and Victor V. Albert","Approximating the two-mode two-photon Rabi model","7 pages, 2 figures; Accepted by Physics Letters A",,"10.1016/j.physleta.2021.127779",,"quant-ph cond-mat.mes-hall physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Rabi model describes the simplest nontrivial interaction between a
few-level system and a bosonic mode, featuring in multiple seemingly unrelated
systems of importance to quantum science and technology. While exact
expressions for the energies of this model and its few-mode extensions have
been obtained, they involve roots of transcendental functions and are thus
cumbersome and unintuitive. Utilizing the symmetric generalized rotating wave
approximation (S-GRWA), we develop a family of approximations to the energies
of the two-mode two-photon Rabi model. The simplest elements of the family are
analytically tractable, providing good approximations in regimes of interest
such as ultra- and deep-strong coupling. Higher-order approximate energies can
be used if more accuracy is required.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:44:57 GMT""},{""version"":""v2"",""created"":""Tue, 2 Nov 2021 15:19:10 GMT""}]","2021-11-03"
"2012.06995","Fangrui Lv","Shuang Li, Fangrui Lv, Binhui Xie, Chi Harold Liu, Jian Liang, Chen
  Qin","Bi-Classifier Determinacy Maximization for Unsupervised Domain
  Adaptation","Accepted as AAAI 2021. The code is publicly available at
  https://github.com/BIT-DA/BCDM",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised domain adaptation challenges the problem of transferring
knowledge from a well-labelled source domain to an unlabelled target domain.
Recently,adversarial learning with bi-classifier has been proven effective in
pushing cross-domain distributions close. Prior approaches typically leverage
the disagreement between bi-classifier to learn transferable representations,
however, they often neglect the classifier determinacy in the target domain,
which could result in a lack of feature discriminability. In this paper, we
present a simple yet effective method, namely Bi-Classifier Determinacy
Maximization(BCDM), to tackle this problem. Motivated by the observation that
target samples cannot always be separated distinctly by the decision boundary,
here in the proposed BCDM, we design a novel classifier determinacy disparity
(CDD) metric, which formulates classifier discrepancy as the class relevance of
distinct target predictions and implicitly introduces constraint on the target
feature discriminability. To this end, the BCDM can generate discriminative
representations by encouraging target predictive outputs to be consistent and
determined, meanwhile, preserve the diversity of predictions in an adversarial
manner. Furthermore, the properties of CDD as well as the theoretical
guarantees of BCDM's generalization bound are both elaborated. Extensive
experiments show that BCDM compares favorably against the existing
state-of-the-art domain adaptation methods.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:55:39 GMT""}]","2020-12-15"
"2012.06996","Hendrik Bentmann","M. \""Unzelmann, H. Bentmann, T. Figgemeier, P. Eck, J. N. Neu, B.
  Geldiyev, F. Diekmann, S. Rohlf, J. Buck, M. Hoesch, M. Kall\""ane, K.
  Rossnagel, R. Thomale, T. Siegrist, G. Sangiovanni, D. Di Sante, F. Reinert","Momentum-space signatures of Berry flux monopoles in a Weyl semimetal",,,"10.1038/s41467-021-23727-3",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since the early days of Dirac flux quantization, magnetic monopoles have been
sought after as a potential corollary of quantized electric charge. As opposed
to magnetic monopoles embedded into the theory of electromagnetism, Weyl
crystals exhibit Berry flux monopoles in reciprocal parameter space. As a
function of crystal momentum, such monopoles locate at the degeneracy point of
the Weyl cone. Here, we report momentum-resolved spectroscopic signatures of
Berry flux monopoles in TaAs as a paradigmatic Weyl semimetal. We have probed
the orbital and spin angular momentum (OAM and SAM) of the Weyl-fermion states
by angle-resolved photoemission spectroscopy at bulk-sensitive soft X-ray
energies (SX-ARPES) combined with photoelectron spin detection and circular
dichroism. Supported by first-principles calculations, our measurements image
characteristics of a topologically non-trivial winding of the OAM at the Weyl
nodes and unveil a chirality-dependent SAM of the Weyl bands. Our results
experimentally visualize the non-trivial momentum-space topology in a Weyl
semimetal, promising to have profound implications for the study of
quantum-geometric effects in solids.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:02:32 GMT""},{""version"":""v2"",""created"":""Tue, 21 Mar 2023 10:30:37 GMT""}]","2023-03-22"
"2012.06997","Panyue Zhou","Yu Liu, Panyue Zhou","Hereditary cotorsion pairs on extriangulated subcategories","18 pages",,,,"math.RT math.CT","http://creativecommons.org/licenses/by/4.0/","  Let $\mathcal B$ be an extriangulated category with enough projectives and
enough injectives. We define a proper $m$-term subcategory $\mathcal G$ on
$\mathcal B$, which is an extriangulated subcategory. Then we give a
correspondence between cotorsion pairs on $\mathcal G$, support $\tau$-tilting
subcategories on an abelian quotient of $\mathcal G$ when $m=2$. If such
$\mathcal G$ is induced by a hereditary cotorsion pair, then we give a
correspondence between cotorsion pairs on $\mathcal G$ and intermediate
cotorsion pairs on $\mathcal B$ under certain assumptions. At last, we study an
important property of such extriangulated subcategory $\mathcal G$.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:05:43 GMT""}]","2020-12-15"
"2012.06998","Mickael Matusinski","Olivier Le Gal, Micka\""el Matusinski, Fernando Sanz S\'anchez","Solutions of definable ODEs with regular separation and dichotomy
  interlacement versus Hardy","25 pages","Rev. Mat. Iberoam. Electronically published on December 23, 2021","10.4171/RMI/1311",,"math.DS math.CA math.DG math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a notion of regular separation for solutions of systems of ODEs
$y'=F(x,y)$, where F is definable in a polynomially bounded o-minimal structure
and $y = (y_1,y_2)$. Given a pair of solutions with flat contact, we prove
that, if one of them has the property of regular separation, the pair is either
interlaced or generates a Hardy field. We adapt this result to trajectories of
three-dimensional vector fields with definable coefficients. In the particular
case of real analytic vector fields, it improves the dichotomy
interlaced/separated of certain integral pencils obtained by F. Cano, R. Moussu
and the third author. In this context, we show that the set of trajectories
with the regular separation property and asymptotic to a formal invariant curve
is never empty and it is represented by a subanalytic set of minimal dimension
containing the curve. Finally, we show how to construct examples of formal
invariant curves which are transcendental with respect to subanalytic sets,
using the so-called (SAT) property introduced by J.-P. Rolin, R. Shaefke and
the third author.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:19:35 GMT""},{""version"":""v2"",""created"":""Sat, 29 Jan 2022 15:13:37 GMT""}]","2022-02-01"
"2012.06999","Pavel Levashov","Vladimir Filinov, Pavel Levashov and Alexander Larkin","Thermodynamic properties of the finite-temperature electron gas by the
  fermionic path integral Monte Carlo method","8 pages, 2 figures",,"10.1063/5.0051775",,"physics.plasm-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The new {\em ab initio} quantum path integral Monte Carlo approach has been
developed and applied for the entropy difference calculations for the strongly
coupled degenerated uniform electron gas (UEG), a well--known model of simple
metals. Calculations have been carried out at finite temperature in canonical
ensemble over the wide density and temperature ranges. Obtained data may be
crucial for density functional theory. Improvements of the developed approach
include the Coulomb and exchange interaction of fermions in the basic Monte
Carlo cell and its periodic images and the proper change of variables in the
path integral measure. The developed approach shows good agreement with
available results for fermions even at temperature four times less than the
Fermi energy and practically doesn't suffer from the ""fermionic sign problem"",
which takes place in standard path integral Monte Carlo simulations of
degenerate fermionic systems. Presented results include pair distribution
functions, isochors and isotherms of pressure, internal energy and entropy
change in strongly coupled and degenerate UEG in a wide range of density and
temperature.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:22:02 GMT""}]","2021-07-28"
"2012.07000","Siyi Ma","Dandan Song, Siyi Ma, Zhanchen Sun, Sicheng Yang, Lejian Liao","KVL-BERT: Knowledge Enhanced Visual-and-Linguistic BERT for Visual
  Commonsense Reasoning",,,,,"cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reasoning is a critical ability towards complete visual understanding. To
develop machine with cognition-level visual understanding and reasoning
abilities, the visual commonsense reasoning (VCR) task has been introduced. In
VCR, given a challenging question about an image, a machine must answer
correctly and then provide a rationale justifying its answer. The methods
adopting the powerful BERT model as the backbone for learning joint
representation of image content and natural language have shown promising
improvements on VCR. However, none of the existing methods have utilized
commonsense knowledge in visual commonsense reasoning, which we believe will be
greatly helpful in this task. With the support of commonsense knowledge,
complex questions even if the required information is not depicted in the image
can be answered with cognitive reasoning. Therefore, we incorporate commonsense
knowledge into the cross-modal BERT, and propose a novel Knowledge Enhanced
Visual-and-Linguistic BERT (KVL-BERT for short) model. Besides taking visual
and linguistic contents as input, external commonsense knowledge extracted from
ConceptNet is integrated into the multi-layer Transformer. In order to reserve
the structural information and semantic representation of the original
sentence, we propose using relative position embedding and mask-self-attention
to weaken the effect between the injected commonsense knowledge and other
unrelated components in the input sequence. Compared to other task-specific
models and general task-agnostic pre-training models, our KVL-BERT outperforms
them by a large margin.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:22:33 GMT""}]","2020-12-15"
"2012.07001","Gao Xianlong","Xianqi Tong, Yeming Meng, Xunda Jiang, Chaohong Lee, Gentil Dias de
  Moraes Neto, Gao Xianlong","Dynamics of a quantum phase transition in the Aubry-Andr\'{e}-Harper
  model with $p$-wave superconductivity","9 pages, 7 figures","Phys. Rev. B 103, 104202 (2021)","10.1103/PhysRevB.103.104202",,"cond-mat.dis-nn cond-mat.str-el quant-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate the nonequilibrium dynamics of the one-dimension
Aubry-Andr\'{e}-Harper model with $p$-wave superconductivity by changing the
potential strength with slow and sudden quench. Firstly, we study the slow
quench dynamics from localized phase to critical phase by linearly decreasing
the potential strength $V$. The localization length is finite and its scaling
obeys the Kibble-Zurek mechanism. The results show that the second-order phase
transition line shares the same critical exponent $z\nu$, giving the
correlation length $\nu=0.997$ and dynamical exponent $z=1.373$, which are
different from the Aubry-Andr\'{e} model. Secondly, we also study the sudden
quench dynamics between three different phases: localized phase, critical
phase, and extended phase. In the limit of $V=0$ and $V=\infty$, we
analytically study the sudden quench dynamics via the Loschmidt echo. The
results suggest that, if the initial state and the post-quench Hamiltonian are
in different phases, the Loschmidt echo vanishes at some time intervals.
Furthermore, we found that, if the initial value is in the critical phase, the
direction of the quench is the same as one of the two limits mentioned before,
and similar behaviors will occur.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:25:15 GMT""}]","2021-03-17"
"2012.07002","Jihua Zhu","Yanlin Ma, Jihua Zhu, Zhongyu Li, Zhiqiang Tian, Yaochen Li","Effective multi-view registration of point sets based on student's t
  mixture model","11pages, 6 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Recently, Expectation-maximization (EM) algorithm has been introduced as an
effective means to solve multi-view registration problem. Most of the previous
methods assume that each data point is drawn from the Gaussian Mixture Model
(GMM), which is difficult to deal with the noise with heavy-tail or outliers.
Accordingly, this paper proposed an effective registration method based on
Student's t Mixture Model (StMM). More specially, we assume that each data
point is drawn from one unique StMM, where its nearest neighbors (NNs) in other
point sets are regarded as the t-distribution centroids with equal covariances,
membership probabilities, and fixed degrees of freedom. Based on this
assumption, the multi-view registration problem is formulated into the
maximization of the likelihood function including all rigid transformations.
Subsequently, the EM algorithm is utilized to optimize rigid transformations as
well as the only t-distribution covariance for multi-view registration. Since
only a few model parameters require to be optimized, the proposed method is
more likely to obtain the desired registration results. Besides, all
t-distribution centroids can be obtained by the NN search method, it is very
efficient to achieve multi-view registration. What's more, the t-distribution
takes the noise with heavy-tail into consideration, which makes the proposed
method be inherently robust to noises and outliers. Experimental results tested
on benchmark data sets illustrate its superior performance on robustness and
accuracy over state-of-the-art methods.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:27:29 GMT""}]","2020-12-15"
"2012.07003","Z. H. Wang","Hongwei Yu, Zhihai Wang and Jin-Hui Wu","Entanglement preparation and non-reciprocal excitation evolution in
  giant atoms by controllable dissipation and coupling","9 Pages, 4 Figures, Accepted by Phys. Rev. A",,"10.1103/PhysRevA.104.013720",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate the dynamics of giant atom(s) in a waveguide QED scenario,
where the atom couples to the coupled resonator waveguide via two sites. For a
single giant atom setup, we find that the atomic dissipation rate can be
adjusted by tuning its size. For the two giant atoms system, the waveguide will
induce the controllable individual and collective dissipation as well as
effective inter-atom coupling. As a result, we can theoretically realize the
robust entangled state preparation and non-reciprocal excitation evolution. We
hope our study can be applied in quantum information processing based on
photonic and acoustic waveguide setup.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:33:11 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 06:17:19 GMT""}]","2021-08-04"
"2012.07004","Yutai Hou","Yutai Hou, Sanyuan Chen, Wanxiang Che, Cheng Chen, Ting Liu","C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot
  Filling","Accepted by AAAI-2021",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Slot filling, a fundamental module of spoken language understanding, often
suffers from insufficient quantity and diversity of training data. To remedy
this, we propose a novel Cluster-to-Cluster generation framework for Data
Augmentation (DA), named C2C-GenDA. It enlarges the training set by
reconstructing existing utterances into alternative expressions while keeping
semantic. Different from previous DA works that reconstruct utterances one by
one independently, C2C-GenDA jointly encodes multiple existing utterances of
the same semantics and simultaneously decodes multiple unseen expressions.
Jointly generating multiple new utterances allows to consider the relations
between generated instances and encourages diversity. Besides, encoding
multiple existing utterances endows C2C with a wider view of existing
expressions, helping to reduce generation that duplicates existing data.
Experiments on ATIS and Snips datasets show that instances augmented by
C2C-GenDA improve slot filling by 7.99 (11.9%) and 5.76 (13.6%) F-scores
respectively, when there are only hundreds of training utterances.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:35:37 GMT""}]","2020-12-15"
"2012.07005","Ali Nassif","Mohammad Azzeh, Ali Bou Nassif, Imtinan Attili","Predicting Software Effort from Use Case Points: A Systematic Review","accepted at Science of Computer Programming Journal",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context: Predicting software project effort from Use Case Points (UCP) method
is increasingly used among researchers and practitioners. However, unlike other
effort estimation domains, this area of interest has not been systematically
reviewed. Aims: There is a need for a systemic literature review to provide
directions and supports for this research area of effort estimation.
Specifically, the objective of this study is twofold: to classify UCP effort
estimation papers based on four criteria: contribution type, research approach,
dataset type and techniques used with UCP; and to analyze these papers from
different views: estimation accuracy, favorable estimation context and impact
of combined techniques on the accuracy of UCP. Method: We used the systematic
literature review methodology proposed by Kitchenham and Charters. This
includes searching for the most relevant papers, selecting quality papers,
extracting data and drawing results. Result: The authors of UCP research paper,
are generally not aware of previous published results and conclusions in the
field of UCP effort estimation. There is a lack of UCP related publications in
the top software engineering journals. This makes a conclusion that such papers
are not useful for the community. Furthermore, most articles used small numbers
of projects which cannot support generalizing the conclusion in most cases.
Conclusions: There are multiple research directions for UCP method that have
not been examined so far such as validating the algebraic construction of UCP
based on industrial data. Also, there is a need for standard automated tools
that govern the process of translating use case diagram into its corresponding
UCP metrics. Although there is an increase interest among researchers to
collect industrial data and build effort prediction models based on machine
learning methods, the quality of data is still subject to debate
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:39:37 GMT""}]","2020-12-15"
"2012.07006","Yi Zeng","Han Qiu, Yi Zeng, Shangwei Guo, Tianwei Zhang, Meikang Qiu, Bhavani
  Thuraisingham","DeepSweep: An Evaluation Framework for Mitigating DNN Backdoor Attacks
  using Data Augmentation",,,,,"cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Public resources and services (e.g., datasets, training platforms,
pre-trained models) have been widely adopted to ease the development of Deep
Learning-based applications. However, if the third-party providers are
untrusted, they can inject poisoned samples into the datasets or embed
backdoors in those models. Such an integrity breach can cause severe
consequences, especially in safety- and security-critical applications. Various
backdoor attack techniques have been proposed for higher effectiveness and
stealthiness. Unfortunately, existing defense solutions are not practical to
thwart those attacks in a comprehensive way.
  In this paper, we investigate the effectiveness of data augmentation
techniques in mitigating backdoor attacks and enhancing DL models' robustness.
An evaluation framework is introduced to achieve this goal. Specifically, we
consider a unified defense solution, which (1) adopts a data augmentation
policy to fine-tune the infected model and eliminate the effects of the
embedded backdoor; (2) uses another augmentation policy to preprocess input
samples and invalidate the triggers during inference. We propose a systematic
approach to discover the optimal policies for defending against different
backdoor attacks by comprehensively evaluating 71 state-of-the-art data
augmentation functions. Extensive experiments show that our identified policy
can effectively mitigate eight different kinds of backdoor attacks and
outperform five existing defense methods. We envision this framework can be a
good benchmark tool to advance future DNN backdoor studies.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:51:37 GMT""},{""version"":""v2"",""created"":""Sun, 11 Apr 2021 17:09:10 GMT""}]","2021-04-13"
"2012.07007","Xiaodong Cun","Xiaodong Cun and Chi-Man Pun","Split then Refine: Stacked Attention-guided ResUNets for Blind Single
  Image Visible Watermark Removal","AAAI21",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Digital watermark is a commonly used technique to protect the copyright of
medias. Simultaneously, to increase the robustness of watermark, attacking
technique, such as watermark removal, also gets the attention from the
community. Previous watermark removal methods require to gain the watermark
location from users or train a multi-task network to recover the background
indiscriminately. However, when jointly learning, the network performs better
on watermark detection than recovering the texture. Inspired by this
observation and to erase the visible watermarks blindly, we propose a novel
two-stage framework with a stacked attention-guided ResUNets to simulate the
process of detection, removal and refinement. In the first stage, we design a
multi-task network called SplitNet. It learns the basis features for three
sub-tasks altogether while the task-specific features separately use multiple
channel attentions. Then, with the predicted mask and coarser restored image,
we design RefineNet to smooth the watermarked region with a mask-guided spatial
attention. Besides network structure, the proposed algorithm also combines
multiple perceptual losses for better quality both visually and numerically. We
extensively evaluate our algorithm over four different datasets under various
settings and the experiments show that our approach outperforms other
state-of-the-art methods by a large margin. The code is available at
http://github.com/vinthony/deep-blind-watermark-removal.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:05:37 GMT""}]","2020-12-15"
"2012.07008","Xuejian Wang","Xuejian Wang","Product Differentiation and Geographical Expansion of Exports Network at
  Industry level","34 pages, 3 figures",,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Industries can enter one country first, and then enter its neighbors'
markets. Firms in the industry can expand trade network through the export
behavior of other firms in the industry. If a firm is dependent on a few
foreign markets, the political risks of the markets will hurt the firm. The
frequent trade disputes reflect the importance of the choice of export
destinations. Although the market diversification strategy was proposed before,
most firms still focus on a few markets, and the paper shows reasons.In this
paper, we assume the entry cost of firms is not all sunk cost, and show 2 ways
that product heterogeneity impacts extensive margin of exports theoretically
and empirically. Firstly, the increase in product heterogeneity promotes the
increase in market power and profit, and more firms are able to pay the entry
cost. If more firms enter the market, the information of the market will be
known by other firms in the industry. Firms can adjust their behavior according
to other firms, so the information changes entry cost and is not sunk cost
completely. The information makes firms more likely to entry the market, and
enter the surrounding markets of existing markets of other firms in the
industry. When firms choose new markets, they tend to enter the markets with
few competitors first.Meanwhile, product heterogeneity will directly affect the
firms' network expansion, and the reduction of product heterogeneity will
increase the value of peer information. This makes firms more likely to entry
the market, and firms in the industry concentrate on the markets.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:14:46 GMT""}]","2020-12-15"
"2012.07009","Zhigang Li","Yanqi Liu, Zhigang Li, Wei Wei, Jiehui Zheng, and Hongcai Zhang","Data-Driven Dispatchable Regions with Potentially Active Boundaries for
  Renewable Power Generation: Concept and Construction",,"in IEEE Transactions on Sustainable Energy, vol. 13, no. 2, pp.
  882-891, April 2022","10.1109/TSTE.2021.3138125",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dispatchable region of volatile renewable power generation (RPG)
quantifies how much uncertainty the power system can handle at a given
operating point. State-of-the-art dispatchable region (DR) research has studied
how system operational constraints influence the DR but has seldom considered
the effect of the uncertainty features of RPG outputs. The traditional DR is
generally described by a large number of boundaries, and it is computationally
intensive to construct. To bridge these gaps, a novel type of DR is defined,
which is enclosed by potentially active boundaries (PABs) that consider the
operational constraints and uncertainty features of RPG outputs. The proposed
DR is easier to construct because the PABs are only a small part of the
traditional DR boundaries. The procedure for constructing the proposed DR is
described in terms of the progressive search for PABs, which is formulated as a
mixed-integer linear program by incorporating the discrete observed data points
of RPG outputs as an approximate distribution. A parallel solution paradigm is
also developed to expedite the construction procedure when using a large
observed dataset. Simulation tests on the IEEE 30-bus and 118-bus systems
verify the effectiveness and scalability of the proposed DR and the efficiency
of the proposed algorithm.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:18:14 GMT""},{""version"":""v2"",""created"":""Sun, 24 Apr 2022 02:16:36 GMT""}]","2022-04-26"
"2012.07010","Wojciech Grochala","Kacper Koteras, Jakub Gawraczynski, Mariana Derzsi, Zoran Mazej and
  Wojciech Grochala","Lattice dynamics of KAgF3 perovskite, unique 1D antiferromagnet","10 pages, 7 figures, 2 tables, and electronic supplement inclusing 1
  figure and 1 table",,"10.3390/chemistry3010007",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Theoretical DFT calculations using GGA+U and HSE06 frameworks enabled
vibrational mode assignment and partial (atomic) phonon DOS determination in
KAgF3 perovskite, a low-dimensional magnetic fluoroargentate(II). Twelve bands
in the spectra of KAgF3 were assigned to either IR active or Raman active
modes, reaching very good correlation with experimental values (R2>0.997).
Low-temperature Raman measurements indicate that the intriguing
spin-Peierls-like phase transition at 230 K is an order-disorder transition and
it does not strongly impact the vibrational structure of the material.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:19:27 GMT""}]","2021-01-20"
"2012.07011","Ziyue Qiao","Ziyue Qiao, Zhiyuan Ning, Yi Du, Yuanchun Zhou","Context-Enhanced Entity and Relation Embedding for Knowledge Graph
  Completion","2 pages, accepted by AAAI-21 student abstract and poster program",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most researches for knowledge graph completion learn representations of
entities and relations to predict missing links in incomplete knowledge graphs.
However, these methods fail to take full advantage of both the contextual
information of entity and relation. Here, we extract contexts of entities and
relations from the triplets which they compose. We propose a model named AggrE,
which conducts efficient aggregations respectively on entity context and
relation context in multi-hops, and learns context-enhanced entity and relation
embeddings for knowledge graph completion. The experiment results show that
AggrE is competitive to existing models.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:20:42 GMT""}]","2020-12-15"
"2012.07012","Timur Gureyev","T.E. Gureyev, H.M. Quiney, A. Kozlov, D.M. Paganin, G. Schmalz and
  L.J. Allen","Relative roles of multiple scattering and Fresnel diffraction in the
  imaging of small molecules using electrons, Part II: Differential Holographic
  Tomography","32 pages, 8 figures, version 5c (a few typos have been found in the
  previous version and fixed in the current version)","Ultramicroscopy Volume 230, 113311 (2021)","10.1016/j.ultramic.2021.113311",,"physics.optics cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been argued that in atomic-resolution transmission electron microscopy
(TEM) of sparse weakly scattering structures, such as small biological
molecules, multiple electron scattering usually has only a small effect, while
the in-molecule Fresnel diffraction can be significant due to the intrinsically
shallow depth of focus. These facts suggest that the three-dimensional
reconstruction of such structures from defocus image series collected at
multiple rotational orientations of a molecule can be effectively performed for
each atom separately, using the incoherent first Born approximation. The
corresponding reconstruction method, termed here Differential Holographic
Tomography, is developed theoretically and demonstrated computationally on
several numerical models of biological molecules. It is shown that the method
is capable of accurate reconstruction of the locations of atoms in a molecule
from TEM data collected at a small number of random orientations of the
molecule, with one or more defocus images per orientation. Possible
applications to cryogenic electron microscopy and other areas are briefly
discussed.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:27:55 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 03:55:09 GMT""}]","2021-11-16"
"2012.07013","Sriram Nagaraj","Sriram Nagaraj","Optimization and Learning With Nonlocal Calculus",,,,,"math.OC cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonlocal models have recently had a major impact in nonlinear continuum
mechanics and are used to describe physical systems/processes which cannot be
accurately described by classical, calculus based ""local"" approaches. In part,
this is due to their multiscale nature that enables aggregation of micro-level
behavior to obtain a macro-level description of singular/irregular phenomena
such as peridynamics, crack propagation, anomalous diffusion and transport
phenomena. At the core of these models are nonlocal differential operators,
including nonlocal analogs of the gradient/Hessian. This paper initiates the
use of such nonlocal operators in the context of optimization and learning. We
define and analyze the convergence properties of nonlocal analogs of
(stochastic) gradient descent and Newton's method on Euclidean spaces. Our
results indicate that as the nonlocal interactions become less noticeable, the
optima corresponding to nonlocal optimization converge to the ""usual"" optima.
At the same time, we argue that nonlocal learning is possible in situations
where standard calculus fails. As a stylized numerical example of this, we
consider the problem of non-differentiable parameter estimation on a non-smooth
translation manifold and show that our nonlocal gradient descent recovers the
unknown translation parameter from a non-differentiable objective function.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:27:56 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 00:40:35 GMT""}]","2021-03-10"
"2012.07014","Hailing Liu","Hailing Liu, Yusen Wu, Linchun Wan, Shijie Pan, Sujuan Qin, Fei Gao,
  and Qiaoyan Wen","Variational Quantum algorithm for Poisson equation",,"Phys. Rev. A 104, 022418 (2021)","10.1103/PhysRevA.104.022418",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Poisson equation has wide applications in many areas of science and
engineering. Although there are some quantum algorithms that can efficiently
solve the Poisson equation, they generally require a fault-tolerant quantum
computer which is beyond the current technology. In this paper, we propose a
Variational Quantum Algorithm (VQA) to solve the Poisson equation, which can be
executed on Noise Intermediate-Scale Quantum (NISQ) devices. In detail, we
first adopt the finite difference method to transform the Poisson equation into
a linear system. Then, according to the special structure of the linear system,
we find an explicit tensor product decomposition, with only $2\log n+1$ items,
of its coefficient matrix under a specific set of simple operators, where $n$
is the dimension of the coefficient matrix. This implies that the proposed VQA
only needs $O(\log n)$ measurements, which dramatically reduce quantum
resources. Additionally, we perform quantum Bell measurements to efficiently
evaluate the expectation values of simple operators. Numerical experiments
demonstrate that our algorithm can effectively solve the Poisson equation.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:28:04 GMT""}]","2021-08-25"
"2012.07015","Fuhai Zhu","Huibin Chen, Zhiqi Chen and Fuhai Zhu","Geodesic orbit metrics on homogeneous spaces constructed by strongly
  isotropy irreducible spaces","18 pages. Accepted for publication in SCIENCE CHINA Mathematics",,,,"math.DG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we focus on homogeneous spaces which are constructed from two
strongly isotropy irreducible spaces, and prove that any geodesic orbit metric
on these spaces is naturally reductive.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:33:07 GMT""}]","2020-12-15"
"2012.07016","Giovanni Abbiendi","Giovanni Abbiendi","Status of the MUonE experiment","8 pages, 4 figures, to be published in the Proceedings of the 40th
  International Conference on High Energy physics (ICHEP2020), July 28 - August
  6, 2020, Prague, Czech Republic (virtual meeting)",,,,"hep-ex hep-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The MUonE experiment aims at an independent and very precise determination of
the leading hadronic contribution to the muon magnetic moment, based on an
alternative method, complementary to the existing ones. This can be achieved by
measuring with unprecedented precision the shape of the differential cross
section of $\mu e$ elastic scattering, using the intense muon beam available at
CERN, with energy of 150 GeV, off atomic electrons of a light target. The
status of the project is presented, with recent results in preparation for the
test run scheduled in 2021 with a reduced detector.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:43:39 GMT""}]","2020-12-15"
"2012.07017","Nikolai Gorbushin","Nikolai Gorbushin, Lev Truskinovsky","Peristalsis by pulses of activity",,"Phys. Rev. E 103, 042411 (2021)","10.1103/PhysRevE.103.042411",,"physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Peristalsis by actively generated waves of muscle contraction is one of the
most fundamental ways of producing motion in living systems. We show that
peristalsis can be modeled by a train of rectangular-shaped solitary waves of
localized activity propagating through otherwise passive matter. Our analysis
is based on the FPU-type discrete model accounting for active stresses and we
reveal the existence in this problem of a critical regime which we argue to be
physiologically advantageous.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:44:30 GMT""}]","2021-04-21"
"2012.07018","Andrea Lucchini","Andrea Lucchini","Maximal intersections in finite groups",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  For a finite group $G$, we investigate the behaviour of four invariants,
$\text{MaxDim}(G),$ $\text{MinDim}(G),$ $\text{MaxInt}(G)$ and
$\text{MinInt}(G),$ measuring in some way the width and the height of the
lattice $\mathcal M(G)$ consisting of the intersections of the maximal
subgroups of $G.$
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:46:19 GMT""}]","2020-12-15"
"2012.07019","Yinuo Guo","Yinuo Guo, Zeqi Lin, Jian-Guang Lou, Dongmei Zhang","Iterative Utterance Segmentation for Neural Semantic Parsing","Accepted by AAAI 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural semantic parsers usually fail to parse long and complex utterances
into correct meaning representations, due to the lack of exploiting the
principle of compositionality. To address this issue, we present a novel
framework for boosting neural semantic parsers via iterative utterance
segmentation. Given an input utterance, our framework iterates between two
neural modules: a segmenter for segmenting a span from the utterance, and a
parser for mapping the span into a partial meaning representation. Then, these
intermediate parsing results are composed into the final meaning
representation. One key advantage is that this framework does not require any
handcraft templates or additional labeled data for utterance segmentation: we
achieve this through proposing a novel training method, in which the parser
provides pseudo supervision for the segmenter. Experiments on Geo,
ComplexWebQuestions, and Formulas show that our framework can consistently
improve performances of neural semantic parsers in different domains. On data
splits that require compositional generalization, our framework brings
significant accuracy gains: Geo 63.1 to 81.2, Formulas 59.7 to 72.7,
ComplexWebQuestions 27.1 to 56.3.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:46:24 GMT""}]","2020-12-15"
"2012.07020","Brian M. Andersen","Daniel Steffensen, Andreas Kreisel, P. J. Hirschfeld, Brian M.
  Andersen","Inter-orbital nematicity and the origin of a single electron Fermi
  pocket in FeSe","8 pages, 5 figures + Appedices","Phys. Rev. B 103, 054505 (2021)","10.1103/PhysRevB.103.054505","CMT NBI 2020","cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/publicdomain/zero/1.0/","  The electronic structure of the enigmatic iron-based superconductor FeSe has
puzzled researchers since spectroscopic probes failed to observe the expected
electron pocket at the $Y$ point in the 1-Fe Brillouin zone. It has been
speculated that this pocket, essential for an understanding of the
superconducting state, is either absent or incoherent. Here, we perform a
theoretical study of the preferred nematic order originating from
nearest-neighbor Coulomb interactions in an electronic model relevant for FeSe.
We find that at low temperatures the dominating nematic components are of
inter-orbital $d_{xz}-d_{xy}$ and $d_{yz}-d_{xy}$ character, with spontaneously
broken amplitudes for these two components. This inter-orbital nematic order
naturally leads to distinct hybridization gaps at the $X$ and $Y$ points of the
1-Fe Brillouin zone, and may thereby produce highly anisotropic Fermi surfaces
with only a single electron pocket at one of these momentum-space locations.
The associated superconducting gap structure obtained with the generated
low-energy electronic band structure from spin-fluctuation mediated pairing
agrees well with that measured experimentally. Finally, from a comparison of
the computed spin susceptibility to available neutron scattering data, we
discuss the necessity of additional self-energy effects, and explore the role
of orbital-dependent quasiparticle weights as a minimal means to include them.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:57:34 GMT""}]","2021-02-16"
"2012.07021","Jingxin Zhang","Jingxin Zhang, Maoyin Chen, Hao Chen, Xia Hong, and Donghua Zhou","Process monitoring based on orthogonal locality preserving projection
  with maximum likelihood estimation",,"Industrial and Engineering Chemistry Research, 58(14), 5579-5587,
  2019","10.1021/acs.iecr.8b05875",,"stat.ME cs.LG","http://creativecommons.org/licenses/by/4.0/","  By integrating two powerful methods of density reduction and intrinsic
dimensionality estimation, a new data-driven method, referred to as OLPP-MLE
(orthogonal locality preserving projection-maximum likelihood estimation), is
introduced for process monitoring. OLPP is utilized for dimensionality
reduction, which provides better locality preserving power than locality
preserving projection. Then, the MLE is adopted to estimate intrinsic
dimensionality of OLPP. Within the proposed OLPP-MLE, two new static measures
for fault detection $T_{\scriptscriptstyle {OLPP}}^2$ and ${\rm
SPE}_{\scriptscriptstyle {OLPP}}$ are defined. In order to reduce algorithm
complexity and ignore data distribution, kernel density estimation is employed
to compute thresholds for fault diagnosis. The effectiveness of the proposed
method is demonstrated by three case studies.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:20:47 GMT""}]","2020-12-15"
"2012.07022","Zezhou Hu","Zezhou Hu, Zhen Zhong, Peng-Cheng Li, Minyong Guo, Bin Chen","QED Effect on Black Hole Shadow","27 pages and 14 figures, some references added","Phys. Rev. D 103, 044057 (2021)","10.1103/PhysRevD.103.044057",,"gr-qc hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  In this work, taking the QED effect into account, we investigate the shadows
of the static black hole with magnetic monopoles and neutral black holes in
magnetic fields through the numerical backward ray-tracing method. For a static
black holes with magnetic monopole, we obtain the relation between the shadow
radius and the coupling constant. For neutral black holes in the uniform
magnetic fields, we find that the shadow curves deviate very small from the
ellipses for equatorial observer, and we read the linear relation between the
eccentricity and the coupling constant. For $\theta_o\neq\pi/2$, we find that
the shadow curves can be well approximated by ellipses in most cases, except
the case that the magnetic field is very strong and the observer sits around
the angle $\theta_o=\pi/4$ or $3\pi/4$. Moreover we extend our investigation to
a neutral static black hole surrounded with a current loop.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:23:33 GMT""},{""version"":""v2"",""created"":""Fri, 18 Dec 2020 14:08:05 GMT""}]","2021-03-03"
"2012.07023","Nghi D. Q. Bui","Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang","InferCode: Self-Supervised Learning of Code Representations by
  Predicting Subtrees","Accepted at ICSE 2021",,,,"cs.SE cs.AI cs.LG cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Building deep learning models on source code has found many successful
software engineering applications, such as code search, code comment
generation, bug detection, code migration, and so on. Current learning
techniques, however, have a major drawback that these models are mostly trained
on datasets labeled for particular downstream tasks, and code representations
may not be suitable for other tasks. While some techniques produce
representations from unlabeled code, they are far from satisfactory when
applied to downstream tasks. Although certain techniques generate
representations from unlabeled code when applied to downstream tasks they are
far from satisfactory. This paper proposes InferCode to overcome the limitation
by adapting the self-supervised learning mechanism to build source code model.
The key novelty lies in training code representations by predicting
automatically identified subtrees from the context of the ASTs. Subtrees in
ASTs are treated with InferCode as the labels for training code representations
without any human labeling effort or the overhead of expensive graph
construction, and the trained representations are no longer tied to any
specific downstream tasks or code units. We trained an InferCode model instance
using the Tree-based CNN as the encoder of a large set of Java code and applied
it to downstream unsupervised tasks such as code clustering, code clone
detection, cross-language code search or reused under a transfer learning
scheme to continue training the model weights for supervised tasks such as code
classification and method name prediction. Compared to previous code learning
techniques applied to the same downstream tasks, such as Code2Vec, Code2Seq,
ASTNN, higher performance results are achieved using our pre-trained InferCode
model with a significant margin for most tasks including those involving
different programming languages.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:33:41 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 16:37:23 GMT""}]","2020-12-16"
"2012.07024","Takhmasib Aliev","T.M.Aliev, M.Savci, S.Bilmis","Light-cone sum rules for radial excitation of decuplet to octet baryons
  electromagnetic transition form factors","21 pages, 7 figures",,"10.1142/S0217732321502394",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Magnetic dipole moment form factor, $G_M^{(2)}(Q^2)$, describing the radial
excitation of decuplet baryons to octet baryons electromagnetic transitions as
well as the ratios, $R_{SM} = -\frac{1}{4 m_2^2} \sqrt{4 m_2^2 Q^2 + (m_2^2 -
Q^2 -m_1^2)^2} \frac{G_C^{(2)}(Q^2)}{G_M^{(2)}(Q^2)}$ and $R_{EM} =
-\frac{G_E^{(2)}(Q^2)}{G_M^{(2)}(Q^2)}$ are calculated in the framework of
light-cone sum rules. We also estimate the degree of the violation of U-spin
symmetry. The obtained results for the multipole form factors can be useful in
searching the properties of radially excited baryon states.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:34:42 GMT""}]","2021-12-15"
"2012.07025","Matteo Salvato","Matteo Salvato, Mattia Scagliotti, Maurizio De Crescenzi, Paola
  Castrucci, Fabio De Matteis, Michele Crivellari, Stefano Pelli Cresi, Daniele
  Catone, Thilo Bauch and Floriana Lombardi","Stoichiometric Bi2Se3 Topological Insulator Ultra-Thin Films Obtained
  Through a New Fabrication Process for Optoelectronic Applications","11 pages, 8 figures, paper","Nanoscale 12, 12405 (2020)","10.1039/d0nr02725a",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new fabrication process is developed for growing Bi2Se3 topological
insulators in the form of nanowires/nanobelts and ultra-thin films. It consists
of two consecutive procedures: first Bi2Se3 nanowires/nanobelts are deposited
by standard catalyst free vapour-solid deposition on different substrates
positioned inside a quartz tube. Then, the Bi2Se3, stuck on the inner surface
of the quartz tube, is re-evaporated and deposited in the form of ultra-thin
films on new substrates at temperature below 100 {\deg}C, which is of relevance
for flexible electronic applications. The method is new, quick, very
inexpensive, easy to control and allows obtaining films with different
thickness down to one quintuple layer (QL) during the same procedure. The
composition and the crystal structure of both the nanowires/nanobelts and the
thin films is analysed by different optical, electronic and structural
techniques. For the films, scanning tunnelling spectroscopy shows that the
Fermi level is positioned in the middle of the energy bandgap as a consequence
of the achieved correct stoichiometry. Ultra-thin films, with thickness in the
range 1-10 QLs deposited on n-doped Si substrates, show good rectified
properties suitable for their use as photodetectors in the ultra
violet-visible-near infrared wavelength range
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:48:38 GMT""}]","2020-12-15"
"2012.07026","Luigi Pagano","Luigi Pagano","Motivic zeta function of the Hilbert schemes of points on a surface","32 pages. Comments are very welcome",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  Let $K$ be a discretely-valued field. Let $X\rightarrow Spec K$ be a surface
with trivial canonical bundle. In this paper we construct a weak N\'eron model
of the schemes $Hilb^n(X)$ over the ring of integers $R\subseteq K$. We exploit
this construction in order to compute the Motivic Zeta Function of $Hilb^n(X)$
in terms of $Z_X$. We determine the poles of $Z_{Hilb^n(X)}$ and study its
monodromy property, showing that if the monodromy conjecture holds for $X$ then
it holds for $Hilb^n(X)$ too.
  Sit $K$ corpus cum absoluto ualore discreto. Sit $ X\rightarrow Spec K$
leuigata superficies cum canonico fasce congruenti $\mathcal{O}_X$. In hoc
scripto defecta Neroniensia paradigmata $Hilb^n(X)$ schematum super annulo
integrorum in $K$ corpo, $R \subset K$, constituimus. Ex hoc, Functionem Zetam
Motiuicam $Z_{Hilb^n(X)}$, dato $Z_X$, computamus. Suos polos statuimus et suam
monodromicam proprietatem studemus, coniectura monodromica, quae super $X$
ualet, ualere super $Hilb^n(X)$ quoque demostrando.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:48:41 GMT""}]","2020-12-15"
"2012.07027","Xuejian Wang","Xuejian Wang","Impact of Regional Reactions to War on Contemporary Chinese Trade","29 pages, 1 figure",,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Different regional reactions to war in 1894 and 1900 can significantly impact
Chinese imports in 2001. As international relationship gets tense and China
rises, international conflicts could decrease trade.We analyze impact of
historic political conflict. We measure regional change of number of people
passing imperial exam because of war. War leads to an unsuccessful reform and
shocks elites. Elites in different regions have different ideas about
modernization, and the change of number of people passing exam is quite
different in different regions after war. Regional number of people passing
exam increases 1% after war, imports from then empires decrease 2.050% in 2001,
and this shows impact of cultural barrier. Manufactured goods can be impacted
because brands can be identified easily. Risk aversion of expensive products in
conservative regions can increase imports of equipment. Value chains need deep
trust, and this decreases imports of foreign company and assembly trade.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:49:34 GMT""}]","2020-12-15"
"2012.07028","Anthony Suen","Anthony Suen","Uniqueness of weak solutions of the three-dimensional compressible
  Navier-Stokes equations with potential force","arXiv admin note: text overlap with arXiv:2011.14581",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove uniqueness of weak solutions of the three-dimensional compressible
Navier-Stokes equations with potential force. We make use of the Lagrangean
framework in comparing the instantaneous states of corresponding fluid
particles in two different solutions. The present work provides qualitative
results on how the weak solutions depend continuously on initial data and
steady states.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:49:35 GMT""}]","2020-12-15"
"2012.07029","Florentin Rauscher","Florentin Rauscher and Oliver Sawodny","Efficient Online Trajectory Planning for Integrator Chain Dynamics using
  Polynomial Elimination",,,,,"cs.RO cs.SY eess.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Providing smooth reference trajectories can effectively increase performance
and accuracy of tracking control applications while overshoot and unwanted
vibrations are reduced. Trajectory planning computations can often be
simplified significantly by transforming the system dynamics into decoupled
integrator chains using methods such as feedback linearization, differential
flatness or the controller canonical form. We present an efficient method to
plan time optimal trajectories for integrator chains subject to derivative
bound constraints. Therefore, an algebraic precomputation algorithm formulates
the necessary conditions for time optimality in form of a set of polynomial
systems, followed by a symbolic polynomial elimination using Gr\""obner bases. A
fast online algorithm then plans the trajectories by calculating the roots of
the decomposed polynomial systems. These roots describe the switching time
instants of the input signal and the full trajectory simply follows by multiple
integration. This method presents a systematic way to compute time optimal
trajectories exactly via algebraic calculations without numerical approximation
iterations. It is applied to various trajectory types with different continuity
order, asymmetric derivative bounds and non-rest initial and final states.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:50:04 GMT""}]","2020-12-15"
"2012.07030","Pan Cunhua","Kangda Zhi, Cunhua Pan, Hong Ren and Kezhi Wang","Statistical CSI-based Design for Reconfigurable Intelligent
  Surface-aided Massive MIMO Systems with Direct Links","Accepted by IEEE Wireless Communications Letters. Keywords:
  Intelligent Reflecting Surface (IRS), reconfigurable intelligent surface
  (RIS)",,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the performance of reconfigurable intelligent surface
(RIS)-aided massive multiple-input multiple-output (MIMO) systems with direct
links, and the phase shifts of the RIS are designed based on the statistical
channel state information (CSI). We first derive the closed-form expression of
the uplink ergodic data rate. Then, based on the derived expression, we use the
genetic algorithm (GA) to solve the sum data rate maximization problem. With
low-complexity maximal-ratio combination (MRC) and low-overhead statistical
CSI-based scheme, we validate that the RIS can still bring significant
performance gains to traditional massive MIMO systems.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:50:06 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 02:13:05 GMT""},{""version"":""v3"",""created"":""Mon, 15 Feb 2021 12:49:32 GMT""}]","2021-02-16"
"2012.07031","Claudianor Alves","Claudianor O. Alves and Geovany F. Patricio","Existence of solution for a class of elliptic equation with
  discontinuous nonlinearity and asymptotically linear",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper concerns the existence of a nontrivial solution for the following
problem
  \begin{equation}
  \left\{\begin{aligned}
  -\Delta u + V(x)u & \in \partial_u F(x,u)\;\;\mbox{a.e.
in}\;\;\mathbb{R}^{N},\nonumber
  u \in H^{1}(\mathbb{R}^{N}),
  \end{aligned}
  \right.\leqno{(P)}
  \end{equation} where $F(x,t)=\int_{0}^{t}f(x,s)\,ds$, $f$ is a discontinuous
function and asymptotically linear at infinity, $\lambda=0$ is in a spectral
gap of $-\Delta+V$, and $\partial_t F$ denotes the generalized gradient of $F$
with respect to variable $t$. Here, by employing Variational Methods for
Locally Lipschitz Functionals, we establish the existence of solution when $f$
is periodic and non periodic
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:52:28 GMT""}]","2020-12-15"
"2012.07032","Vincent Corlay","Vincent Corlay, Joseph J. Boutros, Philippe Ciblat, and Lo\""ic Brunel","Neural network approaches to point lattice decoding","submitted to IEEE Transactions on Information Theory. arXiv admin
  note: text overlap with arXiv:1902.11294",,,,"cs.IT cs.LG math.IT","http://creativecommons.org/licenses/by/4.0/","  We characterize the complexity of the lattice decoding problem from a neural
network perspective. The notion of Voronoi-reduced basis is introduced to
restrict the space of solutions to a binary set. On the one hand, this problem
is shown to be equivalent to computing a continuous piecewise linear (CPWL)
function restricted to the fundamental parallelotope. On the other hand, it is
known that any function computed by a ReLU feed-forward neural network is CPWL.
As a result, we count the number of affine pieces in the CPWL decoding function
to characterize the complexity of the decoding problem. It is exponential in
the space dimension $n$, which induces shallow neural networks of exponential
size. For structured lattices we show that folding, a technique equivalent to
using a deep neural network, enables to reduce this complexity from exponential
in $n$ to polynomial in $n$. Regarding unstructured MIMO lattices, in contrary
to dense lattices many pieces in the CPWL decoding function can be neglected
for quasi-optimal decoding on the Gaussian channel. This makes the decoding
problem easier and it explains why shallow neural networks of reasonable size
are more efficient with this category of lattices (in low to moderate
dimensions).
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:53:34 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 14:12:17 GMT""}]","2021-10-11"
"2012.07033","Zhengxiong Luo","Zhengxiong Luo, Zhicheng Wang, Yuanhao Cai, Guanan Wang, Yan Huang,
  Liang Wang, Erjin Zhou, Tieniu Tan, Jian Sun","Efficient Human Pose Estimation by Learning Deeply Aggregated
  Representations",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose an efficient human pose estimation network (DANet)
by learning deeply aggregated representations. Most existing models explore
multi-scale information mainly from features with different spatial sizes.
Powerful multi-scale representations usually rely on the cascaded pyramid
framework. This framework largely boosts the performance but in the meanwhile
makes networks very deep and complex. Instead, we focus on exploiting
multi-scale information from layers with different receptive-field sizes and
then making full of use this information by improving the fusion method.
Specifically, we propose an orthogonal attention block (OAB) and a second-order
fusion unit (SFU). The OAB learns multi-scale information from different layers
and enhances them by encouraging them to be diverse. The SFU adaptively selects
and fuses diverse multi-scale information and suppress the redundant ones. This
could maximize the effective information in final fused representations. With
the help of OAB and SFU, our single pyramid network may be able to generate
deeply aggregated representations that contain even richer multi-scale
information and have a larger representing capacity than that of cascaded
networks. Thus, our networks could achieve comparable or even better accuracy
with much smaller model complexity. Specifically, our \mbox{DANet-72} achieves
$70.5$ in AP score on COCO test-dev set with only $1.0G$ FLOPs. Its speed on a
CPU platform achieves $58$ Persons-Per-Second~(PPS).
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 10:58:07 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 02:48:52 GMT""}]","2020-12-16"
"2012.07034","Siva Mouni Nemalidinne","Nemalidinne Siva Mouni, Abhinav Kumar and Prabhat K. Upadhyay","Adaptive User Pairing for Downlink NOMA System with Imperfect SIC","5 pages, 8 figures",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Non-orthogonal multiple access (NOMA) has been recognized as a key driving
technology for the fifth generation (5G) and beyond 5G cellular networks. For a
practical dowlink NOMA system with imperfect successive interference
cancellation (SIC), we derive bounds on channel coefficients and power
allocation factors between NOMA users to achieve higher rates than an
equivalent orthogonal multiple access (OMA) system. We propose an adaptive user
pairing (A-UP) algorithm for NOMA systems. Through extensive simulations, we
show that NOMA with imperfect SIC is not always superior to OMA. Further, the
proposed A-UP algorithm results in better performance than state-of-the-art
NOMA pairing algorithms in presence of SIC imperfections.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 11:06:35 GMT""}]","2020-12-15"
"2012.07035","Walaa Elmetenawee","Walaa Elmetenawee","CMS track reconstruction performance during Run 2 and developments for
  Run 3",,,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An efficient and precise reconstruction of charged-particle tracks is crucial
for the overall performance of the CMS experiment. During Run 2 of LHC,
significant upgrades were made to the track reconstruction algorithms in order
to accommodate for the high pileup environment and the installation of an
upgraded pixel detector in 2017. This paper provides an overview of the
iterative track reconstruction algorithm used in CMS during Run 2 and of the
performance measured both with simulated and collision data. Developments are
ongoing to further improve track reconstruction in Run 3, especially for what
concerns the CMS high-level trigger, and the status of these improvements will
be discussed.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 11:08:08 GMT""}]","2020-12-15"
"2012.07036","Daniel Hexner","Daniel Hexner","Training nonlinear elastic functions: nonmonotonic, sequence dependent
  and bifurcating",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The elastic behavior of materials operating in the linear regime is
constrained, by definition, to operations that are linear in the imposed
deformation. Though the nonlinear regime holds promise for new functionality,
the design in this regime is challenging. In this paper we demonstrate that a
recent approach based on training [Hexner et al., PNAS 2020, 201922847] allows
responses that are inherently non-linear. By applying designer strains, a
disordered solids evolves through plastic deformations that alter its response.
We show examples of elaborate nonlinear training paths that lead to the
following functions: (1) Frequency conversion (2) Logic gate and (3) Expansion
or contraction along one axis, depending on the sequence of imposed transverse
compressions. We study the convergence rate and find that it depends on the
trained function.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 11:10:38 GMT""}]","2020-12-15"
"2012.07037","Michael Beyer","Michael Beyer, Andrey Morozov, Emil Valiev, Christoph Schorn, Lydia
  Gauerhof, Kai Ding, Klaus Janschek","Fault Injectors for TensorFlow: Evaluation of the Impact of Random
  Hardware Faults on Deep CNNs","Preprint of the corresponding ESREL 2020 PSAM15 conference
  publication",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Today, Deep Learning (DL) enhances almost every industrial sector, including
safety-critical areas. The next generation of safety standards will define
appropriate verification techniques for DL-based applications and propose
adequate fault tolerance mechanisms. DL-based applications, like any other
software, are susceptible to common random hardware faults such as bit flips,
which occur in RAM and CPU registers. Such faults can lead to silent data
corruption. Therefore, it is crucial to develop methods and tools that help to
evaluate how DL components operate under the presence of such faults. In this
paper, we introduce two new Fault Injection (FI) frameworks InjectTF and
InjectTF2 for TensorFlow 1 and TensorFlow 2, respectively. Both frameworks are
available on GitHub and allow the configurable injection of random faults into
Neural Networks (NN). In order to demonstrate the feasibility of the
frameworks, we also present the results of FI experiments conducted on four
VGG-based Convolutional NNs using two image sets. The results demonstrate how
random bit flips in the output of particular mathematical operations and layers
of NNs affect the classification accuracy. These results help to identify the
most critical operations and layers, compare the reliability characteristics of
functionally similar NNs, and introduce selective fault tolerance mechanisms.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 11:16:25 GMT""}]","2020-12-15"
"2012.07038","Christina Petschnigg","Christina Petschnigg and Juergen Pilz","Uncertainty Estimation in Deep Neural Networks for Point Cloud
  Segmentation in Factory Planning","17 pages, 5 figures, submitted to MDPI Modelling journal for review",,,,"cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The digital factory provides undoubtedly a great potential for future
production systems in terms of efficiency and effectivity. A key aspect on the
way to realize the digital copy of a real factory is the understanding of
complex indoor environments on the basis of 3D data. In order to generate an
accurate factory model including the major components, i.e. building parts,
product assets and process details, the 3D data collected during digitalization
can be processed with advanced methods of deep learning. In this work, we
propose a fully Bayesian and an approximate Bayesian neural network for point
cloud segmentation. This allows us to analyze how different ways of estimating
uncertainty in these networks improve segmentation results on raw 3D point
clouds. We achieve superior model performance for both, the Bayesian and the
approximate Bayesian model compared to the frequentist one. This performance
difference becomes even more striking when incorporating the networks'
uncertainty in their predictions. For evaluation we use the scientific data set
S3DIS as well as a data set, which was collected by the authors at a German
automotive production plant. The methods proposed in this work lead to more
accurate segmentation results and the incorporation of uncertainty information
makes this approach especially applicable to safety critical applications.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 11:18:52 GMT""}]","2020-12-15"
"2012.07039","Lina Ji","Lina Ji and Zenghu Li","Construction of age-structured branching processes by stochastic
  equations",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give constructions of age-structured branching processes without or with
immigration as pathwise unique solutions to stochastic integral equations. A
necessary and sufficient condition for the ergodicity of the model with
immigration is also given.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 11:20:17 GMT""}]","2020-12-15"
"2012.07040","Michele  Ciavarella","G.Violano, A.Papangelo, M.Ciavarella","Stickiness of randomly rough surfaces with high fractal dimension: is
  there a fractal limit?","15 pages; 5 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Two surfaces are ""sticky"" if breaking their mutual contact requires a finite
tensile force. At low fractal dimensions D, there is consensus stickiness does
not depend on the upper truncation frequency of roughness spectrum (or
""magnification""). As debate is still open for the case at high D, we exploit
BAM theory of Ciavarella and Persson-Tosatti theory, to derive criteria for all
fractal dimensions. For high D, we show that stickiness is more influenced by
short wavelength roughness with respect to the low D case. BAM converges at
high magnifications to a simple criterion which depends only on D, in agreement
with theories that includes Lennard-Jones traction-gap law, while
Persson-Tosatti disagrees because of its simplifying approximations.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 11:28:43 GMT""}]","2020-12-15"
"2012.07041","Dawei Zhai","Dawei Zhai, Wang Yao","Layer pseudospin dynamics and genuine non-Abelian Berry phase in
  inhomogeneously strained moir\'e pattern","To appear in Phys. Rev. Lett","Phys. Rev. Lett. 125, 266404 (2020)","10.1103/PhysRevLett.125.266404",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Periodicity of long wavelength moir\'e patterns is very often destroyed by
the inhomogeneous strain introduced in fabrications of van der Waals layered
structures. We present a framework to describe massive Dirac fermions in such
distorted moir\'e pattern of transition metal dichalcogenides homobilayers,
accounting for the dynamics of layer pseudospin. In decoupled bilayers, we show
two causes of in-plane layer pseudospin precession: By the coupling of layer
antisymmetric strain to valley magnetic moment; and by the Aharonov-Bohm effect
in the SU(2) gauge potential for the case of R-type bilayer under antisymmetric
strain and H-type under symmetric strain. With interlayer coupling in the
moir\'e, its interplay with strain manifests as a non-Abelian gauge field. We
show a genuine non-Abelian Aharonov-Bohm effect in such field, where the
evolution operators for different loops are non-commutative. This provides an
exciting platform to explore non-Abelian gauge field effects on electron, with
remarkable tunability of the field by strain and interlayer bias.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 11:43:01 GMT""}]","2021-01-05"
"2012.07042","Xiangde Luo","Xiangde Luo, Wenjun Liao, Jieneng Chen, Tao Song, Yinan Chen, Shichuan
  Zhang, Nianyong Chen, Guotai Wang, Shaoting Zhang","Efficient Semi-Supervised Gross Target Volume of Nasopharyngeal
  Carcinoma Segmentation via Uncertainty Rectified Pyramid Consistency","13 pages, provisional accept by MICCAI2021,code
  at:https://github.com/HiLab-git/SSL4MIS",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Gross Target Volume (GTV) segmentation plays an irreplaceable role in
radiotherapy planning for Nasopharyngeal Carcinoma (NPC). Despite that
Convolutional Neural Networks (CNN) have achieved good performance for this
task, they rely on a large set of labeled images for training, which is
expensive and time-consuming to acquire. In this paper, we propose a novel
framework with Uncertainty Rectified Pyramid Consistency (URPC) regularization
for semi-supervised NPC GTV segmentation. Concretely, we extend a backbone
segmentation network to produce pyramid predictions at different scales. The
pyramid predictions network (PPNet) is supervised by the ground truth of
labeled images and a multi-scale consistency loss for unlabeled images,
motivated by the fact that prediction at different scales for the same input
should be similar and consistent. However, due to the different resolution of
these predictions, encouraging them to be consistent at each pixel directly has
low robustness and may lose some fine details. To address this problem, we
further design a novel uncertainty rectifying module to enable the framework to
gradually learn from meaningful and reliable consensual regions at different
scales. Experimental results on a dataset with 258 NPC MR images showed that
with only 10% or 20% images labeled, our method largely improved the
segmentation performance by leveraging the unlabeled images, and it also
outperformed five state-of-the-art semi-supervised segmentation methods.
Moreover, when only 50% images labeled, URPC achieved an average Dice score of
82.74% that was close to fully supervised learning.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 11:45:00 GMT""},{""version"":""v2"",""created"":""Sat, 27 Feb 2021 07:16:26 GMT""},{""version"":""v3"",""created"":""Thu, 4 Mar 2021 06:04:41 GMT""},{""version"":""v4"",""created"":""Fri, 4 Jun 2021 03:31:58 GMT""}]","2021-06-07"
"2012.07043","WenHui Lei","Wenhui Lei, Wei Xu, Ran Gu, Hao Fu, Shaoting Zhang, Guotai Wang","Contrastive Learning of Relative Position Regression for One-Shot Object
  Localization in 3D Medical Images","Early accepted by MICCAI 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep learning networks have shown promising performance for accurate object
localization in medial images, but require large amount of annotated data for
supervised training, which is expensive and expertise burdensome. To address
this problem, we present a one-shot framework for organ and landmark
localization in volumetric medical images, which does not need any annotation
during the training stage and could be employed to locate any landmarks or
organs in test images given a support (reference) image during the inference
stage. Our main idea comes from that tissues and organs from different human
bodies have a similar relative position and context. Therefore, we could
predict the relative positions of their non-local patches, thus locate the
target organ. Our framework is composed of three parts: (1) A projection
network trained to predict the 3D offset between any two patches from the same
volume, where human annotations are not required. In the inference stage, it
takes one given landmark in a reference image as a support patch and predicts
the offset from a random patch to the corresponding landmark in the test
(query) volume. (2) A coarse-to-fine framework contains two projection
networks, providing more accurate localization of the target. (3) Based on the
coarse-to-fine model, we transfer the organ boundingbox (B-box) detection to
locating six extreme points along x, y and z directions in the query volume.
Experiments on multi-organ localization from head-and-neck (HaN) CT volumes
showed that our method acquired competitive performance in real time, which is
more accurate and 10^5 times faster than template matching methods with the
same setting. Code is available: https://github.com/LWHYC/RPR-Loc.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 11:54:19 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 13:13:27 GMT""}]","2021-05-26"
"2012.07044","Jingxin Zhang","Jingxin Zhang, Donghua Zhou, and Maoyin Chen","Monitoring multimode processes: a modified PCA algorithm with continual
  learning ability","This paper has been accepted by Journal of Process Control",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  For multimode processes, one generally establishes local monitoring models
corresponding to local modes. However, the significant features of previous
modes may be catastrophically forgotten when a monitoring model for the current
mode is built. It would result in an abrupt performance decrease. It could be
an effective manner to make local monitoring model remember the features of
previous modes. Choosing the principal component analysis (PCA) as a basic
monitoring model, we try to resolve this problem. A modified PCA algorithm is
built with continual learning ability for monitoring multimode processes, which
adopts elastic weight consolidation (EWC) to overcome catastrophic forgetting
of PCA for successive modes. It is called PCA-EWC, where the significant
features of previous modes are preserved when a PCA model is established for
the current mode. The optimal parameters are acquired by differences of convex
functions. Moreover, the proposed PCA-EWC is extended to general multimode
processes and the procedure is presented. The computational complexity and key
parameters are discussed to further understand the relationship between PCA and
the proposed algorithm. Potential limitations and relevant solutions are
pointed to understand the algorithm further. Numerical case study and a
practical industrial system in China are employed to illustrate the
effectiveness of the proposed algorithm.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:09:38 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 03:33:54 GMT""},{""version"":""v3"",""created"":""Mon, 28 Dec 2020 12:46:44 GMT""},{""version"":""v4"",""created"":""Mon, 26 Apr 2021 13:45:40 GMT""},{""version"":""v5"",""created"":""Fri, 28 May 2021 08:50:55 GMT""}]","2021-05-31"
"2012.07045","Lili Du","Jianfeng Cheng, Lili Du, Qin Zhang","Existence and uniqueness of axially symmetric compressible subsonic jet
  impinging on an infinite wall","Accepted for publicaiton in Interfaces and Free Boudanries. 61 pages,
  6 figures",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  This paper is concerned with the well-posedness theory of the impact of a
subsonic axially symmetric jet emerging from a semi-infinitely long nozzle,
onto a rigid wall. The fluid motion is described by the steady isentropic Euler
system. We showed that there exists a critical value $M_{cr}>0$, if the given
mass flux is less than $M_{cr}$, there exists a unique smooth subsonic axially
symmetric jet issuing from the given semi-infinitely long nozzle and hitting a
given uneven wall. The surface of the axially symmetric impinging jet is a free
boundary, which detaches from the edge of the nozzle smoothly. It is showed
that a unique suitable choice of the pressure difference between the chamber
and the atmosphere guarantees the continuous fit condition of the free
boundary. Moreover, the asymptotic behaviors and the decay properties of the
impinging jet and the free surface in downstream were also obtained. The main
results in this paper solved the open problem on the well-posedness of the
compressible axially symmetric impinging jet, which has proposed by A. Friedman
in Chapter 16 in [FA2]. The key ingredient of our proof is based on the
variational method to the quasilinear elliptic equation with the Bernoulli's
type free boundaries.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:10:21 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 02:41:37 GMT""}]","2020-12-16"
"2012.07046","Sunny Katyara","Sunny Katyara, Fanny Ficuciello, Fei Chen, Bruno Siciliano, Darwin G.
  Caldwell","Vision Based Adaptation to Kernelized Synergies for Human Inspired
  Robotic Manipulation",,,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Humans in contrast to robots are excellent in performing fine manipulation
tasks owing to their remarkable dexterity and sensorimotor organization.
Enabling robots to acquire such capabilities, necessitates a framework that not
only replicates the human behaviour but also integrates the multi-sensory
information for autonomous object interaction. To address such limitations,
this research proposes to augment the previously developed kernelized synergies
framework with visual perception to automatically adapt to the unknown objects.
The kernelized synergies, inspired from humans, retain the same reduced
subspace for object grasping and manipulation. To detect object in the scene, a
simplified perception pipeline is used that leverages the RANSAC algorithm with
Euclidean clustering and SVM for object segmentation and recognition
respectively. Further, the comparative analysis of kernelized synergies with
other state of art approaches is made to confirm their flexibility and
effectiveness on the robotic manipulation tasks. The experiments conducted on
the robot hand confirm the robustness of modified kernelized synergies
framework against the uncertainties related to the perception of environment.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:17:37 GMT""}]","2020-12-15"
"2012.07047","Jie Liu","Jie Liu and Zhenyu Li and Jinlong Yang","An efficient adaptive variational quantum solver of the Schrodinger
  equation based on reduced density matrices","27 pages and 5 figures",,"10.1063/5.0054822",,"quant-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Recently, an adaptive variational algorithm termed Adaptive
Derivative-Assembled Pseudo-Trotter ansatz Variational Quantum Eigensolver
(ADAPT-VQE) has been proposed by Grimsley et al. (Nat. Commun. 10, 3007) while
the number of measurements required to perform this algorithm scales O(N^8). In
this work, we present an efficient adaptive variational quantum solver of the
Schrodinger equation based on ADAPT-VQE together with the reduced density
matrix reconstruction approach, which reduces the number of measurements from
O(N^8) to O(N^4). This new algorithm is quite suitable for quantum simulations
of chemical systems on near-term noisy intermediate-scale hardware due to low
circuit complexity and reduced measurement. Numerical benchmark calculations
for small molecules demonstrate that this new algorithm provides an accurate
description of the ground-state potential energy curves. In addition, we
generalize this new algorithm for excited states with the variational quantum
deflation approach and achieve the same accuracy as ground-state simulations.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:22:41 GMT""}]","2021-07-28"
"2012.07048","Siwei Wang","Siwei Wang, Haoyun Wang, Longbo Huang","Adaptive Algorithms for Multi-armed Bandit with Composite and Anonymous
  Feedback",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the multi-armed bandit (MAB) problem with composite and anonymous
feedback. In this model, the reward of pulling an arm spreads over a period of
time (we call this period as reward interval) and the player receives partial
rewards of the action, convoluted with rewards from pulling other arms,
successively. Existing results on this model require prior knowledge about the
reward interval size as an input to their algorithms. In this paper, we propose
adaptive algorithms for both the stochastic and the adversarial cases, without
requiring any prior information about the reward interval. For the stochastic
case, we prove that our algorithm guarantees a regret that matches the lower
bounds (in order). For the adversarial case, we propose the first algorithm to
jointly handle non-oblivious adversary and unknown reward interval size. We
also conduct simulations based on real-world dataset. The results show that our
algorithms outperform existing benchmarks.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:25:41 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 11:44:06 GMT""}]","2020-12-16"
"2012.07049","Jinsong Zhang","Kun Li, Jinsong Zhang, Yebin Liu, Yu-Kun Lai, Qionghai Dai","PoNA: Pose-guided Non-local Attention for Human Pose Transfer","16 pages, 14 figures","IEEE Transactions on Image Processing (2020), Volume 29","10.1109/TIP.2020.3029455",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human pose transfer, which aims at transferring the appearance of a given
person to a target pose, is very challenging and important in many
applications. Previous work ignores the guidance of pose features or only uses
local attention mechanism, leading to implausible and blurry results. We
propose a new human pose transfer method using a generative adversarial network
(GAN) with simplified cascaded blocks. In each block, we propose a pose-guided
non-local attention (PoNA) mechanism with a long-range dependency scheme to
select more important regions of image features to transfer. We also design
pre-posed image-guided pose feature update and post-posed pose-guided image
feature update to better utilize the pose and image features. Our network is
simple, stable, and easy to train. Quantitative and qualitative results on
Market-1501 and DeepFashion datasets show the efficacy and efficiency of our
model. Compared with state-of-the-art methods, our model generates sharper and
more realistic images with rich details, while having fewer parameters and
faster speed. Furthermore, our generated images can help to alleviate data
insufficiency for person re-identification.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:38:29 GMT""}]","2020-12-15"
"2012.07050","Dine Ousmane Samary","Vincent Lahoche, Mohamed Ouerfelli, Dine Ousmane Samary and Mohamed
  Tamaazousti","Field theoretical approach for signal detection in nearly continuous
  positive spectra II: Tensorial data","12 pages, 6 figures",,"10.3390/e23070795",,"hep-th cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The tensorial principal component analysis is a generalization of ordinary
principal component analysis, focusing on data which are suitably described by
tensors rather than matrices. This paper aims at giving the nonperturbative
renormalization group formalism based on a slight generalization of the
covariance matrix, to investigate signal detection for the difficult issue of
nearly continuous spectra. Renormalization group allows constructing effective
description keeping only relevant features in the low ``energy'' (i.e. large
eigenvalues) limit and thus provides universal descriptions allowing to
associate the presence of the signal with objectives and computable quantities.
Among them, in this paper, we focus on the vacuum expectation value. We exhibit
experimental evidence in favor of a connection between symmetry breaking and
the existence of an intrinsic detection threshold, in agreement with our
conclusions for matrices, providing a new step in the direction of a universal
statement.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:47:24 GMT""},{""version"":""v2"",""created"":""Sun, 20 Jun 2021 23:29:00 GMT""},{""version"":""v3"",""created"":""Wed, 3 Nov 2021 10:29:43 GMT""}]","2021-11-04"
"2012.07051","Prabhu Kaliyammal Thiruvasagam","Prabhu Kaliyammal Thiruvasagam, Vijeth J. Kotagi, and C. Siva Ram
  Murthy","A Reliability-Aware, Delay Guaranteed, and Resource Efficient Placement
  of Service Function Chains in Softwarized 5G Networks","17 pages",,"10.1109/TCC.2020.3020269",,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network Functions Virtualization (NFV) allows flexibility, scalability,
agility, and easy manageability of networks by leveraging the features of
virtualization and cloud computing technologies. However, softwarization of
network functions imposes many challenges. Reliability and latency are major
challenges in NFV-enabled 5G networks that can lead to customer dissatisfaction
and revenue loss. In general, redundancy is used to improve the reliability of
communication services. However, redundancy requires the same amount of
additional resources and thus increases cost. In this work, we address the
reliability-aware, delay guaranteed, and resource efficient Service Function
Chain (SFC) placement problem in softwarized 5G networks. First, we propose a
novel SFC subchaining method to enhance the reliability of an SFC without
backups. If reliability requirement is not met after subchaining method, we add
backups to VNFs to meet the reliability requirement. Then, we formulate the
reliable SFC placement problem as an Integer Linear Programming (ILP) problem
in order to solve it optimally. Owing to high computational complexity of the
ILP problem for solving large input instances, we propose a modified stable
matching algorithm to provide near-optimal solution in polynomial time. By
extensive simulations we show that our proposed solutions consume lesser
physical resources compared to state-of-the-art solutions for provisioning
reliable communication services.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:47:33 GMT""}]","2020-12-15"
"2012.07052","Sebastian Lesnic Mr.","Sebastian Cristian Lesnic","The generalisation of some invariants of modules to groups with
  operators","14 pages. Article to be published soon (after the current moment of
  December 13 2020) in the ""Bulletin Math\'ematique de la Soci\'et\'e des
  Sciences Math\'ematiques de Roumanie""",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The article $-$ part of a larger thesis which aims to give a detailed
description of the generalisation to the category of groups with operators of
the classical theory of semisimplicity for modules $-$ presents a
straightforward generalisation to groups with operators of a number of
invariants well-known in the theory of modules, having a special bearing on
phenomena of semisimplicity. The behaviour of these generalised invariants in
relation to the fundamental construction of restricted direct sums and in
particular in the context of semisimple groups with operators is in particular
examined. The article also introduces a particular type of morphisms between
groups with operators, morphisms which naturally preserve the generalised
invariants in question and thus show themselves to be an adequate notion for
the study of semisimplicity in the more general frame considered.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:49:29 GMT""}]","2020-12-15"
"2012.07053","Yoonsang Park","Yoonsang Park, Hossein Daneshpajooh, Timo Scholehwar, Eberhard Hennig,
  Kenji Uchino","Physical Parameter and Loss Determination of Piezoceramics Using Partial
  Electrode: k31 and k33 Mode Cases","29 pages with supplementary materials included",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The standard method to determine physical parameters of piezoceramics,
established by IEEE, has been utilized for decades by the number of
researchers, yet it omits presence of important loss factors and possesses
serious deficits that restricts accurate parameter determination. In order to
resolve these issues, the partial electrode (PE) method (mechanical excitation
method) was previously proposed. In this study, we aim to propose a modified PE
method to enhance the efficiency of parameter determination process, along with
a simplified analytical admittance equation for better understanding of the PE
configuration. To prove that the PE method is reliable, possible causes of
errors were listed, and it was shown that they were either negligibly small or
resolved with proper calibration methods. Throughout the paper, it was
validated that the PE method not only reduces the errors of several physical
parameters by avoiding error propagation, but also enables measurement
compatibility with commercially available impedance analyzers.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:54:49 GMT""},{""version"":""v2"",""created"":""Wed, 23 Dec 2020 14:34:17 GMT""}]","2020-12-24"
"2012.07054","Jonathan Lacotte","Jonathan Lacotte, Mert Pilanci","Adaptive and Oblivious Randomized Subspace Methods for High-Dimensional
  Optimization: Sharp Analysis and Lower Bounds",,,,,"cs.IT cs.LG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose novel randomized optimization methods for high-dimensional convex
problems based on restrictions of variables to random subspaces. We consider
oblivious and data-adaptive subspaces and study their approximation properties
via convex duality and Fenchel conjugates. A suitable adaptive subspace can be
generated by sampling a correlated random matrix whose second order statistics
mirror the input data. We illustrate that the adaptive strategy can
significantly outperform the standard oblivious sampling method, which is
widely used in the recent literature. We show that the relative error of the
randomized approximations can be tightly characterized in terms of the spectrum
of the data matrix and Gaussian width of the dual tangent cone at optimum. We
develop lower bounds for both optimization and statistical error measures based
on concentration of measure and Fano's inequality. We then present the
consequences of our theory with data matrices of varying spectral decay
profiles. Experimental results show that the proposed approach enables
significant speed ups in a wide variety of machine learning and optimization
problems including logistic regression, kernel classification with random
convolution layers and shallow neural networks with rectified linear units.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:02:31 GMT""}]","2020-12-15"
"2012.07055","Marcelo Bortolozzo","Marcelo Bortolozzo, Rodrigo Schramm, Claudio R. Jung","Improving the Classification of Rare Chords with Unlabeled Data",,,,,"cs.SD cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we explore techniques to improve performance for rare classes
in the task of Automatic Chord Recognition (ACR). We first explored the use of
the focal loss in the context of ACR, which was originally proposed to improve
the classification of hard samples. In parallel, we adapted a self-learning
technique originally designed for image recognition to the musical domain. Our
experiments show that both approaches individually (and their combination)
improve the recognition of rare chords, but using only self-learning with noise
addition yields the best results.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:02:55 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 11:57:24 GMT""}]","2021-02-11"
"2012.07056","Anamay Tengse","Mrinal Kumar, C. Ramya, Ramprasad Saptharishi, Anamay Tengse","If VNP is hard, then so are equations for it",,,,,"cs.CC","http://creativecommons.org/licenses/by/4.0/","  Assuming that the Permanent polynomial requires algebraic circuits of
exponential size, we show that the class VNP does not have efficiently
computable equations. In other words, any nonzero polynomial that vanishes on
the coefficient vectors of all polynomials in the class VNP requires algebraic
circuits of super-polynomial size.
  In a recent work of Chatterjee and the authors (FOCS 2020), it was shown that
the subclasses of VP and VNP consisting of polynomials with bounded integer
coefficients do have equations with small algebraic circuits. Their work left
open the possibility that these results could perhaps be extended to all of VP
or VNP. The results in this paper show that assuming the hardness of Permanent,
at least for VNP, allowing polynomials with large coefficients does indeed
incur a significant blow up in the circuit complexity of equations.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:17:12 GMT""}]","2020-12-15"
"2012.07057","Iain Muntz","Iain Muntz, James A. Richards, Sam Brown, Andrew B. Schofield, Marcel
  Rey, Job H. J. Thijssen","Contactless Interfacial Rheology: Probing Shear at Liquid-Liquid
  Interfaces without an Interfacial Geometry via Fluorescence Microscopy","14 pages, 11 figures","Journal of Rheology 67, 67-80 (2023)","10.1122/8.0000559",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Interfacial rheology is important for understanding properties such as
Pickering emulsion or foam stability. Currently, the response is measured using
a probe directly attached to the interface. This can both disturb the interface
and is coupled to flow in the bulk phase, limiting its sensitivity. We have
developed a contactless interfacial method to perform interfacial shear
rheology on liquid/liquid interfaces with no tool attached directly to the
interface. This is achieved by shearing one of the liquid phases and measuring
the interfacial response via confocal microscopy. Using this method we have
measured steady shear material parameters such as interfacial elastic moduli
for interfaces with solid-like behaviour and interfacial viscosities for
fluid-like interfaces. The accuracy of this method has been verified relative
to a double-wall ring geometry. Moreover, using our contactless method we are
able to measure lower interfacial viscosities than those that have previously
been reported using a double-wall ring geometry. A further advantage is the
simultaneous combination of macroscopic rheological analysis with microscopic
structural analysis. Our analysis directly visualizes how the interfacial
response is strongly correlated to the particle surface coverage and their
interfacial assembly. Furthermore, we capture the evolution and irreversible
changes in the particle assembly that correspond with the rheological response
to steady shear.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:23:43 GMT""},{""version"":""v2"",""created"":""Tue, 8 Nov 2022 13:03:52 GMT""}]","2022-11-09"
"2012.07058","Vineet Nair","Vineet Nair, Vishakha Patil, Gaurav Sinha","Budgeted and Non-budgeted Causal Bandits",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-sa/4.0/","  Learning good interventions in a causal graph can be modelled as a stochastic
multi-armed bandit problem with side-information. First, we study this problem
when interventions are more expensive than observations and a budget is
specified. If there are no backdoor paths from an intervenable node to the
reward node then we propose an algorithm to minimize simple regret that
optimally trades-off observations and interventions based on the cost of
intervention. We also propose an algorithm that accounts for the cost of
interventions, utilizes causal side-information, and minimizes the expected
cumulative regret without exceeding the budget. Our cumulative-regret
minimization algorithm performs better than standard algorithms that do not
take side-information into account. Finally, we study the problem of learning
best interventions without budget constraint in general graphs and give an
algorithm that achieves constant expected cumulative regret in terms of the
instance parameters when the parent distribution of the reward variable for
each intervention is known. Our results are experimentally validated and
compared to the best-known bounds in the current literature.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:31:14 GMT""}]","2020-12-15"
"2012.07059","Valerii Pchelintsev","Valerii Pchelintsev","On Variations of Neumann Eigenvalues of p-Laplacian Generated by Measure
  Preserving Quasiconformal Mappings",,,,,"math.AP math.FA","http://creativecommons.org/licenses/by/4.0/","  In this paper we study variations of the first non-trivial eigenvalues of the
two-dimensional $p$-Laplace operator, $p>2$, generated by measure preserving
quasiconformal mappings $\varphi : \mathbb D\to\Omega$, $\Omega \subset\mathbb
R^2$. This study is based on the geometric theory of composition operators on
Sobolev spaces with applications to sharp embedding theorems. By using a sharp
version of the reverse H\""older inequality we obtain lower estimates of the
first non-trivial eigenvalues for Ahlfors type domains.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:35:28 GMT""}]","2020-12-15"
"2012.07060","Ji Han Dr","Ji Han, Serhad Sarica, Feng Shi, Jianxi Luo","Semantic Networks for Engineering Design: A Survey","12 pages, 2 tables, conference",,,,"cs.DL cs.DB","http://creativecommons.org/licenses/by/4.0/","  There have been growing uses of semantic networks in the past decade, such as
leveraging large-scale pre-trained graph knowledge databases for various
natural language processing (NLP) tasks in engineering design research.
Therefore, the paper provides a survey of the research that has employed
semantic networks in the engineering design research community. The survey
reveals that engineering design researchers have primarily relied on WordNet,
ConceptNet, and other common-sense semantic network databases trained on
non-engineering data sources to develop methods or tools for engineering
design. Meanwhile, there are emerging efforts to mine large scale technical
publication and patent databases to construct engineering-contextualized
semantic network databases, e.g., B-Link and TechNet, to support NLP in
engineering design. On this basis, we recommend future research directions for
the construction and applications of engineering-related semantic networks in
engineering design research and practice.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:36:20 GMT""}]","2020-12-15"
"2012.07061","Jiayi Ji","Jiayi Ji, Yunpeng Luo, Xiaoshuai Sun, Fuhai Chen, Gen Luo, Yongjian
  Wu, Yue Gao, Rongrong Ji","Improving Image Captioning by Leveraging Intra- and Inter-layer Global
  Representation in Transformer Network","Accepted at AAAI 2021 (preprint version)",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Transformer-based architectures have shown great success in image captioning,
where object regions are encoded and then attended into the vectorial
representations to guide the caption decoding. However, such vectorial
representations only contain region-level information without considering the
global information reflecting the entire image, which fails to expand the
capability of complex multi-modal reasoning in image captioning. In this paper,
we introduce a Global Enhanced Transformer (termed GET) to enable the
extraction of a more comprehensive global representation, and then adaptively
guide the decoder to generate high-quality captions. In GET, a Global Enhanced
Encoder is designed for the embedding of the global feature, and a Global
Adaptive Decoder are designed for the guidance of the caption generation. The
former models intra- and inter-layer global representation by taking advantage
of the proposed Global Enhanced Attention and a layer-wise fusion module. The
latter contains a Global Adaptive Controller that can adaptively fuse the
global information into the decoder to guide the caption generation. Extensive
experiments on MS COCO dataset demonstrate the superiority of our GET over many
state-of-the-arts.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:38:58 GMT""}]","2020-12-15"
"2012.07062","Guillaume Avice","G. Avice, A. Belousov, K. A. Farley, S. M. Madzunkov, J. Simcic, D.
  Nikoli\'c, M. R. Darrach, C. Sotin","High-precision measurements of krypton and xenon isotopes with a new
  static-mode Quadrupole Ion Trap Mass Spectrometer","42 pages, 9 figures, 4 tables","Journal of Analytical Atomic Spectrometry 34 (2019) 104-117","10.1039/C8JA00218E",,"physics.ins-det","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Measuring the abundance and isotopic composition of noble gases in planetary
atmospheres can answer fundamental questions in cosmochemistry and comparative
planetology. However, noble gases are rare elements, a feature making their
measurement challenging even on Earth. Furthermore, in space applications,
power consumption, volume and mass constraints on spacecraft instrument
accommodations require the development of compact innovative instruments able
to meet the engineering requirements of the mission while still meeting the
science requirements. Here we demonstrate the ability of the quadrupole ion
trap mass spectrometer (QITMS) developed at the Jet Propulsion Laboratory
(Caltech, Pasadena) to measure low quantities of heavy noble gases (Kr, Xe) in
static operating mode and in the absence of a buffer gas such as helium. The
sensitivity reaches 1E13 cps Torr-1 (about 1011 cps/Pa) of gas (Kr or Xe). The
instrument is able to measure gas in static mode for extended periods of time
(up to 48 h) enabling the acquisition of thousands of isotope ratios per
measurement. Errors on isotope ratios follow predictions of the counting
statistics and the instrument provides reproducible results over several days
of measurements. For example, 1.7E-10 Torr (2.3E-8 Pa) of Kr measured
continuously for 7 hours yielded a 0.6 permil precision on the 86Kr/84Kr ratio.
Measurements of terrestrial and extraterrestrial samples reproduce values from
the literature. A compact instrument based upon the QITMS design would have a
sensitivity high enough to reach the precision on isotope ratios (e.g. better
than 1 percent for 129,131-136Xe/130Xe ratios) necessary for a scientific
payload measuring noble gases collected in the Venus atmosphere.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:53:12 GMT""}]","2020-12-15"
"2012.07063","Willem Gispen","Willem Gispen and Austen Lamacraft","Ground States of Quantum Many Body Lattice Models via Reinforcement
  Learning","Accepted at MSML2021",,,,"quant-ph cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce reinforcement learning (RL) formulations of the problem of
finding the ground state of a many-body quantum mechanical model defined on a
lattice. We show that stoquastic Hamiltonians - those without a sign problem -
have a natural decomposition into stochastic dynamics and a potential
representing a reward function. The mapping to RL is developed for both
continuous and discrete time, based on a generalized Feynman-Kac formula in the
former case and a stochastic representation of the Schr\""odinger equation in
the latter. We discuss the application of this mapping to the neural
representation of quantum states, spelling out the advantages over approaches
based on direct representation of the wavefunction of the system.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:53:59 GMT""},{""version"":""v2"",""created"":""Sun, 11 Apr 2021 11:31:19 GMT""}]","2021-04-13"
"2012.07064","Bowen Hao","Bowen Hao, Jing Zhang, Hongzhi Yin, Cuiping Li and Hong Chen","Pre-Training Graph Neural Networks for Cold-Start Users and Items
  Representation",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cold-start problem is a fundamental challenge for recommendation tasks.
Despite the recent advances on Graph Neural Networks (GNNs) incorporate the
high-order collaborative signal to alleviate the problem, the embeddings of the
cold-start users and items aren't explicitly optimized, and the cold-start
neighbors are not dealt with during the graph convolution in GNNs. This paper
proposes to pre-train a GNN model before applying it for recommendation. Unlike
the goal of recommendation, the pre-training GNN simulates the cold-start
scenarios from the users/items with sufficient interactions and takes the
embedding reconstruction as the pretext task, such that it can directly improve
the embedding quality and can be easily adapted to the new cold-start
users/items. To further reduce the impact from the cold-start neighbors, we
incorporate a self-attention-based meta aggregator to enhance the aggregation
ability of each graph convolution step, and an adaptive neighbor sampler to
select the effective neighbors according to the feedbacks from the pre-training
GNN model. Experiments on three public recommendation datasets show the
superiority of our pre-training GNN model against the original GNN models on
user/item embedding inference and the recommendation task.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:57:12 GMT""}]","2020-12-15"
"2012.07065","Juncheng Liu","Juncheng Liu, Yiwei Wang, Bryan Hooi, Renchi Yang, Xiaokui Xiao","LSCALE: Latent Space Clustering-Based Active Learning for Node
  Classification","ECML-PKDD 2022",,,,"cs.LG cs.SI","http://creativecommons.org/licenses/by/4.0/","  Node classification on graphs is an important task in many practical domains.
It usually requires labels for training, which can be difficult or expensive to
obtain in practice. Given a budget for labelling, active learning aims to
improve performance by carefully choosing which nodes to label. Previous graph
active learning methods learn representations using labelled nodes and select
some unlabelled nodes for label acquisition. However, they do not fully utilize
the representation power present in unlabelled nodes. We argue that the
representation power in unlabelled nodes can be useful for active learning and
for further improving performance of active learning for node classification.
In this paper, we propose a latent space clustering-based active learning
framework for node classification (LSCALE), where we fully utilize the
representation power in both labelled and unlabelled nodes. Specifically, to
select nodes for labelling, our framework uses the K-Medoids clustering
algorithm on a latent space based on a dynamic combination of both unsupervised
features and supervised features. In addition, we design an incremental
clustering module to avoid redundancy between nodes selected at different
steps. Extensive experiments on five datasets show that our proposed framework
LSCALE consistently and significantly outperforms the stateof-the-art
approaches by a large margin.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:59:48 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jul 2022 12:02:52 GMT""}]","2022-07-21"
"2012.07066","Jacques Balayla","Jacques Balayla","Theorems on the Geometric Definition of the Positive Likelihood Ratio
  (LR+)",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  From the fundamental theorem of screening (FTS) we obtain the following
mathematical relationship relaying the pre-test probability of disease $\phi$
to the positive predictive value $\rho(\phi)$ of a screening test:
  $\displaystyle\lim_{\varepsilon \to 2}{\displaystyle
\int_{0}^{1}}{\rho(\phi)d\phi} = 1$
  where $\varepsilon$ is the screening coefficient - the sum of the sensitivity
($a$) and specificity ($b$) parameters of the test in question. However, given
the invariant points on the screening plane, identical values of $\varepsilon$
may yield different shapes of the screening curve since $\varepsilon$ does not
respect traditional commutative properties. In order to compare the performance
between two screening curves with identical $\varepsilon$ values, we derive two
geometric definitions of the positive likelihood ratio (LR+), defined as the
likelihood of a positive test result in patients with the disease divided by
the likelihood of a positive test result in patients without the disease, which
helps distinguish the performance of both screening tests. The first definition
uses the angle $\beta$ created on the vertical axis by the line between the
origin invariant and the prevalence threshold $\phi_e$ such that $LR+ =
\frac{a}{1-b} = cot^2{(\beta)}$. The second definition projects two lines
$(y_1,y_2)$ from any point on the curve to the invariant points on the plane
and defines the LR+ as the ratio of its derivatives $\frac{dy_1}{dx}$ and
$\frac{dy_2}{dx}$. Using the concepts of the prevalence threshold and the
invariant points on the screening plane, the work herein presented provides a
new geometric definition of the positive likelihood ratio (LR+) throughout the
prevalence spectrum and describes a formal measure to compare the performance
of two screening tests whose screening coefficients $\varepsilon$ are equal.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:10:41 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 01:28:16 GMT""},{""version"":""v3"",""created"":""Sun, 10 Oct 2021 16:21:37 GMT""}]","2021-10-12"
"2012.07067","Koji Tasaka","Yoshihiro Takeyama, Koji Tasaka","Supercongruences of multiple harmonic $q$-sums and generalized
  finite/symmetric multiple zeta values","51 pages",,,,"math.NT math.QA","http://creativecommons.org/licenses/by/4.0/","  The Kaneko--Zagier conjecture describes a correspondence between finite
multiple zeta values and symmetric multiple zeta values. Its refined version
has been established by Jarossay, Rosen and Ono--Seki--Yamamoto. In this paper,
we explicate these conjectures through studies of multiple harmonic $q$-sums.
We show that the (generalized) finite/symmetric multiple zeta value are
obtained by taking an algebraic/analytic limit of multiple harmonic $q$-sums.
As applications, new proofs of reversal, duality and cyclic sum formulas for
the generalized finite/symmetric multiple zeta values are given.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:10:53 GMT""},{""version"":""v2"",""created"":""Thu, 17 Feb 2022 23:25:01 GMT""}]","2022-02-21"
"2012.07068","Francesco Mainardi","Alexander Apelblat, Francesco Mainardi","Application of the Efros theorem to the function represented by the
  inverse Laplace transform of $s^{-\mu}\,\exp(-s^\nu)$","19 pages, 1 figure","Symmetry 13, 354 (2021)","10.3390/sym13020354",,"math.CA math-ph math.CV math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using a special case of the Efros theorem which was derived by Wlodarski, and
operational calculus, it was possible to derive many infinite integrals, finite
integrals and integral identities for the function represented by the inverse
Laplace transform. The integral identities are mainly in terms of convolution
integrals with the Mittag-Leffler and Volterra functions. The integrands of
determined integrals include elementary functions (power, exponential,
logarithmic, trigonometric and hyperbolic functions) and the error functions,
the Mittag-Leffler functions and the Volterra functions. Some properties of the
inverse Laplace transform of $s^{-\mu} \exp(-s^\nu)$ with $\mu \ge0$ and
$0<\nu<1$ are presented
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:25:26 GMT""},{""version"":""v2"",""created"":""Tue, 29 Dec 2020 13:19:58 GMT""},{""version"":""v3"",""created"":""Mon, 22 Feb 2021 10:49:59 GMT""}]","2021-02-23"
"2012.07069","Debashis Saha","Chandan Datta, Tanmoy Biswas, Debashis Saha, and Remigiusz Augusiak","Perfect discrimination of quantum measurements using entangled systems","11 pages, 2 figures","New Journal of Physics 23, 043021 (2021)","10.1088/1367-2630/abecaf",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distinguishing physical processes is one of the fundamental problems in
quantum physics. Although distinguishability of quantum preparations and
quantum channels have been studied considerably, distinguishability of quantum
measurements remains largely unexplored. We investigate the problem of
single-shot discrimination of quantum measurements using two strategies, one
based on single quantum systems and the other one based on entangled quantum
systems. First, we formally define both scenarios. We then construct sets of
measurements (including non-projective) in arbitrary finite dimensions that are
perfectly distinguishable within the second scenario using quantum
entanglement, while not in the one based on single quantum systems.
Furthermore, we show that any advantage in measurement discrimination tasks
over single systems is a demonstration of Einstein-Podolsky-Rosen 'quantum
steering'. Alongside, we prove that all pure two-qubit entangled states provide
an advantage in a measurement discrimination task over one-qubit systems.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:30:06 GMT""},{""version"":""v2"",""created"":""Sun, 11 Apr 2021 07:40:41 GMT""}]","2021-04-13"
"2012.07070","Yael Avni","Y. Avni, S. Komura and D. Andelman","Brownian motion of a charged colloid in restricted confinement","10 pages, 7 figures","Phys. Rev. E 103, 042607 (2021)","10.1103/PhysRevE.103.042607",,"cond-mat.soft cond-mat.stat-mech physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Brownian motion of a charged colloid, confined between two
charged walls, for small separation between the colloid and the walls. The
system is embedded in an ionic solution. The combined effect of electrostatic
repulsion and reduced diffusion due to hydrodynamic forces results in a
specific motion in the direction perpendicular to the confining walls. The
apparent diffusion coefficient at short times as well as the diffusion
characteristic time are shown to follow a sigmoid curve as function of a
dimensionless parameter. This parameter depends on the electrostatic properties
and can be controlled by tuning the solution ionic strength. At low ionic
strength, the colloid moves faster and is localized, while at high ionic
strength it moves slower and explores a wider region between the walls,
resulting in a larger diffusion characteristic time.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:31:01 GMT""},{""version"":""v2"",""created"":""Sat, 17 Apr 2021 08:08:30 GMT""}]","2021-04-28"
"2012.07071","Karomat Mirtadjieva","Karomat Mirtadjieva, Kamola Mannapova","The role of dark matter halo in the evolution of the non-stationary disk
  of spiral galaxies","4 pages, one figure",,,,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the problem of the evolution of the disk subsystem
of galaxies in view of the halo. To this end, we have studied the dependence of
the evolution of a non-linearly non-radially disk oscillating in its plane
depending on the basic parameters of the dark matter halo numerically. The dark
matter halo stabilizes the instabilities in the plane of the disk, but
destabilizes its vertical oscillations. The global disk structure is dependent
strongly on the mass and shape of the of dark matter halo. The evolutionary
dependence of the oscillation process of a self-gravitating disk versus the
indicated parameters of the dark matter halo are constructed.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:36:15 GMT""}]","2020-12-15"
"2012.07072","Muhammad Afifi","Mohamed Afifi, Yara Ali, Karim Amer, Mahmoud Shaker, Mohamed Elhelw","Robust Real-Time Pedestrian Detection on Embedded Devices",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detection of pedestrians on embedded devices, such as those on-board of
robots and drones, has many applications including road intersection
monitoring, security, crowd monitoring and surveillance, to name a few.
However, the problem can be challenging due to continuously-changing camera
viewpoint and varying object appearances as well as the need for lightweight
algorithms suitable for embedded systems. This paper proposes a robust
framework for pedestrian detection in many footages. The framework performs
fine and coarse detections on different image regions and exploits temporal and
spatial characteristics to attain enhanced accuracy and real time performance
on embedded boards. The framework uses the Yolo-v3 object detection [1] as its
backbone detector and runs on the Nvidia Jetson TX2 embedded board, however
other detectors and/or boards can be used as well. The performance of the
framework is demonstrated on two established datasets and its achievement of
the second place in CVPR 2019 Embedded Real-Time Inference (ERTI) Challenge.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:43:30 GMT""}]","2020-12-15"
"2012.07073","Hussein Al-Natsheh","Wael Farhan, Muhy Eddin Za'ter, Qusai Abu Obaidah, Hisham al Bataineh,
  Zyad Sober, Hussein T. Al-Natsheh","SPARTA: Speaker Profiling for ARabic TAlk",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper proposes a novel approach to an automatic estimation of three
speaker traits from Arabic speech: gender, emotion, and dialect. After showing
promising results on different text classification tasks, the multi-task
learning (MTL) approach is used in this paper for Arabic speech classification
tasks. The dataset was assembled from six publicly available datasets. First,
The datasets were edited and thoroughly divided into train, development, and
test sets (open to the public), and a benchmark was set for each task and
dataset throughout the paper. Then, three different networks were explored:
Long Short Term Memory (LSTM), Convolutional Neural Network (CNN), and
Fully-Connected Neural Network (FCNN) on five different types of features: two
raw features (MFCC and MEL) and three pre-trained vectors (i-vectors,
d-vectors, and x-vectors). LSTM and CNN networks were implemented using raw
features: MFCC and MEL, where FCNN was explored on the pre-trained vectors
while varying the hyper-parameters of these networks to obtain the best results
for each dataset and task. MTL was evaluated against the single task learning
(STL) approach for the three tasks and six datasets, in which the MTL and
pre-trained vectors almost constantly outperformed STL. All the data and
pre-trained models used in this paper are available and can be acquired by the
public.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:45:01 GMT""}]","2020-12-15"
"2012.07074","Jun Dai","J. Dai, Q. M. Zhang, Y. N. Su, and H. S. Ji","Transverse oscillation of a coronal loop induced by a flare-related jet",,"A&A 646, A12 (2021)","10.1051/0004-6361/202039013",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we report our multi-wavelength observations of the transverse
oscillation of a large scale coronal loop with a length of 350 Mm. The
oscillation was induced by a blowout coronal jet, which was related to a
circular ribbon flare (CRF) in AR 12434 on 2015 October 16. We aim to determine
the physical parameters in the coronal loop, including the Alfven speed and
magnetic field strength. The jet induced kink oscillation was observed in
extreme-ultraviolet (EUV) wavelengths by the Atmospheric Imaging Assembly (AIA)
on board the Solar Dynamics Observatory (SDO). Line of sight magnetograms were
observed by the Helioseismic and Magnetic Imager (HMI) on board SDO. We took
several slices along the loop to assemble time-distance diagrams, and used an
exponentially decaying sine function to fit the decaying oscillation. The
initial amplitude, period, and damping time of kink oscillation were obtained.
Coronal seismology of the kink mode was applied to estimate the Alfven speed
and magnetic field strength in the oscillating loop. In addition, we measured
the magnetic field of the loop through non-linear force free field (NLFFF)
modeling using the flux rope insertion method. The oscillation is most
pronounced in AIA 171 and 131. The oscillation is almost in phase along the
loop with a peak initial amplitude of 13.6 Mm, meaning that the oscillation
belong to the fast standing kink mode. The oscillation lasts for 3.5 cycles
with an average period of 462 s and average damping time of 976 s. The values
of t/P lie in the range of 1.5-2.5. Based on coronal seismology, the Alfven
speed in the oscillating loop is estimated to be 1210 km. Two independent
methods are applied to calculate the magnetic field strength of the loop,
resulting in 30043 G using the coronal seismology and 21123 G using the NLFFF
modeling, respectively.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:49:41 GMT""}]","2021-02-03"
"2012.07075","Adamantia Zampeli","Andronikos Paliathanasis, Adamantia Zampeli, Theodosios
  Christodoulakis, M.T. Mustafa","Quantization of the Szekeres spacetime through generalized symmetries","Prepared for the proceedings of the Fifteenth Marcel Grossmann
  Meeting - MG15",,,,"gr-qc hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the effect of the quantum corrections on the Szekeres spacetime, a
system important for the study of the inhomogeneities of the pre-inflationary
era of the universe. The study is performed in the context of canonical
quantisation in the presence of symmetries. We construct an effective classical
Lagrangian and impose the quantum version of its classical integrals of motion
on the wave function. The interpretational scheme of the quantum solution is
that of Bohmian mechanics, in which one can avoid the unitarity problem of
quantum cosmology. We discuss our results in this context.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:49:53 GMT""}]","2020-12-15"
"2012.07076","Yasuhiro Oki","Yasuhiro Oki","Notes on Rapoport--Zink spaces of Hodge type with parahoric level
  structure","18 pages, comments are welcome",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we treat two questions on Rapoport--Zink spaces of Hodge
type constructed by Hamacher and Kim. One of which is their singularities, and
the other is $p$-adic uniformization of Shimura varieties. More precisely, we
prove that the singularity of a Rapoport--Zink space is controlled by its
asssociated local model, and the basic locus of a Kisin--Pappas integral model
of a Shimura variety is uniformized by the corresponding Rapoport--Zink space.
These results extend the known facts by Rapoport and Zink in the case of PEL
type.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:50:47 GMT""}]","2020-12-15"
"2012.07077","John Groh","John Groh, Kam Arnold, Jessica Avva, Darcy Barron, Kevin T. Crowley,
  Matt Dobbs, Tijmen de Haan, William Holzapfel, Adrian Lee, Lindsay Ng Lowry,
  Joshua Montgomery, Maximiliano Silva-Feaver, Aritoki Suzuki, Nathan Whitehorn","Anomalous Frequency Noise from the Megahertz Channelizing Resonators in
  Frequency-Division Multiplexed Transition Edge Sensor Readout","5 pages, 5 figures, accepted to IEEE Transactions on Applied
  Superconductivity",,"10.1109/TASC.2021.3065283",,"astro-ph.IM cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Superconducting lithographed resonators have a broad range of current and
potential applications in the multiplexed readout of cryogenic detectors. Here,
we focus on LC bandpass filters with resonances in the 1-5 MHz range used in
the transition edge sensor (TES) bolometer readout of the Simons Array cosmic
microwave background (CMB) experiment. In this readout scheme, each detector
signal amplitude-modulates a sinusoidal carrier tone at the resonance frequency
of the detector's accompanying LC filter. Many modulated signals are
transmitted over the same wire pair, and quadrature demodulation recovers the
complex detector signal. We observe a noise in the resonant frequencies of the
LC filters, which presents primarily as a current-dependent noise in the
quadrature component after demodulation. This noise has a rich phenomenology,
bearing many similarities to that of two-level system (TLS) noise observed in
similar resonators in the GHz regime. These similarities suggest a common
physical origin, thereby offering a new regime in which the underlying physics
might be probed. We further describe an observed non-orthogonality between this
noise and the detector responsivities, and present laboratory measurements that
bound the resulting sensitivity penalty expected in the Simons Array. From
these results, we do not anticipate this noise to appreciably affect the
overall Simons Array sensitivity, nor do we expect it to limit future
implementations.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:51:19 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 18:25:29 GMT""}]","2021-06-02"
"2012.07078","Yasuhiro Oki","Yasuhiro Oki","Rapoport--Zink spaces for spinor groups with special maximal parahoric
  level structure","32 pages, continued from ""Notes on Rapoport--Zink spaces of Hodge
  type with parahoric level structure"". Comments are welcome",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we give a concrete description of the underlying reduced
subscheme of the Rapoport--Zink spaces for spinor similitude groups with
special maximal parahoric (and non-hyperspecial) level structure. Moreover, we
give two applications of the above result. One of which is describing the
structure of the basic loci of mod $p$ reductions of Kisin--Pappas integral
models of Shimura varieties for spinor similitude groups with special maximal
parahoric level structure at $p$. The other is constructing a variant of the
result of He, Li and Zhu, which gives a formula on the intersection
multiplicity of the GGP cycles associated codimension $1$ embeddings of
Rapoport--Zink spaces for spinor similitude groups.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:51:23 GMT""}]","2020-12-15"
"2012.07079","Narinder Singh Punn","Narinder Singh Punn, Sonali Agarwal","CHS-Net: A Deep learning approach for hierarchical segmentation of
  COVID-19 infected CT images",,"Neural Processing Letters 2022","10.1007/s11063-022-10785-x",,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  The pandemic of novel SARS-CoV-2 also known as COVID-19 has been spreading
worldwide, causing rampant loss of lives. Medical imaging such as CT, X-ray,
etc., plays a significant role in diagnosing the patients by presenting the
visual representation of the functioning of the organs. However, for any
radiologist analyzing such scans is a tedious and time-consuming task. The
emerging deep learning technologies have displayed its strength in analyzing
such scans to aid in the faster diagnosis of the diseases and viruses such as
COVID-19. In the present article, an automated deep learning based model,
COVID-19 hierarchical segmentation network (CHS-Net) is proposed that functions
as a semantic hierarchical segmenter to identify the COVID-19 infected regions
from lungs contour via CT medical imaging using two cascaded residual attention
inception U-Net (RAIU-Net) models. RAIU-Net comprises of a residual inception
U-Net model with spectral spatial and depth attention network (SSD) that is
developed with the contraction and expansion phases of depthwise separable
convolutions and hybrid pooling (max and spectral pooling) to efficiently
encode and decode the semantic and varying resolution information. The CHS-Net
is trained with the segmentation loss function that is the defined as the
average of binary cross entropy loss and dice loss to penalize false negative
and false positive predictions. The approach is compared with the recently
proposed approaches and evaluated using the standard metrics like accuracy,
precision, specificity, recall, dice coefficient and Jaccard similarity along
with the visualized interpretation of the model prediction with GradCam++ and
uncertainty maps. With extensive trials, it is observed that the proposed
approach outperformed the recently proposed approaches and effectively segments
the COVID-19 infected regions in the lungs.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 15:02:05 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jan 2021 14:21:52 GMT""},{""version"":""v3"",""created"":""Sun, 17 Jan 2021 18:15:12 GMT""},{""version"":""v4"",""created"":""Fri, 30 Apr 2021 11:03:07 GMT""},{""version"":""v5"",""created"":""Sun, 12 Dec 2021 19:25:04 GMT""},{""version"":""v6"",""created"":""Tue, 14 Dec 2021 08:00:50 GMT""},{""version"":""v7"",""created"":""Wed, 29 Dec 2021 15:50:54 GMT""}]","2022-03-29"
"2012.07080","Alessandro Grillo","Alessandro Grillo and Antonio Di Bartolomeo","A current-voltage model for double Schottky barrier devices",,,"10.1002/aelm.202000979",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Schottky barriers are often formed at the semiconductor/metal contacts and
affect the electrical behaviour of semiconductor devices. In particular,
Schottky barriers have been playing a major role in the investigation of the
electrical properties of mono and two-dimensional nanostructured materials,
although their impact on the current-voltage characteristics has been
frequently neglected or misunderstood. In this work, we propose a single
equation to describe the current-voltage characteristics of two-terminal
semiconductor devices with Schottky contacts. We apply the equation to
numerically simulate the electrical behaviour for both ideal and non-ideal
Schottky barriers. The proposed model can be used to directly estimate the
Schottky barrier height and the ideality factor. We apply it to perfectly
reproduce the experimental current-voltage characteristics of ultrathin
molybdenum disulphide or tungsten diselenide nanosheets and tungsten disulphide
nanotubes. The model constitutes a useful tool for the analysis and the
extraction of relevant transport parameters in any two-terminal device with
Schottky contacts.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 15:09:09 GMT""}]","2021-10-18"
"2012.07081","Vladimir Voronin","Sergei N. Nedelko, Vladimir E. Voronin","Energy-driven disorder in the mean field QCD","31 pages, 12 figures","Phys. Rev. D 103, 114021 (2021)","10.1103/PhysRevD.103.114021",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  An impact of the finite size effects on the vacuum free energy density of
full QCD with $N_{\rm f}$ massless flavors in the presence of homogeneous
(anti-)self-dual Abelian background gluon field is studied. The zero
temperature free energy density of the four-dimensional spherical domain is
computed as a function of the background field strength $B$ and domain radius
$R$. Calculation is performed in the one-loop approximation improved by
accounting for mixing of the quark and gluon quasi-zero modes with normal
modes, with the use of the $\zeta$-function regularization. It is indicated
that, under plausible assumption on the character of the mixing, the quantum
correction to the free energy density has a minimum as a function of $B$ and
$R$. Within the mean field approach to QCD vacuum based on domain wall network
representation of the mean field, an existence of the minimum may prevent
infinite growth of individual domain, thus protecting the vacuum from the
long-range ordering, and, hence, serving as the origin of disorder in the
statistical ensemble of domain wall networks, driven by the minimization of the
overall free energy of the dominant gauge field configurations.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 15:11:28 GMT""}]","2021-06-30"
"2012.07082","Margarida Carvalho","Margarida Carvalho, Andrea Lodi, Jo\~ao Pedro Pedroso","Computing Nash equilibria for integer programming games",,"European Journal of Operational Research, Volume 303, Issue 3,
  2022","10.1016/j.ejor.2022.03.048",,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recently defined class of integer programming games (IPG) models
situations where multiple self-interested decision makers interact, with their
strategy sets represented by a finite set of linear constraints together with
integer requirements. Many real-world problems can suitably be fit in this
class, and hence anticipating IPG outcomes is of crucial value for policy
makers and regulators. Nash equilibria have been widely accepted as the
solution concept of a game. Consequently, their computation provides a
reasonable prediction of the games outcome.
  In this paper, we start by showing the computational complexity of deciding
the existence of a Nash equilibrium for an IPG. Then, using sufficient
conditions for their existence, we develop two general algorithmic approaches
that are guaranteed to approximate an equilibrium under mild conditions. We
also showcase how our methodology can be changed to determine other equilibria
definitions. The performance of our methods is analyzed through computational
experiments in a knapsack game, a competitive lot-sizing game, and a kidney
exchange game. To the best of our knowledge, this is the first time that
equilibria computation methods for general integer programming games have been
designed and computationally tested.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 15:14:28 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 01:41:32 GMT""}]","2023-04-25"
"2012.07083","Polina Vytnova","Mark Pollicott and Polina Vytnova","Hausdorff dimension estimates applied to Lagrange and Markov spectra,
  Zaremba theory, and limit sets of Fuchsian groups","53 pages, 7 figures",,,,"math.DS math.NT","http://creativecommons.org/licenses/by/4.0/","  In this note we will describe a simple and practical approach to get rigorous
bounds on the Hausdorff dimension of limits sets for some one dimensional
Markov iterated function schemes. The general problem has attracted
considerable attention, but we are particularly concerned with the role of the
value of the Hausdorff dimension in solving conjectures and problems in other
areas red of mathematics. As our first application we confirm, and often
strengthen, conjectures on the difference of the Lagrange and Markov spectra in
Diophantine analysis, which appear in the work of Matheus and Moreira
arXiv:1803.01230. As a second application we (re-)validate and improve
estimates connected with the Zaremba conjecture in number theory, used in the
work of Bourgain-Kontorovich arXiv:1107.3776v2, Huang arXiv:1310.3772v4 and Kan
arXiv:1604.04884. As a third more geometric application, we rigorously bound
the bottom of the spectrum of the Laplacian for infinite area surfaces, as
illustrated by an example studied by McMullen. In all approaches to estimating
the dimension of limit sets there are questions about the efficiency of the
algorithm, the computational effort required and the rigour of the bounds. The
approach we use has the virtues of being simple and efficient and we present it
in section 3 in a way that is straightforward to implement.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 15:17:07 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 20:05:48 GMT""},{""version"":""v3"",""created"":""Mon, 17 Jan 2022 14:57:05 GMT""}]","2022-01-19"
"2012.07084","Ethan Sussman","Ethan Sussman","The microlocal irregularity of Gaussian noise","37 pages. Improved figure","Studia Math. 266 (2022) 1--54","10.4064/sm210105-30-12",,"math.SP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of random Fourier series, linear combinations of trigonometric
functions whose coefficients are independent (in our case Gaussian) random
variables with polynomially bounded means and standard deviations, dates back
to Norbert Wiener in one of the original constructions of Brownian motion. A
geometric generalization -- relevant e.g.\ to Euclidean quantum field theory
with an infrared cutoff -- is the study of random Gaussian linear combinations
of the eigenfunctions of the Laplace-Beltrami operator on an arbitrary compact
Riemannian manifold $(M,g)$, Gaussian noise $\Phi$.
  I will prove that, when our random coefficients are independent Gaussians
whose standard deviations obey polynomial asymptotics and whose means obey a
corresponding polynomial upper bound, the resultant random
$\mathscr{H}^s$-wavefront set $\operatorname{WF}^s(\Phi)$ (defined as a subset
of the cosphere bundle $\mathbb{S}^*M$) is either almost surely empty or almost
surely the entirety of $\mathbb{S}^*M$, depending on $s \in \mathbb{R}$, and we
will compute the threshold $s$ and the behavior of the wavefront set at it.
Consequently, the random $C^\infty$-wavefront set $\operatorname{WF}(\Phi)$ is
almost surely the entirety of the cosphere bundle. The method of proof is as
follows: using Sazonov's theorem and its converse, it suffices to understand
which compositions of microlocal cutoffs and inclusions of $L^2$-based
fractional order Sobolev spaces are Hilbert-Schmidt (HS), and the answer
follows from general facts about the HS-norms of the elements of the
pseudodifferential calculus of Kohn and Nirenberg.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 15:24:30 GMT""},{""version"":""v2"",""created"":""Fri, 7 Jan 2022 12:19:54 GMT""},{""version"":""v3"",""created"":""Thu, 6 Oct 2022 23:14:44 GMT""},{""version"":""v4"",""created"":""Sun, 8 Jan 2023 21:09:53 GMT""}]","2023-01-10"
"2012.07085","Mattia Manucci","Nicola Guglielmi, Maria L\'opez-Fern\'andez, Mattia Manucci","Pseudospectral roaming contour integral methods for convection-diffusion
  equations",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We generalize ideas in the recent literature and develop new ones in order to
propose a general class of contour integral methods for linear
convection-diffusion PDEs and in particular for those arising in finance. These
methods aim to provide a numerical approximation of the solution by computing
its inverse Laplace transform. The choice of the integration contour is
determined by the computation of a few suitably weighted pseudo-spectral level
sets of the leading operator of the equation. Parabolic and hyperbolic profiles
proposed in the literature are investigated and compared to the elliptic
contour originally proposed by Guglielmi, L\'opez-Fern\'andez and Nino. In
summary, the article
  (i) provides a comparison among three different integration profiles;
  (ii) proposes a new fast pseudospectral roaming method;
  (iii) optimizes the selection of time windows on which one may arbitrarily
approximate the solution by no extra computational cost with respect to the
case of a fixed time instant;
  (iv) focuses extensively on computational aspects and it is the reference of
the MATLAB code https://github.com/MattiaManucci/Contour_Integral_Methods.git,
where all algorithms described here are implemented.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 15:37:39 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 14:12:40 GMT""}]","2021-05-31"
"2012.07086","Wenqiang Zhang","Wenqiang Zhang, Jiemin Fang, Xinggang Wang, Wenyu Liu","EfficientPose: Efficient Human Pose Estimation with Neural Architecture
  Search",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human pose estimation from image and video is a vital task in many multimedia
applications. Previous methods achieve great performance but rarely take
efficiency into consideration, which makes it difficult to implement the
networks on resource-constrained devices. Nowadays real-time multimedia
applications call for more efficient models for better interactions. Moreover,
most deep neural networks for pose estimation directly reuse the networks
designed for image classification as the backbone, which are not yet optimized
for the pose estimation task. In this paper, we propose an efficient framework
targeted at human pose estimation including two parts, the efficient backbone
and the efficient head. By implementing the differentiable neural architecture
search method, we customize the backbone network design for pose estimation and
reduce the computation cost with negligible accuracy degradation. For the
efficient head, we slim the transposed convolutions and propose a spatial
information correction module to promote the performance of the final
prediction. In experiments, we evaluate our networks on the MPII and COCO
datasets. Our smallest model has only 0.65 GFLOPs with 88.1% PCKh@0.5 on MPII
and our large model has only 2 GFLOPs while its accuracy is competitive with
the state-of-the-art large model, i.e., HRNet with 9.5 GFLOPs.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 15:38:38 GMT""}]","2020-12-15"
"2012.07087","Chantal Valeriani","Jose Martin, Raul Martinez, Lachlan C. Alexander, Angel Luis Diez,
  Dirk G. A. L. Aarts, Francisco Alarcon, Jorge Ramirez, and Chantal Valeriani","Characterization of MIPS in a suspension of repulsive Active Brownian
  Particles through dynamical features",,"Journal of Chemical Physics, 154, 164901 (2021)","10.1063/5.0040141",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  The two-dimensional Active Brownian Particles system is meant to be composed
of hard disks, that show excluded volume interactions, usually simulated via
molecular dynamics using pure repulsive potentials. We show that the softness
of the chosen potential plays a role in the result of the simulation, focusing
on the case of the emergence of Motility Induced Phase Separation. In a pure
hard-sphere system with no traslational diffusion,the phase diagram should be
completely determined by their density and P\'eclet number. However, we have
found two additional effects that affect the phase diagram in the ABP model we
simulate: the relative strength of the traslational diffusion compared to the
propulsion term and the overlapping of the particles. As we show, the second
effect can be strongly mitigated if we use, instead of the standard
Weeks-Chandler- Andersen potential, a harder one, the pseudo-hard spheres
potential. Moreover, in determining the boundary of our phase space, we have
tried different approaches to detect MIPS and concluded that observing
dynamical features, via the non-Gaussian parameter, is more efficient than
observing structural ones, via the local density distribution function. We also
demonstrate that the Vogel-Fulcher equation successfully reproduces the decay
of the diffusion as a function of density, except for very high density cases.
Thus, the ABP system behaves similarly to a fragile glass in this regard.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 15:40:10 GMT""},{""version"":""v2"",""created"":""Mon, 26 Apr 2021 15:47:20 GMT""}]","2021-04-27"
"2012.07835","C\u{a}lin-\c{S}erban B\u{a}rbat","C\v{a}lin-\c{S}erban B\v{a}rbat","The Liouville line element and the energy of the diagonals",,,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this work I show that in each rectangle formed by the parameter curves on
a Liouville surface the energies of the main diagonals are equal. This result
extends naturally to n-dimensional Liouville manifolds.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 08:34:21 GMT""}]","2020-12-16"
"2012.07836","Danko Georgiev","Danko D. Georgiev","Quantum information theoretic approach to the mind-brain problem","27 pages, 6 figures","Progress in Biophysics and Molecular Biology 2020; 158: 16-32","10.1016/j.pbiomolbio.2020.08.002",,"q-bio.NC quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The brain is composed of electrically excitable neuronal networks regulated
by the activity of voltage-gated ion channels. Further portraying the molecular
composition of the brain, however, will not reveal anything remotely
reminiscent of a feeling, a sensation or a conscious experience. In classical
physics, addressing the mind-brain problem is a formidable task because no
physical mechanism is able to explain how the brain generates the unobservable,
inner psychological world of conscious experiences and how in turn those
conscious experiences steer the underlying brain processes toward desired
behavior. Yet, this setback does not establish that consciousness is
non-physical. Modern quantum physics affirms the interplay between two types of
physical entities in Hilbert space: unobservable quantum states, which are
vectors describing what exists in the physical world, and quantum observables,
which are operators describing what can be observed in quantum measurements.
Quantum no-go theorems further provide a framework for studying quantum brain
dynamics, which has to be governed by a physically admissible Hamiltonian.
Comprising consciousness of unobservable quantum information integrated in
quantum brain states explains the origin of the inner privacy of conscious
experiences and revisits the dynamic timescale of conscious processes to
picosecond conformational transitions of neural biomolecules. The observable
brain is then an objective construction created from classical bits of
information, which are bound by Holevo's theorem, and obtained through the
measurement of quantum brain observables. Thus, quantum information theory
clarifies the distinction between the unobservable mind and the observable
brain, and supports a solid physical foundation for consciousness research.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:07:33 GMT""}]","2020-12-16"
"2012.08310","Mohammad Reza Rahmati","Mohammad Reza Rahmati, Gerardo Flores","On finite generation of fiber ring of invariant jet differentials",,,,,"math.RT","http://creativecommons.org/licenses/by/4.0/","  We prove that the fiber ring of the space of invariant jet differentials of a
projective manifold is finitely generated on the regular locus. Berczi-Kirwan
has partially worked out the question in \cite{BK}; however, our method is
different and complementary. The analytic automorphism group of regular
$k$-jets of holomorphic curves on a projective variety $X$ is a non-reductive
subgroup of the general linear group $GL_k \mathbb{C}$. In this case, the
Chevalley theorem on the invariant polynomials in the fiber rings fails in
general. Thus, the analysis of Cartan subalgebras of the Lie algebra and its
Weyl group requires different methods. We employ some techniques of algebraic
Lie groups (not necessarily reductive) together with basic results obtained in
\cite{BK} to prove the finite generation of the stalk ring at a regular point.
We prove that the fibre ring of the space of invariant jet differentials of a
projective manifold is finitely generated on the regular locus. The question
has been partially worked out by Berczi-Kirwan in \cite{BK}, however our method
is different and complementary. The analytic automorphism group of regular
$k$-jets of holomorphic curves on a projective variety $X$ is a non-reductive
subgroup of the general linear group $GL_k \mathbb{C}$. In this case the
Chevalley theorem on the invariant polynomials in the fiber rings fails in
general. Thus the analysis of Cartan subalgebras of the Lie algebra and its
Weyl group requires extra methods. We employ some methods of algebraic Lie
groups (not necessarily reductive) together with basic results obtained in
\cite{BK} to prove the finite generation of the stalk ring at a regular point.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:55:57 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 19:05:38 GMT""},{""version"":""v3"",""created"":""Fri, 27 Aug 2021 00:56:17 GMT""},{""version"":""v4"",""created"":""Thu, 20 Jan 2022 02:19:26 GMT""}]","2022-01-21"
"2012.08314","Shimry Haviv","Shimry Haviv, Natali Revivo, Nimrod Kruger, Assaf Manor, Bagrat
  Khachatryan, Michael Shustov, and Carmel Rotschild","Luminescent solar power: PV/thermal hybrid electricity generation for
  cost effective dispatchable solar energy",,,"10.1021/acsami.0c08185",,"physics.app-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  The challenge in solar energy today is not the cost of photovoltaic (PV)
electricity generation, already competing with fossil fuel prices, but rather
utility-scale energy storage and flexibility in supply. Low-cost thermal energy
storage (TES) exists but relies on expensive heat engines. Here, we introduce
the concept of luminescent solar power (LSP), where sunlight is absorbed in a
photoluminescent (PL) absorber, followed by red-shifted PL emission matched to
an adjacent PV cell's band-edge. This way the PV cell operates nearly as
efficiently as under direct illumination, but with minimal excessive heat. The
PL-absorber temperature rises due to thermalization, allowing it to store the
excessive heat, which can later be converted into electricity. Tailored
luminescent materials that support an additional 1.5kWh PV-electricity for
every 1 kWh of (virtual) heat engine-electricity, with a dynamic shift between
the two sources are experimentally demonstrated. Such an ideal hybrid system
may lead to a potential reduction in the cost of electricity for a base-load
solution.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 12:13:20 GMT""}]","2020-12-16"
"2012.08316","Hooman Moradpour","H. Moradpour, A. H. Ziaie, C. Corda","Tsallis uncertainty","Accepted version by EPL",,"10.1209/0295-5075/134/20003","134, 20003 (2021)","gr-qc","http://creativecommons.org/licenses/by/4.0/","  It has been recently shown that the Bekenstein entropy bound is not respected
by the systems satisfying modified forms of Heisenberg uncertainty principle
(HUP) including the generalized and extended uncertainty principles, or even
their combinations. On the other, the use of generalized entropies, which
differ from Bekenstein entropy, in describing gravity and related topics
signals us to different equipartition expressions compared to the usual one. In
that way, The mathematical form of an equipartition theorem can be related to
the algebraic expression of a particular entropy, different from the standard
Bekenstein entropy, initially chosen to describe the black hole event horizon,
see E. M. C. Abreu et al., MPLA 32, 2050266 (2020). Motivated by these works,
we address three new uncertainty principles leading to recently introduced
generalized entropies. In addition, the corresponding energy-time uncertainty
relations and Unruh temperatures are also calculated. As a result, it seems
that systems described by generalized entropies, such as those of Tsallis, do
not necessarily meet HUP and may satisfy modified forms of HUP.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 06:05:13 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 05:23:50 GMT""}]","2021-08-11"
"2012.08317","Huahong Zhang","Huahong Zhang and Ipek Oguz","Multiple Sclerosis Lesion Segmentation -- A Survey of Supervised
  CNN-Based Methods","Accepted by BrainLes 2020",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lesion segmentation is a core task for quantitative analysis of MRI scans of
Multiple Sclerosis patients. The recent success of deep learning techniques in
a variety of medical image analysis applications has renewed community interest
in this challenging problem and led to a burst of activity for new algorithm
development. In this survey, we investigate the supervised CNN-based methods
for MS lesion segmentation. We decouple these reviewed works into their
algorithmic components and discuss each separately. For methods that provide
evaluations on public benchmark datasets, we report comparisons between their
results.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 19:05:41 GMT""},{""version"":""v2"",""created"":""Sat, 26 Dec 2020 23:54:04 GMT""}]","2020-12-29"
"2012.08318","Jafar Majidpour","Jafar Majidpour and Hiwa Hasanzadeh","Application of deep learning to enhance the accuracy of intrusion
  detection in modern computer networks","12 pages",,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Application of deep learning to enhance the accuracy of intrusion detection
in modern computer networks were studied in this paper. The identification of
attacks in computer networks is divided in to two categories of intrusion
detection and anomaly detection in terms of the information used in the
learning phase. Intrusion detection uses both routine traffic and attack
traffic. Abnormal detection methods attempt to model the normal behavior of the
system, and any incident that violates this model is considered to be a
suspicious behavior. For example, if the web server, which is usually passive,
tries to There are many addresses that are likely to be infected with the worm.
The abnormal diagnostic methods are Statistical models, Secure system approach,
Review protocol, Check files, Create White list, Neural Networks, Genetic
Algorithm, Vector Machines, decision tree. Our results have demonstrated that
our approach offers high levels of accuracy, precision and recall together with
reduced training time. In our future work, the first avenue of exploration for
improvement will be to assess and extend the capability of our model to handle
zero-day attacks.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 07:21:43 GMT""}]","2020-12-16"
"2012.08974","Abir De","Indradyumna Roy, Abir De, Soumen Chakrabarti","Adversarial Permutation Guided Node Representations for Link Prediction","Rectified an error in evaluation in earlier 60-40 splits",,,,"cs.SI cs.LG physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After observing a snapshot of a social network, a link prediction (LP)
algorithm identifies node pairs between which new edges will likely materialize
in future. Most LP algorithms estimate a score for currently non-neighboring
node pairs, and rank them by this score. Recent LP systems compute this score
by comparing dense, low dimensional vector representations of nodes. Graph
neural networks (GNNs), in particular graph convolutional networks (GCNs), are
popular examples. For two nodes to be meaningfully compared, their embeddings
should be indifferent to reordering of their neighbors. GNNs typically use
simple, symmetric set aggregators to ensure this property, but this design
decision has been shown to produce representations with limited expressive
power. Sequence encoders are more expressive, but are permutation sensitive by
design. Recent efforts to overcome this dilemma turn out to be unsatisfactory
for LP tasks. In response, we propose PermGNN, which aggregates neighbor
features using a recurrent, order-sensitive aggregator and directly minimizes
an LP loss while it is `attacked' by adversarial generator of neighbor
permutations. By design, PermGNN{} has more expressive power compared to
earlier symmetric aggregators. Next, we devise an optimization framework to map
PermGNN's node embeddings to a suitable locality-sensitive hash, which speeds
up reporting the top-$K$ most likely edges for the LP task. Our experiments on
diverse datasets show that \our outperforms several state-of-the-art link
predictors by a significant margin, and can predict the most likely edges fast.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 03:52:25 GMT""},{""version"":""v2"",""created"":""Sun, 28 Mar 2021 04:13:23 GMT""}]","2021-03-30"
"2012.09111","Bo Lin","Bo Lin, Qianxiao Li, and Weiqing Ren","A Data Driven Method for Computing Quasipotentials",,,,,"math.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quasipotential is a natural generalization of the concept of energy
functions to non-equilibrium systems. In the analysis of rare events in
stochastic dynamics, it plays a central role in characterizing the statistics
of transition events and the likely transition paths. However, computing the
quasipotential is challenging, especially in high dimensional dynamical systems
where a global landscape is sought. Traditional methods based on the dynamic
programming principle or path space minimization tend to suffer from the curse
of dimensionality. In this paper, we propose a simple and efficient machine
learning method to resolve this problem. The key idea is to learn an orthogonal
decomposition of the vector field that drives the dynamics, from which one can
identify the quasipotential. We demonstrate on various example systems that our
method can effectively compute quasipotential landscapes without requiring
spatial discretization or solving path-space optimization problems. Moreover,
the method is purely data driven in the sense that only observed trajectories
of the dynamics are required for the computation of the quasipotential. These
properties make it a promising method to enable the general application of
quasipotential analysis to dynamical systems away from equilibrium.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 02:32:49 GMT""}]","2020-12-17"
"2012.09604","Luis Anchordoqui","Alexandra D Bloshenko, Jasmin M. Robinson, Rafael A. Colon, and Luis
  A. Anchordoqui","Health threat from cosmic radiation during a manned mission to Mars","In Proceedings of the 37th International Cosmic Ray Conference
  ICRC2021, Berlin","PoS (ICRC2021) 1317",,,"physics.pop-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cosmic radiation is a critical factor for astronauts' safety in the context
of evaluating the prospect of future space exploration. The Radiation
Assessment Detector (RAD) on board the Curiosity Rover launched by the Mars
Scientific Laboratory mission collected valuable data to model the energetic
particle radiation environment inside a spacecraft during travel from Earth to
Mars, and is currently doing the same on the surface of Mars itself. The
Martian Radiation Experiment (MARIE) on board the Mars Odyssey satellite
provides estimates of the absorbed radiation dose in the Martian orbit, which
are predicted to be similar to the radiation dose on Mars' surface. In
combination, these data provide a reliable assessment of the radiation hazards
for a manned mission to Mars. Using data from RAD and MARIE we reexamine the
risks for a crew on a manned flight to Mars and discuss recent developments in
space exploration.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 14:33:44 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jul 2021 12:06:56 GMT""}]","2021-07-06"
"2012.09605","Guruprasad Raghavan","Guruprasad Raghavan, Matt Thomson","Sparsifying networks by traversing Geodesics","5 pages; Presented work at NeurIPS 2020 Workshop (DiffGeo4DL). arXiv
  admin note: text overlap with arXiv:2005.11603",,,,"cs.LG cs.NE math.DG","http://creativecommons.org/licenses/by/4.0/","  The geometry of weight spaces and functional manifolds of neural networks
play an important role towards 'understanding' the intricacies of ML. In this
paper, we attempt to solve certain open questions in ML, by viewing them
through the lens of geometry, ultimately relating it to the discovery of points
or paths of equivalent function in these spaces. We propose a mathematical
framework to evaluate geodesics in the functional space, to find
high-performance paths from a dense network to its sparser counterpart. Our
results are obtained on VGG-11 trained on CIFAR-10 and MLP's trained on MNIST.
Broadly, we demonstrate that the framework is general, and can be applied to a
wide variety of problems, ranging from sparsification to alleviating
catastrophic forgetting.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 21:39:19 GMT""}]","2020-12-18"
"2012.11309","Louis Omenyi Dr","Louis Omenyi and McSylvester Omaba","Gegenbauer kernel filtration on the unit hypersphere",,,,,"math.CA math.AP","http://creativecommons.org/licenses/by/4.0/","  Filtration of quantifiable objects by smoothing kernels on Riemannian
manifolds for visualisation is an ongoing research. However, using common
filters created for linear domains on manifolds with non-Euclidean topologies
can yield misleading results. While there is a lot of ongoing research on
convolution of quantifiable functions with smoothing kernels on the lower
dimensional manifolds, higher-dimensional problems particularly pose a
challenge. One important generalization of lower dimensional compact Riemannian
manifolds is the unit hypersphere. In this paper, we derive explicit forms of
convolution formulae for Gegenbauer kernel filtration on the surface of unit
hypersphere. We prove that the Gegebauer filtration is the limit of a sequence
of finite linear combinations of the hyperspherical Legendre harmonics, among
other results.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 21:10:06 GMT""}]","2020-12-22"
"2012.11338","Ricardo Gallego Torrom\'e","Ricardo Gallego Torrom\'e","Average of geometric structures in Finsler spaces with Lorentzian
  signature","11 pages, no figures; Acepted in International Journal of Geometric
  Methods in Modern Physics",,"10.1142/S0219887821501073",,"math.DG gr-qc math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given the class of Finsler spaces with Lorentzian signature $(M,L)$ on a
manifold $M$ endowed with a timelike vector field $\mathcal{X}$ satisfying
$g_{(x,y)}(\mathcal{X},\mathcal{X})<0$ at any point $(x,y)$ of the slit tangent
bundle, a pseudo-Riemannian metric defined on $M$ of signature $n-1$ is
associated to the fundamental tensor $g$. Furthermore, an affine, torsion free
connection is associated to the Chern connection determined by $L$. The
definition of the average connection does not make use of $\mathcal{X}$.
Therefore, there is no direct relation between these two averaged objects.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 13:46:13 GMT""},{""version"":""v2"",""created"":""Sat, 20 Feb 2021 08:25:49 GMT""}]","2021-03-09"
"2012.12199","Yasuhito Tanaka","Yasuhito Tanaka","Involuntary unemployment in overlapping generations model due to
  instability of the economy",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The existence of involuntary unemployment advocated by J. M. Keynes is a very
important problem of the modern economic theory. Using a three-generations
overlapping generations model, we show that the existence of involuntary
unemployment is due to the instability of the economy. Instability of the
economy is the instability of the difference equation about the equilibrium
price around the full-employment equilibrium, which means that a fall in the
nominal wage rate caused by the presence of involuntary unemployment further
reduces employment. This instability is due to the negative real balance effect
that occurs when consumers' net savings (the difference between savings and
pensions) are smaller than their debt multiplied by the marginal propensity to
consume from childhood consumption.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 09:23:09 GMT""}]","2020-12-23"
"2101.03895","Xiang Lan","Zhaowei Zhu, Xiang Lan, Tingting Zhao, Yangming Guo, Pipin Kojodjojo,
  Zhuoyang Xu, Zhuo Liu, Siqi Liu, Han Wang, Xingzhi Sun, Mengling Feng","Identification of 27 abnormalities from multi-lead ECG signals: An
  ensembled Se-ResNet framework with Sign Loss function",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cardiovascular disease is a major threat to health and one of the primary
causes of death globally. The 12-lead ECG is a cheap and commonly accessible
tool to identify cardiac abnormalities. Early and accurate diagnosis will allow
early treatment and intervention to prevent severe complications of
cardiovascular disease. In the PhysioNet/Computing in Cardiology Challenge
2020, our objective is to develop an algorithm that automatically identifies 27
ECG abnormalities from 12-lead ECG recordings.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 17:16:02 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jan 2021 04:46:56 GMT""}]","2021-01-13"
"2102.00962","Mohd Aman","Mohd Aman and Bushra Miftah","A transition of shared mobility in metro cities; a challenge post Covid
  19 lockdown","17 pages, 9 figures, 1 table",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This chapter is written for the welfare of the society, questioning and
enlightening the effects of the increment or decrement in the percentage of
quality of air causing pollution due to the rise in the traffic post lockdown
due to COVID 19 in metro cities, specifically in Delhi. In this chapter, we
address the question about people's preference in moving in the shared taxis to
their workplaces or their reluctance and denial of the idea of moving in the
shared vehicle because of the fear of getting infected. The sensitivity of the
situation will compel the people to move in a single occupied vehicle (SOV).
The rise in the number of vehicles on the roads will result in traffic jams and
different kinds of pollution where people battling with the pandemic will
inevitably get exposed to other health related issues. We use a BPR (Bureau of
Public Roads) model to combat this issue endangering the environment and public
health. We exploit the BPR function to relate average travel time to the
estimated number of commuters travelling by car. We collect mode share data
from the NITI Ayog, the State Resource Centre and other authentic sources,
which gives unique figures of the impact of shared mobility in India and how,
in its absence, various sectors will get affected. Using the given data and the
BPR, we evaluate increased vehicle volumes on the road if different portions of
transit and carpool users switch to single occupancy vehicles and its effect on
multiple other factors. Based on the study of densely populated city, Delhi, we
predict that cities with significant transit ridership are at risk for extreme
traffic and pollution unless transit systems can resume safe with effective
protocols.
","[{""version"":""v1"",""created"":""Sun, 13 Dec 2020 15:56:55 GMT""}]","2021-02-02"
