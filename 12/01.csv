"2011.14932","S\'ebastien Salmon Dr","S\'ebastien Salmon, Val\'erie Van Grootel, Ga\""el Buldgen,
  Marc-Antoine Dupret, Patrick Eggenberger","Reinvestigating $\alpha$ Cen AB in light of asteroseismic forward and
  inverse methods","16 pages, 8 figures, accepted for publication in Astronomy and
  Astrophysics",,"10.1051/0004-6361/201937174",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The $\alpha$ Cen stellar system is the closest neighbour to our Sun. Its main
component is a binary composed of two main-sequence stars, one more massive
than the Sun and one less massive. The system's bright magnitude led to a
wealth of astronomical observations over a long period, making it an appealing
testbed for stellar physics. In particular, detection of stellar pulsations in
both $\alpha$ Cen A and B has revealed the potential of asteroseismology for
determining its fundamental stellar parameters. Asteroseismic studies have also
focused on the presence of a convective core in the A component, but as yet
without definitive confirmation. Progress in the determination of solar surface
abundances and stellar opacities have yielded new input for stellar theoretical
models. We investigate their impact on a reference system such as $\alpha$ Cen
AB. We seek to confirm the presence of a convective core in $\alpha$ Cen A by
analysing the role of different stellar physics and the potential of
asteroseismic inverse methods. We present a new series of asteroseismic
calibrations carried out using forward approach modelling and including updated
chemical mixture and opacities in the models. We then complement our analysis
with help of recent asteroseismic diagnostic tools based on inverse methods
developed for solar-like stars. The inclusion of an updated chemical mixture --
that is less metal-rich -- appears to reduce the predicted asteroseismic masses
of each component. Neither classical asteroseismic indicators such as frequency
ratios, nor asteroseismic inversions favour the presence of a convective core
in $\alpha$ Cen A. The quality of the observational seismic dataset is the main
limiting factor to settle the issue. Implementing new observing strategies to
improve the precision on the pulsation frequencies would certainly refine the
outcome of asteroseismology for this binary system.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:00:18 GMT""}]","2021-02-10"
"2011.14935","Hong Ling","Hong Y. Ling and Ben Kain","Selection Rule for Topological Amplifiers in Bogoliubov de Gennes
  Systems","12 pages and 3 figures. q = 0.2t_1 in the caption of fig. 1 in our
  published paper [Phys. Rev. A 104, 013305 (2021)] has been changed to the
  correct one, q = 0.4t_1","Phys. Rev. A 104, 013305 (2021)","10.1103/PhysRevA.104.013305",,"cond-mat.quant-gas cond-mat.mes-hall quant-ph","http://creativecommons.org/licenses/by/4.0/","  Dynamical instability is an inherent feature of bosonic systems described by
the Bogoliubov de Geenes (BdG) Hamiltonian. Since it causes the BdG system to
collapse, it is generally thought that it should be avoided. Recently, there
has been much effort to harness this instability for the benefit of creating a
topological amplifier with stable bulk bands but unstable edge modes which can
be populated at an exponentially fast rate. We present a theorem for
determining the stability of states with energies sufficiently away from zero,
in terms of an unconventional commutator between the number conserving part and
number nonconserving part of the BdG Hamiltonian. We apply the theorem to a
generalization of a model from Galilo et al. [Phys. Rev. Lett, 115,
245302(2015)] for creating a topological amplifier in an interacting spin-1
atom system in a honeycomb lattice through a quench process. We use this model
to illustrate how the vanishing of the unconventional commutator selects the
symmetries for a system so that its bulk states are stable against (weak)
pairing interactions. We find that as long as time reversal symmetry is
preserved, our system can act like a topological amplifier, even in the
presence of an onsite staggered potential which breaks the inversion symmetry.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:01:27 GMT""},{""version"":""v2"",""created"":""Sat, 6 Mar 2021 01:18:14 GMT""},{""version"":""v3"",""created"":""Fri, 20 Aug 2021 17:51:25 GMT""}]","2021-08-23"
"2011.14936","Yi Wang","Yi Wang, Zhen-Peng Bian, Yunhao Zhou, Lap-Pui Chau","Rethinking and Designing a High-performing Automatic License Plate
  Recognition Approach","13 pages. Accepted for Publication at IEEE Transactions on
  Intelligent Transportation Systems",,"10.1109/TITS.2021.3087158",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a real-time and accurate automatic license plate
recognition (ALPR) approach. Our study illustrates the outstanding design of
ALPR with four insights: (1) the resampling-based cascaded framework is
beneficial to both speed and accuracy; (2) the highly efficient license plate
recognition should abundant additional character segmentation and recurrent
neural network (RNN), but adopt a plain convolutional neural network (CNN); (3)
in the case of CNN, taking advantage of vertex information on license plates
improves the recognition performance; and (4) the weight-sharing character
classifier addresses the lack of training images in small-scale datasets. Based
on these insights, we propose a novel ALPR approach, termed VSNet.
Specifically, VSNet includes two CNNs, i.e., VertexNet for license plate
detection and SCR-Net for license plate recognition, integrated in a
resampling-based cascaded manner. In VertexNet, we propose an efficient
integration block to extract the spatial features of license plates. With
vertex supervisory information, we propose a vertex-estimation branch in
VertexNet such that license plates can be rectified as the input images of
SCR-Net. In SCR-Net, we introduce a horizontal encoding technique for
left-to-right feature extraction and propose a weight-sharing classifier for
character recognition. Experimental results show that the proposed VSNet
outperforms state-of-the-art methods by more than 50% relative improvement on
error rate, achieving > 99% recognition accuracy on CCPD and AOLP datasets with
149 FPS inference speed. Moreover, our method illustrates an outstanding
generalization capability when evaluated on the unseen PKUData and CLPD
datasets.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:03:57 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jun 2021 07:05:00 GMT""}]","2021-06-18"
"2011.14937","Simon Tindemans","Julian N. Betge, Barbera Droste, Jacco Heres, Simon H. Tindemans","Efficient Assessment of Electricity Distribution Network Adequacy with
  the Cross-Entropy Method",,"2021 IEEE Madrid PowerTech","10.1109/PowerTech46648.2021.9494891",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identifying future congestion points in electricity distribution networks is
an important challenge distribution system operators face. A proven approach
for addressing this challenge is to assess distribution grid adequacy using
probabilistic models of future demand. However, computational cost can become a
severe challenge when evaluating large probabilistic electricity demand
forecasting models with long forecasting horizons. In this paper, Monte Carlo
methods are developed to increase the computational efficiency of obtaining
asset overload probabilities from a bottom-up stochastic demand model.
Cross-entropy optimised importance sampling is contrasted with conventional
Monte Carlo sampling. Benchmark results of the proposed methods suggest that
the importance sampling-based methods introduced in this work are suitable for
estimating rare overload probabilities for assets with a small number of
customers.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:04:33 GMT""},{""version"":""v2"",""created"":""Sat, 17 Apr 2021 12:26:06 GMT""}]","2022-07-12"
"2011.14938","Chengcheng Yang","Chengcheng Yang","A triangulation of semi-algebraic sets concerning an analytical
  condition for shortest-length curves",,,,,"math.AG math.CA","http://creativecommons.org/licenses/by/4.0/","  This paper concerns an analytical stratification question of real algebraic
and semi-algebraic sets. For Whitney's stratification in 1957, it partitions a
real algebraic set into partial algebraic manifolds\cite{W}. In 1975 Hironaka
reproved that a real algebraic set is triangulable and also generalized it to
semi-algebraic sets, following the idea of Lojasiewicz's triangulation of
semi-analytic sets in 1964. Following their examples and wondering how geometry
looks like locally. this paper tries to come up with a stratification, in
particular a cell decomposition, such that it satisfies the following
analytical property. Given any shortest curve between two points in a real
algebraic or semi-algebraic set, it interacts each cell (or simplex) at most
finitely many times.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:04:39 GMT""}]","2020-12-01"
"2011.14939","Stephan Scholz","Stephan Scholz, Lothar Berger","Modeling of a multiple source heating plate","11 pages, 6 figures",,,,"cs.CE cs.SY eess.SY","http://creativecommons.org/licenses/by-sa/4.0/","  Heating plates describe the transfer of heat from actuators to a target
object. In other words, they separate the heat sources and heated object and
can be further used to apply a specific heat distribution on this object.
Therefore, an exact description of their thermal dynamics and an efficient
coordination of their actuators is necessary to achieve a desired
time-dependent temperature profile accurately. In this contribution, the
thermal dynamics of a multiple source heating plate is modeled as a
quasi-linear heat equation and the configuration of the spatially distributed
actuators and sensors are discussed. Furthermore, the distributed parameter
system is approximated using a Finite Volume scheme, and the influence of the
actuators' spatial characterization on the plate's thermal dynamics is studied
with the resulting high-dimensional system.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:06:46 GMT""}]","2020-12-01"
"2011.14940","Sicong Zhou","Lu Liu, Sicong Zhou, Huawei Huang, Zibin Zheng","From Technology to Society: An Overview of Blockchain-based DAO","11 pages, 4 figures, 3 tables, submitted to IEEE OJ-CS",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decentralized Autonomous Organization (DAO) is believed to play a significant
role in our future society governed in a decentralized way. In this article, we
first explain the definitions and preliminaries of DAO. Then, we conduct a
literature review of the existing studies of DAO published in the recent few
years. Through the literature review, we find out that a comprehensive survey
towards the state-of-the-art studies of DAO is still missing. To fill this gap,
we perform such an overview by identifying and classifying the most valuable
proposals and perspectives closely related to the combination of DAO and
blockchain technologies. We anticipate that this survey can help researchers,
engineers, and educators acknowledge the cutting-edge development of
blockchain-related DAO technologies.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:07:18 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 04:43:31 GMT""}]","2021-02-17"
"2011.14941","Ian Hutchinson","I H Hutchinson","Oblate Electron Holes are not attributable to Anisotropic Shielding",,,"10.1063/5.0039233",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Shielding mechanisms' influence on the ratio of perpendicular to parallel
scale lengths of multidimensional plasma electron hole equilibria are analyzed
theoretically and computationally. It is shown that the ``gyrokinetic'' model,
invoking perpendicular polarization, is based on a misunderstanding and cannot
explain the observational trend that greater transverse extent accompanies
lower magnetic field. Instead, the potential in the wings of the hole, outside
the region of trapped-electron depletion, has isotropic shielding giving
$\phi\propto {\rm e}^{-r/L}/r$, with the shielding length $L$ equal to the
Debye length for holes much slower than the electron thermal speed. Particle in
cell simulations confirm the analysis.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:07:42 GMT""}]","2021-09-29"
"2011.14942","Richard Schaeufele","Richard S. Sch\""aufele, Miguel Vazquez-Pufleau, Juan J. Vilatela","Tough sheets of nanowires produced floating in the gas phase","12 pages, 4 figure, 1 table","Mater. Horiz., 2020, 7, 2978-2984","10.1039/D0MH00777C",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Assembling nanostructured building blocks into network materials unlocks
macroscopic properties inaccessible with monolithic solids, notably toughness
and tolerance to electrochemical alloying. A method is reported for
large-scale, continuous synthesis of silicon nanowires (SiNWs) suspended in the
gas phase and their direct assembly into macroscopic sheets. Performing
gas-phase growth of SiNWs through floating catalyst chemical vapor deposition
using an aerosol of gold nanoparticles eliminates the need for substrates,
increasing the growth rate by a factor of 500, reaching 1.4 $\mu$m s$^{-1}$ and
leading to very long SiNWs. The combined high aspect ratio ($>$210) and large
concentration of SiNWs in the gas-phase (1.5 x 107 cm$^{-3}$) enable the
formation of macroscopic solids solely composed of percolated SiNWs, such as
free-standing sheets and continuous metre-long SiNW tapes. Sheet samples of
small diameter SiNWs ($<$25 nm) combine extraordinary flexibility in bending,
tensile ductility around 3%, and over 50-fold higher toughness than Si-based
anodes (fracture energy 0.18 $\pm$ 0.1 J g$^{-1}$). This synthesis and assembly
process should be applicable to virtually any one-dimensional inorganic
nanomaterial producible by thermochemical methods.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:07:50 GMT""}]","2020-12-01"
"2011.14943","Kashif Ahmad","Naina Said, Kashif Ahmad, Asma Gul, Nasir Ahmad, Ala Al-Fuqaha","Floods Detection in Twitter Text and Images","3 pages",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present our methods for the MediaEval 2020 Flood Related
Multimedia task, which aims to analyze and combine textual and visual content
from social media for the detection of real-world flooding events. The task
mainly focuses on identifying floods related tweets relevant to a specific
area. We propose several schemes to address the challenge. For text-based flood
events detection, we use three different methods, relying on Bog of Words (BOW)
and an Italian Version of Bert individually and in combination, achieving an
F1-score of 0.77%, 0.68%, and 0.70% on the development set, respectively. For
the visual analysis, we rely on features extracted via multiple
state-of-the-art deep models pre-trained on ImageNet. The extracted features
are then used to train multiple individual classifiers whose scores are then
combined in a late fusion manner achieving an F1-score of 0.75%. For our
mandatory multi-modal run, we combine the classification scores obtained with
the best textual and visual schemes in a late fusion manner. Overall, better
results are obtained with the multimodal scheme achieving an F1-score of 0.80%
on the development set.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:08:19 GMT""}]","2020-12-01"
"2011.14944","Kashif Ahmad","Firoj Alam, Zohaib Hassan, Kashif Ahmad, Asma Gul, Michael Reiglar,
  Nicola Conci, Ala AL-Fuqaha","Flood Detection via Twitter Streams using Textual and Visual Features","3 pages",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The paper presents our proposed solutions for the MediaEval 2020
Flood-Related Multimedia Task, which aims to analyze and detect flooding events
in multimedia content shared over Twitter. In total, we proposed four different
solutions including a multi-modal solution combining textual and visual
information for the mandatory run, and three single modal image and text-based
solutions as optional runs. In the multimodal method, we rely on a supervised
multimodal bitransformer model that combines textual and visual features in an
early fusion, achieving a micro F1-score of .859 on the development data set.
For the text-based flood events detection, we use a transformer network (i.e.,
pretrained Italian BERT model) achieving an F1-score of .853. For image-based
solutions, we employed multiple deep models, pre-trained on both, the ImageNet
and places data sets, individually and combined in an early fusion achieving
F1-scores of .816 and .805 on the development set, respectively.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:09:11 GMT""}]","2020-12-01"
"2011.14945","Min Jiang","Min Jiang, Ji Bian, Qing Li, Ze Wu, Haowen Su, Minxiang Xu, Yuanhong
  Wang, Xin Wang, Xinhua Peng","Zero- to ultralow-field nuclear magnetic resonance and its applications","22 pages, 13 figures",,,,"quant-ph physics.app-ph","http://creativecommons.org/publicdomain/zero/1.0/","  As a complementary analysis tool to conventional high-field NMR, zero- to
ultralow-field (ZULF) NMR detects nuclear magnetization signals in the
sub-microtesla regime. Spin-exchange relaxation-free (SERF) atomic
magnetometers provide a new generation of sensitive detector for ZULF NMR. Due
to the features such as low-cost, high-resolution and potability, ZULF NMR has
recently attracted considerable attention in chemistry, biology, medicine, and
tests of fundamental physics. This review describes the basic principles,
methodology and recent experimental and theoretical development of ZULF NMR, as
well as its applications in spectroscopy, quantum control, imaging, NMR-based
quantum devices, and tests of fundamental physics. The future prospects of ZULF
NMR are also discussed.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:13:20 GMT""}]","2020-12-01"
"2011.14946","Valerio D'Alessandro","V. D'Alessandro, M. Falone, L. Giammichele, R. Ricci","Eulerian-Lagrangian modelling of bio-aerosols irradiated by UV-C light
  in relation to SARS-CoV-2 transmission","12 pages, 23 figures. It will be submitted to Physics of Fluids",,"10.1063/5.0039224",,"physics.med-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  It is well known that several viruses, as well as SARS-CoV-2, can be
transmitted through airborne diffusion of saliva micro-droplets. For this
reason many reserach groups have been devoted their efforts in order to gain
new insight into the transport of fluids and particles originted from human
respiratory tracts. This paper aims to provide a contribution to the numerical
modelling of bio-aerosols. In particular, the well-known problem around the
safety distance to be held for avoiding virus transmission in the absence of
external wind is further investigated. Thus, new indexes capable of evaluating
the contamination risk are introduced and the possibility to inactivate virus
particles by means of an external UV-C radiation source is studied. For this
purpose, a new model which takes into account biological inactivation deriving
from UV-C exposure in a Eulerian-Lagrangian framework is presented.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:14:46 GMT""}]","2021-03-10"
"2011.14947","Chris Hamilton","Chris Hamilton (1), Roman R. Rafikov (1,2) ((1) DAMTP, Cambridge, (2)
  IAS)","Secular dynamics of binaries in stellar clusters -- III. Doubly-averaged
  dynamics in the presence of general relativistic precession","Final version, accepted for publication in MNRAS",,"10.1093/mnras/stab1284",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Secular evolution of binaries driven by an external (tidal) potential is a
classic astrophysical problem. Tidal perturbations can arise due to an external
point mass, as in the Lidov-Kozai (LK) theory of hierarchical triples, or due
to an extended stellar system (e.g. galaxy or globular cluster) in which the
binary resides. For many applications, general-relativistic (GR) apsidal
precession is important, and has been accounted for in some LK calculations.
Here we generalise and extend these studies by exploring in detail the effect
of GR precession on (quadrupole-level) tidal evolution of binaries orbiting in
arbitrary axisymmetric potentials (which includes LK theory as a special case).
We study the (doubly-averaged) orbital dynamics for arbitrary strengths of GR
and binary initial conditions and uncover entirely new phase space morphologies
with important implications for the binary orbital evolution. We also explore
how GR precession affects secular evolution of binary orbital elements when the
binary reaches high eccentricity ($e\to 1$) and delineate several different
dynamical regimes. Our results are applicable to a variety of astrophysical
systems. In particular, they can be used to understand the high-eccentricity
behaviour of (cluster) tide-driven compact object mergers -- i.e. LIGO/Virgo
gravitational wave sources -- for which GR effects are crucial.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:15:18 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 17:06:46 GMT""}]","2021-05-20"
"2011.14948","Yu Chih Tseng","Yu-Chih Tseng, Yan-Cheng Wei, Ying-Cheng Chen","Efficient quantum memory for heralded single photons generated by
  cavity-enhanced spontaneous parametric downconversion",,,,,"physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We interface a spontaneous parametric down conversion (SPDC) crystal and a
cold atomic ensemble and demonstrate a highly efficient quantum memory through
polarization-encoded single-photon qubits. Specifically, narrowband heralded
single photons from a cavity-enhanced SPDC source is stored using cold atomic
ensemble, with ~70% storage-and-retrieval efficiency and ~10$\mu$s storage time
at 50% efficiency. To prevent the degradation after storage, we also manipulate
the single-photon wave profile so that the retrieved non-classical nature of
single photon is preserved. On the other hand, the dual-rail storage is used
for storing polarization-encoded qubits, and the corrected fidelity of flying
qubits after storage reaches ~97%. The results pave the way toward large-scale
quantum network.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:19:39 GMT""}]","2020-12-01"
"2011.14951","Yueqiao Faith Zhang","Faith Zhang","Rank one perturbation with a generalized eigenvector",,,,,"math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The relationship between the Jordan structures of two matrices sufficiently
close has been largely studied in the literature, among which a square matrix
$A$ and its rank one updated matrix of the form $A+xb^*$ are of special
interest. The eigenvalues of $A+xb^*$, where $x$ is an eigenvector of $A$ and
$b$ is an arbitrary vector, were first expressed in terms of eigenvalues of $A$
by Brauer in 1952. Jordan structures of $A$ and $A+xb^*$ have been studied, and
similar results were obtained when a generalized eigenvector of $A$ was used
instead of an eigenvector. However, in the latter case, restrictions on $b$
were put so that the spectrum of the updated matrix is the same as that of $A$.
There does not seem to be results on the eigenvalues and generalized
eigenvectors of $A+xb^*$ when $x$ is a generalized eigenvector and $b$ is an
arbitrary vector. In this paper we show that the generalized eigenvectors of
the updated matrix can be written in terms of those of $A$ when a generalized
eigenvector of $A$ and an arbitrary vector $b$ are involved in the
perturbation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:24:58 GMT""}]","2020-12-01"
"2011.14952","Griselda Figueroa Aguirre","Ernesto F. Eiroa, Griselda Figueroa-Aguirre","Thin shells in (2+1)-dimensional F(R) gravity","14 pages, 4 figures; v2: minor changes, new references added","Phys. Rev. D 103, 044011 (2021)","10.1103/PhysRevD.103.044011",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We study thin shells of matter in (2+1)-dimensional F(R) theories of gravity
with constant scalar curvature R. We consider a wide class of spacetimes with
circular symmetry, in which a thin shell joins an inner region with an outer
one. We analyze the stability of the static configurations under radial
perturbations. As examples of spacetimes asymptotically anti-de Sitter, we
present a charged bubble and a charged thin shell surrounding a non-charged
black hole. In both cases, we show that stable solutions can be found for
suitable values of the parameters.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:26:06 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 11:59:00 GMT""}]","2021-02-10"
"2011.14953","Carlos Bertulani","Carlos A. Bertulani, Ronaldo V. Lobato","Neutron tunneling: A new mechanism to power explosive phenomena in
  neutron stars, magnetars, and neutron star mergers","9 pages, 3 figures, changes made in text and definitions, accepted
  for publication in the Astrophysical Journal",,"10.3847/1538-4357/abf141",,"nucl-th astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neutron tunneling between neutron-rich nuclei in inhomogeneous dense matter
encountered in neutron star crusts can release enormous energy on a
short-timescale to power explosive phenomena in neutron stars. In this work we
clarify aspects of this process that can occur in the outer regions of neutron
stars when oscillations or cataclysmic events increase the ambient density. We
use a time-dependent Hartree-Fock-Bogoliubov formalism to determine the rate of
neutron diffusion and find that large amounts of energy can be released
rapidly. The role of nuclear binding, the two-body interaction and pairing, on
the neutron diffusion times is investigated. We consider a one-dimensional
quantum diffusion model and extend our analysis to study the impact of
diffusion in three-dimensions. We find that these novel neutron transfer
reactions can generate energy at the amount of $\simeq 10^{40}-10^{44}$ ergs
under suitable conditions.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:26:45 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 21:17:45 GMT""}]","2021-05-19"
"2011.14957","Rocio Isabel P\'aez","Roc\'io Isabel P\'aez, Massimiliano Guzzo","Transits close to the Lagrangian solutions $L_1,L_2$ in the Elliptic
  Restricted Three-body Problem","36 pages, 8 figures. Submitted for publication",,"10.1088/1361-6544/ac13be",,"astro-ph.EP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the last decades a peculiar family of solutions of the Circular Restricted
Three Body Problem has been used to explain the temporary captures of small
bodies and spacecrafts by a planet of the Solar System. These solutions, which
transit close to the Lagrangian points $L_1,L_2$ of the CRTBP, have been
classified using the values of approximate local integrals and of the Jacobi
constant. The use for small bodies of the Solar System requires to consider a
hierarchical extension of the model, from the CRTBP to the the full $N$
planetary problem. The Elliptic Restricted Three Body, which is the first
natural extension of the CRTBP, represents already a challenge, since global
first integrals such as the Jacobi constant are not known for this problem. In
this paper we extend the classification of the transits occurring close to the
Lagrangian points $L_1,L_2$ of the ERTBP using a combination of the Floquet
theory and Birkhoff normalizations. Provided that certain non-resonance
conditions are satisfied, we conjugate the Hamiltonian of the problem to an
integrable normal form Hamiltonian with remainder, which is used to define
approximate local first integrals and to classify the transits of orbits
through a neighbourhood of the Lagrange equilibria according to the values of
these integrals. We provide numerical demonstrations for the Earth-Moon ERTBP.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:31:53 GMT""}]","2021-09-01"
"2011.14958","Mohammad Reza Jafari Harandi","M. Reza J. Harandi and Hamid D. Taghirad","On the Matching Equations of Kinetic Energy Shaping in IDA-PBC",,,"10.1016/j.jfranklin.2021.08.034",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interconnection and damping assignment passivity-based control scheme has
been used to stabilize many physical systems such as underactuated mechanical
systems through total energy shaping. In this method, some partial differential
equations (PDEs) arisen by kinetic and potential energy shaping, shall be
solved analytically. Finding a suitable desired inertia matrix as the solution
of nonlinear PDEs related to kinetic energy shaping is a challenging problem.
  In this paper, a systematic approach to solve this matching equation for
systems with one degree of underactuation is proposed. A special structure for
desired inertia matrix is proposed to simplify the solution of the
corresponding PDE. It is shown that the proposed method is more general than
that of some reported methods in the literature. In order to derive a suitable
desired inertia matrix, a necessary condition is also derived. The proposed
method is applied to three examples, including VTOL aircraft, pendubot and 2D
SpiderCrane system.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:33:26 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 06:28:05 GMT""}]","2021-11-16"
"2011.14959","Ti Bai","Ti Bai, Biling Wang, Dan Nguyen, Steve Jiang","Deep Dose Plugin Towards Real-time Monte Carlo Dose Calculation Through
  a Deep Learning based Denoising Algorithm","under review",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Monte Carlo (MC) simulation is considered the gold standard method for
radiotherapy dose calculation. However, achieving high precision requires a
large number of simulation histories, which is time consuming. The use of
computer graphics processing units (GPUs) has greatly accelerated MC simulation
and allows dose calculation within a few minutes for a typical radiotherapy
treatment plan. However, some clinical applications demand real time efficiency
for MC dose calculation. To tackle this problem, we have developed a real time,
deep learning based dose denoiser that can be plugged into a current GPU based
MC dose engine to enable real time MC dose calculation. We used two different
acceleration strategies to achieve this goal: 1) we applied voxel unshuffle and
voxel shuffle operators to decrease the input and output sizes without any
information loss, and 2) we decoupled the 3D volumetric convolution into a 2D
axial convolution and a 1D slice convolution. In addition, we used a weakly
supervised learning framework to train the network, which greatly reduces the
size of the required training dataset and thus enables fast fine tuning based
adaptation of the trained model to different radiation beams. Experimental
results show that the proposed denoiser can run in as little as 39 ms, which is
around 11.6 times faster than the baseline model. As a result, the whole MC
dose calculation pipeline can be finished within 0.15 seconds, including both
GPU MC dose calculation and deep learning based denoising, achieving the real
time efficiency needed for some radiotherapy applications, such as online
adaptive radiotherapy.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:33:51 GMT""},{""version"":""v2"",""created"":""Wed, 23 Dec 2020 16:57:15 GMT""}]","2020-12-24"
"2011.14965","Priyabrata Saha","Priyabrata Saha and Saibal Mukhopadhyay","A Deep Learning Approach for Predicting Spatiotemporal Dynamics From
  Sparsely Observed Data","11 pages, 10 figures; Accepted manuscript IEEE Access","IEEE Access, vol. 9, pp. 64200-64210, 2021","10.1109/ACCESS.2021.3075899",,"stat.ML cs.LG cs.NA math.AP math.NA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider the problem of learning prediction models for
spatiotemporal physical processes driven by unknown partial differential
equations (PDEs). We propose a deep learning framework that learns the
underlying dynamics and predicts its evolution using sparsely distributed data
sites. Deep learning has shown promising results in modeling physical dynamics
in recent years. However, most of the existing deep learning methods for
modeling physical dynamics either focus on solving known PDEs or require data
in a dense grid when the governing PDEs are unknown. In contrast, our method
focuses on learning prediction models for unknown PDE-driven dynamics only from
sparsely observed data. The proposed method is spatial dimension-independent
and geometrically flexible. We demonstrate our method in the forecasting task
for the two-dimensional wave equation and the Burgers-Fisher equation in
multiple geometries with different boundary conditions, and the ten-dimensional
heat equation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:38:00 GMT""},{""version"":""v2"",""created"":""Sat, 1 May 2021 17:27:58 GMT""}]","2021-05-04"
"2011.14966","Harikrishnan P","Hrithwik Shalu, Harikrishnan P, Hari Sankar CN, Akash Das, Saptarshi
  Majumder, Arnhav Datar, Subin Mathew MS, Anugyan Das and Juned Kadiwala","Depression Status Estimation by Deep Learning based Hybrid Multi-Modal
  Fusion Model",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Preliminary detection of mild depression could immensely help in effective
treatment of the common mental health disorder. Due to the lack of proper
awareness and the ample mix of stigmas and misconceptions present within the
society, mental health status estimation has become a truly difficult task. Due
to the immense variations in character level traits from person to person,
traditional deep learning methods fail to generalize in a real world setting.
In our study we aim to create a human allied AI workflow which could
efficiently adapt to specific users and effectively perform in real world
scenarios. We propose a Hybrid deep learning approach that combines the essence
of one shot learning, classical supervised deep learning methods and human
allied interactions for adaptation. In order to capture maximum information and
make efficient diagnosis video, audio, and text modalities are utilized. Our
Hybrid Fusion model achieved a high accuracy of 96.3% on the Dataset; and
attained an AUC of 0.9682 which proves its robustness in discriminating classes
in complex real-world scenarios making sure that no cases of mild depression
are missed during diagnosis. The proposed method is deployed in a cloud-based
smartphone application for robust testing. With user-specific adaptations and
state of the art methodologies, we present a state-of-the-art model with user
friendly experience.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:38:18 GMT""}]","2020-12-01"
"2011.14967","Celia Hacker","Asilata Bapat, Robyn Brooks, Celia Hacker, Claudia Landi, Barbara I.
  Mahler","Morse-based Fibering of the Persistence Rank Invariant",,,,,"math.AT cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although there is no doubt that multi-parameter persistent homology is a
useful tool to analyse multi-variate data, efficient ways to compute these
modules are still lacking in the available topological data analysis toolboxes.
Other issues such as interpretation and visualization of the output remain
difficult to solve. Software visualizing multi-parameter persistence diagrams
is currently only available for 2-dimensional persistence modules. One of the
simplest invariants for a multi-parameter persistence module is its rank
invariant, defined as the function that counts the number of linearly
independent homology classes that live in the filtration through a given pair
of values of the multi-parameter. We propose a step towards interpretation and
visualization of the rank invariant for persistence modules for any given
number of parameters. We show how discrete Morse theory may be used to compute
the rank invariant, proving that it is completely determined by its values at
points whose coordinates are critical with respect to a discrete Morse gradient
vector field. These critical points partition the set of all lines of positive
slope in the parameter space into equivalence classes, such that the rank
invariant along lines in the same class are also equivalent. We show that we
can deduce all persistence diagrams of the restrictions to the lines in a given
class from the persistence diagram of the restriction to a representative in
that class.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:38:30 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 18:46:38 GMT""}]","2021-04-15"
"2011.14968","Furqan Ahmed","Jessica Moysen, Furqan Ahmed, Mario Garc\'ia-Lozano, Jarno Niemel\""a","Big Data-driven Automated Anomaly Detection and Performance Forecasting
  in Mobile Networks","Accepted in IEEE Globecomm 2020 workshop on AI-Enabled 5G/6G
  Networks: Automation, Openness, and Radio Access",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  The massive amount of data available in operational mobile networks offers an
invaluable opportunity for operators to detect and analyze possible anomalies
and predict network performance. In particular, application of advanced machine
learning (ML) techniques on data aggregated from multiple sources can lead to
important insights, not only for the detection of anomalous behavior but also
for performance forecasting, thereby complementing classic network operation
and maintenance solutions with intelligent monitoring tools. In this paper, we
propose a novel framework that aggregates diverse data sets (e.g.
configuration, performance, inventory, locations, user speeds) from an
operational LTE network and applies ML algorithms to diagnose network issues
and analyze their impact on key performance indicators. To this end, pattern
identification and time-series forecasting algorithms are used on the ingested
data. Results show that proposed framework can indeed be leveraged to automate
the identification of anomalous behaviors associated with the spatial-temporal
characteristics, and predict customer impact in an accurate manner.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:39:31 GMT""}]","2020-12-01"
"2011.14969","Gaurang Sriramanan","Gaurang Sriramanan, Sravanti Addepalli, Arya Baburaj, R. Venkatesh
  Babu","Guided Adversarial Attack for Evaluating and Enhancing Adversarial
  Defenses","NeurIPS 2020 (Spotlight)",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advances in the development of adversarial attacks have been fundamental to
the progress of adversarial defense research. Efficient and effective attacks
are crucial for reliable evaluation of defenses, and also for developing robust
models. Adversarial attacks are often generated by maximizing standard losses
such as the cross-entropy loss or maximum-margin loss within a constraint set
using Projected Gradient Descent (PGD). In this work, we introduce a relaxation
term to the standard loss, that finds more suitable gradient-directions,
increases attack efficacy and leads to more efficient adversarial training. We
propose Guided Adversarial Margin Attack (GAMA), which utilizes function
mapping of the clean image to guide the generation of adversaries, thereby
resulting in stronger attacks. We evaluate our attack against multiple defenses
and show improved performance when compared to existing attacks. Further, we
propose Guided Adversarial Training (GAT), which achieves state-of-the-art
performance amongst single-step defenses by utilizing the proposed relaxation
term for both attack generation and training.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:39:39 GMT""}]","2020-12-01"
"2011.14970","Lazar Kish","L. L. Kish, A. Thaler, M. Lee, A. V. Zakrzewski, D. Reig-i-Plessis, B.
  Wolin, X. Wang, K. C. Littrell, R. Budakian, H. D. Zhou, V. S. Zapf, A. A.
  Aczel, L. DeBeer-Schmitt, G. J. MacDougall","Domain wall patterning and giant response functions in ferrimagnetic
  spinels","19 pages, 13 figures","Adv. Sci. 2021, 8, 2101402","10.1002/advs.202101402",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The manipulation of mesoscale domain wall phenomena has emerged as a powerful
strategy for designing ferroelectric responses in functional devices, but its
full potential has not yet been realized in the field of magnetism. We show
that mechanically strained samples of Mn$_3$O$_4$ and MnV$_2$O$_4$ exhibit a
stripe-like patterning of the bulk magnetization below known magnetostructural
transitions, similar to the structural domains reported in ferroelectric
materials. Building off our previous magnetic force microscopy data, we use
small angle neutron scattering to show that these patterns extend to the bulk,
and demonstrate an ability to manipulate the domain walls via applied magnetic
field and mechanical stress. We then connect these domains back to the
anomalously large magnetoelastic and magnetodielectric response functions
reported in these materials, directly correlating local and macroscopic
measurements on the same crystals.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:41:42 GMT""}]","2022-03-03"
"2011.14971","Huey-Wen Lin","Huey-Wen Lin, Jiunn-Wei Chen, Rui Zhang","Lattice Nucleon Isovector Unpolarized Parton Distribution in the
  Physical-Continuum Limit","5 figures",,,"MSUHEP-20-019","hep-lat hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first lattice-QCD calculation of the nucleon isovector
unpolarized parton distribution functions (PDFs) at the physical-continuum
limit using Large-Momentum Effective Theory (LaMET). The lattice results are
calculated using ensembles with multiple sea pion masses with the lightest one
around 135~MeV, 3 lattice spacings $a\in[0.06,0.12]$~fm, and multiple volumes
with $M_\pi L$ ranging 3.3 to 5.5. We perform a simultaneous chiral-continuum
extrapolation to obtain RI/MOM renormalized nucleon matrix elements with
various Wilson-link displacements in the continuum limit at physical pion mass.
Then, we apply one-loop perturbative matching to the quasi-PDFs to obtain the
lightcone PDFs. We find the lattice-spacing dependence to be much larger than
the dependence on pion mass and lattice volume for these LaMET matrix elements.
Our physical-continuum limit unpolarized isovector nucleon PDFs are found to be
consistent with global-PDF results.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:42:38 GMT""}]","2020-12-01"
"2011.14972","Zhexu Xi","Zhexu Xi, Hui Zhao","Study on Transient Spectrum Based on Charge Transfer of Semiconductor
  Quantum Dots","12 pages, 29 references, 11 figures",,,,"cond-mat.mes-hall cond-mat.str-el physics.ins-det quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the increasing energy crisis and the prevalent concept of green
sustainability, quantum dot materials have become a hot spot in the academic
and industrial fields of chemistry. Due to unique, tailor-made photovoltaic
properties based on marked quantum-confined effects, it's necessary to identify
the QD-based charge transfer process connected with a lifetime of stimulated
excitons. Additionally, inorganic nanoparticles with a continuum of electron
states contribute to the consistency between electron dynamics and their
function through complexation with QDs. Ultrafast spectroscopy can be widely
used in this system, the most typical of which is the time-resolved transient
absorption spectroscopy, especially on a femtosecond or picosecond timescale.
In this paper, we used the ZnSe/CdS core-shell quantum dot as the donor, and
the TiO2 film as the metal oxide molecule as the acceptor, through steady-state
and transient absorption techniques. Within, the electron transfer and related
processes between the two composite systems were explored, and the relationship
between the electron transfer rate constant (kBET) and particle size and QD
core size was further studied. Through the research content of this paper, it
is hoped to provide materials for quantum dot sensitization devices with more
controllable features.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:44:42 GMT""},{""version"":""v2"",""created"":""Sat, 9 Jan 2021 18:07:17 GMT""}]","2021-01-12"
"2011.14973","Yongjia Zhang","Liang Cheng, Yongjia Zhang","Perelman-type no breather theorem for noncompact Ricci flows","28 pages",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we first show that a complete shrinking breather with Ricci
curvature bounded from below must be a shrinking gradient Ricci soliton. This
result has several applications. First, we can classify all complete
$3$-dimensional shrinking breathers. Second, we can show that every complete
shrinking Ricci soliton with Ricci curvature bounded from below must be
gradient -- a generalization of Naber's result. Furthermore, we develop a
general condition for the existence of the asymptotic shrinking gradient Ricci
soliton, which hopefully will contribute to the study of ancient solutions.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:45:17 GMT""}]","2020-12-01"
"2011.14974","Matthew Foreman","Niall Byrnes and Matthew R. Foreman","Symmetry constraints for vector scattering and transfer matrices
  containing evanescent components: energy conservation, reciprocity and time
  reversal",,"Phys. Rev. Research 3, 013129 (2021)","10.1103/PhysRevResearch.3.013129",,"physics.optics physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we study the scattering and transfer matrices for electric
fields defined with respect to an angular spectrum of plane waves. For these
matrices, we derive the constraints that are enforced by conservation of
energy, reciprocity and time reversal symmetry. Notably, we examine the general
case of vector fields in three dimensions and allow for evanescent field
components. Moreover, we consider fields described by both continuous and
discrete angular spectra, the latter being more relevant to practical
applications, such as optical scattering experiments. We compare our results to
better-known constraints, such as the unitarity of the scattering matrix for
far-field modes, and show that previous results follow from our framework as
special cases. Finally, we demonstrate our results numerically with a simple
example of wave propagation at a planar glass-air interface, including the
effects of total internal reflection. Our formalism makes minimal assumptions
about the nature of the scattering medium and is thus applicable to a wide
range of scattering problems.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:47:46 GMT""}]","2021-02-17"
"2011.14975","R\""udiger Haas","R\""udiger Haas, Eskil Varenius, Saho Matsumoto, Matthias Schartner","Observing UT1-UTC with VGOS","12 pages, 3 figures, 2 tables",,"10.1186/s40623-021-01396-2",,"physics.geo-ph astro-ph.IM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present first results of UT1-UTC determinations using the VLBI Global
Observing System (VGOS). During December 2019 through February 2020 a series of
1~hour long observing sessions were performed using the VGOS stations at
Ishioka in Japan and the Onsala twin telescopes in Sweden. The data of this
VGOS-B series were correlated, post-correlation processed, and analysed at the
Onsala Space Observatory. The derived UT1-UTC results were compared to
corresponding results from standard legacy S/X Intensive sessions (INT1/INT2),
as well to the final values of the International Earth Rotation and Reference
Frame Service (IERS), provided in IERS Bulletin~B. The VGOS-B series achieve
3-4 times lower formal uncertainties for the UT1-UTC results than standard
legacy S/X INT series. Furthermore, the root mean square (RMS) agreement with
respect to the IERS Bulletin~B is 30-40 % better for the VGOS-B results than
for the INT1/INT2 results.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:47:50 GMT""}]","2021-03-31"
"2011.14976","Mahmoud Darwich","Xiangbo Li, Mahmoud Darwich, Magdy Bayoumi, Mohsen Amini Salehi","Cloud-Based Video Streaming Services: A Survey","accepted to be published in Elsevier book chapter Advances in
  Computers Volume 123",,,,"cs.MM","http://creativecommons.org/licenses/by/4.0/","  Video streaming, in various forms of video on demand (VOD), live, and 360
degree streaming, has grown dramatically during the past few years. In
comparison to traditional cable broadcasters whose contents can only be watched
on TVs, video streaming is ubiquitous and viewers can flexibly watch the video
contents on various devices, ranging from smart-phones to laptops and large TV
screens. Such ubiquity and flexibility are enabled by interweaving multiple
technologies, such as video compression, cloud computing, content delivery
networks, and several other technologies. As video streaming gains more
popularity and dominates the Internet traffic, it is essential to understand
the way it operates and the interplay of different technologies involved in it.
Accordingly, the first goal of this paper is to unveil sophisticated processes
to deliver a raw captured video to viewers' devices. In particular, we
elaborate on the video encoding, transcoding, packaging, encryption, and
delivery processes. We survey recent efforts in academia and industry to
enhance these processes. As video streaming industry is increasingly becoming
reliant on cloud computing, the second goal of this survey is to explore and
survey the ways cloud services are utilized to enable video streaming services.
The third goal of the study is to position the undertaken research works in
cloud-based video streaming and identify challenges that need to be obviated in
future to advance cloud-based video streaming industry to a more flexible and
user-centric service.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:48:21 GMT""}]","2020-12-01"
"2011.14977","Julia Lindberg","Julia Lindberg, Nigel Boston, Bernard C. Lesieutre","Exploiting Symmetry in the Power Flow Equations Using Monodromy","5 pages",,,,"math.AG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose solving the power flow equations using monodromy. We prove the
variety under consideration decomposes into trivial and nontrivial subvarieties
and that the nontrivial subvariety is irreducible. We also show various
symmetries in the solutions. We finish by giving numerical results comparing
monodromy against polyhedral and total degree homotopy methods and giving an
example of a network where we can find all solutions to the power flow equation
using monodromy where other homotopy techniques fail. This work gives hope that
finding all solutions to the power flow equations for networks of realistic
size is possible.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:48:45 GMT""}]","2020-12-01"
"2011.14978","Dylan Butson","Dylan Butson","Equivariant localization in factorization homology and applications in
  mathematical physics II: Gauge theory applications","153 pages, 5 figures, Part II of a series",,,,"math.RT hep-th math-ph math.AG math.AT math.MP math.QA","http://creativecommons.org/licenses/by/4.0/","  We give an account of the theory of factorization spaces, categories,
functors, and algebras, following the approach of [Ras1]. We apply these
results to give geometric constructions of factorization $\mathbb{E}_n$
algebras describing mixed holomorphic-topological twists of supersymmetric
gauge theories in low dimensions. We formulate and prove several recent
predictions from the physics literature in this language:
  We recall the Coulomb branch construction of [BFN1] from this perspective. We
prove a conjecture from [CosG] that the Coulomb branch factorization
$\mathbb{E}_1$ algebra $\mathcal{A}(G,N)$ acts on the factorization algebra of
chiral differential operators $\mathcal{D}^{ch}(Y)$ on the quotient stack
$Y=N/G$. We identify the latter with the semi-infinite cohomology of
$\mathcal{D}^{ch}(N)$ with respect to $\hat{\mathfrak{g}}$, following the
results of [Ras3]. Both these results require the hypothesis that $Y$ admits a
Tate structure, or equivalently that $\mathcal{D}^{ch}(N)$ admits an action of
$\hat{\mathfrak{g}}$ at level $\kappa=-\text{Tate}$.
  We construct an analogous factorization $\mathbb{E}_2$ algebra
$\mathcal{F}(Y)$ describing the local observables of the mixed holomorphic-B
twist of four dimensional $\mathcal{N}=2$ gauge theory. We apply the theory of
equivariant factorization algebras of the prequel [Bu1] in this example: we
identify $S^1$ equivariant structures on $\mathcal{F}(Y)$ with Tate structures
on $Y=N/G$, and prove that the corresponding filtered quantization of
$\iota^!\mathcal{F}(Y)$ is given by the two-periodic Rees algebra of chiral
differential operators on $Y$. This gives a mathematical account of the results
of [Beem4]. Finally, we apply the equivariant cigar reduction principle of
[Bu1] to explain the relationship between these results and our account of the
results of [CosG] described above.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:49:38 GMT""}]","2020-12-01"
"2011.14979","Antonio Toral","Antonio Toral, Antoni Oliver, Pau Ribas Ballest\'in","Machine Translation of Novels in the Age of Transformer","Chapter published in the book Maschinelle \""Ubersetzung f\""ur
  \""Ubersetzungsprofis (pp. 276-295). J\""org Porsiel (Ed.), BD\""U Fachverlag,
  2020. ISBN 978-3-946702-09-2",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this chapter we build a machine translation (MT) system tailored to the
literary domain, specifically to novels, based on the state-of-the-art
architecture in neural MT (NMT), the Transformer (Vaswani et al., 2017), for
the translation direction English-to-Catalan. Subsequently, we assess to what
extent such a system can be useful by evaluating its translations, by comparing
this MT system against three other systems (two domain-specific systems under
the recurrent and phrase-based paradigms and a popular generic on-line system)
on three evaluations. The first evaluation is automatic and uses the
most-widely used automatic evaluation metric, BLEU. The two remaining
evaluations are manual and they assess, respectively, preference and amount of
post-editing required to make the translation error-free. As expected, the
domain-specific Transformer-based system outperformed the three other systems
in all the three evaluations conducted, in all cases by a large margin.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:51:08 GMT""}]","2020-12-01"
"2011.14980","Alex B. Grilo","Alex B. Grilo, Huijia Lin, Fang Song and Vinod Vaikuntanathan","Oblivious Transfer is in MiniQCrypt",,,,,"quant-ph cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MiniQCrypt is a world where quantum-secure one-way functions exist, and
quantum communication is possible. We construct an oblivious transfer (OT)
protocol in MiniQCrypt that achieves simulation-security in the plain model
against malicious quantum polynomial-time adversaries, building on the
foundational work of Bennett, Brassard, Cr\'epeau and Skubiszewska (CRYPTO
1991). Combining the OT protocol with prior works, we obtain secure two-party
and multi-party computation protocols also in MiniQCrypt. This is in contrast
to the classical world, where it is widely believed that one-way functions
alone do not give us OT.
  In the common random string model, we achieve a constant-round universally
composable (UC) OT protocol.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:51:17 GMT""}]","2020-12-01"
"2011.14981","Elena Ushakova","Elena P. Ushakova","Images of integration operators in weighted function spaces",,"Siberian Mathematical Journal, 2022, Vol. 63, No. 6, pp. 1181-1207","10.1134/S0037446622060167",,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Images of integration operators of natural orders are considered as elements
of Besov and Triebel--Lizorkin spaces with local Muckenhoupt weights on
$\mathbb{R}^N$. The results connect entropy and approximation numbers of
embedding operators with the same characteristics of the integration operators.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:54:33 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 12:03:04 GMT""}]","2022-12-05"
"2011.14982","Volodymyr Svitlyk","V. Svitlyk, M. Mezouar","Pressure-induced symmetry lowering in Nb3Sn1-x superconductor",,,"10.1088/1361-648X/abe96e",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cubic Pm-3n Nb3Sn0.92 superconductor (Tc ~ 16 K) was found to exhibit
tetragonal instabilities at the superconducting state (T = 10 K). These
instabilities are manifested through the appearance of reflections which are
forbidden in the Pm-3n symmetry but are compatible with the P42/mmc structure
which is observed in the Nb3Sn1-x system for higher Sn content at temperatures
lower than ~ 43 K. Nevertheless, the low-temperature structure of Nb3Sn0.92
remains metrically fully cubic, as concluded from single crystal synchrotron
radiation diffraction experiments. Subsequent application of external pressure
amplifies the observed instabilities with a resulting pseudo-cubic - tetragonal
transformation at P = 3 GPa at 10 K and this transition is energy driven, as
concluded from ab initio calculations. The electronic structures of the
corresponding phases are virtually identical and, therefore, the pseudo-cubic -
tetragonal transformation does not influence significantly the underlying
electronic interactions. Consequently, no anomalies in the behavior of the
critical temperature, Tc, are expected at this pressure. However, anomalies in
the upper critical field are anticipated during this transition, in analogy to
the corresponding behavior observed during the cubic-tetragonal transformation
in Nb3Sn1-x induced by increase in Sn content. Therefore targeted changes in
composition could be used to enhance upper critical field of Nb3Sn1-x for
specific extreme conditions of temperature and pressure.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:55:23 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 09:18:33 GMT""}]","2021-07-07"
"2011.14983","Douglas Gomes PhD","Douglas P. S. Gomes, Michael J. Horry, Anwaar Ulhaq, Manoranjan Paul,
  Subrata Chakraborty, Manash Saha, Tanmoy Debnath, D.M. Motiur Rahaman","MAVIDH Score: A COVID-19 Severity Scoring using Chest X-Ray Pathology
  Features",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  The application of computer vision for COVID-19 diagnosis is complex and
challenging, given the risks associated with patient misclassifications.
Arguably, the primary value of medical imaging for COVID-19 lies rather on
patient prognosis. Radiological images can guide physicians assessing the
severity of the disease, and a series of images from the same patient at
different stages can help to gauge disease progression. Hence, a simple method
based on lung-pathology interpretable features for scoring disease severity
from Chest X-rays is proposed here. As the primary contribution, this method
correlates well to patient severity in different stages of disease progression
with competitive results compared to other existing, more complex methods. An
original data selection approach is also proposed, allowing the simple model to
learn the severity-related features. It is hypothesized that the resulting
competitive performance presented here is related to the method being
feature-based rather than reliant on lung involvement or opacity as others in
the literature. A second contribution comes from the validation of the results,
conceptualized as the scoring of patients groups from different stages of the
disease. Besides performing such validation on an independent data set, the
results were also compared with other proposed scoring methods in the
literature. The results show that there is a significant correlation between
the scoring system (MAVIDH) and patient outcome, which could potentially help
physicians rating and following disease progression in COVID-19 patients.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:55:28 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 20:52:56 GMT""},{""version"":""v3"",""created"":""Tue, 2 Feb 2021 13:01:09 GMT""}]","2021-02-03"
"2011.14986","Lorenzo Monacelli","Lorenzo Monacelli and Francesco Mauri","Time-Dependent Self Consistent Harmonic Approximation: Anharmonic
  nuclear quantum dynamics and time correlation functions",,"Phys. Rev. B 103, 104305 (2021)","10.1103/PhysRevB.103.104305",,"cond-mat.stat-mech physics.atom-ph physics.comp-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  Most material properties of great physical interest are directly related to
nuclear dynamics, e.g. the ionic thermal conductivity, Raman/IR vibrational
spectra, inelastic X-ray, and Neutron scattering. A theory able to compute from
first principles these properties, accounting for the anharmonicity and quantum
fluctuations in the nuclear energy landscape that can be implemented in systems
with hundreds of atoms is missing. Here, we derive an approximate theory for
the quantum time evolution of lattice vibrations at finite temperature. This
theory introduces the time dynamics in the Self-Consistent Harmonic
Approximation (SCHA) and shares with the static case the same computational
cost. It is nonempirical, as pure states evolve according to the Dirac least
action principle and the dynamics of the thermal ensemble conserves both energy
and entropy. The static SCHA is recovered as a stationary solution of the
dynamical equations. We apply perturbation theory around the static SCHA
solution and derive an algorithm to compute efficiently quantum dynamical
response functions. Thanks to this new algorithm, we have access to the
response function of any general external time-dependent perturbation, enabling
the simulation of phonon spectra without following any perturbative expansion
of the nuclear potential or empirical methods. We benchmark the algorithm on
the IR and Raman spectroscopy of high-pressure hydrogen phase III, with a
simulation cell of 96 atoms. Our work also explores the nonlinear regime of the
dynamical nuclear motion, providing a paradigm to simulate the interaction with
intense or multiple probes, as in pump-probe spectroscopy, or chemical
reactions involving light atoms, as the proton transfer in biomolecules
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:56:50 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 11:44:44 GMT""},{""version"":""v3"",""created"":""Fri, 5 Mar 2021 19:43:53 GMT""}]","2021-03-31"
"2011.14987","Dmitri Yafaev","D. R. Yafaev","Universal relations in asymptotic formulas for orthogonal polynomials",,,,,"math.CA math.FA math.SP","http://creativecommons.org/licenses/by/4.0/","  Orthogonal polynomials $P_{n}(\lambda)$ are oscillating functions of $n$ as
$n\to\infty$ for $\lambda$ in the absolutely continuous spectrum of the
corresponding Jacobi operator $J$. We show that, irrespective of any specific
assumptions on coefficients of the operator $J$, amplitude and phase factors in
asymptotic formulas for $P_{n}(\lambda)$ are linked by certain universal
relations found in the paper.
  Our approach relies on a study of operators diagonalizing Jacobi operators.
Diagonalizing operators are constructed in terms of orthogonal polynomials
$P_{n}(\lambda)$. They act from the space $L^2 (\Bbb R)$ of functions into the
space $\ell^2 ({\Bbb Z}_{+})$ of sequences. We consider such operators in a
rather general setting and find necessary and sufficient conditions of their
boundedness.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:57:04 GMT""}]","2020-12-01"
"2011.14988","Dylan Butson","Dylan Butson","Equivariant localization in factorization homology and applications in
  mathematical physics I: Foundations","95 pages, 5 figures, Part I of a series",,,,"math.RT hep-th math.AG math.AT math.QA","http://creativecommons.org/licenses/by/4.0/","  We develop a theory of equivariant factorization algebras on varieties with
an action of a connected algebraic group $G$, extending the definitions of
Francis-Gaitsgory [FG] and Beilinson-Drinfeld [BD1] to the equivariant setting.
We define an equivariant analogue of factorization homology, valued in modules
over $\text{H}^\bullet_G(\text{pt})$, and in the case $G=(\mathbb{C}^\times)^n$
we prove an equivariant localization theorem for factorization homology,
analogous to the classical localization theorem [AtB]. We establish a
relationship between $\mathbb{C}^\times$ equivariant factorization algebras and
filtered quantizations of their restrictions to the fixed point subvariety.
These results provide a model for predictions from the physics literature about
the $\Omega$-background construction introduced in [Nek1], interpreting
factorization $\mathbb{E}_n$ algebras as observables in mixed
holomorphic-topological quantum field theories.
  In the companion paper [Bu2], we develop tools to give geometric
constructions of factorization $\mathbb{E}_n$ algebras, and apply them to
define those corresponding to holomorphic-topological twists of supersymmetric
gauge theories in low dimensions. Further, we apply our above results in these
examples to give an account of the predictions of [CosG] as well as [Beem4],
and explain the relation between these constructions from this perspective.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:57:23 GMT""}]","2020-12-01"
"2011.14989","Hannah Earley","Hannah Earley","The $\aleph$ Calculus","51 pages, 18 figures/listings; update references and acknowledgements",,,,"cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by a need for a model of reversible computation appropriate for a
Brownian molecular architecture, the $\aleph$ calculus is introduced. This
novel model is declarative, concurrent, and term-based--encapsulating all
information about the program data and state within a single structure in order
to obviate the need for a von Neumann-style discrete computational 'machine', a
challenge in a molecular environment. The name is inspired by the Greek for
'not forgotten', due to the emphasis on (reversibly) learning and un-learning
knowledge of different variables. To demonstrate its utility for this purpose,
as well as its elegance as a programming language, a number of examples are
presented; two of these examples, addition/subtraction and
squaring/square-rooting, are furnished with designs for abstract molecular
implementations. A natural by-product of these examples and accompanying
syntactic sugar is the design of a fully-fledged programming language, alethe,
which is also presented along with an interpreter. Efficiently simulating
$\aleph$ on a deterministic computer necessitates some static analysis of
programs within the alethe interpreter in order to render the declarative
programs sequential. Finally, work towards a type system appropriate for such a
reversible, declarative model of computation is presented.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:57:46 GMT""},{""version"":""v2"",""created"":""Fri, 11 Dec 2020 08:29:01 GMT""},{""version"":""v3"",""created"":""Tue, 30 Nov 2021 23:40:14 GMT""}]","2021-12-02"
"2011.14990","Vivek Gopalakrishnan","Vivek Gopalakrishnan, Jaewon Chung, Eric Bridgeford, Benjamin D.
  Pedigo, Jes\'us Arroyo, Lucy Upchurch, G. Allan Johnson, Nian Wang, Youngser
  Park, Carey E. Priebe, Joshua T. Vogelstein","Discovery of Multi-Level Network Differences Across Populations of
  Heterogeneous Connectomes","29 pages, 12 figures",,,,"q-bio.NC stat.ME","http://creativecommons.org/licenses/by/4.0/","  A connectome is a map of the structural and/or functional connections in the
brain. This information-rich representation has the potential to transform our
understanding of the relationship between patterns in brain connectivity and
neurological processes, disorders, and diseases. However, existing
computational techniques used to analyze connectomes are oftentimes
insufficient for interrogating multi-subject connectomics datasets: most
current methods are either solely designed to analyze single connectomes, or
leverage heuristic graph statistics that are unable to capture the complete
topology of connections between brain regions. To enable more rigorous
connectomics analysis, we introduce a set of robust and interpretable
statistical hypothesis tests motivated by recent theoretical advances in random
graph models. These tests facilitate simultaneous analysis of multiple
connectomes across different levels of network topology, enabling the robust
and reproducible discovery of hierarchical brain structures that vary in
relation with phenotypic profiles. In addition to explaining the theoretical
foundations and guarantees of our hypothesis tests, we demonstrate their
superiority over current state-of-the-art connectomics methods through
extensive simulation studies, as well as synthetic and real-data experiments.
Using a set of high-resolution connectomes obtained from genetically distinct
mouse strains (including the BTBR mouse -- a standard model of autism -- and
three behavioral wild-types), we illustrate how our methods can be used to
successfully uncover latent information in multi-subject connectomics data and
yield valuable insights into the connective correlates of neurological
phenotypes. The code necessary to reproduce the analyses, simulations, and
figures presented in this work are available in a series of Jupyter Notebooks
(https://github.com/neurodata/MCC).
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:58:25 GMT""},{""version"":""v2"",""created"":""Wed, 30 Dec 2020 20:31:55 GMT""},{""version"":""v3"",""created"":""Wed, 20 Jan 2021 06:24:43 GMT""},{""version"":""v4"",""created"":""Sat, 28 Aug 2021 17:19:21 GMT""},{""version"":""v5"",""created"":""Wed, 13 Apr 2022 13:29:21 GMT""}]","2022-04-14"
"2011.14991","Navin McGinnis","Radovan Dermisek, Enrico Lunghi, Navin McGinnis, Seodong Shin","Charged and neutral Higgs bosons in final states with six bottom quarks","5 pages, 4 figures. Contribution to Proceedings of The 40th
  International Conference on High Energy Physics, ICHEP-2020; Jul 28-Aug 6,
  2020, Prague, Czech Republic",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In extensions of two Higgs doublet models with vectorlike quarks, the decays
of vectorlike quarks may be easily dominated by cascade decays through charged
or neutral Higgs bosons leading to signatures with 6 top or bottom quarks.
Since top quark decays also contain bottom quarks, the 6 bottom quarks in final
states is a common signature to a large class of possible decay chains. We
present a search strategy focusing on this final state and find the mass ranges
of vectorlike quarks and Higgs bosons that can be explored at the Large Hadron
Collider. Among other results the sensitivity to the charged Higgs boson,
extending above 2 TeV, stands out when compared to models without vectorlike
matter.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:58:26 GMT""}]","2020-12-01"
"2011.14994","Ugur Cetiner","Ugur Cetiner and Jeremy Gunawardena","Reformulating non-equilibrium steady-states and generalised Hopfield
  discrimination","Central results unchanged from previous version. The entropy
  production index, a new graph-theoretic measure of non-equilibrium
  complexity, has been introduced. Added numerical simulations demonstrating
  that optimal discrimination is still possible on a complex graph with only a
  single energetic edge",,,,"cond-mat.stat-mech physics.bio-ph q-bio.MN","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Despite substantial progress in non-equilibrium physics, steady-state (s.s.)
probabilities remain intractable to analysis. For a Markov process, s.s.
probabilities can be expressed in terms of transition rates using the
Matrix-Tree theorem (MTT) in the graph-based linear framework. The MTT reveals
that, away from equilibrium, s.s. probabilities become globally dependent on
all rates, with expressions growing exponentially in the system size. This
overwhelming complexity and lack of thermodynamic interpretation have greatly
impeded analysis. Here, we show that s.s. probabilities are proportional to the
average of $\exp(-S(P))$, where $S(P)$ is the entropy generated along minimal
paths, $P$, in the graph, and the average is taken over a probability
distribution on spanning trees. Assuming Arrhenius rates, this ""arboreal""
distribution becomes Boltzmann-like, with the energy of a tree being its total
edge barrier energy. This reformulation offers a thermodynamic interpretation
that smoothly generalises equilibrium statistical mechanics and reorganises the
expression complexity: the number of distinct minimal-path entropies depends on
the entropy production index, a new graph-theoretic measure of non-equilibrium
complexity, not on graph size. We demonstrate the power of this reformulation
by extending Hopfield's analysis of discrimination by kinetic proofreading to
any graph with index 1. We derive a general formula for the error ratio and use
it to show that local energy dissipation can yield optimal discrimination
through global synergy.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:59:50 GMT""},{""version"":""v2"",""created"":""Sat, 4 Sep 2021 17:09:56 GMT""}]","2021-09-07"
"2011.14995","Edgar Fajardo","Edgar Fajardo, Frank Wuerthwein, Brian Bockelman, Miron Livny, Greg
  Thain, James Alexander Clark, Peter Couvares and Josh Willis","Adapting LIGO workflows to run in the Open Science Grid",,,,,"cs.DC physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  During the first observation run the LIGO collaboration needed to offload
some of its most, intense CPU workflows from its dedicated computing sites to
opportunistic resources. Open Science Grid enabled LIGO to run PyCbC, RIFT and
Bayeswave workflows to seamlessly run in a combination of owned and
opportunistic resources. One of the challenges is enabling the workflows to use
several heterogeneous resources in a coordinated and effective way.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:02:38 GMT""}]","2020-12-01"
"2011.14996","Emily C Hector","Emily C. Hector and Peter X.-K. Song","Joint integrative analysis of multiple data sources with correlated
  vector outcomes","26 pages, 4 figures, 4 tables","The Annals of Applied Statistics 16(3):1700-1717 (2022)","10.1214/21-AOAS1563",,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a distributed quadratic inference function framework to jointly
estimate regression parameters from multiple potentially heterogeneous data
sources with correlated vector outcomes. The primary goal of this joint
integrative analysis is to estimate covariate effects on all outcomes through a
marginal regression model in a statistically and computationally efficient way.
We develop a data integration procedure for statistical estimation and
inference of regression parameters that is implemented in a fully distributed
and parallelized computational scheme. To overcome computational and modeling
challenges arising from the high-dimensional likelihood of the correlated
vector outcomes, we propose to analyze each data source using Qu, Lindsay and
Li (2000)'s quadratic inference functions, and then to jointly reestimate
parameters from each data source by accounting for correlation between data
sources using a combined meta-estimator in a similar spirit to Hansen (1982)'s
generalised method of moments. We show both theoretically and numerically that
the proposed method yields efficiency improvements and is computationally fast.
We illustrate the proposed methodology with the joint integrative analysis of
the association between smoking and metabolites in a large multi-cohort study
and provide an R package for ease of implementation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:03:04 GMT""}]","2022-07-28"
"2011.14997","M Akbari Moghanjoughi","M. Akbari-Moghanjoughi","Resonant Electron-Plasmon Interactions in Drifting Electron Gas","arXiv admin note: substantial text overlap with arXiv:2002.04690",,"10.1063/5.0039067",,"physics.plasm-ph physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  In this paper we investigate the resonant electron-plasmon interactions in a
drifting electron gas of arbitrary degeneracy. The kinetic corrected quantum
hydrodyanmic model is transformed into the effective Schr\""{o}dinger-Poisson
model and driven coupled pseudoforce system is obtained via the separation of
variables from the appropriately linearized system. It is remarked that in the
low phase-speed kinetic regime the characteristic particle-like plasmon branch
is profoundly affected by this correction which is a function of the electron
number density and temperature. We also present an alternative explanation of
the quantum wave-particle duality as a direct consequence of resonant
electron-plasmon interaction (electron murmuration). In this picture drifting
electrons are resonantly scattered by spatial electrostatic energy
distribution, characterizing them by the de Broglie's oscillations. The
phase-shift and amplitude of excitations in damped driven pseudoforce system is
derived and their variations in terms of normalized chemical potential and
electron temperature is studied. In particular we investigate the kinetic
correction effect on energy dispersion relation in the electron gas in detail.
It is revealed that only the low phase-speed branch of the dispersion curve is
significantly affected by the kinetic correction. It is also found that
increase in the electron number density leads to increase in effective mass and
consequently decrease in electron mobility while the increase in the electron
temperature has the converse effect. The kinetic correction also significantly
lowers the plasmon conduction band. Current model may be further elaborated to
investigate the beam-plasmon interaction and energy exchange in multispecies
quantum plasmas.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:04:08 GMT""},{""version"":""v2"",""created"":""Thu, 14 Jan 2021 14:54:48 GMT""}]","2021-02-24"
"2011.14998","Frederik De Ceuster","Frederik De Ceuster, Jan Bolte, Ward Homan, Silke Maes, Jolien
  Malfait, Leen Decin, Jeremy Yates, Peter Boyle, and James Hetherington","Magritte, a modern software library for 3D radiative transfer: II.
  Adaptive ray-tracing, mesh construction and reduction","12 pages, published in MNRAS",,"10.1093/mnras/staa3199",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radiative transfer is a notoriously difficult and computationally demanding
problem. Yet, it is an indispensable ingredient in nearly all astrophysical and
cosmological simulations. Choosing an appropriate discretization scheme is a
crucial part of the simulation, since it not only determines the direct memory
cost of the model but also largely determines the computational cost and the
achievable accuracy. In this paper, we show how an appropriate choice of
directional discretization scheme as well as spatial model mesh can help
alleviate the computational cost, while largely retaining the accuracy. First,
we discuss the adaptive ray-tracing scheme implemented in our 3D radiative
transfer library Magritte, that adapts the rays to the spatial mesh and uses a
hierarchical directional discretization based on HEALPix. Second, we
demonstrate how the free and open-source software library Gmsh can be used to
generate high quality meshes that can be easily tailored for Magritte. In
particular, we show how the local element size distribution of the mesh can be
used to optimise the sampling of both analytically and numerically defined
models. Furthermore, we show that when using the output of hydrodynamics
simulations as input for a radiative transfer simulation, the number of
elements in the input model can often be reduced by an order of magnitude,
without significant loss of accuracy in the radiation field. We demonstrate
this for two models based on a hierarchical octree mesh resulting from adaptive
mesh refinement (AMR), as well as two models based on smoothed-particle
hydrodynamics (SPH) data.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:04:36 GMT""}]","2020-12-01"
"2011.14999","Ryan Giordano","Tamara Broderick, Ryan Giordano, and Rachael Meager","An Automatic Finite-Sample Robustness Metric: When Can Dropping a Little
  Data Make a Big Difference?","53 pages. Submitted to the Quarterly Journal of Economics",,,,"stat.ME econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Study samples often differ from the target populations of inference and
policy decisions in non-random ways. Researchers typically believe that such
departures from random sampling -- due to changes in the population over time
and space, or difficulties in sampling truly randomly -- are small, and their
corresponding impact on the inference should be small as well. We might
therefore be concerned if the conclusions of our studies are excessively
sensitive to a very small proportion of our sample data. We propose a method to
assess the sensitivity of applied econometric conclusions to the removal of a
small fraction of the sample. Manually checking the influence of all possible
small subsets is computationally infeasible, so we use an approximation to find
the most influential subset. Our metric, the ""Approximate Maximum Influence
Perturbation,"" is based on the classical influence function, and is
automatically computable for common methods including (but not limited to) OLS,
IV, MLE, GMM, and variational Bayes. We provide finite-sample error bounds on
approximation performance. At minimal extra cost, we provide an exact
finite-sample lower bound on sensitivity. We find that sensitivity is driven by
a signal-to-noise ratio in the inference problem, is not reflected in standard
errors, does not disappear asymptotically, and is not due to misspecification.
While some empirical applications are robust, results of several influential
economics papers can be overturned by removing less than 1% of the sample.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:05:48 GMT""},{""version"":""v2"",""created"":""Sat, 17 Apr 2021 14:11:11 GMT""},{""version"":""v3"",""created"":""Wed, 3 Nov 2021 16:58:05 GMT""},{""version"":""v4"",""created"":""Thu, 9 Mar 2023 20:58:25 GMT""}]","2023-03-13"
"2011.15000","Abhijeet Patil","Abhijeet Patil, Mohd. Talha, Aniket Bhatia, Nikhil Cherian Kurian,
  Sammed Mangale, Sunil Patel, Amit Sethi","Fast, Self Supervised, Fully Convolutional Color Normalization of H&E
  Stained Images","--",,,,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Performance of deep learning algorithms decreases drastically if the data
distributions of the training and testing sets are different. Due to variations
in staining protocols, reagent brands, and habits of technicians, color
variation in digital histopathology images is quite common. Color variation
causes problems for the deployment of deep learning-based solutions for
automatic diagnosis system in histopathology. Previously proposed color
normalization methods consider a small patch as a reference for normalization,
which creates artifacts on out-of-distribution source images. These methods are
also slow as most of the computation is performed on CPUs instead of the GPUs.
We propose a color normalization technique, which is fast during its
self-supervised training as well as inference. Our method is based on a
lightweight fully-convolutional neural network and can be easily attached to a
deep learning-based pipeline as a pre-processing block. For classification and
segmentation tasks on CAMELYON17 and MoNuSeg datasets respectively, the
proposed method is faster and gives a greater increase in accuracy than the
state of the art methods.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:05:58 GMT""}]","2020-12-01"
"2011.15001","Morgane Menz","Morgane Menz, Sylvain Dubreuil, J\'er\^ome Morio, Christian Gogu,
  Nathalie Bartoli and Marie Chiron","Variance based sensitivity analysis for Monte Carlo and importance
  sampling reliability assessment with Gaussian processes",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Running a reliability analysis on engineering problems involving complex
numerical models can be computationally very expensive, requiring advanced
simulation methods to reduce the overall numerical cost. Gaussian process based
active learning methods for reliability analysis have emerged as a promising
way for reducing this computational cost. The learning phase of these methods
consists in building a Gaussian process surrogate model of the performance
function and using the uncertainty structure of the Gaussian process to enrich
iteratively this surrogate model. For that purpose a learning criterion has to
be defined. Then, the estimation of the probability of failure is typically
obtained by a classification of a population evaluated on the final surrogate
model. Hence, the estimator of the probability of failure holds two different
uncertainty sources related to the surrogate model approximation and to the
sampling based integration technique. In this paper, we propose a methodology
to quantify the sensitivity of the probability of failure estimator to both
uncertainty sources. This analysis also enables to control the whole error
associated to the failure probability estimate and thus provides an accuracy
criterion on the estimation. Thus, an active learning approach integrating this
analysis to reduce the main source of error and stopping when the global
variability is sufficiently low is introduced. The approach is proposed for
both a Monte Carlo based method as well as an importance sampling based method,
seeking to improve the estimation of rare event probabilities. Performance of
the proposed strategy is then assessed on several examples.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:06:28 GMT""}]","2020-12-01"
"2011.15002","Jinjin Gu","Jinjin Gu, Haoming Cai, Haoyu Chen, Xiaoxing Ye, Jimmy Ren, Chao Dong","Image Quality Assessment for Perceptual Image Restoration: A New
  Dataset, Benchmark and Metric","arXiv admin note: substantial text overlap with arXiv:2007.12142",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Image quality assessment (IQA) is the key factor for the fast development of
image restoration (IR) algorithms. The most recent perceptual IR algorithms
based on generative adversarial networks (GANs) have brought in significant
improvement on visual performance, but also pose great challenges for
quantitative evaluation. Notably, we observe an increasing inconsistency
between perceptual quality and the evaluation results. We present two
questions: Can existing IQA methods objectively evaluate recent IR algorithms?
With the focus on beating current benchmarks, are we getting better IR
algorithms? To answer the questions and promote the development of IQA methods,
we contribute a large-scale IQA dataset, called Perceptual Image Processing
ALgorithms (PIPAL) dataset. Especially, this dataset includes the results of
GAN-based IR algorithms, which are missing in previous datasets. We collect
more than 1.13 million human judgments to assign subjective scores for PIPAL
images using the more reliable Elo system. Based on PIPAL, we present new
benchmarks for both IQA and SR methods. Our results indicate that existing IQA
methods cannot fairly evaluate GAN-based IR algorithms. While using appropriate
evaluation methods is important, IQA methods should also be updated along with
the development of IR algorithms. At last, we shed light on how to improve the
IQA performance on GAN-based distortion. Inspired by the find that the existing
IQA methods have an unsatisfactory performance on the GAN-based distortion
partially because of their low tolerance to spatial misalignment, we propose to
improve the performance of an IQA network on GAN-based distortion by explicitly
considering this misalignment. We propose the Space Warping Difference Network,
which includes the novel l_2 pooling layers and Space Warping Difference
layers. Experiments demonstrate the effectiveness of the proposed method.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:06:46 GMT""}]","2020-12-01"
"2011.15003","Christoph Boeddeker","Christoph Boeddeker, Wangyou Zhang, Tomohiro Nakatani, Keisuke
  Kinoshita, Tsubasa Ochiai, Marc Delcroix, Naoyuki Kamo, Yanmin Qian, Reinhold
  Haeb-Umbach","Convolutive Transfer Function Invariant SDR training criteria for
  Multi-Channel Reverberant Speech Separation","Accepted by ICASSP 2021",,,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time-domain training criteria have proven to be very effective for the
separation of single-channel non-reverberant speech mixtures. Likewise,
mask-based beamforming has shown impressive performance in multi-channel
reverberant speech enhancement and source separation. Here, we propose to
combine neural network supported multi-channel source separation with a
time-domain training objective function. For the objective we propose to use a
convolutive transfer function invariant Signal-to-Distortion Ratio (CI-SDR)
based loss. While this is a well-known evaluation metric (BSS Eval), it has not
been used as a training objective before. To show the effectiveness, we
demonstrate the performance on LibriSpeech based reverberant mixtures. On this
task, the proposed system approaches the error rate obtained on single-source
non-reverberant input, i.e., LibriSpeech test_clean, with a difference of only
1.2 percentage points, thus outperforming a conventional permutation invariant
training based system and alternative objectives like Scale Invariant
Signal-to-Distortion Ratio by a large margin.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:08:19 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 08:43:20 GMT""},{""version"":""v3"",""created"":""Mon, 7 Jun 2021 15:02:05 GMT""},{""version"":""v4"",""created"":""Tue, 8 Jun 2021 07:40:08 GMT""}]","2021-06-09"
"2011.15004","Erik van Zwet","Erik van Zwet and Simon Schwab and Stephen Senn","The statistical properties of RCTs and a proposal for shrinkage","13 pages, 5 figures",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  We abstract the concept of a randomized controlled trial (RCT) as a triple
(beta,b,s), where beta is the primary efficacy parameter, b the estimate and s
the standard error (s>0). The parameter beta is either a difference of means, a
log odds ratio or a log hazard ratio. If we assume that b is unbiased and
normally distributed, then we can estimate the full joint distribution of
(beta,b,s) from a sample of pairs (b_i,s_i). We have collected 23,747 such
pairs from the Cochrane database to do so. Here, we report the estimated
distribution of the signal-to-noise ratio beta/s and the achieved power. We
estimate the median achieved power to be 0.13. We also consider the
exaggeration ratio which is the factor by which the magnitude of beta is
overestimated. We find that if the estimate is just significant at the 5%
level, we would expect it to overestimate the true effect by a factor of 1.7.
This exaggeration is sometimes referred to as the winner's curse and it is
undoubtedly to a considerable extent responsible for disappointing replication
results. For this reason, we believe it is important to shrink the unbiased
estimator, and we propose a method for doing so.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:09:20 GMT""}]","2020-12-01"
"2011.15005","Alexey Guskov","A. Arbuzov, A. Bacchetta, M. Butenschoen, F.G. Celiberto, U. D'Alesio,
  M. Deka, I. Denisenko, M. G. Echevarria, A. Efremov, N.Ya. Ivanov, A. Guskov,
  A. Karpishkov, Ya. Klopot, B. A. Kniehl, A. Kotzinian, S. Kumano, J.P.
  Lansberg, Keh-Fei Liu, F. Murgia, M. Nefedov, B. Parsamyan, C. Pisano, M.
  Radici, A. Rymbekova, V. Saleev, A. Shipilova, Qin-Tao Song, O. Teryaev","On the physics potential to study the gluon content of proton and
  deuteron at NICA SPD","arXiv admin note: text overlap with arXiv:2102.00442",,,,"hep-ex hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  The Spin Physics Detector (SPD) is a future multipurpose experiment foreseen
to run at the NICA collider, which is currently under construction at the Joint
Institute for Nuclear Research (JINR, Dubna, Russia). The physics program of
the experiment is based on collisions of longitudinally and transversely
polarized protons and deuterons at $\sqrt{s}$ up to 27 GeV and luminosity up to
10$^{32}$ cm$^{-2}$ s$^{-1}$. The SPD will operate as a universal facility for
comprehensive study of unpolarized and polarized gluon content of the nucleon,
using different complementary probes such as: charmonia, open charm, and prompt
photon production processes. The aim of this work is to make a thorough review
of the physics objectives that can potentially be addressed at the SPD,
underlining related theoretical aspects and discussing relevant experimental
results when available. Among different pertinent phenomena particular
attention is drawn to the study of the gluon helicity, gluon Sivers and
Boer-Mulders functions in the nucleon, as well as the gluon transversity
distribution in the deuteron, via the measurement of specific single and double
spin asymmetries.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:11:53 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 11:02:21 GMT""},{""version"":""v3"",""created"":""Sat, 27 Feb 2021 21:21:31 GMT""},{""version"":""v4"",""created"":""Tue, 1 Jun 2021 19:42:40 GMT""}]","2021-06-03"
"2011.15006","Alexandre Rege","Alexandre Rege","The Vlasov-Poisson system with a uniform magnetic field: propagation of
  moments and regularity","23 pages. All comments are welcome!",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show propagation of moments in velocity for the 3-dimensional
Vlasov-Poisson system with a uniform magnetic field $B = (0, 0, {\omega})$ by
adapting the work of Lions, Perthame. The added magnetic field also produces
singularities at times which are the multiples of the cyclotron period $t =
\dfrac{2\pi k}{\omega}, k \in \mathbb{N}$ . This result also allows to show
propagation of regularity for the solution. For uniqueness, we extend Loeper's
result by showing that the set of solutions with bounded macroscopic density is
a uniqueness class.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:12:15 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 11:44:36 GMT""}]","2020-12-22"
"2011.15007","Brady Neal","Brady Neal, Chin-Wei Huang, Sunand Raghupathi","RealCause: Realistic Causal Inference Benchmarking",,,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  There are many different causal effect estimators in causal inference.
However, it is unclear how to choose between these estimators because there is
no ground-truth for causal effects. A commonly used option is to simulate
synthetic data, where the ground-truth is known. However, the best causal
estimators on synthetic data are unlikely to be the best causal estimators on
real data. An ideal benchmark for causal estimators would both (a) yield
ground-truth values of the causal effects and (b) be representative of real
data. Using flexible generative models, we provide a benchmark that both yields
ground-truth and is realistic. Using this benchmark, we evaluate over 1500
different causal estimators and provide evidence that it is rational to choose
hyperparameters for causal estimators using predictive metrics.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:12:18 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 14:14:37 GMT""}]","2021-03-30"
"2011.15008","Tao Yu","Tao Yu, Chen Wang, Michael A. Sentef, Gerrit E. W. Bauer","Spin-Wave Doppler Shift by Magnon Drag in Magnetic Insulators","6 pages, 4 figures","Phys. Rev. Lett. 126, 137202 (2021)","10.1103/PhysRevLett.126.137202",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-sa/4.0/","  The Doppler shift of the quasiparticle dispersion by charge currents is
responsible for the critical supercurrents in superconductors and instabilities
of the magnetic ground state of metallic ferromagnets. Here we predict an
analogous effect in thin films of magnetic insulators in which microwaves
emitted by a proximity stripline generate coherent chiral spin currents that
cause a Doppler shift in the magnon dispersion. The spin-wave instability is
suppressed by magnon-magnon interactions that limit spin currents to values
close to but below the threshold for the instability. The spin current
limitations by the backaction of magnon currents on the magnetic order should
be considered as design parameters in magnonic devices.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:12:23 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 15:19:45 GMT""}]","2021-04-07"
"2011.15009","Maxime Gheysens","Maxime Gheysens","Dynamics and structure of groups of homeomorphisms of scattered spaces",,,,,"math.GR math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the topological structure and the topological dynamics of groups of
homeomorphisms of scattered spaces. For a large class of them (including the
homeomorphism group of any ordinal space or of any locally compact scattered
space), we establish Roelcke-precompactness and amenability, classify all
closed normal subgroups and compute the universal minimal flow. As a
by-product, we classify up to isomorphism the homeomorphism groups of compact
ordinal spaces.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:12:49 GMT""}]","2020-12-01"
"2011.15010","Chengcheng Yang","Chengcheng Yang","A Problem of Erd\""{o}s Concerning Lattice Cubes",,,,,"math.CO math.CA","http://creativecommons.org/licenses/by/4.0/","  This paper studies a problem of Erd\""{o}s concerning lattice cubes. Given an
$N \times N \times N$ lattice cube, we want to find the maximum number of
vertices one can select so that no eight corners of a rectangular box are
chosen simultaneously. Erd\""{o}s conjectured that it has a sharp upper bound,
which is $O(N^{11/4})$, but no example that large has been found yet. We start
approaching this question for small $N$ using the method of exhaustion, and we
find that there is not necessarily a unique maximal set of vertices (counting
all possible symmetries). Next, we study an equivalent two-dimensional version
of this problem looking for patterns that might be useful for generalizing to
the three-dimensional case. Since an $n \times n$ grid is also an $n \times n$
matrix, we rephrase and generalize the original question to: what is the
minimum number $\alpha(k,n)$ of vertices one can put in an $n \times n$ matrix
with entries 0 and 1, such that every $k \times k$ minor contains at least one
entry of 1, for $1 \leq k \leq n$? We discover some interesting formulas and
asymptotic patterns that shed new light on the question.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:13:04 GMT""}]","2020-12-01"
"2011.15011","Carlos Handy","Carlos R. Handy","Generating Converging Eigenenergy Bounds for Multidimensional Systems: A
  New Moment Representation, Algebraic, Quantization Formalism","28 pages, 3 Figures, 5 Tables",,,,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For low dimension systems admitting a moment equation representation (MER),
the development of an effective eigenenergy bounding theory applicable to all
discrete states had remained elusive, until now. Whereas Handy et al (1988
Phys. Rev. Lett. 60 253) demonstrated the effectiveness of the {\it Moment
Problem} based, Eigenvalue Moment Method (EMM), for generating arbitrarily
tight bounds to the multidimensional, positive, bosonic ground state, its
extension to arbitrary excited states seemed intractable. We have discovered a
new, moment representation based, quantization formalism that achieves this.
Unlike EMM, no convex optimization methods are required. The entire formulation
is algebraic. As a result of our preliminary investigation, we are able to
match, or surpass, the excellent, but intricate, analysis of Kravchenko et al
(1996 Phys. Rev. A 54 287) with respect to the quadratic Zeeman effect, for a
broad range of magnetic field strengths. Unlike their analysis, the proposed
method is simple, involves no truncations, and the projection of the quantum
operator is exact, within each moment subspace. Our new approach, the
Orthogonal Polynomial Projection Quantization-Bounding Method (OPPQ-BM),
exploits the implicit bounding capabilities of a previous method developed by
Handy and Vrinceanu (2013 J. of Phys. A: Math. Theor. 46 135202). What emerges
is a completely new type of analysis (i.e. constrained quadratic form
minimization) that validates the importance of moment equation representations
for quantizing physical systems. Whereas the underlying principles of EMM
guarantee it to be more efficient than OPPQ-BM, the ability to implement
algebraic computations, as opposed to pursuing nonlinear convex optimization
methods (which can be relaxed through linear programming alternatives)
recommends OPPQ-BM. We give an overview of the new method with applications.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:13:45 GMT""}]","2020-12-01"
"2011.15012","Peter Morfe","Peter S. Morfe","Homogenization of the Allen-Cahn equation with periodic mobility",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We analyze the sharp interface limit for the Allen-Cahn equation with an
anisotropic, spatially periodic mobility coefficient and prove that the
large-scale behavior of interfaces is determined by mean curvature flow with an
effective mobility. Formally, the result follows from the asymptotics developed
by Barles and Souganidis for bistable reaction-diffusion equations with
periodic coefficients. However, we show that the corresponding cell problem is
actually ill-posed when the normal direction is rational. To circumvent this
issue, a number of new ideas are needed, both in the construction of mesoscopic
sub- and supersolutions controlling the large-scale behavior of interfaces and
in the proof that the interfaces obtained in the limit are actually described
by the effective equation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:14:56 GMT""}]","2020-12-01"
"2011.15013","Brijesh Dongol","Eleni Bila, John Derrick, Simon Doherty, Brijesh Dongol, Gerhard
  Schellhorn, and Heike Wehrheim","Modularising Verification Of Durable Opacity",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Non-volatile memory (NVM), also known as persistent memory, is an emerging
paradigm for memory that preserves its contents even after power loss. NVM is
widely expected to become ubiquitous, and hardware architectures are already
providing support for NVM programming. This has stimulated interest in the
design of novel concepts ensuring correctness of concurrent programming
abstractions in the face of persistency and in the development of associated
verification approaches.
  Software transactional memory (STM) is a key programming abstraction that
supports concurrent access to shared state. In a fashion similar to
linearizability as the correctness condition for concurrent data structures,
there is an established notion of correctness for STMs known as opacity. We
have recently proposed durable opacity as the natural extension of opacity to a
setting with non-volatile memory. Together with this novel correctness
condition, we designed a verification technique based on refinement. In this
paper, we extend this work in two directions. First, we develop a durably
opaque version of NOrec (no ownership records), an existing STM algorithm
proven to be opaque. Second, we modularise our existing verification approach
by separating the proof of durability of memory accesses from the proof of
opacity. For NOrec, this allows us to re-use an existing opacity proof and
complement it with a proof of the durability of accesses to shared state.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:15:35 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 09:07:47 GMT""},{""version"":""v3"",""created"":""Fri, 28 Jan 2022 15:51:36 GMT""},{""version"":""v4"",""created"":""Mon, 13 Jun 2022 08:46:26 GMT""},{""version"":""v5"",""created"":""Wed, 27 Jul 2022 15:18:14 GMT""}]","2022-07-28"
"2011.15014","Wanxin Jin","Wanxin Jin, Todd D. Murphey, Zehui Lu, Shaoshuai Mou","Learning from Human Directional Corrections","This is a preprint. The published version can be accessed at IEEE
  Transactions on Robotics",,,,"cs.RO cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a novel approach that enables a robot to learn an
objective function incrementally from human directional corrections. Existing
methods learn from human magnitude corrections; since a human needs to
carefully choose the magnitude of each correction, those methods can easily
lead to over-corrections and learning inefficiency. The proposed method only
requires human directional corrections -- corrections that only indicate the
direction of an input change without indicating its magnitude. We only assume
that each correction, regardless of its magnitude, points in a direction that
improves the robot's current motion relative to an unknown objective function.
The allowable corrections satisfying this assumption account for half of the
input space, as opposed to the magnitude corrections which have to lie in a
shrinking level set. For each directional correction, the proposed method
updates the estimate of the objective function based on a cutting plane method,
which has a geometric interpretation. We have established theoretical results
to show the convergence of the learning process. The proposed method has been
tested in numerical examples, a user study on two human-robot games, and a
real-world quadrotor experiment. The results confirm the convergence of the
proposed method and further show that the method is significantly more
effective (higher success rate), efficient/effortless (less human corrections
needed), and potentially more accessible (fewer early wasted trials) than the
state-of-the-art robot learning frameworks.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:16:39 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 23:54:39 GMT""},{""version"":""v3"",""created"":""Fri, 5 Aug 2022 15:21:36 GMT""}]","2022-08-08"
"2011.15015","Xiang Ni","Xiang Ni, Zhen Yang, Jianyu Li","Scaling behavior of fracture properties of tough adhesive hydrogels","submitted to ACS Macro Letters",,,,"cond-mat.soft","http://creativecommons.org/licenses/by-sa/4.0/","  Tough adhesive hydrogels find broad applications in engineering and medicine.
Such hydrogels feature high resistance against both cohesion and adhesion
failure. The superior fracture properties may, however, deteriorate when the
hydrogels swell upon exposure of water. The underlying correlation between the
polymer fraction and fracture properties of tough adhesive hydrogels remains
largely unexplored. Here we study how the cohesion and adhesion energies of a
tough adhesive hydrogel evolve with the swelling process. The results reveal a
similar scaling law of the two quantities on the polymer fraction. Our scaling
analysis and computational study reveal that it stems from the scaling of shear
modulus. The study will promote the investigation of scaling of hydrogel
fracture and provide development guidelines for new tough adhesive hydrogels.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:16:56 GMT""}]","2020-12-01"
"2011.15016","Thao Phuong Le","Thao P. Le and Alexandra Olaya-Castro","Basis-independent system-environment coherence is necessary to detect
  magnetic field direction in an avian-inspired quantum magnetic sensor","10 + 13 pages, 6 figures. Comments welcomed",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advancing our understanding of non-trivial quantum effects in biomolecular
complexes operating in physiological conditions requires the precise
characterisation of the non-classicalities that may be present in such systems
as well as asserting whether such features are required for robust function.
Here we consider an avian-inspired quantum magnetic sensor composed of two
radicals with a third ""scavenger"" radical under the influence of a collisional
environment that allows to capture a variety of decoherence processes. We show
that basis-independent coherence, in which the initial system-environment state
is non-maximally mixed, is necessary for optimal performance of the quantum
magnetic sensor, and appears to be sufficient in particular situations. We
discuss how such non-maximally mixed initial states may be common for a variety
of biomolecular scenarios. Our results therefore suggest that a small degree of
coherence--regardless of basis--is likely to be a quantum resource for
biomolecular systems operating at the interface between the quantum and
classical domains.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:19:17 GMT""}]","2020-12-01"
"2011.15017","Lucas Pili","D. Slobinsky, L. Pili, G. Baglietto, S. A. Grigera, R. A. Borzi","Monopole matter from magnetoelastic coupling in the Ising pyrochlore",,,,,"cond-mat.str-el cond-mat.stat-mech","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Ising models on a pyrochlore oxide lattice are usually associated with spin
ice materials and ""magnetic monopoles"". Ever more often effects connecting
magnetic and elastic degrees of freedom are reported on these and other related
frustrated materials. Here we extend a spin-ice Hamiltonian to include coupling
between spins and the O$^{-2}$ ions mediating superexchange; we call it the
Magnetoelastic Spin Ice model (MeSI). There has been a long search for a model
in which monopoles would spontaneously become the building blocks of new
ground-states: the MeSI Hamiltonian is such a model. In spite of its simplicity
and classical approach, it describes (both spin and oxygen lattice) the
double-layered monopole crystal observed in Tb$_2$Ti$_2$O$_7$. Remarkably, the
dipolar electric moment of single monopoles emerges as a probe for magnetism.
As an example we show that, in principle, pinch points related to Coulomb
phases could be detected in association with the O$^{-2}$-ion displacements.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:19:34 GMT""}]","2020-12-01"
"2011.15018","Giovanni Arico'","Giovanni Aric\`o, Raul E. Angulo, Sergio Contreras, Lurdes
  Ondaro-Mallea, Marcos Pellejero-Iba\~nez, Matteo Zennaro","The BACCO Simulation Project: A baryonification emulator with Neural
  Networks","13 pages, 11 figures. Comments are welcome",,"10.1093/mnras/stab1911",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a neural-network emulator for baryonic effects in the non-linear
matter power spectrum. We calibrate this emulator using more than 50,000
measurements in a 15-dimensional parameters space, varying cosmology and
baryonic physics. Baryonic physics is described through a baryonification
algorithm, that has been shown to accurately capture the relevant effects on
the power spectrum and bispectrum in state-of-the-art hydrodynamical
simulations. Cosmological parameters are sampled using a cosmology-rescaling
approach including massive neutrinos and dynamical dark energy. The specific
quantity we emulate is the ratio between matter power spectrum with baryons and
gravity-only, and we estimate the overall precision of the emulator to be 1-2%,
at all scales 0.01 < k < 5 h/Mpc, and redshifts 0 < z < 1.5. We also obtain an
accuracy of 1-2%, when testing the emulator against a collection of 74
different cosmological hydrodynamical simulations and their respective
gravity-only counterparts. We show also that only one baryonic parameter,
namely Mc, which set the gas fraction retained per halo mass, is enough to have
accurate and realistic predictions of the baryonic feedback at a given epoch.
Our emulator will become publicly available in http://www.dipc.org/bacco.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:19:49 GMT""}]","2021-08-11"
"2011.15019","Jes\'us Garc\'ia D\'iaz","Jes\'us Garc\'ia D\'iaz, Julio C\'esar P\'erez Sansalvador, Lil
  Mar\'ia Xibai Rodr\'iguez Henr\'iquez, Jos\'e Alejandro Cornejo Acosta","Burning graphs through farthest-first traversal",,,"10.1109/ACCESS.2022.3159695",,"cs.DS cs.DM","http://creativecommons.org/licenses/by/4.0/","  The graph burning problem is an NP-hard combinatorial optimization problem
that helps quantify the vulnerability of a graph to contagion. This paper
introduces a simple farthest-first traversal-based approximation algorithm for
this problem over general graphs. We refer to this proposal as the Burning
Farthest-First (BFF) algorithm. BFF runs in $O(n^3)$ steps and has an
approximation factor of $3-2/b(G)$, where $b(G)$ is the size of an optimal
solution. Despite its simplicity, BFF tends to generate near-optimal solutions
when tested over some benchmark datasets; in fact, it returns similar solutions
to those returned by much more elaborated heuristics from the literature.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:23:06 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 23:22:08 GMT""},{""version"":""v3"",""created"":""Sat, 6 Feb 2021 22:30:54 GMT""},{""version"":""v4"",""created"":""Mon, 13 Dec 2021 18:04:58 GMT""}]","2022-03-21"
"2011.15020","Moonyoung Lee","Moonyoung Lee, Youngsun Kwon, Sebin Lee, JongHun Choe, Junyong Park,
  Hyobin Jeong, Yujin Heo, Min-su Kim, Jo Sungho, Sung-Eui Yoon, Jun-Ho Oh","Dynamic Humanoid Locomotion over Uneven Terrain With Streamlined
  Perception-Control Pipeline","Submitted to Int. Conf. Robotics and Automation (ICRA) 2021",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Although bipedal locomotion provides the ability to traverse unstructured
environments, it requires careful planning and control to safely walk across
without falling. This poses an integrated challenge for the robot to perceive,
plan, and control its movements, especially with dynamic motions where the
robot may have to adapt its swing-leg trajectory onthe-fly in order to safely
place its foot on the uneven terrain. In this paper we present an efficient
geometric footstep planner and the corresponding walking controller that
enables a humanoid robot to dynamically walk across uneven terrain at speeds up
to 0.3 m/s. As dynamic locomotion, we refer first to the continuous walking
motion without stopping, and second to the on-the-fly replanning of the landing
footstep position in middle of the swing phase during the robot gait cycle.
This is mainly achieved through the streamlined integration between an
efficient sampling-based planner and robust walking controller. The footstep
planner is able to generate feasible footsteps within 5 milliseconds, and the
controller is able to generate a new corresponding swing leg trajectory as well
as the wholebody motion to dynamically balance the robot to the newly updated
footsteps. The proposed perception-control pipeline is evaluated and
demonstrated with real experiments using a fullscale humanoid to traverse
across uneven terrains featured by static stepping stones, dynamically movable
stepping stone, or narrow path.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:23:14 GMT""}]","2020-12-01"
"2011.15021","Daniel Gratzer","Daniel Gratzer, G.A. Kavvos, Andreas Nuyts, Lars Birkedal","Multimodal Dependent Type Theory",,"Logical Methods in Computer Science, Volume 17, Issue 3 (July 28,
  2021) lmcs:7713","10.46298/lmcs-17(3:11)2021",,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  We introduce MTT, a dependent type theory which supports multiple modalities.
MTT is parametrized by a mode theory which specifies a collection of modes,
modalities, and transformations between them. We show that different choices of
mode theory allow us to use the same type theory to compute and reason in many
modal situations, including guarded recursion, axiomatic cohesion, and
parametric quantification. We reproduce examples from prior work in guarded
recursion and axiomatic cohesion, thereby demonstrating that MTT constitutes a
simple and usable syntax whose instantiations intuitively correspond to
previous handcrafted modal type theories. In some cases, instantiating MTT to a
particular situation unearths a previously unknown type theory that improves
upon prior systems. Finally, we investigate the metatheory of MTT. We prove the
consistency of MTT and establish canonicity through an extension of recent
type-theoretic gluing techniques. These results hold irrespective of the choice
of mode theory, and thus apply to a wide variety of modal situations.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:23:34 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 13:08:02 GMT""},{""version"":""v3"",""created"":""Tue, 27 Jul 2021 13:34:30 GMT""}]","2021-10-04"
"2011.15022","Amar Sarkar","Amar Deep Sarkar","Boundary behaviour of the Span metric and its higher-order curvatures",,,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  In this note, we use scaling principle to study the boundary behaviour of the
span metric and its higher-order curvatures on finitely connected Jordan planar
domains. A localization of this metric near boundary points of finitely
connected Jordan domains is also obtained. Further, we obtain boundary sharp
estimates for this metric on $ C^2 $-smooth bounded domains and consequently,
this metric is comparable to the Carath\'eodory and the Kobayashi metrics on
these domains.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:23:36 GMT""}]","2020-12-01"
"2011.15023","Siddharth Dalmia","Siddharth Dalmia, Yuzong Liu, Srikanth Ronanki, Katrin Kirchhoff","Transformer-Transducers for Code-Switched Speech Recognition","Accepted at ICASSP 2021",,,,"cs.CL eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We live in a world where 60% of the population can speak two or more
languages fluently. Members of these communities constantly switch between
languages when having a conversation. As automatic speech recognition (ASR)
systems are being deployed to the real-world, there is a need for practical
systems that can handle multiple languages both within an utterance or across
utterances. In this paper, we present an end-to-end ASR system using a
transformer-transducer model architecture for code-switched speech recognition.
We propose three modifications over the vanilla model in order to handle
various aspects of code-switching. First, we introduce two auxiliary loss
functions to handle the low-resource scenario of code-switching. Second, we
propose a novel mask-based training strategy with language ID information to
improve the label encoder training towards intra-sentential code-switching.
Finally, we propose a multi-label/multi-audio encoder structure to leverage the
vast monolingual speech corpora towards code-switching. We demonstrate the
efficacy of our proposed approaches on the SEAME dataset, a public
Mandarin-English code-switching corpus, achieving a mixed error rate of 18.5%
and 26.3% on test_man and test_sge sets respectively.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:27:41 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 02:46:51 GMT""}]","2021-02-16"
"2011.15024","Zhiyuan Yao","Zhiyuan Yao, Feng Yuan, Jeremiah P. Ostriker","Active Galactic Nucleus Feedback in an Elliptical Galaxy with the Most
  Updated AGN Physics: Parameter Explorations","Accepted for publication in MNRAS",,"10.1093/mnras/staa3755",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In a previous work, we have proposed a sub-grid model of active galactic
nucleus (AGN) feedback by taking into account the state-of-the-art AGN physics,
and used that model to study the effect of AGN feedback on the evolution of an
isolated elliptical galaxy by performing two dimensional high-resolution (i.e.,
the Bondi radius is well resolved) simulations. In that work, typical values of
model parameters were adopted. In the present work, we extend that study by
exploring the effects of uncertainties of parameter values. Such a study is
also useful for us to understand the respective roles of various components of
the model. These parameters include the mass flux and velocity of AGN wind and
radiative efficiency in both the hot and cold feedback modes, and the initial
black hole (BH) mass. We find that the velocity of AGN wind in the hot mode is
the most important quantity to control the typical accretion rate and
luminosity of AGN, and the mass growth of the BH. The effect of the wind on
star formation is less sensitive. Within the limited parameter range explored
in the current work, a stronger AGN wind suppresses star formation within ~100
pc but enhances star formation beyond this radius, while the star formation
integrated over the evolution time and the whole galaxy roughly remain
unchanged. AGN radiation suppresses the BH accretion in a mild way, but dust is
not considered here. Finally, a smaller initial BH mass results in a more
violent evolution of the BH accretion rate. The corresponding AGN spends more
time in the high-luminosity state and the percentage of BH mass growth is
higher. Our results indicate the robustness of AGN feedback in keeping the
galaxy quenched.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:27:51 GMT""}]","2020-12-08"
"2011.15025","Jiri Kovar","Ji\v{r}\'i Kov\'a\v{r}, Yasufumi Kojima, Petr Slan\'y, Zden\v{e}k
  Stuchl\'ik, Vladim\'ir Karas","Charged fluids encircling compact objects: force representations and
  conformal geometries","23 pages, 3 figures","Classical and Quantum Gravity, 37, 245007 (2020)","10.1088/1361-6382/abbe70",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Charged fluids rotating around compact objects can form unique equilibrium
structures when ambient large-scale electromagnetic fields combine with strong
gravity. Equatorial as well as off-equatorial toroidal structures are among
such figures of equilibrium with a direct relevance for astrophysics. To
investigate their geometrical shapes and physical properties in the
near-horizon regime, where effects of general relativity play a significant
role, we commonly employ a scheme based on the energy-momentum conservation
written in a standard representation. Here, we develop its interesting
alternatives in terms of two covariant force representations, both based on a
hypersurface projection of the energy-momentum conservation. In a proper
hypersurface, space-like forces can be defined, following from a decomposition
of the fluid four-acceleration. Each of the representations provides us with an
insight into properties of the fluid flow, being well reflected in related
conformal hypersurface geometries; we find behaviour of centrifugal forces
directly related to geodesics of these conformal hypersurfaces and their
embedding diagrams. We also reveal correspondence between the charged fluid
flow world-lines from an ordinary spacetime, and world-lines determined by a
charged test particles equation of motion in a conformal spacetime.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:28:46 GMT""}]","2020-12-30"
"2011.15026","Christian Hohl","Stefan Antusch, Christian Hohl, Vasja Susi\v{c}","Employing nucleon decay as a fingerprint of SUSY GUT models using
  \texttt{SusyTCProton}","Note: 34 pages, 6 figures, 5 tables. The packages ProtonDecay and
  SusyTCProton can be downloaded from
  http://particlesandcosmology.unibas.ch/downloads/protondecay.html",,"10.1007/JHEP06(2021)022",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  While the observation of nucleon decay would be a smoking gun of Grand
Unified Theories (GUTs) in general, the ratios between the decay rates of the
various channels carry rich information about the specific GUT model
realization. To investigate this fingerprint of GUT models in the context of
supersymmetric (SUSY) GUTs, we present the software tool \texttt{SusyTCProton},
which is an extension of the module \texttt{SusyTC} to be used with the
\texttt{REAP} package. It allows to calculate nucleon decay rates from the
relevant dimension five GUT operators specified at the GUT scale, including the
full loop-dressing at the SUSY scale. As an application, we investigate the
fingerprints of two example GUT toy models with different flavor structures,
performing an MCMC analysis to include the experimental uncertainties for the
charged fermion masses and CKM mixing parameters. While both toy models provide
equally good fits to the low energy data, we show how they could be
distinguished via their predictions of ratios for nucleon decay rates. Together
with \texttt{SusyTCProton} we also make the additional module
\texttt{ProtonDecay} public. It can be used independently from \texttt{REAP}
and allows to calculate nucleon decay rates from given $D=5$ and $D=6$ operator
coefficients (accepting the required SUSY input for the $D=5$ case in SLHA
format). The $D=6$ functionality can also be used to calculate nucleon decay in
non-SUSY GUTs.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:28:59 GMT""}]","2021-06-30"
"2011.15028","G\'abor Sz\'arnyas","Alexandru Iosup, Ahmed Musaafir, Alexandru Uta, Arnau Prat P\'erez,
  G\'abor Sz\'arnyas, Hassan Chafi, Ilie Gabriel T\u{a}nase, Lifeng Nai,
  Michael Anderson, Mihai Capot\u{a}, Narayanan Sundaram, Peter Boncz,
  Siegfried Depner, Stijn Heldens, Thomas Manhardt, Tim Hegeman, Wing Lung
  Ngai, Yinglong Xia","The LDBC Graphalytics Benchmark",,,,,"cs.DC cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this document, we describe LDBC Graphalytics, an industrial-grade
benchmark for graph analysis platforms. The main goal of Graphalytics is to
enable the fair and objective comparison of graph analysis platforms. Due to
the diversity of bottlenecks and performance issues such platforms need to
address, Graphalytics consists of a set of selected deterministic algorithms
for full-graph analysis, standard graph datasets, synthetic dataset generators,
and reference output for validation purposes. Its test harness produces deep
metrics that quantify multiple kinds of systems scalability, weak and strong,
and robustness, such as failures and performance variability. The benchmark
also balances comprehensiveness with runtime necessary to obtain the deep
metrics. The benchmark comes with open-source software for generating
performance data, for validating algorithm results, for monitoring and sharing
performance data, and for obtaining the final benchmark result as a standard
performance report.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:34:37 GMT""},{""version"":""v2"",""created"":""Sun, 31 Jan 2021 13:59:29 GMT""},{""version"":""v3"",""created"":""Tue, 13 Apr 2021 18:37:57 GMT""},{""version"":""v4"",""created"":""Thu, 31 Mar 2022 09:47:08 GMT""},{""version"":""v5"",""created"":""Wed, 15 Feb 2023 09:58:57 GMT""},{""version"":""v6"",""created"":""Thu, 6 Apr 2023 07:24:03 GMT""}]","2023-04-07"
"2011.15029","Antonio Martinez","Antonio Mart\'inez, A.L. Mart\'inez-Trivi\~no, J. P. dos Santos","Mean convex properly embedded $[\varphi,\vec{e}_{3}]$-minimal surfaces
  in $\mathbb{R}^3$","25 pages, 0 figures",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish curvature estimates and a convexity result for mean convex
properly embedded $[\varphi,\vec{e}_{3}]$-minimal surfaces in $\mathbb{R}^3$,
i.e., $\varphi$-minimal surfaces when $\varphi$ depends only on the third
coordinate of $\mathbb{R}^3$. Led by the works on curvature estimates for
surfaces in 3-manifolds, due to White for minimal surfaces, to Rosenberg, Souam
and Toubiana, for stable CMC surfaces, and to Spruck and Xiao for stable
translating solitons in $\mathbb{R}^3$, we use a compactness argument to
provide curvature estimates for a family of mean convex
$[\varphi,\vec{e}_{3}]$-minimal surfaces in $\mathbb{R}^{3}$. We apply this
result to generalize the convexity property of Spruck and Xiao for translating
solitons. More precisely, we characterize the convexity of a properly embedded
$[\varphi,\vec{e}_{3}]$-minimal surface in $\mathbb{R}^{3}$ with non positive
mean curvature when the growth at infinity of $\varphi$ is at most quadratic.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:34:39 GMT""}]","2020-12-01"
"2011.15030","Mark Lacy","M. Lacy (1), J.A. Surace (2), D. Farrah (3,4), K. Nyland (5), J.
  Afonso (6,7), W.N. Brandt (8,9,10), D.L. Clements (11), C.D.P. Lagos
  (12,13,14), C. Maraston (15), J. Pforr (16), A. Sajina (17), M. Sako (18), M.
  Vaccari (19,20), G. Wilson (21), D.R. Ballantyne (22), W.A. Barkhouse (23),
  R. Brunner (18), R. Cane (18), T.E. Clarke (24), M. Cooper (25), A. Cooray
  (25), G. Covone (26), C. D'Andrea (18), A.E. Evrard (27,28), H.C. Ferguson
  (29), J. Frieman (30,31), V. Gonzalez-Perez (15,32), R. Gupta (18), E.
  Hatziminaoglou (33), J. Huang (34,35,36), P. Jagannathan (37), M.J. Jarvis
  (19,38) K.M. Jones (39), A. Kimball (37), C. Lidman (40), L. Lubin (41), L.
  Marchetti (42,19,20), P. Martini (43,44), R.G. McMahon (45), S. Mei (46,47),
  H. Messias (48), E.J. Murphy (1), J.A. Newman (49), R. Nichol (15), R.P.
  Norris (50), S. Oliver (51), I. Perez-Fournon (52,53), W.M. Peters (24), M.
  Pierre (54), E. Polisensky (24), G.T. Richards (55), S.E. Ridgway (56),
  H.J.A. R\""ottgering (57), N. Seymour (58), R. Shirley (51,52), R. Somerville
  (59), M.A. Strauss (60), N. Suntzeff (61), P.A. Thorman (62), E. van Kampen
  (33), A. Verma (38), R. Wechsler (63), W.M. Wood-Vasey (64) ((1) NRAO,
  Charlottesville, (2) IPAC, Caltech, (3) Dept of Physics and Astronomy,
  Hawaii, (4) IfA, Hawaii, (5) NRC Fellow (resident at NRL), (6) Inst. de
  Astrophysica, Lisbon, (7) Dept of Physics, Lisbon, (8) Dept. of Astronomy &
  Astrophysics, Penn State, (9) IGC, Penn State, (10), Dept. of Physics, Penn
  State, (11) Imperial College, (12) ICRAR, (13) ASTRO-3D, (14) DAWN, (15) ICG,
  Portsmouth, (16) ESTEC, (17) Tufts, (18) UPenn, (19) Western Cape, (20) INAF,
  (21) UC Riverside, (22) Georgia Tech, (23) North Dakota, (24) NRL, (25) UC
  Irvine, (26) Naples, (27) Dept. of Physics, Michigan, (28) Dept. of
  Astronomy, Michigan, (29) STScI, (30) Chicago, (31) Fermilab, (32) Liverpool
  JMU, (33) ESO Garching, (34) NAOC, (35) China-Chile Joint Center for
  Astronomy, (36) CfA Harvard, (37) NRAO, Socorro, (38) Oxford, (39) Kansas,
  (40) AAO, (41) UC Davis, (42) Cape Town, (43) Ohio State, (44) Dept. of
  Astronomy, Ohio State, (45) Cambridge, (46) LERMA/PSL U. Paris, (47) JPL,
  (48) Joint ALMA Observatory, (49) Pittsburgh, (50) Western Sydney, (51)
  Sussex, (52) IAC, (53) La Laguna, (54) U. Paris-Saclay (55) Drexel, (56)
  NOIRLab, (57) Leiden, (58) Curtin, (59) Flatiron, (60) Princeton, (61) Texas
  A&M, (62) Haverford, (63) Stanford, (64) Pitt-PACC)","A Spitzer survey of Deep Drilling Fields to be targeted by the Vera C.
  Rubin Observatory Legacy Survey of Space and Time","20 pages, 9 figures; MNRAS in press",,"10.1093/mnras/staa3714",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST) will
observe several Deep Drilling Fields (DDFs) to a greater depth and with a more
rapid cadence than the main survey. In this paper, we describe the
``DeepDrill'' survey, which used the Spitzer Space Telescope Infrared Array
Camera (IRAC) to observe three of the four currently defined DDFs in two bands,
centered on 3.6 $\mu$m and 4.5 $\mu$m. These observations expand the area which
was covered by an earlier set of observations in these three fields by the
Spitzer Extragalactic Representative Volume Survey (SERVS). The combined
DeepDrill and SERVS data cover the footprints of the LSST DDFs in the Extended
Chandra Deep Field-South field (ECDFS), the ELAIS-S1 field (ES1), and the XMM
Large-Scale Structure Survey field (XMM-LSS). The observations reach an
approximate $5\sigma$ point-source depth of 2 $\mu$Jy (corresponding to an AB
magnitude of 23.1; sufficient to detect a 10$^{11} M_{\odot}$ galaxy out to
$z\approx 5$) in each of the two bands over a total area of $\approx
29\,$deg$^2$. The dual-band catalogues contain a total of 2.35 million sources.
In this paper we describe the observations and data products from the survey,
and an overview of the properties of galaxies in the survey. We compare the
source counts to predictions from the SHARK semi-analytic model of galaxy
formation. We also identify a population of sources with extremely red
([3.6]$-$[4.5] $>1.2$) colours which we show mostly consists of highly-obscured
active galactic nuclei.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:35:05 GMT""}]","2020-12-01"
"2011.15031","Siavash Golkar","Siavash Golkar, David Lipshutz, Yanis Bahroun, Anirvan M. Sengupta,
  Dmitri B. Chklovskii","A biologically plausible neural network for local supervision in
  cortical microcircuits","Abstract presented at the NeurIPS 2020 workshop ""Beyond
  Backpropagation"". arXiv admin note: text overlap with arXiv:2010.12660",,,,"cs.NE cs.LG q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  The backpropagation algorithm is an invaluable tool for training artificial
neural networks; however, because of a weight sharing requirement, it does not
provide a plausible model of brain function. Here, in the context of a
two-layer network, we derive an algorithm for training a neural network which
avoids this problem by not requiring explicit error computation and
backpropagation. Furthermore, our algorithm maps onto a neural network that
bears a remarkable resemblance to the connectivity structure and learning rules
of the cortex. We find that our algorithm empirically performs comparably to
backprop on a number of datasets.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:35:22 GMT""}]","2020-12-01"
"2011.15032","Saeed Nasseh","Saeed Nasseh, Maiko Ono, Yuji Yoshino","The theory of j-operators with application to (weak) liftings of DG
  modules","20 pages",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A major part of this paper is devoted to an in-depth study of j-operators and
their properties. This study enables us to obtain several results on liftings
and weak liftings of DG modules along simple extensions of DG algebras and
unify the proofs of the existing results obtained by the authors on these
subjects. Finally, we provide a new characterization of the (weak) lifting
property of DG modules along simple extensions of DG algebras.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:36:06 GMT""}]","2020-12-01"
"2011.15033","Sangita Jha","S. Verma, S. Jha","Dimensional analysis of fractal interpolation functions","19 pages",,,,"math.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We provide a rigorous study on dimensions of fractal interpolation function
defined on a closed and bounded interval of $\mathbb{R}$ which is associated to
a continuous function with respect to a base function, scaling functions and a
partition of the interval. In particular, we provide an exact estimation of the
box dimension of $\alpha$-fractal functions.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:36:08 GMT""}]","2020-12-01"
"2011.15034","Dorsa Mohammadi Arezooji","Dorsa Mohammadi Arezooji","A Markov Chain Monte-Carlo Approach to Dose-Response Optimization Using
  Probabilistic Programming (RStan)","12 pages, 9 figures ""for code source, see
  https://github.com/Dorsa-Arezooji/Sick-Pigs""",,,,"stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A hierarchical logistic regression Bayesian model is proposed and implemented
in R to model the probability of patient improvement corresponding to any given
dosage of a certain drug. RStan is used to obtain samples from the posterior
distributions via Markov Chain Monte-Carlo (MCMC) sampling. The effects of
selecting different families of prior distributions are examined and finally,
the posterior distributions are compared across RStan, and two other
environments, namely PyMC, and AgenaRisk.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:37:42 GMT""}]","2020-12-01"
"2011.15035","Jonathan Viquerat","Elie Hachem and Hassan Ghraieb and Jonathan Viquerat and Aur\'elien
  Larcher and Philippe Meliga","Deep reinforcement learning for the control of conjugate heat transfer
  with application to workpiece cooling","arXiv admin note: text overlap with arXiv:2006.02979",,,,"physics.flu-dyn math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This research gauges the ability of deep reinforcement learning (DRL)
techniques to assist the control of conjugate heat transfer systems governed by
the coupled Navier--Stokes and heat equations. It uses a novel, ""degenerate""
version of the proximal policy optimization (PPO) algorithm, intended for
situations where the optimal policy to be learnt by a neural network does not
depend on state, as is notably the case in optimization and open-loop control
problems. The numerical reward fed to the neural network is computed with an
in-house stabilized finite elements environment combining variational
multi-scale (VMS) modeling of the governing equations, immerse volume method,
and multi-component anisotropic mesh adaptation. Several test cases of natural
and forced convection in two and three dimensions are used as testbed for
developing the methodology. The approach successfully alleviates the natural
convection induced enhancement of heat transfer in a two-dimensional,
differentially heated square cavity controlled by piece-wise constant
fluctuations of the sidewall temperature. It also proves capable of improving
the homogeneity of temperature across the surface of two and three-dimensional
hot workpieces under impingement cooling. Various cases are tackled, in which
the position of multiple cold air injectors is optimized relative to a fixed
workpiece position. The flexibility of the numerical framework makes it
tractable to solve also the inverse problem, i.e., to optimize the workpiece
position relative to a fixed injector distribution. The obtained results
showcase the potential of the method for black-box optimization of practically
meaningful computational fluid dynamics (CFD) conjugate heat transfer systems.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:37:47 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 14:05:52 GMT""}]","2021-03-25"
"2011.15036","Robert Harper","Robert Harper and Philip Tee","Balancing Capacity and Epidemic Spread in the Global Airline Network",,,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The structure of complex networks has long been understood to play a role in
transmission and spreading phenomena on a graph. This behavior is difficult to
model analytically and is most often modeled numerically. Such networks form an
important part of the structure of society, including transportation networks.
As society fights to control the COVID-19 pandemic, an important question is to
choose the optimum balance between the full opening of transport networks and
the control of epidemic spread. In this paper we investigate how recent
advances in analyzing network structure using information theory could inform
decisions regarding the opening of such networks. By virtue of the richness of
data available we focus upon the worldwide airline network, but these methods
are in principle applicable to any transport network. We are able to
demonstrate that it is possible to substantially open the airline network and
have some degree of control on the spread of the virus.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:39:03 GMT""}]","2020-12-01"
"2011.15037","Erik van Zwet","Erik van Zwet and Andrew Gelman","A proposal for informative default priors scaled by the standard error
  of estimates","20 pages, 4 figures",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  If we have an unbiased estimate of some parameter of interest, then its
absolute value is positively biased for the absolute value of the parameter.
This bias is large when the signal-to-noise ratio (SNR) is small, and it
becomes even larger when we condition on statistical significance; the winner's
curse. This is a frequentist motivation for regularization. To determine a
suitable amount of shrinkage, we propose to estimate the distribution of the
SNR from a large collection or corpus of similar studies and use this as a
prior distribution. The wider the scope of the corpus, the less informative the
prior, but a wider scope does not necessarily result in a more diffuse prior.
We show that the estimation of the prior simplifies if we require that
posterior inference is equivariant under linear transformations of the data. We
demonstrate our approach with corpora of 86 replication studies from psychology
and 178 phase 3 clinical trials. Our suggestion is not intended to be a
replacement for a prior based on full information about a particular problem;
rather, it represents a familywise choice that should yield better long-term
properties than the current default uniform prior, which has led to systematic
overestimates of effect sizes and a replication crisis when these inflated
estimates have not shown up in later studies.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:39:43 GMT""}]","2020-12-01"
"2011.15038","Rafi Trad","Rafi Trad, Myra Spiliopoulou","A Framework for Authorial Clustering of Shorter Texts in Latent Semantic
  Spaces","8 pages including references",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Authorial clustering involves the grouping of documents written by the same
author or team of authors without any prior positive examples of an author's
writing style or thematic preferences. For authorial clustering on shorter
texts (paragraph-length texts that are typically shorter than conventional
documents), the document representation is particularly important: very
high-dimensional feature spaces lead to data sparsity and suffer from serious
consequences like the curse of dimensionality, while feature selection may lead
to information loss. We propose a high-level framework which utilizes a compact
data representation in a latent feature space derived with non-parametric topic
modeling. Authorial clusters are identified thereafter in two scenarios: (a)
fully unsupervised and (b) semi-supervised where a small number of shorter
texts are known to belong to the same author (must-link constraints) or not
(cannot-link constraints). We report on experiments with 120 collections in
three languages and two genres and show that the topic-based latent feature
space provides a promising level of performance while reducing the
dimensionality by a factor of 1500 compared to state-of-the-arts. We also
demonstrate that, while prior knowledge on the precise number of authors (i.e.
authorial clusters) does not contribute much to additional quality, little
knowledge on constraints in authorial clusters memberships leads to clear
performance improvements in front of this difficult task. Thorough
experimentation with standard metrics indicates that there still remains an
ample room for improvement for authorial clustering, especially with shorter
texts
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:39:44 GMT""}]","2020-12-01"
"2011.15039","Runzhong Wang","Runzhong Wang, Tianqi Zhang, Tianshu Yu, Junchi Yan, Xiaokang Yang","Combinatorial Learning of Graph Edit Distance via Dynamic Embedding",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph Edit Distance (GED) is a popular similarity measurement for pairwise
graphs and it also refers to the recovery of the edit path from the source
graph to the target graph. Traditional A* algorithm suffers scalability issues
due to its exhaustive nature, whose search heuristics heavily rely on human
prior knowledge. This paper presents a hybrid approach by combing the
interpretability of traditional search-based techniques for producing the edit
path, as well as the efficiency and adaptivity of deep embedding models to
achieve a cost-effective GED solver. Inspired by dynamic programming,
node-level embedding is designated in a dynamic reuse fashion and suboptimal
branches are encouraged to be pruned. To this end, our method can be readily
integrated into A* procedure in a dynamic fashion, as well as significantly
reduce the computational burden with a learned heuristic. Experimental results
on different graph datasets show that our approach can remarkably ease the
search process of A* without sacrificing much accuracy. To our best knowledge,
this work is also the first deep learning-based GED method for recovering the
edit path.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:41:02 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 02:05:29 GMT""}]","2020-12-03"
"2011.15040","Matteo Salvador","Francesco Regazzoni, Matteo Salvador, Pasquale Claudio Africa, Marco
  Fedele, Luca Dede', Alfio Quarteroni","A cardiac electromechanics model coupled with a lumped parameters model
  for closed-loop blood circulation. Part I: model derivation",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We propose an integrated electromechanical model of the human heart, with
focus on the left ventricle, wherein biophysically detailed models describe the
different physical phenomena concurring to the cardiac function. We model the
subcellular generation of active force by means of an Artificial Neural
Network, which is trained by a suitable Machine Learning algorithm from a
collection of pre-computed numerical simulations of a biophysically detailed,
yet computational demanding, high-fidelity model. To provide physiologically
meaningful results, we couple the 3D electromechanical model with a closed-loop
0D (lumped parameters) model describing the blood circulation in the whole
cardiovascular network. We prove that the 3D-0D coupling of the two models is
compliant with the principle of energy conservation, which is achieved in
virtue of energy-consistent boundary conditions that account for the
interaction among cardiac chambers within the computational domain, pericardium
and surrounding tissue. We thus derive an overall balance of mechanical energy
for the 3D-0D model. This provides a quantitative insight into the energy
utilization, dissipation and transfer among the different compartments of the
cardiovascular network and during different stages of the heartbeat. In virtue
of this new model and the energy balance, we propose a new validation tool of
heart energy usage against relationships used in the daily clinical practice.
Finally, we provide a mathematical formulation of an inverse problem aimed at
recovering the reference configuration of one or multiple cardiac chambers,
starting from the stressed configuration acquired from medical imaging. This is
fundamental to correctly initialize electromechanical simulations. Numerical
methods and simulations of the 3D-0D model will be detailed in Part II.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:41:08 GMT""}]","2020-12-01"
"2011.15041","Simone Colucci","Simone Colucci, Paolo Papale","Deep magma transport control on the size and evolution of explosive
  volcanic eruptions",,,,,"physics.geo-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Explosive eruptions are the surface manifestation of dynamics that involve
transfer of magma from the underground regions of magma accumulation. Evidence
of the involvement of compositionally different magmas from different
reservoirs is continuously increasing to countless cases. Yet, models of
eruption dynamics consider only the uppermost portion of the plumbing system,
neglecting connections to deeper regions of magma storage. Here we show that
the extent and efficiency of the interconnections between different magma
storage regions largely control the size of the eruptions, their evolution, the
causes of their termination, and ultimately their impact on the surrounding
environment. Our numerical simulations first reproduce the magnitude-intensity
relationship observed for explosive eruptions on Earth and explain the observed
variable evolutions of eruption mass flow rates. Because deep magmatic
interconnections are largely inaccessible to present-day imaging capabilities,
our results imply a limit to eruption size forecasts based on observations and
measurements during volcanic unrest.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:41:46 GMT""}]","2020-12-01"
"2011.15042","Yuanqi Wang","Yuanqi Wang","Atiyah classes and the essential obstructions in deforming a singular
  $G_{2}-$instanton","23 pages. Comments are welcome",,,,"math.DG math.AP","http://creativecommons.org/licenses/by/4.0/","  When the rank of the bundle is $\geq 2$, in a certain sense, we found an
essential obstruction for the gluing construction of $G_{2}-$instantons with
$1-$dimensional singularities. It involves the Atiyah classes generated by
contracting a vector in $\mathbb{C}^{3}$ with the curvature. Intuitively
speaking, the gluing does not work if the tangent connection at a component of
the $1-$dimensional singular locus is not the twisted Fubini-Study connection
on a twisted tangent bundle of $\mathbb{P}^{2}$. Particularly, it fails if the
rank of the bundle is $\geq 3$.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:42:12 GMT""}]","2020-12-01"
"2011.15043","Ivan A. Dynnikov","Ivan Dynnikov, Pascal Hubert, Alexandra Skripchenko","Dynamical systems around the Rauzy gasket and their ergodic properties","30 pages, 12 figures",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  At the beggining of the 80's, H.Masur and W.Veech started the study of
generic properties of interval exchange transformations proving that almost
every such transformation is uniquely ergodic. About the same time, S.Novikov's
school and French mathematicians independently discovered very intriguing
phenomena for classes of measured foliations on surfaces and respective IETs.
For instance, minimality is exceptional in these families. A precise version of
this statement is a conjecture by Novikov. The French and Russian constructions
are very different ones. Nevertheless, in the most simple situation (surfaces
of genus three with two singularities) it was recently observed that both
foliations share the same type of properties. For instance, the space of
minimal parameters is the same, called the Rauzy gasket. However, the precise
connection between these two series of works was rather unclear. The aim of
this paper is to prove that both theories describe in different languages the
same objects. This text provides an explicit dictionary between both
constructions.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:44:06 GMT""}]","2020-12-01"
"2011.15044","Salvador Bar\'a","Salvador Bar\'a, Enric Marco, Salvador J. Ribas, Manuel Garcia Gil,
  Alejandro S\'anchez de Miguel, Jaime Zamorano","Direct assessment of the sensitivity drift of SQM sensors installed
  outdoors","5 pages, 1 figure. ArXiv identifier added, some minor misprints
  corrected",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Long-term monitoring of the evolution of the artificial night sky brightness
is a key tool for developing science-informed public policies and assessing the
efficacy of light pollution mitigation measures. Detecting the underlying
artificial brightness trend is a challenging task, since the typical night sky
brightness signal shows a large variability with characteristic time scales
ranging from seconds to years. In order to effectively isolate the weak
signature of the effect of interest, determining the potential long term drifts
of the radiance sensing systems is crucial. If these drifts can be adequately
characterized, the raw measurements could be easily corrected for them and
transformed to a consistent scale. In this short note we report on the
progressive darkening of the signal recorded by SQM detectors belonging to
several monitoring networks, permanently installed outdoors for periods ranging
from several months to several years. The sensitivity drifts were estimated by
means of parallel measurements made at the beginning and at the end of the
evaluation periods using reference detectors of the same kind that were little
or no exposed to weathering in the intervening time. Our preliminary results
suggest that SQM detectors installed outdoors steadily increase their readings
at an average rate of +0.034 magSQM/arcsec^2 per MWh/m^2 of exposure to solar
horizontal global irradiation, that for our locations translates into
approximately +0.05 to +0.06 magSQM/arcsec^2 per year.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:44:11 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 16:59:16 GMT""}]","2020-12-02"
"2011.15045","Dev Yashpal Sheth","Dev Yashpal Sheth, Sreyas Mohan, Joshua L. Vincent, Ramon Manzorro,
  Peter A. Crozier, Mitesh M. Khapra, Eero P. Simoncelli, Carlos
  Fernandez-Granda","Unsupervised Deep Video Denoising","Dev and Sreyas contributed equally. To appear at 2021 IEEE/CVF
  International Conference on Computer Vision (ICCV). See
  https://sreyas-mohan.github.io/udvd/ for code and more results",,,,"eess.IV cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep convolutional neural networks (CNNs) for video denoising are typically
trained with supervision, assuming the availability of clean videos. However,
in many applications, such as microscopy, noiseless videos are not available.
To address this, we propose an Unsupervised Deep Video Denoiser (UDVD), a CNN
architecture designed to be trained exclusively with noisy data. The
performance of UDVD is comparable to the supervised state-of-the-art, even when
trained only on a single short noisy video. We demonstrate the promise of our
approach in real-world imaging applications by denoising raw video,
fluorescence-microscopy and electron-microscopy data. In contrast to many
current approaches to video denoising, UDVD does not require explicit motion
compensation. This is advantageous because motion compensation is
computationally expensive, and can be unreliable when the input data are noisy.
A gradient-based analysis reveals that UDVD automatically adapts to local
motion in the input noisy videos. Thus, the network learns to perform implicit
motion compensation, even though it is only trained for denoising.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:45:08 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 04:25:50 GMT""},{""version"":""v3"",""created"":""Thu, 19 Aug 2021 19:41:54 GMT""}]","2021-08-23"
"2011.15046","M Meuwly","Haydar Taylan Turan and Markus Meuwly","Spectroscopy, Dynamics and Hydration of S-Nitrosylated Myoglobin",,,,,"physics.chem-ph physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  S-nitrosylation, the covalent addition of NO to the thiol side chain of
cysteine, is an important post-transitional modification that can alter the
function of various proteins. The structural dynamics and vibrational
spectroscopy of S-nitrosylation in the condensed phase is investigated for the
methyl-capped cysteine model system and for myoglobin. Using conventional point
charge and physically more realistic multipolar force fields for the -SNO group
it is found that the SN- and NO-stretch and the SNO-bend vibrations can be
located and distinguished from the other protein modes for simulations of MbSNO
at 50 K. The finding of stable cis- and trans-MbSNO is consistent with
experiments on other proteins as is the observation of buried -SNO. For MbSNO
the observed relocation of the EF loop in the simulations by $\sim 3$ \AA\/ is
consistent with the available X-ray structure and the conformations adopted by
the -SNO label are in good overall agreement with the X-ray structure. Despite
the larger size of the -SNO group, MbSNO is found to recruit more water
molecules within 10 \AA\/ of the modification site than WT Mb due to the
stronger electrostatics. Similarly, when comparing the hydration between the A-
and H-helices they differ by up to 30 \% between WT and MbSNO. This suggests
that local hydration can also be significantly modulated through nitrosylation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:46:22 GMT""}]","2020-12-01"
"2011.15047","Stefan Schreieder","Stefan Schreieder","Infinite torsion in Griffiths groups","28 pages, final version, to appear in JEMS",,,,"math.AG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that there are smooth complex projective varieties with infinite
2-torsion in their third Griffiths groups. It follows that the torsion subgroup
of Griffiths groups is in general not finitely generated, thereby solving a
problem of Schoen from 1992.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:47:15 GMT""},{""version"":""v2"",""created"":""Sun, 13 Dec 2020 17:18:23 GMT""},{""version"":""v3"",""created"":""Tue, 17 Aug 2021 16:52:38 GMT""},{""version"":""v4"",""created"":""Fri, 28 Jan 2022 11:39:07 GMT""}]","2022-01-31"
"2011.15048","Juan Carlos Garcia-Escartin","Juan Carlos Garcia-Escartin, Vicent Gimeno and Julio Jos\'e
  Moyano-Fern\'andez","Optimal approximation to unitary quantum operators with linear optics","Comments welcome","Quantum Information Processing, vol. 20, Article number: 314
  (2021)","10.1007/s11128-021-03254-2",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Linear optical systems acting on photon number states produce many
interesting evolutions, but cannot give all the allowed quantum operations on
the input state. Using Toponogov's theorem from differential geometry, we
propose an iterative method that, for any arbitrary quantum operator $U$ acting
on $n$ photons in $m$ modes, returns an operator $\widetilde{U}$ which can be
implemented with linear optics. The approximation method is locally optimal and
converges. The resulting operator $\widetilde{U}$ can be translated into an
experimental optical setup using previous results.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:47:23 GMT""}]","2021-09-29"
"2011.15049","Vinicius Vianna","Vinicius Pavanelli Vianna and Luiz Otavio Murta Jr","Long-range medical image registration through generalized mutual
  information (GMI): toward a fully automatic volumetric alignment","13 pages, 8 figures, 3 tables",,,,"eess.IV cs.CV cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image registration is a key operation in medical image processing, allowing a
plethora of applications. Mutual information (MI) is consolidated as a robust
similarity metric often used for medical image registration. Although MI
provides a robust medical image registration, it usually fails when the needed
image transform is too big due to MI local maxima traps. In this paper, we
propose and evaluate a generalized parametric MI as an affine registration cost
function. We assessed the generalized MI (GMI) functions for separable affine
transforms and exhaustively evaluated the GMI mathematical image seeking the
maximum registration range through a gradient descent simulation. We also
employed Monte Carlo simulation essays for testing translation registering of
randomized T1 versus T2 images. GMI functions showed to have smooth isosurfaces
driving the algorithm to the global maxima. Results show significantly
prolonged registration ranges, avoiding the traps of local maxima. We evaluated
a range of [-150mm,150mm] for translations, [-180{\deg},180{\deg}] for
rotations, [0.5,2] for scales, and [-1,1] for skew with a success rate of
99.99%, 97.58%, 99.99%, and 99.99% respectively for the transforms in the
simulated gradient descent. We also obtained 99.75% success in Monte Carlo
simulation from 2,000 randomized translations trials with 1,113 subjects T1 and
T2 MRI images. The findings point towards the reliability of GMI for long-range
registration with enhanced speed performance
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:48:28 GMT""}]","2020-12-01"
"2011.15050","Ivan Stelmakh","Ivan Stelmakh, Nihar B. Shah, Aarti Singh, and Hal Daum\'e III","A Novice-Reviewer Experiment to Address Scarcity of Qualified Reviewers
  in Large Conferences",,,,,"cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conference peer review constitutes a human-computation process whose
importance cannot be overstated: not only it identifies the best submissions
for acceptance, but, ultimately, it impacts the future of the whole research
area by promoting some ideas and restraining others. A surge in the number of
submissions received by leading AI conferences has challenged the
sustainability of the review process by increasing the burden on the pool of
qualified reviewers which is growing at a much slower rate. In this work, we
consider the problem of reviewer recruiting with a focus on the scarcity of
qualified reviewers in large conferences. Specifically, we design a procedure
for (i) recruiting reviewers from the population not typically covered by major
conferences and (ii) guiding them through the reviewing pipeline. In
conjunction with ICML 2020 -- a large, top-tier machine learning conference --
we recruit a small set of reviewers through our procedure and compare their
performance with the general population of ICML reviewers. Our experiment
reveals that a combination of the recruiting and guiding mechanisms allows for
a principled enhancement of the reviewer pool and results in reviews of
superior quality compared to the conventional pool of reviews as evaluated by
senior members of the program committee (meta-reviewers).
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:48:55 GMT""}]","2020-12-01"
"2011.15051","Matteo Salvador","Francesco Regazzoni, Matteo Salvador, Pasquale Claudio Africa, Marco
  Fedele, Luca Dede', Alfio Quarteroni","A cardiac electromechanics model coupled with a lumped parameters model
  for closed-loop blood circulation. Part II: numerical approximation",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the framework of accurate and efficient segregated schemes for 3D cardiac
electromechanics and 0D cardiovascular models, we propose here a novel
numerical approach to address the coupled 3D-0D problem introduced in Part I of
this two-part series of papers. We combine implicit-explicit schemes to solve
the different cardiac models in a multiphysics setting. We properly separate
and manage the different time and space scales related to cardiac
electromechanics and blood circulation. We employ a flexible and scalable
intergrid transfer operator that enables to interpolate Finite Element
functions among different meshes and, possibly, among different Finite Element
spaces. We propose a numerical method to couple the 3D electromechanical model
and the 0D circulation model in a numerically stable manner within a fully
segregated fashion. No adaptations are required through the different phases of
the heartbeat. We also propose a robust algorithm to reconstruct the
stress-free reference configuration. Due to the computational cost associated
with the numerical solution of this inverse problem, the reference
configuration recovery algorithm comes along with a novel projection technique
to precisely recover the unloaded geometry from a coarser representation of the
computational domain. We show the convergence property of our numerical schemes
by performing an accuracy study through grid refinement. To prove the
biophysical accuracy of our computational model, we also address different
scenarios of clinical interest in our numerical simulations by varying preload,
afterload and contractility. Indeed, we simulate physiologically relevant
behaviors and we reproduce meaningful results in the context of cardiac
function.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:49:31 GMT""}]","2020-12-01"
"2011.15052","Andreas Frutiger","Yves Blickenstorfer, Markus M\""uller, Roland Dreyfus, Andreas Michael
  Reichmuth, Christof Fattinger, Andreas Frutiger","Quantitative Diffractometric Biosensing",,"Phys. Rev. Applied 15, 034023 (2021)","10.1103/PhysRevApplied.15.034023",,"physics.optics physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Diffractometric biosensing is a promising technology to overcome critical
limitations of refractometric biosensors, the dominant class of label-free
optical transducers. These limitations manifest themselves by higher noise and
drifts due to insufficient rejection of refractive index fluctuations caused by
variation in temperature, solvent concentration, and most prominently,
non-specific binding. Diffractometric biosensors overcome these limitations
with inherent self-referencing on the submicron scale with no compromise on
resolution. Despite this highly promising attribute, the field of
diffractometric biosensors has only received limited recognition. A major
reason is the lack of a general quantitative analysis. This hinders comparison
to other techniques and amongst different diffractometric biosensors. For
refractometric biosensors, on the other hand, such a comparison is possible by
means of the refractive index unit (RIU). In this publication, we suggest the
coherent surface mass density, $\Gamma_{\rm{coh}}$, as a quantity for
label-free diffractometric biosensors with the same purpose as RIU in
refractometric sensors. It is easy to translate $\Gamma_{\rm{coh}}$ to the
total surface mass density $\Gamma_{\rm{tot}}$, which is an important parameter
for many assays. We provide a generalized framework to determine
$\Gamma_{\rm{coh}}$ for various diffractometric biosensing arrangements which
enables quantitative comparison. Additionally, the formalism can be used to
estimate background scattering in order to further optimize sensor
configurations. Finally, a practical guide with important experimental
considerations is given to enable readers of any background to apply the
theory. Therefore, this paper provides a powerful tool for the development of
diffractometric biosensors and will help the field to mature and unveil its
full potential.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:50:41 GMT""}]","2021-03-17"
"2011.15053","Patricio Salgado-Rebolledo","Joaquim Gomis, Diego Hidalgo, Patricio Salgado-Rebolledo","Non-relativistic and Carrollian limits of Jackiw-Teitelboim gravity","44 pages, typos corrected",,"10.1007/JHEP05(2021)162",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct the non-relativistic and Carrollian versions of
Jackiw-Teitelboim gravity. In the second order formulation, there are no
divergences in the non-relativistic and Carrollian limits. Instead, in the
first order formalism there are divergences that can be avoided by starting
from a relativistic BF theory with (A)dS2$\times\mathbb{R}$ gauge algebra. We
show how to define the boundary duals of the gravity actions using the method
of non-linear realisations and suitable Inverse Higgs constraints. In
particular, the non-relativistic version of the Schwarzian action is
constructed in this way. We derive the asymptotic symmetries of the theory, as
well as the corresponding conserved charges and Newton-Cartan geometric
structure. Finally, we show how the same construction applies to the Carrollian
case.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:51:18 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 12:24:08 GMT""}]","2023-01-11"
"2011.15054","Giada Cianfarani Carnevale","Paolo Antonelli, Giada Cianfarani Carnevale, Corrado Lattanzio,
  Stefano Spirito","Relaxation limit from the Quantum-Navier-Stokes equations to the Quantum
  Drift Diffusion equation",,,"10.1007/s00332-021-09728-y",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  The relaxation-time limit from the Quantum-Navier-Stokes-Poisson system to
the quantum drift-diffusion equation is performed in the framework of finite
energy weak solutions. No assumptions on the limiting solution are made. The
proof exploits the suitably scaled a priori bounds inferred by the energy and
BD entropy estimates. Moreover, it is shown how from those estimates the Fisher
entropy and free energy estimates associated to the diffusive evolution are
recovered in the limit. As a byproduct, our main result also provides an
alternative proof for the existence of finite energy weak solutions to the
quantum drift-diffusion equation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:52:27 GMT""}]","2021-07-14"
"2011.15055","Steven Senger","Slade Gunter, Eyvi Palsson, Ben Rhodes, and Steven Senger","Bounds on point configurations determined by distances and dot products","21 pages, 4 figures",,,,"math.CO math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a family of variants of Erd\H os' unit distance problem, concerning
distances and dot products between pairs of points chosen from a large finite
point set. Specifically, given a large finite set of $n$ points $E$, we look
for bounds on how many subsets of $k$ points satisfy a set of relationships
between point pairs based on distances or dot products. We survey some of the
recent work in the area and present several new, more general families of
bounds.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:54:28 GMT""}]","2020-12-01"
"2011.15056","Jakub Tomczak","Jakub M. Tomczak","General Invertible Transformations for Flow-based Generative Modeling","Code: https://github.com/jmtomczak/git_flow, accepted to INNF+ 2021
  at ICML",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a new class of invertible transformations with an
application to flow-based generative models. We indicate that many well-known
invertible transformations in reversible logic and reversible neural networks
could be derived from our proposition. Next, we propose two new coupling layers
that are important building blocks of flow-based generative models. In the
experiments on digit data, we present how these new coupling layers could be
used in Integer Discrete Flows (IDF), and that they achieve better results than
standard coupling layers used in IDF and RealNVP.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:54:43 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 13:04:58 GMT""}]","2021-07-13"
"2011.15057","Peter Constantin","Peter Constantin, Mihaela Ignatova, Fizay-Noah Lee","Interior Electroneutrality in Nernst-Planck-Navier-Stokes Systems",,,"10.1007/s00205-021-01700-0",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the limit of vanishing Debye length for ionic diffusion in
fluids, described by the Nernst-Planck-Navier-Stokes system. In the
asymptotically stable cases of blocking (vanishing normal flux) and uniform
selective (special Dirichlet) boundary conditions for the ionic concentrations,
we prove that the ionic charge density $\rho$ converges in time to zero in the
interior of the domain, in the limit of vanishing Debye length ($\epsilon\to
0$). For the unstable regime of Dirichlet boundary conditions for the ionic
concentrations, we prove bounds that are uniform in time and $\epsilon$. We
also consider electroneutral boundary conditions, for which we prove that
electroneutrality $\rho\to 0$ is achieved at any fixed $\epsilon> 0$,
exponentially fast in time in $L^p$, for all $1\le p<\infty$. The results hold
for two oppositely charged ionic species with arbitrary ionic diffusivities, in
bounded domains with smooth boundaries.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:54:49 GMT""}]","2021-09-01"
"2011.15058","Nikolaos Ladas","Nikolaos Michael Ladas, John Christopher Meyer","Comparison principles for a class of nonlinear non-local
  integro-differential operators on unbounded domains","12 pages, 0 figures",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present extensions of the comparison and maximum principles available for
nonlinear non-local integro-differential operators $P:\mathcal{C}^{2,1}(\Omega
\times (0,T])\times L^\infty (\Omega \times (0,T])\to\mathbb{R}$, of the form
$P[u] = L[u] -f(\cdot ,\cdot ,u,Ju)$ on $\Omega \times (0,T]$. Here, we
consider: unbounded spatial domains $\Omega \subset \mathbb{R}^n$, with $T>0$;
sufficiently regular second order linear parabolic partial differential
operators $L$; sufficiently regular semi-linear terms $f:(\Omega \times (0,T])
\times \mathbb{R}^2\to\mathbb{R}$; and the non-local term $Ju=
\int_{{\Omega}}\phi(x-y)u(y,t)dy$, with $\phi$ in a class of non-negative
sufficiently summable kernels. We also provide examples illustrating the
limitations and applicability of our results.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:56:22 GMT""}]","2020-12-01"
"2011.15059","Ngoc Tien Tran","C. Carstensen, N. T. Tran","Unstabilized Hybrid High-Order method for a class of degenerate convex
  minimization problems",,,"10.1137/20M1335625",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The relaxation in the calculus of variation motivates the numerical analysis
of a class of degenerate convex minimization problems with non-strictly convex
energy densities with some convexity control and two-sided $p$-growth. The
minimizers may be non-unique in the primal variable but lead to a unique stress
$\sigma \in H(\operatorname{div},\Omega;\mathbb{M})$. Examples include the
p-Laplacian, an optimal design problem in topology optimization, and the
convexified double-well problem. The approximation by hybrid high-order methods
(HHO) utilizes a reconstruction of the gradients with piecewise Raviart-Thomas
or BDM finite elements without stabilization on a regular triangulation into
simplices. The application of this HHO method to the class of degenerate convex
minimization problems allows for a unique $H(\operatorname{div})$ conforming
stress approximation $\sigma_h$. The main results are a~priori and a posteriori
error estimates for the stress error $\sigma-\sigma_h$ in Lebesgue norms and a
computable lower energy bound. Numerical benchmarks display higher convergence
rates for higher polynomial degrees and include adaptive mesh-refining with the
first superlinear convergence rates of guaranteed lower energy bounds.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:56:28 GMT""}]","2021-05-25"
"2011.15060","Sara Khatibi","Sara Khatibi and Hamzeh Khanpour","Probing four-fermion operators in the triple top production at future
  hadron colliders","9 pages, 5 figures","Nuclear Physics B 967 (2021) 115432","10.1016/j.nuclphysb.2021.115432",,"hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we study the triple top quark production at the future
high-energy proton-proton colliders to probe the four-fermion interactions
involving three top quarks. We employ the Standard Model Effective Field Theory
(SMEFT) to find the upper limits at $95\%$ CL on the Wilson coefficients of
these kinds of four-fermion operators. We consider a detailed analysis with a
unique signal signature of two same-sign leptons. A full simulation chain
includes all the relevant backgrounds, realistic detector simulations and a
cut-based technique are taken into account. This study is presented for the
HE-LHC working at the center of mass energy of 27 TeV with 15~ab$^{-1}$ and
FCC-hh working at the center of mass energy of 100 TeV with 30~ab$^{-1}$. We
show that the future high-energy proton-proton colliders could reach an
impressive sensitivity to four-fermion contact interactions involving three top
quarks.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:58:20 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 10:43:40 GMT""}]","2021-05-18"
"2011.15061","Francois Andrieu","D. Bosch, P. Acosta Alba, S. Kerdiles, V. Benevent, C. Perrot, J.
  Lassarre, J. Richy, J. Lacord, B. Sklenard, L. Brunet, P. Batude, C.
  Fenouillet-Beranger, D. Lattard, J.P. Colinge, F. Balestra, F. Andrieu","Laser Processing For 3D Junctionless Transistor Fabrication",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To take fully advantage of Junctionless transistor (JLT) low-cost and
low-temperature features we investigate a 475 degC process to create onto a
wafer a thin poly-Si layer on insulator. We fabricated a 13nm doped
(Phosphorous, 1E19 at/cm3) poly-silicon film featuring excellent roughness
values (Rmax= 1.6nm and RMS=0.2nm). Guidelines for grain size optimization
using nanosecond (ns) laser annealing are given.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:58:28 GMT""}]","2020-12-01"
"2011.15062","Peter Morfe","Peter S. Morfe","On the homogenization of second order level set PDE in periodic media",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  This paper analyzes two classes of second order level set PDE in periodic
media in the parabolic scaling. First, we study fully nonlinear geometric
operators under general assumptions in dimension $d = 2$ and prove that the
associated equations homogenize in this case. Next, we treat a class of
quasi-linear geometric operators in arbitrary dimensions $d \geq 2$. In this
setting, by adapting arguments form the study of oscillating boundary value
problems, we prove that the effective coefficients are generically
discontinuous in all dimensions $d \geq 3$. This necessitates a study of level
set PDE driven by operators that are discontinuous at every rational direction
on the sphere. We prove that, in fact, the effective operators so obtained do
have a comparison principle and, thus, homogenization occurs. Finally, we
investigate the connection between the effective mobility obtained in the
quasi-linear case and linear response, drawing a connection between our results
and those obtained in the hyperbolic scaling.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:59:07 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jan 2021 22:46:41 GMT""},{""version"":""v3"",""created"":""Wed, 3 Nov 2021 15:17:16 GMT""}]","2021-11-04"
"2011.15063","Lulu Fan","Lulu Fan (USTC & SDU), Wen Chen (YNAO), Tao An (SHAO), Fu-Guo Xie
  (SHAO), Yunkun Han (YNAO), Kirsten K. Knudsen (CTH), Jun Yang (CTH)","The hyperluminous, dust-obscured quasar W2246-0526 at z=4.6: detection
  of parsec-scale radio activity","9 pages, 4 figures. Accepted for publication in The Astrophysical
  Journal Letters",,"10.3847/2041-8213/abcebf",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  WISE J224607.56$-$052634.9 (W2246-0526) is a hyperluminous ($L_{\rm
bol}\approx 1.7\times 10^{14}~L_\odot$), dust-obscured and radio-quiet quasar
at redshift $z=4.6$. It plays a key role in probing the transition stage
between dusty starbursts and unobscured quasars in the co-evolution of galaxies
and supermassive black holes (SMBHs). To search for the evidence of the jet
activity launched by the SMBH in W2246-0526, we performed very long baseline
interferometry (VLBI) observations of its radio counterpart with the European
VLBI Network (EVN) plus the enhanced Multi Element Remotely Linked
Interferometer Network (e-MERLIN) at 1.66 GHz and the Very Long Baseline Array
(VLBA) at 1.44 and 1.66 GHz. The deep EVN plus e-MERLIN observations detect a
compact (size $\leq32$ pc) sub-mJy component contributing about ten percent of
its total flux density, which spatially coincides with the peak of dust
continuum and [C II] emissions. Together with its relatively high brightness
temperature ($\geq8\times10^{6}$ K), we interpret the component as a
consequence of non-thermal radio activity powered by the central SMBH, which
likely originates from a stationary jet base. The resolved-out radio emission
possibly come from a diffuse jet, quasar-driven winds, or both, while the
contribution by star formation activity is negligible. Moreover, we propose an
updated geometry structure of its multi-wavelength active nucleus and shed
light on the radio quasar selection bias towards the blazars at $z>4$.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:00:11 GMT""}]","2021-01-06"
"2011.15064","David Loeffler","David Loeffler and Sarah Livia Zerbes","P-adic L-functions and diagonal cycles for GSp(4) x GL(2) x GL(2)","24 pages. v2: minor updates to references and acknowledgements",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a (largely conjectural) theory of p-adic L-functions interpolating
square roots of central L-values for automorphic forms on GSp(4) x GL(2) x
GL(2), and a relation between these p-adic L-functions and families of Galois
cohomology classes interpolating algebraic cycles. Our theory is a
generalisation of the theory of ""diagonal cycles"" developed by Darmon and
Rotger for the GL(2) triple product.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:02:08 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 16:42:01 GMT""}]","2021-07-02"
"2011.15065","Olivier Nicole","Olivier Nicole, Matthieu Lemerre, S\'ebastien Bardin, Xavier Rival","No Crash, No Exploit: Automated Verification of Embedded Kernels","Published in IEEE Real-Time and Embedded Technology and Applications
  Symposium (RTAS'21)",,"10.1109/RTAS52030.2021.00011",,"cs.CR cs.OS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The kernel is the most safety- and security-critical component of many
computer systems, as the most severe bugs lead to complete system crash or
exploit. It is thus desirable to guarantee that a kernel is free from these
bugs using formal methods, but the high cost and expertise required to do so
are deterrent to wide applicability. We propose a method that can verify both
absence of runtime errors (i.e. crashes) and absence of privilege escalation
(i.e. exploits) in embedded kernels from their binary executables. The method
can verify the kernel runtime independently from the application, at the
expense of only a few lines of simple annotations. When given a specific
application, the method can verify simple kernels without any human
intervention. We demonstrate our method on two different use cases: we use our
tool to help the development of a new embedded real-time kernel, and we verify
an existing industrial real-time kernel executable with no modification.
Results show that the method is fast, simple to use, and can prevent real
errors and security vulnerabilities.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:03:28 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 21:47:51 GMT""}]","2021-05-25"
"2011.15066","Mikael Beuthe","Mikael Beuthe, Bernard Charlier, Olivier Namur, Attilio Rivoldini, Tim
  Van Hoolst","Mercury's crustal thickness correlates with lateral variations in mantle
  melt production","11 pages of main text, 37 pages with supplements; 3+12 figures, 1+1
  tables","Geophysical Research Letters 47 (2020) e2020GL087261","10.1029/2020GL087261",,"astro-ph.EP physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  Mercury's crust has a complex structure resulting from a billion years of
volcanism. The surface variations in chemical composition have been identified
from orbit by the spacecraft MESSENGER. Combining these measurements with
laboratory experiments on partial melting, we estimate which variations in
surface density and degree of mantle melting are required to produce surface
rocks. If the surface density is representative of the deep crustal density,
more than one half of crustal thickness variations in the northern hemisphere
are explained by lateral variations in mantle melting. The crust is thin below
the magnesium-poor Northern Volcanic Plains whereas the thickest crust is found
in the magnesium-rich region located at mid-northern latitudes in the Western
Hemisphere. The magnesium-rich region is thus not due to an early impact but
rather to extensive mantle melting. The thickness-melting relation has also
been observed for the oceanic crust on Earth and might be a common feature of
terrestrial planets.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:03:44 GMT""}]","2020-12-01"
"2011.15067","Marlene Berke","Marlene Berke, Mario Belledonne, and Julian Jara-Ettinger","Learning a metacognition for object perception","SVRHM workshop at NeurIPS",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Beyond representing the external world, humans also represent their own
cognitive processes. In the context of perception, this metacognition helps us
identify unreliable percepts, such as when we recognize that we are seeing an
illusion. Here we propose MetaGen, a model for the unsupervised learning of
metacognition. In MetaGen, metacognition is expressed as a generative model of
how a perceptual system produces noisy percepts. Using basic principles of how
the world works (such as object permanence, part of infants' core knowledge),
MetaGen jointly infers the objects in the world causing the percepts and a
representation of its own perceptual system. MetaGen can then use this
metacognition to infer which objects are actually present in the world. On
simulated data, we find that MetaGen quickly learns a metacognition and
improves overall accuracy, outperforming models that lack a metacognition.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:05:00 GMT""}]","2020-12-01"
"2011.15068","Reza Mousavi","Xunyi Wang, Reza Mousavi, Yili Hong","The Unintended Consequences of Stay-at-Home Policies on Work Outcomes:
  The Impacts of Lockdown Orders on Content Creation",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The COVID-19 pandemic has posed an unprecedented challenge to individuals
around the globe. To mitigate the spread of the virus, many states in the U.S.
issued lockdown orders to urge their residents to stay at their homes, avoid
get-togethers, and minimize physical interactions. While many offline workers
are experiencing significant challenges performing their duties, digital
technologies have provided ample tools for individuals to continue working and
to maintain their productivity. Although using digital platforms to build
resilience in remote work is effective, other aspects of remote work (beyond
the continuation of work) should also be considered in gauging true resilience.
In this study, we focus on content creators, and investigate how restrictions
in individual's physical environment impact their online content creation
behavior. Exploiting a natural experimental setting wherein four states issued
state-wide lockdown orders on the same day whereas five states never issued a
lockdown order, and using a unique dataset collected from a short video-sharing
social media platform, we study the impact of lockdown orders on content
creators' behaviors in terms of content volume, content novelty, and content
optimism. We combined econometric methods (difference-in-differences
estimations of a matched sample) with machine learning-based natural language
processing to show that on average, compared to the users residing in
non-lockdown states, the users residing in lockdown states create more content
after the lockdown order enforcement. However, we find a decrease in the
novelty level and optimism of the content generated by the latter group. Our
findings have important contributions to the digital resilience literature and
shed light on managers' decision-making process related to the adjustment of
employees' work mode in the long run.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:05:17 GMT""}]","2020-12-01"
"2011.15069","R\'emy Brossard","R\'emy Brossard, Oriel Frigo, David Dehaene","Graph convolutions that can finally model local structure",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite quick progress in the last few years, recent studies have shown that
modern graph neural networks can still fail at very simple tasks, like
detecting small cycles. This hints at the fact that current networks fail to
catch information about the local structure, which is problematic if the
downstream task heavily relies on graph substructure analysis, as in the
context of chemistry. We propose a very simple correction to the now standard
GIN convolution that enables the network to detect small cycles with nearly no
cost in terms of computation time and number of parameters. Tested on real life
molecule property datasets, our model consistently improves performance on
large multi-tasked datasets over all baselines, both globally and on a per-task
setting.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:05:22 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 07:58:32 GMT""}]","2021-06-04"
"2011.15070","Emmanuil Saridakis","W. El Hanafy and Emmanuel N. Saridakis","$f(T)$ cosmology: From Pseudo-Bang to Pseudo-Rip","32 pages, 8 figures, 1 table, version published in JCAP","JCAP 09 (2021) 019","10.1088/1475-7516/2021/09/019",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the complete universe evolution in the framework of $f(T)$
cosmology. We first study the requirements at the kinematic level and we
introduce a simple scale factor with the necessary features. Performing a
detailed analysis of the phase portrait we show that the universe begins in the
infinite past from a phase where the scale factor goes to zero but the Hubble
parameter goes to a constant, and its derivative to zero. Since these features
resemble those of the Pseudo-Rip fate but in a reverted way, we call this
initial phase as Pseudo-Bang. Then the universe evolves in a first inflationary
phase, a cosmological turnaround and a bounce, after which we have a second
inflationary regime with a successful exit. Subsequently we obtain the standard
thermal history and the sequence of radiation, matter and late-time
acceleration epochs, showing that the universe will result in an everlasting
Pseudo-Rip phase. Finally, taking advantage of the fact that the field
equations of $f(T)$ gravity are of second order, and therefore the
corresponding autonomous dynamical system is one dimensional, we incorporate
the aforementioned kinematic features and we reconstruct the specific $f(T)$
form that can dynamically generate the Pseudo-Bang cosmological scenario.
Lastly, we examine the evolution of the primordial fluctuations showing that
they are initially sub-horizon, and we show that the total fluid does not
exhibit any singular behaviour at the phantom crossing points, while the
torsional fluid experiences them as Type II singular phases.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:08:26 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 17:51:49 GMT""}]","2021-09-16"
"2011.15071","Jeffrey Langford","Jeffrey J. Langford","PDE Comparison Principles for Robin Problems","Improved notation, new mixed results added, typos corrected",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We compare the solutions of two Poisson problems in a spherical shell with
Robin boundary conditions, one with given data, and one where the data has been
cap symmetrized. When the Robin parameters are nonnegative, we show that the
solution to the symmetrized problem has larger (increasing) convex means. We
prove similar results on balls. We also prove a comparison principle on
generalized cylinders with mixed boundary conditions (Neumann and Robin).
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:08:59 GMT""},{""version"":""v2"",""created"":""Thu, 7 Jan 2021 18:50:04 GMT""}]","2021-01-08"
"2011.15072","Indranil Biswas","Indranil Biswas and Harald Upmeier","A normal variety of invariant connections on hermitian symmetric spaces","Final version; to appear in Proc. Ind. Acad. Sci",,,,"math.DG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a class of $G$-invariant connections on a homogeneous principal
bundle $Q$ over a hermitian symmetric space $M=G/K$. The parameter space
carries the structure of normal variety and has a canonical anti-holomorphic
involution. The fixed points of the anti-holomorphic involution are precisely
the integrable invariant complex structures on $Q.$ This normal variety is
closely related to quiver varieties and, more generally, to varieties of
commuting matrix tuples modulo simultaneous conjugation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:10:01 GMT""}]","2020-12-01"
"2011.15073","Mashnoon Islam","Mashnoon Islam, Preetom Nag, Md. Mamun Molla","GPU Accelerated Lattice Boltzmann Simulation of Non-Newtonian Power-Law
  Fluid in a Porous Enclosure","Accepted Version, International Conference on Mechanical Engineering
  2019 (ICME2019) 18-20 December, Dhaka, Bangladesh",,"10.1063/5.0037577",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper demonstrates a numerical study of heat transfer in a square porous
cavity filled with non-Newtonian power-law fluid. A Graphics Processing Unit
(GPU) has been used to accelerate the numerical simulation, which uses the
Multiple-Relaxation-Time (MRT) Lattice Boltzmann Method. A modified power-law
model has been employed to characterize the flow of non-Newtonian fluids. The
simulations have been conducted for the power-law index $n$ ranging from $(0.6
\leq n \leq 1.0)$, the Darcy number $Da$ ranging from $(10^{-3} \leq Da \leq
10^{-1})$ and the Rayleigh number $Ra$ ranging from $(10^3 \leq Ra \leq 10^5)$.
Results show that the average Nusselt number ($\overline{Nu}$) decreases with
an increase in the value of $n$ while $\overline{Nu}$ increases with an
increase in the value of $Da$. Moreover, an increment in the value of $Ra$
leads to an increase in the average Nusselt number.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:12:30 GMT""}]","2021-03-09"
"2011.15074","Debasish Pattanayak","Kartikey Kant, Debasish Pattanayak, and Partha Sarathi Mandal","Fort Formation by an Automaton",,,,,"cs.CC","http://creativecommons.org/licenses/by/4.0/","  Building structures by low capability robots is a very recent research
development. A robot (or a mobile agent) is designed as a deterministic finite
automaton. The objective is to make a structure from a given distribution of
materials (\textit{bricks}) in an infinite grid $Z\times Z$. The grid cells may
contain a brick (\textit{full cells}) or it may be empty (\textit{empty
cells}). The \textit{field}, a sub-graph induced by the full cells, is
initially connected. At a given point in time, a robot can carry at most one
brick. The robot can move in four directions (north, east, south, and west) and
starts from a \textit{full cell}. The \textit{Manhattan distance} between the
farthest full cells is the \textit{span} of the field.
  We consider the construction of a \textit{fort}, a structure with the minimum
span and maximum covered area. On a square grid, a fort is a hollow rectangle
with bricks on the perimeter. We show that the construction of such a fort can
be done in $O(z^2)$ time -- with a matching lower bound $\Omega(z^2)$ -- where
$z$ is the number of bricks present in the environment.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:13:50 GMT""}]","2020-12-01"
"2011.15075","Marco Boggi","Marco Boggi","Automorphisms of procongruence mapping class groups","53 pages",,,,"math.GT math.AG math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For $S=S_{g,n}$ a closed orientable differentiable surface of genus $g$ from
which $n$ points have been removed, with $\chi(S)=2-2g-n<0$, let $\Gamma(S)$ be
the mapping class group of $S$ and $\hat{\Gamma}(S)$ and $\check{\Gamma}(S)$,
respectively, its profinite and its congruence completion. The latter is the
image of the natural representation
$\hat{\Gamma}(S)\to\operatorname{Out}(\hat{\pi}_1(S))$, where $\hat{\pi}_1(S)$
is the profinite completion of the fundamental group of the surface $S$. Let
$\operatorname{Out}^{\mathbb{I}_0}(\check{\Gamma}(S))$ be the group of outer
automorphisms of $\check{\Gamma}(S)$ which preserve the conjugacy class of a
procyclic subgroup generated by a nonseparating Dehn twist and put
$d(S)=3g-3+n$. The main result of the paper is that, for $d(S)>1$, there is a
natural isomorphism:
\[\operatorname{Out}^{\mathbb{I}_0}(\check{\Gamma}(S))\cong\widehat{\operatorname{GT}},\]
where $\widehat{\operatorname{GT}}$ is the profinite Grothendieck-Teichm\""uller
group. We will actually prove a slightly stronger result which implies that the
automorphism group of the procongruence Grothendieck-Teichm\""uller tower is
also isomorphic to $\widehat{\operatorname{GT}}$.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:14:38 GMT""},{""version"":""v2"",""created"":""Thu, 26 May 2022 14:49:35 GMT""}]","2022-05-27"
"2011.15076","Filip Rozp\k{e}dek","Filip Rozp\k{e}dek, Kyungjoo Noh, Qian Xu, Saikat Guha, Liang Jiang","Quantum repeaters based on concatenated bosonic and discrete-variable
  quantum codes","17 + 26 pages, 17 figures. v2: additional discussions of generation
  of higher-level-encoded states and of the secret-key rate performance metric;
  detailed simulation error analysis; restructuring of the sections with the
  new ""Methods"" section; published version. See also the related work by Fukui
  et al., arXiv:2011.14876","npj Quantum Inf. 7, 102 (2021)","10.1038/s41534-021-00438-7",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an architecture of quantum-error-correction-based quantum
repeaters that combines techniques used in discrete- and continuous-variable
quantum information. Specifically, we propose to encode the transmitted qubits
in a concatenated code consisting of two levels. On the first level we use a
continuous-variable GKP code encoding the qubit in a single bosonic mode. On
the second level we use a small discrete-variable code. Such an architecture
has two important features. Firstly, errors on each of the two levels are
corrected in repeaters of two different types. This enables for achieving
performance needed in practical scenarios with a reduced cost with respect to
an architecture for which all repeaters are the same. Secondly, the use of
continuous-variable GKP code on the lower level generates additional analog
information which enhances the error-correcting capabilities of the
second-level code such that long-distance communication becomes possible with
encodings consisting of only four or seven optical modes.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:14:39 GMT""},{""version"":""v2"",""created"":""Wed, 23 Jun 2021 09:43:53 GMT""}]","2021-06-24"
"2011.15077","Andreas Ask MSc","Andreas Ask, Yao-Lung L. Fang, Anton Frisk Kockum","Synthesizing electromagnetically induced transparency without a control
  field in waveguide QED using small and giant atoms","10 pages, 3 figures, 1 table",,,,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The absorption of photons in a three-level atom can be controlled and
manipulated by applying a coherent drive at one of the atomic transitions. The
situation where the absorption is fully canceled, and the atom thus has been
turned completely transparent, has been coined electromagnetically induced
transparency (EIT). The characteristics of EIT is a narrow transparency window
associated with a fluorescence quench at its center frequency, indicating that
inelastic scattering at this particular point is suppressed. The emergence of
EIT-like transparency windows is common in waveguide quantum electrodynamics
(QED) when multiple closely spaced quantum emitters are coupled to a waveguide.
The transparency depends on the separation and energy detuning of the atoms. In
this work, we study a number of different setups with two-level atoms in
waveguide QED that all exhibit EIT-like transparency windows. Unlike the case
of a genuine three-level atom, no drive fields are required in the systems we
consider, and the coherent coupling of energy levels is mediated by the
waveguide. We specifically distinguish between systems with genuine EIT-like
dynamics and those that exhibit a transparency window but lack the fluorescence
quench. The systems that we consider consist of both small and giant atoms,
which can be experimentally realized with artificial atoms coupled to either
photons or phonons. These systems can offer a simpler route to many EIT
applications since the need for external driving is eliminated.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:18:19 GMT""}]","2020-12-01"
"2011.15078","Beatrix Hiesmayr C.","B. C. Hiesmayr, D. McNulty, S. Baek, S. Singha Roy, J. Bae, D.
  Chru\'sci\'nski","Detecting Entanglement can be More Effective with Inequivalent Mutually
  Unbiased Bases","6 pages, 1 figure; added details to d=9","New J. Phys. 23, 093018 (2021)","10.1088/1367-2630/ac20ea",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mutually unbiased bases (MUBs) provide a standard tool in the verification of
quantum states, especially when harnessing a complete set for optimal quantum
state tomography. In this work, we investigate the detection of entanglement
via inequivalent sets of MUBs, with a particular focus on unextendible MUBs.
These are bases for which an additional unbiased basis cannot be constructed
and, consequently, are unsuitable for quantum state verification. Here, we show
that unextendible MUBs, as well as other inequivalent sets in higher
dimensions, can be more effective in the verification of entanglement.
Furthermore, we provide an efficient and systematic method to search for
inequivalent MUBs and show that such sets occur regularly within the
Heisenberg-Weyl MUBs, as the dimension increases. Our findings are particularly
useful for experimentalists since adding optimal MUBs to an experimental setup
enables a step-by-step approach to detect a larger class of entangled states.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:20:06 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 10:59:22 GMT""}]","2021-09-14"
"2011.15079","Christian Diller","Christian Diller, Thomas Funkhouser, Angela Dai","Forecasting Characteristic 3D Poses of Human Actions","CVPR 2022; Project Page: https://charposes.christian-diller.de/;
  Paper Video: https://youtu.be/kVhn8OWMgME",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose the task of forecasting characteristic 3d poses: from a short
sequence observation of a person, predict a future 3d pose of that person in a
likely action-defining, characteristic pose -- for instance, from observing a
person picking up an apple, predict the pose of the person eating the apple.
Prior work on human motion prediction estimates future poses at fixed time
intervals. Although easy to define, this frame-by-frame formulation confounds
temporal and intentional aspects of human action. Instead, we define a
semantically meaningful pose prediction task that decouples the predicted pose
from time, taking inspiration from goal-directed behavior. To predict
characteristic poses, we propose a probabilistic approach that models the
possible multi-modality in the distribution of likely characteristic poses. We
then sample future pose hypotheses from the predicted distribution in an
autoregressive fashion to model dependencies between joints. To evaluate our
method, we construct a dataset of manually annotated characteristic 3d poses.
Our experiments with this dataset suggest that our proposed probabilistic
approach outperforms state-of-the-art methods by 26% on average.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:20:17 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 17:58:08 GMT""},{""version"":""v3"",""created"":""Tue, 8 Mar 2022 18:59:31 GMT""}]","2022-03-09"
"2011.15080","Maciej Kowalski","Maciej Kowalski","LLT cumulants of unicellular Young diagrams, parking functions and Schur
  positivity",,,,,"math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We give a combinatorial formula for LLT cumulants of unicellular unilevelled
shapes in terms of parking functions and Cayley trees. Our formula implies
previously conjectured Schur positivity.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:20:54 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 19:43:46 GMT""}]","2020-12-03"
"2011.15081","Albert Matveev","Albert Matveev, Ruslan Rakhimov, Alexey Artemov, Gleb Bobrovskikh,
  Vage Egiazarian, Emil Bogomolov, Daniele Panozzo, Denis Zorin, Evgeny Burnaev","DEF: Deep Estimation of Sharp Geometric Features in 3D Shapes",,,,,"cs.CV cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose Deep Estimators of Features (DEFs), a learning-based framework for
predicting sharp geometric features in sampled 3D shapes. Differently from
existing data-driven methods, which reduce this problem to feature
classification, we propose to regress a scalar field representing the distance
from point samples to the closest feature line on local patches. Our approach
is the first that scales to massive point clouds by fusing distance-to-feature
estimates obtained on individual patches. We extensively evaluate our approach
against related state-of-the-art methods on newly proposed synthetic and
real-world 3D CAD model benchmarks. Our approach not only outperforms these
(with improvements in Recall and False Positives Rates), but generalizes to
real-world scans after training our model on synthetic data and fine-tuning it
on a small dataset of scanned data. We demonstrate a downstream application,
where we reconstruct an explicit representation of straight and curved sharp
feature lines from range scan data.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:21:00 GMT""},{""version"":""v2"",""created"":""Fri, 10 Sep 2021 21:33:32 GMT""},{""version"":""v3"",""created"":""Fri, 4 Feb 2022 11:08:47 GMT""},{""version"":""v4"",""created"":""Thu, 26 May 2022 12:27:19 GMT""}]","2022-05-27"
"2011.15082","Hsin-Po Wang","Hsin-Po Wang and Iwan Duursma","Parity-Checked Strassen Algorithm","40 pages, 18 figures, 2 tables; v2 adds MSC and applies corrections;
  v3 applies corrections",,,,"cs.IT math.CO math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To multiply astronomic matrices using parallel workers subject to straggling,
we recommend interleaving checksums with some fast matrix multiplication
algorithms. Nesting the parity-checked algorithms, we weave a product code
flavor protection.
  Two demonstrative configurations are as follows: (A) $9$ workers multiply two
$2\times 2$ matrices; each worker multiplies two linear combinations of entries
therein. Then the entry products sent from any $8$ workers suffice to assemble
the matrix product. (B) $754$ workers multiply two $9\times 9$ matrices. With
empirical frequency $99.8\%$, $729$ workers suffice, wherein $729$ is the
complexity of the schoolbook algorithm.
  In general, we propose probability-wisely favorable configurations whose
numbers of workers are close to, if not less than, the thresholds of other
codes (e.g., entangled polynomial code and PolyDot code). Our proposed scheme
applies recursively, respects worker locality, incurs moderate pre- and
post-processes, and extends over small finite fields.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:22:17 GMT""},{""version"":""v2"",""created"":""Sun, 13 Dec 2020 03:36:38 GMT""},{""version"":""v3"",""created"":""Wed, 12 Jan 2022 00:51:46 GMT""}]","2022-01-13"
"2011.15083","Ivan Stelmakh","Ivan Stelmakh, Charvi Rastogi, Nihar B. Shah, Aarti Singh, and Hal
  Daum\'e III","A Large Scale Randomized Controlled Trial on Herding in Peer-Review
  Discussions",,,,,"cs.HC cs.LG stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Peer review is the backbone of academia and humans constitute a cornerstone
of this process, being responsible for reviewing papers and making the final
acceptance/rejection decisions. Given that human decision making is known to be
susceptible to various cognitive biases, it is important to understand which
(if any) biases are present in the peer-review process and design the pipeline
such that the impact of these biases is minimized. In this work, we focus on
the dynamics of between-reviewers discussions and investigate the presence of
herding behaviour therein. In that, we aim to understand whether reviewers and
more senior decision makers get disproportionately influenced by the first
argument presented in the discussion when (in case of reviewers) they form an
independent opinion about the paper before discussing it with others.
Specifically, in conjunction with the review process of ICML 2020 -- a large,
top tier machine learning conference -- we design and execute a randomized
controlled trial with the goal of testing for the conditional causal effect of
the discussion initiator's opinion on the outcome of a paper.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:23:07 GMT""}]","2020-12-01"
"2011.15084","Yecheng Jason Ma","Yecheng Jason Ma, Jeevana Priya Inala, Dinesh Jayaraman, Osbert
  Bastani","Likelihood-Based Diverse Sampling for Trajectory Forecasting","ICCV 2021",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Forecasting complex vehicle and pedestrian multi-modal distributions requires
powerful probabilistic approaches. Normalizing flows (NF) have recently emerged
as an attractive tool to model such distributions. However, a key drawback is
that independent samples drawn from a flow model often do not adequately
capture all the modes in the underlying distribution. We propose
Likelihood-Based Diverse Sampling (LDS), a method for improving the quality and
the diversity of trajectory samples from a pre-trained flow model. Rather than
producing individual samples, LDS produces a set of trajectories in one shot.
Given a pre-trained forecasting flow model, we train LDS using gradients from
the model, to optimize an objective function that rewards high likelihood for
individual trajectories in the predicted set, together with high spatial
separation among trajectories. LDS outperforms state-of-art post-hoc neural
diverse forecasting methods for various pre-trained flow models as well as
conditional variational autoencoder (CVAE) models. Crucially, it can also be
used for transductive trajectory forecasting, where the diverse forecasts are
trained on-the-fly on unlabeled test examples. LDS is easy to implement, and we
show that it offers a simple plug-in improvement over baselines on two
challenging benchmarks. Code is at: https://github.com/JasonMa2016/LDS
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:23:29 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 23:29:16 GMT""}]","2021-09-16"
"2011.15085","Bernardo Martin-Iradi","Bernardo Martin-Iradi, Dario Pacino, Stefan Ropke","The multi-port berth allocation problem with speed optimization: Exact
  methods and a cooperative game analysis","42 pages, 9 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a variant of the berth allocation problem-i.e., the multi-port
berth allocation problem-aimed at assigning berthing times and positions to
vessels in container terminals. This variant involves optimizing vessel travel
speeds between multiple ports, thereby exploiting the potentials of a
collaboration between carriers (shipping lines) and terminal operators. Using a
graph representation of the problem, we reformulate an existing mixed-integer
problem into a generalized set partitioning problem, in which each variable
refers to a sequence of feasible berths in the ports that the vessel visits. By
integrating column generation and cut separation in a branch-and-cut-and-price
procedure, our proposed method is able to outperform commercial solvers in a
set of benchmark instances and adapt better to larger instances. In addition,
we apply cooperative game theory methods to efficiently distribute the savings
resulting from a potential collaboration and show that both carriers and
terminal operators would benefit from collaborating.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:23:34 GMT""},{""version"":""v2"",""created"":""Mon, 4 Oct 2021 09:19:50 GMT""}]","2021-10-05"
"2011.15086","Yue Wu","Yue Wu","A randomised trapezoidal quadrature",,,,,"math.NA cs.NA math.PR","http://creativecommons.org/licenses/by/4.0/","  A randomised trapezoidal quadrature rule is proposed for continuous functions
which enjoys less regularity than commonly required. Indeed, we consider
functions in some fractional Sobolev space. Various error bounds for this
randomised rule are established while an error bound for classical trapezoidal
quadrature is obtained for comparison. The randomised trapezoidal quadrature
rule is shown to improve the order of convergence by half.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:23:53 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 10:39:49 GMT""}]","2020-12-03"
"2011.15087","Jack Holguin","Jack Holguin, Jeffrey R. Forshaw, Simon Pl\""atzer","Improvements on dipole shower colour","26 pages, 2 appendices, 9 figures. Version 2 contains small changes
  and is inline with the version published in EPJ C","Eur. Phys. J. C 81, 364 (2021)","10.1140/epjc/s10052-021-09145-1",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dipole formalism provides a powerful framework from which parton showers
can be constructed. In a recent paper, we proposed a dipole shower with
improved colour accuracy and in this paper we show how it can be further
improved. After an explicit check at $\mathcal{O}(\alpha_{\mathrm{s}}^{2})$ we
confirm that our original shower performs as it was designed to, i.e.
inheriting its handling of angular-ordered radiation from a coherent branching
algorithm. We also show how other dipole shower algorithms fail to achieve
this. Nevertheless, there is an $\mathcal{O}(\alpha_{\mathrm{s}}^{2})$ topology
where it differs at sub-leading $N_{\mathrm{c}}$ from a coherent branching
algorithm. This erroneous topology can contribute a leading logarithm to some
observables and corresponds to emissions that are ordered in $k_t$ but not
angle. We propose a simple, computationally efficient way to correct this and
assign colour factors in accordance with the coherence properties of QCD to all
orders in $\alpha_{\mathrm{s}}$.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:25:33 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 17:26:16 GMT""}]","2021-04-29"
"2011.15088","Ilya Gorshkov","Ilya Gorshkov","Characterization of groups with non-simple socle",,,,,"math.GR","http://creativecommons.org/publicdomain/zero/1.0/","  The spectrum of a finite group is a set of its element orders. We prove that
if $m>5$ then the group $L_{2^m}(2)\times L_{2^m}(2)\times L_{2^m}(2)$ is
uniquely determined by its spectrum in the class of finite groups
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:26:46 GMT""}]","2020-12-01"
"2011.15089","Lorenzo Pizzuti","Lorenzo Pizzuti, Ippocratis D. Saltas and Luca Amendola","MG-MAMPOSSt: A code to test modifications of gravity with the dynamics
  of galaxy clusters","19 pages, 13 figures, accepted for publication on MNRAS. For v3 : an
  error in the acknowledgements of v2 has been corrected. A significant
  extension about lensing in Vainshtein screening has been added compared to v1",,"10.1093/mnras/stab1727",,"astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  We present an upgraded version of \textsc{MG-MAMPOSSt}, an extension of the
\textsc{MAMPOSSt} algorithm that performs Bayesian fits of models of mass and
velocity anisotropy profiles to the distribution of tracers in projected phase
space, to handle modified gravity models and constrain their parameters. The
new version implements two distinct types of gravity modifications, namely
general chameleon and Vainshtein screening, and is further equipped with a
Monte-Carlo-Markov-Chain module for an efficient parameter space exploration.
The program is complemented by the \textsc{ClusterGEN} code, capable of
producing mock galaxy clusters under the assumption of spherical symmetry,
dynamical equilibrium, and Gaussian local velocity distribution functions as in
\textsc{MAMPOSSt}. We demonstrate the potential of the method by analysing a
set of synthetic, isolated spherically-symmetric dark matter haloes, focusing
on the statistical degeneracies between model parameters. Assuming the
availability of additional lensing-like information, we forecast the
constraints on the modified gravity parameters for the two models presented, as
expected from joint lensing+internal kinematics analyses, in view of upcoming
galaxy cluster surveys. In Vainshtein screening, we forecast the weak lensing
effect through the estimation of the full convergence-shear profile. For
chameleon screening, we constrain the allowed region in the space of the two
free parameters of the model, further focusing on the $f(\mathcal{R})$ subclass
to obtain realistic bounds on the background field $|f_{\mathcal{R}0}|$. Our
analysis demonstrates the complementarity of internal kinematics and lensing
probes for constraining modified gravity theories, and how the bounds on
Vainshtein-screened theories improve through the combination of the two probes.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:26:58 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 13:56:35 GMT""},{""version"":""v3"",""created"":""Mon, 12 Jul 2021 17:42:43 GMT""}]","2021-07-13"
"2011.15090","Hugo Duminil-Copin","Hugo Duminil-Copin and Ioan Manolescu","Planar random-cluster model: scaling relations","85 pages, 14 figures, 1 table",,,,"math.PR math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  This paper studies the critical and near-critical regimes of the planar
random-cluster model on $\mathbb Z^2$ with cluster-weight $q\in[1,4]$ using
novel coupling techniques. More precisely, we derive the scaling relations
between the critical exponents $\beta$, $\gamma$, $\delta$, $\eta$, $\nu$,
$\zeta$ as well as $\alpha$ (when $\alpha\ge0$). As a key input, we show the
stability of crossing probabilities in the near-critical regime using new
interpretations of the notion of influence of an edge in terms of the rate of
mixing. As a byproduct, we derive a generalization of Kesten's classical
scaling relation for Bernoulli percolation involving the ``mixing rate''
critical exponent $\iota$ replacing the four-arm event exponent $\xi_4$.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:27:16 GMT""}]","2020-12-01"
"2011.15091","Anirudh Goyal","Anirudh Goyal, Yoshua Bengio","Inductive Biases for Deep Learning of Higher-Level Cognition","This document contains a review of authors research as part of the
  requirement of AG's predoctoral exam, an overview of the main contributions
  of the authors few recent papers (co-authored with several other co-authors)
  as well as a vision of proposed future research",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  A fascinating hypothesis is that human and animal intelligence could be
explained by a few principles (rather than an encyclopedic list of heuristics).
If that hypothesis was correct, we could more easily both understand our own
intelligence and build intelligent machines. Just like in physics, the
principles themselves would not be sufficient to predict the behavior of
complex systems like brains, and substantial computation might be needed to
simulate human-like intelligence. This hypothesis would suggest that studying
the kind of inductive biases that humans and animals exploit could help both
clarify these principles and provide inspiration for AI research and
neuroscience theories. Deep learning already exploits several key inductive
biases, and this work considers a larger list, focusing on those which concern
mostly higher-level and sequential conscious processing. The objective of
clarifying these particular principles is that they could potentially help us
build AI systems benefiting from humans' abilities in terms of flexible
out-of-distribution and systematic generalization, which is currently an area
where a large gap exists between state-of-the-art machine learning and human
intelligence.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:29:25 GMT""},{""version"":""v2"",""created"":""Mon, 7 Dec 2020 17:51:00 GMT""},{""version"":""v3"",""created"":""Wed, 17 Feb 2021 21:54:35 GMT""},{""version"":""v4"",""created"":""Mon, 1 Aug 2022 13:58:56 GMT""}]","2022-08-02"
"2011.15092","Toni Ikonen","Toni Ikonen, Enrico Pasqualetto, Elefterios Soultanis","Abstract and concrete tangent modules on Lipschitz differentiability
  spaces","14 pages, to appear in Proc. Amer. Math. Soc",,,,"math.MG math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct an isometric embedding from Gigli's abstract tangent module into
the concrete tangent module of a space admitting a (weak) Lipschitz
differentiable structure, and give two equivalent conditions which characterize
when the embedding is an isomorphism. Together with arguments from a recent
article by Bate--Kangasniemi--Orponen, this equivalence is used to show that
the ${\rm Lip}-{\rm lip}$ -type condition ${\rm lip} f\le C|Df|$ implies the
existence of a Lipschitz differentiable structure, and moreover self-improves
to ${\rm lip} f =|Df|$.
  We also provide a direct proof of a result by Gigli and the second author
that, for a space with a strongly rectifiable decomposition, Gigli's tangent
module admits an isometric embedding into the so-called Gromov--Hausdorff
tangent module, without any a priori reflexivity assumptions.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:29:36 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 12:01:19 GMT""}]","2021-10-19"
"2011.15093","Ahmed Fetit","Seoin Chai, Daniel Rueckert, Ahmed E. Fetit","Reducing Textural Bias Improves Robustness of Deep Segmentation Models","To appear in MIUA 2021 (accepted version)",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Despite advances in deep learning, robustness under domain shift remains a
major bottleneck in medical imaging settings. Findings on natural images
suggest that deep neural models can show a strong textural bias when carrying
out image classification tasks. In this thorough empirical study, we draw
inspiration from findings on natural images and investigate ways in which
addressing the textural bias phenomenon could bring up the robustness of deep
segmentation models when applied to three-dimensional (3D) medical data. To
achieve this, publicly available MRI scans from the Developing Human Connectome
Project are used to study ways in which simulating textural noise can help
train robust models in a complex semantic segmentation task. We contribute an
extensive empirical investigation consisting of 176 experiments and illustrate
how applying specific types of simulated textural noise prior to training can
lead to texture invariant models, resulting in improved robustness when
segmenting scans corrupted by previously unseen noise types and levels.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:29:53 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 22:17:35 GMT""},{""version"":""v3"",""created"":""Sun, 27 Jun 2021 21:15:40 GMT""}]","2021-06-29"
"2011.15094","Thiago Bergamaschi","Thiago Bergamaschi","Simulated Quantum Annealing is Efficient on the Spike Hamiltonian",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this work we study the convergence of a classical algorithm called
Simulated Quantum Annealing (SQA) on the Spike Hamiltonian, a specific toy
model Hamiltonian for quantum-mechanical tunneling introduced by [FGG02]. This
toy model Hamiltonian encodes a simple bit-symmetric cost function f in the
computational basis, and is used to emulate local minima in more complex
optimization problems. In previous work [CH16] showed that SQA runs in
polynomial time in much of the regime of spikes that QA does, pointing to
evidence against an exponential speedup through tunneling. In this paper we
extend their analysis to the remaining polynomial regime of energy gaps of the
spike Hamiltonian, to show that indeed QA presents no exponential speedup with
respect to SQA on this family of toy models.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:30:15 GMT""}]","2020-12-01"
"2011.15095","Sneh Pandya","Joshua Yao-Yu Lin, Sneh Pandya, Devanshi Pratap, Xin Liu, Matias
  Carrasco Kind","AGNet: Weighing Black Holes with Machine Learning","5 pages, 3 figures, 1 table. Accepted to the Machine Learning and the
  Physical Sciences Workshop at NeurIPS 2020",,,,"astro-ph.GA astro-ph.HE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supermassive black holes (SMBHs) are ubiquitously found at the centers of
most galaxies. Measuring SMBH mass is important for understanding the origin
and evolution of SMBHs. However, traditional methods require spectral data
which is expensive to gather. To solve this problem, we present an algorithm
that weighs SMBHs using quasar light time series, circumventing the need for
expensive spectra. We train, validate, and test neural networks that directly
learn from the Sloan Digital Sky Survey (SDSS) Stripe 82 data for a sample of
$9,038$ spectroscopically confirmed quasars to map out the nonlinear encoding
between black hole mass and multi-color optical light curves. We find a
1$\sigma$ scatter of 0.35 dex between the predicted mass and the fiducial
virial mass based on SDSS single-epoch spectra. Our results have direct
implications for efficient applications with future observations from the Vera
Rubin Observatory.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:30:24 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 06:15:26 GMT""}]","2020-12-02"
"2011.15096","Etienne Richan","Etienne Richan, Jean Rouat","A proposal and evaluation of new timbre visualisation methods for audio
  sample browsers","14 pages. Personal and Ubiquitous Computing (2020)",,"10.1007/s00779-020-01388-1",,"cs.HC cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Searching through vast libraries of sound samples can be a daunting and
time-consuming task. Modern audio sample browsers use mappings between acoustic
properties and visual attributes to visually differentiate displayed items.
There are few studies focused on how well these mappings help users search for
a specific sample. We propose new methods for generating textural labels and
positioning samples based on perceptual representations of timbre. We perform a
series of studies to evaluate the benefits of using shape, color or texture as
labels in a known-item search task. We describe the motivation and
implementation of the study, and present an in-depth analysis of results. We
find that shape significantly improves task performance, while color and
texture have little effect. We also compare results between in-person and
online participants and propose research directions for further studies.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:30:26 GMT""}]","2020-12-01"
"2011.15097","Mikael Beuthe","Mikael Beuthe","Isostasy with Love: I Elastic equilibrium","67 pages, 12 figures, 5 tables; revised version for publication","Geophysical Journal International (2021) 225, 2157-2193","10.1093/gji/ggab073",,"astro-ph.EP physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  Isostasy explains why observed gravity anomalies are generally much weaker
than what is expected from topography alone, and why planetary crusts can
support high topography without breaking up. Classical isostasy, however,
neglects internal stresses and geoid contributions to topographical support,
and yields ambiguous predictions of geoid anomalies. Isostasy should instead be
defined either by minimizing deviatoric elastic stresses within the elastic
shell, or by studying the dynamic response of the body in the long-time limit.
I implement here the first option by formulating Airy isostatic equilibrium as
the response of an elastic shell to surface and internal loads. Isostatic
ratios are defined in terms of deviatoric Love numbers which quantify
deviations with respect to a fluid state. The Love number approach separates
the physics of isostasy from the technicalities of elastic-gravitational
spherical deformations, and provides flexibility in the choice of the interior
structure. Since elastic isostasy is invariant under a global rescaling of the
shell shear modulus, it can be defined in the fluid shell limit, which reveals
a deep connection with viscous isostasy. If the shell is homogeneous, minimum
stress isostasy is dual to a variant of elastic isostasy called zero deflection
isostasy, which is less physical but simpler to compute. Each isostatic model
is combined with general boundary conditions applied at the surface and bottom
of the shell, resulting in one-parameter isostatic families. At long
wavelength, the influence of boundary conditions disappears as all isostatic
families members yield the same isostatic ratios. At short wavelength,
topography is supported by shallow stresses so that Airy isostasy becomes
similar to either pure top or bottom loading. The isostatic ratios of
incompressible bodies with three homogeneous layers are implemented in freely
available software.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:31:17 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 10:27:20 GMT""}]","2021-05-21"
"2011.15098","David Loeffler","David Loeffler and Sarah Livia Zerbes","On p-adic regulators for GSp(4) x GL(2) and GSp(4) x GL(2) x GL(2)","v2: updates to references, acknowledgements",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the images of motivic cohomology classes for GSp(4) x GL(2) and
GSp(4) x GL(2) x GL(2) under the syntomic regulator, and relate them to
non-critical values of p-adic L-functions.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:32:15 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 16:58:06 GMT""}]","2021-07-02"
"2011.15099","Roy Adams","Roy Adams, Suchi Saria, Michael Rosenblum","The Impact of Time Series Length and Discretization on Longitudinal
  Causal Estimation Methods",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of observational time series data to assess the impact of multi-time
point interventions is becoming increasingly common as more health and activity
data are collected and digitized via wearables, social media, and electronic
health records. Such time series may involve hundreds or thousands of
irregularly sampled observations. One common analysis approach is to simplify
such time series by first discretizing them into sequences before applying a
discrete-time estimation method that adjusts for time-dependent confounding. In
certain settings, this discretization results in sequences with many time
points; however, the empirical properties of longitudinal causal estimators
have not been systematically compared on long sequences. We compare three
representative longitudinal causal estimation methods on simulated and real
clinical data. Our simulations and analyses assume a Markov structure and that
longitudinal treatments/exposures are binary-valued and have at most a single
jump point. We identify sources of bias that arise from temporally discretizing
the data and provide practical guidance for discretizing data and choosing
between methods when working with long sequences. Additionally, we compare
these estimators on real electronic health record data, evaluating the impact
of early treatment for patients with a life-threatening complication of
infection called sepsis.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:32:19 GMT""}]","2020-12-01"
"2011.15100","Upinder Kaur","Glebys T. Gonzalez, Upinder Kaur, Masudur Rahma, Vishnunandan
  Venkatesh, Natalia Sanchez, Gregory Hager, Yexiang Xue, Richard Voyles, Juan
  Wachs","From the DESK (Dexterous Surgical Skill) to the Battlefield -- A
  Robotics Exploratory Study","First 3 authors share equal contribution","Published in MHSRS 2020",,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Short response time is critical for future military medical operations in
austere settings or remote areas. Such effective patient care at the point of
injury can greatly benefit from the integration of semi-autonomous robotic
systems. To achieve autonomy, robots would require massive libraries of
maneuvers. While this is possible in controlled settings, obtaining surgical
data in austere settings can be difficult. Hence, in this paper, we present the
Dexterous Surgical Skill (DESK) database for knowledge transfer between robots.
The peg transfer task was selected as it is one of 6 main tasks of laparoscopic
training. Also, we provide a ML framework to evaluate novel transfer learning
methodologies on this database. The collected DESK dataset comprises a set of
surgical robotic skills using the four robotic platforms: Taurus II, simulated
Taurus II, YuMi, and the da Vinci Research Kit. Then, we explored two different
learning scenarios: no-transfer and domain-transfer. In the no-transfer
scenario, the training and testing data were obtained from the same domain;
whereas in the domain-transfer scenario, the training data is a blend of
simulated and real robot data that is tested on a real robot. Using simulation
data enhances the performance of the real robot where limited or no real data
is available. The transfer model showed an accuracy of 81% for the YuMi robot
when the ratio of real-to-simulated data was 22%-78%. For Taurus II and da
Vinci robots, the model showed an accuracy of 97.5% and 93% respectively,
training only with simulation data. Results indicate that simulation can be
used to augment training data to enhance the performance of models in real
scenarios. This shows the potential for future use of surgical data from the
operating room in deployable surgical robots in remote areas.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:32:20 GMT""}]","2020-12-01"
"2011.15101","Yang P. Liu","Yang P. Liu","Vertex Sparsification for Edge Connectivity in Polynomial Time","16 pages, changed license",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An important open question in the area of vertex sparsification is whether
$(1+\epsilon)$-approximate cut-preserving vertex sparsifiers with size close to
the number of terminals exist. The work Chalermsook et al. (SODA 2021)
introduced a relaxation called connectivity-$c$ mimicking networks, which asks
to construct a vertex sparsifier which preserves connectivity among $k$
terminals exactly up to the value of $c$, and showed applications to dynamic
connectivity data structures and survivable network design. We show that
connectivity-$c$ mimicking networks with $\widetilde{O}(kc^3)$ edges exist and
can be constructed in polynomial time in $n$ and $c$, improving over the
results of Chalermsook et al. (SODA 2021) for any $c \ge \log n$, whose
runtimes depended exponentially on $c$.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:33:16 GMT""},{""version"":""v2"",""created"":""Thu, 14 Jan 2021 05:53:50 GMT""}]","2021-01-15"
"2011.15102","Pengtao Xie","Xuefeng Du, Haochen Zhang, Pengtao Xie","Learning by Passing Tests, with Application to Neural Architecture
  Search","arXiv admin note: substantial text overlap with arXiv:2012.04863,
  arXiv:2012.12502, arXiv:2012.12899",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Learning through tests is a broadly used methodology in human learning and
shows great effectiveness in improving learning outcome: a sequence of tests
are made with increasing levels of difficulty; the learner takes these tests to
identify his/her weak points in learning and continuously addresses these weak
points to successfully pass these tests. We are interested in investigating
whether this powerful learning technique can be borrowed from humans to improve
the learning abilities of machines. We propose a novel learning approach called
learning by passing tests (LPT). In our approach, a tester model creates
increasingly more-difficult tests to evaluate a learner model. The learner
tries to continuously improve its learning ability so that it can successfully
pass however difficult tests created by the tester. We propose a multi-level
optimization framework to formulate LPT, where the tester learns to create
difficult and meaningful tests and the learner learns to pass these tests. We
develop an efficient algorithm to solve the LPT problem. Our method is applied
for neural architecture search and achieves significant improvement over
state-of-the-art baselines on CIFAR-100, CIFAR-10, and ImageNet.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:33:34 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 03:43:01 GMT""}]","2021-03-15"
"2011.15103","Parmida Davarmanesh","Parmida Davarmanesh, Kuanhao Jiang, Tingting Ou, Artem Vysogorets,
  Stanislav Ivashkevich, Max Kiehn, Shantanu H. Joshi, Nicholas Malaya","Automating Artifact Detection in Video Games",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In spite of advances in gaming hardware and software, gameplay is often
tainted with graphics errors, glitches, and screen artifacts. This proof of
concept study presents a machine learning approach for automated detection of
graphics corruptions in video games. Based on a sample of representative screen
corruption examples, the model was able to identify 10 of the most commonly
occurring screen artifacts with reasonable accuracy. Feature representation of
the data included discrete Fourier transforms, histograms of oriented
gradients, and graph Laplacians. Various combinations of these features were
used to train machine learning models that identify individual classes of
graphics corruptions and that later were assembled into a single mixed experts
""ensemble"" classifier. The ensemble classifier was tested on heldout test sets,
and produced an accuracy of 84% on the games it had seen before, and 69% on
games it had never seen before.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:34:40 GMT""}]","2020-12-01"
"2011.15104","J. de Curt\'o i D\'iAz","J. de Curt\'o and R. Duvall","Vulcan Centaur: towards end-to-end real-time perception in lunar rovers",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new real-time pipeline for Simultaneous Localization and
Mapping (SLAM) and Visual Inertial Odometry (VIO) in the context of planetary
rovers. We leverage prior information of the location of the lander to propose
an object-level SLAM approach that optimizes pose and shape of the lander
together with camera trajectories of the rover. As a further refinement step,
we propose to use techniques of interpolation between adjacent temporal
samples; videlicet synthesizing non-existing images to improve the overall
accuracy of the system. The experiments are conducted in the context of the
Iris Lunar Rover, a nano-rover that will be deployed in lunar terrain in 2021
as the flagship of Carnegie Mellon, being the first unmanned rover of America
to be on the Moon.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:39:03 GMT""}]","2020-12-01"
"2011.15105","Alessandra L\""utz","Alessandra Friedrich L\""utz, Marco Antonio Amaral, Lucas Wardil","Moderate immigration may promote a peak of cooperation among natives",,"Phys. Rev. E 104, 014304 (2021)","10.1103/PhysRevE.104.014304",,"physics.soc-ph cond-mat.stat-mech physics.bio-ph q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  In a world of hardening borders, nations may deprive themselves of enjoying
the benefits of cooperative immigrants. Here, we analyze the effect of
efficient cooperative immigrants on a population playing public goods games. We
considered a population structured on a square lattice with individuals playing
public goods games with their neighbors. The demographics are determined by
stochastic birth, death, and migration. The strategies spread through imitation
dynamics. Our model shows that cooperation among natives can emerge due to
social contagion of good role-model agents that can provide better quality
public goods. Only a small fraction of efficient cooperators, among immigrants,
is enough to trigger cooperation across the native population. We see that
native cooperation achieves its peak at moderate values of immigration rate.
Such efficient immigrant cooperators act as nucleation centers for the growth
of cooperative clusters, that eventually dominate defection.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:39:11 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 18:11:40 GMT""},{""version"":""v3"",""created"":""Fri, 11 Jun 2021 18:24:07 GMT""}]","2021-07-14"
"2011.15106","David Loeffler","David Loeffler","On local zeta-integrals for GSp(4) and GSp(4) x GL(2)",,,,,"math.RT math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that Novodvorsky's definition of local L-factors for generic
representations of GSp(4) x GL(2) is compatible with the local Langlands
correspondence when the GL(2) representation is non-supercuspidal. We also give
an interpretation in terms of Langlands parameters of the ""exceptional"" poles
of the GSp(4) x GL(2) L-factor, and of the ""subregular"" poles of the GSp(4)
L-factor studied in recent work of Roesner and Weissauer.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:40:09 GMT""}]","2020-12-01"
"2011.15107","Adam-Christiaan van Roosmalen","Ruben Henrard and Sondre Kvamme and Adam-Christiaan van Roosmalen","Auslander's formula and correspondence for exact categories","36 pages, comments welcome!",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Auslander correspondence is a fundamental result in Auslander-Reiten
theory. In this paper we introduce the category
$\operatorname{mod_{\mathsf{adm}}}(\mathcal{E})$ of admissibly finitely
presented functors and use it to give a version of Auslander correspondence for
any exact category $\mathcal{E}$. An important ingredient in the proof is the
localization theory of exact categories. We also investigate how properties of
$\mathcal{E}$ are reflected in
$\operatorname{mod_{\mathsf{adm}}}(\mathcal{E})$, for example being (weakly)
idempotent complete or having enough projectives or injectives. Furthermore, we
describe $\operatorname{mod_{\mathsf{adm}}}(\mathcal{E})$ as a subcategory of
$\operatorname{mod}(\mathcal{E})$ when $\mathcal{E}$ is a resolving subcategory
of an abelian category. This includes the category of Gorenstein projective
modules and the category of maximal Cohen-Macaulay modules as special cases.
Finally, we use $\operatorname{mod_{\mathsf{adm}}}(\mathcal{E})$ to give a
bijection between exact structures on an idempotent complete additive category
$\mathcal{C}$ and certain resolving subcategories of
$\operatorname{mod}(\mathcal{C})$.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:41:22 GMT""}]","2020-12-01"
"2011.15108","Brett McLean","C\'elia Borlido and Brett McLean","Difference-restriction algebras of partial functions: axiomatisations
  and representations","32 pages. Sections 3 and 4 have been re-arranged","Algebra Universalis, Volume 83, Issue 3 (August 2022)","10.1007/s00012-022-00775-4",,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the representation and complete representation classes for
algebras of partial functions with the signature of relative complement and
domain restriction. We provide and prove the correctness of a finite equational
axiomatisation for the class of algebras representable by partial functions. As
a corollary, the same equations axiomatise the algebras representable as
injective partial functions. For complete representations, we show that a
representation is meet complete if and only if it is join complete. Then we
show that the class of completely representable algebras is precisely the class
of atomic and representable algebras. As a corollary, the same properties
axiomatise the class of algebras completely representable by injective partial
functions. The universal-existential-universal axiomatisation this yields for
these complete representation classes is the simplest possible, in the sense
that no existential-universal-existential axiomatisation exists.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:43:41 GMT""},{""version"":""v2"",""created"":""Wed, 4 May 2022 12:06:54 GMT""}]","2022-12-05"
"2011.15109","Giulia Cusin","Giulia Cusin and Nicola Tamanini","Characterisation of lensing selection effects for LISA massive black
  hole binary mergers","10 pages, 6 figures",,"10.1093/mnras/stab1130",,"astro-ph.CO astro-ph.GA astro-ph.IM gr-qc","http://creativecommons.org/licenses/by/4.0/","  We present a method to include lensing selection effects due to the finite
horizon of a given detector when studying lensing of gravitational wave (GW)
sources. When selection effects are included, the mean of the magnification
distribution is shifted from one to higher values for sufficiently
high-redshift sources. This introduces an irreducible (multiplicative) bias on
the luminosity distance reconstruction, in addition to the typical source of
uncertainty in the distance determination. We apply this method to study
lensing of GWs emitted by massive black hole binary mergers at high redshift
detectable by LISA. We estimate the expected bias induced by selection effects
on the luminosity distance reconstruction as function of cosmological redshift,
and discuss its implications for cosmological and astrophysical analyses with
LISA. We also reconstruct the distribution of lensing magnification as a
function of the observed luminosity distance to a source, that is the
observable quantity in the absence of an electromagnetic counterpart. Lensing
provides the dominant source of errors in distance measurements of
high-redshift GW sources. Its full characterisation, including the impact of
selection effects, is of paramount importance to correctly determine the
astrophysical properties of the underlying source population and to be able to
use gravitational wave sources as a new cosmological probe.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:45:03 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 09:23:21 GMT""}]","2021-05-21"
"2011.15110","Thomas O'Leary-Roseberry","Thomas O'Leary-Roseberry, Umberto Villa, Peng Chen, and Omar Ghattas","Derivative-Informed Projected Neural Networks for High-Dimensional
  Parametric Maps Governed by PDEs",,,,,"math.NA cs.CE cs.LG cs.NA","http://creativecommons.org/licenses/by/4.0/","  Many-query problems, arising from uncertainty quantification, Bayesian
inversion, Bayesian optimal experimental design, and optimization under
uncertainty-require numerous evaluations of a parameter-to-output map. These
evaluations become prohibitive if this parametric map is high-dimensional and
involves expensive solution of partial differential equations (PDEs). To tackle
this challenge, we propose to construct surrogates for high-dimensional
PDE-governed parametric maps in the form of projected neural networks that
parsimoniously capture the geometry and intrinsic low-dimensionality of these
maps. Specifically, we compute Jacobians of these PDE-based maps, and project
the high-dimensional parameters onto a low-dimensional derivative-informed
active subspace; we also project the possibly high-dimensional outputs onto
their principal subspace. This exploits the fact that many high-dimensional
PDE-governed parametric maps can be well-approximated in low-dimensional
parameter and output subspace. We use the projection basis vectors in the
active subspace as well as the principal output subspace to construct the
weights for the first and last layers of the neural network, respectively. This
frees us to train the weights in only the low-dimensional layers of the neural
network. The architecture of the resulting neural network captures to first
order, the low-dimensional structure and geometry of the parametric map. We
demonstrate that the proposed projected neural network achieves greater
generalization accuracy than a full neural network, especially in the limited
training data regime afforded by expensive PDE-based parametric maps. Moreover,
we show that the number of degrees of freedom of the inner layers of the
projected network is independent of the parameter and output dimensions, and
high accuracy can be achieved with weight dimension independent of the
discretization dimension.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:46:40 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 22:08:58 GMT""}]","2021-03-18"
"2011.15111","Milan Ding","Milan Ding and Juliet C. Pickering","Measurements of the Hyperfine Structure of Atomic Energy Levels in Co II","Revision accepted by ApJS",,"10.3847/1538-4365/abbdf8",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analysis of hyperfine structure constants of singly ionised cobalt (Co II)
were performed on cobalt spectra measured by Fourier transform spectrometers in
the region $3000-63000$ cm$^{-1}$ ($3333-159$ nm). Fits to over $700$ spectral
lines led to measurements of $292$ magnetic dipole hyperfine interaction $A$
constants, with values between $-32.5$ mK and $59.5$ mK ($1$ mK $=0.001$
cm$^{-1}$). Uncertainties of $255$ A constants were between $\pm0.4$ mK and
$\pm3.0$ mK, the remaining $37$ ranged up to $\pm7$ mK. The electric quadrupole
hyperfine interaction $B$ constant could be estimated for only $1$ energy
level. The number of Co II levels with known $A$ values has now increased
tenfold, improving and enabling the wider, more reliable and accurate
application of Co II in astronomical chemical abundance analyses.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:47:41 GMT""}]","2020-12-09"
"2011.15112","Zachary Weller-Davies","Jonathan Oppenheim and Zachary Weller-Davies","The constraints of post-quantum classical gravity","32 +4 pages, V2 added background material and general improvements.
  Accepted in JHEP","JHEP 02 (2022) 080","10.1007/JHEP02(2022)080",,"hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a class of theories in which space-time is treated classically,
while interacting with quantum fields. These circumvent various no-go theorems
and the pathologies of semi-classical gravity, by being linear in the density
matrix and phase-space density. The theory can either be considered fundamental
or as an effective theory where the classical limit is taken of space-time. The
theories have the dynamics of general relativity as their classical limit and
provide a way to study the back-action of quantum fields on the space-time
metric. The theory is invariant under spatial diffeomorphisms, and here, we
provide a methodology to derive the constraint equations of such a theory by
imposing invariance of the dynamics under time-reparametrization invariance.
This leads to generalisations of the Hamiltonian and momentum constraints. We
compute the constraint algebra for a wide class of realisations of the theory
(the ""discrete class"") in the case of a quantum scalar field interacting with
gravity. We find that the algebra doesn't close without additional constraints,
although these do not necessarily reduce the number of local degrees of
freedom.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:48:25 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 00:42:48 GMT""}]","2022-02-15"
"2011.15113","Bakul Agarwal `","Bakul Agarwal, Stephen P. Jones, Andreas von Manteuffel","Two-loop helicity amplitudes for $gg \to ZZ$ with full top-quark mass
  effects","40 pages, 16 figures, 5 tables, 2 algorithms, and 2 ancillary files;
  v2: added comparisons with Pade approximations, added discussion of
  subtraction scheme dependence, fixed conventions of results and issues in
  presentation of numerical checks",,"10.1007/JHEP05(2021)256","CERN-TH-2020-201 IPPP/20/61 MSUHEP-20-017","hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate the two-loop QCD corrections to $gg \to ZZ$ involving a closed
top-quark loop. We present a new method to systematically construct linear
combinations of Feynman integrals with a convergent parametric representation,
where we also allow for irreducible numerators, higher powers of propagators,
dimensionally shifted integrals, and subsector integrals. The amplitude is
expressed in terms of such finite integrals by employing syzygies derived with
linear algebra and finite field techniques. Evaluating the amplitude using
numerical integration, we find agreement with previous expansions in asymptotic
limits and provide ab initio results also for intermediate partonic energies
and non-central scattering at higher energies.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:48:32 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 23:35:33 GMT""}]","2021-06-16"
"2011.15114","Melih Bastopcu","Melih Bastopcu and Sennur Ulukus","Timely Group Updating",,,,,"cs.IT cs.NI eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider two closely related problems: anomaly detection in sensor
networks and testing for infections in human populations. In both problems, we
have $n$ nodes (sensors, humans), and each node exhibits an event of interest
(anomaly, infection) with probability $p$. We want to keep track of the
anomaly/infection status of all nodes at a central location. We develop a
$group$ $updating$ scheme, akin to group testing, which updates a central
location about the status of each member of the population by appropriately
grouping their individual status. Unlike group testing, which uses the expected
number of tests as a metric, in group updating, we use the expected age of
information at the central location as a metric. We determine the optimal group
size to minimize the age of information. We show that, when $p$ is small, the
proposed group updating policy yields smaller age compared to a sequential
updating policy.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:48:35 GMT""}]","2020-12-01"
"2011.15115","Isabelle Shankar","Serkan Ho\c{s}ten, Isabelle Shankar, Ang\'elica Torres","The degree of the central curve in semidefinite, linear, and quadratic
  programming","16 pages, updated with revisions including changing Theorem 4.1 to be
  a bound on the degree",,,,"math.OC math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Zariski closure of the central path which interior point algorithms track
in convex optimization problems such as linear, quadratic, and semidefinite
programs is an algebraic curve. The degree of this curve has been studied in
relation to the complexity of these interior point algorithms, and for linear
programs it was computed by De Loera, Sturmfels, and Vinzant in 2012. We show
that the degree of the central curve for generic semidefinite programs is equal
to the maximum likelihood degree of linear concentration models. New results
from the intersection theory of the space of complete quadrics imply that this
is a polynomial in the size of semidefinite matrices with degree equal to the
number of constraints. Besides its degree we explore the arithmetic genus of
the same curve. We also compute the degree of the central curve for generic
linear programs with different techniques which extend to bounding the same
degree for generic quadratic programs.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:49:07 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 18:17:14 GMT""}]","2021-04-19"
"2011.15116","Vikesh Siddhu","Vikesh Siddhu","Leaking information to gain entanglement","14 pages, 3 figures, comments are welcome",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entanglement lies at the root of quantum theory. It is a remarkable resource
that is generally believed to diminish when entangled systems interact with
their environment. On the contrary, we find that engaging a system with its
environment increases its ability to retain entanglement. The maximum rate of
retaining entanglement is given by the quantum channel capacity. We
counter-intuitively boost the quantum capacity of a channel by leaking almost
all quantum information to the channel's environment. This boost exploits
two-letter level non-additivity in the channel's coherent information. The
resulting non-additivity has a far larger magnitude and a qualitatively wider
extent than previously known. Our findings have a surprising implication for
quantum key distribution: maximum rates for key distribution can be boosted by
allowing leakage of information to the eavesdropping environment.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:49:45 GMT""}]","2020-12-01"
"2011.15117","Henrique Vazquez","Henrique V\'azquez, Alina Kononov, Andreas Kyritsakis, Nikita
  Medvedev, Andr\'e Schleife, Flyura Djurabekova","Electron cascades and secondary electron emission in graphene under
  energetic ion irradiation","14 pages, 8 figures","Phys. Rev. B 103, 224306 (2021)","10.1103/PhysRevB.103.224306",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Highly energetic ions traversing a two-dimensional material such as graphene
produce strong electronic excitations. Electrons excited to energy states above
the work function can give rise to secondary electron emission, reducing the
amount of energy that remains the graphene after the ion impact. Electrons can
either be emitted (kinetic energy transfer) or captured by the passing ion
(potential energy transfer). To elucidate this behavior that is absent in
three-dimensional materials, we simulate the electron dynamics in graphene
during the first femtoseconds after ion impact. We employ two conceptually
different computational methods: a Monte Carlo (MC) based one, where electrons
are treated as classical particles, and time-dependent density functional
theory (TDDFT), where electrons are described quantum-mechanically. We observe
that the linear dependence of electron emission on deposited energy, emerging
from MC simulations, becomes sublinear and closer to the TDDFT values when the
electrostatic interactions of emitted electrons with graphene are taken into
account via complementary particle-in-cell simulations. Our TDDFT simulations
show that the probability for electron capture decreases rapidly with
increasing ion velocity, whereas secondary electron emission dominates in the
high velocity regime. We estimate that these processes reduce the amount of
energy deposited in the graphene layer by 15\,\% to 65\,\%, depending on the
ion and its velocity. This finding clearly shows that electron emission must be
taken into consideration when modelling damage production in two-dimensional
materials under ion irradiation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:50:23 GMT""}]","2021-06-23"
"2011.15118","R. Loganayagam","Nachiket Karve and R. Loganayagam","Heisenberg Picture for Open Quantum Systems","20 pages, no figures",,,,"quant-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  In this note, we develop a framework to describe open quantum systems in the
Heisenberg picture, i.e., via time evolving operator algebras. We point out the
incompleteness of the previous proposals in this regard. We argue that a
complete Heisenberg picture for an open quantum system involves multiple image
Heisenberg operators for each system observable. For a given system observable,
the number of such image operators is equal to the dimension of the environment
Hilbert space. We derive a perturbative expression, accurate upto arbitrary
orders in the system environment coupling, for these image operators in terms
of a single one point operator. This expression depends non-linearly on the
state of the environment. This perturbative expression can equivalently be
thought of as deforming the operator product on the Hilbert space of the open
quantum system. In the Markovian limit, the one point operator evolves by an
adjoint Lindblad equation. We illustrate these ideas using a simple spin
system.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:51:08 GMT""}]","2020-12-01"
"2011.15119","Tingwu Wang","Tingwu Wang, Yunrong Guo, Maria Shugrina, Sanja Fidler","UniCon: Universal Neural Controller For Physics-based Character Motion","15 pages, 15 figures",,,,"cs.GR cs.CV cs.LG cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The field of physics-based animation is gaining importance due to the
increasing demand for realism in video games and films, and has recently seen
wide adoption of data-driven techniques, such as deep reinforcement learning
(RL), which learn control from (human) demonstrations. While RL has shown
impressive results at reproducing individual motions and interactive
locomotion, existing methods are limited in their ability to generalize to new
motions and their ability to compose a complex motion sequence interactively.
In this paper, we propose a physics-based universal neural controller (UniCon)
that learns to master thousands of motions with different styles by learning on
large-scale motion datasets. UniCon is a two-level framework that consists of a
high-level motion scheduler and an RL-powered low-level motion executor, which
is our key innovation. By systematically analyzing existing multi-motion RL
frameworks, we introduce a novel objective function and training techniques
which make a significant leap in performance. Once trained, our motion executor
can be combined with different high-level schedulers without the need for
retraining, enabling a variety of real-time interactive applications. We show
that UniCon can support keyboard-driven control, compose motion sequences drawn
from a large pool of locomotion and acrobatics skills and teleport a person
captured on video to a physics-based virtual avatar. Numerical and qualitative
results demonstrate a significant improvement in efficiency, robustness and
generalizability of UniCon over prior state-of-the-art, showcasing
transferability to unseen motions, unseen humanoid models and unseen
perturbation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:51:16 GMT""}]","2020-12-01"
"2011.15120","Fatemeh Rezaee","Fatemeh Rezaee","An interesting wall-crossing: Failure of the wall-crossing/MMP
  correspondence","30 pages, 2 figures. Comments welcome",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the wall-crossing in Bridgeland stability fails to be detected
by the birational geometry of stable sheaves, and vice versa. There is a wall
in the stability space of canonical genus four curves which does not induce a
step in the Minimal Model Program. More precisely, we give an example of a
wall-crossing in $\mathrm{D}^{b}(\mathbb{P}^{3})$ such that: the wall induces a
small contraction of the moduli space of stable objects associated to one of
the adjacent chambers, but a divisorial contraction to the other. This
significantly complicates the overall picture in this correspondence to
applications of stability conditions to algebraic geometry.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:51:41 GMT""}]","2020-12-01"
"2011.15121","Kajal Samanta","Goutam Das, M. C. Kumar and Kajal Samanta","Precision QCD phenomenology of exotic spin-2 search at the LHC","32 pages, 10 figures, 1 table",,"10.1007/JHEP04(2021)111","SI-HEP-2020-32, P3H-20-077","hep-ph","http://creativecommons.org/licenses/by/4.0/","  The complete next-to-next-to leading order (NNLO) QCD correction matched with
next-to-next-to leading logarithm (NNLL) has been studied for Drell-Yan
production through spin-2 particle at the Large hadron collider (LHC). We
consider generic spin-2 particle which couples differently to the quarks and
the gluons (non-universal scenario). The threshold enhanced analytical
coefficient has been obtained up to third order exploiting the universality of
the soft function as well as the process dependent form factors at the same
order. We performed a detailed phenomenological analysis and give prediction
for the 13 TeV LHC for the search of such BSM signature. We found that the
matched correction at the second order gives sizeable corrections over wide
range of invariant mass of the lepton pair. The scale variation also stabilizes
at this order and reduces to 4%. As a by-product we also provide ingredients
for third order soft-virtual (SV) prediction as well as resummation and study
the impact on LHC searches.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:52:36 GMT""}]","2021-04-28"
"2011.15122","Willem van Jaarsveld","Willem van Jaarsveld","Deep controlled learning of dynamic policies with an application to
  lost-sales inventory control",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recent literature established that neural networks can represent good
policies across a range of stochastic dynamic models in supply chain and
logistics. We propose a new algorithm that incorporates variance reduction
techniques, to overcome limitations of algorithms typically employed in
literature to learn such neural network policies. For the classical lost sales
inventory model, the algorithm learns neural network policies that are vastly
superior to those learned using model-free algorithms, while outperforming the
best heuristic benchmarks by an order of magnitude. The algorithm is an
interesting candidate to apply to other stochastic dynamic problems in supply
chain and logistics, because the ideas in its development are generic.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:53:08 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 10:08:31 GMT""},{""version"":""v3"",""created"":""Tue, 9 Nov 2021 14:59:21 GMT""},{""version"":""v4"",""created"":""Fri, 12 Nov 2021 11:47:09 GMT""}]","2021-11-15"
"2011.15123","Benito A. Ju\'arez-Aubry","Yuri Bonder, Benito A. Ju\'arez-Aubry","Black Holes and the 2020 Nobel Prize in Physics","Invited commentary by the Revista Cubana de F\'isica. Title and
  abstract available also in Spanish. 4 pp","Rev. Cubana de F\'isica 37 (2020) 142",,,"physics.pop-ph gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The 2020 Nobel Prize in Physics distinguished two research projects on black
holes, which are one of the most striking predictions of General Relativity.
The prize was divided in two parts. The first half was awarded to Roger Penrose
in recognition of his singularity theorems that guarantee that black holes,
which were mathematically found since an early stage of the study of General
Relativity, are not mere highly-symmetric, curious gravitational
configurations, but robust predictions of the theory. The second half was
awarded to Andrea Ghez and Reinhard Genzel who led two independent groups that
carried out sophisticated observations of the center of our galaxy, which
suggest that therein is a supermassive black hole. In this note, the main ideas
of the theory of general relativity are briefly described, as well as the main
features of black holes. The two works awarded in the aforementioned Nobel
prize are described.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:53:51 GMT""}]","2021-02-15"
"2011.15124","Emanuele Bugliarello","Emanuele Bugliarello, Ryan Cotterell, Naoaki Okazaki, Desmond Elliott","Multimodal Pretraining Unmasked: A Meta-Analysis and a Unified Framework
  of Vision-and-Language BERTs","To appear in TACL 2021",,,,"cs.CL cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale pretraining and task-specific fine-tuning is now the standard
methodology for many tasks in computer vision and natural language processing.
Recently, a multitude of methods have been proposed for pretraining vision and
language BERTs to tackle challenges at the intersection of these two key areas
of AI. These models can be categorised into either single-stream or dual-stream
encoders. We study the differences between these two categories, and show how
they can be unified under a single theoretical framework. We then conduct
controlled experiments to discern the empirical differences between five V&L
BERTs. Our experiments show that training data and hyperparameters are
responsible for most of the differences between the reported results, but they
also reveal that the embedding layer plays a crucial role in these massive
models.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:55:24 GMT""},{""version"":""v2"",""created"":""Sun, 30 May 2021 23:37:58 GMT""}]","2021-06-01"
"2011.15125","Andrey Moskalenko S.","Sangwon Kim, Tobias Schmude, Guido Burkard and Andrey S. Moskalenko","Quasiclassical theory of non-adiabatic tunneling in nanocontacts induced
  by phase-controlled ultrashort light pulses","38 pages, 13 figures",,"10.1088/1367-2630/ac1552",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically investigate tunneling through free-space or dielectric
nanogaps between metallic nanocontacts driven by ultrashort ultrabroadband
light pulses. For this purpose we develop a time-dependent quasiclassical
theory being especially suitable to describe the tunneling process in the
non-adiabatic regime, when this process can be significantly influenced by the
photon absorption as the electron moves in the classically forbidden region.
Firstly, the case of driving by an ideal half-cycle pulse is studied. For
different distances between the contacts, we analyze the main solutions having
the form of a quasiclassical wave packet of the tunneling electron and an
evanescent wave of the electron density. For each of these solutions the
resulting tunneling probability is determined with the exponential accuracy
inherent to the method. We identify a crossover between two tunneling regimes
corresponding to both solutions in dependence on the field strength and
intercontact distance that can be observed in the corresponding behaviour of
the tunneling probability. Secondly, considering realistic temporal profiles of
few-femtosecond pulses, we demonstrate that the preferred direction of the
electron transport through the nanogap can be controlled by changing the
carrier-envelope phase of the pulse, in agreement with recent experimental
findings and numerical simulations. We find analytical expressions for the
tunneling probability, determining the resulting charge transfer in dependence
on the pulse parameters. Further, we determine temporal shifts of the outgoing
electron trajectories with respect to the peaks of the laser field in
dependence on the pulse phase and illustrate when the non-adiabatical character
of the tunneling process is particularly important.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:56:17 GMT""}]","2021-09-01"
"2011.15126","Ting-Chun Wang","Ting-Chun Wang, Arun Mallya, Ming-Yu Liu","One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing","CVPR 2021 camera ready (oral). Our project page can be found at
  https://nvlabs.github.io/face-vid2vid",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a neural talking-head video synthesis model and demonstrate its
application to video conferencing. Our model learns to synthesize a
talking-head video using a source image containing the target person's
appearance and a driving video that dictates the motion in the output. Our
motion is encoded based on a novel keypoint representation, where the
identity-specific and motion-related information is decomposed unsupervisedly.
Extensive experimental validation shows that our model outperforms competing
methods on benchmark datasets. Moreover, our compact keypoint representation
enables a video conferencing system that achieves the same visual quality as
the commercial H.264 standard while only using one-tenth of the bandwidth.
Besides, we show our keypoint representation allows the user to rotate the head
during synthesis, which is useful for simulating face-to-face video
conferencing experiences.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:56:35 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 17:54:33 GMT""},{""version"":""v3"",""created"":""Fri, 2 Apr 2021 23:37:06 GMT""}]","2021-04-06"
"2011.15127","Christian Pedersen","Christian Pedersen, Andreu Font-Ribera, Keir K. Rogers, Patrick
  McDonald, Hiranya V. Peiris, Andrew Pontzen, An\v{z}e Slosar","An emulator for the Lyman-$\alpha$ forest in beyond-$\Lambda$CDM
  cosmologies","26 pages, 11 figures. Minor changes to match version published in
  JCAP","JCAP 05 (2021) 033","10.1088/1475-7516/2021/05/033",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interpreting observations of the Lyman-$\alpha$ forest flux power spectrum
requires interpolation between a small number of expensive simulations. We
present a Gaussian process emulator modelling the 1D flux power spectrum as a
function of the amplitude and slope of the small-scale linear matter power
spectrum, and the state of the intergalactic medium at the epoch of interest
($2 < z < 4$). This parameterisation enables the prediction of the flux power
spectrum in extended cosmological models that are not explicitly included in
the training set, eliminating the need to construct bespoke emulators for a
number of extensions to $\Lambda$CDM. Our emulator is appropriate for
cosmologies in which the linear matter power spectrum is described to percent
level accuracy by just an amplitude and slope across the epoch of interest, and
in the regime probed by eBOSS/DESI data. We demonstrate this for massive
neutrino cosmologies, where the emulator is able to predict the flux power
spectrum in a $\Sigma m_\nu=0.3$ eV neutrino cosmology to sub-percent accuracy,
without including massive neutrinos in the training simulations. Further
parameters would be required to describe models with sharp features in the
linear power, such as warm or light axion dark matter. This work will
facilitate the combination of upcoming DESI data with observations of the
cosmic microwave background, to obtain constraints on neutrino mass and other
extensions to $\Lambda$CDM cosmology.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:56:45 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 17:22:56 GMT""},{""version"":""v3"",""created"":""Fri, 14 May 2021 10:40:11 GMT""}]","2021-05-17"
"2011.15128","Aleksander Holynski","Aleksander Holynski, Brian Curless, Steven M. Seitz, Richard Szeliski","Animating Pictures with Eulerian Motion Fields",,,,,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we demonstrate a fully automatic method for converting a still
image into a realistic animated looping video. We target scenes with continuous
fluid motion, such as flowing water and billowing smoke. Our method relies on
the observation that this type of natural motion can be convincingly reproduced
from a static Eulerian motion description, i.e. a single, temporally constant
flow field that defines the immediate motion of a particle at a given 2D
location. We use an image-to-image translation network to encode motion priors
of natural scenes collected from online videos, so that for a new photo, we can
synthesize a corresponding motion field. The image is then animated using the
generated motion through a deep warping technique: pixels are encoded as deep
features, those features are warped via Eulerian motion, and the resulting
warped feature maps are decoded as images. In order to produce continuous,
seamlessly looping video textures, we propose a novel video looping technique
that flows features both forward and backward in time and then blends the
results. We demonstrate the effectiveness and robustness of our method by
applying it to a large collection of examples including beaches, waterfalls,
and flowing rivers.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:59:06 GMT""}]","2020-12-01"
"2011.15129","Sebastian Eggert","S. Fazzini, P. Chudzinski, C. Dauer, I. Schneider, and S. Eggert","Non-equilibrium Floquet steady states of time-periodic driven Luttinger
  liquids","10 pages, 4 figures. Published version with all Suppl. Materials as
  Appendix. For more information and latest version see
  https://www.physik.uni-kl.de/eggert/papers/index.html","Phys. Rev. Lett. 126, 243401 (2021)","10.1103/PhysRevLett.126.243401",,"cond-mat.quant-gas cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time-periodic driving facilitates a wealth of novel quantum states and
quantum engineering. The interplay of Floquet states and strong interactions is
particularly intriguing, which we study using time-periodic fields in a
one-dimensional quantum gas, modeled by a Luttinger liquid with periodically
changing interactions. By developing a time-periodic operator algebra, we are
able to solve and analyze the complete set of non-equilibrium steady states in
terms of a Floquet-Bogoliubov ansatz and known analytic functions. Complex
valued Floquet eigenenergies occur when multiples of driving frequency
approximately match twice the dispersion energy, which correspond to resonant
states. In experimental systems of Lieb-Liniger bosons we predict a change from
powerlaw correlations to dominant collective density wave excitations at the
corresponding wave numbers as the frequency is lowered below a characteristic
cut-off.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:59:59 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 15:32:59 GMT""}]","2021-07-27"
"2011.15130","Falk Hassler","Falk Hassler and Thomas B. Rochais","O($D$,$D$)-covariant two-loop $\beta$-functions and Poisson-Lie
  T-duality","44 pages, 2 tables",,"10.1007/JHEP10(2021)210",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We show that the one- and two-loop $\beta$-functions of the closed, bosonic
string can be written in a manifestly O($D$,$D$)-covariant form. Based on this
result, we prove that 1) Poisson-Lie symmetric $\sigma$-models are two-loop
renormalisable and 2) their $\beta$-functions are invariant under Poisson-Lie
T-duality. Moreover, we identify a distinguished scheme in which Poisson-Lie
symmetry is manifest. It simplifies the calculation of two-loop
$\beta$-functions significantly and thereby provides a powerful new tool to
advance into the quantum regime of integrable $\sigma$-models and generalised
T-dualities. As an illustrating example, we present the two-loop
$\beta$-functions of the integrable $\lambda$- and $\eta$-deformation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:59:59 GMT""}]","2021-11-10"
"2012.00001","Lingjing Jiang","Lingjing Jiang, Niina Haiminen, Anna-Paola Carrieri, Shi Huang,
  Yoshiki Vazquez-Baeza, Laxmi Parida, Ho-Cheol Kim, Austin D. Swafford, Rob
  Knight, Loki Natarajan","Utilizing stability criteria in choosing feature selection methods
  yields reproducible results in microbiome data",,,,"https://doi.org/10.1111/biom.13481","q-bio.QM cs.LG","http://creativecommons.org/licenses/by/4.0/","  Feature selection is indispensable in microbiome data analysis, but it can be
particularly challenging as microbiome data sets are high-dimensional,
underdetermined, sparse and compositional. Great efforts have recently been
made on developing new methods for feature selection that handle the above data
characteristics, but almost all methods were evaluated based on performance of
model predictions. However, little attention has been paid to address a
fundamental question: how appropriate are those evaluation criteria? Most
feature selection methods often control the model fit, but the ability to
identify meaningful subsets of features cannot be evaluated simply based on the
prediction accuracy. If tiny changes to the training data would lead to large
changes in the chosen feature subset, then many of the biological features that
an algorithm has found are likely to be a data artifact rather than real
biological signal. This crucial need of identifying relevant and reproducible
features motivated the reproducibility evaluation criterion such as Stability,
which quantifies how robust a method is to perturbations in the data. In our
paper, we compare the performance of popular model prediction metric MSE and
proposed reproducibility criterion Stability in evaluating four widely used
feature selection methods in both simulations and experimental microbiome
applications. We conclude that Stability is a preferred feature selection
criterion over MSE because it better quantifies the reproducibility of the
feature selection method.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:23:26 GMT""}]","2021-08-04"
"2012.00006","Manila Songvilay","M. Songvilay, J. Robert, S. Petit, J. A. Rodriguez-Rivera, W. D.
  Ratcliff, F. Damay, V. Bal\'edent, M. Jim\'enez-Ruiz, P. Lejay, E. Pachoud,
  A. Hadj-Azzem, V. Simonet and C. Stock","Kitaev interactions in the Co honeycomb antiferromagnets
  Na$_3$Co$_2$SbO$_6$ and Na$_2$Co$_2$TeO$_6$",,"Phys. Rev. B 102, 224429 (2020)","10.1103/PhysRevB.102.224429",,"cond-mat.str-el","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Co$^{2+}$ ions in an octahedral crystal field, stabilise a j$_{eff}$ = 1/2
ground state with an orbital degree of freedom and have been recently put
forward for realising Kitaev interactions, a prediction we have tested by
investigating spin dynamics in two cobalt honeycomb lattice compounds,
Na$_2$Co$_2$TeO$_6$ and Na$_3$Co$_2$SbO$_6$, using inelastic neutron
scattering. We used linear spin wave theory to show that the magnetic spectra
can be reproduced with a spin Hamiltonian including a dominant Kitaev
nearest-neighbour interaction, weaker Heisenberg interactions up to the third
neighbour and bond-dependent off-diagonal exchange interactions. Beyond the
Kitaev interaction that alone would induce a quantum spin liquid state, the
presence of these additional couplings is responsible for the zigzag-type
long-range magnetic ordering observed at low temperature in both compounds.
These results provide evidence for the realization of Kitaev-type coupling in
cobalt-based materials, despite hosting a weaker spin-orbit coupling than their
4d and 5d counterparts.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:26:44 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 10:27:27 GMT""},{""version"":""v3"",""created"":""Wed, 6 Jan 2021 10:41:36 GMT""}]","2021-01-07"
"2012.00007","Abdellatif Ben Makhlouf","Abdellatif Ben Makhlouf","A Novel Finite Time Stability Analysis of Nonlinear Fractional-Order
  Time Delay Systems: A Fixed Point Approach",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, a novel Finite Time Stability (FTS) analysis of
Fractional-Order Time Delay Systems (FOTDSs) is proposed. By using the fixed
point approach, sufficient conditions for the robust FTS of FOTDSs have been
established. Two illustrative examples are provided to prove the validity of
the main result.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 17:15:19 GMT""}]","2020-12-02"
"2012.00008","Dmitriy Blinov","D. Blinov, S. Kiehlmann, V. Pavlidou, G. V. Panopoulou, R. Skalidis,
  E. Angelakis, C. Casadio, E. N. Einoder, T. Hovatta, K. Kokolakis, A.
  Kougentakis, A. Kus, N. Kylafis, E. Kyritsis, A. Lalakos, I. Liodakis, S.
  Maharana, E. Makrydopoulou, N. Mandarakas, G. M. Maragkakis, I. Myserlis, I.
  Papadakis, G. Paterakis, T. J. Pearson, A. N. Ramaprakash, A. C. S. Readhead,
  P. Reig, A. S{\l}owikowska, K. Tassis, K. Xexakis, M. \.Zejmo, J. A. Zensus","RoboPol: AGN polarimetric monitoring data","Accepted to MNRAS",,"10.1093/mnras/staa3777",,"astro-ph.HE astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We present uniformly reprocessed and re-calibrated data from the RoboPol
programme of optopolarimetric monitoring of active galactic nuclei (AGN),
covering observations between 2013, when the instrument was commissioned, and
2017. In total, the dataset presented in this paper includes 5068 observations
of 222 AGN with Dec > -25 deg. We describe the current version of the RoboPol
pipeline that was used to process and calibrate the entire dataset, and we make
the data publicly available for use by the astronomical community. Average
quantities summarising optopolarimetric behaviour (average degree of
polarization, polarization variability index) are also provided for each source
we have observed and for the time interval we have followed it.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:00 GMT""}]","2020-12-23"
"2012.00009","Miguel Montero","Ben Heidenreich, Jacob McNamara, Miguel Montero, Matthew Reece, Tom
  Rudelius and Irene Valenzuela","Chern-Weil Global Symmetries and How Quantum Gravity Avoids Them","62 pages + appendices, 5 figures. v2: References added",,"10.1007/JHEP11(2021)053","ACFI-T20-16","hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We draw attention to a class of generalized global symmetries, which we call
""Chern-Weil global symmetries,"" that arise ubiquitously in gauge theories. The
Noether currents of these Chern-Weil global symmetries are given by wedge
products of gauge field strengths, such as $F_2 \wedge H_3$ and
$\text{tr}(F_2^2)$, and their conservation follows from Bianchi identities. As
a result, they are not easy to break. However, it is widely believed that exact
global symmetries are not allowed in a consistent theory of quantum gravity. As
a result, any Chern-Weil global symmetry in a low-energy effective field theory
must be either broken or gauged when the theory is coupled to gravity. In this
paper, we explore the processes by which Chern-Weil symmetries may be broken or
gauged in effective field theory and string theory. We will see that many
familiar phenomena in string theory, such as axions, Chern-Simons terms,
worldvolume degrees of freedom, and branes ending on or dissolving in other
branes, can be interpreted as consequences of the absence of Chern-Weil
symmetries in quantum gravity, suggesting that they might be general features
of quantum gravity. We further discuss implications of breaking and gauging
Chern-Weil symmetries for particle phenomenology and for boundary CFTs of AdS
bulk theories. Chern-Weil global symmetries thus offer a unified framework for
understanding many familiar aspects of quantum field theory and quantum
gravity.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 21:58:43 GMT""}]","2021-11-24"
"2012.00010","Arthur Hebecker","Arthur Hebecker, Sascha Leonhardt","Winding Uplifts and the Challenges of Weak and Strong SUSY Breaking in
  AdS","32 pages, 2 figures, v2: References and more detailed explanations
  added","JHEP 03 (2021) 284","10.1007/JHEP03(2021)284",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the problem of metastable SUSY breaking in the landscape. While
this is clearly crucial for the various de Sitter proposals, it is also
interesting to consider the SUSY breaking challenge in the AdS context. For
example, it could be that a stronger form of the non-SUSY AdS conjecture holds:
It would forbid even metastable non-SUSY AdS in cases where the SUSY-breaking
scale is parametrically above/below the AdS scale. At the technical level, the
present paper proposes to break SUSY using the multi-cosine-shaped axion
potentials which arise if a long winding trajectory of a `complex-structure
axion' appears in the large-complex-structure limit of a Calabi-Yau
orientifold. This has been studied in the context of `Winding Inflation', but
the potential for SUSY breaking has not been fully explored. We discuss the
application to uplifting LVS vacua, point out the challenges which one faces in
the KKLT context, and consider the possibility of violating the non-SUSY AdS
conjecture in the type-IIA setting of DGKT.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 17:06:26 GMT""}]","2021-04-13"
"2012.00011","Hiromichi Tagawa","Hiromichi Tagawa, Bence Kocsis, Zoltan Haiman, Imre Bartos, Kazuyuki
  Omukai, Johan Samsing","Mass-gap Mergers in Active Galactic Nuclei","12 pages, 4 figures, accepted in ApJ",,"10.3847/1538-4357/abd555",,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The recently discovered gravitational wave sources GW190521 and GW190814 have
shown evidence of BH mergers with masses and spins that could be outside of the
range expected from isolated stellar evolution. These merging objects could
have undergone previous mergers. Such hierarchical mergers are predicted to be
frequent in active galactic nuclei (AGN) disks, where binaries form and evolve
efficiently by dynamical interactions and gaseous dissipation. Here we compare
the properties of these observed events to the theoretical models of mergers in
AGN disks, which are obtained by performing one-dimensional $N$-body
simulations combined with semi-analytical prescriptions. The high BH masses in
GW190521 are consistent with mergers of high-generation (high-g) BHs where the
initial progenitor stars had high metallicity, 2g BHs if the original
progenitors were metal-poor, or 1g BHs that had gained mass via super-Eddington
accretion. Other measured properties related to spin parameters in GW190521 are
also consistent with mergers in AGN disks. Furthermore, mergers in the lower
mass gap or those with low mass ratio as found in GW190814 and GW190412 are
also reproduced by mergers of 2g-1g or 1g-1g objects with significant accretion
in AGN disks. Finally, due to gas accretion, the massive neutron star merger
reported in GW190425 can be produced in an AGN disk.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:00 GMT""},{""version"":""v2"",""created"":""Sun, 20 Dec 2020 07:58:13 GMT""}]","2021-03-03"
"2012.00012","Liye Fu","Liye Fu, Susan R. Fussell and Cristian Danescu-Niculescu-Mizil","Facilitating the Communication of Politeness through Fine-Grained
  Paraphrasing","Proceedings of EMNLP 2020, 14 pages. Data and code at
  https://convokit.cornell.edu/ and
  https://github.com/CornellNLP/politeness-paraphrase",,,,"cs.CL cs.AI cs.CY cs.HC","http://creativecommons.org/licenses/by/4.0/","  Aided by technology, people are increasingly able to communicate across
geographical, cultural, and language barriers. This ability also results in new
challenges, as interlocutors need to adapt their communication approaches to
increasingly diverse circumstances. In this work, we take the first steps
towards automatically assisting people in adjusting their language to a
specific communication circumstance.
  As a case study, we focus on facilitating the accurate transmission of
pragmatic intentions and introduce a methodology for suggesting paraphrases
that achieve the intended level of politeness under a given communication
circumstance. We demonstrate the feasibility of this approach by evaluating our
method in two realistic communication scenarios and show that it can reduce the
potential for misalignment between the speaker's intentions and the listener's
perceptions in both cases.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:00 GMT""}]","2020-12-02"
"2012.00013","Markus Dierigl","Markus Dierigl and Jonathan J. Heckman","On the Swampland Cobordism Conjecture and Non-Abelian Duality Groups","25 pages, 3 figures; clarifications added","Phys. Rev. D 103, 066006 (2021)","10.1103/PhysRevD.103.066006",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the cobordism conjecture of McNamara and Vafa which asserts that the
bordism group of quantum gravity is trivial. In the context of type IIB string
theory compactified on a circle, this predicts the presence of D7-branes. On
the other hand, the non-Abelian structure of the IIB duality group
$SL(2,\mathbb{Z})$ implies the existence of additional $[p,q]$ 7-branes. We
find that this additional information is instead captured by the space of
closed paths on the moduli space of elliptic curves parameterizing distinct
values of the type IIB axio-dilaton. This description allows to recover the
full structure of non-Abelian braid statistics for 7-branes. Combining the
cobordism conjecture with an earlier Swampland conjecture by Ooguri and Vafa,
we argue that only certain congruence subgroups $\Gamma \subset
SL(2,\mathbb{Z})$ specifying genus zero modular curves can appear in 8D
F-theory vacua. This leads to a successful prediction for the allowed
Mordell-Weil torsion groups for 8D F-theory vacua.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 11:39:01 GMT""}]","2021-03-10"
"2012.00014","Hamsa Padmanabhan","Hamsa Padmanabhan (Geneva), Abraham Loeb (Harvard)","Distinguishing AGN from starbursts as the origin of double peaked
  Lyman-Alpha Emitters in the reionization era","4 pages, 1 figure; accepted for publication in A&A Letters","A&A 646, L10 (2021)","10.1051/0004-6361/202040107",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the possible origin of the double-peaked profiles recently
observed in Lyman-Alpha Emitters (LAEs) at the epoch of reionization ($z
\gtrsim 6.5$) from obscured active galactic nuclei (AGN). Combining the extent
of the Lyman-$\alpha$ near-zones estimated from the blue peak velocity offset
in these galaxies, with the ionizing emissivity of quasars at $z \gtrsim 6$, we
forecast the intrinsic UV and X-ray luminosities of the AGN needed to give rise
to their double-peaked profiles. We also estimate the extent of the obscuration
of the AGN by comparing their luminosities to those of similar quasar samples
at these epochs. Future X-ray and radio observations, as well as those with the
${James \ Webb \ Space \ Telescope}$, will be valuable tools to test the AGN
contribution to the intergalactic-scale ionization zones of high-redshift LAEs.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 14:57:38 GMT""}]","2021-02-17"
"2012.00015","Adrian M. Price-Whelan","Adrian M. Price-Whelan, David W. Hogg, Kathryn V. Johnston, Melissa K.
  Ness, Hans-Walter Rix, Rachael L. Beaton, Joel R. Brownstein, Domingo
  An\'ibal Garc\'ia-Hern\'andez, Sten Hasselquist, Christian R. Hayes, Richard
  R. Lane, Gail Zasowski","Orbital Torus Imaging: Using Element Abundances to Map Orbits and Mass
  in the Milky Way","34 pages, 8 figures. Published in ApJ","The Astrophysical Journal, Volume 910, Issue 1, id.17, 16 pp.,
  2021","10.3847/1538-4357/abe1b7",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many approaches to galaxy dynamics assume that the gravitational potential is
simple and the distribution function is time-invariant. Under these assumptions
there are traditional tools for inferring potential parameters given
observations of stellar kinematics (e.g., Jeans models). However, spectroscopic
surveys measure many stellar properties beyond kinematics. Here we present a
new approach for dynamical inference, Orbital Torus Imaging, which makes use of
kinematic measurements and element abundances (or other invariant labels). We
exploit the fact that, in steady state, stellar labels vary systematically with
orbit characteristics (actions), yet must be invariant with respect to orbital
phases (conjugate angles). The orbital foliation of phase space must therefore
coincide with surfaces along which all moments of all stellar label
distributions are constant. Both classical-statistics and Bayesian methods can
be built on this; these methods will be more robust and require fewer
assumptions than traditional tools because they require no knowledge of the
(spatial) survey selection function and they do not involve second moments of
velocity distributions. We perform a classical-statistics demonstration with
red giant branch stars from the APOGEE surveys: We model the vertical orbit
structure in the Milky Way disk to constrain the local disk mass, scale height,
and the disk--halo mass ratio (at fixed local circular velocity). We find that
the disk mass can be constrained (na\""ively) at the few-percent level with
Orbital Torus Imaging using only eight element-abundance ratios, demonstrating
the promise of combining stellar labels with dynamical invariants.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 20:00:03 GMT""}]","2021-03-31"
"2012.00016","Joan Najita","Joan R. Najita (NSF's NOIRLab), John S. Carr (U. Maryland), Sean D.
  Brittain (Clemson University), John H. Lacy (U. Texas at Austin), Matthew J.
  Richter (UC Davis), and Greg W. Doppmann (Keck Observatory)","High-Resolution Mid-Infrared Spectroscopy of GV Tau N: Surface Accretion
  and Detection of Ammonia in a Young Protoplanetary Disk","55 pages, 18 figures, accepted for publication in the Astrophysical
  Journal",,"10.3847/1538-4357/abcfc6",,"astro-ph.SR astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Physical processes that redistribute or remove angular momentum from
protoplanetary disks can drive mass accretion onto the star and affect the
outcome of planet formation. Despite ubiquitous evidence that protoplanetary
disks are engaged in accretion, the process(es) responsible remain unclear.
Here we present evidence for redshifted molecular absorption in the spectrum of
a Class I source that indicates rapid inflow at the disk surface. High
resolution mid-infrared spectroscopy of GV Tau N reveals a rich absorption
spectrum of individual lines of C2H2, HCN, NH3, and water. From the properties
of the molecular absorption, we can infer that it carries a significant
accretion rate (~ 1e-8 to 1e-7 Msun/yr), comparable to the stellar accretion
rates of active T Tauri stars. Thus we may be observing disk accretion in
action. The results may provide observational evidence for supersonic ""surface
accretion flows,"" which have been found in MHD simulations of magnetized disks.
The observed spectra also represent the first detection of ammonia in the
planet formation region of a protoplanetary disk. With ammonia only comparable
in abundance to HCN, it cannot be a major missing reservoir of nitrogen. If, as
expected, the dominant nitrogen reservoir in inner disks is instead N2, its
high volatility would make it difficult to incorporate into forming planets,
which may help to explain the low nitrogen content of the bulk Earth.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:01 GMT""}]","2021-03-03"
"2012.00017","Rick Gupta","R.S. Gupta, V.V. Khoze and M. Spannowsky","Small instantons and the strong CP problem in composite Higgs models","8 pages, 3 figures","Phys. Rev. D 104, 075011 (2021)","10.1103/PhysRevD.104.075011",,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that QCD instantons can generate large effects at small length scales
in the ultraviolet in standard composite Higgs models that utilise partial
compositeness. This has important implications for possible solutions of the
strong CP problem in these models. First we show that in the simplest known UV
completions of composite Higgs models, if an axion is also present, it can have
a mass much larger than the usual QCD axion. Even more remarkable is the case
where there are no axions, but the strong CP problem can be solved by
generating the up quark mass entirely from the contribution of instantons thus
reviving the massless up-quark solution for these models. In both cases no
additional field content is required apart from what is required to realise
partial compositeness.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:01 GMT""}]","2021-10-13"
"2012.00018","Philine Van Vliet","Aleix Gimenez-Grau, Pedro Liendo and Philine van Vliet","Superconformal Boundaries in $4-\epsilon$ dimensions","45 pages, no figures",,"10.1007/JHEP04(2021)167","DESY 20-215","hep-th","http://creativecommons.org/licenses/by/4.0/","  Boundaries in three-dimensional $\mathcal{N}=2$ superconformal theories may
preserve one half of the original bulk supersymmetry. There are two
possibilities which are characterized by the chirality of the leftover
supercharges. Depending on the choice, the remaining $2d$ boundary algebra
exhibits $\mathcal{N}=(0,2)$ or $\mathcal{N}=(1,1)$ supersymmetry. In this work
we focus on correlation functions of chiral fields for both types of
supersymmetric boundaries. We study a host of correlators using superspace
techniques and calculate superconformal blocks for two- and three-point
functions. For $\mathcal{N}=(1,1)$ supersymmetry, some of our results can be
analytically continued in the spacetime dimension while keeping the codimension
fixed. This opens the door for a bootstrap analysis of the $\epsilon$-expansion
in supersymmetric BCFTs. Armed with our analytically-continued superblocks, we
prove that in the free theory limit two-point functions of chiral (and
antichiral) fields are unique. The first order correction, which already
describes interactions, is universal up to two free parameters. As a check of
our analysis, we study the Wess-Zumino model with a supersymmetric boundary
using Feynman diagrams, and find perfect agreement between the perturbative and
bootstrap results.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 09:27:09 GMT""}]","2021-05-05"
"2012.00019","Jaeyeon Kim","Jaeyeon Kim, M\'elanie Chevance, J. M. Diederik Kruijssen, Andreas
  Schruba, Karin Sandstrom, Ashley T. Barnes, Frank Bigiel, Guillermo A. Blanc,
  Yixian Cao, Daniel A. Dale, Christopher M. Faesi, Simon C. O. Glover, Kathryn
  Grasha, Brent Groves, Cinthya Herrera, Ralf S. Klessen, Kathryn Kreckel,
  Janice C. Lee, Adam K. Leroy, J\'er\^ome Pety, Miguel Querejeta, Eva
  Schinnerer, Jiayi Sun, Antonio Usero, Jacob L. Ward, Thomas G. Williams","On the duration of the embedded phase of star formation","23 pages, 9 figures, 4 tables; accepted for publication in MNRAS
  (March 19, 2021)",,"10.1093/mnras/stab878",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feedback from massive stars plays a key role in molecular cloud evolution.
After the onset of star formation, the young stellar population is exposed by
photoionization, winds, supernovae, and radiation pressure from massive stars.
Recent observations of nearby galaxies have provided the evolutionary timeline
between molecular clouds and exposed young stars, but the duration of the
embedded phase of massive star formation is still ill-constrained. We measure
how long massive stellar populations remain embedded within their natal cloud,
by applying a statistical method to six nearby galaxies at 20-100 pc
resolution, using CO, Spitzer 24$\rm\,\mu m$, and H$\alpha$ emission as tracers
of molecular clouds, embedded star formation, and exposed star formation,
respectively. We find that the embedded phase (with CO and 24$\rm\,\mu m$
emission) lasts for $2{-}7$ Myr and constitutes $17{-}47\%$ of the cloud
lifetime. During approximately the first half of this phase, the region is
invisible in H$\alpha$, making it heavily obscured. For the second half of this
phase, the region also emits in H$\alpha$ and is partially exposed. Once the
cloud has been dispersed by feedback, 24$\rm\,\mu m$ emission no longer traces
ongoing star formation, but remains detectable for another $2{-}9$ Myr through
the emission from ambient CO-dark gas, tracing star formation that recently
ended. The short duration of massive star formation suggests that pre-supernova
feedback (photoionization and winds) is important in disrupting molecular
clouds. The measured timescales do not show significant correlations with
environmental properties (e.g. metallicity). Future JWST observations will
enable these measurements routinely across the nearby galaxy population.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 16:14:46 GMT""}]","2021-04-07"
"2012.00020","Niklas Mueller","Jo\~ao Barata, Niklas Mueller, Andrey Tarasov, Raju Venugopalan","Single-particle digitization strategy for quantum computation of a
  $\phi^4$ scalar field theory","31 pages, 13 figures; journal version published in Phys. Rev. A 103,
  042410 (2021); Table I modified to to include more precise estimate for cost
  of initial state preparation; Appendix B (discussion of state preparation)
  significantly extended & figures 10 and 11 added","Phys. Rev. A 103, 042410 (2021)","10.1103/PhysRevA.103.042410",,"hep-th hep-ph nucl-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the parton picture of high energy quantum chromodynamics, we
develop a single-particle digitization strategy for the efficient quantum
simulation of relativistic scattering processes in a $d+1$ dimensional scalar
$\phi^4$ field theory. We work out quantum algorithms for initial state
preparation, time evolution and final state measurements. We outline a
non-perturbative renormalization strategy in this single-particle framework.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:02 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 23:56:33 GMT""},{""version"":""v3"",""created"":""Wed, 14 Apr 2021 14:54:27 GMT""}]","2021-04-15"
"2012.00021","S Sameer","Sameer, J. C. Charlton, J. M. Norris, M. Gebhardt, C. W. Churchill, G.
  G. Kacprzak, S. Muzahid, Anand Narayanan, N. M. Nielsen, Philipp Richter, and
  Bart P. Wakker","Cloud-by-cloud, multiphase, Bayesian modeling: Application to four weak,
  low ionization absorbers","Accepted for Publication in MNRAS",,"10.1093/mnras/staa3754",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new method aimed at improving the efficiency of component by
component ionization modeling of intervening quasar absorption line systems. We
carry out cloud-by-cloud, multiphase modeling making use of CLOUDY and Bayesian
methods to extract physical properties from an ensemble of absorption profiles.
Here, as a demonstration of method, we focus on four weak, low ionization
absorbers at low redshift, because they are multi-phase but relatively simple
to constrain. We place errors on the inferred metallicities and ionization
parameters for individual clouds, and show that the values differ from
component to component across the absorption profile. Our method requires user
input on the number of phases and relies on an optimized transition for each
phase, one observed with high resolution and signal-to-noise. The measured
Doppler parameter of the optimized transition provides a constraint on the
Doppler parameter of HI, thus providing leverage in metallicity measurements
even when hydrogen lines are saturated. We present several tests of our
methodology, demonstrating that we can recover the input parameters from
simulated profiles. We also consider how our model results are affected by
which radiative transitions are covered by observations (for example how many
HI transitions) and by uncertainties in the b parameters of optimized
transitions. We discuss the successes and limitations of the method, and
consider its potential for large statistical studies. This improved methodology
will help to establish direct connections between the diverse properties
derived from characterizing the absorbers and the multiple physical processes
at play in the circumgalactic medium.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:02 GMT""}]","2020-12-23"
"2012.00022","Erez Michaely","Erez Michaely and Michael Shara","White dwarf - main sequence star collisions from wide triples in the
  field","Comments are welcomed",,"10.1093/mnras/stab339",,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Multiple star systems interact strongly with Galactic field stars when the
outer semi-major axis of a triple or multiple star is > 10 3 AU. Stable triples
composed of two white-dwarfs (WD) and a low mass main sequence (MS) star in a
wide outer orbit can thus be destabilized by gravitational interactions with
random field stars. Such interactions excite the eccentricity of the distant
third star sufficiently so that it begins to interact significantly with the
inner binary. When this occurs the triple undergoes multiple binary-single
resonant encounters. These encounters may result either in a collision between
the nondegenerate component and a WD, or the breakup of the triple into a
compact binary and a third object which is ejected. The compact binary can be
either a MS-WD pair which survives, or collides, or a double WD which may
inspiral through gravitational wave emission. We calculate the collision rate
between a MS and WD star, and the merger rate of double WDs. Additionally, we
describe the prospects of detectability of such a collision, which may resemble
a sub-luminous SN event.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:04 GMT""}]","2021-02-17"
"2012.00023","Luca Grassitelli Dr.","Luca Grassitelli, Norbert Langer, Jonathan Mackey, Goetz Graefener,
  Nathan Grin, Andreas Sander, Jorick Vink","Wind-envelope interaction as the origin of the slow cyclic brightness
  variations of luminous blue variables","A&A Accepted, 14 pages, many colorful figures","A&A 647, A99 (2021)","10.1051/0004-6361/202038298","AA/2020/38298","astro-ph.SR astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Luminous blue variables (LBVs) are hot, very luminous massive stars
displaying large quasi-periodic variations in brightness, radius,and
photospheric temperature, on timescales of years to decades. The physical
origin of this variability, called S Doradus cycle after its prototype, has
remained elusive. Here, we study the feedback of stellar wind mass-loss on the
envelope structure in stars near the Eddington limit. We perform a
time-dependent hydrodynamic stellar evolutionary calculation, applying a
stellar wind mass-loss prescription with a temperature-dependence inspired by
the predicted systematic increase in mass-loss rates below 25 kK. We find that
when the wind mass-loss rate crosses a well-defined threshold, a discontinuous
change in the wind base conditions leads to a restructuring of the stellar
envelope. The induced drastic radius and temperature changes, which occur on
the thermal timescale of the inflated envelope, impose in turn mass-loss
variations that reverse the initial changes, leading to a cycle that lacks a
stationary equilibrium configuration. Our proof-of-concept model broadly
reproduces the typical observational phenomenology of the S Doradus
variability. We identify three key physical ingredients needed to trigger the
instability: inflated envelopes in close proximity to the Eddington limit, a
temperature range where decreasing opacities do not lead to an accelerating
outflow, and a mass-loss rate that increases with decreasing temperature,
crossing a critical threshold value within this temperature range. Our scenario
and model provide testable predictions, and open the door for a consistent
theoretical treatment of the LBV phase in stellar evolution, with consequences
for their further evolution as single stars or in binary systems.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:05 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 18:16:52 GMT""}]","2021-03-17"
"2012.00024","Caterina Chiocchetta","Caterina Chiocchetta, Alessandro Gruppuso, Massimiliano Lattanzi,
  Paolo Natoli and Luca Pagano","Lack-of-correlation anomaly in CMB large scale polarisation maps","19 pages, 15 figures",,"10.1088/1475-7516/2021/08/015",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an assessment of the CMB large scale anomalies in polarisation
using the two-point correlation function as a test case. We employ the state of
the art of large scale polarisation datasets: the first based on a Planck 2018
HFI 100 and 143 GHz cross-spectrum analysis, based on SRoll2 processing, and
the second from a map-based approach derived through a joint treatment of
Planck 2018 LFI and WMAP-9yr. We consider the well-known $S_{1/2}$ estimator,
which measures the distance of the two-point correlation function from zero at
angular scales larger than $60^{\circ}$, and rely on realistic simulations for
both datasets to assess confidence intervals. By focusing on the pure
polarisation field described by either the $Q$ and $U$ Stokes parameters or by
the local $E-$modes, we show that the first description is heavily influenced
by the quadrupole (which is poorly constrained in both datasets) while the
second one is more suited for an analysis containing higher multipoles up to
$\ell \sim 10$, limit above which both datasets become markedly noise
dominated. We find that both datasets exhibit a lack-of-correlation anomaly in
pure polarisation, similar to the one observed in temperature, which is better
constrained by the less noisy Planck HFI 100$\times$143 data, where its
significance lies at about $99.5\%$. We perform our analysis using realizations
that are either constrained or non-constrained by the observed temperature
field, and find similar results in the two cases.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:05 GMT""}]","2021-08-25"
"2012.00025","Stephanie O'Neil","Stephanie O'Neil (1), David J. Barnes (1), Mark Vogelsberger (1),
  Benedikt Diemer (2) ((1) MIT, (2) UMD)","The splashback boundary of haloes in hydrodynamic simulations","18 pages, 15 figures, accepted by MNRAS",,"10.1093/mnras/stab1221",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The splashback radius, $R_{\rm sp}$, is a physically motivated halo boundary
that separates infalling and collapsed matter of haloes. We study $R_{\rm sp}$
in the hydrodynamic and dark matter only IllustrisTNG simulations. The most
commonly adopted signature of $R_{\rm sp}$ is the radius at which the radial
density profiles are steepest. Therefore, we explicitly optimise our density
profile fit to the profile slope and find that this leads to a $\sim5\%$ larger
radius compared to other optimisations. We calculate $R_{\rm sp}$ for haloes
with masses between $10^{13-15}{\rm M}_{\odot}$ as a function of halo mass,
accretion rate and redshift. $R_{\rm sp}$ decreases with mass and with redshift
for haloes of similar $M_{\rm200m}$ in agreement with previous work. We also
find that $R_{\rm sp}/R_{\rm200m}$ decreases with halo accretion rate. We apply
our analysis to dark matter, gas and satellite galaxies associated with haloes
to investigate the observational potential of $R_{\rm sp}$. The radius of
steepest slope in gas profiles is consistently smaller than the value
calculated from dark matter profiles. The steepest slope in galaxy profiles,
which are often used in observations, tends to agree with dark matter profiles
but is lower for less massive haloes. We compare $R_{\rm sp}$ in hydrodynamic
and N-body dark matter only simulations and do not find a significant
difference caused by the addition of baryonic physics. Thus, results from dark
matter only simulations should be applicable to realistic haloes.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:05 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 00:14:04 GMT""}]","2021-05-27"
"2012.00026","Brendan O'Connor","B. O'Connor, E. Troja, S. Dichiara, E. A. Chase, G. Ryan, S. B. Cenko,
  C. L. Fryer, R. Ricci, F. Marshall, C. Kouveliotou, R. T. Wollaeger, C. J.
  Fontes, O. Korobkin, P. Gatkine, A. Kutyrev, S. Veilleux, N. Kawai, and T.
  Sakamoto","A tale of two mergers: constraints on kilonova detection in two short
  GRBs at z$\sim$0.5","MNRAS, In Press",,"10.1093/mnras/stab132",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a detailed multi-wavelength analysis of two short Gamma-Ray Bursts
(sGRBs) detected by the Neil Gehrels Swift Observatory: GRB 160624A at
$z=0.483$ and GRB 200522A at $z=0.554$. These sGRBs demonstrate very different
properties in their observed emission and environment. GRB 160624A is
associated to a late-type galaxy with an old stellar population ($\approx$3
Gyr) and moderate on-going star formation ($\approx$1 $M_{\odot}$ yr$^{-1}$).
Hubble and Gemini limits on optical/nIR emission from GRB 160624A are among the
most stringent for sGRBs, leading to tight constraints on the allowed kilonova
properties. In particular, we rule out any kilonova brighter than AT2017gfo,
disfavoring large masses of wind ejecta ($\lesssim$0.03 $M_\odot$). In
contrast, observations of GRB 200522A uncovered a luminous
($L_\textrm{F125W}\approx 10^{42}$ erg s$^{-1}$ at 2.3~d) and red ($r-H\approx
1.3$ mag) counterpart. The red color can be explained either by bright kilonova
emission powered by the radioactive decay of a large amount of wind ejecta
(0.03 $M_\odot$ $\lesssim$ $M$ $\lesssim$ 0.1 $M_\odot$) or moderate
extinction, $E(B-V)\approx0.1-0.2$ mag, along the line of sight. The location
of this sGRB in the inner regions of a young ($\approx$0.1 Gyr) star-forming
($\approx$2-6 $M_{\odot}$ yr$^{-1}$) galaxy and the limited sampling of its
counterpart do not allow us to rule out dust effects as contributing, at least
in part, to the red color.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:06 GMT""},{""version"":""v2"",""created"":""Thu, 14 Jan 2021 01:28:33 GMT""}]","2021-01-27"
"2012.00027","Rossella Gamba","Rossella Gamba, Sebastiano Bernuzzi, Alessandro Nagar","Fast, faithful, frequency-domain effective-one-body waveforms for
  compact binary coalescences",,,"10.1103/PhysRevD.104.084058",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The inference of binary neutron star properties from gravitational-wave
observations requires the generation of millions of waveforms, each one
spanning about three order of magnitudes in frequency range. Thus, waveform
models must be efficiently generated and, at the same time, be faithful from
the post-Newtonian quasi-adiabatic inspiral up to the merger regime. A simple
solution to this problem is to combine effective-one-body waveforms with the
stationary phase approximation to obtain frequency-domain multipolar
approximants valid from any low frequency to merger. We demonstrate that
effective-one-body frequency-domain waveforms generated in post-adiabatic
approximation are computationally competitive with current phenomenological and
surrogate models, (virtually) arbitrarily long, and faithful up to merger for
any binary parameter. The same method can also be used to efficiently generate
intermediate mass binary black hole inspiral waveforms detectable by
space-based interferometers.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:06 GMT""}]","2021-10-27"
"2012.00028","Madhurima Choudhury","Madhurima Choudhury, Atrideb Chatterjee, Abhirup Datta, Tirthankar Roy
  Choudhury","Using Artificial Neural Networks to extract the 21-cm Global Signal from
  the EDGES data","Submitted to MNRAS",,"10.1093/mnras/stab180",,"astro-ph.CO astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The redshifted 21-cm signal of neutral Hydrogen is a promising probe into the
period of evolution of our Universe when the first stars were formed (Cosmic
Dawn), to the period where the entire Universe changed its state from being
completely neutral to completely ionized (Reionization). The most striking
feature of this line of neutral Hydrogen is that it can be observed across an
entire frequency range as a sky-averaged continuous signature, or its
fluctuations can be measured using an interferometer. However, the 21-cm signal
is very faint and is dominated by a much brighter Galactic and extra-galactic
foregrounds, making it an observational challenge. We have used different
physical models to simulate various realizations of the 21-cm Global signals,
including an excess radio background to match the amplitude of the EDGES 21-cm
signal. First, we have used an artificial neural network (ANN) to extract the
astrophysical parameters from these simulated datasets. Then, mock observations
were generated by adding a physically motivated foreground model and an ANN was
used to extract the astrophysical parameters from such data. The $R^2$ score of
our predictions from the mock-observations is in the range of 0.65-0.89. We
have used this ANN to predict the signal parameters giving the EDGES data as
the input. We find that the reconstructed signal closely mimics the amplitude
of the reported detection. The recovered parameters can be used to infer the
physical state of the gas at high redshifts.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:06 GMT""}]","2021-01-26"
"2012.00029","Valentin Decoene","Valentin Decoene, Kumiko Kotera, Joseph Silk","Fast radio burst repeaters produced via Kozai-Lidov feeding of neutron
  stars in binary systems","21 pages, 7 figures, 3 appendices, accepted in A&A (November 26 2020)","A&A 645, A122 (2021)","10.1051/0004-6361/202038975",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Neutron stars are likely surrounded by gas, debris, and asteroid belts.
Kozai-Lidov perturbations, induced by a distant, but gravitationally bound
companion, can trigger the infall of such orbiting bodies onto a central
compact object. These effects could lead to the emission of fast radio bursts
(FRBs), for example by asteroid-induced magnetic wake fields in the wind of the
compact object. A few percent of binary neutron star systems in the Universe,
such as neutron star-main sequence star, neutron star-white dwarf, double
neutron star, and neutron star-black hole systems, can account for the observed
non-repeating FRB rates. More remarkably, we find that wide and close companion
orbits lead to non-repeating and repeating sources, respectively, and they
allow for one to compute a ratio between repeating and non-repeating sources of
a few percent, which is in close agreement with the observations. Three major
predictions can be made from our scenario, which can be tested in the coming
years: 1) most repeaters should stop repeating after a period between 10 years
to a few decades, as their asteroid belts become depleted; 2) some
non-repeaters could occasionally repeat, if we hit the short period tail of the
FRB period distribution; and 3) series of sub-Jansky level short radio bursts
could be observed as electromagnetic counterparts of the mergers of binary
neutron star systems.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:07 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 09:51:57 GMT""}]","2021-01-27"
"2012.00030","Stephen G. Naculich","Stephen G. Naculich","All-loop-orders relation between Regge limits of ${\cal N}=4$ SYM and
  ${\cal N}=8$ supergravity four-point amplitudes","34 pages; v2: clarification added, minor typos corrected, published
  version",,"10.1007/JHEP02(2021)044","BOW-PH-169","hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine in detail the structure of the Regge limit of the (nonplanar)
${\cal N}=4$ SYM four-point amplitude. We begin by developing a basis of color
factors $C_{ik}$ suitable for the Regge limit of the amplitude at any loop
order, and then calculate explicitly the coefficients of the amplitude in that
basis through three-loop order using the Regge limit of the full amplitude
previously calculated by Henn and Mistlberger. We compute these coefficients
exactly at one loop, through ${\cal O} (\epsilon^2)$ at two loops, and through
${\cal O} (\epsilon^0)$ at three loops, verifying that the IR-divergent pieces
are consistent with (the Regge limit of) the expected infrared divergence
structure, including a contribution from the three-loop correction to the
dipole formula. We also verify consistency with the IR-finite NLL and NNLL
predictions of Caron-Huot et al. Finally we use these results to motivate the
conjecture of an all-orders relation between one of the coefficients and the
Regge limit of the ${\cal N} =8$ supergravity four-point amplitude.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:08 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 21:31:27 GMT""}]","2021-02-24"
"2012.00031","Shengqi Sang","Shengqi Sang, Yaodong Li, Tianci Zhou, Xiao Chen, Timothy H. Hsieh,
  Matthew P. A. Fisher","Entanglement Negativity at Measurement-Induced Criticality",,"PRX Quantum 2, 030313 (2021)","10.1103/PRXQuantum.2.030313",,"cond-mat.stat-mech cond-mat.dis-nn cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose entanglement negativity as a fine-grained probe of
measurement-induced criticality. We motivate this proposal in stabilizer
states, where for two disjoint subregions, comparing their ""mutual negativity""
and their mutual information leads to a precise distinction between bipartite
and multipartite entanglement. In a measurement-only stabilizer circuit that
maps exactly to two-dimensional critical percolation, we show that the mutual
information and the mutual negativity are governed by boundary conformal fields
of different scaling dimensions at long distances. We then consider a class of
""hybrid"" circuit models obtained by perturbing the measurement-only circuit
with unitary gates of progressive levels of complexity. While other critical
exponents vary appreciably for different choices of unitary gate ensembles at
their respective critical points, the mutual negativity has scaling dimension 3
across remarkably many of the hybrid circuits, which is notably different from
that in percolation. We contrast our results with limiting cases where a
geometrical minimal-cut picture is available.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:09 GMT""}]","2021-07-28"
"2012.00032","Konstantinos Rigatos","Nick Evans, Konstantinos S. Rigatos","Chiral symmetry breaking and confinement: separating the scales","9 pages, 2 figures, 1 table, v2: added commentary, v3: minor
  corrections, added references","Phys. Rev. D 103, 094022 (2021)","10.1103/PhysRevD.103.094022",,"hep-ph hep-lat hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review arguments that chiral symmetry breaking is triggered when the quark
bilinear condensate's dimension passes through one ($\gamma=1$). This is
supported by gap equations and more recently holographic models. Confinement
may then be a separate property of the pure Yang-Mills theory below the scale
of the dynamically generated quark mass, occurring at the scale of the pole in
the deep IR running. Here, we use perturbative results for the running of the
gauge coupling and $\gamma$ in asymptotically free SU($N_c$) gauge theories
with matter in higher dimension representations to seek the best candidate
theories where confinement and chiral symmetry breaking can be maximally
separated. For example, SU(2) gauge theory with a single Weyl quark in the
$S_3$ (dimension 4) representation may have a factor of 20 separation in scale.
Such a theory could be simulated on the lattice to test the separation. We also
propose studying multi-representation theories where the higher dimension
representation forms a condensate at one scale that can be quite separate from
the condensation scale of the second representation matter. The confinement
scale would presumably be below the second scale. For example, SU(3) gauge
theory with a Weyl adjoint fermion and ten fundamental quarks may have a
separation of a factor of 20 also.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:09 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 10:37:33 GMT""},{""version"":""v3"",""created"":""Wed, 19 May 2021 07:38:40 GMT""}]","2021-05-26"
"2012.00033","Saulo De Mesquita Diles","Saulo Diles","Two theorems for the gradient expansion of relativistic hydrodynamics","6 pages; Published in Physics Letters B",,"10.1016/j.physletb.2021.136850",,"hep-th gr-qc hep-ph","http://creativecommons.org/licenses/by/4.0/","  This letter is dedicated to providing proof of two statements concerning the
gradient expansion of relativistic hydrodynamics. The first statement is that
\textit{the ordering of transverse derivatives is irrelevant in the gradient
expansion of a non-conformal fluid}. The second statement is that \textit{the
longitudinal projection of the Weyl covariant derivative can be eliminated in
the gradient expansion of a conformal fluid}. This second statement does not
apply to curvature tensors. In the conformal case, we know that the ordering of
Weyl covariant derivatives is irrelevant in the gradient expansion.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:09 GMT""},{""version"":""v2"",""created"":""Mon, 20 Dec 2021 21:09:30 GMT""},{""version"":""v3"",""created"":""Wed, 5 Jan 2022 15:57:27 GMT""}]","2022-01-12"
"2012.00034","Irene Valenzuela","Jos\'e Calder\'on-Infante, Angel M. Uranga and Irene Valenzuela","The Convex Hull Swampland Distance Conjecture and Bounds on
  Non-geodesics","35 pages, 6 figures",,"10.1007/JHEP03(2021)299","IFT-UAM/CSIC-20-169","hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Swampland Distance Conjecture (SDC) restricts the geodesic distances that
scalars can traverse in effective field theories as they approach points at
infinite distance in moduli space. We propose that, when applied to the subset
of light fields in effective theories with scalar potentials, the SDC restricts
the amount of non-geodesicity allowed for trajectories along valleys of the
potential. This is necessary to ensure consistency of the SDC as a valid
swampland criterium at any energy scale across the RG flow. We provide a simple
description of this effect in moduli space of hyperbolic space type, and
products thereof, and obtain critical trajectories which lead to maximum
non-geodesicity compatible with the SDC. We recover and generalize these
results by expressing the SDC as a new Convex Hull constraint on trajectories,
characterizing towers by their scalar charge to mass ratio in analogy to the
Scalar Weak Gravity Conjecture. We show that recent results on the asymptotic
scalar potential of flux compatifications near infinity in moduli space
precisely realize these critical amounts of non-geodesicity. Our results
suggest that string theory flux compactifications lead to the most generic
potentials allowing for maximum non-geodesicity of the potential valleys while
respecting the SDC along them.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:12 GMT""}]","2021-04-21"
"2012.00035","Joseph Guidry","Joseph A. Guidry, Zachary P. Vanderbosch, J. J. Hermes, Brad N.
  Barlow, Isaac D. Lopez, Emily M. Boudreaux, Kyle A. Corcoran, Keaton J. Bell,
  M. H. Montgomery, Tyler M. Heintz, Barbara G. Castanheira, Joshua S. Reding,
  Bart H. Dunlap, D. E. Winget, Karen I. Winget, J. W. Kuehne","I Spy Transits and Pulsations: Empirical Variability in White Dwarfs
  Using Gaia and the Zwicky Transient Facility","30 pages, 14 figures, revised and accepted to ApJ on March 11, 2021",,"10.3847/1538-4357/abee68",,"astro-ph.SR astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We present a novel method to detect variable astrophysical objects and
transient phenomena using anomalous excess scatter in repeated measurements
from public catalogs of Gaia DR2 and Zwicky Transient Facility (ZTF) DR3
photometry. We first provide a generalized, all-sky proxy for variability using
only Gaia DR2 photometry, calibrated to white dwarf stars. To ensure more
robust candidate detection, we further employ a method combining Gaia with ZTF
photometry and alerts. To demonstrate the efficacy, we apply this latter
technique to a sample of roughly $12,100$ white dwarfs within 200 pc centered
on the ZZ Ceti instability strip, where hydrogen-atmosphere white dwarfs are
known to pulsate. Through inspecting the top $1\%$ samples ranked by these
methods, we demonstrate that both the Gaia-only and ZTF-informed techniques are
highly effective at identifying known and new variable white dwarfs, which we
verify using follow-up, high-speed photometry. We confirm variability in all 33
out of 33 ($100\%$) observed white dwarfs within our top $1\%$ highest-ranked
candidates, both inside and outside the ZZ Ceti instability strip. In addition
to dozens of new pulsating white dwarfs, we also identify five white dwarfs
highly likely to show transiting planetary debris; if confirmed, these systems
would more than triple the number of white dwarfs known to host transiting
debris.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:13 GMT""},{""version"":""v2"",""created"":""Sun, 14 Mar 2021 22:20:39 GMT""}]","2023-06-02"
"2012.00036","Courtney Carter","Courtney Carter, Charlie Conroy, Dennis Zaritsky, Yuan-Sen Ting, Ana
  Bonaca, Rohan Naidu, Benjamin Johnson, Phillip Cargile, Nelson Caldwell, Josh
  Speagle, Jiwon Jesse Han","Ancient Very Metal-Poor Stars Associated With the Galactic Disk in the
  H3 Survey","9 pages, 4 figures, accepted to ApJ",,"10.3847/1538-4357/abcda4",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ancient, very metal-poor stars offer a window into the earliest epochs of
galaxy formation and assembly. We combine data from the H3 Spectroscopic Survey
and Gaia to measure metallicities, abundances of $\alpha$ elements, stellar
ages, and orbital properties of a sample of 482 very metal-poor (VMP;
[Fe/H]$<-2$) stars in order to constrain their origins. This sample is confined
to $1\lesssim |Z| \lesssim3$ kpc from the Galactic plane. We find that >70% of
VMP stars near the disk are on prograde orbits and this fraction increases
toward lower metallicities. This result unexpected if metal-poor stars are
predominantly accreted from many small systems with no preferred orientation,
as such a scenario would imply a mostly isotropic distribution. Furthermore, we
find there is some evidence for higher fractions of prograde orbits amongst
stars with lower [$\alpha$/Fe]. Isochrone-based ages for main sequence turn-off
stars reveal that these VMP stars are uniformly old ($\approx12$ Gyr)
irrespective of the $\alpha$ abundance and metallicity, suggesting that the
metal-poor population was not born from the same well-mixed gas disk. We
speculate that the VMP population has a heterogeneous origin, including both
in-situ formation in the ancient disk and accretion from a satellite with the
same direction of rotation as the ancient disk at early times. Our precisely
measured ages for these VMP stars on prograde orbits show that the Galaxy has
had a relatively quiescent merging history over most of cosmic time, and
implies the angular momentum alignment of the Galaxy has been in place for at
least 12 Gyr.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:13 GMT""}]","2021-03-03"
"2012.00037","Denis Krotov","Denis S. Krotov (Sobolev Institute of Mathematics, Novosibirsk,
  Russia)","On minimal subspace Zp-null designs","5 pages",,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $q$ be a power of a prime $p$, and let $V$ be an $n$-dimensional space
over the field GF$(q)$. A $Z_p$-valued function $C$ on the set of
$k$-dimensional subspaces of $V$ is called a $k$-uniform $Z_p$-null design of
strength $t$ if for every $t$-dimensional subspace $y$ of $V$ the sum of $C$
over the $k$-dimensional superspaces of $y$ equals $0$. For $q=p=2$ and $0\le
t<k<n$, we prove that the minimum number of non-zeros of a non-void $k$-uniform
$Z_p$-null design of strength $t$ equals $2^{t+1}$. For $q>2$, we give lower
and upper bounds for that number.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:14 GMT""}]","2020-12-02"
"2012.00038","Denis Krotov","Denis S. Krotov (Sobolev Institute of Mathematics, Novosibirsk,
  Russia)","[[2,10],[6,6]]-equitable partitions of the 12-cube",,,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the computer-aided classification of equitable partitions of the
12-cube with quotient matrix [[2,10],[6,6]], or, equivalently, simple
orthogonal arrays OA(1536,12,2,7), or order-7 correlation-immune Boolean
functions in 12 variables with 1536 ones (which completes the classification of
unbalanced order-7 correlation-immune Boolean functions in 12 variables). We
find that there are 103 equivalence classes of the considered objects, and
there are only two almost-OA(1536,12,2,8) among them.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:16 GMT""}]","2020-12-02"
"2012.00039","Francesco Parisen Toldin","Francesco Parisen Toldin","Boundary critical behavior of the three-dimensional Heisenberg
  universality class","11 pages, 3 figures, including Supplemental Material; v2: expanded
  discussion and technical details, results unchanged, 12 pages, 3 figures
  including Supplemental Material","Phys. Rev. Lett. 126, 135701 (2021)","10.1103/PhysRevLett.126.135701",,"cond-mat.stat-mech cond-mat.str-el hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the boundary critical behavior of the three-dimensional Heisenberg
universality class, in the presence of a bidimensional surface. By means of
high-precision Monte Carlo simulations of an improved lattice model, where
leading bulk scaling corrections are suppressed, we prove the existence of a
special phase transition, with unusual exponents, and of an extraordinary phase
with logarithmically decaying correlations. These findings contrast with
na\""ive arguments on the bulk-surface phase diagram, and allow us to explain
some recent puzzling results on the boundary critical behavior of quantum spin
models.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:17 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 21:28:04 GMT""}]","2021-04-01"
"2012.00040","Bowen Shi","Bowen Shi, Xin Dai, Yuan-Ming Lu","Entanglement negativity at the critical point of measurement-driven
  transition","12 pages, 6 figures, v2, improved the discussion of the nature of the
  CFT in question",,,,"cond-mat.stat-mech cond-mat.dis-nn cond-mat.str-el quant-ph","http://creativecommons.org/licenses/by/4.0/","  We study the entanglement behavior of a random unitary circuit punctuated by
projective measurements at the measurement-driven phase transition in one
spatial dimension. We numerically study the logarithmic entanglement negativity
of two disjoint intervals and find that it scales as a power of the
cross-ratio. We investigate two systems: (1) Clifford circuits with projective
measurements, and (2) Haar random local unitary circuit with projective
measurements. Remarkably, we identify a power-law behavior of entanglement
negativity at the critical point. Previous results of entanglement entropy and
mutual information point to an emergent conformal invariance of the
measurement-driven transition. Our result suggests that the critical behavior
of the measurement-driven transition is distinct from the ground state behavior
of any \emph{unitary} conformal field theory.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:18 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 08:49:47 GMT""}]","2021-08-31"
"2012.00041","Ashoke Sen","Ashoke Sen","Cutkosky Rules and Unitarity (Violation) in D-instanton Amplitudes","LaTeX file; 94 pages",,"10.1007/JHEP07(2021)205",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In perturbative amplitudes in quantum field theory and string field theory,
Cutkosky rule expresses the anti-hermitian part of a Feynman diagram in terms
of sum over all its cut diagrams, and this in turn is used to prove unitarity
of the theory. For D-instanton contribution to a string theory amplitude, the
cutting rule needed for the proof of unitarity is somewhat different; we need
to sum over only those cut diagrams for which all the world-sheet boundaries
ending on some particular D-instanton lie on the same side of the cut. By
working with the closed string effective action, obtained after integrating out
the open string modes, we prove that the D-instanton amplitudes actually
satisfy these cutting rules, provided the effective action is real. The
violation of unitarity in the closed string sector of two dimensional string
theory can be traced to the failure of this reality condition. In the critical
superstring theory, multi-instanton and multi anti-instanton amplitudes satisfy
the reality condition. Contribution to the amplitudes from the instanton
anti-instanton sector satisfies the reality condition if we make a specific
choice of integration cycle over the configuration space of string fields,
whereas contribution due to the non-BPS D-instantons will need to either vanish
or have an overall real normalization in order for it to give real
contribution. We use Picard-Lefschetz theory to argue that these conditions are
indeed satisfied in superstring theories.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:20 GMT""}]","2021-08-18"
"2012.00042","Ji Won Park","Ji Won Park, Sebastian Wagner-Carena, Simon Birrer, Philip J.
  Marshall, Joshua Yao-Yu Lin, Aaron Roodman (for the LSST Dark Energy Science
  Collaboration)","Large-Scale Gravitational Lens Modeling with Bayesian Neural Networks
  for Accurate and Precise Inference of the Hubble Constant","21 pages (+2 appendix), 17 figures. Published in ApJ. Code at
  https://github.com/jiwoncpark/h0rton. Datasets, trained models, and inference
  results at https://zenodo.org/record/4300382","ApJ 910 39 (2021)","10.3847/1538-4357/abdfc4",,"astro-ph.IM astro-ph.CO cs.LG","http://creativecommons.org/licenses/by/4.0/","  We investigate the use of approximate Bayesian neural networks (BNNs) in
modeling hundreds of time-delay gravitational lenses for Hubble constant
($H_0$) determination. Our BNN was trained on synthetic HST-quality images of
strongly lensed active galactic nuclei (AGN) with lens galaxy light included.
The BNN can accurately characterize the posterior PDFs of model parameters
governing the elliptical power-law mass profile in an external shear field. We
then propagate the BNN-inferred posterior PDFs into ensemble $H_0$ inference,
using simulated time delay measurements from a plausible dedicated monitoring
campaign. Assuming well-measured time delays and a reasonable set of priors on
the environment of the lens, we achieve a median precision of $9.3$\% per lens
in the inferred $H_0$. A simple combination of 200 test-set lenses results in a
precision of 0.5 $\textrm{km s}^{-1} \textrm{ Mpc}^{-1}$ ($0.7\%$), with no
detectable bias in this $H_0$ recovery test. The computation time for the
entire pipeline -- including the training set generation, BNN training, and
$H_0$ inference -- translates to 9 minutes per lens on average for 200 lenses
and converges to 6 minutes per lens as the sample size is increased. Being
fully automated and efficient, our pipeline is a promising tool for exploring
ensemble-level systematics in lens modeling for $H_0$ inference.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:20 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 00:01:45 GMT""}]","2021-04-13"
"2012.00043","Joshua Simon","Joshua D. Simon, Thomas M. Brown, Alex Drlica-Wagner, Ting S. Li,
  Roberto J. Avila, Keith Bechtol, Gisella Clementini, Denija Crnojevic,
  Alessia Garofalo, Marla Geha, David J. Sand, Jay Strader, and Beth Willman","Eridanus II: A Fossil from Reionization with an Off-Center Star Cluster","17 pages, 12 figures, 3 tables. Accepted for publication in ApJ.
  Structural fitting code is available at
  https://github.com/jsimonastro/EriII-structural-fitting",,"10.3847/1538-4357/abd31b",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present deep Hubble Space Telescope (HST) photometry of the ultra-faint
dwarf galaxy Eridanus II (Eri II). Eri II, which has an absolute magnitude of
M_V = -7.1, is located at a distance of 339 kpc, just beyond the virial radius
of the Milky Way. We determine the star formation history of Eri II and measure
the structure of the galaxy and its star cluster. We find that a star formation
history consisting of two bursts, constrained to match the spectroscopic
metallicity distribution of the galaxy, accurately describes the Eri II stellar
population. The best-fit model implies a rapid truncation of star formation at
early times, with >80% of the stellar mass in place before z~6. A small
fraction of the stars could be as young as 8 Gyr, but this population is not
statistically significant; Monte Carlo simulations recover a component younger
than 9 Gyr only 15% of the time, where they represent an average of 7 +/- 4% of
the population. These results are consistent with theoretical expectations for
quenching by reionization. The HST depth and angular resolution enable us to
show that Eri II's cluster is offset from the center of the galaxy by a
projected distance of 23 +/- 3 pc. This offset could be an indication of a
small (~50-75 pc) dark matter core in Eri II. Moreover, we demonstrate that the
cluster has a high ellipticity of 0.31 +0.05/-0.06 and is aligned with the
orientation of Eri II within 3 +/- 6 degrees, likely due to tides. The stellar
population of the cluster is indistinguishable from that of Eri II itself.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:00:31 GMT""}]","2021-02-17"
"2012.00044","Alexander Turbiner","J.C.del Valle, A.V. Turbiner, Adrian M Escobar Ruiz","Two-body neutral Coulomb system in a magnetic field at rest: from
  Hydrogen atom to positronium","post-publication version: 51 pages, 8 tables (one new), 5 figures, 3
  appendices; several important typos corrected, extra table, clarifications
  added -- all is published in erratum: Phys.Rev.A 105, 049901 (2022)","Phys.Rev.A 103, 032820 (2021); Phys.Rev.A 105, 049901 (2022)
  (erratum)","10.1103/PhysRevA.103.032820",,"quant-ph astro-ph.HE math-ph math.MP physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A simple locally accurate uniform approximation for the nodeless wavefunction
is constructed for a {\it neutral} system of two Coulomb charges of different
masses $(-q,m_1)$ and $(q,m_2)$ at rest in a constant uniform magnetic field
for the states of positive and negative parity, ${(1s_0)}$ and ${(2p_0)}$,
respectively. It is shown that by keeping the mass and charge of one of the
bodies fixed, all systems with different second body masses are related. This
allows one to consider the second body as infinitely-massive and to take such a
system as basic. Three physical systems are considered in details: the Hydrogen
atom with (in)-finitely massive proton (deuteron, triton) and the positronium
atom $(-e,e)$. We derive the Riccati-Bloch and Generalized-Bloch equations,
which describe the domains of small and large distances, respectively. Based on
the interpolation of the small and large distance behavior of the logarithm of
the wavefunction, a compact 10-parametric function is proposed. Taken as a
variational trial function it provides accuracy of not less than 6 significant
digits (s.d.) ($\lesssim 10^{-6}$ in relative deviation) for the total energy
in the whole domain of considered magnetic fields $[0\,,\,10^4]$ a.u. and not
less than 3 s.d. for the quadrupole moment $Q_{zz}$. In order to get reference
points the Lagrange Mesh Method with 16K mesh points was used to get from 10 to
6 s.d. in energy from small to large magnetic fields. Based on the
Riccati-Bloch equation the first 100 perturbative coefficients for the energy,
in the form of rational numbers, are calculated and, using the Pad\'e-Borel
re-summation procedure, the energy is found with not less than 10 s.d. at
magnetic fields $\leq 1$\,a.u.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:01:00 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 02:51:10 GMT""},{""version"":""v3"",""created"":""Mon, 18 Apr 2022 22:18:55 GMT""}]","2022-04-20"
"2012.00045","Luca Lepori","Luca Lepori, Simone Paganelli, Fabio Franchini, and Andrea Trombettoni","Mutual information for fermionic systems",,"Phys. Rev. Research 4, 033212 (2022)","10.1103/PhysRevResearch.4.033212",,"quant-ph cond-mat.mes-hall cond-mat.quant-gas cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the behavior of the mutual information (MI) in various quadratic
fermionic chains, with and without pairing terms and both with short- and
long-range hoppings. The models considered include the short-range limit and
long-range versions of the Kitaev model as well, and also cases in which the
area law for the entanglement entropy is - logarithmically or
non-logarithmically - violated. In all cases surveyed, when the area law is
violated at most logarithmically, the MI is a monotonically increasing function
of the conformal four-point ratio x. Where non-logarithmic violations of the
area law are present, non-monotonic features can be observed in the MI and the
four-point ratio, as well as other natural combinations of the parameters, is
found not to be sufficient to capture the whole structure of the MI with a
collapse onto a single curve. We interpret this behavior as a sign that the
structure of peaks is related to a non-universal spatial configuration of Bell
pairs. For the model exhibiting a perfect volume law, the MI vanishes
identically. For the Kitaev model the MI is vanishing for x -> 0 and it remains
zero up to a finite x in the gapped case. In general, a larger range of the
pairing corresponds to a reduction of the MI at small x. A discussion of the
comparison with the results obtained by the AdS/CFT correspondence in the
strong coupling limit is presented.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:01:04 GMT""},{""version"":""v2"",""created"":""Tue, 20 Sep 2022 10:05:50 GMT""}]","2022-09-21"
"2012.00046","Ismael Ayuso","Ismael Ayuso, Ruth Lazkoz and Vincenzo Salzano","Observational constraints on cosmological solutions of $f(Q)$ theories","15 pages, 13 figures","Phys. Rev. D 103, 063505 (2021)","10.1103/PhysRevD.103.063505",,"astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the last years some interest has been gathered by $f(Q)$ theories, which
are new candidates to replace Einstein's prescription for gravity. The
non-metricity tensor $Q$ allows to put forward the assumption of a free
torsionless connection and, consequently, new degrees of freedom in the action
are taken into account. This work focuses on a class of $f(Q)$ theories,
characterized by the presence of a general power-law term which adds up to the
standard (linear in) $Q$ term in the action, and on new cosmological scenarios
arising from them. Using the Markov chain Montecarlo method we carry out
statistical tests relying upon background data such as Type Ia Supernovae
luminosities and direct Hubble data (from cosmic clocks), along with Cosmic
Microwave Background shift and Baryon Acoustic Oscillations data. This allows
us to perform a multifaceted comparison between these new cosmologies and the
(concordance) $\Lambda$CDM setup. We conclude that, at the current precision
level, the best fits of our $f(Q)$ models correspond to values of their
specific parameters which make them hardly distinguishable from our General
Relativity ""\'echantillon"", that is $\Lambda$CDM.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:01:08 GMT""}]","2021-03-17"
"2012.00047","Ismael Ayuso","Ismael Ayuso, Francisco S. N. Lobo and Jos\'e P. Mimoso","Wormhole geometries induced by action-dependent Lagrangian theories","11 pages, 5 figures, V2: version accepted for publication in PRD","Phys. Rev. D 103, 044018 (2021)","10.1103/PhysRevD.103.044018",,"gr-qc astro-ph.HE hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we explore wormhole geometries in a recently proposed modified
gravity theory arising from a non-conservative gravitational theory,
tentatively denoted action-dependent Lagrangian theories. The generalized
gravitational field equation essentially depends on a background four-vector
$\lambda^\mu$, that plays the role of a coupling parameter associated with the
dependence of the gravitational Lagrangian upon the action, and may generically
depend on the spacetime coordinates. Considering wormhole configurations, by
using ""Buchdahl coordinates"", we find that the four-vector is given by
$\lambda_{\mu}=\left(0,0,\lambda_{\theta},0\right)$, and that the spacetime
geometry is severely restricted by the condition $g_{tt}g_{uu}=-1$, where $u$
is the radial coordinate. We find a plethora of specific asymptotically flat,
symmetric and asymmetric, solutions with power law choices for the function
$\lambda$, by generalizing the Ellis-Bronnikov solutions and the recently
proposed black bounce geometries, amongst others. We show that these compact
objects possess a far richer geometrical structure than their general
relativistic counterparts.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:01:31 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 11:34:57 GMT""}]","2021-02-12"
"2012.00048","Martijn de Vries","Martijn de Vries, Roger W. Romani, Oleg Kargaltsev, George Pavlov,
  Bettina Posselt, Patrick Slane, Niccolo' Bucciantini, Stephen Ng, Noel
  Klingler","PSR J1709-4429's Proper Motion and its Relationship to SNR G343.1-2.3","11 pages, 8 figures. Accepted for publication in the Astrophysical
  Journal",,"10.3847/1538-4357/abcebe",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We have obtained a deep 670 ks CXO ACIS image of the remarkable pulsar wind
nebula (PWN) of PSR J1709-4429, in 4 epochs during 2018-2019. Comparison with
an archival 2004 data set provides a pulsar proper motion mu = 13 \pm 3 mas/yr
at a PA of 86 \pm 9 degree (1 sigma combined statistical and systematic
uncertainties), precluding birth near the center of SNR G343.1-2.3. At the
pulsar's characteristic age of 17 kyr, the association can be preserved through
a combination of progenitor wind, birth kick and PWN outflow. Associated TeV
emission may, however, indicate explosion in an earlier supernova. Inter-epoch
comparison of the X-ray images shows that the PWN is dynamic, but we are unable
to conclusively measure flow speeds from blob motion. The pulsar has generated
a radio/X-ray wind bubble, and we argue that the PWN's long narrow jets are
swept back by shocked pulsar wind venting from this cavity. These jets may
trace the polar magnetic field lines of the PWN flow, an interesting challenge
for numerical modeling.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:04:35 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 02:53:47 GMT""}]","2021-02-17"
"2012.00049","Peng Peng","Zeyuan Xuan, Peng Peng and Xian Chen","Degeneracy between mass and peculiar acceleration for the double white
  dwarfs in the LISA band",,,"10.1093/mnras/stab331",,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mass and distance are fundamental quantities to measure in gravitational-wave
(GW) astronomy. However, recent studies suggest that the measurement may be
biased due to the acceleration of GW source. Here we develop an analytical
method to quantify such a bias induced by a tertiary on a double white dwarf
(DWD), since DWDs are the most common GW sources in the milli-Hertz band. We
show that in a large parameter space the mass is degenerate with the peculiar
acceleration, so that from the waveform we can only retrieve a mass of ${\cal
M}(1+\Gamma)^{3/5}$, where ${\cal M}$ is the real chirp mass of the DWD and
$\Gamma$ is a dimensionless factor proportional to the peculiar acceleration.
Based on our analytical method, we conduct mock observation of DWDs by the
Laser Interferometer Space Antenna (LISA). We find that in about $9\%$ of the
cases the measured chirp mass is biased due to the presence of a tertiary by
$(5-30)\%$. Even more extreme cases are found in about a dozen DWDs and they
may be misclassified as double neutron stars, binary black holes, DWDs
undergoing mass transfer, or even binaries containing lower-mass-gap objects
and primordial black holes. The bias in mass also affects the measurement of
distance, resulting in a seemingly over-density of DWDs within a heliocentric
distance of $1$ kpc as well as beyond $100$ kpc. Our result highlights the
necessity of modeling the astrophysical environments of GW sources to retrieve
their correct physical parameters.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:07:07 GMT""}]","2021-02-17"
"2012.00050","Anup Das","Shihao Song, Anup Das, Onur Mutlu, Nagarajan Kandasamy","Aging-Aware Request Scheduling for Non-Volatile Main Memory","To appear in ASP-DAC 2021",,"10.1145/3394885.3431529",,"cs.AR cs.ET","http://creativecommons.org/licenses/by/4.0/","  Modern computing systems are embracing non-volatile memory (NVM) to implement
high-capacity and low-cost main memory. Elevated operating voltages of NVM
accelerate the aging of CMOS transistors in the peripheral circuitry of each
memory bank. Aggressive device scaling increases power density and temperature,
which further accelerates aging, challenging the reliable operation of
NVM-based main memory. We propose HEBE, an architectural technique to mitigate
the circuit aging-related problems of NVM-based main memory. HEBE is built on
three contributions. First, we propose a new analytical model that can
dynamically track the aging in the peripheral circuitry of each memory bank
based on the bank's utilization. Second, we develop an intelligent memory
request scheduler that exploits this aging model at run time to de-stress the
peripheral circuitry of a memory bank only when its aging exceeds a critical
threshold. Third, we introduce an isolation transistor to decouple parts of a
peripheral circuit operating at different voltages, allowing the decoupled
logic blocks to undergo long-latency de-stress operations independently and off
the critical path of memory read and write accesses, improving performance. We
evaluate HEBE with workloads from the SPEC CPU2017 Benchmark suite. Our results
show that HEBE significantly improves both performance and lifetime of
NVM-based main memory.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:07:10 GMT""}]","2020-12-02"
"2012.00051","Tom\'a\v{s} Brauner","Tomas Brauner","Field theories with higher-group symmetry from composite currents","1+39 pages, 2 tables; v2: added a discussion of charged objects of
  composite symmetries and some extra references, version to appear in JHEP","JHEP 04 (2021) 045","10.1007/JHEP04(2021)045",,"hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Higher-form symmetries are associated with transformations that only act on
extended objects, not on point particles. Typically, higher-form symmetries
live alongside ordinary, point-particle (0-form), symmetries and they can be
jointly described in terms of a direct product symmetry group. However, when
the actions of 0-form and higher-form symmetries become entangled, a more
general mathematical structure is required, related to higher categorical
groups. Systems with continuous higher-group symmetry were previously
constructed in a top-down manner, descending from quantum field theories with a
specific mixed 't Hooft anomaly. I show that higher-group symmetry also
naturally emerges from a bottom-up, low-energy perspective, when the physical
system at hand contains at least two different given, spontaneously broken
symmetries. This leads generically to a hierarchy of emergent higher-form
symmetries, corresponding to the Grassmann algebra of topological currents of
the theory, with an underlying higher-group structure. Examples of physical
systems featuring such higher-group symmetry include superfluid mixtures and
variants of axion electrodynamics.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:07:20 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 19:23:29 GMT""}]","2021-04-08"
"2012.00052","Wen Xiao","Wen Xiao, Giuseppe Carenini","Systematically Exploring Redundancy Reduction in Summarizing Long
  Documents","13 pages. Accepted at AACL 2020",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Our analysis of large summarization datasets indicates that redundancy is a
very serious problem when summarizing long documents. Yet, redundancy reduction
has not been thoroughly investigated in neural summarization. In this work, we
systematically explore and compare different ways to deal with redundancy when
summarizing long documents. Specifically, we organize the existing methods into
categories based on when and how the redundancy is considered. Then, in the
context of these categories, we propose three additional methods balancing
non-redundancy and importance in a general and flexible way. In a series of
experiments, we show that our proposed methods achieve the state-of-the-art
with respect to ROUGE scores on two scientific paper datasets, Pubmed and
arXiv, while reducing redundancy significantly.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:07:27 GMT""}]","2020-12-02"
"2012.00053","Haoxiang Ma","Haoxiang Ma, Jie Fu","Attention-Based Planning with Active Perception",,,,,"cs.RO cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Attention control is a key cognitive ability for humans to select information
relevant to the current task. This paper develops a computational model of
attention and an algorithm for attention-based probabilistic planning in Markov
decision processes. In attention-based planning, the robot decides to be in
different attention modes. An attention mode corresponds to a subset of state
variables monitored by the robot. By switching between different attention
modes, the robot actively perceives task-relevant information to reduce the
cost of information acquisition and processing, while achieving near-optimal
task performance. Though planning with attention-based active perception
inevitably introduces partial observations, a partially observable MDP
formulation makes the problem computational expensive to solve. Instead, our
proposed method employs a hierarchical planning framework in which the robot
determines what to pay attention to and for how long the attention should be
sustained before shifting to other information sources. During the attention
sustaining phase, the robot carries out a sub-policy, computed from an
abstraction of the original MDP given the current attention. We use an example
where a robot is tasked to capture a set of intruders in a stochastic
gridworld. The experimental results show that the proposed method enables
information- and computation-efficient optimal planning in stochastic
environments.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:07:28 GMT""}]","2020-12-02"
"2012.00054","Maria Jose Lombardia","M.D. Esteban, M.J. Lombard\'ia, E. L\'opez-Vizca\'ino, D. Morales and
  A. P\'erez","Empirical best prediction of small area bivariate parameters",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  This paper introduces empirical best predictors of small area bivariate
parameters, like ratios of sums or sums of ratios, by assuming that the target
unit-level vector follows a bivariate nested error regression model. The
corresponding means squared errors are estimated by parametric bootstrap.
Several simulation experiments empirically study the behavior of the introduced
statistical methodology. An application to real data from the Spanish household
budget survey gives estimators of ratios of food household expenditures by
provinces.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:12:56 GMT""}]","2020-12-02"
"2012.00055","Felix von Oppen","Josias Langbehn, Sergio Acero Gonzalez, Piet W. Brouwer, and Felix von
  Oppen","Topological superconductivity in tripartite
  superconductor-ferromagnet-semiconductor nanowires","10 pages, 6 figures","Phys. Rev. B 103, 165301 (2021)","10.1103/PhysRevB.103.165301",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by recent experiments searching for Majorana zero modes in
tripartite semiconductor nanowires with epitaxial superconductor and
ferromagnetic-insulator layers, we explore the emergence of topological
superconductivity in such devices for paradigmatic arrangements of the three
constituents. Accounting for the competition between magnetism and
superconductivity, we treat superconductivity self consistently and describe
the electronic properties, including the superconducting and ferromagnetic
proximity effects, within a direct wave-function approach. We conclude that the
most viable mechanism for topological superconductivity relies on a
superconductor-semiconductor-ferromagnet arrangement of the constituents, in
which spin splitting and superconductivity are independently induced in the
semiconductor by proximity and superconductivity is only weakly affected by the
ferromagnetic insulator.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:14:00 GMT""}]","2021-04-14"
"2012.00056","Anoop Vallabhajosyula","Shreya Malani, Dinesh Gaurav, Anoop Vallabhajosyula, Rahul Agrawal","Diversifying Relevant Phrases",,,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Diverse keyword suggestions for a given landing page or matching queries to
diverse documents is an active research area in online advertising. Modern
search engines provide advertisers with products like Dynamic Search Ads and
Smart Campaigns where they extract meaningful keywords/phrases from the
advertiser's product inventory. These keywords/phrases are representative of a
diverse spectrum of advertiser's interests. In this paper, we address the
problem of obtaining relevant yet diverse keywords/phrases for any given
document. We formulate this as an optimization problem, maximizing the
parameterized trade-off between diversity and relevance constrained over number
of possible keywords/phrases. We show that this is a combinatorial NP-hard
optimization problem. We propose two approaches based on convex relaxations
varying in complexity and performance. In the first approach, we show that the
optimization problem reduces to an eigen value problem. In the second approach,
we show that the optimization problem reduces to minimizing a quadratic form
over an l1-ball. Subsequently, we show that this is equivalent to a
semi-definite optimization problem. To prove the efficacy of our proposed
formulation, we evaluate it on various real-world datasets and compare it to
the state-of-the-art heuristic approaches.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:15:55 GMT""}]","2020-12-02"
"2012.00057","Ayush Jain","Zhaoyuan Fang, Ayush Jain, Gabriel Sarch, Adam W. Harley, Katerina
  Fragkiadaki","Move to See Better: Self-Improving Embodied Object Detection","First three authors contributed equally. Project Page:
  https://ayushjain1144.github.io/SeeingByMoving/",,,,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Passive methods for object detection and segmentation treat images of the
same scene as individual samples and do not exploit object permanence across
multiple views. Generalization to novel or difficult viewpoints thus requires
additional training with lots of annotations. In contrast, humans often
recognize objects by simply moving around, to get more informative viewpoints.
In this paper, we propose a method for improving object detection in testing
environments, assuming nothing but an embodied agent with a pre-trained 2D
object detector. Our agent collects multi-view data, generates 2D and 3D
pseudo-labels, and fine-tunes its detector in a self-supervised manner.
Experiments on both indoor and outdoor datasets show that (1) our method
obtains high-quality 2D and 3D pseudo-labels from multi-view RGB-D data; (2)
fine-tuning with these pseudo-labels improves the 2D detector significantly in
the test environment; (3) training a 3D detector with our pseudo-labels
outperforms a prior self-supervised method by a large margin; (4) given weak
supervision, our method can generate better pseudo-labels for novel objects.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:16:51 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 08:09:11 GMT""}]","2021-03-30"
"2012.00058","Trang Le","Joseph D. Romano, Trang T. Le, William La Cava, John T. Gregg, Daniel
  J. Goldberg, Natasha L. Ray, Praneel Chakraborty, Daniel Himmelstein, Weixuan
  Fu, and Jason H. Moore","PMLB v1.0: An open source dataset collection for benchmarking machine
  learning methods","4 pages, 1 figure. *: These authors contributed equally",,,,"cs.LG cs.DB","http://creativecommons.org/licenses/by/4.0/","  Motivation: Novel machine learning and statistical modeling studies rely on
standardized comparisons to existing methods using well-studied benchmark
datasets. Few tools exist that provide rapid access to many of these datasets
through a standardized, user-friendly interface that integrates well with
popular data science workflows.
  Results: This release of PMLB provides the largest collection of diverse,
public benchmark datasets for evaluating new machine learning and data science
methods aggregated in one location. v1.0 introduces a number of critical
improvements developed following discussions with the open-source community.
  Availability: PMLB is available at https://github.com/EpistasisLab/pmlb.
Python and R interfaces for PMLB can be installed through the Python Package
Index and Comprehensive R Archive Network, respectively.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:21:44 GMT""},{""version"":""v2"",""created"":""Sun, 4 Apr 2021 20:31:09 GMT""},{""version"":""v3"",""created"":""Tue, 6 Apr 2021 12:37:35 GMT""}]","2021-04-07"
"2012.00059","Shobhit Jain","Gergely Buza, George Haller, Shobhit Jain","Integral Equations & Model Reduction For Fast Computation of Nonlinear
  Periodic Response",,"International Journal of Numerical Methods in Engineering (2021)","10.1002/nme.6740",,"cs.CE math.DS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We propose a reformulation for the integral equations approach of Jain,
Breunung \& Haller [Nonlinear Dyn. 97, 313--341 (2019)] to steady-state
response computation for periodically forced nonlinear mechanical systems. This
reformulation results in additional speed-up and better convergence. We show
that the solutions of the reformulated equations are in one-to-one
correspondence with those of the original integral equations and derive
conditions under which a collocation type approximation converges to the exact
solution in the reformulated setting. Furthermore, we observe that model
reduction using a selected set of vibration modes of the linearized system
substantially enhances the computational performance. Finally, we discuss an
open-source implementation of this approach and demonstrate the gains in
computational performance using three examples that also include nonlinear
finite-element models.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:21:59 GMT""}]","2021-06-01"
"2012.00060","Dongrui Wu","Zhenhua Shi, Dongrui Wu, Chenfeng Guo, Changming Zhao, Yuqi Cui, and
  Fei-Yue Wang","FCM-RDpA: TSK Fuzzy Regression Model Construction Using Fuzzy C-Means
  Clustering, Regularization, DropRule, and Powerball AdaBelief",,"Information Sciences, 574:490:504, 2021",,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To effectively optimize Takagi-Sugeno-Kang (TSK) fuzzy systems for regression
problems, a mini-batch gradient descent with regularization, DropRule, and
AdaBound (MBGD-RDA) algorithm was recently proposed. This paper further
proposes FCM-RDpA, which improves MBGD-RDA by replacing the grid partition
approach in rule initialization by fuzzy c-means clustering, and AdaBound by
Powerball AdaBelief, which integrates recently proposed Powerball gradient and
AdaBelief to further expedite and stabilize parameter optimization. Extensive
experiments on 22 regression datasets with various sizes and dimensionalities
validated the superiority of FCM-RDpA over MBGD-RDA, especially when the
feature dimensionality is higher. We also propose an additional approach,
FCM-RDpAx, that further improves FCM-RDpA by using augmented features in both
the antecedents and consequents of the rules.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:22:15 GMT""}]","2022-11-15"
"2012.00061","Francois Andrieu","M. Ezzadeen, D. Bosch, B. Giraud, S. Barraud, J.-P. Noel, D. Lattard,
  J. Lacord, J.-M. Portal, F. Andrieu","Ultra-High-density 3D vertical RRAM with stacked JunctionLess nanowires
  for In-Memory-Computing applications",,,"10.1109/TED.2020.3020779",,"physics.app-ph cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Von-Neumann bottleneck is a clear limitation for data-intensive
applications, bringing in-memory computing (IMC) solutions to the fore. Since
large data sets are usually stored in nonvolatile memory (NVM), various
solutions have been proposed based on emerging memories, such as OxRAM, that
rely mainly on area hungry, one transistor (1T) one OxRAM (1R) bit-cell. To
tackle this area issue, while keeping the programming control provided by 1T1R
bit-cell, we propose to combine gate-all-around stacked junctionless nanowires
(1JL) and OxRAM (1R) technology to create a 3-D memory pillar with ultrahigh
density. Nanowire junctionless transistors have been fabricated, characterized,
and simulated to define current conditions for the whole pillar. Finally, based
on Simulation Program with Integrated Circuit Emphasis (SPICE) simulations, we
demonstrated successfully scouting logic operations up to three-pillar layers,
with one operand per layer.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:23:00 GMT""}]","2020-12-02"
"2012.00062","Jie Gu","Stavros Garoufalidis, Jie Gu, Marcos Marino","Peacock patterns and resurgence in complex Chern-Simons theory","68 pages. Typos corrected, references added",,,,"math.GT hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The partition function of complex Chern-Simons theory on a 3-manifold with
torus boundary reduces to a finite dimensional state-integral which is a
holomorphic function of a complexified Planck's constant $\tau$ in the complex
cut plane and an entire function of a complex parameter $u$. This gives rise to
a vector of factorially divergent perturbative formal power series whose Stokes
rays form a peacock-like pattern in the complex plane.
  We conjecture that these perturbative series are resurgent, their
trans-series involve two non-perturbative variables, their Stokes automorphism
satisfies a unique factorization property and that it is given explicitly in
terms of a fundamental matrix solution to a (dual) linear $q$-difference
equation. We further conjecture that entries of the Stokes automorphism matrix
are the 3D-indices of Dimofte-Gaiotto-Gukov. We provide proofs of our
statements regarding the $q$-difference equations and their properties of their
fundamental solutions and illustrate our conjectures regarding the Stokes
matrices with numerical calculations for the two simplest hyperbolic $4_1$ and
$5_2$ knots.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:29:38 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 21:28:22 GMT""},{""version"":""v3"",""created"":""Thu, 7 Apr 2022 02:47:23 GMT""}]","2022-04-08"
"2012.00063","Srinivas Parthasarathy","Srinivas Parthasarathy and Shiva Sundaram","Detecting expressions with multimodal transformers","IEEE Spoken Language Technology Workshop 2021",,,,"eess.AS cs.SD eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Developing machine learning algorithms to understand person-to-person
engagement can result in natural user experiences for communal devices such as
Amazon Alexa. Among other cues such as voice activity and gaze, a person's
audio-visual expression that includes tone of the voice and facial expression
serves as an implicit signal of engagement between parties in a dialog. This
study investigates deep-learning algorithms for audio-visual detection of
user's expression. We first implement an audio-visual baseline model with
recurrent layers that shows competitive results compared to current state of
the art. Next, we propose the transformer architecture with encoder layers that
better integrate audio-visual features for expressions tracking. Performance on
the Aff-Wild2 database shows that the proposed methods perform better than
baseline architecture with recurrent layers with absolute gains approximately
2% for arousal and valence descriptors. Further, multimodal architectures show
significant improvements over models trained on single modalities with gains of
up to 3.6%. Ablation studies show the significance of the visual modality for
the expression detection on the Aff-Wild2 database.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:31:03 GMT""}]","2020-12-02"
"2012.00064","Mar\'ia Jos\'e Lombard\'ia","M.J. Lombard\'ia, E. L\'opez-Vizca\'ino and C. Rueda","A new approach to the gender pay gap decomposition by economic activity",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  The aim of this paper is to present an original approach to estimate the
gender pay gap. We propose a model-based decomposition, similar to the most
popular approaches, where the first component measures differences in group
characteristics and the second component measures the unexplained effect; the
latter being the real gap. The novel approach incorporates model selection and
bias correction. %, avoiding the main limitation of standard approaches, which
is the dependence on the choice of explanatory variables and the functional
form in regression. The pay gap problem in a small area context is considered
in this paper, although the approach is flexible to be applied to other
contexts.
  Specifically, the methodology is validated for analysing wage differentials
by economic activities in the region of Galicia (Spain) and by analysing
simulated data from an experimental design that imitates the generation of real
data. The good performance of the proposed estimators is shown in both cases,
specifically when compared with those obtained from the widely used
Oaxaca-Blinder approach.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:32:31 GMT""}]","2020-12-02"
"2012.00065","George Lykotrafitis","Yihao Zhang, Zhaojie Chai and George Lykotrafitis","Deep reinforcement learning with a particle dynamics environment applied
  to emergency evacuation of a room with obstacles","30 pages, 8 figures, 6 supplemental figures",,"10.1016/j.physa.2021.125845",,"cs.LG physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  A very successful model for simulating emergency evacuation is the
social-force model. At the heart of the model is the self-driven force that is
applied to an agent and is directed towards the exit. However, it is not clear
if the application of this force results in optimal evacuation, especially in
complex environments with obstacles. Here, we develop a deep reinforcement
learning algorithm in association with the social force model to train agents
to find the fastest evacuation path. During training, we penalize every step of
an agent in the room and give zero reward at the exit. We adopt the Dyna-Q
learning approach. We first show that in the case of a room without obstacles
the resulting self-driven force points directly towards the exit as in the
social force model and that the median exit time intervals calculated using the
two methods are not significantly different. Then, we investigate evacuation of
a room with one obstacle and one exit. We show that our method produces similar
results with the social force model when the obstacle is convex. However, in
the case of concave obstacles, which sometimes can act as traps for agents
governed purely by the social force model and prohibit complete room
evacuation, our approach is clearly advantageous since it derives a policy that
results in object avoidance and complete room evacuation without additional
assumptions. We also study evacuation of a room with multiple exits. We show
that agents are able to evacuate efficiently from the nearest exit through a
shared network trained for a single agent. Finally, we test the robustness of
the Dyna-Q learning approach in a complex environment with multiple exits and
obstacles. Overall, we show that our model can efficiently simulate emergency
evacuation in complex environments with multiple room exits and obstacles where
it is difficult to obtain an intuitive rule for fast evacuation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:34:57 GMT""}]","2021-03-09"
"2012.00066","Viviana Acquaviva","Viviana Acquaviva, Chistopher Lovell, and Emille Ishida","Debunking Generalization Error or: How I Learned to Stop Worrying and
  Love My Training Set","Accepted for 2020 NeurIPS workshop ""Machine Learning and the Physical
  Sciences""; comments welcome!",,,,"astro-ph.IM astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We aim to determine some physical properties of distant galaxies (for
example, stellar mass, star formation history, or chemical enrichment history)
from their observed spectra, using supervised machine learning methods. We know
that different astrophysical processes leave their imprint in various regions
of the spectra with characteristic signatures. Unfortunately, identifying a
training set for this problem is very hard, because labels are not readily
available - we have no way of knowing the true history of how galaxies have
formed. One possible approach to this problem is to train machine learning
models on state-of-the-art cosmological simulations. However, when algorithms
are trained on the simulations, it is unclear how well they will perform once
applied to real data. In this paper, we attempt to model the generalization
error as a function of an appropriate measure of distance between the source
domain and the application domain. Our goal is to obtain a reliable estimate of
how a model trained on simulations might behave on data.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:35:49 GMT""}]","2020-12-02"
"2012.00067","Pablo Luis De N\'apoli","Pablo De N\'apoli and Tiago Picon","Stein-Weiss inequality in $L^{1}$ norm for vector fields",,,,,"math.CA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we investigate the limit case $p=1$ of the classical
Stein--Weiss inequality for the Riesz potential.We present a characterization
for a special class of vector fields associated to cocanceling operators
introduced by Van Schaftingen in arXiv:1104.0192. As an application, we recover
some div-curl inequalities found in the literature. In addition, we discuss a
two-weight inequality with general weights in the scalar case, extending the
previous result of Sawyer to this case.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:36:18 GMT""}]","2020-12-02"
"2012.00068","Iaroslav Ispolatov","Michael Doebeli, Eduardo Cancino Jaque, Iaroslav Ispolatov","Boom-bust population dynamics can increase diversity in evolving
  competitive communities","37 pages, 9 figures",,,,"q-bio.PE cond-mat.dis-nn nlin.CD","http://creativecommons.org/licenses/by/4.0/","  The processes and mechanisms underlying the origin and maintenance of
biological diversity have long been of central importance in ecology and
evolution. The competitive exclusion principle states that the number of
coexisting species is limited by the number of resources, or by the species'
similarity in resource use. Natural systems such as the extreme diversity of
unicellular life in the oceans provide counter examples. It is known that
mathematical models incorporating population fluctuations can lead to
violations of the exclusion principle. Here we use simple eco-evolutionary
models to show that a certain type of population dynamics, boom-bust dynamics,
can allow for the evolution of much larger amounts of diversity than would be
expected with stable equilibrium dynamics. Boom-bust dynamics are characterized
by long periods of almost exponential growth (boom) and a subsequent population
crash due to competition (bust). When such ecological dynamics are incorporated
into an evolutionary model that allows for adaptive diversification in
continuous phenotype spaces, desynchronization of the boom-bust cycles of
coexisting species can lead to the maintenance of high levels of diversity.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:41:11 GMT""}]","2020-12-02"
"2012.00069","Mar\'ia Jos\'e Lombard\'ia","M. Boubeta, M.J. Lombard\'ia, F. Marey-P\'erez and D. Morales","Area-level spatio-temporal Poisson mixed models for predicting domain
  counts and proportions",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  This paper introduces area-level Poisson mixed models with temporal and
SAR(1) spatially correlated random effects. Small area predictors of the
proportions and counts of a dichotomic variable are derived from the new models
and the corresponding mean squared errors are estimated by parametric
bootstrap. The paper illustrates the introduced methodology with two
applications to real data. The first one deals with data of forest fires in
Galicia (Spain) during 2007-2008 and the target is modeling and predicting
counts of fires. The second one treats data from the Spanish living conditions
survey of Galicia of 2013 and the target is the estimation of county
proportions of women under the poverty line.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:44:32 GMT""}]","2020-12-02"
"2012.00070","Marcel Risch","Frederik J. Stender, Keisuke Obata, Max Baumung, Fatwa F. Abdi, Marcel
  Risch","Characterization of a modular flow cell system for electrocatalytic
  experiments and comparison to a commercial RRDE system",,,,,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Generator-collector experiments offer insights into the mechanisms of
electrochemical reactions by correlating the product and generator currents.
Most commonly, these experiments are performed using a rotating ring-disk
electrode (RRDE). We developed a double electrode flow cell (DEFC) with
exchangeable generator and detector electrodes where the electrode width equals
the channel width. Commonalities and differences between the RRDE and DEFC are
discussed based on analytical solutions, numerical simulations and measurements
of the ferri-/ferrocyanide redox couple on Pt electrodes in a potassium
chloride electrolyte. The analytical solutions agree with the measurements
using electrode widths of 5 and 2 mm. Yet, we find an unexpected dependence on
the exponent of the width so that wider electrodes cannot be analysed using the
conventional analytical solution. In contrast, all the investigated electrodes
show a collection efficiency of close to 35.4% above a minimum rotation speed
or flow rate, where the narrowest electrode is most accurate at the cost of
precision and the widest electrode the least accurate but most precise. Our
DEFC with exchangeable electrodes is an attractive alternative to commercial
RRDEs due to the flexibility to optimize the electrode materials and geometry
for the desired reaction.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:44:57 GMT""}]","2020-12-02"
"2012.00071","Yunfu Ou","Yunfu Ou, Carlos Gonz\'alez, Juan Jos\'e Vilatela","Understanding interlaminar toughening of unidirectional CFRP laminates
  with carbon nanotube veils","27 pages, 10 figures, 1 table","Composites Part B: Engineering , 201: 108372, 2020","10.1016/j.compositesb.2020.108372",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The introduction of nanostructured interlayers is one of the most promising
strategies for interlaminar reinforcement in structural composites. In this
work, we study the failure mechanism and interlayer microstructure of
aerospace-grade structural composites reinforced with thin veils of carbon
nanotube produced using an industrialised spinning process. Samples of
unidirectional carbon fibre/epoxy matrix composites interleaved with different
composition CNT veils were prepared using hot press method and tested for
interlaminar fracture toughness (IFT), measured in Mode-I (opening) and Mode-II
(in-plane shear), and for interlaminar shear strength (ILSS), evaluated by the
short beam shear (SBS) test. The crack propagation mode could be directly
determined through fractography analysis by electron microscopy and resin/CNT
spatial discrimination by Raman spectroscopy, showing a clear correlation
between interlaminar reinforcement and the balance between cohesive/adhesive
failure mode at the interlayer region. Composites with full resin infiltration
of the CNT veils give a large increase of Mode II IFT (88%) to 1500 J/m2 and a
slight enhancement of apparent interlaminar shear strength (6.5%), but a
decrease of Mode I IFT (-21%). The results help establish the role of
interlayer infiltration, interlaminar crossings and formation of a carbon fibre
bridgings, for interlaminar reinforcement with interleaves.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:46:36 GMT""}]","2020-12-02"
"2012.00072","Jay Lennon","Jay T. Lennon, Frank den Hollander, Maite Wilke-Berenguer, Jochen
  Blath","Principles of seed banks: complexity emerging from dormancy","60 pages, 2 figures, 6 boxes",,,,"q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  Across the tree of life, populations have evolved the capacity to contend
with suboptimal conditions by engaging in dormancy, whereby individuals enter a
reversible state of reduced metabolic activity. The resulting seed banks are
complex, storing information and imparting memory that gives rise to
multi-scale structures and networks spanning collections of cells to entire
ecosystems. We outline the fundamental attributes and emergent phenomena
associated with dormancy and seed banks, with the vision for a unifying and
mathematically based framework that can address problems in the life sciences,
ranging from global change to cancer biology.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:47:24 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 13:42:02 GMT""}]","2021-05-07"
"2012.00073","Pedro Saleiro","Jo\~ao Bento, Pedro Saleiro, Andr\'e F. Cruz, M\'ario A.T. Figueiredo,
  Pedro Bizarro","TimeSHAP: Explaining Recurrent Models through Sequence Perturbations","Accepted at KDD 2021",,"10.1145/3447548.3467166",,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although recurrent neural networks (RNNs) are state-of-the-art in numerous
sequential decision-making tasks, there has been little research on explaining
their predictions. In this work, we present TimeSHAP, a model-agnostic
recurrent explainer that builds upon KernelSHAP and extends it to the
sequential domain. TimeSHAP computes feature-, timestep-, and cell-level
attributions. As sequences may be arbitrarily long, we further propose a
pruning method that is shown to dramatically decrease both its computational
cost and the variance of its attributions. We use TimeSHAP to explain the
predictions of a real-world bank account takeover fraud detection RNN model,
and draw key insights from its explanations: i) the model identifies important
features and events aligned with what fraud analysts consider cues for account
takeover; ii) positive predicted sequences can be pruned to only 10% of the
original length, as older events have residual attribution values; iii) the
most recent input event of positive predictions only contributes on average to
41% of the model's score; iv) notably high attribution to client's age,
suggesting a potential discriminatory reasoning, later confirmed as higher
false positive rates for older clients.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:48:57 GMT""},{""version"":""v2"",""created"":""Sat, 26 Jun 2021 09:59:18 GMT""}]","2021-06-29"
"2012.00074","Jing Luo","Jing Luo, Scott Ransom, Paul Demorest, Paul S. Ray, Anne Archibald,
  Matthew Kerr, Ross J. Jennings, Matteo Bachetti, Rutger van Haasteren, Chloe
  A. Champagne, Jonathan Colen, Camryn Phillips, Josef Zimmerman, Kevin
  Stovall, Michael T. Lam and Fredrick A. Jenet","PINT: A Modern Software Package for Pulsar Timing","Re-submitted to the Astrophysical Journal at December 31st, 2020",,"10.3847/1538-4357/abe62f",,"astro-ph.IM","http://creativecommons.org/publicdomain/zero/1.0/","  Over the past few decades, the measurement precision of some pulsar-timing
experiments has advanced from ~10 us to ~10 ns, revealing many subtle
phenomena. Such high precision demands both careful data handling and
sophisticated timing models to avoid systematic error. To achieve these goals,
we present PINT (PINT Is Not Tempo3), a high-precision Python pulsar timing
data analysis package, which is hosted on GitHub and available on Python
Package Index (PyPI) as pint-pulsar. PINT is well-tested, validated,
object-oriented, and modular, enabling interactive data analysis and providing
an extensible and flexible development platform for timing applications. It
utilizes well-debugged public Python packages (e.g., the NumPy and Astropy
libraries) and modern software development schemes (e.g., version control and
efficient development with git and GitHub) and a continually expanding test
suite for improved reliability, accuracy, and reproducibility. PINT is
developed and implemented without referring to, copying, or transcribing the
code from other traditional pulsar timing software packages (e.g., TEMPO and
TEMPO2) and therefore provides a robust tool for cross-checking timing analyses
and simulating pulse arrival times. In this paper, we describe the design,
usage, and validation of PINT, and we compare timing results between it and
TEMPO and TEMPO2.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:50:54 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 22:15:30 GMT""}]","2021-04-21"
"2012.00075","Yunelsy N Alvarez","Yunelsy N Alvarez","Prescribing the curvature to Killing Graphs","20 pages",,,,"math.DG math.AP","http://creativecommons.org/licenses/by/4.0/","  In this work we prove the existence and uniqueness of Killing graphs with
prescribed mean curvature considering functions which are not necessarily
constant along the flow lines of the Killing vector field.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:58:29 GMT""}]","2020-12-02"
"2012.00076","Ehsan Samani","Ehsan Samani and Hamed Mohsenian-Rad","A Data-Driven Study to Discover, Characterize, and Classify Convergence
  Bidding Strategies in California ISO Energy Market",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convergence bidding has been adopted in recent years by most Independent
System Operators (ISOs) in the United States as a relatively new market
mechanism to enhance market efficiency. Convergence bidding affects many
aspects of the operation of the electricity markets and there is currently a
gap in the literature on understanding how the market participants
strategically select their convergence bids in practice. To address this open
problem, in this paper, we study three years of real-world market data from the
California ISO energy market. First, we provide a data-driven overview of all
submitted convergence bids (CBs) and analyze the performance of each individual
convergence bidder based on the number of their submitted CBs, the number of
locations that they placed the CBs, the percentage of submitted supply or
demand CBs, the amount of cleared CBs, and their gained profit or loss. Next,
we scrutinize the bidding strategies of the 13 largest market players that
account for 75\% of all CBs in the California ISO market. We identify
quantitative features to characterize and distinguish their different
convergence bidding strategies. This analysis results in revealing three
different classes of CB strategies that are used in practice. We identify the
differences between these strategic bidding classes and compare their
advantages and disadvantages. We also explain how some of the most active
market participants are using bidding strategies that do not match any of the
strategic bidding methods that currently exist in the literature.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:01:45 GMT""}]","2020-12-02"
"2012.00077","Anusha Lalitha","Anusha Lalitha and Tara Javidi","On Error Exponents of Almost-Fixed-Length Channel Codes and Hypothesis
  Tests",,,,,"cs.IT math.IT stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine a new class of channel coding strategies, and hypothesis tests
referred to as almost-fixed-length strategies that have little flexibility in
the stopping time over fixed-length strategies. The stopping time of these
strategies is allowed to be slightly large only on a rare set of sample paths
with an exponentially small probability. We show that almost-fixed-length
channel coding strategies can achieve Burnashev's optimal error exponent.
Similarly, almost-fixed length hypothesis tests are shown to bridge the gap
between hypothesis testing with fixed sample size and sequential hypothesis
testing and improve the trade-off between type-I and type-II error exponents.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:01:58 GMT""}]","2020-12-02"
"2012.00078","Zachary Taschdjian","Zachary Taschdjian","Why Did the Robot Cross the Road? A User Study of Explanation in
  Human-Robot Interaction",,,,,"cs.HC cs.AI cs.RO","http://creativecommons.org/licenses/by/4.0/","  This work documents a pilot user study evaluating the effectiveness of
contrastive, causal and example explanations in supporting human understanding
of AI in a hypothetical commonplace human robot interaction HRI scenario. In
doing so, this work situates explainable AI XAI in the context of the social
sciences and suggests that HRI explanations are improved when informed by the
social sciences.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:02:19 GMT""}]","2020-12-02"
"2012.00079","Micha{\l} Pilipczuk","Eduard Eiben and Robert Ganian and Du\v{s}an Knop and Sebastian
  Ordyniak and Micha{\l} Pilipczuk and Marcin Wrochna","Integer Programming and Incidence Treedepth","11 pages, 1 figure. This is an extended version of an article that
  appeared at IPCO 2019",,,,"cs.CC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently a strong connection has been shown between the tractability of
integer programming (IP) with bounded coefficients on the one side and the
structure of its constraint matrix on the other side. To that end, integer
linear programming is fixed-parameter tractable with respect to the primal (or
dual) treedepth of the Gaifman graph of its constraint matrix and the largest
coefficient (in absolute value). Motivated by this, Kouteck\'y, Levin, and Onn
[ICALP 2018] asked whether it is possible to extend these result to a more
broader class of integer linear programs. More formally, is integer linear
programming fixed-parameter tractable with respect to the incidence treedepth
of its constraint matrix and the largest coefficient (in absolute value)?
  We answer this question in negative. In particular, we prove that deciding
the feasibility of a system in the standard form, ${A\mathbf{x} = \mathbf{b}},
{\mathbf{l} \le \mathbf{x} \le \mathbf{u}}$, is $\mathsf{NP}$-hard even when
the absolute value of any coefficient in $A$ is 1 and the incidence treedepth
of $A$ is 5. Consequently, it is not possible to decide feasibility in
polynomial time even if both the assumed parameters are constant, unless
$\mathsf{P}=\mathsf{NP}$. Moreover, we complement this intractability result by
showing tractability for natural and only slightly more restrictive settings,
namely: (1) treedepth with an additional bound on either the maximum arity of
constraints or the maximum number of occurrences of variables and (2) the
vertex cover number.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:03:11 GMT""}]","2020-12-02"
"2012.00080","Stephen Kane","Stephen R. Kane, Tiffany Jansen, Thomas Fauchez, Franck Selsis, Alma
  Y. Ceja","Phase Modeling of the TRAPPIST-1 Planetary Atmospheres","14 pages, 6 figures, 2 tables, accepted for publication in the
  Astronomical Journal",,"10.3847/1538-3881/abcfbe",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transiting compact multi-planet systems provide many unique opportunities to
characterize the planets, including studies of size distributions, mean
densities, orbital dynamics, and atmospheric compositions. The relatively short
orbital periods in these systems ensure that events requiring specific orbital
locations of the planets (such as primary transit and secondary eclipse points)
occur with high frequency. The orbital motion and associated phase variations
of the planets provide a means to constrain the atmospheric compositions
through measurement of their albedos. Here we describe the expected phase
variations of the TRAPPIST-1 system and times of superior conjunction when the
summation of phase effects produce maximum amplitudes. We also describe the
infrared flux emitted by the TRAPPIST-1 planets and the influence on the
overall phase amplitudes. We further present the results from using the global
circulation model ROCKE-3D to model the atmospheres of TRAPPIST-1e and
TRAPPIST-1f assuming modern Earth and Archean atmospheric compositions. These
simulations are used to calculate predicted phase curves for both reflected
light and thermal emission components. We discuss the detectability of these
signatures and the future prospects for similar studies of phase variations for
relatively faint M stars.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:05:48 GMT""},{""version"":""v2"",""created"":""Thu, 24 Dec 2020 08:18:51 GMT""}]","2021-01-13"
"2012.00081","Jannik Schaller","Florian Meinfelder and Jannik Schaller","Data Fusion for Joining Income and Consumption Information Using
  Different Donor-Recipient Distance Metrics",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data fusion describes the method of combining data from (at least) two
initially independent data sources to allow for joint analysis of variables
which are not jointly observed. The fundamental idea is to base inference on
identifying assumptions, and on common variables which provide information that
is jointly observed in all the data sources. A popular class of methods dealing
with this particular missing-data problem is based on nearest neighbour
matching. However, exact matches become unlikely with increasing common
information, and the specification of the distance function can influence the
results of the data fusion. In this paper we compare two different approaches
of nearest neighbour hot deck matching: One, Random Hot Deck, is a variant of
the covariate-based matching methods which was proposed by Eurostat, and can be
considered as a 'classical' statistical matching method, whereas the
alternative approach is based on Predictive Mean Matching. We discuss results
from a simulation study to investigate benefits and potential drawbacks of both
variants, and our findings suggest that Predictive Mean Matching tends to
outperform Random Hot Deck.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:10:40 GMT""}]","2020-12-02"
"2012.00082","Lingxiao Wang","Lingxiao Wang, Tian Xu, Till Hannes Stoecker, Horst Stoecker, Yin
  Jiang and Kai Zhou","Machine learning spatio-temporal epidemiological model to evaluate
  Germany-county-level COVID-19 risk","17 pages, 13 figures, comments welcome!",,,,"physics.soc-ph cs.LG physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  As the COVID-19 pandemic continues to ravage the world, it is of critical
significance to provide a timely risk prediction of the COVID-19 in
multi-level. To implement it and evaluate the public health policies, we
develop a framework with machine learning assisted to extract epidemic dynamics
from the infection data, in which contains a county-level spatiotemporal
epidemiological model that combines a spatial Cellular Automaton (CA) with a
temporal Susceptible-Undiagnosed-Infected-Removed (SUIR) model. Compared with
the existing time risk prediction models, the proposed CA-SUIR model shows the
multi-level risk of the county to the government and coronavirus transmission
patterns under different policies. This new toolbox is first utilized to the
projection of the multi-level COVID-19 prevalence over 412 Landkreis (counties)
in Germany, including t-day-ahead risk forecast and the risk assessment to the
travel restriction policy. As a practical illustration, we predict the
situation at Christmas where the worst fatalities are 34.5 thousand, effective
policies could contain it to below 21 thousand. Such intervenable evaluation
system could help decide on economic restarting and public health policies
making in pandemic.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:17:19 GMT""}]","2020-12-02"
"2012.00083","Saulo Martiello Mastelini","Saulo Martiello Mastelini, Andre Carlos Ponce de Leon Ferreira de
  Carvalho","Using dynamical quantization to perform split attempts in online tree
  regressors","Under consideration at Pattern Recognition Letters. The version sent
  to the journal was slightly modified to conform to the page limit",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A central aspect of online decision tree solutions is evaluating the incoming
data and enabling model growth. For such, trees much deal with different kinds
of input features and partition them to learn from the data. Numerical features
are no exception, and they pose additional challenges compared to other kinds
of features, as there is no trivial strategy to choose the best point to make a
split decision. The problem is even more challenging in regression tasks
because both the features and the target are continuous. Typical online
solutions evaluate and store all the points monitored between split attempts,
which goes against the constraints posed in real-time applications. In this
paper, we introduce the Quantization Observer (QO), a simple yet effective
hashing-based algorithm to monitor and evaluate split point candidates in
numerical features for online tree regressors. QO can be easily integrated into
incremental decision trees, such as Hoeffding Trees, and it has a monitoring
cost of $O(1)$ per instance and sub-linear cost to evaluate split candidates.
Previous solutions had a $O(\log n)$ cost per insertion (in the best case) and
a linear cost to evaluate split points. Our extensive experimental setup
highlights QO's effectiveness in providing accurate split point suggestions
while spending much less memory and processing time than its competitors.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:25:38 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 13:13:59 GMT""}]","2020-12-04"
"2012.00084","Roberto Giovanni Ram\'irez-Chavarr\'ia","Roberto G. Ram\'irez-Chavarr\'ia, Celia S\'anchez-P\'erez, Luisa
  Romero-Ornelas and Eva Ram\'on-Gallegos","Time-Constant-Domain Spectroscopy: An Impedance-based Method for Sensing
  Biological Cells in Suspension","8 pages, 6 figures",,"10.1109/JSEN.2020.3014569",,"physics.ins-det eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Impedance measurement is a common technique to characterize and detect the
electrical properties of biological cells. However, to decode the underlying
physical processes, it requires complex electrical models alongside prior
knowledge of the sample under study. In this work, we introduce an attractive
label-free method for sensing biological cells in suspension based on the
measurement of electrical impedance and the distribution of relaxation times
(DRT) model. The DRT maps impedance data from the frequency-domain to a
time-constant-domain spectrum (TCDS) being a useful and robust method for data
analysis. We perform impedance measurements in the range from 1 kHz to 1 MHz to
obtain the TCDS for sensing mimic samples as well as HeLa cells in suspension.
Results show that the TCDS can be seen as an electrical fingerprint for the
sample, as it can decode useful information about the composition and structure
with high sensitivity and resolution.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:32:14 GMT""}]","2020-12-02"
"2012.00085","Otavio Henrique Perez","Otavio Henrique Perez and Paulo Ricardo da Silva","Resolution of singularities of 2-dimensional real analytic constrained
  differential systems","35 pages, 12 figures",,,,"math.DS","http://creativecommons.org/publicdomain/zero/1.0/","  We present a theorem of resolution of singularities for real analytic
constrained differential systems $A(x)\dot{x} = F(x)$ defined on a 2-manifold
with corners having impasse set $\{x; \det A(x) = 0\}$. This result can be seen
as a generalization of the classical one for 2-dimensional real analytic vector
fields. Our proof is based on weighted blow-ups and the Newton polygon.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:38:08 GMT""}]","2020-12-02"
"2012.00086","Federica Cecchetto","Federica Cecchetto and Vera Traub and Rico Zenklusen","Bridging the Gap Between Tree and Connectivity Augmentation: Unified and
  Stronger Approaches",,,,,"cs.DS math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Connectivity Augmentation Problem (CAP), a classical problem
in the area of Survivable Network Design. It is about increasing the
edge-connectivity of a graph by one unit in the cheapest possible way. More
precisely, given a $k$-edge-connected graph $G=(V,E)$ and a set of extra edges,
the task is to find a minimum cardinality subset of extra edges whose addition
to $G$ makes the graph $(k+1)$-edge-connected. If $k$ is odd, the problem is
known to reduce to the Tree Augmentation Problem (TAP) -- i.e., $G$ is a
spanning tree -- for which significant progress has been achieved recently,
leading to approximation factors below $1.5$ (the currently best factor is
$1.458$). However, advances on TAP did not carry over to CAP so far. Indeed,
only very recently, Byrka, Grandoni, and Ameli (STOC 2020) managed to obtain
the first approximation factor below $2$ for CAP by presenting a
$1.91$-approximation algorithm based on a method that is disjoint from recent
advances for TAP.
  We first bridge the gap between TAP and CAP, by presenting techniques that
allow for leveraging insights and methods from TAP to approach CAP. We then
introduce a new way to get approximation factors below $1.5$, based on a new
analysis technique. Through these ingredients, we obtain a
$1.393$-approximation algorithm for CAP, and therefore also TAP. This leads to
the currently best approximation result for both problems in a unified way, by
significantly improving on the above-mentioned $1.91$-approximation for CAP and
also the previously best approximation factor of $1.458$ for TAP by Grandoni,
Kalaitzis, and Zenklusen (STOC 2018). Additionally, a feature we inherit from
recent TAP advances is that our approach can deal with the weighted setting
when the ratio between the largest to smallest cost on extra links is bounded,
in which case we obtain approximation factors below $1.5$.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:40:53 GMT""},{""version"":""v2"",""created"":""Tue, 12 Apr 2022 10:56:49 GMT""},{""version"":""v3"",""created"":""Wed, 23 Nov 2022 10:44:00 GMT""}]","2022-11-24"
"2012.00088","Qihao Liu","Qihao Liu, Weichao Qiu, Weiyao Wang, Gregory D. Hager, Alan L. Yuille","Nothing But Geometric Constraints: A Model-Free Method for Articulated
  Object Pose Estimation","10 pages, 3 figures",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an unsupervised vision-based system to estimate the joint
configurations of the robot arm from a sequence of RGB or RGB-D images without
knowing the model a priori, and then adapt it to the task of
category-independent articulated object pose estimation. We combine a classical
geometric formulation with deep learning and extend the use of epipolar
constraint to multi-rigid-body systems to solve this task. Given a video
sequence, the optical flow is estimated to get the pixel-wise dense
correspondences. After that, the 6D pose is computed by a modified PnP
algorithm. The key idea is to leverage the geometric constraints and the
constraint between multiple frames. Furthermore, we build a synthetic dataset
with different kinds of robots and multi-joint articulated objects for the
research of vision-based robot control and robotic vision. We demonstrate the
effectiveness of our method on three benchmark datasets and show that our
method achieves higher accuracy than the state-of-the-art supervised methods in
estimating joint angles of robot arms and articulated objects.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:46:48 GMT""}]","2020-12-02"
"2012.00089","Jorge Kamassury","Jorge Kysnney Santos Kamassury and Danilo Silva","Iterative Error Decimation for Syndrome-Based Neural Network Decoders","To appear in Journal of Communication and Information Systems","Journal of Communication and Information Systems, 36 (2021)
  151-155","10.14209/jcis.2021.16",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this letter, we introduce a new syndrome-based decoder where a deep neural
network (DNN) estimates the error pattern from the reliability and syndrome of
the received vector. The proposed algorithm works by iteratively selecting the
most confident positions to be the error bits of the error pattern, updating
the vector received when a new position of the error pattern is selected.
Simulation results for the (63,45) and (63,36) BCH codes show that the proposed
approach outperforms existing neural network decoders. In addition, the new
decoder is flexible in that it can be applied on top of any existing
syndrome-based DNN decoder without retraining.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:53:03 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 17:38:22 GMT""},{""version"":""v3"",""created"":""Mon, 23 Aug 2021 13:21:33 GMT""},{""version"":""v4"",""created"":""Sat, 28 Aug 2021 21:09:39 GMT""}]","2021-08-31"
"2012.00090","Valtteri Lindholm","Valtteri Lindholm, Alexis Finoguenov, Johan Comparat, Charles C.
  Kirkpatrick, Eli Rykoff, Nicolas Clerc, Chris Collins, Sanna Damsted, Jacob
  Ider Chitham, Nelson Padilla","Clustering of CODEX clusters","13 pages, 15 figures","A&A 646, A8 (2021)","10.1051/0004-6361/202038807",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Aims. We analyze the autocorrelation function of a large contiguous sample of
galaxy clusters, the Constrain Dark Energy with X-ray (CODEX) sample, in which
we take particular care of cluster definition. These clusters were X-ray
selected using the RASS survey and then identified as galaxy clusters using the
code redMaPPer run on the photometry of the SDSS. We develop methods for
precisely accounting for the sample selection effects on the clustering and
demonstrate their robustness using numerical simulations. Methods. Using the
clean CODEX sample, which was obtained by applying a redshift-dependent
richness selection, we computed the two-point autocorrelation function of
galaxy clusters in the $0.1<z<0.3$ and $0.3<z<0.5$ redshift bins. We compared
the bias in the measured correlation function with values obtained in numerical
simulations using a similar cluster mass range. Results. By fitting a power
law, we measured a correlation length $r_0=18.7 \pm 1.1$ and slope $\gamma=1.98
\pm 0.14$ for the correlation function in the full redshift range. By fixing
the other cosmological parameters to their WMAP9 values, we reproduced the
observed shape of the correlation function under the following cosmological
conditions: $\Omega_{m_0}=0.22^{+0.04}_{-0.03}$ and $S_8=\sigma_8 (\Omega_{m_0}
/0.3)^{0.5}=0.85^{+0.10}_{-0.08}$ with estimated additional systematic errors
of $\sigma_{\Omega_{m_0}} = 0.02$ and $\sigma_{S_8} = 0.20$. We illustrate the
complementarity of clustering constraints by combining them with CODEX
cosmological constraints based on the X-ray luminosity function, deriving
$\Omega_{m_0} = 0.25 \pm 0.01$ and $\sigma_8 = 0.81^{+0.01}_{-0.02}$ with an
estimated additional systematic error of $\sigma_{\Omega_{m_0}} = 0.07$ and
$\sigma_{\sigma_8} = 0.04$. The mass calibration and statistical quality of the
mass tracers are the dominant source of uncertainty.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:53:08 GMT""}]","2022-05-24"
"2012.00091","Barbara Ilse Mahler","Barbara I. Mahler","Contagion Dynamics for Manifold Learning","33 pages, 23 figures",,,,"stat.ML cs.LG math.AT","http://creativecommons.org/licenses/by/4.0/","  Contagion maps exploit activation times in threshold contagions to assign
vectors in high-dimensional Euclidean space to the nodes of a network. A point
cloud that is the image of a contagion map reflects both the structure
underlying the network and the spreading behaviour of the contagion on it.
Intuitively, such a point cloud exhibits features of the network's underlying
structure if the contagion spreads along that structure, an observation which
suggests contagion maps as a viable manifold-learning technique. We test
contagion maps as a manifold-learning tool on a number of different real-world
and synthetic data sets, and we compare their performance to that of Isomap,
one of the most well-known manifold-learning algorithms. We find that, under
certain conditions, contagion maps are able to reliably detect underlying
manifold structure in noisy data, while Isomap fails due to noise-induced
error. This consolidates contagion maps as a technique for manifold learning.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:58:21 GMT""}]","2020-12-02"
"2012.00093","J\""urgen Dieber","J\""urgen Dieber, Sabrina Kirrane","Why model why? Assessing the strengths and limitations of LIME","13 pages, 4 figures",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  When it comes to complex machine learning models, commonly referred to as
black boxes, understanding the underlying decision making process is crucial
for domains such as healthcare and financial services, and also when it is used
in connection with safety critical systems such as autonomous vehicles. As such
interest in explainable artificial intelligence (xAI) tools and techniques has
increased in recent years. However, the effectiveness of existing xAI
frameworks, especially concerning algorithms that work with data as opposed to
images, is still an open research question. In order to address this gap, in
this paper we examine the effectiveness of the Local Interpretable
Model-Agnostic Explanations (LIME) xAI framework, one of the most popular model
agnostic frameworks found in the literature, with a specific focus on its
performance in terms of making tabular models more interpretable. In
particular, we apply several state of the art machine learning algorithms on a
tabular dataset, and demonstrate how LIME can be used to supplement
conventional performance assessment methods. In addition, we evaluate the
understandability of the output produced by LIME both via a usability study,
involving participants who are not familiar with LIME, and its overall
usability via an assessment framework, which is derived from the International
Organisation for Standardisation 9241-11:1998 standard.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:08:07 GMT""}]","2020-12-02"
"2012.00095","Peter Persoon","P.G.J. Persoon, R.N.A. Bekkers, F. Alkemade","How cumulative is technological knowledge?",,,,,"cs.SI econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Technological cumulativeness is considered one of the main mechanisms for
technological progress, yet its exact meaning and dynamics often remain
unclear. To develop a better understanding of this mechanism we approach a
technology as a body of knowledge consisting of interlinked inventions.
Technological cumulativeness can then be understood as the extent to which
inventions build on other inventions within that same body of knowledge. The
cumulativeness of a technology is therefore characterized by the structure of
its knowledge base, which is different from, but closely related to, the size
of its knowledge base. We analytically derive equations describing the relation
between the cumulativeness and the size of the knowledge base. In addition, we
empirically test our ideas for a number of selected technologies, using patent
data. Our results suggest that cumulativeness increases proportionally with the
size of the knowledge base, at a rate which varies considerably across
technologies. At the same time we find that across technologies, this rate is
inversely related to the rate of invention over time. This suggests that the
cumulativeness increases relatively slow in rapidly growing technologies. In
sum, the presented approach allows for an in-depth, systematic analysis of
cumulativeness variations across technologies and the knowledge dynamics
underlying technology development.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:10:59 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 13:36:07 GMT""}]","2021-05-05"
"2012.00096","Arnhav Datar","Amish Mittal, Sourav Sahoo, Arnhav Datar, Juned Kadiwala, Hrithwik
  Shalu and Jimson Mathew","Multi-Modal Detection of Alzheimer's Disease from Speech and Text","9 pages, 3 figures, Accepted in BIOKDD 2021",,,,"cs.LG cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reliable detection of the prodromal stages of Alzheimer's disease (AD)
remains difficult even today because, unlike other neurocognitive impairments,
there is no definitive diagnosis of AD in vivo. In this context, existing
research has shown that patients often develop language impairment even in mild
AD conditions. We propose a multimodal deep learning method that utilizes
speech and the corresponding transcript simultaneously to detect AD. For audio
signals, the proposed audio-based network, a convolutional neural network (CNN)
based model, predicts the diagnosis for multiple speech segments, which are
combined for the final prediction. Similarly, we use contextual embedding
extracted from BERT concatenated with a CNN-generated embedding for classifying
the transcript. The individual predictions of the two models are then combined
to make the final classification. We also perform experiments to analyze the
model performance when Automated Speech Recognition (ASR) system generated
transcripts are used instead of manual transcription in the text-based model.
The proposed method achieves 85.3% 10-fold cross-validation accuracy when
trained and evaluated on the Dementiabank Pitt corpus.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:18:17 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jun 2021 14:44:57 GMT""},{""version"":""v3"",""created"":""Sat, 31 Jul 2021 13:37:22 GMT""}]","2021-08-03"
"2012.00097","Krzysztof \'Swi\k{e}cicki","Krzysztof \'Swi\k{e}cicki","There is no equivariant coarse embedding of $L_{p}$ into $\ell_p$",,,,,"math.MG math.FA math.GR","http://creativecommons.org/licenses/by/4.0/","  In this paper we prove that $L_{p}$ does not admit an equivariant coarse
embedding into $\ell_p$ i.e there is no proper, affine, isometric action of
$L_{p}$, viewed as a group under addition with the standard metric $|| . ||_p$,
on $\ell_p$. This is done by showing that representations of $L_{p}$ into $
Isom(\ell_p)$ has to be trivial, which allows us to reduce the question to
bi-Lipschitz setting.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:18:41 GMT""}]","2020-12-02"
"2012.00098","Andrew Kosenko","Andrew Kosenko","Mediated Persuasion",,,,,"econ.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study a game of strategic information design between a sender, who chooses
state-dependent information structures, a mediator who can then garble the
signals generated from these structures, and a receiver who takes an action
after observing the signal generated by the first two players. We characterize
sufficient conditions for information revelation, compare outcomes with and
without a mediator and provide comparative statics with regard to the
preferences of the sender and the mediator. We also provide novel conceptual
and computational insights about the set of feasible posterior beliefs that the
sender can induce, and use these results to obtain insights about equilibrium
outcomes. The sender never benefits from mediation, while the receiver might.
Strikingly, the receiver benefits when the mediator's preferences are not
perfectly aligned with hers; rather the mediator should prefer more information
revelation than the sender, but less than perfect revelation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:20:01 GMT""},{""version"":""v2"",""created"":""Fri, 4 Dec 2020 18:39:11 GMT""}]","2020-12-07"
"2012.00099","Elise Darragh-Ford","Elise Darragh-Ford, Ethan O. Nadler, Sean McLaughlin, Risa H. Wechsler","Searching for Dwarf Galaxies in ${\it Gaia}$ DR2 Phase-Space Data Using
  Wavelet Transforms","17 pages, 10 figures, 3 tables; submitted to ApJ. Candidate lists
  available at https://dwarfswaves.github.io. Updated to published version","ApJ 915 48 (2021)","10.3847/1538-4357/ac0053","SLAC-PUB-17614","astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a wavelet-based algorithm to identify dwarf galaxies in the Milky
Way in ${\it Gaia}$ DR2 data. Our algorithm detects overdensities in 4D
position--proper motion space, making it the first search to explicitly use
velocity information to search for dwarf galaxy candidates. We optimize our
algorithm and quantify its performance by searching for mock dwarfs injected
into ${\it Gaia}$ DR2 data and for known Milky Way satellite galaxies.
Comparing our results with previous photometric searches, we find that our
search is sensitive to undiscovered systems at Galactic latitudes~$\lvert
b\rvert>20^{\circ}$ and with half-light radii larger than the 50% detection
efficiency threshold for Pan-STARRS1 (PS1) at (${\it i}$) absolute magnitudes
of =$-7<M_V<-3$ and distances of $32$ kpc $< D < 64$ kpc, and (${\it ii}$)
$M_V< -4$ and $64$ kpc $< D < 128$ kpc. Based on these results, we predict that
our search is expected to discover $5 \pm 2$ new satellite galaxies: four in
the PS1 footprint and one outside the Dark Energy Survey and PS1 footprints. We
apply our algorithm to the ${\it Gaia}$ DR2 dataset and recover $\sim 830$
high-significance candidates, out of which we identify a ""gold standard"" list
of $\sim 200$ candidates based on cross-matching with potential candidates
identified in a preliminary search using ${\it Gaia}$ EDR3 data. All of our
candidate lists are publicly distributed for future follow-up studies. We show
that improvements in astrometric measurements provided by ${\it Gaia}$ EDR3
increase the sensitivity of this technique; we plan to continue to refine our
candidate list using future data releases.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:20:43 GMT""},{""version"":""v2"",""created"":""Wed, 14 Jul 2021 15:49:05 GMT""}]","2021-07-15"
"2012.00100","Edgard Rivera-Valent\'in","Edgard G. Rivera-Valent\'in, Vincent F. Chevrier, Alejandro Soto,
  Germ\'an Mart\'inez","Distribution and habitability of (meta)stable brines on present-day Mars",,"Rivera-Valentin, E. G., Chevrier, V. F., Soto, A., Martinez, G.
  (2020) Distribution and habitability of (meta)stable brines on present-day
  Mars. Nat Astron 4, 756-761","10.1038/s41550-020-1080-9",,"astro-ph.EP physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  Special Regions on Mars are defined as environments able to host liquid water
that meets certain temperature and water activity requirements that allow known
terrestrial organisms to replicate, and therefore could be habitable. Such
regions would be a concern for planetary protection policies owing to the
potential for forward contamination (biological contamination from Earth). Pure
liquid water is unstable on the Martian surface, but brines may be present.
Experimental work has shown that brines persist beyond their predicted
stability region, leading to metastable liquids. Here we show that (meta)stable
brines can form and persist from the equator to high latitudes on the surface
of Mars for a few percent of the year for up to six consecutive hours, a
broader range than previously thought. However, only the lowest eutectic
solutions can form, leading to brines with temperatures of less than 225 K. Our
results indicate that (meta)stable brines on the Martian surface and shallow
subsurface (a few centimeters deep) are not habitable because their water
activities and temperatures fall outside the known tolerances for terrestrial
life. Furthermore, (meta)stable brines do not meet the Special Regions
requirements, reducing the risk for forward contamination and easing threats
related to the exploration of the Martian surface.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:23:21 GMT""}]","2020-12-02"
"2012.00101","Abhinav Anand","Abhinav Anand, Matthias Degroote, and Al\'an Aspuru-Guzik","Natural Evolutionary Strategies for Variational Quantum Computation",,,"10.1088/2632-2153/abf3ac",,"quant-ph cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Natural evolutionary strategies (NES) are a family of gradient-free black-box
optimization algorithms. This study illustrates their use for the optimization
of randomly-initialized parametrized quantum circuits (PQCs) in the region of
vanishing gradients. We show that using the NES gradient estimator the
exponential decrease in variance can be alleviated. We implement two specific
approaches, the exponential and separable natural evolutionary strategies, for
parameter optimization of PQCs and compare them against standard gradient
descent. We apply them to two different problems of ground state energy
estimation using variational quantum eigensolver (VQE) and state preparation
with circuits of varying depth and length. We also introduce batch optimization
for circuits with larger depth to extend the use of evolutionary strategies to
a larger number of parameters. We achieve accuracy comparable to
state-of-the-art optimization techniques in all the above cases with a lower
number of circuit evaluations. Our empirical results indicate that one can use
NES as a hybrid tool in tandem with other gradient-based methods for
optimization of deep quantum circuits in regions with vanishing gradients.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:23:38 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 17:15:50 GMT""}]","2021-04-01"
"2012.00102","Aqeeb Iqbal Arka","Aqeeb Iqbal Arka, Biresh Kumar Joardar, Ryan Gary Kim, Dae Hyun Kim,
  Janardhan Rao Doppa, and Partha Pratim Pande","HeM3D: Heterogeneous Manycore Architecture Based on Monolithic 3D
  Vertical Integration","This work has been accepted in ACM Transactions on Design Automation
  of Electronic Systems",,"10.1145/3424239",,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heterogeneous manycore architectures are the key to efficiently execute
compute- and data-intensive applications. Through silicon via (TSV)-based 3D
manycore system is a promising solution in this direction as it enables
integration of disparate computing cores on a single system. However, the
achievable performance of conventional through-silicon-via (TSV)-based 3D
systems is ultimately bottlenecked by the horizontal wires (wires in each
planar die). Moreover, current TSV 3D architectures suffer from thermal
limitations. Hence, TSV-based architectures do not realize the full potential
of 3D integration. Monolithic 3D (M3D) integration, a breakthrough technology
to achieve - More Moore and More Than Moore - and opens up the possibility of
designing cores and associated network routers using multiple layers by
utilizing monolithic inter-tier vias (MIVs) and hence, reducing the effective
wire length. Compared to TSV-based 3D ICs, M3D offers the true benefits of
vertical dimension for system integration: the size of a MIV used in M3D is
over 100x smaller than a TSV. In this work, we demonstrate how M3D-enabled
vertical core and uncore elements offer significant performance and thermal
improvements in manycore heterogeneous architectures compared to its TSV-based
counterpart. To overcome the difficult optimization challenges due to the large
design space and complex interactions among the heterogeneous components (CPU,
GPU, Last Level Cache, etc.) in an M3D-based manycore chip, we leverage novel
design-space exploration algorithms to trade-off different objectives. The
proposed M3D-enabled heterogeneous architecture, called HeM3D, outperforms its
state-of-the-art TSV-equivalent counterpart by up to 18.3% in execution time
while being up to 19 degrees Celcius cooler.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:23:41 GMT""},{""version"":""v2"",""created"":""Tue, 8 Dec 2020 02:07:11 GMT""}]","2020-12-09"
"2012.00106","Joseph Near","Ivoline C. Ngong, Krystal Maughan, Joseph P. Near","Towards Auditability for Fairness in Deep Learning","Presented at the workshop on Algorithmic Fairness through the Lens of
  Causality and Interpretability (AFCI'20)",,,,"cs.LG cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Group fairness metrics can detect when a deep learning model behaves
differently for advantaged and disadvantaged groups, but even models that score
well on these metrics can make blatantly unfair predictions. We present smooth
prediction sensitivity, an efficiently computed measure of individual fairness
for deep learning models that is inspired by ideas from interpretability in
deep learning. smooth prediction sensitivity allows individual predictions to
be audited for fairness. We present preliminary experimental results suggesting
that smooth prediction sensitivity can help distinguish between fair and unfair
predictions, and that it may be helpful in detecting blatantly unfair
predictions from ""group-fair"" models.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:28:12 GMT""}]","2020-12-02"
"2012.00107","Hanumantharao Vutukuri","Hanumantha Rao Vutukuri, Maciej Lisicki, Eric Lauga, Jan Vermant","Light-switchable propulsion of active particles with reversible
  interactions","28 pages, 4 figures","Nature Communications 11, 2628 (2020)","10.1038/s41467-020-15764-1",,"cond-mat.soft cond-mat.mtrl-sci physics.bio-ph physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Active systems such as microorganisms and self-propelled particles show a
plethora of collective phenomena, including swarming, clustering, and phase
separation. Control over the propulsion direction and switchability of the
interactions between the individual self-propelled units may open new avenues
in designing of materials from within. Here, we present a self-propelled
particle system, consisting of half-gold coated titania ($\mathrm{TiO}_2$)
particles, in which we can fast and on-demand reverse the propulsion direction,
by exploiting the different photocatalytic activities on both sides. We
demonstrate that the reversal in propulsion direction changes the nature of the
hydrodynamic interaction from attractive to repulsive and can drive the
particle assemblies to undergo both fusion and fission transitions. Moreover,
we show these active colloids can act as nucleation sites, and switch rapidly
the interactions between active and passive particles, leading to
reconfigurable assembly and disassembly. Our experiments are qualitatively
described by a minimal hydrodynamic model.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:30:17 GMT""}]","2020-12-02"
"2012.00108","Lucas Gagnon","Lucas Gagnon","The combinatorics of normal subgroups in the unipotent upper triangular
  group","33 pages, 1 figure, 1 table",,,,"math.CO math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Describing the conjugacy classes of the unipotent upper triangular groups
$\mathrm{UT}_{n}(\mathbb{F}_{q})$ uniformly (for all or many values of $n$ and
$q$) is a nearly impossible task. This paper takes on the related problem of
describing the normal subgroups of $\mathrm{UT}_{n}(\mathbb{F}_{q})$. For $q$ a
prime, a bijection will be established between these subgroups and pairs of
combinatorial objects with labels from $\mathbb{F}_{q}^{\times}$. Each pair
comprises a loopless binary matroid and a tight splice, an apparently new kind
of combinatorial object which interpolates between nonnesting partitions and
shortened polyominoes. For arbitrary $q$, the same approach describes a natural
subset of normal subgroups: those which correspond to the ideals of the Lie
algebra $\mathfrak{ut}_{n}(\mathbb{F}_{q})$ under an approximation of the
exponential map.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:30:21 GMT""},{""version"":""v2"",""created"":""Sat, 14 Aug 2021 13:46:33 GMT""}]","2021-08-17"
"2012.00109","Charles Semple","Allan Bai, Peter Erdos, Charles Semple, Mike Steel","Defining phylogenetic networks using ancestral profiles","18 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:1901.04064",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Rooted phylogenetic networks provide a more complete representation of the
ancestral relationship between species than phylogenetic trees when reticulate
evolutionary processes are at play. One way to reconstruct a phylogenetic
network is to consider its `ancestral profile' (the number of paths from each
ancestral vertex to each leaf). In general, this information does not uniquely
determine the underlying phylogenetic network. A recent paper considered a new
class of phylogenetic networks called `orchard networks' where this uniqueness
was claimed to hold. Here we show that an additional restriction on the
network, that of being `stack-free', is required in order for the original
uniqueness claim to hold. On the other hand, if the additional stack-free
restriction is lifted, we establish an alternative result; namely, there is
uniqueness within the class of orchard networks up to the resolution of
vertices of high in-degree.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:32:18 GMT""}]","2020-12-02"
"2012.00110","Andrew Miller","Jeffrey Chan, Andrew C. Miller, Emily B. Fox","Representing and Denoising Wearable ECG Recordings","ML for Mobile Health Workshop, NeurIPS 2020",,,,"stat.ML cs.LG stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern wearable devices are embedded with a range of noninvasive biomarker
sensors that hold promise for improving detection and treatment of disease. One
such sensor is the single-lead electrocardiogram (ECG) which measures
electrical signals in the heart. The benefits of the sheer volume of ECG
measurements with rich longitudinal structure made possible by wearables come
at the price of potentially noisier measurements compared to clinical ECGs,
e.g., due to movement. In this work, we develop a statistical model to simulate
a structured noise process in ECGs derived from a wearable sensor, design a
beat-to-beat representation that is conducive for analyzing variation, and
devise a factor analysis-based method to denoise the ECG. We study synthetic
data generated using a realistic ECG simulator and a structured noise model. At
varying levels of signal-to-noise, we quantitatively measure an upper bound on
performance and compare estimates from linear and non-linear models. Finally,
we apply our method to a set of ECGs collected by wearables in a mobile health
study.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:33:11 GMT""}]","2020-12-02"
"2012.00111","Digvijay Wadekar","Digvijay Wadekar, Francisco Villaescusa-Navarro, Shirley Ho, Laurence
  Perreault-Levasseur","Modeling assembly bias with machine learning and symbolic regression","16 pages, 12 figures. To be submitted to PNAS. Figures 3, 5 and 6
  show our main results. Comments are welcome",,,,"astro-ph.CO astro-ph.GA physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Upcoming 21cm surveys will map the spatial distribution of cosmic neutral
hydrogen (HI) over unprecedented volumes. Mock catalogues are needed to fully
exploit the potential of these surveys. Standard techniques employed to create
these mock catalogs, like Halo Occupation Distribution (HOD), rely on
assumptions such as the baryonic properties of dark matter halos only depend on
their masses. In this work, we use the state-of-the-art magneto-hydrodynamic
simulation IllustrisTNG to show that the HI content of halos exhibits a strong
dependence on their local environment. We then use machine learning techniques
to show that this effect can be 1) modeled by these algorithms and 2)
parametrized in the form of novel analytic equations. We provide physical
explanations for this environmental effect and show that ignoring it leads to
underprediction of the real-space 21-cm power spectrum at $k\gtrsim 0.05$ h/Mpc
by $\gtrsim$10\%, which is larger than the expected precision from upcoming
surveys on such large scales. Our methodology of combining numerical
simulations with machine learning techniques is general, and opens a new
direction at modeling and parametrizing the complex physics of assembly bias
needed to generate accurate mocks for galaxy and line intensity mapping
surveys.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:34:58 GMT""}]","2020-12-02"
"2012.00112","Simone Selenu Dr","S.Selenu","Adiabatic Variations of Quantum Heat of a quantum body",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this article it will be introduced a new theorem, can be considered a
generalization of Hellmann-Feynman theorem[1]. The latter used in conjunction
with the quantization of the free energy[2] of a quantum system allows to
derive strightly the electronic Heat variations of a quantum electronic system,
in its condensed phase of eigenstates, showing its agreement with classical
thermodynamics, making then possible to desing ab inito quantum models of the
electronic structure in its thermodynamical states.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:35:00 GMT""}]","2020-12-02"
"2012.00113","Michail Tsagris","Michail Tsagris","The FEDHC Bayesian network learning algorithm","This is a preprint of the paper published in Mathematics","Mathematics 2022, 10(15), 2604","10.3390/math10152604",,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper proposes a new hybrid Bayesian network learning algorithm, termed
Forward Early Dropping Hill Climbing (FEDHC), devised to work with either
continuous or categorical variables. Further, the paper manifests that the only
implementation of MMHC in the statistical software \textit{R}, is prohibitively
expensive and a new implementation is offered. Further, specifically for the
case of continuous data, a robust to outliers version of FEDHC, that can be
adopted by other BN learning algorithms, is proposed. The FEDHC is tested via
Monte Carlo simulations that distinctly show it is computationally efficient,
and produces Bayesian networks of similar to, or of higher accuracy than MMHC
and PCHC. Finally, an application of FEDHC, PCHC and MMHC algorithms to real
data, from the field of economics, is demonstrated using the statistical
software \textit{R}.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:36:25 GMT""},{""version"":""v2"",""created"":""Sat, 3 Apr 2021 13:08:47 GMT""},{""version"":""v3"",""created"":""Thu, 27 May 2021 19:38:08 GMT""},{""version"":""v4"",""created"":""Tue, 9 Nov 2021 08:18:08 GMT""},{""version"":""v5"",""created"":""Fri, 4 Feb 2022 12:49:59 GMT""},{""version"":""v6"",""created"":""Fri, 12 Aug 2022 21:49:43 GMT""}]","2022-08-16"
"2012.00114","Antonio Stabile","Gaetano Lambiase, Mairi Sakellariadou, Antonio Stabile","Constraints on extended gravity models through gravitational wave
  emission","11 pages, submitted to JCAP",,"10.1088/1475-7516/2021/03/014",,"gr-qc","http://creativecommons.org/licenses/by-sa/4.0/","  Using recent experimental results of detection of gravitational waves from
the binary black hole signals by Advanced LIGO and Advanced Virgo, we
investigate the propagation of gravitational waves in the context of fourth
order gravity nonminimally coupled to a massive scalar field. Gravitational
radiation admits extra massive modes of oscillation and we assume that the
amplitude of these modes is comparable to that of the massless mode. We derive
the propagation equation and effective mass for each degree of freedom and we
infer, from the current observational data, constraints on the free parameters
of the gravity models we considered. In particular, for $f(R)=R-R^2/R_0 $, the
constraint obtained from the speed of gravitational waves is not compatible
with the one set by Solar System tests, which implies that amplitude of the
massive modes could not be detectable with current experiments on Earth
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:37:04 GMT""},{""version"":""v2"",""created"":""Tue, 29 Dec 2020 18:54:23 GMT""},{""version"":""v3"",""created"":""Thu, 14 Jan 2021 12:54:30 GMT""}]","2021-03-17"
"2012.00115","Ahmed Jaber","Ahmed Jaber, Pascal Lafon, Rafic Younes","A Branch and Bound Based on NSGAII Algorithm for Multi-Objective Mixed
  Integer Non Linear Optimization Problems","This article has been submitted for publication in Engineering
  Optimization Journal, published by Taylor & Francis. The article contains 28
  pages, 13 figures, and 5 tables",,"10.1080/0305215X.2021.1904918",,"math.OC","http://creativecommons.org/licenses/by/4.0/","  Multi-Objective Mixed-Integer Non-Linear Programming problems (MO-MINLPs)
appear in several real-world applications, especially in the mechanical
engineering field. To determine a good approximated Pareto front for this type
of problems, we propose a general hybrid approach based on a Multi-Criteria
Branch-and-Bound (MCBB) and Non-dominated Sorting Genetic Algorithm 2 (NSGAII).
We present a computational experiment based on a statistical assessment to
compare the performance of the proposed algorithm (BnB-NSGAII) with NSGAII
using well-known metrics from literature. We propose a new metric, Investment
Ratio (IR), that relate the quality of the solution to the consumed effort. We
consider five real-world mechanical engineering problems and two mathematical
ones to be used as test problems in this experiment. Experimental results
indicate that BnB-NSGAII could be a competitive alternative for solving
MO-MINLPs.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:37:23 GMT""}]","2021-05-17"
"2012.00116","Martin Strohmeier","Matthias Sch\""afer, Martin Strohmeier, Mauro Leonardi, Vincent Lenders","LocaRDS: A Localization Reference Data Set","10 pages, 6 figures, 1 table",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of wireless signals for purposes of localization enables a host of
applications relating to the determination and verification of the positions of
network participants, ranging from radar to satellite navigation. Consequently,
it has been a longstanding interest of theoretical and practical research in
mobile networks and many solutions have been proposed in the scientific
literature. However, it is hard to assess the performance of these in the real
world and, more severely, to compare their advantages and disadvantages in a
controlled scientific manner.
  With this work, we attempt to improve the current state of the art in
localization research and put it on a solid scientific grounding for the
future. Concretely, we develop LocaRDS, an open reference dataset of real-world
crowdsourced flight data featuring more than 222 million measurements from over
50 million transmissions recorded by 323 sensors. We show how LocaRDS can be
used to test, analyze and directly compare different localization techniques
and further demonstrate its effectiveness by examining the open question of the
aircraft localization problem in crowdsourced sensor networks. Finally, we
provide a working reference implementation for the aircraft localization
problem and a discussion of possible metrics for use with LocaRDS.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:37:57 GMT""}]","2020-12-02"
"2012.00117","Yue Chen","Yue Chen, Matthew R. Carver, Steven K. Morley, and Andrew S. Hoover","Determining Ionizing Doses in Medium Earth Orbits Using Long-Term GPS
  Particle Measurements","10 pages, 11 figures, submitted to 2021 IEEE Aerospace Conference. It
  has been accepted for final revision. This is not the published version",,,"LA-UR-20-28033","physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use long-term electron and proton in-situ measurements made by the CXD
particle instruments, developed by Los Alamos National Laboratory and carried
on board GPS satellites, to determine total ionizing dose (TID) values and
daily/yearly dose rate (DR) values in medium Earth orbits (MEOs) caused by the
natural space radiation environment. Here measurement-based TID and DR values
on a simplified sample geometry--a small (with a radius of 0.1 mm) Silicon
detector within an Aluminum shielding sphere with a thickness of 100 mil--are
compared to those calculated from empirical radiation models. Results over the
solar cycle 24 show that electron TID from measurements in GPS orbit is well
above the values calculated from the median/mean fluences from AE8 and AE9
models, but close to model fluences at high percentiles. Also, it is confirmed
that in MEOs proton contributions to TID are minor and mainly dominated by
solar energetic protons. Several factors affecting those dose calculations are
discussed and evaluated. Results from this study provide us another
out-of-sample test on the reliability of existing empirical space radiation
models, and also help estimate the margin factors on calculated dose values in
MEOs that pass through the heart of the Earth's outer radiation belt.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:38:13 GMT""}]","2020-12-02"
"2012.00118","G. Michele Pinna","G. Michele Pinna","A new operational representation of dependencies in Event Structures",,"Logical Methods in Computer Science, Volume 17, Issue 4 (December
  2, 2021) lmcs:8791","10.46298/lmcs-17(4:16)2021",,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  The execution of an event in a complex and distributed system where the
dependencies vary during the evolution of the system can be represented in many
ways, and one of them is to use Context-Dependent Event structures. Event
structures are related to Petri nets. The aim of this paper is to propose what
can be the appropriate kind of Petri net corresponding to Context-Dependent
Event structures, giving an operational flavour to the dependencies represented
in a Context/Dependent Event structure. Dependencies are often operationally
represented, in Petri nets, by tokens produced by activities and consumed by
others. Here we shift the perspective using contextual arcs to characterize
what has happened so far and in this way to describe the dependencies among the
various activities.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:39:05 GMT""},{""version"":""v2"",""created"":""Thu, 29 Jul 2021 14:51:14 GMT""},{""version"":""v3"",""created"":""Tue, 5 Oct 2021 14:49:28 GMT""},{""version"":""v4"",""created"":""Wed, 1 Dec 2021 09:32:18 GMT""}]","2021-12-11"
"2012.00119","Gongbo Liang","Xin Xing, Gongbo Liang, Hunter Blanton, Muhammad Usman Rafique, Chris
  Wang, Ai-Ling Lin, Nathan Jacobs","Dynamic Image for 3D MRI Image Alzheimer's Disease Classification","Accepted to ECCV2020 Workshop on BioImage Computing",,"10.1007/978-3-030-66415-2_23",,"cs.CV cs.AI cs.LG cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose to apply a 2D CNN architecture to 3D MRI image Alzheimer's disease
classification. Training a 3D convolutional neural network (CNN) is
time-consuming and computationally expensive. We make use of approximate rank
pooling to transform the 3D MRI image volume into a 2D image to use as input to
a 2D CNN. We show our proposed CNN model achieves $9.5\%$ better Alzheimer's
disease classification accuracy than the baseline 3D models. We also show that
our method allows for efficient training, requiring only 20% of the training
time compared to 3D CNN models. The code is available online:
https://github.com/UkyVision/alzheimer-project.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:39:32 GMT""}]","2021-01-14"
"2012.00120","Kevin Palmowski","Griffin M. Kearney, Kevin F. Palmowski, Michael Robinson","Sheaf-theoretic framework for optimal network control","22 pages",,,,"math.AT math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we use tools from sheaf theory to model and analyze optimal
network control problems and their associated discrete relaxations. We consider
a general problem setting in which pieces of equipment and their causal
relations are represented as a directed network, and the state of this
equipment evolves over time according to known dynamics and the presence or
absence of control actions. First, we provide a brief introduction to key
concepts in the theory of sheaves on partial orders. This foundation is used to
construct a series of sheaves that build upon each other to model the problem
of optimal control, culminating in a result that proves that solving our
optimal control problem is equivalent to finding an assignment to a sheaf that
has minimum consistency radius and restricts to a global section on a
particular subsheaf. The framework thus built is applied to the specific case
where a model is discretized to one in which the state and control variables
are Boolean in nature, and we provide a general bound for the error incurred by
such a discretization process. We conclude by presenting an application of
these theoretical tools that demonstrates that this bound is improved when the
system dynamics are affine.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:39:35 GMT""}]","2020-12-02"
"2012.00121","Simone Selenu Dr","S.Selenu","DFT quantization of the Gibbs Free Energy of a quantum body",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this article it is introduced a theoretical model made in order to perform
calculations of the quantum heat of a body that could be acquired or delivered
during a thermal transformation of its quantum states. Here the model is mainly
targeted to the electronic structure of matter[1] at the nano and micro scale
where DFT models have been frequently developed of the total energy of quantum
systems. Defining an Entropy functional $S[\rho]$ makes us able optimizing a
free energy $G[\rho]$ of the quantum system at finite temperatures. Due to the
generality of the model, the latter can be also applied to several first
principles computational codes where ab initio modelling of quantum matter is
asked.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:42:42 GMT""}]","2020-12-02"
"2012.00122","Justine Falque","Justine Falque","A Bijection Between Weighted Dyck Paths and 1234-avoiding Up-Down
  Permutations",,,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three-dimensional Catalan numbers are a variant of the classical
(bidimensional) Catalan numbers, that count, among other interesting objects,
the standard Young tableaux of shape (n,n,n). In this paper, we present a
structural bijection between two three-dimensional Catalan objects:
1234-avoiding up-down permutations, and a class of weighted Dyck paths.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:45:08 GMT""}]","2020-12-02"
"2012.00123","Yujia Xie","Yujia Xie, Yixiu Mao, Simiao Zuo, Hongteng Xu, Xiaojing Ye, Tuo Zhao,
  Hongyuan Zha","A Hypergradient Approach to Robust Regression without Correspondence",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  We consider a variant of regression problem, where the correspondence between
input and output data is not available. Such shuffled data is commonly observed
in many real world problems. Taking flow cytometry as an example, the measuring
instruments may not be able to maintain the correspondence between the samples
and the measurements. Due to the combinatorial nature of the problem, most
existing methods are only applicable when the sample size is small, and limited
to linear regression models. To overcome such bottlenecks, we propose a new
computational framework -- ROBOT -- for the shuffled regression problem, which
is applicable to large data and complex nonlinear models. Specifically, we
reformulate the regression without correspondence as a continuous optimization
problem. Then by exploiting the interaction between the regression model and
the data correspondence, we develop a hypergradient approach based on
differentiable programming techniques. Such a hypergradient approach
essentially views the data correspondence as an operator of the regression, and
therefore allows us to find a better descent direction for the model parameter
by differentiating through the data correspondence. ROBOT can be further
extended to the inexact correspondence setting, where there may not be an exact
alignment between the input and output data. Thorough numerical experiments
show that ROBOT achieves better performance than existing methods in both
linear and nonlinear regression tasks, including real-world applications such
as flow cytometry and multi-object tracking.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:47:38 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 16:47:12 GMT""}]","2021-02-12"
"2012.00124","Kanthashree Mysore Sathyendra","Kanthashree Mysore Sathyendra, Samridhi Choudhary, Leah
  Nicolich-Henkin","Extreme Model Compression for On-device Natural Language Understanding","Long paper at COLING 2020",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose and experiment with techniques for extreme
compression of neural natural language understanding (NLU) models, making them
suitable for execution on resource-constrained devices. We propose a
task-aware, end-to-end compression approach that performs word-embedding
compression jointly with NLU task learning. We show our results on a
large-scale, commercial NLU system trained on a varied set of intents with huge
vocabulary sizes. Our approach outperforms a range of baselines and achieves a
compression rate of 97.4% with less than 3.7% degradation in predictive
performance. Our analysis indicates that the signal from the downstream task is
important for effective compression with minimal degradation in performance.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:47:48 GMT""}]","2020-12-02"
"2012.00126","Allal Ghanmi","Aiad El Gourari, Allal Ghanmi, Ilham Rouchdi","Bicomplex polyharmonicity and polyholomorphy","19 pages, Improved version",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we are concerned with the bicomplex analog of the well-known
result asserting that real-valued harmonic functions, on simply connected
domains, are the real parts of holomorphic functions. We show that this
assertion, word for word, fails for bc-harmonic functions and we provide a
complete characterization of bc-harmonic functions that are the hyperbolic real
parts of a specific kind of bc-holomorphic functions. Moreover, we extend the
result to bicomplex polyharmonic functions, which implies the introduction of
specific classes of bc-polyholomorphic functions.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:51:48 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 19:26:37 GMT""},{""version"":""v3"",""created"":""Sat, 12 Mar 2022 09:24:05 GMT""}]","2022-03-15"
"2012.00127","William Kuszmaul","William Kuszmaul and Alek Westover","The Variable-Processor Cup Game",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of scheduling tasks on $p$ processors so that no task ever gets
too far behind is often described as a game with cups and water. In the
$p$-processor cup game on $n$ cups, there are two players, a filler and an
emptier, that take turns adding and removing water from a set of $n$ cups. In
each turn, the filler adds $p$ units of water to the cups, placing at most $1$
unit of water in each cup, and then the emptier selects $p$ cups to remove up
to $1$ unit of water from. The emptier's goal is to minimize the backlog, which
is the height of the fullest cup.
  The $p$-processor cup game has been studied in many different settings,
dating back to the late 1960's. All of the past work shares one common
assumption: that $p$ is fixed. This paper initiates the study of what happens
when the number of available processors $p$ varies over time, resulting in what
we call the \emph{variable-processor cup game}.
  Remarkably, the optimal bounds for the variable-processor cup game differ
dramatically from its classical counterpart. Whereas the $p$-processor cup has
optimal backlog $\Theta(\log n)$, the variable-processor game has optimal
backlog $\Theta(n)$. Moreover, there is an efficient filling strategy that
yields backlog $\Omega(n^{1 - \epsilon})$ in quasi-polynomial time against any
deterministic emptying strategy.
  We additionally show that straightforward uses of randomization cannot be
used to help the emptier. In particular, for any positive constant $\Delta$,
and any $\Delta$-greedy-like randomized emptying algorithm $\mathcal{A}$, there
is a filling strategy that achieves backlog $\Omega(n^{1 - \epsilon})$ against
$\mathcal{A}$ in quasi-polynomial time.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:58:41 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 19:13:20 GMT""}]","2021-02-11"
"2012.00128","Wenzheng Kuang","Guosheng Fu, Wenzheng Kuang","A monolithic divergence-conforming HDG scheme for a linear
  fluid-structure interaction model","26 pages",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We present a novel monolithic divergence-conforming HDG scheme for a linear
fluid-structure interaction (FSI) problem with a thick structure. A
pressure-robust optimal energy-norm estimate is obtained for the semidiscrete
scheme. When combined with a Crank-Nicolson time discretization, our fully
discrete scheme is energy stable and produces an exactly divergence-free fluid
velocity approximation. The resulting linear system, which is symmetric and
indefinite, is solved using a preconditioned MinRes method with a robust block
algebraic multigrid (AMG) preconditioner.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:59:15 GMT""}]","2020-12-02"
"2012.00129","Zhidong Lu","Zhidong Lu, Florian Holzapfel","Stability and Performance Analysis for SISO Incremental Flight Control","20 pages",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Incremental Nonlinear Dynamic Inversion (INDI) control has attracted
increasing research attention for it retains the high-performance of NDI and
has enhanced robustness. However, when actual elements of the flight control
system and real-world phenomena (such as actuator dynamics, sensor noise, time
delay, etc.) are considered, the INDI control may have degraded performance or
even lose stability. This paper analyzed the stability and performance of an
incremental controller for a SISO linear plant based on transfer functions.
Besides, the theoretical analysis results are verified through numerical
evaluations for the incremental controller of the short-period aircraft model
using comprehensive metrics.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:00:27 GMT""}]","2020-12-02"
"2012.00130","Joseph Fowler","Joseph W. Fowler (1 and 2), Galen C. O'Neil (2), Bradley K. Alpert
  (2), Douglas A. Bennett (2), Ed V. Denison (2), W. B. Doriese (2), Gene C.
  Hilton (2), Lawrence T. Hudson (2), Young-Il Joe (1 and 2), Kelsey M. Morgan
  (1 and 2), Daniel R. Schmidt (2), Daniel S. Swetz (2), Csilla I. Szabo (2 and
  3), and Joel N. Ullom (1 and 2) ((1) Department of Physics, University of
  Colorado (2) US National Institute of Standards and Technology (3) Theiss
  Research, La Jolla, California)","Absolute energies and emission line shapes of the L x-ray transitions of
  lanthanide metals",,"Metrologia 58 (2021) 015016","10.1088/1681-7575/abd28a",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use an array of transition-edge sensors, cryogenic microcalorimeters with
4 eV energy resolution, to measure L x-ray emission-line profiles of four
elements of the lanthanide series: praseodymium, neodymium, terbium, and
holmium. The spectrometer also surveys numerous x-ray standards in order to
establish an absolute-energy calibration traceable to the International System
of Units for the energy range 4 keV to 10 keV. The new results include emission
line profiles for 97 lines, each expressed as a sum of one or more Voigt
functions; improved absolute energy uncertainty on 71 of these lines relative
to existing reference data; a median uncertainty on the peak energy of 0.24 eV,
four to ten times better than the median of prior work; and 6 lines that lack
any measured values in existing reference tables. The 97 lines comprise nearly
all of the most intense L lines from these elements under broad-band x-ray
excitation. The work improves on previous measurements made with a similar
cryogenic spectrometer by the use of sensors with better linearity in the
absorbed energy and a gold x-ray absorbing layer that has a Gaussian
energy-response function. It also employs a novel sample holder that enables
rapid switching between science targets and calibration targets with excellent
gain balancing. Most of the results for peak energy values shown here should be
considered as replacements for the currently tabulated standard reference
values, while the line shapes given here represent a significant expansion of
the scope of available reference data.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:00:47 GMT""}]","2022-04-15"
"2012.00131","Sutanay Choudhury","Sutanay Choudhury, Jenna A. Bilbrey, Logan Ward, Sotiris S. Xantheas,
  Ian Foster, Joseph P. Heindel, Ben Blaiszik, Marcus E. Schwarting","HydroNet: Benchmark Tasks for Preserving Intermolecular Interactions and
  Structural Motifs in Predictive and Generative Models for Molecular Data","Machine Learning and the Physical Sciences Workshop at the 34th
  Conference on Neural Information Processing Systems (NeurIPS)",,,,"cs.LG physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Intermolecular and long-range interactions are central to phenomena as
diverse as gene regulation, topological states of quantum materials,
electrolyte transport in batteries, and the universal solvation properties of
water. We present a set of challenge problems for preserving intermolecular
interactions and structural motifs in machine-learning approaches to chemical
problems, through the use of a recently published dataset of 4.95 million water
clusters held together by hydrogen bonding interactions and resulting in longer
range structural patterns. The dataset provides spatial coordinates as well as
two types of graph representations, to accommodate a variety of
machine-learning practices.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:01:00 GMT""}]","2020-12-02"
"2012.00132","Siyang Li","Siyang Li (a) and George F. Smoot (a-h) ((a) Department of Physics,
  University of California, Berkeley, USA, (b) Lawrence Berkeley National
  Laboratory, USA, Emeritus, (c) Department of Physics, Hong Kong University of
  Science and Technology, China, (d) Institute for Advanced Study, Hong Kong
  University of Science and Technology, China, (e) Energetic Cosmos Laboratory,
  Nazarbayev University, Kazakhstan, (f) Department of Physics, Universit\'e
  Paris Diderot, France, Emeritus, (g) Paris Centre for Cosmological Physics,
  Universit\'e Paris, France, (h) Donostia International Physics Center,
  Universidad del Pa\'is Vasco, Spain)","Characterization of a high efficiency silicon photomultiplier for
  millisecond to sub-microsecond astrophysical transient searches","7 pages, 6 figures, 1 table, submitted to SPIE Astronomical
  Telescopes + Instrumentation 2020 conference proceedings","Proc. SPIE 11454, X-Ray, Optical, and Infrared Detectors for
  Astronomy IX (2020)","10.1117/12.2561936",,"astro-ph.IM physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We characterized the S14160-3050HS Multi-Pixel Photon Counter (MPPC), a high
efficiency, single channel silicon photomultiplier manufactured by Hamamatsu
Photonics K.K. All measurements were performed at a room temperature of (23.0
$\pm$ 0.3) $^{\circ}$C. We obtained an I-V curve and used relative derivatives
to find a breakdown voltage of 38.88 V. At a 3 V over voltage, we find a dark
count rate of 1.08 MHz, crosstalk probability of 21 $\%$, photon detection
efficiency of 55 $\%$ at 450 nm, and saturation at 1.0x10$^{11}$ photons per
second. The S14160-3050HS MPPC is a candidate detector for the Ultra-Fast
Astronomy (UFA) telescope which will characterize the optical (320 nm - 650 nm)
sky in the millisecond to sub-microsecond timescales using two photon counting
arrays operated in coincidence on the 0.7 meter Nazarbayev University Transient
Telescope at the Assy-Turgen Astrophysical Observatory (NUTTelA-TAO) located
near Almaty, Kazakhstan. We discuss advantages and disadvantages of using the
S14160-3050HS MPPC for the UFA telescope and future ground-based telescopes in
sub-second time domain astrophysics.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:01:09 GMT""}]","2020-12-21"
"2012.00133","Yile Gu","Vijay Ravi, Yile Gu, Ankur Gandhe, Ariya Rastrow, Linda Liu, Denis
  Filimonov, Scott Novotney, Ivan Bulyko","Improving accuracy of rare words for RNN-Transducer through unigram
  shallow fusion",,,,,"cs.CL cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  End-to-end automatic speech recognition (ASR) systems, such as recurrent
neural network transducer (RNN-T), have become popular, but rare word remains a
challenge. In this paper, we propose a simple, yet effective method called
unigram shallow fusion (USF) to improve rare words for RNN-T. In USF, we
extract rare words from RNN-T training data based on unigram count, and apply a
fixed reward when the word is encountered during decoding. We show that this
simple method can improve performance on rare words by 3.7% WER relative
without degradation on general test set, and the improvement from USF is
additive to any additional language model based rescoring. Then, we show that
the same USF does not work on conventional hybrid system. Finally, we reason
that USF works by fixing errors in probability estimates of words due to
Viterbi search used during decoding with subword-based RNN-T.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:06:02 GMT""}]","2020-12-02"
"2012.00134","Hatim Labrigui","Hatim Labrigui and Samir Kabbaj","Integral $K$-Operator Frames for $End_{\mathcal{A}}^{\ast}(\mathcal{H})$",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we introduce a new concept of integral $K$-operator frame for
the set of all adjointable operators from Hilbert $C^{\ast}$-modules
$\mathcal{H}$ to it self noted $End_{\mathcal{A}}^{\ast}(\mathcal{H}) $. We
give some propertis relating some construction of integral $K$-operator frame
and operators preserving integral $K$-operator frame and we establish some new
results.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:09:34 GMT""}]","2020-12-02"
"2012.00135","Yingtai Xiao","Yingtai Xiao, Zeyu Ding, Yuxin Wang, Danfeng Zhang, Daniel Kifer","Optimizing Fitness-For-Use of Differentially Private Linear Queries",,,,,"cs.DB","http://creativecommons.org/licenses/by/4.0/","  In practice, differentially private data releases are designed to support a
variety of applications. A data release is fit for use if it meets target
accuracy requirements for each application. In this paper, we consider the
problem of answering linear queries under differential privacy subject to
per-query accuracy constraints. Existing practical frameworks like the matrix
mechanism do not provide such fine-grained control (they optimize total error,
which allows some query answers to be more accurate than necessary, at the
expense of other queries that become no longer useful). Thus, we design a
fitness-for-use strategy that adds privacy-preserving Gaussian noise to query
answers. The covariance structure of the noise is optimized to meet the
fine-grained accuracy requirements while minimizing the cost to privacy.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:10:21 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 01:14:08 GMT""},{""version"":""v3"",""created"":""Mon, 28 Dec 2020 16:22:22 GMT""},{""version"":""v4"",""created"":""Fri, 19 Mar 2021 02:26:31 GMT""},{""version"":""v5"",""created"":""Thu, 1 Apr 2021 11:24:38 GMT""},{""version"":""v6"",""created"":""Mon, 14 Jun 2021 17:30:36 GMT""}]","2021-06-15"
"2012.00136","Harry Halpin","Harry Halpin","A Critique of Immunity Passports and W3C Decentralized Identifiers",,,,,"cs.CR cs.CY","http://creativecommons.org/licenses/by-sa/4.0/","  Due to the widespread COVID-19 pandemic, there has been a push for `immunity
passports' and even technical proposals. Although the debate about the medical
and ethical problems of immunity passports has been widespread, there has been
less inspection of the technical foundations of immunity passport schemes.
These schemes are envisaged to be used for sharing COVID-19 test and
vaccination results in general. The most prominent immunity passport schemes
have involved a stack of little-known standards, such as Decentralized
Identifiers (DIDs) and Verifiable Credentials (VCs) from the World Wide Web
Consortium (W3C). Our analysis shows that this group of technical identity
standards are based on under-specified and often non-standardized documents
that have substantial security and privacy issues, due in part to the
questionable use of blockchain technology. One concrete proposal for immunity
passports is even susceptible to dictionary attacks. The use of `cryptography
theater' in efforts like immunity passports, where cryptography is used to
allay the privacy concerns of users, should be discouraged in standardization.
Deployment of these W3C standards for `self-sovereign identity' in use-cases
like immunity passports could just as well lead to a dangerous form identity
totalitarianism.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:10:43 GMT""}]","2020-12-02"
"2012.00137","Fernando Lund","Dmitry Churochkin and Fernando Lund","Coherent propagation and incoherent diffusion of elastic waves in a two
  dimensional continuum with a random distribution of edge dislocations",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We study the coherent propagation and incoherent diffusion of in-plane
elastic waves in a two dimensional continuum populated by many, randomly placed
and oriented, edge dislocations. Because of the Peierls-Nabarro force the
dislocations can oscillate around an equilibrium position with frequency
$\omega_0$. The coupling between waves and dislocations is given by the
Peach-Koehler force. This leads to a wave equation with an inhomogeneous term
that involves a differential operator. In the coherent case, a Dyson equation
for a mass operator is set up and solved to all orders in perturbation theory
in independent scattering approximation (ISA). As a result, a complex index of
refraction is obtained, from which an effectve wave velocity and attenuation
can be read off, for both longitudinal and transverse waves. In the incoherent
case a Bethe-Salpeter equation is set up, and solved to leading order in
perturbation theory in the limit of low frequency and wave number. A diffusion
equation is obtained and the (frequency-dependent) diffusion coefficient is
explicitly calculated. It reduces to the value obtained with energy transfer
arguments at low frequency. An important intermediate step is the obtention of
a Ward-Takahashi identity (WTI) for a wave equation that involves a
differential operator, which is shown to be compatible with the ISA.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:16:05 GMT""}]","2020-12-02"
"2012.00138","Ross Drummond","Jiaqi Li, Ross Drummond and Stephen R. Duncan","Robust error bounds for quantised and pruned neural networks",,,,,"cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the rise of smartphones and the internet-of-things, data is increasingly
getting generated at the edge on local, personal devices. For privacy, latency
and energy saving reasons, this shift is causing machine learning algorithms to
move towards decentralisation with the data and algorithms stored, and even
trained, locally on devices. The device hardware becomes the main bottleneck
for model capability in this set-up, creating a need for slimmed down, more
efficient neural networks. Neural network pruning and quantisation are two
methods that have been developed for this, with both approaches demonstrating
impressive results in reducing the computational cost without sacrificing
significantly on model performance. However, the understanding behind these
reduction methods remains underdeveloped. To address this issue, a
semi-definite program is introduced to bound the worst-case error caused by
pruning or quantising a neural network. The method can be applied to many
neural network structures and nonlinear activation functions with the bounds
holding robustly for all inputs in specified sets. It is hoped that the
computed bounds will provide certainty to the performance of these algorithms
when deployed on safety-critical systems.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:19:44 GMT""},{""version"":""v2"",""created"":""Tue, 27 Apr 2021 20:49:29 GMT""}]","2021-04-29"
"2012.00139","Davis Gilton","Davis Gilton, Gregory Ongie, Rebecca Willett","Model Adaptation for Inverse Problems in Imaging",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep neural networks have been applied successfully to a wide variety of
inverse problems arising in computational imaging. These networks are typically
trained using a forward model that describes the measurement process to be
inverted, which is often incorporated directly into the network itself.
However, these approaches are sensitive to changes in the forward model: if at
test time the forward model varies (even slightly) from the one the network was
trained for, the reconstruction performance can degrade substantially. Given a
network trained to solve an initial inverse problem with a known forward model,
we propose two novel procedures that adapt the network to a change in the
forward model, even without full knowledge of the change. Our approaches do not
require access to more labeled data (i.e., ground truth images). We show these
simple model adaptation approaches achieve empirical success in a variety of
inverse problems, including deblurring, super-resolution, and undersampled
image reconstruction in magnetic resonance imaging.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:19:59 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 20:38:44 GMT""}]","2021-04-14"
"2012.00140","John Mackereth","J. Ted Mackereth, Andrea Miglio, Yvonne Elsworth, Benoit Mosser,
  Savita Mathur, Rafael A. Garcia, Domenico Nardiello, Oliver J. Hall, Mathieu
  Vrard, Warrick H. Ball, Sarbani Basu, Rachael L. Beaton, Paul G. Beck, Maria
  Bergemann, Diego Bossini, Luca Casagrande, Tiago L. Campante, William J.
  Chaplin, Christina Chiappini, L\'eo Girardi, Andreas Christ S{\o}lvsten
  J{\o}rgensen, Saniya Khan, Josefina Montalb\'an, Martin B. Nielsen, Marc H.
  Pinsonneault, Tha\'ise S. Rodrigues, Aldo Serenelli, Victor Silva Aguirre,
  Dennis Stello, Jamie Tayar, Johanna Teske, Jennifer L. van Saders and Emma
  Willett","Prospects for Galactic and stellar astrophysics with asteroseismology of
  giant stars in the $\it{TESS}$ Continuous Viewing Zones and beyond","15 Pages (+6 Pages Appendices), 14 Figures (+3 in Appendices).
  Re-submitted to MNRAS following positive initial review. Full catalogue with
  seismic parameters, mass and age estimates available at
  https://zenodo.org/record/4299142#.X8VseC2ZNNk",,"10.1093/mnras/stab098",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The NASA-$\it{TESS}$ mission presents a treasure trove for understanding the
stars it observes and the Milky Way, in which they reside. We present a first
look at the prospects for Galactic and stellar astrophysics by performing
initial asteroseismic analyses of bright ($G < 11$) red giant stars in the
$\it{TESS}$ Southern Continuous Viewing Zone (SCVZ). Using three independent
pipelines, we detect $\nu_{\mathrm{max}}$ and $\Delta\nu$ in 41% of the 15,405
star parent sample (6,388 stars), with consistency at a level of $\sim 2\%$ in
$\nu_{\mathrm{max}}$ and $\sim 5\%$ in $\Delta\nu$. Based on this, we predict
that seismology will be attainable for $\sim 3\times10^{5}$ giants across the
whole sky, subject to improvements in analysis and data reduction techniques.
The best quality $\it{TESS}$-CVZ data, for 5,574 stars where pipelines returned
consistent results, provide high quality power spectra across a number of
stellar evolutionary states. This makes possible studies of, for example, the
Asymptotic Giant Branch bump (AGBb). We demonstrate that mixed $\ell=1$ modes
and rotational splitting are cleanly observed in the 1-year data set. By
combining $\it{TESS}$-CVZ data with $\it{TESS}$-HERMES, $\it{SkyMapper}$,
APOGEE and $\it{Gaia}$ we demonstrate the potential for Galactic archaeology
studies using the data, which provides good age precision and accuracy that
reproduces the age of high $\mathrm{[\alpha/Fe]}$ stars and relationships
between mass and kinematics from studies based on $\it{Kepler}$. Better quality
astrometry and simpler target selection than the $\it{Kepler}$ sample makes
this data ideal for studies of the local star formation history and evolution
of the Galactic disc. These results provide a strong case for detailed
spectroscopic follow-up in the CVZs to complement that which has been (or will
be) collected by current surveys. [Abridged]
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:20:51 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 17:17:33 GMT""}]","2021-01-20"
"2012.00141","Marcin Stawiski","Marcin Stawiski","The role of the Axiom of Choice in proper and distinguishing colourings",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Call a colouring of a graph distinguishing if the only automorphism which
preserves it is the identity. We investigate the role of the Axiom of Choice in
the existence of certain proper or distinguishing colourings in both vertex and
edge variants with special emphasis on locally finite connected graphs. We show
that every locally finite connected graph has a distinguishing colouring with
at most countable number of colours or every locally finite connected graph has
a proper colouring with at most countable number of colours if and only if
K\H{o}nig's Lemma holds. This statement holds for both vertex and edge
colourings. Furthermore, we show that it is not provable in ZF that such
colourings exist even for every connected graph with maximum degree 3. We also
formulate a few conditions about distinguishing and proper colourings which are
equivalent to the Axiom of Choice.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:37:05 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 11:20:01 GMT""},{""version"":""v3"",""created"":""Thu, 4 May 2023 11:23:18 GMT""}]","2023-05-05"
"2012.00142","Daniel Sinambela","Daniel Sinambela","Large-amplitude solitary waves in two-layer density stratified water","57 pages, 2 figures",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a large-amplitude existence theory for two-dimensional solitary
waves propagating through a two layer body of water. The domain of the fluid is
bounded below by an impermeable flat ocean floor and above by a free boundary
at constant pressure. For any piecewise smooth upstream density distribution
and laminar background current, we construct a global curve of solutions. This
curve bifurcates from the background current and, following along the curve, we
find waves that are arbitrarily close to having horizontal stagnation points.
  The small-amplitude waves are constructed using a center manifold reduction
technique. The large-amplitude theory is obtained through analytical global
bifurcation together with refined qualitative properties of the waves.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:40:15 GMT""}]","2020-12-02"
"2012.00143","Umair Mohammad","Umair Mohammad, Sameh Sorour, Mohamed Hefeida","Task Allocation for Asynchronous Mobile Edge Learning with Delay and
  Energy Constraints","12 pages, 5 figures",,,,"cs.LG cs.NI","http://creativecommons.org/licenses/by/4.0/","  This paper extends the paradigm of ""mobile edge learning (MEL)"" by designing
an optimal task allocation scheme for training a machine learning model in an
asynchronous manner across mutiple edge nodes or learners connected via a
resource-constrained wireless edge network. The optimization is done such that
the portion of the task allotted to each learner is completed within a given
global delay constraint and a local maximum energy consumption limit. The time
and energy consumed are related directly to the heterogeneous communication and
computational capabilities of the learners; i.e. the proposed model is
heterogeneity aware (HA). Because the resulting optimization is an NP-hard
quadratically-constrained integer linear program (QCILP), a two-step
suggest-and-improve (SAI) solution is proposed based on using the solution of
the relaxed synchronous problem to obtain the solution to the asynchronous
problem. The proposed HA asynchronous (HA-Asyn) approach is compared against
the HA synchronous (HA-Sync) scheme and the heterogeneity unaware (HU) equal
batch allocation scheme. Results from a system of 20 learners tested for
various completion time and energy consumption constraints show that the
proposed HA-Asyn method works better than the HU synchronous/asynchronous
(HU-Sync/Asyn) approach and can provide gains of up-to 25\% compared to the
HA-Sync scheme.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:45:59 GMT""},{""version"":""v2"",""created"":""Fri, 4 Dec 2020 18:01:02 GMT""}]","2020-12-07"
"2012.00144","Alireza Borjali","Gergo Merkely, Alireza Borjali, Molly Zgoda, Evan M. Farina, Simon
  Gortz, Orhun Muratoglu, Christian Lattermann, Kartik M. Varadarajan","Improved Diagnosis of Tibiofemoral Cartilage Defects on MRI Images Using
  Deep Learning",,"https://doi.org/10.1016/j.jcjp.2021.100009","10.1016/j.jcjp.2021.100009",,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background: MRI is the modality of choice for cartilage imaging; however, its
diagnostic performance is variable and significantly lower than the gold
standard diagnostic knee arthroscopy. In recent years, deep learning has been
used to automatically interpret medical images to improve diagnostic accuracy
and speed. Purpose: The primary purpose of this study was to evaluate whether
deep learning applied to the interpretation of knee MRI images can be utilized
to identify cartilage defects accurately. Methods: We analyzed data from
patients who underwent knee MRI evaluation and consequently had arthroscopic
knee surgery (207 with cartilage defect, 90 without cartilage defect).
Patients' arthroscopic findings were compared to preoperative MRI images to
verify the presence or absence of isolated tibiofemoral cartilage defects. We
developed three convolutional neural networks (CNNs) to analyze the MRI images
and implemented image-specific saliency maps to visualize the CNNs'
decision-making process. To compare the CNNs' performance against human
interpretation, the same test dataset images were provided to an experienced
orthopaedic surgeon and an orthopaedic resident. Results: Saliency maps
demonstrated that the CNNs learned to focus on the clinically relevant areas of
the tibiofemoral articular cartilage on MRI images during the decision-making
processes. One CNN achieved higher performance than the orthopaedic surgeon,
with two more accurate diagnoses made by the CNN. All the CNNs outperformed the
orthopaedic resident. Conclusion: CNN can be used to enhance the diagnostic
performance of MRI in identifying isolated tibiofemoral cartilage defects and
may replace diagnostic knee arthroscopy in certain cases in the future.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:50:37 GMT""}]","2021-06-24"
"2012.00145","Yuhan Jiang","Kathlen Kohn, Rosa Winter, Yuhan Jiang","Linear Spaces of Symmetric Matrices with Non-Maximal Maximum Likelihood
  Degree",,,,,"math.AG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the maximum likelihood degree of linear concentration models in
algebraic statistics. We relate the geometry of the reciprocal variety to that
of semidefinite programming. We show that the Zariski closure in the
Grassmanian of the set of linear spaces that do not attain their maximal
possible maximum likelihood degree coincides with the Zariski closure of the
set of linear spaces defining a projection with non-closed image of the
positive semidefinite cone. In particular, this shows that this closure is a
union of coisotropic hypersurfaces.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:53:11 GMT""}]","2020-12-02"
"2012.00146","Deidre A. Hunter","Deidre A. Hunter, Bruce G. Elmegreen, Esther Goldberger, Hannah
  Taylor, Anton I. Ermakov, Kimberly A. Herrmann, Se-Heon Oh, Bradley Malko,
  Brian Barandi, and Ryan Jundt","Relationships between the Stellar, Gaseous, and Star Formation Disks in
  LITTLE THINGS Dwarf Irregular Galaxies: Indirect Evidence for Substantial
  Fractions of Dark Molecular Gas","In press in the Astronomical Journal",,"10.3847/1538-3881/abd089",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The stellar, gaseous and young stellar disks in the LITTLE THINGS sample of
nearby dIrrs are fitted with functions to search for correlations between the
parameters. We find that the HI radial profiles are generally flatter in the
center and fall faster in the outer regions than the V-band profiles, while
young stars are more centrally concentrated, especially if the HI is more
centrally flat. This pattern suggests that the HI is turning into molecules in
the center and the molecular clouds are forming stars and FUV. A model that
assumes the molecular surface density is proportional to the total gas surface
density to a power of 1.5 or 2, in analogy with the Kennicutt-Schmidt relation,
reproduces the relationship between the ratio of the visible to the HI scale
length and the HI Sersic index. The molecular fraction is estimated as a
function of radius for each galaxy by converting the FUV to a molecular surface
density using conventional calibrations. The average molecular fraction inside
3R_D is 23+/-17%. However, the break in the stellar surface brightness profile
has no unified tracer related to star formation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:54:14 GMT""}]","2021-01-27"
"2012.00147","Mina Aziziha","Mina Aziziha, Saeed Akbarshahi, Suresh Pittala, Sayandeep Ghosh,
  Rishmali Sooriyagoda, Aldo H. Romero, Subhash Thota, Alan D. Bristow,
  Mohindar S. Seehra, and Matthew B. Johnson","Experimental and Computational Studies of the Optical Properties of
  CuAl1-xFexO2",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Delafossites are promising candidates for photocatalysis applications because
of their chemical stability and absorption in the solar region of the
electromagnetic spectrum. For example, CuAlO2 has good chemical stability but
has a large indirect bandgap (~3 eV), so that efforts to improve its absorption
in the solar region through alloying are investigated. The effect of dilute
alloying on the optical absorption of powdered CuAl1-xFexO2 (x = 0.0-1.0) is
measured and compared to electronic band structures calculations using a
generalized gradient approximation with Hubbard exchange-correlation parameter
and spin. A new absorption feature is observed at 1.8 eV for x = 0.01, which
redshifts to 1.4 eV for x = 0.10. This feature is associated with transitions
from the L-point valence band maximum to the Fe-3d state that appears below the
conduction band of the spin-down band structure. The feature increases the
optical absorption below the bandgap of pure CuAlO2, making dilute CuAl1-xFexO2
alloys better suited for solar photocatalysis.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:56:16 GMT""}]","2020-12-02"
"2012.00148","Tatyana Ivanova","Tatyana Ivanova","Contact join-semilattices",,"Studia Logica, 2022","10.1007/s11225-022-09994-1",,"math.LO","http://creativecommons.org/licenses/by/4.0/","  Contact algebra is one of the main tools in region-based theory of space. In
\cite{dmvw1, dmvw2,iv,i1} it is generalized by dropping the operation Boolean
complement. Furthermore we can generalize contact algebra by dropping also the
operation meet. Thus we obtain structures, called contact join-semilattices
(CJS) and structures, called distributive contact join-semilattices (DCJS). We
obtain a set-theoretical representation theorem for CJS and a relational
representation theorem for DCJS. As corollaries we get also topological
representation theorems. We prove that the universal theory of CJS and of DCJS
is the same and is decidable.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:57:38 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 20:04:34 GMT""}]","2022-05-17"
"2012.00149","Yernat Assylbekov","Yernat M. Assylbekov, Maarten V. de Hoop","Unique recovery of electrical conductivity and magnetic permeability
  from Magneto-Telluric data","26 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a comprehensive mathematical study of the Magneto-Telluric (MT)
method, on bounded domain in $\mathbb{R}^3$. We show that electrical
conductivity and magnetic permeability, assumed to be $C^2$, can be uniquely
recovered from MT data measured on the boundary of the domain. The proof is
based on the construction of complex geometric optics solutions. Furthermore,
we obtain a unique determination result in the case when the MT data are
measured only on an open subset of the boundary. Here, we assume that the part
of the boundary inaccessible for measurements is a subset of a sphere.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:58:52 GMT""}]","2020-12-02"
"2012.00150","Hanchen Xie","Hanchen Xie, Mohamed E. Hussein, Aram Galstyan, Wael Abd-Almageed","MUSCLE: Strengthening Semi-Supervised Learning Via Concurrent
  Unsupervised Learning Using Mutual Information Maximization","10 pages, 3 figures, Accepted to WACV2021",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep neural networks are powerful, massively parameterized machine learning
models that have been shown to perform well in supervised learning tasks.
However, very large amounts of labeled data are usually needed to train deep
neural networks. Several semi-supervised learning approaches have been proposed
to train neural networks using smaller amounts of labeled data with a large
amount of unlabeled data. The performance of these semi-supervised methods
significantly degrades as the size of labeled data decreases. We introduce
Mutual-information-based Unsupervised & Semi-supervised Concurrent LEarning
(MUSCLE), a hybrid learning approach that uses mutual information to combine
both unsupervised and semi-supervised learning. MUSCLE can be used as a
stand-alone training scheme for neural networks, and can also be incorporated
into other learning approaches. We show that the proposed hybrid model
outperforms state of the art on several standard benchmarks, including
CIFAR-10, CIFAR-100, and Mini-Imagenet. Furthermore, the performance gain
consistently increases with the reduction in the amount of labeled data, as
well as in the presence of bias. We also show that MUSCLE has the potential to
boost the classification performance when used in the fine-tuning phase for a
model pre-trained only on unlabeled data.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:01:04 GMT""}]","2020-12-02"
"2012.00151","Sobhan Goudarzi","Sobhan Goudarzi, Amir Asif, and Hassan Rivaz","Plane-Wave Ultrasound Beamforming Through Independent Component Analysis",,,,,"eess.IV","http://creativecommons.org/licenses/by/4.0/","  Beamforming in plane-wave imaging (PWI) is an essential step in creating
images with optimal quality. Adaptive methods estimate the apodization weights
from echo traces acquired by several transducer elements. Herein, we formulate
plane-wave beamforming as a blind source separation problem. The output of each
transducer element is considered as a non-independent observation of the field.
As such, beamforming can be formulated as the estimation of an independent
component out of the observations. We then adapt the independent component
analysis (ICA) algorithm to solve this problem and reconstruct the final image.
The proposed method is evaluated on a set of simulation, real phantom, and in
vivo data available from the PWI challenge in medical ultrasound. The
performance of the proposed beamforming approach is also evaluated in different
imaging settings. The proposed algorithm improves lateral resolution by as much
as $36.5\%$ and contrast by $10\%$ as compared to the classical delay and sum.
Moreover, results are compared with other well-known adaptive methods. Finally,
the robustness of the proposed method to noise is investigated.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:02:23 GMT""}]","2020-12-02"
"2012.00152","Pedro Domingos","Pedro Domingos","Every Model Learned by Gradient Descent Is Approximately a Kernel
  Machine","12 pages, 2 figures",,,,"cs.LG cs.NE stat.ML","http://creativecommons.org/licenses/by/4.0/","  Deep learning's successes are often attributed to its ability to
automatically discover new representations of the data, rather than relying on
handcrafted features like other learning methods. We show, however, that deep
networks learned by the standard gradient descent algorithm are in fact
mathematically approximately equivalent to kernel machines, a learning method
that simply memorizes the data and uses it directly for prediction via a
similarity function (the kernel). This greatly enhances the interpretability of
deep network weights, by elucidating that they are effectively a superposition
of the training examples. The network architecture incorporates knowledge of
the target function into the kernel. This improved understanding should lead to
better learning algorithms.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:02:47 GMT""}]","2020-12-02"
"2012.00153","Ephraim Fischbach","M. H. McDuffie, P. Graham, J. L. Eppele, J. T. Gruenwald, D. Javorsek
  II, D. E. Krause, E. Fischbach","Anomalies in Radioactive Decay Rates: A Bibliography of Measurements and
  Theory","30 pages, fixed hyperlink issue",,,,"nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge of the decay rates (or half-lives) of radioisotopes is critical in
many fields, including medicine, archeology, and nuclear physics, to name just
a few. Central to the many uses of radioisotopes is the belief that decay rates
are fundamental constants of nature, just as the masses of the radioisotopes
themselves are. Recently, the belief that decay rates are fundamental constants
has been called into question following the observation of various reported
anomalies in decay rates, such as apparent periodic variations. The purpose of
this bibliography is to collect in one place the relevant literature on both
sides of this issue in the expectation that doing so will deepen our
understanding of the available data.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:04:52 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 21:19:35 GMT""}]","2020-12-07"
"2012.00154","Kiarash Gordiz","Kiarash Gordiz, Sokseiha Muy, Wolfgang G. Zeier, Yang Shao-Horn,
  Asegun Henry","Enhancement of Ion Diffusion by Targeted Phonon Excitation","50 pages, 17 figures",,,,"cond-mat.mtrl-sci physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Ion diffusion is important in a variety of applications, yet fundamental
understanding of the diffusive process in solids is still missing, especially
considering the interaction of lattice vibrations (phonons) and the mobile
species. In this work, we introduce two formalisms that determine the
individual contributions of normal modes of vibration (phonons) to the
diffusion of ions through a solid, based on (i) Nudged Elastic Band (NEB)
calculations and (ii) molecular dynamics (MD) simulations. The results for a
model ion conductor of $\rm{Ge}$-substituted $\rm{Li_3PO_4}$
($\rm{Li_{3.042}Ge_{0.042}P_{0.958}O_4}$) revealed that more than 87% of the
$\rm{Li^+}$ ion diffusion in the lattice originated from a subset of less than
10% of the vibrational modes with frequencies between 8 and 20 THz. By
deliberately exciting a small targeted subset of these contributing modes (less
than 1%) to a higher temperature and still keeping the lattice at low
temperature, we observed an increase in diffusivity by several orders of
magnitude, consistent with what would be observed if the entire material (i.e.,
all modes) were excited to the same high temperature. This observation suggests
that an entire material need not be heated to elevated temperatures to increase
diffusivity, but instead only the modes that contribute to diffusion, or more
generally a reaction/transition pathway, need to be excited to elevated
temperatures. This new understanding identifies new avenues for increasing
diffusivity by engineering the vibrations in a material, and/or increasing
diffusivity by external stimuli/excitation of phonons (e.g., via photons or
other interactions) without necessarily changing the compound chemistry.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:07:28 GMT""}]","2020-12-02"
"2012.00155","Abu Jahid","Abu Jahid, Mohammed H. Alsharif, Trevor J. Hall","A Contemporary Survey on Free Space Optical Communication: Potential,
  Technical Challenges, Recent Advances and Research Direction","59 pages, 14 figures",,,,"cs.IT cs.SY eess.SY math.IT","http://creativecommons.org/licenses/by/4.0/","  Optical wireless communication (OWC) covering an ultra-wide range of
unlicensed spectrum has emerged as an extent efficient solution to mitigate
conventional RF spectrum scarcity ranging from communication distances from nm
to several kilometers. Free space optical (FSO) systems operating near IR (NIR)
band in OWC links has received substantial attention for enormous data
transmission between fixed transceivers covering few kilometers path distance
due to high optical bandwidth and higher bit rate as well. Despite the
potential benefits of FSO technology, its widespread link reliability suffers
especially in the long-range deployment due to atmospheric turbulence, cloud
induced fading, some other environmental factors such as fog, aerosol,
temperature variations, storms, heavy rain, cloud, pointing error, and
scintillation. FSO has the potential to offloading massive traffic demands from
RF networks, consequently the combined application of FSO/RF and radio over FSO
(RoFSO) systems is regarded as an excellent solution to support 5G and beyond
for improving the limitations of an individual system. This survey presents the
overview of several key technologies and implications of state-of-the-art
criteria in terms of spectrum reuse, classification, architecture and
applications are described for understanding FSO. This paper provides
principle, significance, demonstration, and recent technological development of
FSO technology among different appealing optical wireless technologies. The
opportunities in the near future, the potential challenges that need to be
addressed to realize the successful deployment of FSO schemes are outlined.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:08:32 GMT""}]","2020-12-02"
"2012.00156","Carlotta Pittori","Carlotta Pittori","AGILE results on relativistic outflows above 100 MeV","9 pages, 5 figures","International Journal of Modern Physics D, Vol. 27, No. 10,
  1844015 (2018)","10.1142/S0218271818440157",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an overview of the AGILE gamma-ray satellite scientific highlights.
AGILE is an Italian Space Agency (ASI) mission devoted to observations in the
30 MeV - 50 GeV gamma-ray energy range, with simultaneous X-ray imaging in the
18-60 keV band. Launched in April 2007, the AGILE satellite has completed its
tenth year of operations in orbit, and it is substantially contributing to
improve our knowledge of the high-energy sky. Emission from cosmic sources at
energies above 100 MeV is intrinsically non-thermal, and the study of the wide
variety of observed Galactic and extragalactic gamma-ray sources provides a
unique opportunity to test theories of particle acceleration and radiation
processes in extreme conditions.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:10:16 GMT""}]","2020-12-02"
"2012.00157","Zachary Kilpatrick PhD","Subekshya Bidari and Zachary P Kilpatrick","Hive geometry shapes the recruitment rate of honeybee colonies","32 pages; 10 figures",,,,"q-bio.PE math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Honey bees make decisions regarding foraging and nest-site selection in
groups ranging from hundreds to thousands of individuals. To effectively make
these decisions bees need to communicate within a spatially distributed group.
However, the spatiotemporal dynamics of honey bee communication have been
mostly overlooked in models of collective decisions, focusing primarily on mean
field models of opinion dynamics. We analyze how the spatial properties of the
nest or hive, and the movement of individuals with different belief states
(uncommitted or committed) therein affect the rate of information transmission
using spatially-extended models of collective decision-making within a hive.
Honeybees waggle-dance to recruit conspecifics with an intensity that is a
threshold nonlinear function of the waggler concentration. Our models range
from treating the hive as a chain of discrete patches to a continuous line
(long narrow hive). The combination of population-thresholded recruitment and
compartmentalized populations generates tradeoffs between rapid information
propagation with strong population dispersal and recruitment failures resulting
from excessive population diffusion and also creates an effective colony-level
signal-detection mechanism whereby recruitment to low quality objectives is
blocked.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:10:54 GMT""}]","2020-12-02"
"2012.00158","Benjamin Cho","Benjamin Y. Cho, Jeageun Jung, Mattan Erez","Accelerating Bandwidth-Bound Deep Learning Inference with Main-Memory
  Accelerators",,,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  DL inference queries play an important role in diverse internet services and
a large fraction of datacenter cycles are spent on processing DL inference
queries. Specifically, the matrix-matrix multiplication (GEMM) operations of
fully-connected MLP layers dominate many inference tasks. We find that the GEMM
operations for datacenter DL inference tasks are memory bandwidth bound,
contrary to common assumptions: (1) strict query latency constraints force
small-batch operation, which limits reuse and increases bandwidth demands; and
(2) large and colocated models require reading the large weight matrices from
main memory, again requiring high bandwidth without offering reuse
opportunities. We demonstrate the large potential of accelerating these
small-batch GEMMs with processing in the main CPU memory. We develop a novel
GEMM execution flow and corresponding memory-side address-generation logic that
exploits GEMM locality and enables long-running PIM kernels despite the complex
address-mapping functions employed by the CPU that would otherwise destroy
locality. Our evaluation of StepStone variants at the channel, device, and
within-device PIM levels, along with optimizations that balance parallelism
benefits with data-distribution overheads demonstrate $12\times$ better minimum
latency than a CPU and $2.8\times$ greater throughput for strict query latency
constraints. End-to-end performance analysis of recent recommendation and
language models shows that StepStone PIM outperforms a fast CPU (by up to
$16\times$) and prior main-memory acceleration approaches (by up to $2.4\times$
compared to the best prior approach).
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:22:42 GMT""}]","2020-12-02"
"2012.00159","F\'elix Parraud","Beno\^it Collins and F\'elix Parraud","Concentration estimates for random subspaces of a tensor product, and
  application to Quantum Information Theory",,,,,"quant-ph math-ph math.MP math.OA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a random subspace $H_n$ chosen uniformly in a tensor product of Hilbert
spaces $V_n\otimes W$, we consider the collection $K_n$ of all singular values
of all norm one elements of $H_n$ with respect to the tensor structure. A law
of large numbers has been obtained for this random set in the context of $W$
fixed and the dimension of $H_n$ and $V_n$ tending to infinity at the same
speed in a paper of Belinschi, Collins and Nechita. In this paper, we provide
measure concentration estimates in this context. The probabilistic study of
$K_n$ was motivated by important questions in Quantum Information Theory, and
allowed to provide the smallest known dimension (184) for the dimension an an
ancilla space allowing Minimum Output Entropy (MOE) violation. With our
estimates, we are able, as an application, to provide actual bounds for the
dimension of spaces where violation of MOE occurs.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:22:55 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 15:03:23 GMT""}]","2021-10-01"
"2012.00160","Yuhan Yao","Yuhan Yao, S. R. Kulkarni, K. C. Gendreau, Gaurava K. Jaisawal,
  Teruaki Enoto, Brian W. Grefenstette, Herman L. Marshall, Javier A. Garc\'ia,
  R. M. Ludlam, Sean N. Pike, Mason Ng, Liang Zhang, Diego Altamirano, Amruta
  Jaodand, S. Bradley Cenko, Ronald A. Remillard, James F. Steiner, Hitoshi
  Negoro, Murray Brightman, Amy Lien, Michael T. Wolff, Paul S. Ray, Koji
  Mukai, Zorawar Wadiasingh, Zaven Arzoumanian, Nobuyki Kawai, Tatehiro Mihara,
  Tod E. Strohmayer","A Comprehensive X-ray Report on AT2019wey","Accepted by ApJ",,"10.3847/1538-4357/ac15f8",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here, we present MAXI, SWIFT, NICER, NuSTAR and Chandra observations of the
X-ray transient AT2019wey (SRGA J043520.9+552226, SRGE J043523.3+552234). From
spectral and timing analyses we classify it as a Galactic low-mass X-ray binary
(LMXB) with a black hole (BH) or neutron star (NS) accretor. AT2019wey stayed
in the low/hard state (LHS) from 2019 December to 2020 August 21, and the
hard-intermediate state (HIMS) from 2020 August 21 to 2020 November. For the
first six months of the LHS, AT2019wey had a flux of $\sim 1$ mCrab, and
displayed a power-law X-ray spectrum with photon index $\Gamma = 1.8$. From
2020 June to August, it brightened to $\sim 20$ mCrab. Spectral features
characteristic of relativistic reflection became prominent. On 2020 August 21,
the source left the ""hard line"" on the rms--intensity diagram, and transitioned
from LHS to HIMS. The thermal disk component became comparable to the power-law
component. A low-frequency quasi-periodic oscillation (QPO) was observed. The
QPO central frequency increased as the spectrum softened. No evidence of
pulsation was detected. We are not able to decisively determine the nature of
the accretor (BH or NS). However, the BH option is favored by the position of
this source on the $\Gamma$--$L_{\rm X}$, $L_{\rm radio}$--$L_{\rm X}$, and
$L_{\rm opt}$--$L_{\rm X}$ diagrams. We find the BH candidate XTE J1752-223 to
be an analog of AT2019wey. Both systems display outbursts with long plateau
phases in the hard states. We conclude by noting the potential of SRG in
finding new members of this emerging class of low luminosity and long-duration
LMXB outbursts.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:27:35 GMT""},{""version"":""v2"",""created"":""Sat, 4 Sep 2021 20:48:14 GMT""}]","2021-11-03"
"2012.00161","Pratheep Bondalapati","Pratheep Bondalapati, Abhishek Tiwari, Mustafa Emin Sahin, Qi Tang,
  Srishti Saraswat, Vishvas Suryakumar, Ali Yazdan, Julius Kusuma and Amit
  Dubey","SuperCell: A Wide-Area Coverage Solution Using High-Gain, High-Order
  Sectorized Antennas on Tall Towers",,,,,"eess.SY cs.SY eess.SP","http://creativecommons.org/licenses/by-sa/4.0/","  In this article we introduce a novel solution called SuperCell, which can
improve the return on investment (ROI) for rural area network coverage.
SuperCell offers two key technical features: it uses tall towers with high-gain
antennas for wide coverage and high-order sectorization for high capacity. We
show that a solution encompassing a high-elevation platform in excess of 200
meters increases coverage by 5x. Combined with dense frequency reuse by using
as many as 36 azimuthal sectors from a single location, our solution can
adequately serve the rural coverage and capacity demands. We validate this
through propagation analysis, modeling, and experiments. The article gives a
design perspective using different classes of antennas: Luneburg lens,
active/passive phased array, and spatial multiplexing solutions. For each
class, the corresponding analytical model of the resulting
signal-to-interference plus noise ratio (SINR) based range and capacity
prediction is presented. The spatial multiplexing solution is also validated
through field measurements and additional 3D ray-tracing simulation. Finally,
in this article we also shed light on two recent SuperCell field trials
performed using a Luneburg lens antenna system. The trials took place in rural
New Mexico and Mississippi. In the trials, we quantified the coverage and
capacity of SuperCell in barren land and in a densely forested location,
respectively. In the article, we demonstrate the results obtained in the trials
and share the lessons learned regarding green-field and brown-field
deployments.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:28:08 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 19:14:37 GMT""}]","2020-12-23"
"2012.00162","David Hru\v{s}ka","David Hru\v{s}ka","A note on directional Lipschitz continuity in the Euclidean plane","6 pages",,,,"math.CA","http://creativecommons.org/licenses/by/4.0/","  We prove a stronger version of a conjecture stated in a paper from 2017 by J.
M. Ash and S. Catoiu concerning relations between various notions of the
Lipschitz property and differentiability in the Euclidean plane. We also
provide an improved version of the main result of that paper.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:29:24 GMT""},{""version"":""v2"",""created"":""Tue, 28 Sep 2021 14:10:35 GMT""}]","2021-09-29"
"2012.00163","Yulia Peet","Yulia T. Peet and Matthew M. Peet","A New Treatment of Boundary Conditions in PDE Solution with Galerkin
  Methods via Partial Integral Equation Framework","42 pages, 9 figures",,,,"math.NA cs.NA physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a new analytical and numerical framework for solution of Partial
Differential Equations (PDEs) that is based on an exact transformation that
moves the boundary constraints into the dynamics of the corresponding governing
equation. The framework is based on a Partial Integral Equation (PIE)
representation of PDEs, where a PDE equation is transformed into an equivalent
PIE formulation that does not require boundary conditions on its solution
state. The PDE-PIE framework allows for a development of a generalized
PIE-Galerkin approximation methodology for a broad class of linear PDEs with
non-constant coefficients governed by non-periodic boundary conditions,
including, e.g., Dirichlet, Neumann and Robin boundaries. The significance of
this result is that solution to almost any linear PDE can now be constructed in
a form of an analytical approximation based on a series expansion using a
suitable set of basis functions, such as, e.g., Chebyshev polynomials of the
first kind, irrespective of the boundary conditions. In many cases involving
homogeneous or simple time-dependent boundary inputs, an analytical integration
in time is also possible. We present several PDE solution examples in one
spatial variable implemented with the developed PIE-Galerkin methodology using
both analytical and numerical integration in time. The developed framework can
be naturally extended to multiple spatial dimensions and, potentially, to
nonlinear problems.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:30:15 GMT""},{""version"":""v2"",""created"":""Sat, 24 Apr 2021 22:38:50 GMT""},{""version"":""v3"",""created"":""Sun, 19 Dec 2021 21:38:14 GMT""},{""version"":""v4"",""created"":""Tue, 17 Jan 2023 17:24:49 GMT""},{""version"":""v5"",""created"":""Fri, 10 Feb 2023 22:22:44 GMT""}]","2023-02-14"
"2012.00164","Eric Flesch","Eric Wim Flesch","Identification confusion and blending concealment in the SDSS-DR16
  Quasar catalogues -- 40 new quasars and 82 false quasars identified","Accepted by Monthly Notices of the Royal Astronomical Society. 14
  pages, 22 figures, 2 tables",,"10.1093/mnras/stab812",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The SDSS-DR16 Quasar Superset and pipeline catalogues are searched for
undeclared quasars which were concealed by or confused with other objects,
usually due to incomplete deblending. Forty such quasars with redshifts are
found and herewith presented. Also, 82 entries in the SDSS-DR16Q main quasar
catalogue are shown to be non-quasars, some also due to incomplete deblending,
especially ""line poachers"". Other non-quasars are shown to be star spikes or
moving stars or other types, and 7 new quasars are identified from analysis of
""unplugged"" spectra. These numbers are tiny compared with the millions of DR16
spectra, but highlight some heretofore overlooked systematics. The deblending
issue is discussed throughout.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:31:38 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 04:46:23 GMT""},{""version"":""v3"",""created"":""Wed, 24 Feb 2021 00:07:01 GMT""},{""version"":""v4"",""created"":""Tue, 16 Mar 2021 13:54:00 GMT""}]","2021-03-31"
"2012.00165","Bahador Bahmani","Bahador Bahmani, WaiChing Sun","An accelerated hybrid data-driven/model-based approach for
  poroelasticity problems with multi-fidelity multi-physics data",,"Computer Methods in Applied Mechanics and Engineering 382 (2021)
  113868","10.1016/j.cma.2021.113868",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We present a hybrid model/model-free data-driven approach to solve
poroelasticity problems. Extending the data-driven modeling framework
originated from Kirchdoerfer and Ortiz (2016), we introduce one model-free and
two hybrid model-based/data-driven formulations capable of simulating the
coupled diffusion-deformation of fluid-infiltrating porous media with different
amounts of available data. To improve the efficiency of the model-free data
search, we introduce a distance-minimized algorithm accelerated by a
k-dimensional tree search. To handle the different fidelities of the solid
elasticity and fluid hydraulic constitutive responses, we introduce a
hybridized model in which either the solid and the fluid solver can switch from
a model-based to a model-free approach depending on the availability and the
properties of the data. Numerical experiments are designed to verify the
implementation and compare the performance of the proposed model to other
alternatives.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:36:05 GMT""}]","2021-07-27"
"2012.00166","Derek Frydel","Jorge Munzenmayer and Derek Frydel","The presence of non-analyticities and singularities in the wavefunction
  and the role of invisible delta potentials","5",,,,"quant-ph cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article examines the suggestion made in Ref. [EPL, 115 (2016) 60001]
that a solution to a particle in an infinite spherical well model, if it is
square-integrable, is a physically valid solution, even if at the precise
location of the singularity there is no underlying physical cause, therefore,
the divergence would have to be a nonlocal phenomenon caused by confining walls
at a distance. In this work we examine this claim more carefully. By
identifying the correct differential equation for a divergent square-integrable
solution and rewriting it in the form of the Schroedinger equation, we infer
that the divergent wavefunction would be caused by the potential V(r)=-r
delta(r), which is a kind of attractive delta potential. Because of its
peculiar form and the fact that it leads to a divergent potential energy <V> =
- infinity, the potential V(r) and the divergent wavefunction associated with
it are not physically meaningful.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:37:00 GMT""}]","2020-12-02"
"2012.00167","B. Pinheiro da Silva","B. Pinheiro da Silva, B. A. D. Marques, R. B. Rodrigues, P. H. Souto
  Ribeiro, and A. Z. Khoury","Machine learning recognition of light orbital-angular-momentum
  superpositions",,"Phys. Rev. A 103, 063704 (2021)","10.1103/PhysRevA.103.063704",,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We developed a method to characterize arbitrary superpositions of light
orbital angular momentum (OAM) with high fidelity by using astigmatic
tomography and machine learning processing. In order to define each
superposition unequivocally, we combine two intensity measurements. The first
one is the direct image of the input beam, which cannot distinguish between
opposite OAM components. This ambiguity is removed by a second image obtained
after astigmatic transformation of the input beam. Samples of these image pairs
are used to train a convolution neural network and achieve high fidelity
recognition of arbitrary OAM superpositions with dimension up to five.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:39:57 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 12:57:10 GMT""},{""version"":""v3"",""created"":""Tue, 8 Dec 2020 21:18:44 GMT""}]","2021-06-09"
"2012.00168","Satya Narayan Shukla","Satya Narayan Shukla, Benjamin M. Marlin","A Survey on Principles, Models and Methods for Learning from Irregularly
  Sampled Time Series","Presented at NeurIPS 2020 Workshop: ML Retrospectives, Surveys &
  Meta-Analyses (ML-RSA)",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Irregularly sampled time series data arise naturally in many application
domains including biology, ecology, climate science, astronomy, and health.
Such data represent fundamental challenges to many classical models from
machine learning and statistics due to the presence of non-uniform intervals
between observations. However, there has been significant progress within the
machine learning community over the last decade on developing specialized
models and architectures for learning from irregularly sampled univariate and
multivariate time series data. In this survey, we first describe several axes
along which approaches to learning from irregularly sampled time series differ
including what data representations they are based on, what modeling primitives
they leverage to deal with the fundamental problem of irregular sampling, and
what inference tasks they are designed to perform. We then survey the recent
literature organized primarily along the axis of modeling primitives. We
describe approaches based on temporal discretization, interpolation,
recurrence, attention and structural invariance. We discuss similarities and
differences between approaches and highlight primary strengths and weaknesses.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:41:47 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 20:59:24 GMT""}]","2021-01-07"
"2012.00169","Yuhan Yao","Yuhan Yao, S. R. Kulkarni, Kevin B. Burdge, Ilaria Caiazzo, Kishalay
  De, Dillon Dong, C. Fremling, Mansi M. Kasliwal, Thomas Kupfer, Jan van
  Roestel, Jesper Sollerman, Ashot Bagdasaryan, Eric C. Bellm, S. Bradley
  Cenko, Andrew J. Drake, Dmitry A. Duev, Matthew J. Graham, Stephen Kaye,
  Frank J. Masci, Nicolas Miranda, Thomas A. Prince, Reed Riddle, Ben Rusholme,
  Maayane T. Soumagnac","Multi-wavelength Observations of AT2019wey: a New Candidate Black Hole
  Low-mass X-ray Binary","Accepted by ApJ",,"10.3847/1538-4357/ac15f9",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  AT2019wey (SRGA J043520.9+552226, SRGE J043523.3+552234) is a transient first
reported by the ATLAS optical survey in 2019 December. It rose to prominence
upon detection, three months later, by the Spektrum-Roentgen-Gamma (SRG)
mission in its first all-sky survey. X-ray observations reported in Yao et al.
suggest that AT2019wey is a Galactic low-mass X-ray binary (LMXB) with a black
hole (BH) or neutron star (NS) accretor. Here we present ultraviolet, optical,
near-infrared, and radio observations of this object. We show that the
companion is a short-period (P < 16 hr) low-mass (< 1 Msun) star. We consider
AT2019wey to be a candidate BH system since its locations on the L_radio--L_X
and L_opt--L_X diagrams are closer to BH binaries than NS binaries. We
demonstrate that from 2020 June to August, despite the more than 10 times
brightening at radio and X-ray wavelengths, the optical luminosity of AT2019wey
only increased by 1.3--1.4 times. We interpret the UV/optical emission before
the brightening as thermal emission from a truncated disk in a hot accretion
flow and the UV/optical emission after the brightening as reprocessing of the
X-ray emission in the outer accretion disk. AT2019wey demonstrates that
combining current wide-field optical surveys and SRG provides a way to discover
the emerging population of short-period BH LMXB systems with faint X-ray
outbursts.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:42:11 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 22:56:43 GMT""}]","2021-11-03"
"2012.00170","Gianluca Calcagni","Gianluca Calcagni, Sachiko Kuroyanagi","Stochastic gravitational-wave background in quantum gravity","1+41 pages, 12 figures, 1 table. v2: minor typos corrected,
  clarifications added","JCAP 03(2021)019","10.1088/1475-7516/2021/03/019","IFT-UAM/CSIC-20-171","gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among all cosmological quantum-gravity or quantum-gravity-inspired scenarios,
only very few predict a blue-tilted primordial tensor spectrum. We explore five
of them and check whether they can generate a stochastic gravitational-wave
background detectable by present and future interferometers: non-local quantum
gravity, string-gas cosmology, new ekpyrotic scenario, Brandenberger-Ho
non-commutative inflation and multi-fractional spacetimes. We show that
non-local quantum gravity is unobservable, while all the other models can reach
the strain sensitivity of DECIGO but not that of LIGO-Virgo-KAGRA, LISA or
Einstein Telescope. Other quantum-gravity models with red-tilted spectra (most
loop quantum cosmologies) or with exceptionally tiny quantum corrections
(Wheeler-DeWitt quantum cosmology) are found to be non-detectable.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:49:40 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 21:00:49 GMT""}]","2021-03-12"
"2012.00171","Takashi J. Moriya","Takashi J. Moriya, Ji-an Jiang, Naoki Yasuda, Mitsuru Kokubo, Kojiro
  Kawana, Keiichi Maeda, Yen-Chen Pan, Robert M. Quimby, Nao Suzuki, Ichiro
  Takahashi, Masaomi Tanaka, Nozomu Tominaga, Ken'ichi Nomoto, Jeff Cooke,
  Lluis Galbany, Santiago Gonzalez-Gaitan, Chien-Hsiu Lee, Giuliano Pignata","Constraints on the rate of supernovae lasting for more than a year from
  Subaru/Hyper Suprime-Cam","18 pages, 9 figures, 6 tables, accepted by The Astrophysical Journal","The Astrophysical Journal, Volume 908, Issue 2, id.249, 13 pp.
  (2021)","10.3847/1538-4357/abcfc0",,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Some supernovae such as pair-instability supernovae are predicted to have the
duration of more than a year in the observer frame. To constrain the rates of
supernovae lasting for more than a year, we conducted a long-term deep
transient survey using Hyper Suprime-Cam (HSC) on the 8.2m Subaru telescope.
HSC is a wide-field (a 1.75 deg2 field-of-view) camera and it can efficiently
conduct transient surveys. We observed the same 1.75 deg2 field repeatedly
using the g, r, i, and z band filters with the typical depth of 26 mag for 4
seasons (from late 2016 to early 2020). Using these data, we searched for
transients lasting for more than a year. Two supernovae were detected in 2
continuous seasons, one supernova was detected in 3 continuous seasons, but no
transients lasted for all 4 seasons searched. The discovery rate of supernovae
lasting for more than a year with the typical limiting magnitudes of 26 mag is
constrained to be 1.4^{+1.3}_{-0.7}(stat.)^{+0.2}_{-0.3}(sys.) events deg-2
yr-1. All the long-lasting supernovae we found are likely Type IIn supernovae
and our results indicate that about 40% of Type IIn supernovae have
long-lasting light curves. No plausible pair-instability supernova candidates
lasting for more than a year are discovered. By comparing the survey results
and survey simulations, we constrain the luminous pair-instability supernova
rate up to z ~ 3 should be of the order of 100 Gpc-3 yr-1 at most, which is
0.01 - 0.1 per cent of the core-collapse supernova rate.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:50:25 GMT""}]","2021-08-05"
"2012.00172","Maxwell Van Gelder","Maxwell Van Gelder, Mitchell Wortsman, Kiana Ehsani","Deconstructing the Structure of Sparse Neural Networks","6 pages, 4 figures, Accepted to ML-Retrospectives, Surveys &
  Meta-Analyses @ NeurIPS 2020 Workshop",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Although sparse neural networks have been studied extensively, the focus has
been primarily on accuracy. In this work, we focus instead on network
structure, and analyze three popular algorithms. We first measure performance
when structure persists and weights are reset to a different random
initialization, thereby extending experiments in Deconstructing Lottery Tickets
(Zhou et al., 2019). This experiment reveals that accuracy can be derived from
structure alone. Second, to measure structural robustness we investigate the
sensitivity of sparse neural networks to further pruning after training,
finding a stark contrast between algorithms. Finally, for a recent dynamic
sparsity algorithm we investigate how early in training the structure emerges.
We find that even after one epoch the structure is mostly determined, allowing
us to propose a more efficient algorithm which does not require dense gradients
throughout training. In looking back at algorithms for sparse neural networks
and analyzing their performance from a different lens, we uncover several
interesting properties and promising directions for future research.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:51:33 GMT""}]","2020-12-02"
"2012.00173","Raghav Kansal","Raghav Kansal and Javier Duarte and Breno Orzari and Thiago Tomei and
  Maurizio Pierini and Mary Touranakou and Jean-Roch Vlimant and Dimitrios
  Gunopulos","Graph Generative Adversarial Networks for Sparse Data Generation in High
  Energy Physics","9 pages, 4 figures, 4 tables, To appear in Third Workshop on Machine
  Learning and the Physical Sciences (NeurIPS 2020)",,,,"physics.data-an cs.LG hep-ex hep-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  We develop a graph generative adversarial network to generate sparse data
sets like those produced at the CERN Large Hadron Collider (LHC). We
demonstrate this approach by training on and generating sparse representations
of MNIST handwritten digit images and jets of particles in proton-proton
collisions like those at the LHC. We find the model successfully generates
sparse MNIST digits and particle jet data. We quantify agreement between real
and generated data with a graph-based Fr\'echet Inception distance, and the
particle and jet feature-level 1-Wasserstein distance for the MNIST and jet
datasets respectively.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:53:45 GMT""},{""version"":""v2"",""created"":""Sat, 5 Dec 2020 22:24:34 GMT""},{""version"":""v3"",""created"":""Tue, 8 Dec 2020 20:57:05 GMT""},{""version"":""v4"",""created"":""Sat, 30 Jan 2021 20:20:52 GMT""}]","2021-02-02"
"2012.00174","Andrew Gelman","Andrew Gelman and Aki Vehtari","What are the most important statistical ideas of the past 50 years?",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  We review the most important statistical ideas of the past half century,
which we categorize as: counterfactual causal inference, bootstrapping and
simulation-based inference, overparameterized models and regularization,
Bayesian multilevel models, generic computation algorithms, adaptive decision
analysis, robust inference, and exploratory data analysis. We discuss key
contributions in these subfields, how they relate to modern computing and big
data, and how they might be developed and extended in future decades. The goal
of this article is to provoke thought and discussion regarding the larger
themes of research in statistics and data science.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:54:59 GMT""},{""version"":""v2"",""created"":""Tue, 8 Dec 2020 15:52:22 GMT""},{""version"":""v3"",""created"":""Mon, 18 Jan 2021 13:53:16 GMT""},{""version"":""v4"",""created"":""Thu, 27 May 2021 12:24:54 GMT""},{""version"":""v5"",""created"":""Thu, 3 Jun 2021 15:44:39 GMT""}]","2021-06-04"
"2012.00175","Vishesh Jain","Vishesh Jain, Ashwin Sah, Mehtaab Sawhney","Optimal and algorithmic norm regularization of random matrices","13 pages; comments welcome!",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  Let $A$ be an $n\times n$ random matrix whose entries are i.i.d. with mean
$0$ and variance $1$. We present a deterministic polynomial time algorithm
which, with probability at least $1-2\exp(-\Omega(\epsilon n))$ in the choice
of $A$, finds an $\epsilon n \times \epsilon n$ sub-matrix such that zeroing it
out results in $\widetilde{A}$ with \[\|\widetilde{A}\| =
O\left(\sqrt{n/\epsilon}\right).\] Our result is optimal up to a constant
factor and improves previous results of Rebrova and Vershynin, and Rebrova. We
also prove an analogous result for $A$ a symmetric $n\times n$ random matrix
whose upper-diagonal entries are i.i.d. with mean $0$ and variance $1$.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:55:30 GMT""}]","2020-12-02"
"2012.00176","Clement Nyirenda","Dineshan Subramoney, Clement N. Nyirenda","A Comparative Evaluation of Population-based Optimization Algorithms for
  Workflow Scheduling in Cloud-Fog Environments","8 pages","2020 IEEE Symposium Series on Computational Intelligence (SSCI)
  (SSCI 2020)",,,"cs.NE cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents a comparative evaluation of four population-based
optimization algorithms for workflow scheduling in cloud-fog environments.
These algorithms are as follows: Particle Swarm Optimization (PSO), Genetic
Algorithm (GA), Differential Evolution (DE) and GA-PSO. This work also provides
the motivational groundwork for the weighted sum objective function for the
workflow scheduling problem and develops this function based on three
objectives: makespan, cost and energy. The recently proposed FogWorkflowSim is
used as the simulation environment with the aforementioned objectives serving
performance metrics. Results show that hybrid combination of the GA-PSO
algorithm exhibits slightly better than the standard algorithms. Future work
will include expansion of the workflows used by increasing the number of tasks
as well as adding some more workflows. The addition of some more objectives to
the weighted objective function will also be pursued
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:58:05 GMT""},{""version"":""v2"",""created"":""Sat, 12 Dec 2020 17:39:21 GMT""}]","2020-12-15"
"2012.00177","James Evans","James Evans","The Entropy and Hausdorff Dimension of self-similar sets","9 pages, 8 figures",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  Given a $k$-self similar set $X\subset [0,1]^{d}$ we calculate both its
Hausdorff dimension and its entropy, and show that these two quantities are in
fact equal. This affirmatively resolves a conjecture of Adamczewski and Bell.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 23:58:10 GMT""}]","2020-12-02"
"2012.00178","Runlin Zhang","Runlin Zhang","Counting integral points on some homogeneous varieties with large
  reductive stabilizers","Correct a mistake made in the last section; main results unchanged;
  correct various typos; 20 pages",,,,"math.NT math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let G be a semisimple group over rational numbers and H is a subgroup over
rational numbers. Given a representation of G and an integral vector x whose
stabilizer is equal to H. In this paper we investigate the asymptotic of
integral points on Gx with bounded height. We find its asymptotic up to an
implicit constant when H is large in G but we allow the presence of
intermediate subgroups. This is achieved by a novel combination of two
equidistribution results in two different settings: one is that of Eskin, Mozes
and Shah on a Lie group modulo a lattice and the other one is a result of
Chamber-Loir and Tschinkel on a smooth projective variety with a normal
crossing divisor.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:00:36 GMT""},{""version"":""v2"",""created"":""Thu, 14 Jan 2021 05:54:20 GMT""}]","2021-01-15"
"2012.00179","Benjamin Choi","Benjamin Choi, John Kamalu","Crowd-Sourced Road Quality Mapping in the Developing World","Presented at NeurIPS 2020 Workshop on Machine Learning for the
  Developing World",,,,"cs.LG cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  Road networks are among the most essential components of a country's
infrastructure. By facilitating the movement and exchange of goods, people, and
ideas, they support economic and cultural activity both within and across
borders. Up-to-date mapping of the the geographical distribution of roads and
their quality is essential in high-impact applications ranging from land use
planning to wilderness conservation. Mapping presents a particularly pressing
challenge in developing countries, where documentation is poor and
disproportionate amounts of road construction are expected to occur in the
coming decades. We present a new crowd-sourced approach capable of assessing
road quality and identify key challenges and opportunities in the
transferability of deep learning based methods across domains.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:10:36 GMT""}]","2020-12-02"
"2012.00180","John R.J. Thompson","John R.J. Thompson, W. John Braun","Anisotropic local constant smoothing for change-point regression
  function estimation","30 pages, 12 figures",,,,"stat.ME math.ST stat.AP stat.TH","http://creativecommons.org/licenses/by-sa/4.0/","  Understanding forest fire spread in any region of Canada is critical to
promoting forest health, and protecting human life and infrastructure.
Quantifying fire spread from noisy images, where regions of a fire are
separated by change-point boundaries, is critical to faithfully estimating fire
spread rates. In this research, we develop a statistically consistent smooth
estimator that allows us to denoise fire spread imagery from micro-fire
experiments. We develop an anisotropic smoothing method for change-point data
that uses estimates of the underlying data generating process to inform
smoothing. We show that the anisotropic local constant regression estimator is
consistent with convergence rate $O\left(n^{-1/{(q+2)}}\right)$. We demonstrate
its effectiveness on simulated one- and two-dimensional change-point data and
fire spread imagery from micro-fire experiments.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:11:04 GMT""}]","2020-12-02"
"2012.00181","Leonardo Dinamarca","Leonardo Dinamarca and Maximiliano Escayola","Some examples of distorted interval diffeomorphisms of intermediate
  regularity","15 pages",,,,"math.DS math.GR math.GT math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We improve a recent construction of Andr\'es Navas to produce the first
examples of $C^2$-undistorted diffeomorphisms of the interval that are
$C^{1+\alpha}$-distorted (for every $\alpha < 1$). We do this via explicit
computations due to the failure of an extension to class $C^{1+\alpha}$ of a
classical lemma related to the work of Nancy Kopell.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:11:14 GMT""}]","2020-12-02"
"2012.00182","Shubham Kanodia","Shubham Kanodia, Joe P. Ninan, Andrew J. Monson, Suvrath Mahadevan,
  Colin Nitroy, Christian Schwab, Samuel Halverson, Chad F. Bender, Ryan
  Terrien, Frederick R.Hearty, Emily Lubar, Michael W. McElwain, Lawrence. W.
  Ramsey, Paul M.Robertson, Arpita Roy, Gudmundur Stefansson, and Daniel J.
  Stevens","Ghosts of NEID's Past","Conference Proceeding from SPIE Astronomical Telescopes +
  Instrumentation (2020): 12 pages",,"10.1117/12.2561679",,"astro-ph.IM astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The NEID spectrograph is a R $\sim$ 120,000 resolution fiber-fed and highly
stabilized spectrograph for extreme radial velocity (RV) precision. It is being
commissioned at the 3.5 m WIYN telescope in Kitt Peak National Observatory with
a desired instrumental precision of better than 30 \cms{}. NEID's bandpass of
380 -- 930 nm enables the simultaneous wavelength coverage of activity
indicators from the Ca HK lines in the blue to the Ca IR triplet in the IR. In
this paper we will present our efforts to characterize and mitigate optical
ghosts in the NEID spectrograph during assembly, integration and testing, and
highlight several of the dominant optical element contributors such as the
cross dispersion prism and input optics. We shall present simulations of the
2-D spectrum and discuss the predicted ghost features on the focal plane, and
how they may impact the RV performance for NEID. We also present the mitigation
strategy adopted for each ghost which may be applied to future instrument
designs. This work will enable other instrument builders to potentially avoid
some of these issues, as well as outline mitigation strategies.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:11:44 GMT""},{""version"":""v2"",""created"":""Tue, 8 Dec 2020 17:52:39 GMT""}]","2020-12-09"
"2012.00183","Lijun Ding","Lijun Ding and Madeleine Udell","A Strict Complementarity Approach to Error Bound and Sensitivity of
  Solution of Conic Programs","23 pages, 2 figures. In this revision, we added an approach based on
  conic decomposition. See Section D for details",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we provide an elementary, geometric, and unified framework to
analyze conic programs that we call the strict complementarity approach. This
framework allows us to establish error bounds and quantify the sensitivity of
the solution. The framework uses three classical ideas from convex geometry and
linear algebra: linear regularity of convex sets, facial reduction, and
orthogonal decomposition. We show how to use this framework to derive error
bounds for linear programming (LP), second order cone programming (SOCP), and
semidefinite programming (SDP).
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:23:32 GMT""},{""version"":""v2"",""created"":""Fri, 16 Sep 2022 05:41:03 GMT""}]","2022-09-19"
"2012.00184","Breno Chrispim","B. A. S. D. Chrispim, R. C. L. Bruni and M. S. Guimaraes","Massive photon propagator in the presence of axionic fluctuations","32 pages and 7 figures; added Acknowledgements section; Version to
  appear in PhysRevB","Phys. Rev. B 103, 165120 (2021)","10.1103/PhysRevB.103.165120",,"hep-ph cond-mat.str-el cond-mat.supr-con hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The theory of massive photons in the presence of axions is studied as the
effective theory describing the electromagnetic response of semimetals when a
particular quartic fermionic pairing perturbation triggers the formation of
charged chiral condensates, giving rise to an axionic superconductor. We
investigate corrections to the Yukawa-like potential mediated by massive
photons due to axion excitations up to one-loop order and compute the
modifications of the London penetration length.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:33:04 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jan 2021 20:35:04 GMT""},{""version"":""v3"",""created"":""Fri, 23 Apr 2021 20:43:32 GMT""}]","2021-04-27"
"2012.00185","Kedi Yan","Kedi Yan","Research on Intelligent Charging System Technology of Automobile Group",,,"10.1088/1742-6596/1187/2/022010",,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  This paper analyzes the smart charging system for dealing with issues related
to large parking garages, and analyzes the relevant technical standards of
intelligent charging piles application and comprehensive transportation hubs.
It mainly includes the number, area and charging method of the charging piles
installed in the garages. New forms of construction management is conceived,
and the investment and construction are reinforced, apportioning all charging
system property rights to investment parties. Simultaneously, the investors
take full responsibility for the future management and operation, mainly
including the collection of service fees and charging fees.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:34:46 GMT""}]","2020-12-02"
"2012.00186","Noah Kasmanoff","Noah Kasmanoff, Francisco Villaescusa-Navarro, Jeremy Tinker, Shirley
  Ho","dm2gal: Mapping Dark Matter to Galaxies with Neural Networks","6 pages, 1 figure, paper accepted by the NeurIPS 2020 Machine
  Learning and the Physical Sciences Workshop. Code available at
  https://github.com/nkasmanoff/dm2gal",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Maps of cosmic structure produced by galaxy surveys are one of the key tools
for answering fundamental questions about the Universe. Accurate theoretical
predictions for these quantities are needed to maximize the scientific return
of these programs. Simulating the Universe by including gravity and
hydrodynamics is one of the most powerful techniques to accomplish this;
unfortunately, these simulations are very expensive computationally.
Alternatively, gravity-only simulations are cheaper, but do not predict the
locations and properties of galaxies in the cosmic web. In this work, we use
convolutional neural networks to paint galaxy stellar masses on top of the dark
matter field generated by gravity-only simulations. Stellar mass of galaxies
are important for galaxy selection in surveys and thus an important quantity
that needs to be predicted. Our model outperforms the state-of-the-art
benchmark model and allows the generation of fast and accurate models of the
observed galaxy distribution.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:36:53 GMT""}]","2020-12-02"
"2012.00187","Haitao Liu","Shuiyuan Yu, Chunshan Xu, Haitao Liu","Statistical patterns of word frequency suggesting the probabilistic
  nature of human languages",,,,,"cs.CL physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional linguistic theories have largely regard language as a formal
system composed of rigid rules. However, their failures in processing real
language, the recent successes in statistical natural language processing, and
the findings of many psychological experiments have suggested that language may
be more a probabilistic system than a formal system, and thus cannot be
faithfully modeled with the either/or rules of formal linguistic theory. The
present study, based on authentic language data, confirmed that those important
linguistic issues, such as linguistic universal, diachronic drift, and language
variations can be translated into probability and frequency patterns in parole.
These findings suggest that human language may well be probabilistic systems by
nature, and that statistical may well make inherent properties of human
languages.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:48:27 GMT""}]","2020-12-02"
"2012.00188","Alexander Soen","Alexander Soen, Hisham Husain, Richard Nock","Fair Densities via Boosting the Sufficient Statistics of Exponential
  Families",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  We introduce a boosting algorithm to pre-process data for fairness. Starting
from an initial fair but inaccurate distribution, our approach shifts towards
better data fitting while still ensuring a minimal fairness guarantee. To do
so, it learns the sufficient statistics of an exponential family with
boosting-compliant convergence. Importantly, we are able to theoretically prove
that the learned distribution will have a representation rate and statistical
rate data fairness guarantee. Unlike recent optimization based pre-processing
methods, our approach can be easily adapted for continuous domain features.
Furthermore, when the weak learners are specified to be decision trees, the
sufficient statistics of the learned distribution can be examined to provide
clues on sources of (un)fairness. Empirical results are present to display the
quality of result on real-world data.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:49:17 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 01:09:20 GMT""},{""version"":""v3"",""created"":""Mon, 13 Feb 2023 23:47:41 GMT""}]","2023-02-15"
"2012.00189","Lucas Cieza","Lucas A. Cieza, Camilo Gonz\'alez-Ruilova, Antonio S. Hales, Paola
  Pinilla, Dary Ru\'iz-Rodr\'iguez, Alice Zurlo, Sim\'on Casassus, Sebasti\'an
  P\'erez, Hector C\'anovas, Carla Arce-Tord, Mario Flock, Nicolas Kurtovic,
  Sebastian Marino, Pedro H. Nogueira, Laura Perez, Daniel J. Price, David A.
  Principe and Jonathan P. Williams","The Ophiuchus DIsc Survey Employing ALMA (ODISEA)-III: the evolution of
  substructures in massive discs at 3-5 au resolution","21 pages, 10 figures. Appendix with 3 additional figures. Version 2,
  identical to previous one, but now accepted for publication (in MNRAS)",,"10.1093/mnras/staa3787",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present 1.3 mm continuum ALMA long-baseline observations at 3-5 au
resolution of 10 of the brightest discs from the Ophiuchus DIsc Survey
Employing ALMA (ODISEA) project. We identify a total of 26 narrow rings and
gaps distributed in 8 sources and 3 discs with small dust cavities (r $<$10
au). We find that two discs around embedded protostars lack the clear gaps and
rings that are ubiquitous in more evolved sources with Class II SEDs. Our
sample includes 5 objects with previously known large dust cavities (r $>$20
au). We find that the 1.3 mm radial profiles of these objects are in good
agreement with those produced by numerical simulations of dust evolution and
planet-disc interactions, which predict the accumulation of mm-sized grains at
the edges of planet-induced cavities. Our long-baseline observations resulted
in the largest sample of discs observed at $\sim$3-5 au resolution in any given
star-forming region (15 objects when combined with Ophiuchus objects in the
DSHARP Large Program) and allow for a demographic study of the brightest
$\sim5\%$ of the discs in Ophiuchus (i.e. the most likely formation sites of
giant planets in the cloud). We use this unique sample to propose an
evolutionary sequence and discuss a scenario in which the substructures
observed in massive protoplanetary discs are mainly the result of planet
formation and dust evolution. If this scenario is correct, the detailed study
of disc substructures might provide a window to investigate a population of
planets that remains mostly undetectable by other techniques.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:52:26 GMT""},{""version"":""v2"",""created"":""Sat, 5 Dec 2020 21:45:28 GMT""}]","2020-12-16"
"2012.00190","Sven Buechel","Sven Buechel, Luise Modersohn, and Udo Hahn","Towards Label-Agnostic Emotion Embeddings","EMNLP 2021 camera-ready version",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Research in emotion analysis is scattered across different label formats
(e.g., polarity types, basic emotion categories, and affective dimensions),
linguistic levels (word vs. sentence vs. discourse), and, of course, (few
well-resourced but much more under-resourced) natural languages and text genres
(e.g., product reviews, tweets, news). The resulting heterogeneity makes data
and software developed under these conflicting constraints hard to compare and
challenging to integrate. To resolve this unsatisfactory state of affairs we
here propose a training scheme that learns a shared latent representation of
emotion independent from different label formats, natural languages, and even
disparate model architectures. Experiments on a wide range of datasets indicate
that this approach yields the desired interoperability without penalizing
prediction quality. Code and data are archived under DOI
10.5281/zenodo.5466068.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:54:13 GMT""},{""version"":""v2"",""created"":""Sat, 6 Nov 2021 20:48:40 GMT""}]","2021-11-09"
"2012.00191","Aliaksei Petsiuk","Aliaksei L. Petsiuk and Joshua M. Pearce","Open Source 3-D Filament Diameter Sensor for Recycling, Winding and
  Additive Manufacturing Machines","25 pages, 16 figures, 2 tables",,"10.1115/1.4050762",,"cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  To overcome the challenge of upcycling plastic waste into 3-D printing
filament in the distributed recycling and additive manufacturing systems, this
study designs, builds, tests and validates an open source 3-D filament diameter
sensor for recycling and winding machines. The modular system for multi-axis
optical control of the diameter of the recycled 3-D-printer filament makes it
possible to analyze the surface structure of the processed filament, save the
history of measurements along the entire length of the spool, as well as mark
defective areas. The sensor is developed as an independent module and
integrated into a recyclebot. The diameter sensor was tested on different kinds
of polymers (ABS, PLA) different sources of plastic (recycled 3-D prints and
virgin plastic waste) and different colors including clear plastic. The results
of the diameter measurements using the camera were compared with the manual
measurements, and the measurements obtained with a one-dimensional digital
light caliper. The results found that the developed open source filament
sensing method allows users to obtain significantly more information in
comparison with basic one-dimensional light sensors and using the received data
not only for more accurate diameter measurements, but also for a detailed
analysis of the recycled filament surface. The developed method ensures greater
availability of plastics recycling technologies for the manufacturing community
and stimulates the growth of composite materials creation. The presented system
can greatly enhance the user possibilities and serve as a starting point for a
complete recycling control system that will regulate motor parameters to
achieve the desired filament diameter with acceptable deviations and even
control the extrusion rate on a printer to recover from filament
irregularities.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:54:47 GMT""}]","2021-06-22"
"2012.00192","Anand Jayarajan","Anand Jayarajan, Kimberly Hau, Andrew Goodwin, Gennady Pekhimenko","LifeStream: A High-Performance Stream Processing Engine for Periodic
  Streams",,,"10.1145/3445814.3446725",,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Hospitals around the world collect massive amounts of physiological data from
their patients every day. Recently, there has been an increase in research
interest to subject this data to statistical analysis to gain more insights and
provide improved medical diagnoses. Such analyses require complex computations
on large volumes of data, demanding efficient data processing systems. This
paper shows that currently available data processing solutions either fail to
meet the performance requirements or lack simple and flexible programming
interfaces. To address this problem, we propose \emph{LifeStream}, a
high-performance stream processing engine for physiological data. LifeStream
hits the sweet spot between ease of programming by providing a rich temporal
query language support and performance by employing optimizations that exploit
the periodic nature of physiological data. We demonstrate that LifeStream
achieves end-to-end performance up to $7.5\times$ higher than state-of-the-art
streaming engines and $3.2\times$ than hand-optimized numerical libraries on
real-world datasets and workloads.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:54:57 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 01:44:53 GMT""}]","2021-03-04"
"2012.00193","Muhammad Usman","Muhammad Usman","Lightweight Encryption for the Low Powered IoT Devices","This is a short survey of lightweight encryption algorithms used in
  IoT, submitted as an assignment for the graduate course titled ""Internet of
  Things""",,,,"cs.CR cs.CC","http://creativecommons.org/publicdomain/zero/1.0/","  The internet of things refers to the network of devices connected to the
internet and can communicate with each other. The term things is to refer
non-conventional devices that are usually not connected to the internet. The
network of such devices or things is growing at an enormous rate. The security
and privacy of the data flowing through these things is a major concern. The
devices are low powered and the conventional encryption algorithms are not
suitable to be employed on these devices. In this correspondence a survey of
the contemporary lightweight encryption algorithms suitable for use in the IoT
environment has been presented.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 00:59:33 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 05:15:27 GMT""}]","2020-12-03"
"2012.00194","Luca Saglietti","Luca Saglietti and Lenka Zdeborov\'a","Solvable Model for Inheriting the Regularization through Knowledge
  Distillation",,"Proceedings of the 2nd Mathematical and Scientific Machine
  Learning Conference, PMLR 145:809-846, 2022",,,"cs.LG cond-mat.dis-nn cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years the empirical success of transfer learning with neural
networks has stimulated an increasing interest in obtaining a theoretical
understanding of its core properties. Knowledge distillation where a smaller
neural network is trained using the outputs of a larger neural network is a
particularly interesting case of transfer learning. In the present work, we
introduce a statistical physics framework that allows an analytic
characterization of the properties of knowledge distillation (KD) in shallow
neural networks. Focusing the analysis on a solvable model that exhibits a
non-trivial generalization gap, we investigate the effectiveness of KD. We are
able to show that, through KD, the regularization properties of the larger
teacher model can be inherited by the smaller student and that the yielded
generalization performance is closely linked to and limited by the optimality
of the teacher. Finally, we analyze the double descent phenomenology that can
arise in the considered KD setting.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:01:34 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 16:55:14 GMT""}]","2022-11-11"
"2012.00195","Jesse Vig","Pascal Sturmfels, Jesse Vig, Ali Madani, Nazneen Fatema Rajani","Profile Prediction: An Alignment-Based Pre-Training Task for Protein
  Sequence Models",,,,,"cs.LG q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For protein sequence datasets, unlabeled data has greatly outpaced labeled
data due to the high cost of wet-lab characterization. Recent deep-learning
approaches to protein prediction have shown that pre-training on unlabeled data
can yield useful representations for downstream tasks. However, the optimal
pre-training strategy remains an open question. Instead of strictly borrowing
from natural language processing (NLP) in the form of masked or autoregressive
language modeling, we introduce a new pre-training task: directly predicting
protein profiles derived from multiple sequence alignments. Using a set of
five, standardized downstream tasks for protein models, we demonstrate that our
pre-training task along with a multi-task objective outperforms masked language
modeling alone on all five tasks. Our results suggest that protein sequence
models may benefit from leveraging biologically-inspired inductive biases that
go beyond existing language modeling techniques in NLP.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:01:34 GMT""}]","2020-12-02"
"2012.00196","George Chappelle","George Chappelle, Alan Hastings, Martin Rasmussen","Occupancy times for time-dependent stage-structured models","16 pages, 10 figures",,,,"math.PR q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  During their lifetimes, individuals in populations pass through different
states, and the notion of an occupancy time describes the amount of time an
individual spends in a given set of states. Questions related to this idea were
studied in a recent paper by Roth and Caswell for cases where the environmental
conditions are constant. However, it is truly important to consider the case
where environments are changing randomly or in directional way through time, so
the transition probabilities between different states change over time,
motivating the use of time-dependent stage-structured models.
  Using absorbing inhomogenous Markov chains and the discrete-time
McKendrick--von F{\""o}rster equation, we derive explicit formulas for the
occupancy time, its expectation, and its higher-order moments for
stage-structured models with time-dependent transition rates. We apply our
approach to study a time-dependent model of the Southern Fulmar, and obtain
insights into how the number of breeding attempts depends on external
conditions that vary through time.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:02:05 GMT""}]","2020-12-02"
"2012.00197","Amin Naseri Jorshari","Amin Naseri, Yutao Hu and Wenchen Luo","Unconventional supersymmetric quantum mechanics in spin systems","15 pages, 7 figures",,,,"quant-ph cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that the eigenproblem of any $2\times 2$ matrix Hamiltonian with
discrete eigenvalues is involved with a supersymmetric quantum mechanics. The
energy dependence of the superalgebra marks the disparity between the deduced
supersymmetry and the standard supersymmetric quantum mechanics. The components
of an eigenspinor are superpartners\textemdash up to a $SU(2)$
transformation\textemdash which allows to derive two reduced eigenproblems
diagonalizing the Hamiltonian in the spin subspace. As a result, each component
carries all information encoded in the eigenspinor. We also discuss the
generalization of the formalism to a system of a single spin-$\frac{p}{2}$
coupled with external fields. The unconventional supersymmetry can be regarded
as an extension of the Fulton-Gouterman transformation, which can be
established for a two-level system coupled with multi oscillators displaying a
mirror symmetry. The transformation is exploited recently to solve Rabi-type
models. Correspondingly, we illustrate how the supersymmetric formalism can
solve spin-boson models with no need to appeal a symmetry of the model.
Furthermore, a pattern of entanglement between the components of an eigenstate
of a many-spin system can be unveiled by exploiting the supersymmetric quantum
mechanics associated with single spins which also recasts the eigenstate as a
matrix product state. Examples of many-spin models are presented and solved by
utilizing the formalism.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:03:28 GMT""},{""version"":""v2"",""created"":""Sun, 7 Feb 2021 01:43:04 GMT""}]","2021-02-09"
"2012.00198","Lukas Gustafsson","Carlos Am\'endola, Lukas Gustafsson, Kathl\'en Kohn, Orlando
  Marigliano, Anna Seigal","The Maximum Likelihood Degree of Linear Spaces of Symmetric Matrices","21 pages and 1 figure",,,,"math.AG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study multivariate Gaussian models that are described by linear conditions
on the concentration matrix. We compute the maximum likelihood (ML) degrees of
these models. That is, we count the critical points of the likelihood function
over a linear space of symmetric matrices. We obtain new formulae for the ML
degree, one via Schubert calculus, and another using Segre classes from
intersection theory. We settle the case of codimension one models, and
characterize the degenerate case when the ML degree is zero.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:04:18 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 15:23:09 GMT""}]","2021-02-23"
"2012.00199","Xing Gu","Xing Gu","A distinguished subring of the Chow ring and cohomology of $BPGL_n$","36 pages. TItle changed, Theorem 2 added, Section 2 simplified, with
  a minor error corrected. Comments are welcome",,,,"math.AG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine a subring of the Chow ring and the cohomology of $BPGL_n$, the
classifying space of the projective linear group of degree $n$ over complex
numbers, and explain a way in which this computation might play a role in the
period-index problem. In addition, we show that the Chow ring of $BPGL_n$ is
not generated by the Chern classes of linear representations of $PGL_n$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:05:36 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 11:45:05 GMT""},{""version"":""v3"",""created"":""Thu, 21 Oct 2021 15:05:17 GMT""}]","2021-10-22"
"2012.00200","Mehdi Ouaki","Mehdi Ouaki","Scalar Conservation Laws with white noise initial data","38 pages, 2 figures","Probab. Theory Relat. Fields 182, 955-998 (2022)","10.1007/s00440-021-01083-z",,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The statistical description of the scalar conservation law of the form
$\rho_t=H(\rho)_x$ with $H: \mathbb{R} \rightarrow \mathbb{R}$ a smooth convex
function has been an object of interest when the initial profile
$\rho(\cdot,0)$ is random. The special case when $H(\rho)=\frac{\rho^2}{2}$
(Burgers equation) has in particular received extensive interest in the past
and is now understood for various random initial conditions. We solve in this
paper a conjecture on the profile of the solution at any time $t>0$ for a
general class of hamiltonians $H$ and show that it is a stationary
piecewise-smooth Feller process. Along the way, we study the excursion process
of the two-sided linear Brownian motion $W$ below any strictly convex function
$\phi$ with superlinear growth and derive a generalized Chernoff distribution
of the random variable $\text{argmax}_{z \in \mathbb{R}} (W(z)-\phi(z))$.
Finally, when $\rho(\cdot,0)$ is a white noise derived from an abrupt L\'evy
process, we show that the shocks structure of the solution is a.s discrete at
any fixed time $t>0$ under some mild assumptions on $H$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:06:34 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 21:53:32 GMT""},{""version"":""v3"",""created"":""Wed, 20 Apr 2022 23:26:10 GMT""}]","2022-04-22"
"2012.00201","Michelle A. Lee","Michelle A. Lee, Matthew Tan, Yuke Zhu, Jeannette Bohg","Detect, Reject, Correct: Crossmodal Compensation of Corrupted Sensors","8 pages, 5 figures",,,,"cs.RO cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Using sensor data from multiple modalities presents an opportunity to encode
redundant and complementary features that can be useful when one modality is
corrupted or noisy. Humans do this everyday, relying on touch and
proprioceptive feedback in visually-challenging environments. However, robots
might not always know when their sensors are corrupted, as even broken sensors
can return valid values. In this work, we introduce the Crossmodal Compensation
Model (CCM), which can detect corrupted sensor modalities and compensate for
them. CMM is a representation model learned with self-supervision that
leverages unimodal reconstruction loss for corruption detection. CCM then
discards the corrupted modality and compensates for it with information from
the remaining sensors. We show that CCM learns rich state representations that
can be used for contact-rich manipulation policies, even when input modalities
are corrupted in ways not seen during training time.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:09:22 GMT""}]","2020-12-02"
"2012.00202","Zhibin Li","Zhibin Li, Jian Zhang, Yongshun Gong, Yazhou Yao, Qiang Wu","Field-wise Learning for Multi-field Categorical Data","Accepted at NeurIPS 2020",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new method for learning with multi-field categorical data.
Multi-field categorical data are usually collected over many heterogeneous
groups. These groups can reflect in the categories under a field. The existing
methods try to learn a universal model that fits all data, which is challenging
and inevitably results in learning a complex model. In contrast, we propose a
field-wise learning method leveraging the natural structure of data to learn
simple yet efficient one-to-one field-focused models with appropriate
constraints. In doing this, the models can be fitted to each category and thus
can better capture the underlying differences in data. We present a model that
utilizes linear models with variance and low-rank constraints, to help it
generalize better and reduce the number of parameters. The model is also
interpretable in a field-wise manner. As the dimensionality of multi-field
categorical data can be very high, the models applied to such data are mostly
over-parameterized. Our theoretical analysis can potentially explain the effect
of over-parametrization on the generalization of our model. It also supports
the variance constraints in the learning objective. The experiment results on
two large-scale datasets show the superior performance of our model, the trend
of the generalization error bound, and the interpretability of learning
outcomes. Our code is available at
https://github.com/lzb5600/Field-wise-Learning.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:10:14 GMT""}]","2020-12-02"
"2012.00203","Takahiko Matsubara","Takahiko Matsubara, Chiaki Hikage and Satoshi Kuriki","Minkowski functionals and the nonlinear perturbation theory in the
  large-scale structure: second-order effects","12 pages, 7 figures, 1 table",,,"KEK-TH-2283; KEK-Cosmo-0270","astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The second-order formula of Minkowski functionals in weakly non-Gaussian
fields is compared with the numerical $N$-body simulations. Recently, weakly
non-Gaussian formula of Minkowski functionals is extended to include the
second-order effects of non-Gaussianity in general dimensions. We apply this
formula to the three-dimensional density field in the large-scale structure of
the Universe. The parameters of the second-order formula include several kinds
of skewness and kurtosis parameters. We apply the tree-level nonlinear
perturbation theory to estimate these parameters. First we compare the
theoretical values with those of numerical simulations on the basis of
parameter values, and next we test the performance of the analytic formula
combined with the perturbation theory. The second-order formula outperforms the
first-order formula in general. The performance of the perturbation theory
depends on the smoothing radius applied in defining the Minkowski functionals.
The quantitative comparisons are presented in detail.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:14:06 GMT""}]","2020-12-03"
"2012.00204","Peng Peng","Peng Peng and Jiugen Wang","How to fine-tune deep neural networks in few-shot learning?",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep learning has been widely used in data-intensive applications. However,
training a deep neural network often requires a large data set. When there is
not enough data available for training, the performance of deep learning models
is even worse than that of shallow networks. It has been proved that few-shot
learning can generalize to new tasks with few training samples. Fine-tuning of
a deep model is simple and effective few-shot learning method. However, how to
fine-tune deep learning models (fine-tune convolution layer or BN layer?) still
lack deep investigation. Hence, we study how to fine-tune deep models through
experimental comparison in this paper. Furthermore, the weight of the models is
analyzed to verify the feasibility of the fine-tuning method.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:20:59 GMT""}]","2020-12-02"
"2012.00205","Alejandro P. Riascos","L. K. Eraso-Hernandez, A. P. Riascos, T.M. Michelitsch and J.
  Wang-Michelitsch","Random walks on networks with preferential cumulative damage: Generation
  of bias and aging","23 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:1909.01493","J. Stat. Mech. (2021) 063401","10.1088/1742-5468/abfcb5",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we explore the reduction of functionality in a complex system
as a consequence of cumulative random damage and imperfect reparation, a
phenomenon modeled as a dynamical process on networks. We analyze the global
characteristics of the diffusive movement of random walkers on networks where
the walkers hop considering the capacity of transport of each link. The links
are susceptible to damage that generates bias and aging. We describe the
algorithm for the generation of damage and the bias in the transport producing
complex eigenvalues of the transition matrix that defines the random walker for
different types of graphs, including regular, deterministic, and random
networks. The evolution of the asymmetry of the transport is quantified with
local information in the links and further with non-local information
associated with the transport on a global scale such as the matrix of the mean
first passage times and the fractional Laplacian matrix. Our findings suggest
that systems with greater complexity live longer.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:25:46 GMT""},{""version"":""v2"",""created"":""Sun, 14 Mar 2021 21:10:10 GMT""}]","2021-06-07"
"2012.00206","Ben-Hur Cardoso","Ben-Hur Francisco Cardoso, Sebasti\'an Gon\c{c}alves and Jos\'e
  Roberto Iglesias","Wealth concentration in systems with unbiased binary exchanges",,,"10.1016/j.physa.2021.126123",,"q-fin.GN cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Aiming to describe the wealth distribution evolution, several models consider
an ensemble of interacting economic agents that exchange wealth in binary
fashion. Intriguingly, models that consider an unbiased market, that gives to
each agent the same chances to win in the game, are always out of equilibrium
until the perfect inequality of the final state is attained. Here we present a
rigorous analytical demonstration that any system driven by unbiased binary
exchanges are doomed to drive the system to perfect inequality and zero
mobility.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:30:59 GMT""},{""version"":""v2"",""created"":""Mon, 7 Dec 2020 01:06:32 GMT""}]","2021-06-30"
"2012.00207","Boyu Li","Boyu Li and Dilian Yang","Zappa-Sz\'{e}p actions of groups on product systems","19 pages",,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be a group and $X$ be a product system over a semigroup $P$. Suppose
$G$ has a left action on $P$ and $P$ has a right action on $G$, so that one can
form a Zappa-Sz\'ep product $P\bowtie G$. We define a Zappa-Sz\'ep action of
$G$ on $X$ to be a collection of functions on $X$ that are compatible with both
actions from $P\bowtie G$ in a certain sense. Given a Zappa-Sz\'ep action of
$G$ on $X$, we construct a new product system $X\bowtie G$ over $P\bowtie G$,
called the Zappa-Sz\'ep product of $X$ by $G$. We then associate to $X\bowtie
G$ several universal C*-algebras and prove their respective Hao-Ng type
isomorphisms. A special case of interest is when a Zappa-Sz\'{e}p action is
homogeneous. This case naturally generalizes group actions on product systems
in the literature. For this case, besides the Zappa-Sz\'ep product system
$X\bowtie G$, one can also construct a new type of Zappa-Sz\'{e}p product $X
\widetilde\bowtie G$ over $P$. Some essential differences arise between these
two types of Zappa-Sz\'ep product systems and their associated C*-algebras.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:33:41 GMT""}]","2020-12-02"
"2012.00208","Hossein Seifoory","Hossein Seifoory and Marc M. Dignam","A general approach to model counterpropagating continuous variable
  entangled states in a lossy CROW","8 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:1905.11542",,,,"quant-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  We present a general approach to model an integrated source of
counterpropagating continuous-variable entangled states based on a
coupled-resonator optical waveguide that is pumped by a classical pulsed source
incident from above the waveguide. This paper is an extension of our previous
work~(Ref. \cite{PhysRevA.100.033839}), where we analytically investigated the
generation and propagation of continues-variable entangled states in this
coupled-cavity system in the presence of intrinsic loss. However, in this work,
we employ a numerical method to implement the Schmidt decomposition method
rather than pursuing analytical methods. We show that not only this gives us a
much higher degree of freedom in choosing the pumping parameters which were not
possible to investigate analytically, but also it enables us to go beyond some
of the approximations we had made to derive analytical expressions before.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:35:33 GMT""}]","2020-12-02"
"2012.00209","Alex Calderwood","Eric Bolton, Alex Calderwood, Niles Christensen, Jerome Kafrouni, Iddo
  Drori","High Quality Real-Time Structured Debate Generation",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Automatically generating debates is a challenging task that requires an
understanding of arguments and how to negate or support them. In this work we
define debate trees and paths for generating debates while enforcing a high
level structure and grammar. We leverage a large corpus of tree-structured
debates that have metadata associated with each argument. We develop a
framework for generating plausible debates which is agnostic to the sentence
embedding model. Our results demonstrate the ability to generate debates in
real-time on complex topics at a quality that is close to humans, as evaluated
by the style, content, and strategy metrics used for judging competitive human
debates. In the spirit of reproducible research we make our data, models, and
code publicly available.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:39:38 GMT""}]","2020-12-02"
"2012.00210","Mohamed Elhamdadi","Jose Ceniceros, Mohamed Elhamdadi and Alireza Mashaghi","Enhancement of the Coloring Invariant for Folded Molecular Chains","22 pages. 23 figures. Comments are welcome",,"10.1063/5.0040051",,"math.GT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Folded linear molecular chains are ubiquitous in biology. Folding is mediated
by intra-chain interactions that ""glue"" two or more regions of a chain. The
resulting fold topology is widely believed to be a determinant of biomolecular
properties and function. Recently, knot theory has been extended to describe
the topology of folded linear chains such as proteins and nucleic acids. To
classify and distinguish chain topologies, algebraic structure of quandles has
been adapted and applied. However, the approach is limited as apparently
distinct topologies may end up having the same number of colorings. Here, we
enhance the resolving power of the quandle coloring approach by introducing
Boltzmann weights. We demonstrate that the enhanced coloring invariants can
distinguish fold topologies with an improved resolution.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:42:05 GMT""}]","2021-07-21"
"2012.00211","Ying-Chiao Liao","Chuan-Chi Wang, Ying-Chiao Liao, Ming-Chang Kao, Wen-Yew Liang,
  Shih-Hao Hung","Toward Accurate Platform-Aware Performance Modeling for Deep Neural
  Networks",,,,,"cs.LG cs.AI cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we provide a fine-grain machine learning-based method,
PerfNetV2, which improves the accuracy of our previous work for modeling the
neural network performance on a variety of GPU accelerators. Given an
application, the proposed method can be used to predict the inference time and
training time of the convolutional neural networks used in the application,
which enables the system developer to optimize the performance by choosing the
neural networks and/or incorporating the hardware accelerators to deliver
satisfactory results in time. Furthermore, the proposed method is capable of
predicting the performance of an unseen or non-existing device, e.g. a new GPU
which has a higher operating frequency with less processor cores, but more
memory capacity. This allows a system developer to quickly search the hardware
design space and/or fine-tune the system configuration. Compared to the
previous works, PerfNetV2 delivers more accurate results by modeling detailed
host-accelerator interactions in executing the full neural networks and
improving the architecture of the machine learning model used in the predictor.
Our case studies show that PerfNetV2 yields a mean absolute percentage error
within 13.1% on LeNet, AlexNet, and VGG16 on NVIDIA GTX-1080Ti, while the error
rate on a previous work published in ICBD 2018 could be as large as 200%.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:42:23 GMT""}]","2020-12-02"
"2012.00212","Shuaicheng Liu Prof.","Kunming Luo, Chuan Wang, Shuaicheng Liu, Haoqiang Fan, Jue Wang, Jian
  Sun","UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present an unsupervised learning approach for optical flow estimation by
improving the upsampling and learning of pyramid network. We design a
self-guided upsample module to tackle the interpolation blur problem caused by
bilinear upsampling between pyramid levels. Moreover, we propose a pyramid
distillation loss to add supervision for intermediate levels via distilling the
finest flow as pseudo labels. By integrating these two components together, our
method achieves the best performance for unsupervised optical flow learning on
multiple leading benchmarks, including MPI-SIntel, KITTI 2012 and KITTI 2015.
In particular, we achieve EPE=1.4 on KITTI 2012 and F1=9.38% on KITTI 2015,
which outperform the previous state-of-the-art methods by 22.2% and 15.7%,
respectively.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:57:46 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 05:26:17 GMT""}]","2021-06-03"
"2012.00213","Ahmed Aziz Ezzat","Petros Papadopoulos, David Coit, Ahmed Aziz Ezzat","Seizing Opportunity: Maintenance Optimization in Offshore Wind Farms
  Considering Accessibility, Production, and Crew Dispatch",,,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Operations and Maintenance (O&M) constitute a major contributor to offshore
wind's cost of energy. Due to the harsh and remote environment in which
offshore turbines operate, there has been a growing interest in opportunistic
maintenance scheduling for offshore wind farms, wherein grouping maintenance
tasks is incentivized at times of opportunity. Our survey of the literature,
however, reveals that there is no unified consensus on what constitutes an
""opportunity"" for offshore maintenance. We therefore propose an opportunistic
maintenance scheduling approach which defines an opportunity as either
crew-dispatch-based (initiated by a maintenance crew already dispatched to a
neighboring turbine), production-based (initiated by projected low production
levels), or access-based (initiated by a provisionally open window of turbine
access). We formulate the problem as a multi-staged rolling-horizon mixed
integer linear program, and propose an iterative solution algorithm to identify
the optimal hourly maintenance schedule, which is found to be drastically
different, yet substantially better, than those obtained using
offshore-agnostic strategies. Extensive numerical experiments on actual wind,
wave, and power data demonstrate substantial margins of improvement achieved by
our proposed approach, across a wide variety of key O&M metrics.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:59:08 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 22:35:49 GMT""},{""version"":""v3"",""created"":""Thu, 12 Aug 2021 14:25:48 GMT""}]","2021-08-13"
"2012.00214","Dongkai Li","Dongkai Li, Li Wang, Yuying Liu","A relaxation accelerated two-sweep modulus-based matrix splitting
  iteration method for solving linear complementarity problems",,,,,"math.OC cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a linear complementarity problem, we present a relaxaiton accelerated
two-sweep matrix splitting iteration method. The convergence analysis
illustrates that the proposed method converges to the exact solution of the
linear complementarity problem when the system matrix is an $H_+$-matrix and
the convergence conditions are given. Numerical experiments show that the
proposed method is more efficient than the existing ones.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:59:58 GMT""}]","2020-12-02"
"2012.00215","Claudia Flores-Saviaga","Claudia Flores-Saviaga, Jessica Hammer, Juan Pablo Flores, Joseph
  Seering, Stuart Reeves, Saiph Savage","Audience and Streamer Participation at Scale on Twitch",,,,,"cs.SI cs.HC","http://creativecommons.org/licenses/by/4.0/","  Large-scale streaming platforms such as Twitch are becoming increasingly
popular, but detailed audience-streamer interaction dynamics remain unexplored
at scale. In this paper, we perform a mixed-methods study on a dataset with
over 12 million audience chat messages and 45 hours of streaming video to
understand audience participation and streamer performance on Twitch. We
uncover five types of streams based on size and audience participation styles:
Clique Streams, small streams with close streamer-audience interactions; Rising
Streamers, mid-range streams using custom technology and moderators to
formalize their communities; Chatter-boxes, mid-range streams with established
conversational dynamics; Spotlight Streamers, large streams that engage large
numbers of viewers while still retaining a sense of community; and
Professionals, massive streams with the stadium-style audiences. We discuss
challenges and opportunities emerging for streamers and audiences from each
style and conclude by providing data-backed design implications that empower
streamers, audiences, live streaming platforms, and game designers
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:09:05 GMT""}]","2020-12-02"
"2012.00216","Pawe{\l} Pra{\l}at","Natalie C. Behague, Trent Marbach, Pawel Pralat","Tight Bounds on the Probabilistic Zero Forcing on Hypercubes and Grids","arXiv admin note: substantial text overlap with arXiv:1909.06568",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Zero forcing is a deterministic iterative graph colouring process in which
vertices are coloured either blue or white, and in every round, any blue
vertices that have a single white neighbour force these white vertices to
become blue. Here we study probabilistic zero forcing, where blue vertices have
a non-zero probability of forcing each white neighbour to become blue. We
explore the propagation time for probabilistic zero forcing on hypercubes and
grids.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:09:56 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 02:35:18 GMT""}]","2021-03-17"
"2012.00217","Roel Van Beeumen","Roel Van Beeumen and Khaled Z. Ibrahim and Gregory D. Kahanamoku-Meyer
  and Norman Y. Yao and Chao Yang","Enhancing Scalability of a Matrix-Free Eigensolver for Studying
  Many-Body Localization",,,,,"cond-mat.dis-nn cs.DC cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In [Van Beeumen, et. al, HPC Asia 2020,
https://www.doi.org/10.1145/3368474.3368497] a scalable and matrix-free
eigensolver was proposed for studying the many-body localization (MBL)
transition of two-level quantum spin chain models with nearest-neighbor $XX+YY$
interactions plus $Z$ terms. This type of problem is computationally
challenging because the vector space dimension grows exponentially with the
physical system size, and averaging over different configurations of the random
disorder is needed to obtain relevant statistical behavior. For each eigenvalue
problem, eigenvalues from different regions of the spectrum and their
corresponding eigenvectors need to be computed. Traditionally, the interior
eigenstates for a single eigenvalue problem are computed via the
shift-and-invert Lanczos algorithm. Due to the extremely high memory footprint
of the LU factorizations, this technique is not well suited for large number of
spins $L$, e.g., one needs thousands of compute nodes on modern high
performance computing infrastructures to go beyond $L = 24$. The matrix-free
approach does not suffer from this memory bottleneck, however, its scalability
is limited by a computation and communication imbalance. We present a few
strategies to reduce this imbalance and to significantly enhance the
scalability of the matrix-free eigensolver. To optimize the communication
performance, we leverage the consistent space runtime, CSPACER, and show its
efficiency in accelerating the MBL irregular communication patterns at scale
compared to optimized MPI non-blocking two-sided and one-sided RMA
implementation variants. The efficiency and effectiveness of the proposed
algorithm is demonstrated by computing eigenstates on a massively parallel
many-core high performance computer.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:10:14 GMT""}]","2020-12-02"
"2012.00218","Shatil Rahman","Shatil Rahman and Steven L. Waslander","Uncertainty-Constrained Differential Dynamic Programming in Belief Space
  for Vision Based Robots","This work has been submitted to the 2021 IEEE International
  Conference on Robotics and Automation (ICRA) with the Robotics and Automation
  Letters (RA-L) option for possible publication. Copyright may be transferred
  without notice, after which this version may no longer be accessible",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Most mobile robots follow a modular sense-planact system architecture that
can lead to poor performance or even catastrophic failure for visual inertial
navigation systems due to trajectories devoid of feature matches. Planning in
belief space provides a unified approach to tightly couple the perception,
planning and control modules, leading to trajectories that are robust to noisy
measurements and disturbances. However, existing methods handle uncertainties
as costs that require manual tuning for varying environments and hardware. We
therefore propose a novel trajectory optimization formulation that incorporates
inequality constraints on uncertainty and a novel Augmented Lagrangian based
stochastic differential dynamic programming method in belief space.
Furthermore, we develop a probabilistic visibility model that accounts for
discontinuities due to feature visibility limits. Our simulation tests
demonstrate that our method can handle inequality constraints in different
environments, for holonomic and nonholonomic motion models with no manual
tuning of uncertainty costs involved. We also show the improved optimization
performance in belief space due to our visibility model.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:19:54 GMT""}]","2020-12-02"
"2012.00219","Alexis Akira Toda","Qingyin Ma, John Stachurski, Alexis Akira Toda","Unbounded Dynamic Programming via the Q-Transform","arXiv admin note: text overlap with arXiv:1911.13025",,"10.1016/j.jmateco.2022.102652",,"math.OC econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new approach to solving dynamic decision problems with unbounded
rewards based on the transformations used in Q-learning. In our case, the
objective of the transform is to convert an unbounded dynamic program into a
bounded one. The approach is general enough to handle problems for which
existing methods struggle, and yet simple relative to other techniques and
accessible for applied work. We show by example that many common decision
problems satisfy our conditions.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:26:07 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 19:33:13 GMT""}]","2022-08-02"
"2012.00220","Saqib Ejaz Awan","Saqib Ejaz Awan, Mohammed Bennamoun, Ferdous Sohel, Frank M
  Sanfilippo, Girish Dwivedi","Imputation of Missing Data with Class Imbalance using Conditional
  Generative Adversarial Networks",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Missing data is a common problem faced with real-world datasets. Imputation
is a widely used technique to estimate the missing data. State-of-the-art
imputation approaches, such as Generative Adversarial Imputation Nets (GAIN),
model the distribution of observed data to approximate the missing values. Such
an approach usually models a single distribution for the entire dataset, which
overlooks the class-specific characteristics of the data. Class-specific
characteristics are especially useful when there is a class imbalance. We
propose a new method for imputing missing data based on its class-specific
characteristics by adapting the popular Conditional Generative Adversarial
Networks (CGAN). Our Conditional Generative Adversarial Imputation Network
(CGAIN) imputes the missing data using class-specific distributions, which can
produce the best estimates for the missing values. We tested our approach on
benchmark datasets and achieved superior performance compared with the
state-of-the-art and popular imputation approaches.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:26:54 GMT""}]","2020-12-02"
"2012.00221","Ziqi Pi","Ziqi Pi, Giovanni Zocchi","Critical behavior in the Artificial Axon","11 pages, 14 figures",,,,"physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Artificial Axon is a unique synthetic system, based on biomolecular
components, which supports action potentials. Here we examine, experimentally
and theoretically, the properties of the threshold for firing in this system.
As in real neurons, this threshold corresponds to the critical point of a
saddle-node bifurcation. We measure the delay time for firing as a function of
the distance to threshold, recovering the expected scaling exponent of $- 1/2$.
We introduce a minimal model of the Morris-Lecar type, validate it on the
experiments, and use it to extend analytical results obtained in the limit of
""fast"" ion channel dynamics. In particular, we discuss the dependence of the
firing threshold on the number of channels. The Artificial Axon is a simplified
system, an Ur-neuron, relying on only one ion channel species for functioning.
Nonetheless, universal properties such as the action potential behavior near
threshold are the same as in real neurons. Thus we may think of the Artificial
Axon as a cell-free breadboard for electrophysiology research.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:28:45 GMT""}]","2020-12-02"
"2012.00222","Dirk Wulferding","Dirk Wulferding, Geunyong Kim, Hoon Kim, Ilkyu Yang, Eric D. Bauer,
  Filip Ronning, Roman Movshovich, Jeehoon Kim","Local characterization of a heavy-fermion superconductor via sub-Kelvin
  magnetic force microscopy",,"Appl. Phys. Lett. 117, 252601 (2020)","10.1063/5.0028517",,"cond-mat.supr-con cond-mat.mtrl-sci physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using magnetic force microscopy operating at sub-Kelvin temperatures we
characterize the heavy-fermion superconductor CeCoIn$_5$. We pinpoint the
absolute London penetration depth $\lambda(0) = 435 \pm 20$ nm and report its
temperature dependence, which is closely linked to the symmetry of the
superconducting gap. In addition, we directly measure the pinning force of
individual Abrikosov vortices and estimate the critical current density $j_c =
9 \times 10^4$ A/cm$^2$. In contrast to the related, well-established tunnel
diode oscillator technique, our method is capable of resolving inhomogeneities
$locally$ on the micrometer-scale at ultra-low temperature.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:40:03 GMT""}]","2020-12-22"
"2012.00223","Yu Chen","Yu Chen","Entropy Linear Response Theory with Non-Markovian Bath","17 pages, 6 figures",,"10.1007/JHEP04(2021)215",,"hep-th cond-mat.quant-gas cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We developed a perturbative calculation for entropy dynamics considering a
sudden coupling between a system and a bath. The theory we developed can work
in general environment without Markovian approximation. A perturbative formula
is given for bosonic environment and fermionic environment, respectively. We
find the Renyi entropy response is only related to the spectral functions of
the system and the environment, together with a specific statistical kernel
distribution function. We find a t^2 growth/decay in the short time limit and a
t linear growth/decay in longer time scale for second Renyi entropy. A
non-monotonic behavior of Renyi entropy for fermionic systems is found to be
quite general when the environment's temperature is lower. A Fourier's law in
heat transport is obtained when two systems' temperature are close to each
other. A consistency check is made for Sachdev-Ye-Kitaev model coupling to free
fermions, a Page curve alike dynamics is found in a process dual to black hole
evaporation. An oscillation of entanglement entropy is found for a gapped
spectrum of environment.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:41:14 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 16:37:35 GMT""},{""version"":""v3"",""created"":""Sun, 20 Dec 2020 06:20:23 GMT""}]","2021-05-12"
"2012.00224","Brett McLean","C\'elia Borlido and Brett McLean","Difference-restriction algebras of partial functions with operators:
  discrete duality and completion","34 pages. Small improvements throughout","Journal of Algebra, Volume 604, (August 2022) 760-789","10.1016/j.jalgebra.2022.03.039",,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We exhibit an adjunction between a category of abstract algebras of partial
functions and a category of set quotients. The algebras are those atomic
algebras representable as a collection of partial functions closed under
relative complement and domain restriction; the morphisms are the complete
homomorphisms. This generalises the discrete adjunction between the atomic
Boolean algebras and the category of sets. We define the compatible completion
of a representable algebra, and show that the monad induced by our adjunction
yields the compatible completion of any atomic representable algebra. As a
corollary, the adjunction restricts to a duality on the compatibly complete
atomic representable algebras, generalising the discrete duality between
complete atomic Boolean algebras and sets. We then extend these adjunction,
duality, and completion results to representable algebras equipped with
arbitrary additional completely additive and compatibility preserving
operators.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:42:30 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 14:14:57 GMT""},{""version"":""v3"",""created"":""Wed, 4 May 2022 11:46:04 GMT""}]","2022-06-15"
"2012.00225","Baijun Li","Baijun Li, \c{S}ahin. K. \""Ozdemir, Xun-Wei Xu, Lin Zhang, Le-Man
  Kuang, Hui Jing","Nonreciprocal optical solitons in a spinning Kerr resonator","8 pages, 4 figures Accepted by Physical Review A","Phys. Rev. A 103, 053522 (2021)","10.1103/PhysRevA.103.053522",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  We propose a spinning nonlinear resonator as an experimentally accessible
platform to achieve nonreciprocal control of optical solitons. Nonreciprocity
here results from the relativistic Sagnac-Fizeau optical drag effect, which is
different for pump fields propagating in the spinning direction or in the
direction opposite to it. We show that in a spinning Kerr resonator, different
soliton states appear for the input fields in different directions. These
nonreciprocal solitons are more stable against losses induced by inter-modal
coupling between clockwise and counterclockwise modes of the resonator. Our
work builds a bridge between nonreciprocal physics and soliton science,
providing a promising route towards achieving soliton-wave optical isolators
and one-way soliton communications.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:43:17 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 02:26:58 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 02:15:30 GMT""},{""version"":""v4"",""created"":""Sat, 22 May 2021 04:22:07 GMT""}]","2021-06-02"
"2012.00226","Jihao Fan","Jihao Fan, Jun Li, Jianxin Wang, Zhihui Wei and Min-Hsiu Hsieh","Asymmetric Quantum Concatenated and Tensor Product Codes with Large
  Z-Distances","36pages, accepted by IEEE Transactions on Communications",,"10.1109/TCOMM.2021.3064566",,"cs.IT math.IT quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a new construction of asymmetric quantum codes
(AQCs) by combining classical concatenated codes (CCs) with tensor product
codes (TPCs), called asymmetric quantum concatenated and tensor product codes
(AQCTPCs) which have the following three advantages. First, only the outer
codes in AQCTPCs need to satisfy the orthogonal constraint in quantum codes,
and any classical linear code can be used for the inner, which makes AQCTPCs
very easy to construct. Second, most AQCTPCs are highly degenerate, which means
they can correct many more errors than their classical TPC counterparts.
Consequently, we construct several families of AQCs with better parameters than
known results in the literature. Third, AQCTPCs can be efficiently decoded
although they are degenerate, provided that the inner and outer codes are
efficiently decodable. In particular, we significantly reduce the inner
decoding complexity of TPCs from $\Omega(n_2a^{n_1})(a>1)$ to $O(n_2)$ by
considering error degeneracy, where $n_1$ and $n_2$ are the block length of the
inner code and the outer code, respectively. Furthermore, we generalize our
concatenation scheme by using the generalized CCs and TPCs correspondingly.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:43:24 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 04:58:58 GMT""}]","2021-03-23"
"2012.00227","Saulo Carneiro","Saulo Carneiro and C\'assio Pigozzo","Quasinormal modes and horizon area quantisation in Loop Quantum Gravity","9 pages, two figures, version to appear in General Relativity and
  Gravitation","Gen. Relat. Gravit. 54 (2022) 20","10.1007/s10714-022-02905-8",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is argued that the quantum of area between consecutive, high overtones
quasinormal modes of a black hole horizon coincides with the area gap predicted
by Loop Quantum Gravity, as long as the horizon is isolated and the
Barbero-Immirzi parameter is $\gamma \approx \sqrt{3}/6$, in agreement with the
value derived from the Bekenstein-Hawking horizon entropy.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:50:17 GMT""},{""version"":""v2"",""created"":""Tue, 25 Jan 2022 14:46:22 GMT""}]","2022-02-16"
"2012.00228","Konstantinos Kravvaris","Konstantinos Kravvaris, Sofia Quaglioni, Guillaume Hupin, Petr
  Navratil","Ab initio framework for nuclear scattering and reactions induced by
  light projectiles",,,,"LLNL-JRNL-816124","nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A quantitative and predictive microscopic theoretical framework that can
describe reactions induced by $\alpha$ particles ($^4$He nuclei) and heavier
projectiles is currently lacking. Such a framework would contribute to reducing
uncertainty in the modeling of stellar evolution and nucleosynthesis and
provide the basis for achieving a comprehensive understanding of the phenomenon
of nuclear clustering (the organization of protons and neutrons into distinct
substructures within a nucleus). We have developed an efficient and general
configuration-interaction framework for the description of low-energy reactions
and clustering in light nuclei. The new formalism takes full advantage of
powerful second-quantization techniques, enabling the description of
$\alpha$-$\alpha$ scattering and an exploration of clustering in the exotic
$^{12}$Be nucleus. We find that the $^4$He($\alpha$, $\alpha$)$^4$He
differential cross section computed with non-locally regulated chiral
interactions is in good agreement with experimental data. Our results for
$^{12}$Be indicate the presence of strongly mixed helium-cluster states
consistent with a molecular-like picture surviving far above the $^6$He+$^6$He
threshold, and reveal the strong influence of neutron decay in both the
$^{12}$Be spectrum and in the $^6$He($^6$He,$\alpha$)$^8$He cross section. We
expect that this approach will enable the description of helium burning cross
sections and provide insight on how three-nucleon forces influence the
emergence of clustering in nuclei.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:57:49 GMT""}]","2020-12-02"
"2012.00229","Bing Xu","Bing Xu, Jinfeng Wang, Zhongjie Li, Chengdong Xu, Yilan Liao, Maogui
  Hu, Jing Yang, Shengjie Lai, Liping Wang, Weizhong Yang","Seasonal association between viral causes of hospitalised acute lower
  respiratory infections and meteorological factors in China: a retrospective
  study","6 figures and tables","The Lancet Planetary Health, 2021","10.1016/S2542-5196(20)30297-7",,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  Acute lower respiratory infections caused by respiratory viruses are common
and persistent infectious diseases worldwide and in China, which have
pronounced seasonal patterns. Meteorological factors have important roles in
the seasonality of some major viruses. Our aim was to identify the dominant
meteorological factors and to model their effects on common respiratory viruses
in different regions of China. We analysed monthly virus data on patients from
81 sentinel hospitals in 22 provinces in mainland China from 2009 to 2013. The
geographical detector method was used to quantify the explanatory power of each
meteorological factor, individually and interacting in pairs. 28369
hospitalised patients with ALRI were tested, 10387 were positive for at least
one virus, including RSV, influenza virus, PIV, ADV, hBoV, hCoV and hMPV. RSV
and influenza virus had annual peaks in the north and biannual peaks in the
south. PIV and hBoV had higher positive rates in the spring summer months. hMPV
had an annual peak in winter spring, especially in the north. ADV and hCoV
exhibited no clear annual seasonality. Temperature, atmospheric pressure,
vapour pressure, and rainfall had most explanatory power on most respiratory
viruses in each region. Relative humidity was only dominant in the north, but
had no significant explanatory power for most viruses in the south. Hours of
sunlight had significant explanatory power for RSV and influenza virus in the
north, and for most viruses in the south. Wind speed was the only factor with
significant explanatory power for human coronavirus in the south. For all
viruses, interactions between any two of the paired factors resulted in
enhanced explanatory power, either bivariately or non-linearly.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 02:59:17 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 05:40:51 GMT""}]","2021-04-16"
"2012.00230","Cheng Lin","Cheng Lin, Changjian Li, Yuan Liu, Nenglun Chen, Yi-King Choi, Wenping
  Wang","Point2Skeleton: Learning Skeletal Representations from Point Clouds","Accepted to CVPR2021 (oral). Project:
  https://github.com/clinplayer/Point2Skeleton",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce Point2Skeleton, an unsupervised method to learn skeletal
representations from point clouds. Existing skeletonization methods are limited
to tubular shapes and the stringent requirement of watertight input, while our
method aims to produce more generalized skeletal representations for complex
structures and handle point clouds. Our key idea is to use the insights of the
medial axis transform (MAT) to capture the intrinsic geometric and topological
natures of the original input points. We first predict a set of skeletal points
by learning a geometric transformation, and then analyze the connectivity of
the skeletal points to form skeletal mesh structures. Extensive evaluations and
comparisons show our method has superior performance and robustness. The
learned skeletal representation will benefit several unsupervised tasks for
point clouds, such as surface reconstruction and segmentation.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:04:09 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 04:24:20 GMT""}]","2021-04-08"
"2012.00231","Vesko Valov","Alexandre Karassev and Vesko Valov","Homological characterizations of $Q$-manifolds and $l_2$-manifolds","15 pages",,,,"math.GT math.GN","http://creativecommons.org/licenses/by/4.0/","  We investigate to what extend the density of $Z_n$-maps in the
characterization of $Q$-manifolds, and the density of maps $f\in C(\mathbb
N\times Q,X)$ having discrete images in the $l_2$-manifolds characterization
can be weakened to the density of homological $Z_n$-maps and homological
$Z$-maps, respectively. As a result, we obtain homological characterizations of
$Q$-manifolds and $l_2$-manifolds.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:06:08 GMT""}]","2020-12-02"
"2012.00232","Jalal Arabneydi","Jalal Arabneydi and Amir G. Aghdam","A Mean-Field Team Approach to Minimize the Spread of Infection in a
  Network","Proceedings of American Control Conference, 2019",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In this paper, a stochastic dynamic control strategy is presented to prevent
the spread of an infection over a homogeneous network. The infectious process
is persistent, i.e., it continues to contaminate the network once it is
established. It is assumed that there is a finite set of network management
options available such as degrees of nodes and promotional plans to minimize
the number of infected nodes while taking the implementation cost into account.
The network is modeled by an exchangeable controlled Markov chain, whose
transition probability matrices depend on three parameters: the selected
network management option, the state of the infectious process, and the
empirical distribution of infected nodes (with not necessarily a linear
dependence). Borrowing some techniques from mean-field team theory the optimal
strategy is obtained for any finite number of nodes using dynamic programming
decomposition and the convolution of some binomial probability mass functions.
For infinite-population networks, the optimal solution is described by a
Bellman equation. It is shown that the infinite-population strategy is a
meaningful sub-optimal solution for finite-population networks if a certain
condition holds. The theoretical results are verified by an example of rumor
control in social networks.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:09:53 GMT""}]","2020-12-02"
"2012.00233","Yonatan Betancur Ocampo","Yonatan Betancur-Ocampo, Parisa Majari, Diego Espitia, Francois
  Leyvraz, and Thomas Stegmann","Anomalous Floquet tunneling in uniaxially strained graphene","12 pages, 8 figures","Phys. Rev. B 103, 155433 (2021)","10.1103/PhysRevB.103.155433",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interplay of strain engineering and photon-assisted tunneling of
electrons in graphene is considered for giving rise to atypical transport
phenomena. The combination of uniaxial strain and a time-periodic potential
barrier helps to control the particle transmission for a wide range of tunable
parameters. With the use of the tight-biding approach, the elasticity theory,
and the Floquet scattering, we found an angular shift of the maximum
transmission in the sidebands for uniaxial strains breaking the mirror symmetry
with respect to the normal incidence, which is called anomalous Floquet
tunneling. We show that electron tunneling depends strongly on the barrier
width, incident angle, uniaxial strain, and the tuning of the time-periodic
potential parameters. An adequate modulation of the barrier width and
oscillation amplitude serves to select the transmission in the sidebands. These
findings can be useful for controlling the electron current through the
photon-assisted tunneling being used in multiple nanotechnological
applications.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:10:26 GMT""}]","2021-05-05"
"2012.00234","Xuesong Shi","Dongjiang Li, Jinyu Miao, Xuesong Shi, Yuxin Tian, Qiwei Long, Tianyu
  Cai, Ping Guo, Hongfei Yu, Wei Yang, Haosong Yue, Qi Wei, Fei Qiao","RaP-Net: A Region-wise and Point-wise Weighting Network to Extract
  Robust Features for Indoor Localization","IROS 2021",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feature extraction plays an important role in visual localization. Unreliable
features on dynamic objects or repetitive regions will interfere with feature
matching and challenge indoor localization greatly. To address the problem, we
propose a novel network, RaP-Net, to simultaneously predict region-wise
invariability and point-wise reliability, and then extract features by
considering both of them. We also introduce a new dataset, named
OpenLORIS-Location, to train the proposed network. The dataset contains 1553
images from 93 indoor locations. Various appearance changes between images of
the same location are included and can help the model to learn the
invariability in typical indoor scenes. Experimental results show that the
proposed RaP-Net trained with OpenLORIS-Location dataset achieves excellent
performance in the feature matching task and significantly outperforms
state-of-the-arts feature algorithms in indoor localization. The RaP-Net code
and dataset are available at https://github.com/ivipsourcecode/RaP-Net.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:12:09 GMT""},{""version"":""v2"",""created"":""Sun, 14 Mar 2021 14:41:33 GMT""},{""version"":""v3"",""created"":""Sun, 22 Aug 2021 14:33:17 GMT""}]","2021-08-24"
"2012.00235","Qianli Zhou","Qianli Zhou, Yong Deng","Fractal-based Belief Entropy",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The total uncertainty measurement of basic probability assignment (BPA) in
Dempster-Shafer evidence theory (DSET) has always been an open issue. Although
some scholars put forward various measurements and entropies of BPA, due to the
existence of discord and non-specificity, there is no method can measure BPA
reasonably. In order to utilize BPA to practical decision-making, pignistic
probability transformation of BPA is a significant method. In the paper, we
simulate the pignistic probability transformation (PPT) process based on the
fractal idea, which describes PPT process in detail and shows the process of
information volume changes during transformation intuitively. Based on
transformation process, we propose a new belief entropy called fractal-based
belief (FB) entropy. After verification, FB entropy is superior to all existing
belief entropies in terms of total uncertainty measurement and physical model
consistency.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:13:57 GMT""},{""version"":""v2"",""created"":""Sun, 30 May 2021 17:05:03 GMT""},{""version"":""v3"",""created"":""Sat, 9 Oct 2021 01:34:32 GMT""}]","2021-10-12"
"2012.00236","Randall Rojas Bolivar","Randall Rojas Bolivar, Daniel Wik, Simona Giacintucci, Fabio
  Gastaldello, Allan Hornstrup, Niels-Jorgen Westergaard, Grzegorz Madjeski","NuSTAR Observations of Abell 2163: Constraints on Non-thermal Emission","16 pages, 17 figures",,"10.3847/1538-4357/abcbf7",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Since the first non-thermal reports of inverse Compton (IC) emission from the
intracluster medium (ICM) of galaxy clusters at hard X-ray energies, we have
yet to unambiguously confirm IC emission in observations with newer facilities.
RXTE detected IC emission in one of the hottest known clusters, Abell 2163
(A2163), a massive merging cluster with a giant radio halo--the presumed source
of relativistic electrons IC scattering CMB photons to X-ray energies. The
cluster's redshift (z~0.2) allows its thermal and non-thermal radio emission to
fit NuSTARS's FOV, permitting a deep observation capable of confirming or
ruling out the RXTE report. The IC flux provides constraints on the average
magnetic field strength in a cluster. To determine the global diffuse IC
emission in A2163, we fit its global NuSTAR spectrum with four models: single
(1T) and two-temperature (2T), 1T+power law component (T+IC), and
multi-temperature+power law (9T+IC). Each represent different characterizations
of the thermal ICM emission, with power law components added to represent IC
emission. We find the 3-30 keV spectrum can be described by purely thermal
emission, with a global average temperature of kT = (11.8 $\pm$ 0.2) keV. The
IC flux is constrained to $<$ $4.0$ $\times$ $10^{-12}$ $erg$ $s^{-1}$
$cm^{-2}$ using the 1T+IC model and $<$ $1.6$ $\times$ $10^{-12}$ $erg$
$s^{-1}$ $cm^{-2}$ with the more physical 9T+IC model, both to 90% confidence
levels. Combining these limits with 1.4 GHz diffuse radio data from the VLA, we
find the average magnetic field strength to be $>$ $0.22$$\mu$$G$ and $>$
$0.35$$\mu$$G$, respectively, providing the strongest constraints on these
values in A2163 to date.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:16:06 GMT""}]","2021-01-20"
"2012.00237","Vesko Valov","V. Valov and J. West","On $Q$-manifolds bundles","17 pages",,,,"math.GT math.GN","http://creativecommons.org/licenses/by/4.0/","  We prove a homological characterization of $Q$-manifolds bundles over
$C$-spaces. This provides a partial answer to Question QM22 from \cite{w}.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:16:11 GMT""}]","2020-12-02"
"2012.00238","Nithin Raghavan","Nithin Raghavan, Punarjay Chakravarty, Shubham Shrivastava","Sim2Real for Self-Supervised Monocular Depth and Segmentation","9 pages, 3 figures",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image-based learning methods for autonomous vehicle perception tasks require
large quantities of labelled, real data in order to properly train without
overfitting, which can often be incredibly costly. While leveraging the power
of simulated data can potentially aid in mitigating these costs, networks
trained in the simulation domain usually fail to perform adequately when
applied to images in the real domain. Recent advances in domain adaptation have
indicated that a shared latent space assumption can help to bridge the gap
between the simulation and real domains, allowing the transference of the
predictive capabilities of a network from the simulation domain to the real
domain. We demonstrate that a twin VAE-based architecture with a shared latent
space and auxiliary decoders is able to bridge the sim2real gap without
requiring any paired, ground-truth data in the real domain. Using only paired,
ground-truth data in the simulation domain, this architecture has the potential
to generate perception tasks such as depth and segmentation maps. We compare
this method to networks trained in a supervised manner to indicate the merit of
these results.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:25:02 GMT""}]","2020-12-02"
"2012.00239","Jalal Arabneydi","Jalal Arabneydi, Mohammad M. Baharloo, and Amir G. Aghdam","Optimal Distributed Control for Leader-Follower Networks: A Scalable
  Design","Proceedings of Canadian Conference on Electrical and Computer
  Engineering, 2018",,,,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  The focus of this paper is directed towards optimal control of multi-agent
systems consisting of one leader and a number of followers in the presence of
noise. The dynamics of every agent is assumed to be linear, and the performance
index is a quadratic function of the states and actions of the leader and
followers. The leader and followers are coupled in both dynamics and cost. The
state of the leader and the average of the states of all followers (called
mean-field) are common information and known to all agents; however, the local
state of the followers are private information and unknown to other agents. It
is shown that the optimal distributed control strategy is linear time-varying,
and its computational complexity is independent of the number of followers.
This strategy can be computed in a distributed manner, where the leader needs
to solve one Riccati equation to determine its optimal strategy while each
follower needs to solve two Riccati equations to obtain its optimal strategy.
  This result is subsequently extended to the case of the infinite horizon
discounted and undiscounted cost functions, where the optimal distributed
strategy is shown to be stationary. A numerical example with $100$ followers is
provided to demonstrate the efficacy of the results.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:26:14 GMT""}]","2020-12-02"
"2012.00240","Renan Alves De Oliveira","Renan Alves de Oliveira, Yin Li, Francisco Villaescusa-Navarro,
  Shirley Ho, David N. Spergel","Fast and Accurate Non-Linear Predictions of Universes with Deep Learning","6 pages, 2 figures, accepted for a poster presentation at Machine
  Learning and the Physical Sciences Workshop @ NeurIPS 2020",,,,"astro-ph.CO astro-ph.IM cs.LG","http://creativecommons.org/licenses/by/4.0/","  Cosmologists aim to model the evolution of initially low amplitude Gaussian
density fluctuations into the highly non-linear ""cosmic web"" of galaxies and
clusters. They aim to compare simulations of this structure formation process
with observations of large-scale structure traced by galaxies and infer the
properties of the dark energy and dark matter that make up 95% of the universe.
These ensembles of simulations of billions of galaxies are computationally
demanding, so that more efficient approaches to tracing the non-linear growth
of structure are needed. We build a V-Net based model that transforms fast
linear predictions into fully nonlinear predictions from numerical simulations.
Our NN model learns to emulate the simulations down to small scales and is both
faster and more accurate than the current state-of-the-art approximate methods.
It also achieves comparable accuracy when tested on universes of significantly
different cosmological parameters from the one used in training. This suggests
that our model generalizes well beyond our training set.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:30:37 GMT""}]","2021-05-05"
"2012.00241","Chang Liu","Chang Liu, Xuemeng Liu, Derrick Wing Kwan Ng, Jinhong Yuan","Deep Residual Network Empowered Channel Estimation for IRS-Assisted
  Multi-User Communication Systems","arXiv admin note: substantial text overlap with arXiv:2009.01423",,,,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Channel estimation is of great importance in realizing practical intelligent
reflecting surface-assisted multi-user communication (IRS-MC) systems. However,
different from traditional communication systems, an IRS-MC system generally
involves a cascaded channel with a sophisticated statistical distribution,
which hinders the implementations of the Bayesian estimators. To further
improve the channel estimation performance, in this paper, we model the channel
estimation as a denoising problem and adopt a data-driven approach to realize
the channel estimation. Specifically, we propose a convolutional neural network
(CNN)-based deep residual network (CDRN) to implicitly learn the residual noise
for recovering the channel coefficients from the noisy pilot-based
observations. In the proposed CDRN, a CNN denoising block equipped with an
element-wise subtraction structure is designed to exploit both the spatial
features of the noisy channel matrices and the additive nature of the noise
simultaneously, which further improves the estimation accuracy. Simulation
results demonstrate that the proposed method can almost achieve the same
estimation accuracy as that of the optimal minimum mean square error (MMSE)
estimator requiring the knowledge of the channel distribution.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:32:03 GMT""}]","2020-12-02"
"2012.00242","Weixuan Sun","Weixuan Sun, Jing Zhang, Nick Barnes","3D Guided Weakly Supervised Semantic Segmentation",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Pixel-wise clean annotation is necessary for fully-supervised semantic
segmentation, which is laborious and expensive to obtain. In this paper, we
propose a weakly supervised 2D semantic segmentation model by incorporating
sparse bounding box labels with available 3D information, which is much easier
to obtain with advanced sensors. We manually labeled a subset of the 2D-3D
Semantics(2D-3D-S) dataset with bounding boxes, and introduce our 2D-3D
inference module to generate accurate pixel-wise segment proposal masks. Guided
by 3D information, we first generate a point cloud of objects and calculate
objectness probability score for each point. Then we project the point cloud
with objectness probabilities back to 2D images followed by a refinement step
to obtain segment proposals, which are treated as pseudo labels to train a
semantic segmentation network. Our method works in a recursive manner to
gradually refine the above-mentioned segment proposals. Extensive experimental
results on the 2D-3D-S dataset show that the proposed method can generate
accurate segment proposals when bounding box labels are available on only a
small subset of training images. Performance comparison with recent
state-of-the-art methods further illustrates the effectiveness of our method.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:34:15 GMT""}]","2020-12-02"
"2012.00243","Insung Park","Insung Park","Levy and Thurston obstructions of finite subdivision rules","46 pages, 15 figures; v3: many revisions, in particular introducing
  train-track structures on the non-expanding spines; v4: Section 9.4 is added",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a post-critically finite branched covering of the sphere that is a
subdivision map of a finite subdivision rule, we define non-expanding spines
which determine the existence of a Levy cycle in a non-exhaustive
semi-decidable algorithm. Especially when a finite subdivision rule has
polynomial growth of edge subdivisions, the algorithm terminates very quickly,
and the existence of a Levy cycle is equivalent to the existence of a Thurston
obstruction. In order to show the equivalence between Levy and Thurston
obstructions, we generalize the arcs intersecting obstruction theorem by
Pilgrim and Tan to a graph intersecting obstruction theorem. As a corollary, we
prove that for a pair of post-critically finite polynomials, if at least one
polynomial has core entropy zero, then their mating has a Levy cycle if and
only if the mating has a Thurston obstruction.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:37:33 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jan 2021 19:36:44 GMT""},{""version"":""v3"",""created"":""Wed, 27 Oct 2021 01:25:55 GMT""},{""version"":""v4"",""created"":""Fri, 11 Feb 2022 18:35:03 GMT""}]","2022-02-14"
"2012.00244","Kedi Yan","Kedi Yan, Gregory E. Moore, Joshua R. Smith","The Optimal Location and Size of an Intermediate Coil in a Magnetic
  Resonant Coupling Wireless Power Transfer System",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To increase the transmission distance of Wireless Power Transfer (WPT)
systems, we provide guidelines on choosing the optimal location of an
Intermediate Coil with respect to size within a standard five-coil axially
aligned experimental setup. From our results, for maximum magnitude of S21 at
the resonant frequency we found the optimal location to exist where the
coupling coefficient between the Transmitter and the Intermediate Coil and the
coupling coefficient between the Receiver and the Intermediate Coil are
identical. Additionally, the optimal outer diameter for the maximum magnitude
of S21 at the resonant frequency of the Intermediate Coil in the given
symmetric and asymmetric setup are found to be larger than both TX and RX.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:44:35 GMT""}]","2020-12-02"
"2012.00245","Oladiran Johnson Abimbola Dr","O. J. Abimbola, E. Bada, A. O. Falaiye, Y. M. Sukam and S. Muhammad","Estimation of Radio Refractivity from a Decade Satellite Derived
  Meteorological Data for West Africa",,,,,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  Radio refractivity, which is the bending of radio signal as it propagates
through media, is very important in works involving terrestrial atmospheric
electromagnetic propagation such as point-to-point microwave communication,
terrestrial radio and television broadcast, mobile communication system, and so
on. This study has focused on the West African region where it was found that
the region has a refractivity which varies exponentially with height and from
the coast towards the desert. Generally, refractivity gradient was found to
range between -46.48 and -29.51 N-units/km (k-factor value of between 1.23 and
1.42) across the region, splitting the between sub- and super-refraction. The
variation in refraction type was found to follow seasonal pattern across the
West African region, with sub-refraction dominating during dry season and
super-refraction dominating most part in the coastal area during the wet
season.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:51:36 GMT""}]","2020-12-02"
"2012.00246","Caspar Groiseau","Caspar Groiseau, Alexander E. J. Elliott, Stuart J. Masson, Scott
  Parkins","Deterministic single-atom source of quasi-superradiant $N$-photon pulses","14 pages, 10 figures","Phys. Rev. Lett. 127, 033602 (2021)","10.1103/PhysRevLett.127.033602",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a single-atom, cavity quantum electrodynamics system, compatible
with recently demonstrated, fiber-integrated micro- and nano-cavity setups, for
the on-demand production of optical number-state, $0N$-state, and
binomial-code-state pulses. The scheme makes use of Raman transitions within an
entire atomic ground-state hyperfine level and operates with laser and cavity
fields detuned from the atomic transition by much more than the excited-state
hyperfine splitting. This enables reduction of the dynamics to that of a
simple, cavity-damped Tavis-Cummings model with the collective spin determined
by the total angular momentum of the ground hyperfine level.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:55:27 GMT""}]","2021-07-21"
"2012.00247","Selim Sukhtaiev","Yuri Latushkin, Selim Sukhtaiev","First-order asymptotic perturbation theory for extensions of symmetric
  operators",,,,,"math.SP math-ph math.AP math.MP","http://creativecommons.org/licenses/by/4.0/","  This work offers a new prospective on asymptotic perturbation theory for
varying self-adjoint extensions of symmetric operators. Employing symplectic
formulation of self-adjointness we obtain a new version of Krein formula for
resolvent difference which facilitates asymptotic analysis of resolvent
operators via first order expansion for the family of Lagrangian planes
associated with perturbed operators. Specifically, we derive a Riccati-type
differential equation and the first order asymptotic expansion for resolvents
of self-adjoint extensions determined by smooth one-parameter families of
Lagrangian planes. This asymptotic perturbation theory yields a symplectic
version of the abstract Kato selection theorem and Hadamard-Rellich-type
variational formula for slopes of multiple eigenvalue curves bifurcating from
an eigenvalue of the unperturbed operator. The latter, in turn, gives a general
infinitesimal version of the celebrated formula equating the spectral flow of a
path of self-adjoint extensions and the Maslov index of the corresponding path
of Lagrangian planes. Applications are given to quantum graphs, periodic
Kronig-Penney model, elliptic second order partial differential operators with
Robin boundary conditions, and physically relevant heat equations with thermal
conductivity.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 03:56:54 GMT""},{""version"":""v2"",""created"":""Sat, 14 Jan 2023 00:49:15 GMT""}]","2023-01-18"
"2012.00248","Byung Gyu Chae","Byung Gyu Chae","Viewing angle analysis of reconstructed image from digital Fresnel
  hologram with enhanced numerical aperture","This is wrong upload. Our paper should replace arXiv:2004.12543",,,,"physics.optics eess.IV","http://creativecommons.org/licenses/by/4.0/","  The viewing-angle enlargement of a holographic image is a crucial factor for
realizing the holographic display. The numerical aperture (NA) of digital
hologram other than a pixel specification has been known to determine the
angular field extent of image. Here, we provide a valid foundation for the
dependence of viewing angle on the hologram numerical aperture by investigating
mathematically the internal structure of the sampled point spread function
showing a self-similarity of its modulating curves and especially, analyzing
this scheme on the basis of quantum mechanical framework. The enhanced-NA
Fresnel hologram generates the multiple images with a high resolution, which
can lead to the higher viewing angle represented as the NA of whole aperture of
hologram. Optical experiment shows the consistent result with quantum
mechanical description of viewing angle of holographic images. Finally, we
discuss the method for enlarging viewing angle of holographic image without
sacrificing image size by using this scheme.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:02:40 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 00:18:39 GMT""},{""version"":""v3"",""created"":""Thu, 25 Mar 2021 22:41:32 GMT""}]","2021-03-29"
"2012.00249","Charles Martin","Charles Martin and Benjamin Forster and Hanna Cormick","Cross-artform performance using networked interfaces: Last Man to Die's
  Vital LMTD",,"Proceedings of the International Conference on New Interfaces for
  Musical Expression (2010) pp. 204-207","10.5281/zenodo.1177843",,"cs.HC cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  In 2009 the cross artform group, Last Man to Die, presented a series of
performances using new interfaces and networked performance to integrate the
three artforms of its members (actor, Hanna Cormick, visual artist, Benjamin
Forster and percussionist, Charles Martin). This paper explains our artistic
motivations and design for a computer vision surface and networked heartbeat
sensor as well as the experience of mounting our first major work, Vital LMTD.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:09:39 GMT""}]","2020-12-02"
"2012.00250","Charles Martin","Charles Martin and Chi-Hsia Lai","Strike on Stage: a percussion and media performance",,"Proceedings of the International Conference on New Interfaces for
  Musical Expression (2011) pp. 142-143","10.5281/zenodo.1178103",,"cs.SD cs.HC eess.AS","http://creativecommons.org/licenses/by/4.0/","  This paper describes Strike on Stage, an interface and corresponding
audio-visual performance work developed and performed in 2010 by percussionists
and media artists Chi-Hsia Lai and Charles Martin. The concept of Strike on
Stage is to integrate computer visuals and sound into an improvised percussion
performance. A large projection surface is positioned directly behind the
performers, while a computer vision system tracks their movements. The setup
allows computer visualisation and sonification to be directly responsive and
unified with the performers' gestures.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:10:24 GMT""}]","2020-12-02"
"2012.00251","Cy Qiu","Huahui Qiu, Meng Xiao, Fan Zhang, and Chunyin Qiu","Higher-order Dirac sonic crystals","Accepted by PRL","Phys. Rev. Lett. 127, 146601 (2021)","10.1103/PhysRevLett.127.146601",,"cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Discovering new topological phases of matter is a major theme in fundamental
physics and materials science. Dirac semimetal provides an exceptional platform
for exploring topological phase transitions under symmetry breaking. Recent
theoretical studies have revealed that a three-dimensional Dirac semimetal can
harbor fascinating hinge states, a higher-order topological manifestation not
known before. However, its realization in experiment is yet to be achieved. In
this Letter, we propose a minimum model to construct a spinless higher-order
Dirac semimetal protected by C_6v symmetry. By breaking different symmetries,
this parent phase transitions into a variety of novel topological phases
including higher-order topological insulator, higher-order Weyl semimetal, and
higher-order nodal-ring semimetal. Furthermore, for the first time, we
experimentally realize this unprecedented higher-order topological phase in a
sonic crystal and present an unambiguous observation of the desired hinge
states via momentun-space spectroscopy and real-space visualization. Our
findings may offer new opportunities to manipulate classical waves such as
sound and light.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:11:17 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 04:10:03 GMT""}]","2021-10-04"
"2012.00252","Pankaj Mehta","Robert Marsland III, Owen Howell, Andreas Mayer, Pankaj Mehta","Tregs self-organize into a ""computing ecosystem"" and implement a
  sophisticated optimization algorithm for mediating immune response","8 pages, 4 figures + Appendix; Accepted at PNAS",,,,"q-bio.PE cond-mat.soft cond-mat.stat-mech nlin.AO q-bio.TO","http://creativecommons.org/licenses/by/4.0/","  Regulatory T cells (Tregs) play a crucial role in mediating immune response.
Yet an algorithmic understanding of the role of Tregs in adaptive immunity
remains lacking. Here, we present a biophysically realistic model of Treg
mediated self-tolerance in which Tregs bind to self-antigens and locally
inhibit the proliferation of nearby activated T cells. By exploiting a duality
between ecological dynamics and constrained optimization, we show that Tregs
tile the potential antigen space while simultaneously minimizing the overlap
between Treg activation profiles. We find that for sufficiently high Treg
diversity, Treg mediated self-tolerance is robust to fluctuations in
self-antigen concentrations but lowering the Treg diversity results in a sharp
transition -- related to the Gardner transition in perceptrons -- to a regime
where changes in self-antigen concentrations can result in an auto-immune
response. We propose a novel experimental test of this transition in
immune-deficient mice and discuss potential implications for autoimmune
diseases.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:12:40 GMT""}]","2020-12-02"
"2012.00253","Cheng Yan","Cheng Yan, Xin Li, Guoqiang Li","A New Action Recognition Framework for Video Highlights Summarization in
  Sporting Events","18 pages, 3 figures, 4 tables",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  To date, machine learning for human action recognition in video has been
widely implemented in sports activities. Although some studies have been
successful in the past, precision is still the most significant concern. In
this study, we present a high-accuracy framework to automatically clip the
sports video stream by using a three-level prediction algorithm based on two
classical open-source structures, i.e., YOLO-v3 and OpenPose. It is found that
by using a modest amount of sports video training data, our methodology can
perform sports activity highlights clipping accurately. Comparing with the
previous systems, our methodology shows some advantages in accuracy. This study
may serve as a new clipping system to extend the potential applications of the
video summarization in sports field, as well as facilitates the development of
match analysis system.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:14:40 GMT""}]","2020-12-02"
"2012.00254","Michael Swaddle Mr","Wee Chaimanowong, Paul Norbury, Michael Swaddle, Mehdi Tavakol","Airy structures and deformations of curves in surfaces","50 pages",,,,"math.AG math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An embedded curve in a symplectic surface $\Sigma\subset X$ defines a smooth
deformation space $\mathcal{B}$ of nearby embedded curves. A key idea of
Kontsevich and Soibelman arXiv:1701.09137 [math.AG], is to equip the symplectic
surface $X$ with a foliation in order to study the deformation space
$\mathcal{B}$. The foliation, together with a vector space $V_\Sigma$ of
meromorphic differentials on $\Sigma$, endows an embedded curve $\Sigma$ with
the structure of the initial data of topological recursion, which defines a
collection of symmetric tensors on $V_\Sigma$. Kontsevich and Soibelman define
an Airy structure on $V_\Sigma$ to be a formal quadratic Lagrangian
$\mathcal{L}\subset T^*(V_\Sigma^*)$ which leads to an alternative construction
of the tensors of topological recursion. In this paper we produce a formal
series $\theta$ on $\mathcal{B}$ of meromorphic differentials on $\Sigma$ which
takes it values in $\mathcal{L}$, and use this to produce the Donagi-Markman
cubic from a natural cubic tensor on $V_\Sigma$, giving a generalisation of a
result of Baraglia and Huang, arXiv:1707.04975 [math.DG].
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:14:56 GMT""}]","2020-12-02"
"2012.00255","Tsz-Kiu Aaron Chow","Tsz-Kiu Aaron Chow","Positivity of Curvature on Manifolds with Boundary","19 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider a compact manifold $M$ with smooth boundary $\partial M$. Suppose
that $g$ and $\tilde{g}$ are two Riemannian metrics on $M$. We construct a
family of metrics on $M$ which agrees with $g$ outside a neighborhood of
$\partial M$ and agrees with $\tilde{g}$ in a neighborhood of $\partial M$. We
prove that the family of metrics preserves various natural curvature conditions
under suitable assumptions on the boundary data. Moreover, under suitable
assumptions on the boundary data, we can deform a metric to one with totally
geodesic boundary while preserving various natural curvature conditions.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:15:04 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 00:15:06 GMT""}]","2021-03-12"
"2012.00256","Ying Mao","Samuel A. Stein, Ryan L'Abbate, Wenrui Mu, Yue Liu, Betis Baheri, Ying
  Mao, Qiang Guan, Ang Li, Bo Fang","A Hybrid System for Learning Classical Data in Quantum States",,,,,"quant-ph","http://creativecommons.org/licenses/by-sa/4.0/","  Deep neural network powered artificial intelligence has rapidly changed our
daily life with various applications. However, as one of the essential steps of
deep neural networks, training a heavily weighted network requires a tremendous
amount of computing resources. Especially in the post-Moore's Law era, the
limit of semiconductor fabrication technology has restricted the development of
learning algorithms to cope with the increasing high-intensity training data.
Meanwhile, quantum computing has demonstrated its significant potential in
terms of speeding up the traditionally compute-intensive workloads. For
example, Google illustrated quantum supremacy by completing a sampling
calculation task in 200 seconds, which is otherwise impracticable on the
world's largest supercomputers. To this end, quantum-based learning has become
an area of interest, with the potential of a quantum speedup. In this paper, we
propose GenQu, a hybrid and general-purpose quantum framework for learning
classical data through quantum states. We evaluate GenQu with real datasets and
conduct experiments on both simulations and real quantum computer IBM-Q. Our
evaluation demonstrates that, compared with classical solutions, the proposed
models running on GenQu framework achieve similar accuracy with a much smaller
number of qubits, while significantly reducing the parameter size by up to
95.86% and converging speedup by 33.33% faster.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:17:33 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 15:18:20 GMT""}]","2021-08-23"
"2012.00257","Andrew Shepley Ph.D.","Andrew Shepley, Greg Falzon, Paul Kwan","Confluence: A Robust Non-IoU Alternative to Non-Maxima Suppression in
  Object Detection","16 pages",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Confluence is a novel non-Intersection over Union (IoU) alternative to
Non-Maxima Suppression (NMS) in bounding box post-processing in object
detection. It overcomes the inherent limitations of IoU-based NMS variants to
provide a more stable, consistent predictor of bounding box clustering by using
a normalized Manhattan Distance inspired proximity metric to represent bounding
box clustering. Unlike Greedy and Soft NMS, it does not rely solely on
classification confidence scores to select optimal bounding boxes, instead
selecting the box which is closest to every other box within a given cluster
and removing highly confluent neighboring boxes. Confluence is experimentally
validated on the MS COCO and CrowdHuman benchmarks, improving Average Precision
by up to 2.3-3.8% and Average Recall by up to 5.3-7.2% when compared against
de-facto standard and state of the art NMS variants. Quantitative results are
supported by extensive qualitative analysis and threshold sensitivity analysis
experiments support the conclusion that Confluence is more robust than NMS
variants. Confluence represents a paradigm shift in bounding box processing,
with potential to replace IoU in bounding box regression processes.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:22:01 GMT""},{""version"":""v2"",""created"":""Wed, 28 Jul 2021 03:29:54 GMT""},{""version"":""v3"",""created"":""Wed, 3 Aug 2022 00:40:26 GMT""}]","2022-08-04"
"2012.00258","Pardyumn Kumar Sahoo","Parbati Sahoo, P.H.R.S. Moraes, Marcelo M. Lapola, P.K. Sahoo","Traversable wormholes in the traceless $f(R,T)$ gravity","Revision submitted to IJMPD","International Journal of Modern Physics D, 30 (2021) 2150100","10.1142/S0218271821501005",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  We present a traversable wormhole solution using the traceless $f(R,T)$
theory of gravity. In the $f(R,T)$ gravity, the Ricci scalar $R$ in the
Einstein-Hilbert action is replaced by a function of $R$ and trace of the
energy momentum tensor $T$. The traceless version of the $f(R,T)$ gravity gives
rise to a possible wormhole geometry without need for ""exotic matter"", which
violates the principle of causality. Using a physically plausible ansatz for
the wormhole's shape function, the traceless field equations lead to compliance
with the weak energy condition at very well defined intervals of the coupling
constant $\lambda$ in the $f(R,T)=R+2\lambda T$ form. Our solution leads to
other well-behaved energy conditions considering some possible values of the
parameter $\omega$ in the equation of state $p_r=\omega \rho$, with $p_r$ being
the radial pressure and $\rho $ the density. The energy conditions are obeyed
in the ranges $\lambda < -4\pi$ and $\omega > -1$. Through the calculation of
the Volume Integral Quantifier, one sees that this wormholes can be traversable
and respect the causality, since the amount of exotic matter in its interior
can be arbitrarily small.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:22:27 GMT""},{""version"":""v2"",""created"":""Sun, 30 May 2021 16:58:02 GMT""},{""version"":""v3"",""created"":""Tue, 13 Jul 2021 07:55:02 GMT""}]","2021-09-02"
"2012.00259","Amine Mezghani","Amine Mezghani and Robert W. Heath Jr","Massive MIMO Precoding and Spectral Shaping with Low Resolution
  Phase-only DACs and Active Constellation Extension","30 pages, 14 figures, submitted to IEEE Transactions on Wireless
  Communications",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonlinear precoding and pulse shaping are jointly considered in multi-user
massive multiple-input multiple-output (MIMO) systems with low-resolution
D/A-converters (DACs) in terms of algorithmic approach as well as large system
performance. Two design criteria are investigated: the mean {squared} error
(MSE) with active constellation extension (ACE) and the symbol error rate
(SER). Both formulations are solved based on a modified version of the
generalized approximate message passing (GAMP) algorithm. Furthermore,
theoretical performance results are derived based on the state evolution
analysis of the GAMP algorithm. The MSE based technique is extended to jointly
perform over-the-air (OTA) spectral shaping and precoding for
frequency-selective channels, in which the spectral performance is
characterized at the transmitter and at the receiver. Simulation and analytical
results demonstrate that the MSE based approach yields the same performance as
the SER based formulation in terms of uncoded SER. The analytical results
provide good performance predictions up to medium SNR. Substantial improvements
in detection, as well as spectral performance, are obtained from the proposed
combined pulse shaping and precoding approach compared to standard linear
methods.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:31:25 GMT""},{""version"":""v2"",""created"":""Sun, 27 Jun 2021 23:26:18 GMT""}]","2021-06-29"
"2012.00260","Jalal Arabneydi","Mohammad M. Baharloo, Jalal Arabneydi and Amir G. Aghdam","Near-Optimal Control Strategy in Leader-Follower Networks: A Case Study
  for Linear Quadratic Mean-Field Teams","Proceedings of IEEE Conference on Decision and Control, 2018",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  In this paper, a decentralized stochastic control system consisting of one
leader and many homogeneous followers is studied. The leader and followers are
coupled in both dynamics and cost, where the dynamics are linear and the cost
function is quadratic in the states and actions of the leader and followers.
The objective of the leader and followers is to reach consensus while
minimizing their communication and energy costs. The leader knows its local
state and each follower knows its local state and the state of the leader. The
number of required links to implement this decentralized information structure
is equal to the number of followers, which is the minimum number of links for a
communication graph to be connected. In the special case of leaderless, no link
is required among followers, i.e., the communication graph is not even
connected. We propose a near-optimal control strategy that converges to the
optimal solution as the number of followers increases. One of the salient
features of the proposed solution is that it provides a design scheme, where
the convergence rate \edit{as well as} the collective behavior of the followers
can be designed by choosing appropriate cost functions. In addition, the
computational complexity of the proposed solution does not depend on the number
of followers. Furthermore, the proposed strategy can be computed in a
distributed manner, where the leader solves one Riccati equation and each
follower solves two Riccati equations to calculate their strategies. Two
numerical examples are provided to demonstrate the effectiveness of the results
in the control of multi-agent systems.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:38:16 GMT""}]","2020-12-02"
"2012.00261","Abhiroop Bhattacharjee","Abhiroop Bhattacharjee, Lakshya Bhatnagar, Youngeun Kim and
  Priyadarshini Panda","NEAT: Non-linearity Aware Training for Accurate and Energy-Efficient
  Implementation of Neural Networks on 1T-1R Memristive Crossbars","7 pages, 11 figures",,,,"cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Memristive crossbars suffer from non-idealities (such as, sneak paths) that
degrade computational accuracy of the Deep Neural Networks (DNNs) mapped onto
them. A 1T-1R synapse, adding a transistor (1T) in series with the memristive
synapse (1R), has been proposed to mitigate such non-idealities. We observe
that the non-linear characteristics of the transistor affect the overall
conductance of the 1T-1R cell which in turn affects the
Matrix-Vector-Multiplication (MVM) operation in crossbars. This 1T-1R
non-ideality arising from the input voltage-dependent non-linearity is not only
difficult to model or formulate, but also causes a drastic performance
degradation of DNNs when mapped onto crossbars. In this paper, we analyse the
non-linearity of the 1T-1R crossbar and propose a novel Non-linearity Aware
Training (NEAT) method to address the non-idealities. Specifically, we first
identify the range of network weights, which can be mapped into the 1T-1R cell
within the linear operating region of the transistor. Thereafter, we regularize
the weights of the DNNs to exist within the linear operating range by using
iterative training algorithm. Our iterative training significantly recovers the
classification accuracy drop caused by the non-linearity. Moreover, we find
that each layer has a different weight distribution and in turn requires
different gate voltage of transistor to guarantee linear operation. Based on
this observation, we achieve energy efficiency while preserving classification
accuracy by applying heterogeneous gate voltage control to the 1T-1R cells
across different layers. Finally, we conduct various experiments on CIFAR10 and
CIFAR100 benchmark datasets to demonstrate the effectiveness of our
non-linearity aware training. Overall, NEAT yields ~20% energy gain with less
than 1% accuracy loss (with homogeneous gate control) when mapping ResNet18
networks on 1T-1R crossbars.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:40:50 GMT""}]","2020-12-02"
"2012.00262","Ashwin Sah","Ashwin Sah, Mehtaab Sawhney, Yufei Zhao","Paths of given length in tournaments","Appendix with alternative entropy proof by Dingding Dong and Tomasz
  \'Slusarczyk",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We prove that every $n$-vertex tournament has at most
$n\left(\frac{n-1}{2}\right)^k$ walks of length $k$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:50:51 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 22:24:34 GMT""}]","2023-02-13"
"2012.00263","Celesta Chang","Celesta S. Chang, Nicholas Tanen, Vladimir Protasenko, Thaddeus J.
  Asel, Shin Mou, Huili Grace Xing, Debdeep Jena, David A. Muller","$\gamma$-phase Inclusions as Common Defects in Alloyed
  $\beta$-(Al$_x$Ga$_{1\text{-}x}$)$_2$O$_3$ and Doped $\beta$-Ga$_2$O$_3$
  Films",,,,,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  $\beta$-Ga$_2$O$_3$ is a promising ultra-wide bandgap semiconductor whose
properties can be further enhanced by alloying with Al. Here, using
atomic-resolution scanning transmission electron microscopy (STEM), we find the
thermodynamically-unstable $\gamma$-phase is a ubiquitous defect in both
$\beta$-(Al$_x$Ga$_{1\text{-}x}$)$_2$O$_3$ films and doped $\beta$-Ga$_2$O$_3$
films grown by molecular beam epitaxy. For undoped
$\beta$-(Al$_x$Ga$_{1\text{-}x}$)$_2$O$_3$ films we observe $\gamma$-phase
inclusions between nucleating islands of the $\beta$-phase at lower growth
temperatures (~400-600 $^{\circ}$C). In doped $\beta$-Ga$_2$O$_3$, a thin layer
of the $\gamma$-phase is observed on the surfaces of films grown with a wide
range of n-type dopants and dopant concentrations. The thickness of the
$\gamma$-phase layer was most strongly correlated with the growth temperature,
peaking at about 600 $^{\circ}$C. Ga interstitials are observed in
$\beta$-phase, especially near the interface with the $\gamma$-phase. By
imaging the same region of the surface of a Sn-doped
$\beta$-(Al$_x$Ga$_{1\text{-}x}$)$_2$O$_3$ after ex-situ heating up to 400
$^{\circ}$C, a $\gamma$-phase region is observed to grow above the initial
surface, accompanied by a decrease in Ga interstitials in the $\beta$-phase.
This suggests that the diffusion of Ga interstitials towards the surface is
likely the mechanism for growth of the surface $\gamma$-phase, and more
generally that the more-open $\gamma$-phase may offer diffusion pathways to be
a kinetically-favored and early-forming phase in the growth of Ga$_2$O$_3$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:54:32 GMT""}]","2020-12-02"
"2012.00264","Taekyun Kim","Yuankui Ma, Dae san Kim, Hyunseok Lee, Hanyoung Kim, Taekyun Kim","poly-Dedekind type DC sums involving poly-Euler functions","16 pages",,,,"math.NT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The classical Dedekind sums appear in the transformation behavior of the
logarithm of the Dedekind eta-function under substitutions from the modular
group. The Dedekind sums and their generalizations are defined in terms of
Bernoulli functions and their generalizations, and are shown to satisfy some
reciprocity relations. In contrast, Dedekind type DC (Daehee and Changhee) sums
and their generalizations are defined in terms of Euler functions and their
generalizations. The purpose of this paper is to introduce the poly-Dedekind
type DC sums, which are obtained from the Dedekind type DC sums by replacing
the Euler function by poly-Euler functions of arbitrary indices, and to show
that those sums satisfy, among other things, a reciprocity relation.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:55:47 GMT""}]","2020-12-02"
"2012.00265","Charles Martin","Charles Martin","Performing with a Mobile Computer System for Vibraphone",,"Proceedings of the International Conference on New Interfaces for
  Musical Expression (2013), pp. 377-380","10.5281/zenodo.1178602",,"cs.SD cs.HC eess.AS","http://creativecommons.org/licenses/by/4.0/","  This paper describes the development of an Apple iPhone based mobile computer
system for vibraphone and its use in a series of the author's performance
projects in 2011 and 2012. This artistic research was motivated by a desire to
develop an alternative to laptop computers for the author's existing percussion
and computer performance practice. The aims were to develop a light, compact
and flexible system using mobile devices that would allow computer music to
infiltrate solo and ensemble performance situations where it is difficult to
use a laptop computer. The project began with a system that brought computer
elements to Nordlig Vinter, a suite of percussion duos, using an iPhone, RjDj,
Pure Data and a home-made pickup system. This process was documented with video
recordings and analysed using ethnographic methods. The mobile computer music
setup proved to be elegant and convenient in performance situations with very
little time and space to set up, as well as in performance classes and
workshops. The simple mobile system encouraged experimentation and the
platforms used enabled sharing with a wider audience.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:57:25 GMT""}]","2020-12-02"
"2012.00266","Joaqu\'in Moraga","Konstantin Loginov, Joaqu\'in Moraga","Maximal log Fano manifolds are generalized Bott towers","27 pages",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that maximal log Fano manifolds are generalized Bott towers. As an
application, we prove that in each dimension, there is a unique maximal snc
Fano variety satisfying Friedman's d-semistability condition.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:57:54 GMT""}]","2020-12-02"
"2012.00267","Hongyang Du","Hongyang Du, Jiayi Zhang, Ke Guan, Dusit Niyato, Huiying Jiao, Zhiqin
  Wang, and Thomas K\""urner","Performance and Optimization of Reconfigurable Intelligent Surface Aided
  THz Communications",,,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  TeraHertz (THz) communications can satisfy the high data rate demand with
massive bandwidth. However, severe path attenuation and hardware imperfection
greatly alleviate its performance. Therefore, we utilize the reconfigurable
intelligent surface (RIS) technology and investigate the RIS-aided THz
communications. We first prove that the small-scale amplitude fading of THz
signals can be accurately modeled by the fluctuating two-ray distribution based
on two THz signal measurement experiments conducted in a variety of different
scenarios. To optimize the phase-shifts at the RIS elements, we propose a novel
swarm intelligence-based method that does not require full channel estimation.
We then derive exact statistical characterizations of end-to-end
signal-to-noise plus distortion ratio (SNDR) and signal-to-noise ratio (SNR).
Moreover, we present asymptotic analysis to obtain more insights when the SNDR
or the number of RIS's elements is high. Finally, we derive analytical
expressions for the outage probability and ergodic capacity. The tight upper
bounds of ergodic capacity for both ideal and nonideal radio frequency chains
are obtained. It is interesting to find that increasing the number of RIS's
elements can significantly improve the THz communications system performance.
For example, the ergodic capacity can increase up to 25% when the number of
elements increases from 40 to 80, which incurs only insignificant costs to the
system.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:00:38 GMT""},{""version"":""v2"",""created"":""Sun, 20 Mar 2022 08:43:14 GMT""}]","2022-03-22"
"2012.00268","Hongyang Du","Xiaoqi Wang, Jiayi Zhang, Hongyang Du, Ning Wang, and Bo Ai","Secrecy Performance of Body-Centric Communications over Alternate Rician
  Shadowed Fading Channels",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the physical layer security over the Alternate
Rician Shadowed fading channel, which is a novel channel model for body-centric
wireless links and land mobile satellite. We derive exact closed-form
expressions for the average secrecy capacity (ASC), secrecy outage probability
(SOP), and probability of non-zero secrecy capacity (PNZ) for two cases: (i) m
is a positive real number and (ii) m is a positive integer number, where m
describes the level of fluctuation of the line-of-sight component. In the first
case, SOP is derived in terms of the Meijer's G-function, while ASC and PNZ are
derived in terms of the multivariate Fox's H-function. In the second case, ASC
is derived in terms of the Meijer's G-function, while SOP and PNZ are derived
in terms of elementary functions. In addition, we derive the asymptotic ASC,
SOP and PNZ expressions which all match well the exact ones at high values of
signal-to-noise ratio, respectively. The capacity slope of asymptotic ASC and
the secrecy diversity order of asymptotic SOP have been derived for providing
more physical insights. Finally, the accuracy of our derived expressions is
validated by Monte-Carlo simulations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:03:16 GMT""}]","2020-12-02"
"2012.00269","Hongyang Du","Jiayi Zhang, Hongyang Du, Qiang Sun, Bo Ai, and Derrick Wing Kwan Ng","Physical Layer Security Enhancement With Reconfigurable Intelligent
  Surface-Aided Networks",,,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  Reconfigurable intelligent surface (RIS)-aided wireless communications have
drawn significant attention recently. We study the physical layer security of
the downlink RIS-aided transmission framework for randomly located users in the
presence of a multi-antenna eavesdropper. To show the advantages of RIS-aided
networks, we consider two practical scenarios: Communication with and without
RIS. In both cases, we apply the stochastic geometry theory to derive exact
probability density function (PDF) and cumulative distribution function (CDF)
of the received signal-to-interference-plus-noise ratio. Furthermore, the
obtained PDF and CDF are exploited to evaluate important security performance
of wireless communication including the secrecy outage probability, the
probability of nonzero secrecy capacity, and the average secrecy rate.
Monte-Carlo simulations are subsequently conducted to validate the accuracy of
our analytical results. Compared with traditional MIMO systems, the RIS-aided
system offers better performance in terms of physical layer security. In
particular, the security performance is improved significantly by increasing
the number of reflecting elements equipped in a RIS. However, adopting RIS
equipped with a small number of reflecting elements cannot improve the system
performance when the path loss of NLoS is small.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:06:41 GMT""},{""version"":""v2"",""created"":""Thu, 17 Dec 2020 08:28:13 GMT""},{""version"":""v3"",""created"":""Thu, 8 Apr 2021 10:42:28 GMT""}]","2021-04-09"
"2012.00270","Jung-Wan Ryu","Jung-Wan Ryu, Sungjong Woo, Nojoon Myoung, Hee Chul Park","Topological edge states in bowtie ladders with different cutting edges","6 pages, 4 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have studied topological edge states in bowtie ladders with various edge
truncations. The symmetric bowtie ladder, which comprises two trivial
Su-Schrieffer-Heeger (SSH) lattices, exhibits an insulator-metal transition
with trivial insulating states. On the other hand, the lattice can be
transformed into an extended SSH lattice depending on the edge shapes with
non-trivial insulating states in that the winding number is non-zero. The
winding numbers are permutationally designated in the phase diagram depending
on the choice of unit cell. The topological edge states are affected by the
shape of the edge and the corresponding winding number. We also studied general
bowtie ladder models with richer phase diagrams using the characteristics of
the localization length of the edge states showing state bifurcation.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:07:02 GMT""}]","2020-12-02"
"2012.00271","Jintao Wang","Jintao Wang, Chunqiu Li, Lu Yang and Mo Jia","Upper semi-continuity of random attractors and existence of invariant
  measures for nonlocal stochastic Swift-Hohenberg equation with multiplicative
  noise",,,"10.1063/5.0039187",,"math.PR math.AP math.DS","http://creativecommons.org/licenses/by/4.0/","  In this paper, we mainly study the long-time dynamical behaviors of 2D
nonlocal stochastic Swift-Hohenberg equations with multiplicative noise from
two perspectives. Firstly, by adopting the analytic semigroup theory, we prove
the upper semi-continuity of random attractors in the Sobolev space $H_0^2(U)$,
as the coefficient of the multiplicative noise approaches zero. Then, we extend
the classical ""stochastic Gronwall's lemma"", making it more convenient in
applications. Based on this improvement, we are allowed to use the analytic
semigroup theory to establish the existence of ergodic invariant measures.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:13:15 GMT""}]","2021-12-01"
"2012.00272","Long Wang","Long Wang","Remarks on nef and movable cones of hypersurfaces in Mori dream spaces","v2: The title changed. Add a new result Theorem 1.2 about the cone
  conjecture. v3: Add Theorem 1.3 about the cone conjecture. v4: Final version",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate nef and movable cones of hypersurfaces in Mori dream spaces.
The first result is: Let $Z$ be a smooth Mori dream space of dimension at least
four whose extremal contractions are of fiber type of relative dimension at
least two and let $X$ be a smooth ample divisor in $Z$, then $X$ is a Mori
dream space as well.
  The second result is: Let $Z$ be a Fano manifold of dimension at least four
whose extremal contractions are of fiber type and let $X$ be a smooth
anti-canonical hypersurface in $Z$, which is a smooth Calabi--Yau variety, then
the unique minimal model of $X$ up to isomorphism is $X$ itself, and moreover,
the movable cone conjecture holds for $X$, namely, there exists a rational
polyhedral cone which is a fundamental domain for the action of birational
automorphisms on the effective movable cone of $X$.
  The third result is: Let $P:= \mathbb{P}^n \times \cdots \times \mathbb{P}^n$
be the $N$-fold self-product of the $n$-dimensional projective space. Let $X$
be a general complete intersection of $n+1$ hypersurfaces of multidegree $(1,
\dots, 1)$ in $P$ with $\dim X \geq 3$. Then $X$ has only finitely many minimal
models up to isomorphism, and moreover, the movable cone conjecture holds for
$X$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:16:54 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 04:08:46 GMT""},{""version"":""v3"",""created"":""Wed, 23 Jun 2021 06:17:55 GMT""},{""version"":""v4"",""created"":""Wed, 18 May 2022 07:10:55 GMT""}]","2022-05-19"
"2012.00273","Sangdon Jin","Sangdon Jin and Jinmyoung Seok","Nonrelativistic limit of solitary waves for nonlinear
  Maxwell-Klein-Gordon equations",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We study the nonrelativistic limit of solitary waves from Nonlinear
Maxwell-Klein-Gordon equations (NMKG) to Nonlinear Schrodinger-Poisson
equations (NSP). It is known that the existence or multiplicity of positive
solutions depends on the choices of parameters the equations contain. In this
paper, we prove that for a given positive solitary wave of NSP, which is found
in Ruiz's work \cite{R}, there corresponds a family of positive solitary waves
of NMKG under the nonrelativistic limit. Notably, our results contain a new
result of existence of positive solutions to (NMKG) with lower order
nonlinearity.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:18:32 GMT""}]","2020-12-02"
"2012.00274","Senthil Velan S Dr","Vinobha A, Senthil Velan S, Chitra Babu","Evaluation of Reusability in Aspect Oriented Software using Inheritance
  Metrics",,,"10.1109/ICACCCT.2014.7019401",,"cs.SE","http://creativecommons.org/publicdomain/zero/1.0/","  Aspect-Oriented Software Development (AOSD) is a promising methodology for
efficiently capturing the cross-cutting functionalities (concerns) as
independent units called aspects. Inheritance of classes and aspects play a
vital role in defining the units of encapsulation. Hence, it is essential to
quantitatively capture the impact of inheritance in AOSD using design level
metrics and to infer on the higher level quality attribute, reusability. An
application to automate the processes of a typical University has been
developed in order to study the effect of using inheritance over the versions
of an aspectized AO application. A set of metrics to capture the manifestations
of inheritance is proposed for measurement. An automated tool named as Aspect
Oriented Software Reusability Measurement AOSRM is also designed and developed
to calculate the values of the proposed metrics. Based on the obtained metric
values for Java and AspectJ versions of the case study application, inheritance
in AspectJ versions showed a positive impact on reusability of software.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:20:24 GMT""}]","2020-12-02"
"2012.00275","Sangdon Jin","Sangdon Jin","Multi-bump standing waves for nonlinear Schrodinger equations with a
  general nonlinearity: the topological effect of potential wells",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this article, we are interested in multi-bump solutions of the singularly
perturbed problem \begin{equation*} -\epsilon^2\Delta v+V(x)v=f(v) \ \ \mbox{
in }\ \ \R^N. \end{equation*} Extending previous results \cite{B, DLY,W1}, we
prove the existence of multi-bump solutions for an optimal class of
nonlinearities $f$ satisfying the Berestycki-Lions conditions and, notably,
also for more general classes of potential wells than those previously studied.
We devise two novel topological arguments to deal with general classes of
potential wells. Our results prove the existence of multi-bump solutions in
which the centers of bumps converge toward potential wells as
$\epsilon\rightarrow 0$. Examples of potential wells include the following: the
union of two compact smooth submanifolds of $\R^N$ where these two submanifolds
meet at the origin and an embedded topological submanifold of $\R^N$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:24:56 GMT""}]","2020-12-02"
"2012.00276","Senthil Velan S Dr","Parthipan S, Senthil Velan S, Chitra Babu","Design Level Metrics to Measure the Complexity Across Versions of AO
  Software",,,"10.1109/ICACCCT.2014.7019400",,"cs.SE","http://creativecommons.org/publicdomain/zero/1.0/","  Software metric plays a vital role in quantitative assessment of any specific
software development methodology and its impact on the maintenance of software.
It can also be used to indicate the degree of interdependence among the
components by providing valuable feedback about quality attributes such as
maintainability, modifiability and understandability. The effort for software
maintenance normally has a high correlation with the complexity of its design.
Aspect Oriented Software Design is an emerging methodology that provides
powerful new techniques to improve the modularity of software from its design.
In this paper, evaluation model to capture the symptoms of complexity has been
defined consisting of metrics, artifacts and elements of complexity. A tool to
automatically capture these metrics across different versions of a case study
application, University Automation System has been developed. The values
obtained for the proposed metrics are used to infer on the complexity of Java
and AspectJ implementations of the case study application. These measurements
indicate that AspectJ implementations are less complex compared to the Java
implementations and there by positively influencing the maintainability of
software.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:27:57 GMT""}]","2020-12-02"
"2012.00277","Chad Sinclair","S. Medrano, H. Zhao, B. Gault, F. De Geuser, C. W. Sinclair","The Benefits of Trace Cu in Wrought Al-Mg Alloys","33 pages, 10 figures",,"10.1016/j.actamat.2021.116734",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The softening and strengthening contributions in pre-deformed and aged
Al-Mg-Cu alloys containing 3wt.%Mg and 0.5wt.%Cu are evaluated by a combination
of microscopy, mechanical testing and modelling. A refined phenomenological
model for the work hardening response, accounting for the separate effects of
recovery and precipitation, is shown to be suitable for an unambiguous
determination of the precipitation hardening contribution in these alloys.
Significantly, it is found that the mechanical response of these alloys is not
strongly impacted by Cu content (in the low Cu content regime), pre-deformation
level or aging temperature meaning that the alloys are robust with respect to
variations in composition. This is interesting from the perspective of alloy
design concepts based on `recycling friendly' compositions in applications that
include paint-baking.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:30:30 GMT""}]","2021-02-23"
"2012.00278","Franziska Weber","Varun M. Gudibanda, Franziska Weber, Yukun Yue","Convergence analysis of a fully discrete energy-stable numerical scheme
  for the Q-tensor flow of liquid crystals",,,,,"math.NA cs.NA math.AP","http://creativecommons.org/licenses/by/4.0/","  We present a fully discrete convergent finite difference scheme for the
Q-tensor flow of liquid crystals based on the energy-stable semi-discrete
scheme by Zhao, Yang, Gong, and Wang (Comput. Methods Appl. Mech. Engrg. 2017).
We prove stability properties of the scheme and show convergence to weak
solutions of the Q-tensor flow equations. We demonstrate the performance of the
scheme in numerical simulations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:32:21 GMT""},{""version"":""v2"",""created"":""Thu, 26 May 2022 15:39:34 GMT""}]","2022-05-27"
"2012.00279","Roman Nikolaevich Lee","Roman N. Lee","Libra: a package for transformation of differential systems for
  multiloop integrals","32 pages",,"10.1016/j.cpc.2021.108058",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new package for Mathematica system, called Libra. Its purpose is
to provide convenient tools for the transformation of the first-order
differential systems $\partial_i \boldsymbol j = M_i \boldsymbol j$ for one or
several variables. In particular, Libra is designed for the reduction to
$\epsilon$-form of the differential systems which appear in multiloop
calculations. The package also contains some tools for the construction of
general solution: both via perturbative expansion of path-ordered exponent and
via generalized power series expansion near regular singular points.Libra also
has tools to determine the minimal list of coefficients in the asymptotics of
the original master integrals, sufficient for fixing the boundary conditions.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:36:00 GMT""}]","2021-07-07"
"2012.00280","Alberto F. Mart\'in","Santiago Badia and Manuel Caicedo and Alberto F. Mart\'in and Javier
  Principe","A robust and scalable unfitted adaptive finite element framework for
  nonlinear solid mechanics",,,"10.1016/j.cma.2021.114093",,"math.NA cs.MS cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we bridge standard adaptive mesh refinement and coarsening on
scalable octree background meshes and robust unfitted finite element
formulations for the automatic and efficient solution of large-scale nonlinear
solid mechanics problems posed on complex geometries, as an alternative to
standard body-fitted formulations, unstructured mesh generation and graph
partitioning strategies. We pay special attention to those aspects requiring a
specialized treatment in the extension of the unfitted h-adaptive aggregated
finite element method on parallel tree-based adaptive meshes, recently
developed for linear scalar elliptic problems, to handle nonlinear problems in
solid mechanics. In order to accurately and efficiently capture localized
phenomena that frequently occur in nonlinear solid mechanics problems, we
perform pseudo time-stepping in combination with h-adaptive dynamic mesh
refinement and rebalancing driven by a-posteriori error estimators. The method
is implemented considering both irreducible and mixed (u/p) formulations and
thus it is able to robustly face problems involving incompressible materials.
In the numerical experiments, both formulations are used to model the inelastic
behavior of a wide range of compressible and incompressible materials. First, a
selected set of benchmarks are reproduced as a verification step. Second, a set
of experiments is presented with problems involving complex geometries. Among
them, we model a cantilever beam problem with spherical hollows distributed in
a Simple Cubic array. This test involves a discrete domain with up to 11.7M
Degrees Of Freedom solved in less than two hours on 3072 cores of a parallel
supercomputer.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:37:24 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 00:34:04 GMT""},{""version"":""v3"",""created"":""Sun, 25 Jul 2021 07:20:36 GMT""}]","2021-09-01"
"2012.00281","Muriel Gros-Balthazard","Muriel Gros-Balthazard and Jonathan M. Flowers","A brief history of the origin of domesticated date palms",,,,,"q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  The study of the origins of crops is of interest from both a fundamental
evolutionary understanding viewpoint, and from an applied agricultural
technology perspective. The date palm (Phoenix dactylifera L.) is the iconic
fruit crop of hot and arid regions of North Africa and the Middle East,
producing sugar-rich fruits, known as dates. There are many different cultivars
each with distinctive fruit traits, and there are many wild Phoenix species
too, which in total form a complex of related species. The understanding of
plant domestication involves multiple disciplines, including phylogeography,
population genetics and archaeology. In the past decade, they have prompted new
discoveries on the evolutionary history of date palm, but a complete
understanding of its origins remains to be elucidated, along with the genetic
architecture of its domestication syndrome. In this chapter, we review the
current state of the art regarding the origins of the domesticated date palm.
We first discuss whether date palms are domesticated, and highlight how they
diverge from their wild Phoenix relatives. We then outline patterns in the
population genetic and archaeobotanical data, and review different models for
the origins of domesticated date palms by highlighting sources of evidence that
are either consistent or inconsistent with each model. We then review the
process of date palm domestication, and emphasize the human activities that
have prompted its domestication. We particularly focus on the evolution of
fruit traits.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:40:54 GMT""}]","2020-12-02"
"2012.00282","Sunhee Hwang","Sunhee Hwang, Sungho Park, Dohyung Kim, Mirae Do, Hyeran Byun","FairFaceGAN: Fairness-aware Facial Image-to-Image Translation","The 31st British Machine Vision Conference (BMVC 2020)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce FairFaceGAN, a fairness-aware facial
Image-to-Image translation model, mitigating the problem of unwanted
translation in protected attributes (e.g., gender, age, race) during facial
attributes editing. Unlike existing models, FairFaceGAN learns fair
representations with two separate latents - one related to the target
attributes to translate, and the other unrelated to them. This strategy enables
FairFaceGAN to separate the information about protected attributes and that of
target attributes. It also prevents unwanted translation in protected
attributes while target attributes editing. To evaluate the degree of fairness,
we perform two types of experiments on CelebA dataset. First, we compare the
fairness-aware classification performances when augmenting data by existing
image translation methods and FairFaceGAN respectively. Moreover, we propose a
new fairness metric, namely Frechet Protected Attribute Distance (FPAD), which
measures how well protected attributes are preserved. Experimental results
demonstrate that FairFaceGAN shows consistent improvements in terms of fairness
over the existing image translation models. Further, we also evaluate image
translation performances, where FairFaceGAN shows competitive results, compared
to those of existing methods.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:43:46 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 05:38:48 GMT""}]","2020-12-03"
"2012.00283","Ayan Mahalanobis","Chris Monico and Ayan Mahalanobis","A remark on MAKE -- a Matrix Action Key Exchange",,,,,"cs.CR cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In a recent paper [arXiv:2009.00716], Rahman and Shpilrain proposed a new
key-exchange protocol MAKE based on external semidirect product of groups. The
purpose of this paper is to show that the key exchange protocol is insecure. We
were able to break their challenge problem in under a second.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:55:52 GMT""}]","2020-12-02"
"2012.00284","Jacky Liang","Vicky Zeng, Tabitha Edith Lee, Jacky Liang, Oliver Kroemer","Visual Identification of Articulated Object Parts","Presented at the 2021 IEEE International Conference on Intelligent
  Robots and Systems (IROS 2021). This version contains the camera-ready paper
  with an appendix. Project page:
  https://sites.google.com/view/articulated-objects/home",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As autonomous robots interact and navigate around real-world environments
such as homes, it is useful to reliably identify and manipulate articulated
objects, such as doors and cabinets. Many prior works in object articulation
identification require manipulation of the object, either by the robot or a
human. While recent works have addressed predicting articulation types from
visual observations alone, they often assume prior knowledge of category-level
kinematic motion models or sequence of observations where the articulated parts
are moving according to their kinematic constraints. In this work, we propose
FormNet, a neural network that identifies the articulation mechanisms between
pairs of object parts from a single frame of an RGB-D image and segmentation
masks. The network is trained on 100k synthetic images of 149 articulated
objects from 6 categories. Synthetic images are rendered via a photorealistic
simulator with domain randomization. Our proposed model predicts motion
residual flows of object parts, and these flows are used to determine the
articulation type and parameters. The network achieves an articulation type
classification accuracy of 82.5% on novel object instances in trained
categories. Experiments also show how this method enables generalization to
novel categories and be applied to real-world images without fine-tuning.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:59:20 GMT""},{""version"":""v2"",""created"":""Sat, 10 Apr 2021 14:15:43 GMT""},{""version"":""v3"",""created"":""Thu, 9 Dec 2021 21:46:27 GMT""}]","2022-01-04"
"2012.00285","Tomokazu Onozuka","Hideki Murahara and Tomokazu Onozuka","Connectors of the Ohno relation for parametrized multiple zeta series","8 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Ohno relation is a well known relation in the theory of multiple zeta
values. Recently, Seki and Yamamoto introduced a connector method and gave its
succinct proof. On the other hand, Igarashi obtained the generalization of the
Ohno relation for parametrized multiple zeta series. In this paper, we give new
connectors to simplify his proof.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:59:21 GMT""}]","2020-12-02"
"2012.00286","Huy Truong Mr","Huy Truong Dinh and Daehee Kim","MILP-based Imitation Learning for HVAC control","10 pages, 14 figures","IEEE Internet of Things Journal, 2021","10.1109/JIOT.2021.3111454",,"cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  To optimize the operation of a HVAC system with advanced techniques such as
artificial neural network, previous studies usually need forecast information
in their method. However, the forecast information inevitably contains errors
all the time, which degrade the performance of the HVAC operation. Hence, in
this study, we propose MILP-based imitation learning method to control a HVAC
system without using the forecast information in order to reduce energy cost
and maintain thermal comfort at a given level. Our proposed controller is a
deep neural network (DNN) trained by using data labeled by a MILP solver with
historical data. After training, our controller is used to control the HVAC
system with real-time data. For comparison, we also develop a second method
named forecast-based MILP which control the HVAC system using the forecast
information. The performance of the two methods is verified by using real
outdoor temperatures and real day-ahead prices in Detroit city, Michigan,
United States. Numerical results clearly show that the performance of the
MILP-based imitation learning is better than that of the forecast-based MILP
method in terms of hourly power consumption, daily energy cost, and thermal
comfort. Moreover, the difference between results of the MILP-based imitation
learning method and optimal results is almost negligible. These optimal results
are achieved only by using the MILP solver at the end of a day when we have
full information on the weather and prices for the day.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:00:05 GMT""}]","2022-02-23"
"2012.00287","Takayuki Osakabe","Takayuki Osakabe, Miki Tanaka, Yuma Kinoshita, Hitoshi Kiya","CycleGAN without checkerboard artifacts for counter-forensics of
  fake-image detection",,,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel CycleGAN without checkerboard artifacts for
counter-forensics of fake-image detection. Recent rapid advances in image
manipulation tools and deep image synthesis techniques, such as Generative
Adversarial Networks (GANs) have easily generated fake images, so detecting
manipulated images has become an urgent issue. Most state-of-the-art forgery
detection methods assume that images include checkerboard artifacts which are
generated by using DNNs. Accordingly, we propose a novel CycleGAN without any
checkerboard artifacts for counter-forensics of fake-mage detection methods for
the first time, as an example of GANs without checkerboard artifacts.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:08:37 GMT""}]","2020-12-02"
"2012.00288","Mahfuz Ahmed Masum","Mahfuz Ahmed Masum, Sheikh Junayed Ahmed, Ayesha Tasnim, Md Saiful
  Islam","BAN-ABSA: An Aspect-Based Sentiment Analysis dataset for Bengali and
  it's baseline evaluation","11 pages,2 figures, 8 tables Included in proceedings of International
  Joint Conference on Advances in Computational Intelligence (IJCACI) 2020",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Due to the breathtaking growth of social media or newspaper user comments,
online product reviews comments, sentiment analysis (SA) has captured
substantial interest from the researchers. With the fast increase of domain, SA
work aims not only to predict the sentiment of a sentence or document but also
to give the necessary detail on different aspects of the sentence or document
(i.e. aspect-based sentiment analysis). A considerable number of datasets for
SA and aspect-based sentiment analysis (ABSA) have been made available for
English and other well-known European languages. In this paper, we present a
manually annotated Bengali dataset of high quality, BAN-ABSA, which is
annotated with aspect and its associated sentiment by 3 native Bengali
speakers. The dataset consists of 2,619 positive, 4,721 negative and 1,669
neutral data samples from 9,009 unique comments gathered from some famous
Bengali news portals. In addition, we conducted a baseline evaluation with a
focus on deep learning model, achieved an accuracy of 78.75% for aspect term
extraction and accuracy of 71.08% for sentiment classification. Experiments on
the BAN-ABSA dataset show that the CNN model is better in terms of accuracy
though Bi-LSTM significantly outperforms CNN model in terms of average
F1-score.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:09:44 GMT""}]","2020-12-02"
"2012.00289","Travis Greene","Travis Greene, Galit Shmueli, Jan Fell, Ching-Fu Lin, Han-Wei Liu","Forks Over Knives: Predictive Inconsistency in Criminal Justice
  Algorithmic Risk Assessment Tools",,,"10.1111/RSSA.12966",,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Big data and algorithmic risk prediction tools promise to improve criminal
justice systems by reducing human biases and inconsistencies in decision
making. Yet different, equally-justifiable choices when developing, testing,
and deploying these sociotechnical tools can lead to disparate predicted risk
scores for the same individual. Synthesizing diverse perspectives from machine
learning, statistics, sociology, criminology, law, philosophy and economics, we
conceptualize this phenomenon as predictive inconsistency. We describe sources
of predictive inconsistency at different stages of algorithmic risk assessment
tool development and deployment and consider how future technological
developments may amplify predictive inconsistency. We argue, however, that in a
diverse and pluralistic society we should not expect to completely eliminate
predictive inconsistency. Instead, to bolster the legal, political, and
scientific legitimacy of algorithmic risk prediction tools, we propose
identifying and documenting relevant and reasonable ""forking paths"" to enable
quantifiable, reproducible multiverse and specification curve analyses of
predictive inconsistency at the individual level.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:12:30 GMT""},{""version"":""v2"",""created"":""Thu, 22 Sep 2022 14:42:03 GMT""}]","2022-09-23"
"2012.00290","Donghuo Zeng","Donghuo Zeng, Yi Yu, Keizo Oyama","MusicTM-Dataset for Joint Representation Learning among Sheet Music,
  Lyrics, and Musical Audio","12 pages, 5 figures, 2 tables","CSMT2020",,,"cs.SD cs.DB cs.IR cs.MM eess.AS","http://creativecommons.org/licenses/by-sa/4.0/","  This work present a music dataset named MusicTM-Dataset, which is utilized in
improving the representation learning ability of different types of cross-modal
retrieval (CMR). Little large music dataset including three modalities is
available for learning representations for CMR. To collect a music dataset, we
expand the original musical notation to synthesize audio and generated
sheet-music image, and build musical notation based sheet-music image, audio
clip and syllable-denotation text as fine-grained alignment, such that the
MusicTM-Dataset can be exploited to receive shared representation for
multimodal data points. The MusicTM-Dataset presents 3 kinds of modalities,
which consists of the image of sheet-music, the text of lyrics and synthesized
audio, their representations are extracted by some advanced models. In this
paper, we introduce the background of music dataset and express the process of
our data collection. Based on our dataset, we achieve some basic methods for
CMR tasks. The MusicTM-Dataset are accessible in https:
//github.com/dddzeng/MusicTM-Dataset.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:18:53 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 14:20:13 GMT""}]","2021-05-10"
"2012.00291","Hai-Han Sun","Wenhao Luo, Hai-Han Sun, Yee Hui Lee, Abdulkadir C. Yucel, Genevieve
  Ow and Mohamed Lokman Mohd Yusof","Effects of Intermediate Frequency Bandwidth on Stepped Frequency Ground
  Penetrating Radar",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A stepped frequency ground penetrating radar (GPR) system is used for
detecting objects buried under high permittivity soil. Different intermediate
frequency bandwidth (IFBW) of the mixing receiver is used and measurement
results are compared. It is shown that the IFBW can affect the system's
signal-to-noise ratio (SNR). Experimental results show that objects of
different materials can clearly be detected when the appropriate IFBW is used.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:24:02 GMT""}]","2020-12-02"
"2012.00292","Anish Sevekari","Wesley Pegden and Anish Sevekari","Comb inequalities for typical Euclidean TSP instances","37 pages, 4 figures",,,,"cs.DS cs.DM math.CO math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that even in average case, the Euclidean Traveling Salesman Problem
exhibits an integrality gap of $(1+\epsilon)$ for $\epsilon>0$ when the
Held-Karp Linear Programming relaxation is augmented by all comb inequalities
of bounded size. This implies that large classes of branch-and-cut algorithms
take exponential time for the Euclidean TSP, even on random inputs.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:25:21 GMT""},{""version"":""v2"",""created"":""Thu, 30 Mar 2023 13:34:39 GMT""}]","2023-03-31"
"2012.00293","Tamiki Komatsuzaki","Sulimon Sattari, Udoy S. Basak, Ryan G. James, James P. Crutchfield,
  and Tamiki Komatsuzaki","Modes of Information Flow in Collective Cohesion",,,"10.1126/sciadv.abj1720",,"nlin.AO","http://creativecommons.org/licenses/by/4.0/","  Pairwise interactions between individuals are taken as fundamental drivers of
collective behavior responsible for group cohesion and decision-making. While
an individual directly influences only a few neighbors, over time indirect
influences penetrate a much larger group. The abiding question is how this
spread of influence comes to affect the collective. One or a few individuals
are often identified as leaders, being more influential than others. Transfer
entropy and time-delayed mutual information are used to identify underlying
asymmetric interactions, such as leader-follower classification in aggregated
individuals--cells, birds, fish, and animals. However, these conflate distinct
functional modes of information flow between individuals. Computing information
measures conditioning on multiple agents requires the proper sampling of a
probability distribution whose dimension grows exponentially with the number of
agents being conditioned on. Employing simple models of interacting
self-propelled particles, we examine the pitfalls of using time-delayed mutual
information and transfer entropy to quantify the strength of influence from a
leader to a follower. Surprisingly, one must be wary of these pitfalls even for
two interacting particles. As an alternative we decompose transfer entropy and
time-delayed mutual information into intrinsic, shared, and synergistic modes
of information flow. The result not only properly reveals the underlying
effective interactions, but also facilitates a more detailed diagnosis of how
individual interactions lead to collective behavior. This exposes the role of
individual and group memory in collective behaviors. In addition, we
demonstrate in a multi-agent system how knowledge of the decomposed information
modes between a single pair of agents reveals the nature of many-body
interactions without conditioning on additional agents.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:27:50 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 10:48:47 GMT""}]","2022-04-12"
"2012.00294","Nakul Soni Dr.","Nakul R. Soni, Rikita M. Parekh, Janaki J. Patel, Akshay N. Gadaria,
  Jignesh N. Pandya","Spectroscopy of heavy-heavy flavour mesons and annihilation widths of
  quarkonia","Accepted for publication in Few-Body Systems","Few-Body Syst. 63, 77 (2022)","10.1007/s00601-022-01778-6",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the framework of nonrelativistic quark-antiquark Cornell potential
model formalism, we study the annihilation of heavy quarkonia. We determine
their annihilation widths resulting into digluon, dilepton, $3\gamma$, $3g$ and
$\gamma gg$ and compare our findings with the available theoretical results and
experimental data. We also provide the charge radii and absolute square of
radial Schr\""odinger wave function at zero quark-antiquark separation for heavy
quarkonia and $B_c$ mesons.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:29:05 GMT""},{""version"":""v2"",""created"":""Mon, 17 Oct 2022 17:08:44 GMT""}]","2022-10-27"
"2012.00295","Xiao-Hua Li","Hong-Ming Liu, You-Tian Zou, Xiao Pan, Jiu-Long Chen, Biao He and
  Xiao-Hua Li","New Geiger-Nuttall law for two-proton radioactivity","6 pages, 2 figures",,,,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present work, combining with the Geiger-Nuttall law, a two-parameter
empirical formula is proposed to study the two-proton (2p) radioactivity. Using
this formula, the calculated 2p radioactivity half-lives are in good agreement
with the experimental data as well as the calculated ones obtained by Goncalves
et al: ([Phys. Lett. B 774, 14 (2017)]) using the effective liquid drop model
(ELDM), Sreeja et al: ([Eur. Phys. J. A 55, 33 (2019)]) using a four-parameter
empirical formula and Cui et al: ([Phys. Rev. C 101: 014301 (2020)]) using a
generalized liquid drop model (GLDM). In addition, this two-parameter empirical
formula is extended to predict the half-lives of 22 possible 2p radioactivity
candidates, whose the 2p radioactivity released energy Q2p>0, obtained from the
latest evaluated atomic mass table AME2016. The predicted results have good
consistency with ones using other theoretical models such as the ELDM, GLDM and
four-parameter empirical formula.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:29:19 GMT""}]","2020-12-02"
"2012.00296","Charles Martin","Charles Martin and Henry Gardner and Ben Swift","Tracking Ensemble Performance on Touch-Screens with Gesture
  Classification and Transition Matrices",,"Proceedings of the International Conference on New Interfaces for
  Musical Expression, 2015, pp. 359-364","10.5281/zenodo.1179130",,"cs.HC cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  We present and evaluate a novel interface for tracking ensemble performances
on touch-screens. The system uses a Random Forest classifier to extract
touch-screen gestures and transition matrix statistics. It analyses the
resulting gesture-state sequences across an ensemble of performers. A series of
specially designed iPad apps respond to this real-time analysis of free-form
gestural performances with calculated modifications to their musical
interfaces. We describe our system and evaluate it through cross-validation and
profiling as well as concert experience.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:36:26 GMT""}]","2020-12-02"
"2012.00297","Roger Hurtado PhD","Roger Hurtado and Robel Arenas","Hypergeometric viable models in $f(R)$ gravity","10 pages, 3 figures",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A cosmologically viable hypergeometric model in the modified gravity theory
$f(R)$ is found from the need for asintoticity towards $\Lambda$CDM, the
existence of an inflection point in the $f(R)$ curve, and the conditions of
viability given by the phase space curves $(m, r)$, where $m$ and $r$ are
characteristic functions of the model. To analyze the constraints associated
with the viability requirements, the models were expressed in terms of a
dimensionless variable, i.e. $R\to x$ and $f(R)\to y(x)=x+h(x)+\lambda$, where
$h(x)$ represents the deviation of the model from General Relativity. Using the
geometric properties imposed by the inflection point, differential equations
were constructed to relate $h'(x)$ and $h''(x)$, and the solutions found were
Starobinsky (2007) and Hu-Sawicki type models, nonetheless, it was found that
these differential equations are particular cases of a hypergeometric
differential equation, so that these models can be obtained from a general
hypergeometric model. The parameter domains of this model were analyzed to make
the model viable.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:37:04 GMT""}]","2020-12-02"
"2012.00298","Shengyang Chen","S. Chen, H. Chen, W. Zhou, C.-Y. Wen, and B. Li","End-to-End UAV Simulation for Visual SLAM and Navigation","9pages,11 figures",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Visual Simultaneous Localization and Mapping (v-SLAM) and navigation of
multirotor Unmanned Aerial Vehicles (UAV) in an unknown environment have grown
in popularity for both research and education. However, due to the complex
hardware setup, safety precautions, and battery constraints, extensive physical
testing can be expensive and time-consuming. As an alternative solution,
simulation tools lower the barrier to carry out the algorithm testing and
validation before field trials. In this letter, we customize the ROS-Gazebo-PX4
simulator in deep and provide an end-to-end simulation solution for the UAV
v-SLAM and navigation study. A set of localization, mapping, and path planning
kits were also integrated into the simulation platform. In our simulation,
various aspects, including complex environments and onboard sensors, can
simultaneously interact with our navigation framework to achieve specific
surveillance missions. In this end-to-end simulation, we achieved click and fly
level autonomy UAV navigation. The source code is open to the research
community.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:39:30 GMT""}]","2020-12-02"
"2012.00299","Chufeng Nien","Chufeng Nien","Representations of finite pattern groups","We found mistakes in the proof of the main theorem",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G=1+A$ be a finite pattern group over the finite field ${\mathbb{F}}_q$.
We give a natural bijection between coadjoint orbits of $G$ and its equivalent
classes of irreducible representations. More precisely, given any $T\in A^t$,
viewed as a representative of associated coadjoint orbit ${\mathfrak{O}}_T$ of
$G$, we can explicitly construct a subgroup $H_T $ of $G$, such that
${\mathrm{Ind}}_{H_T}^G \psi_T$ is irreducible and ${\mathrm{Ind}}_{H_T}^G
\psi_T \cong {\mathrm{Ind}}_{H_{T'}}^G \psi_{T'}$ if and only if $T$ and $ T'$
are in the same coadjoint orbit. Here $\psi_T(x)=\psi({\mathrm{tr}} Tx)\text{
for }x\in H_T,$ and $\psi$ is a fixed nontrivial additive character of
${\mathbb{F}}_q$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:45:37 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 03:25:23 GMT""}]","2020-12-23"
"2012.00300","Yujiro Kawamata","Yujiro Kawamata","On Fujita's semi-ampleness in the rank one case","The result was known",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that a conjecture of Fujita on the semi-ampleness is true in the
case of rank one direct summand, though it is wrong in higher rank case by
Catanese and Dettweiler.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:45:38 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 02:26:22 GMT""}]","2020-12-04"
"2012.00301","Liyuan Pan Miss","Liyuan Pan, Shah Chowdhury, Richard Hartley, Miaomiao Liu, Hongguang
  Zhang, and Hongdong Li","Dual Pixel Exploration: Simultaneous Depth Estimation and Image
  Restoration",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dual-pixel (DP) hardware works by splitting each pixel in half and
creating an image pair in a single snapshot. Several works estimate
depth/inverse depth by treating the DP pair as a stereo pair. However,
dual-pixel disparity only occurs in image regions with the defocus blur. The
heavy defocus blur in DP pairs affects the performance of matching-based depth
estimation approaches. Instead of removing the blur effect blindly, we study
the formation of the DP pair which links the blur and the depth information. In
this paper, we propose a mathematical DP model which can benefit depth
estimation by the blur. These explorations motivate us to propose an end-to-end
DDDNet (DP-based Depth and Deblur Network) to jointly estimate the depth and
restore the image. Moreover, we define a reblur loss, which reflects the
relationship of the DP image formation process with depth information, to
regularise our depth estimate in training. To meet the requirement of a large
amount of data for learning, we propose the first DP image simulator which
allows us to create datasets with DP pairs from any existing RGBD dataset. As a
side contribution, we collect a real dataset for further research. Extensive
experimental evaluation on both synthetic and real datasets shows that our
approach achieves competitive performance compared to state-of-the-art
approaches.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:53:57 GMT""}]","2020-12-02"
"2012.00302","Masaki Aida","Kakeru Ohki, Ayako Hashizume, Masaki Aida","Independence of the Fundamental Equation of the Oscillation Model on
  Algebraic Representations: Social Media Echo Chamber Effect","4 pages, no figure, IEICE ICETC 2020. arXiv admin note: substantial
  text overlap with arXiv:2011.13372",,,,"cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the oscillation model that describes the user dynamics of online social
networks, it is known that the fundamental equation can explicitly describe the
causal relationship between the network structure and user dynamics. The
fundamental equation uses algebra that satisfies the anti-commutation relation,
and its matrix representation is not unique. However, even if the matrix
representations are different, the same results should be derived from
different representations of the fundamental equation if they are describing
the same phenomenon. In this paper, we confirm, using the echo-chamber effect
as an example, that the fundamental equations of different matrix
representations lead to the same result.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:55:33 GMT""}]","2020-12-02"
"2012.00303","Noboru Ito","Noboru Ito, Yusuke Takimura, Kouki Taniyama","Strong and weak (1, 3) homotopies on knot Projections","27 pages, 45 figures","Osaka J. Math. 52 (2015), no. 3, 617--646","10.18910/57647",,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Strong and weak (1, 3) homotopies are equivalence relations on knot
projections, defined by the first flat Reidemeister move and each of two
different types of the third flat Reidemeister moves. In this paper, we
introduce the cross chord number that is the minimal number of double points of
chords of a chord diagram. Cross chord numbers induce a strong (1, 3)
invariant. We show that Hanaki's trivializing number is a weak (1, 3)
invariant. We give a complete classification of knot projections having
trivializing number two up to the first flat Reidemeister moves using cross
chord numbers and the positive resolutions of double points. Two knot
projections with trivializing number two are both weak (1, 3) homotopy
equivalent and strong (1, 3) homotopy equivalent if and only if they can be
related by only the first flat Reidemeister moves. Finally, we determine the
strong (1, 3) homotopy equivalence class containing the trivial knot projection
and other classes of knot projections.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:57:53 GMT""}]","2020-12-02"
"2012.00304","Abhimanyu Kumar","Abhimanyu Kumar and Om Prakash Pandey","Reconsideration of feasibility of Hall amplifier","5 pages, 1 figure",,,,"physics.app-ph cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  In 1955, it was first suggested that Hall effect can be employed for
amplification purposes by using semiconductor material with very high mobility.
While this idea was limited at that time, yet it was not entirely discarded
expecting eventual progress. We revisit this idea and discuss it in the light
of current literature. This manuscript kindles this 65 year old amazing idea
and views it with modern understanding, which will aid in realizing Hall
amplifiers.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:58:43 GMT""}]","2020-12-02"
"2012.00305","Tsuyoshi Yamamoto","Tsuyoshi Yamamoto, Leonid I. Glazman, and Manuel Houzet","Transmission of waves through a pinned elastic medium","19 pages, 12 figures","Phys. Rev. B 103, 224211 (2021)","10.1103/PhysRevB.103.224211",,"cond-mat.dis-nn cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the scattering of elastic waves off a disordered region
described by a one-dimensional random-phase sine-Gordon model. The collective
pinning results in an effective static disorder potential with universal and
non-Gaussian correlations, acting on propagating waves. We find signatures of
the correlations in the wave transmission in a wide frequency range, which
covers both the weak and strong localization regimes. Our theory elucidates the
dynamics of collectively-pinned phases occurring in any natural or synthetic
elastic medium. The latter one is exemplified by a one-dimensional array of
Josephson junctions, for which we specify our results. The obtained results
provide benchmarks for the array-enabled quantum simulations addressing the
dynamics in broader and yet-unexplored domains of individual pinning and
quantum Bose glass.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:59:14 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 15:01:58 GMT""}]","2021-07-01"
"2012.00306","Xi Zhang","Chuanjing Zhang and Xi Zhang","Generalized Donaldson's functionals and related nonlinear partial
  differential equations",,,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce a family of generalized Donaldson's functional on
holomorphic vector bundles, whose Euler-Lagrange equations are a vector bundle
version of the complex $k$-Hessian equations. We also discuss the uniqueness of
solutions to these equations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:01:50 GMT""}]","2020-12-02"
"2012.00307","Xilin Liu","Xilin Liu and Andrew G. Richardson","Edge Deep Learning for Neural Implants","25 pages, 7 figures, 3 tables","J Neural Eng. 2021 Apr 26;18(4)","10.1088/1741-2552/abf473",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Implanted devices providing real-time neural activity classification and
control are increasingly used to treat neurological disorders, such as epilepsy
and Parkinson's disease. Classification performance is critical to identifying
brain states appropriate for the therapeutic action. However, advanced
algorithms that have shown promise in offline studies, in particular deep
learning (DL) methods, have not been deployed on resource-restrained neural
implants. Here, we designed and optimized three embedded DL models of commonly
adopted architectures and evaluated their inference performance in a case study
of seizure detection. A deep neural network (DNN), a convolutional neural
network (CNN), and a long short-term memory (LSTM) network were designed to
classify ictal, preictal, and interictal phases from the CHB-MIT scalp EEG
database. After iterative model compression and quantization, the algorithms
were deployed on a general-purpose, off-the-shelf microcontroller. Inference
sensitivity, false positive rate, execution time, memory size, and power
consumption were quantified. For seizure event detection, the sensitivity and
FPR (h-1) for the DNN, CNN, and LSTM models were 87.36%/0.169, 96.70%/0.102,
and 97.61%/0.071, respectively. Predicting seizures for early warnings was also
feasible. The implemented compression and quantization achieved a significant
saving of power and memory with an accuracy degradation of less than 0.5%. Edge
DL models achieved performance comparable to many prior implementations that
had no time or computational resource limitations. Generic microcontrollers can
provide the required memory and computational resources, while model designs
can be migrated to ASICs for further optimization. The results suggest that
edge DL inference is a feasible option for future neural implants to improve
classification performance and therapeutic outcomes.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:02:04 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 05:32:36 GMT""},{""version"":""v3"",""created"":""Tue, 1 Jun 2021 04:06:38 GMT""}]","2021-06-02"
"2012.00308","Tobias Schlagenhauf","Tobias Schlagenhauf, Tim Brander, Juergen Fleischer","A Stitching Algorithm for Automated Surface Inspection of Rotationally
  Symmetric Components","9 pages, 13 figures","In: CIRP Journal of Manufacturing Science and Technology (35), S.
  169-177 (2021)",,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper provides a novel approach to stitching surface images of
rotationally symmetric parts. It presents a process pipeline that uses a
feature-based stitching approach to create a distortion-free and true-to-life
image from a video file. The developed process thus enables, for example,
condition monitoring without having to view many individual images. For
validation purposes, this will be demonstrated in the paper using the concrete
example of a worn ball screw drive spindle. The developed algorithm aims at
reproducing the functional principle of a line scan camera system, whereby the
physical measuring systems are replaced by a feature-based approach. For
evaluation of the stitching algorithms, metrics are used, some of which have
only been developed in this work or have been supplemented by test procedures
already in use. The applicability of the developed algorithm is not only
limited to machine tool spindles. Instead, the developed method allows a
general approach to the surface inspection of various rotationally symmetric
components and can therefore be used in a variety of industrial applications.
Deep-learning-based detection Algorithms can easily be implemented to generate
a complete pipeline for failure detection and condition monitoring on
rotationally symmetric parts.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:03:45 GMT""},{""version"":""v2"",""created"":""Tue, 27 Apr 2021 12:20:11 GMT""},{""version"":""v3"",""created"":""Mon, 21 Jun 2021 16:26:53 GMT""}]","2021-06-22"
"2012.00309","Dennis Ulbrich","Antoine Pauthier, Jens D.M. Rademacher, Dennis Ulbrich","Weak and strong interaction of excitation kinks in scalar parabolic
  equations","40 pages, 9 figures",,,,"math.AP math.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Motivated by studies of the Greenberg-Hastings cellular automata (GHCA) as a
caricature of excitable systems, in this paper we study kink-antikink dynamics
in the perhaps simplest PDE model of excitable media given by the scalar
reaction diffusion-type $\theta$-equations for excitable angular phase
dynamics. On the one hand, we qualitatively study geometric kink positions
using the comparison principle and the theory of terraces. This yields the
minimal initial distance as a global lower bound, a well-defined sequence of
collision data for kinks- and antikinks, and implies that periodic pure kink
sequences are asymptotically equidistant. On the other hand, we study
metastable dynamics of finitely many kinks using weak interaction theory for
certain analytic kink positions, which admits a rigorous reduction to ODE. By
blow-up type singular rescaling we show that distances become ordered in finite
time, and eventually diverge. We conclude that diffusion implies a loss of
information on kink distances so that the entropic complexity based on
positions and collisions in the GHCA does not simply carry over to the PDE
model.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:15:41 GMT""}]","2020-12-02"
"2012.00310","Mohammad Khorsand Zak","Zeinab Bahramizadeh, Mojtaba Nazari, Mohammad Khorsand Zak and Zahra
  Yarahmadi","Minimal residual Hermitian and skew-Hermitian splitting iteration method
  for the continuous Sylvester equation","arXiv admin note: text overlap with arXiv:2005.08123",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  By applying the minimal residual technique to the Hermitian and
skew-Hermitian (HSS) iteration scheme, we introduce a non-stationary iteration
method named minimal residual Hermitian and skew-Hermitian (MRHSS) iteration
method to solve the continuous Sylvester equation. Numerical results verify the
effectiveness and robustness of the MRHSS iteration method versus the HSS
method for the continuous Sylvester equation. Moreover, by numerical
computation, we show that the MRHSS splitting can be used as a splitting
preconditioner and induce accurate, robust and effective preconditioned Krylov
subspace iteration methods for solving the continuous Sylvester equation.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:20:01 GMT""}]","2020-12-02"
"2012.00311","Gyula Pap","Gyula Pap, J\'ozsef Varny\'u","Synchronized Traveling Salesman Problem",,,,,"cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a variation of the well-known traveling salesman problem in which
there are multiple agents who all have to tour the whole set of nodes of the
same graph, while obeying node- and edge-capacity constraints require that
agents must not ""crash"". We consider the simplest model in which the input is
an undirected graph with all capacities equal to one. A solution to the
synchronized traveling salesman problem is called an ""agency"". Our model puts
the synchronized traveling salesman problem in a similar relation with the
traveling salesman problem as the so-called evacuation problem, or the
well-known dynamic flow (flow-over-time) problem is in relation with the
minimum cost flow problem.
  We measure the strength of an agency in terms of number of agents which
should be as large as possible, and the time horizon which should be as small
as possible. Beside some elementary discussion of the notions introduced, we
establish several upper and lower bounds for the strength of an agency under
the assumption that the input graph is a tree, or a 3-connected 3-regular
graph.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:20:17 GMT""}]","2020-12-02"
"2012.00312","Konstantin Zloshchastiev","Konstantin G. Zloshchastiev","Density operator approach to turbulent flows in plasma and atmospheric
  fluids","17 pages, selected paper from the 17th Russian Gravitational
  Conference - International Conference on Gravitation, Cosmology and
  Astrophysics (RUSGRAV-17), Saint Petersburg, 28 June - 4 July 2020","Universe 6, 216 (2020)","10.3390/universe6110216",,"physics.plasm-ph cond-mat.stat-mech physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  We formulate a statistical wave-mechanical approach to describe dissipation
and instabilities in two-dimensional turbulent flows of magnetized plasmas and
atmospheric fluids, such as drift and Rossby waves. This is made possible by
the existence of Hilbert space, associated with the electric potential of
plasma or stream function of atmospheric fluid. We therefore regard such
turbulent flows as macroscopic wave-mechanical phenomena, driven by the
non-Hermitian Hamiltonian operator we derive, whose anti-Hermitian component is
attributed to an effect of the environment. Introducing a wave-mechanical
density operator for the statistical ensembles of waves, we formulate master
equations and define observables: such as the enstrophy and energy of both the
waves and zonal flow as statistical averages. We establish that our open system
can generally follow two types of time evolution, depending on whether the
environment hinders or assists the system's stability and integrity. We also
consider a phase-space formulation of the theory, including the
geometrical-optic limit and beyond, and study the conservation laws of physical
observables. It is thus shown that the approach predicts various mechanisms of
energy and enstrophy exchange between drift waves and zonal flow, which were
hitherto overlooked in models based on wave kinetic equations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:24:06 GMT""}]","2020-12-02"
"2012.00313","Mengqi Guo","Mengqi Guo, Yutong Bai, Zhishuai Zhang, Adam Kortylewski, Alan Yuille","Unsupervised Part Discovery via Feature Alignment","10 pages, 9 figures, submitted to CVPR 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Understanding objects in terms of their individual parts is important,
because it enables a precise understanding of the objects' geometrical
structure, and enhances object recognition when the object is seen in a novel
pose or under partial occlusion. However, the manual annotation of parts in
large scale datasets is time consuming and expensive. In this paper, we aim at
discovering object parts in an unsupervised manner, i.e., without ground-truth
part or keypoint annotations. Our approach builds on the intuition that objects
of the same class in a similar pose should have their parts aligned at similar
spatial locations. We exploit the property that neural network features are
largely invariant to nuisance variables and the main remaining source of
variations between images of the same object category is the object pose.
Specifically, given a training image, we find a set of similar images that show
instances of the same object category in the same pose, through an affine
alignment of their corresponding feature maps. The average of the aligned
feature maps serves as pseudo ground-truth annotation for a supervised training
of the deep network backbone. During inference, part detection is simple and
fast, without any extra modules or overheads other than a feed-forward neural
network. Our experiments on several datasets from different domains verify the
effectiveness of the proposed method. For example, we achieve 37.8 mAP on
VehiclePart, which is at least 4.2 better than previous methods.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:25:00 GMT""}]","2020-12-02"
"2012.00314","Sanae Amani","Sanae Amani, Christos Thrampoulidis","Decentralized Multi-Agent Linear Bandits with Safety Constraints",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study decentralized stochastic linear bandits, where a network of $N$
agents acts cooperatively to efficiently solve a linear bandit-optimization
problem over a $d$-dimensional space. For this problem, we propose DLUCB: a
fully decentralized algorithm that minimizes the cumulative regret over the
entire network. At each round of the algorithm each agent chooses its actions
following an upper confidence bound (UCB) strategy and agents share information
with their immediate neighbors through a carefully designed consensus procedure
that repeats over cycles. Our analysis adjusts the duration of these
communication cycles ensuring near-optimal regret performance
$\mathcal{O}(d\log{NT}\sqrt{NT})$ at a communication rate of
$\mathcal{O}(dN^2)$ per round. The structure of the network affects the regret
performance via a small additive term - coined the regret of delay - that
depends on the spectral gap of the underlying graph. Notably, our results apply
to arbitrary network topologies without a requirement for a dedicated agent
acting as a server. In consideration of situations with high communication
cost, we propose RC-DLUCB: a modification of DLUCB with rare communication
among agents. The new algorithm trades off regret performance for a
significantly reduced total communication cost of $\mathcal{O}(d^3N^{2.5})$
over all $T$ rounds. Finally, we show that our ideas extend naturally to the
emerging, albeit more challenging, setting of safe bandits. For the recently
studied problem of linear bandits with unknown linear safety constraints, we
propose the first safe decentralized algorithm. Our study contributes towards
applying bandit techniques in safety-critical distributed systems that
repeatedly deal with unknown stochastic environments. We present numerical
simulations for various network topologies that corroborate our theoretical
findings.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:33:00 GMT""}]","2020-12-02"
"2012.00315","Jonathan Harris","Jonathan J. Harris (1) and George A. Pantelopulos (1) and John E.
  Straub (1) ((1) Boston University)","Finite-size effects and optimal system sizes in simulations of
  surfactant micelle self-assembly","19 pages, 5 figures, 2 tables, Corresponding Author: John E. Straub",,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spontaneous formation of micelles in aqueous solutions is governed by the
amphipathic nature of surfactants and is practically interesting due to the
regular use of micelles as membrane mimics, for the characterization of protein
structure, and for drug design and delivery. We performed a systematic
characterization of the finite-size effect observed in single-component
dodecylphosphocholine (DPC) micelles with the coarse-grained MARTINI model. Of
multiple coarse-grained solvent models investigated using large system sizes,
the non-polarizable solvent model was found to most-accurately reproduce SANS
spectra of 100 mM DPC in aqueous solution. We systematically investigated the
finite-size effect at constant 100 mM concentration in 23 systems of sizes 40
to 150 DPC, confirming the finite-size effect to manifest as an oscillation in
the mean micelle aggregation number about the thermodynamic aggregation number
as the system size increases, mostly diminishing once the system supports
formation of three micelles. The accuracy of employing a multiscale simulation
approach to avoid finite-size effects in the micelle size distribution and SANS
spectra using MARTINI and CHARMM36 was explored using multiple long timescale
500-DPC coarse-grained simulations which were back-mapped to CHARMM36 all-atom
systems. It was found that the MARTINI model generally occupies more volume
than the all-atom model, leading to the formation of micelles that are of a
reasonable radius of gyration, but are smaller in aggregation number. The
systematic characterization of the finite-size effect and exploration of
multiscale modeling presented in this work provides guidance for the accurate
modeling of micelles in simulations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:35:36 GMT""}]","2020-12-02"
"2012.00316","Jiaxin Guo","Jiaxin Guo, Lian Fu, Mingkai Jia, Kaijun Wang, Shan Liu","Fast and Robust Bin-picking System for Densely Piled Industrial Objects",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Objects grasping, also known as the bin-picking, is one of the most common
tasks faced by industrial robots. While much work has been done in related
topics, grasping randomly piled objects still remains a challenge because much
of the existing work either lack robustness or costs too much resource. In this
paper, we develop a fast and robust bin-picking system for grasping densely
piled objects adaptively and safely. The proposed system starts with point
cloud segmentation using improved density-based spatial clustering of
application with noise (DBSCAN) algorithm, which is improved by combining the
region growing algorithm and using Octree to speed up the calculation. The
system then uses principle component analysis (PCA) for coarse registration and
iterative closest point (ICP) for fine registration. We propose a grasp risk
score (GRS) to evaluate each object by the collision probability, the stability
of the object, and the whole pile's stability. Through real tests with the Anno
robot, our method is verified to be advanced in speed and robustness.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:36:41 GMT""},{""version"":""v2"",""created"":""Fri, 4 Dec 2020 08:48:23 GMT""}]","2020-12-07"
"2012.00317","Youngwan Lee","Youngwan Lee, Hyung-Il Kim, Kimin Yun, Jinyoung Moon","Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization
  for Efficient Video Classification",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video classification researches that have recently attracted attention are
the fields of temporal modeling and 3D efficient architecture. However, the
temporal modeling methods are not efficient or the 3D efficient architecture is
less interested in temporal modeling. For bridging the gap between them, we
propose an efficient temporal modeling 3D architecture, called VoV3D, that
consists of a temporal one-shot aggregation (T-OSA) module and depthwise
factorized component, D(2+1)D. The T-OSA is devised to build a feature
hierarchy by aggregating temporal features with different temporal receptive
fields. Stacking this T-OSA enables the network itself to model short-range as
well as long-range temporal relationships across frames without any external
modules. Inspired by kernel factorization and channel factorization, we also
design a depthwise spatiotemporal factorization module, named, D(2+1)D that
decomposes a 3D depthwise convolution into two spatial and temporal depthwise
convolutions for making our network more lightweight and efficient. By using
the proposed temporal modeling method (T-OSA), and the efficient factorized
component (D(2+1)D), we construct two types of VoV3D networks, VoV3D-M and
VoV3D-L. Thanks to its efficiency and effectiveness of temporal modeling,
VoV3D-L has 6x fewer model parameters and 16x less computation, surpassing a
state-of-the-art temporal modeling method on both Something-Something and
Kinetics-400. Furthermore, VoV3D shows better temporal modeling ability than a
state-of-the-art efficient 3D architecture, X3D having comparable model
capacity. We hope that VoV3D can serve as a baseline for efficient video
classification.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:40:06 GMT""},{""version"":""v2"",""created"":""Mon, 28 Dec 2020 06:21:50 GMT""},{""version"":""v3"",""created"":""Thu, 22 Apr 2021 01:40:41 GMT""}]","2021-04-23"
"2012.00318","Mingbao Lin","Mingbao Lin, Rongrong Ji, Xiaoshuai Sun, Baochang Zhang, Feiyue Huang,
  Yonghong Tian, Dacheng Tao","Fast Class-wise Updating for Online Hashing","Accepted by IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI)",,,,"cs.CV cs.IR","http://creativecommons.org/licenses/by/4.0/","  Online image hashing has received increasing research attention recently,
which processes large-scale data in a streaming fashion to update the hash
functions on-the-fly. To this end, most existing works exploit this problem
under a supervised setting, i.e., using class labels to boost the hashing
performance, which suffers from the defects in both adaptivity and efficiency:
First, large amounts of training batches are required to learn up-to-date hash
functions, which leads to poor online adaptivity. Second, the training is
time-consuming, which contradicts with the core need of online learning. In
this paper, a novel supervised online hashing scheme, termed Fast Class-wise
Updating for Online Hashing (FCOH), is proposed to address the above two
challenges by introducing a novel and efficient inner product operation. To
achieve fast online adaptivity, a class-wise updating method is developed to
decompose the binary code learning and alternatively renew the hash functions
in a class-wise fashion, which well addresses the burden on large amounts of
training batches. Quantitatively, such a decomposition further leads to at
least 75% storage saving. To further achieve online efficiency, we propose a
semi-relaxation optimization, which accelerates the online training by treating
different binary constraints independently. Without additional constraints and
variables, the time complexity is significantly reduced. Such a scheme is also
quantitatively shown to well preserve past information during updating hashing
functions. We have quantitatively demonstrated that the collective effort of
class-wise updating and semi-relaxation optimization provides a superior
performance comparing to various state-of-the-art methods, which is verified
through extensive experiments on three widely-used datasets.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:41:54 GMT""}]","2020-12-02"
"2012.00319","Sota Sato","Sota Sato, Masaki Waga, and Ichiro Hasuo","Constrained Optimization for Hybrid System Falsification and Application
  to Conjunctive Synthesis",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The synthesis problem of a cyber-physical system (CPS) is to find an input
signal under which the system's behavior satisfies a given specification. Our
setting is that the specification is a formula of signal temporal logic, and
furthermore, that the specification is a conjunction of different and often
conflicting requirements. Conjunctive specifications are often challenging for
optimization-based falsification -- an established method for CPS analysis that
can also be used for synthesis -- since the usual framework (especially how its
robust semantics handles Boolean connectives) is not suited for finding
delicate trade-offs between different requirements. Our proposed method
consists of the combination of optimization-based falsification and constrained
optimization. Specifically, we show that the state-of-the-art multiple
constraint ranking method can be combined with falsification powered by CMA-ES
optimization; its performance advantage is demonstrated in experiments.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:48:54 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 01:09:44 GMT""}]","2021-02-11"
"2012.00320","Chen Wu","Zening Yan, Chen Wu and Wenjun Guo","Scalar field quasinormal modes of noncommutative high dimensional
  Schwarzschild-Tangherlini black hole spacetime with smeared matter sources","26 pages, 11 figures, to be appeared in Nucl. phys. B",,"10.1016/j.nuclphysb.2020.115217",,"gr-qc nucl-th","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We investigate the massless scalar quasinormal modes (QNMs) of the
noncommutative $D$-dimensional Schwarzschild-Tangherlini black hole spacetime
in this paper. By using the Wentzel-Kramers-Brillouin (WKB) approximation
method, the asymptotic iterative method (AIM) and the inverted potential method
(IPM) method, we made a detail analysis of the massless scalar QNM frequencies
by varying the general smeared matter distribution and the allowable
characteristic parameters ($k$ and $\theta$) corresponding to different
dimensions. It is found that the nonconvergence of the high order WKB
approximation exists in the QNMs frequencies of scalar perturbation around the
noncommutative $D$-dimensional Schwarzschild black holes. We conclude that the
3rd WKB result should be more reliable than those of the high order WKB method
since our numerical results are also verified by the AIM method and the IPM
method. In the dimensional range of $4\leq D \leq7$, the scalar QNMs as a
function of the different papameters (the noncommutative parameter $\theta$,
the smeared matter distribution parameter $k$, the multipole number $l$ and the
main node number $n$) are obtained. Moreover, we study the dynamical evolution
of a scalar field in the background of the noncommutative high dimensional
Schwarzschild-Tangherlini black hole.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:52:36 GMT""}]","2020-12-02"
"2012.00321","Buru Chang","Youngkyu Hong, Seungju Han, Kwanghee Choi, Seokjun Seo, Beomsu Kim,
  Buru Chang","Disentangling Label Distribution for Long-tailed Visual Recognition","CVPR 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The current evaluation protocol of long-tailed visual recognition trains the
classification model on the long-tailed source label distribution and evaluates
its performance on the uniform target label distribution. Such protocol has
questionable practicality since the target may also be long-tailed. Therefore,
we formulate long-tailed visual recognition as a label shift problem where the
target and source label distributions are different. One of the significant
hurdles in dealing with the label shift problem is the entanglement between the
source label distribution and the model prediction. In this paper, we focus on
disentangling the source label distribution from the model prediction. We first
introduce a simple but overlooked baseline method that matches the target label
distribution by post-processing the model prediction trained by the
cross-entropy loss and the Softmax function. Although this method surpasses
state-of-the-art methods on benchmark datasets, it can be further improved by
directly disentangling the source label distribution from the model prediction
in the training phase. Thus, we propose a novel method, LAbel distribution
DisEntangling (LADE) loss based on the optimal bound of Donsker-Varadhan
representation. LADE achieves state-of-the-art performance on benchmark
datasets such as CIFAR-100-LT, Places-LT, ImageNet-LT, and iNaturalist 2018.
Moreover, LADE outperforms existing methods on various shifted target label
distributions, showing the general adaptability of our proposed method.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:56:53 GMT""},{""version"":""v2"",""created"":""Sat, 20 Mar 2021 15:22:19 GMT""}]","2021-03-23"
"2012.00322","Kushagra Aggarwal","Kushagra Aggarwal, Andrea Hofmann, Daniel Jirovec, Ivan Prieto, Amir
  Sammak, Marc Botifoll, Sara Marti-Sanchez, Menno Veldhorst, Jordi Arbiol,
  Giordano Scappucci, Jeroen Danon and Georgios Katsaros","Enhancement of Proximity Induced Superconductivity in a Planar Ge Hole
  Gas",,"Phys. Rev. Research 3, 022005 (2021)","10.1103/PhysRevResearch.3.L022005",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hole gases in planar germanium can have high mobilities in combination with
strong spin-orbit interaction and electrically tunable g-factors, and are
therefore emerging as a promising platform for creating hybrid
superconductor-semiconductor devices. A key challenge towards hybrid Ge-based
quantum technologies is the design of high-quality interfaces and
superconducting contacts that are robust against magnetic fields. In this work,
by combining the assets of aluminum, which provides good contact to the Ge, and
niobium, which has a significant superconducting gap, we demonstrate highly
transparent low-disordered JoFETs with relatively large \IcRn \ products that
are capable of withstanding high magnetic fields. We furthermore demonstrate
the ability of phase-biasing individual JoFETs, opening up an avenue to explore
topological superconductivity in planar Ge. The persistence of
superconductivity in the reported hybrid devices beyond 1.8 Tesla paves the way
towards integrating spin qubits and proximity-induced superconductivity on the
same chip.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:56:55 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 11:35:28 GMT""}]","2021-04-21"
"2012.00323","Prithvi Kantan","Prithvi Kantan, Erika G. Spaich, Sofia Dahl","A Technical Framework for Musical Biofeedback in Stroke Rehabilitation",,,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We here present work a generalized low-level technical framework aimed to
provide musical biofeedback in post-stroke balance and gait rehabilitation,
built by an iterative user-centered process. The framework comprises wireless
wearable inertial sensors and a software interface developed using inexpensive
and open-source tools. The interface enables layered and adjustable music
synthesis, real-time control over biofeedback parameters in several training
modes, and extensive supplementary functionality. We evaluated the system in
terms of technical performance, finding that the system has sufficiently low
loop delay (~90 ms), good sensor range (>9 m) and low computational load even
in its most demanding operation mode. In a series of expert interviews,
selected training interactions using the system were deemed by clinicians to be
meaningful and relevant to clinical protocols with comprehensible feedback
(albeit sometimes unpleasant or disturbing) for a wide patient demographic.
Future studies will focus on using this framework with real patients to both
develop the interactions further and measure their effects during therapy.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:58:15 GMT""}]","2020-12-02"
"2012.00324","Kai Zhang","Yuanyuan Lian, Lihe Wang, Kai Zhang","Pointwise Regularity for Fully Nonlinear Elliptic Equations in General
  Forms",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we develop systematically the pointwise regularity for
viscosity solutions of fully nonlinear elliptic equations in general forms. In
particular, the equations with quadratic growth (called natural growth) in the
gradient are covered. We obtain a series of interior and boundary pointwise
$C^{k,\alpha}$ regularity ($k\geq 1$ and $0<\alpha<1$). In addition, we also
derive the pointwise $C^k$ regularity ($k\geq 1$) and $C^{k,\mathrm{lnL}}$
regularity ($k\geq 0$), which correspond to the end points $\alpha=0$ and
$\alpha=1$ respectively. Some regularity results are new even for the linear
equations. Moreover, the minimum requirements are imposed to obtain above
regularity and our proofs are simple.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:59:42 GMT""}]","2020-12-02"
"2012.00325","Fotios Kasolis Dr","M. Clemens, F. Kasolis, M.-L. Henkel, B. K\""ahne, and M. G\""unther","A Two-Step Darwin Model Time Domain Formulation for Quasistatic
  Electromagnetic Field Calculations",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In the absence of wave propagation, transient electromagnetic fields are
governed by a composite scalar/vector potential formulation for the quasistatic
Darwin field model. Darwin-type field models are capable of capturing
inductive, resistive, and capacitive effects. To avoid possibly non-symmetric
and ill-conditioned fully discrete monolithic formulations, here, a Darwin
field model is presented which results in a two-step algorithm, where the
discrete representations of the electric scalar potential and the magnetic
vector potential are computed consecutively. Numerical simulations show the
validity of the presented approach.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:01:13 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 10:45:43 GMT""}]","2021-02-09"
"2012.00326","Zhaoming Wang","Run-Hong He, Rui Wang, Jing Wu, Shen-Shuang Nie, Jia-Hui Zhang and
  Zhao-Ming Wang","Deep reinforcement learning for universal quantum state preparation via
  dynamic pulse control",,"EPJ Quantum Technology 8, 29 (2021)","10.1140/epjqt/s40507-021-00119-6",,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Accurate and efficient preparation of quantum state is a core issue in
building a quantum computer. In this paper, we investigate how to prepare a
certain single- or two-qubit target state from arbitrary initial states in
semiconductor double quantum dots with the aid of deep reinforcement learning.
Our method is based on the training of the network over numerous preparing
tasks. The results show that once the network is well trained, it works for any
initial states in the continuous Hilbert space. Thus repeated training for new
preparation tasks is avoided. Our scheme outperforms the traditional
optimization approaches based on gradient with both the higher designing
efficiency and the preparation quality in discrete control space. Moreover, we
find that the control trajectories designed by our scheme are robust against
static and dynamic fluctuations, such as charge and nuclear noises.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:08:17 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 12:58:53 GMT""}]","2022-07-12"
"2012.00327","Chusei Kiumi","Chusei Kiumi","A new type of quantum walks based on decomposing quantum states","16 pages 10 figures","Quantum Information and Computation, Vol.21, No.7&8, pp541-556
  (2021)","10.26421/QIC21.7-8-1",,"math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the 2-state decomposed-type quantum walk (DQW) on a line is
introduced as an extension of the 2-state quantum walk (QW). The time evolution
of the DQW is defined with two different matrices, one is assigned to a real
component, and the other is assigned to an imaginary component of the quantum
state. Unlike the ordinary 2-state QWs, localization and the spreading
phenomenon can coincide in DQWs. Additionally, a DQW can always be converted to
the corresponding 4-state QW with identical probability measures. In other
words, a class of 4-state QWs can be realized by DQWs with 2 states. In this
work, we reveal that there is a 2-state DQW corresponding to the 4-state Grover
walk. Then, we derive the weak limit theorem of the class of DQWs corresponding
to 4-state QWs which can be regarded as the generalized Grover walks.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:09:05 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 06:38:57 GMT""}]","2021-10-11"
"2012.00328","Camille Couprie","Maxime Oquab, Pierre Stock, Oran Gafni, Daniel Haziza, Tao Xu, Peizhao
  Zhang, Onur Celebi, Yana Hasson, Patrick Labatut, Bobo Bose-Kolanu, Thibault
  Peyronel, Camille Couprie","Low Bandwidth Video-Chat Compression using Deep Generative Models","11 pages",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  To unlock video chat for hundreds of millions of people hindered by poor
connectivity or unaffordable data costs, we propose to authentically
reconstruct faces on the receiver's device using facial landmarks extracted at
the sender's side and transmitted over the network. In this context, we discuss
and evaluate the benefits and disadvantages of several deep adversarial
approaches. In particular, we explore quality and bandwidth trade-offs for
approaches based on static landmarks, dynamic landmarks or segmentation maps.
We design a mobile-compatible architecture based on the first order animation
model of Siarohin et al. In addition, we leverage SPADE blocks to refine
results in important areas such as the eyes and lips. We compress the networks
down to about 3MB, allowing models to run in real time on iPhone 8 (CPU). This
approach enables video calling at a few kbits per second, an order of magnitude
lower than currently available alternatives.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:17:00 GMT""}]","2020-12-02"
"2012.00329","Phillip Galli Dr.","P.A.B. Galli, H. Bouy, J. Olivares, N. Miret-Roig, L.M. Sarro, D.
  Barrado, A. Berihuete, E. Bertin and J.C. Cuillandre","Chamaeleon DANCe. Revisiting the stellar populations of Chamaeleon I and
  Chamaeleon II with Gaia-DR2 data","22 pages, 13 figures, online material (Tables A.1 - A.7). Accepted
  for publication in A&A","A&A 646, A46 (2021)","10.1051/0004-6361/202039395",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context: Chamaeleon is the southernmost low-mass star-forming complex within
200 pc from the Sun. Its stellar population has been extensively studied in the
past, but the current census of the stellar content is not complete yet and
deserves further investigation.
  Aims: We take advantage of the second data release of the \textit{Gaia} space
mission to expand the census of stars in Chamaeleon and to revisit the
properties of the stellar populations associated to the Chamaeleon I (Cha I)
and Chamaeleon II (Cha II) dark clouds.
  Methods: We perform a membership analysis of the sources in the \textit{Gaia}
catalogue over a field of 100 deg$^{2}$ encompassing the Chamaeleon clouds, and
use this new census of cluster members to investigate the 6D structure of the
complex.
  Results: We identify 188 and 41 high-probability members of the stellar
populations in Cha I and Cha II, respectively, including 19 and 7 new members.
Our sample covers the magnitude range from $G=6$ to $G=20$ mag in Cha I, and
from $G=12$ to $G=18$ mag in Cha II. We confirm that the northern and southern
subgroups of Cha I are located at different distances ($191.4^{+0.8}_{-0.8}$ pc
and $186.7^{+1.0}_{-1.0}$ pc), but they exhibit the same space motion within
the reported uncertainties. Cha II is located at a distance of
$197.5^{+1.0}_{-0.9}$ pc and exhibits a space motion that is consistent with
Cha I within the admittedly large uncertainties on the spatial velocities of
the stars that come from radial velocity data. The median age of the stars
derived from the Hertzsprung-Russell diagram (HRD) and stellar models is about
1-2 Myr, suggesting that they are somewhat younger than previously thought. We
do not detect significant age differences between the Chamaeleon subgroups, but
we show that Cha II exhibits a higher fraction of disc-bearing stars compared
to Cha I.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:19:09 GMT""}]","2021-02-10"
"2012.00330","Abhijit S. Mudigonda","Abhijit S. Mudigonda, R. Ryan Williams","Time-Space Lower Bounds for Simulating Proof Systems with Quantum and
  Randomized Verifiers","38 pages, 5 figures. To appear in ITCS 2021",,,,"cs.CC","http://creativecommons.org/licenses/by/4.0/","  A line of work initiated by Fortnow in 1997 has proven model-independent
time-space lower bounds for the $\mathsf{SAT}$ problem and related problems
within the polynomial-time hierarchy. For example, for the $\mathsf{SAT}$
problem, the state-of-the-art is that the problem cannot be solved by
random-access machines in $n^c$ time and $n^{o(1)}$ space simultaneously for $c
< 2\cos(\frac{\pi}{7}) \approx 1.801$.
  We extend this lower bound approach to the quantum and randomized domains.
Combining Grover's algorithm with components from $\mathsf{SAT}$ time-space
lower bounds, we show that there are problems verifiable in $O(n)$ time with
quantum Merlin-Arthur protocols that cannot be solved in $n^c$ time and
$n^{o(1)}$ space simultaneously for $c < \frac{3+\sqrt{3}}{2} \approx 2.366$, a
super-quadratic time lower bound. This result and the prior work on
$\mathsf{SAT}$ can both be viewed as consequences of a more general formula for
time lower bounds against small-space algorithms, whose asymptotics we study in
full.
  We also show lower bounds against randomized algorithms: there are problems
verifiable in $O(n)$ time with (classical) Merlin-Arthur protocols that cannot
be solved in $n^c$ randomized time and $n^{o(1)}$ space simultaneously for $c <
1.465$, improving a result of Diehl. For quantum Merlin-Arthur protocols, the
lower bound in this setting can be improved to $c < 1.5$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:25:55 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 21:49:55 GMT""}]","2021-02-01"
"2012.00331","Zhengshuo Li","Guangrui Wang and Zhengshuo Li","Enhanced Sufficient Battery Model for Aggregate Flexibility of
  Thermostatically Controlled Loads Considering Coupling Constraints","3 pages, 2 figures containing 4 subfigures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This letter proposes an enhanced sufficient battery model (ESBM) as well as a
binary search algorithm for a sharp inner-approximation of the aggregate
flexibility of thermostatically controlled load (TCL) arrays. Compared with the
previous work on generalized battery models, this ESBM preserves the merits of
being sufficient and mitigates the conservativity. Moreover, unlike the work
ignoring the coupling constraints that may also restrict TCLs' aggregate
flexibility, our ESBM can readily handle these constraints. Numerical tests
validate the merits of using the ESBM and its significance for power system
operations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:33:51 GMT""}]","2020-12-02"
"2012.00332","Sedrick Scott Keh","Sedrick Scott Keh","Semi-Supervised Noisy Student Pre-training on EfficientNet Architectures
  for Plant Pathology Classification",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  In recent years, deep learning has vastly improved the identification and
diagnosis of various diseases in plants. In this report, we investigate the
problem of pathology classification using images of a single leaf. We explore
the use of standard benchmark models such as VGG16, ResNet101, and DenseNet 161
to achieve a 0.945 score on the task. Furthermore, we explore the use of the
newer EfficientNet model, improving the accuracy to 0.962. Finally, we
introduce the state-of-the-art idea of semi-supervised Noisy Student training
to the EfficientNet, resulting in significant improvements in both accuracy and
convergence rate. The final ensembled Noisy Student model performs very well on
the task, achieving a test score of 0.982.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:34:03 GMT""}]","2020-12-02"
"2012.00333","Sachin Thukral","Sachin Thukral, Suyash Sangwan, Arnab Chatterjee, Lipika Dey","Identifying pandemic-related stress factors from social-media posts --
  effects on students and young-adults","10 pages, 5 figures",,,,"cs.SI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The COVID-19 pandemic has thrown natural life out of gear across the globe.
Strict measures are deployed to curb the spread of the virus that is causing
it, and the most effective of them have been social isolation. This has led to
wide-spread gloom and depression across society but more so among the young and
the elderly. There are currently more than 200 million college students in 186
countries worldwide, affected due to the pandemic. The mode of education has
changed suddenly, with the rapid adaptation of e-learning, whereby teaching is
undertaken remotely and on digital platforms. This study presents insights
gathered from social media posts that were posted by students and young adults
during the COVID times. Using statistical and NLP techniques, we analyzed the
behavioral issues reported by users themselves in their posts in
depression-related communities on Reddit. We present methodologies to
systematically analyze content using linguistic techniques to find out the
stress-inducing factors. Online education, losing jobs, isolation from friends,
and abusive families emerge as key stress factors.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:42:27 GMT""}]","2020-12-02"
"2012.00334","Jakub Rondo\v{s}","Jakub Rondo\v{s}","On the Banach-Mazur distance between continuous function spaces with
  scattered boundaries",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dependence of the Banach-Mazur distance between two subspaces of
vector-valued continuous functions on the scattered structure of their
boundaries. In the spirit of a result of Gordon, we show that the constant $2$
appearing in the Amir-Cambern theorem may be replaced by $3$ for some class of
subspaces. This we achieve by showing that the Banach-Mazur distance of two
function spaces is at least 3, if the height of the set of weak peak points of
one of the spaces is larger than the height of a closed boundary of the second
space. Next we show that this estimate can be improved, if the considered
heights are finite and significantly different. As a corollary, we obtain new
results even for the case of $\mathcal{C}(K, E)$ spaces.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:42:58 GMT""}]","2020-12-02"
"2012.00335","Suhas A. Kowshik","Suhas A. Kowshik, Sumukha Sridhar, N. C. W. Treleaven","Towards reduced order models of small-scale acoustically significant
  components in gas turbine combustion chambers","We had to add some additional parts of further research, It might
  take a while to do it. So we are withdrawing the research paper",,,"GT2021-59601","physics.flu-dyn physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Gas turbine combustion chambers contain numerous smallscale features that
help to dampen acoustic waves and alter the acoustic mode shapes. This damping
helps to alleviate problems such as thermoacoustic instabilities. During
computational fluid dynamics simulations (CFD) of combustion chambers, these
small-scale features are often neglected as the corresponding increase in the
mesh cell count augments significantly the cost of simulation while the small
physical size of these cells can present problems for the stability of the
solver. In problems where acoustics are prevalent and critical to the validity
of the simulation, the neglected small-scale features and the associated
reduction in overall acoustic damping can cause problems with spurious,
nonphysical noise and prevents accurate simulation of transients and limit
cycle oscillations. Low-order dynamical systems (LODS) and artificial neural
networks (ANNs) are proposed and tested in their ability to represent a simple
two-dimensional acoustically forced simulation of an orifice at multiple
frequencies. These models were built using compressible CFD, using OpenFOAM, of
an orifice placed between two ducts. The acoustic impedance of the orifice has
been computed using the multi-microphone method and compared to a commonly used
analytical model. Following this, the flow field downstream of the orifice has
been modelled using both a LODS and ANN model. Both methods have shown the
ability to closely represent the simulated dynamical flows at much lower
computational cost than the original CFD simulation. Such models may also
assist in the accurate simulation of flame quenching due to cooling flows or
the design of effusion cooled aerodynamic surfaces such as nozzle guide vanes
(NGVs) and turbine blades.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:43:16 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 08:50:28 GMT""}]","2020-12-04"
"2012.00336","Hannes Hagmar","Hannes Hagmar, Robert Eriksson, Le Anh Tuan","Comparison of security margin estimation methods under various load
  configurations","8 pages",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  The post-contingency loadability limit (PCLL) and the secure operating limit
(SOL) are the two main approaches used in computing the security margins of an
electric power system. While the SOL is significantly more computationally
demanding than the PCLL, it can account for the dynamic response after a
disturbance and generally provides a better measure of the security margin. In
this study, the difference between these two methods is compared and analyzed
for a range of different contingency and load model scenarios. A methodology to
allow a fair comparison between the two security margins is developed and
tested on a modified version of the Nordic32 test system. The study shows that
the SOL can differ significantly from the PCLL, especially when the system has
a high penetration of loads with constant power characteristics, or a large
share of induction motor loads with fast load restoration. The difference
between the methods is also tested for different contingencies, where longer
fault clearing times are shown to significantly increase the difference between
the two margins.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:43:31 GMT""}]","2020-12-02"
"2012.00337","Bidisha Sharma","Bidisha Sharma, Xiaoxue Gao, Karthika Vijayan, Xiaohai Tian, Haizhou
  Li","NHSS: A Speech and Singing Parallel Database","Accepted to Speech Communication",,,,"cs.SD cs.HC eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a database of parallel recordings of speech and singing, collected
and released by the Human Language Technology (HLT) laboratory at the National
University of Singapore (NUS), that is called NUS-HLT Speak-Sing (NHSS)
database. We release this database to the public to support research
activities, that include, but not limited to comparative studies of acoustic
attributes of speech and singing signals, cooperative synthesis of speech and
singing voices, and speech-to-singing conversion. This database consists of
recordings of sung vocals of English pop songs, the spoken counterpart of
lyrics of the songs read by the singers in their natural reading manner, and
manually prepared utterance-level and word-level annotations. The audio
recordings in the NHSS database correspond to 100 songs sung and spoken by 10
singers, resulting in a total of 7 hours of audio data. There are 5 male and 5
female singers, singing and reading the lyrics of 10 songs each. In this paper,
we discuss the design methodology of the database, analyse the similarities and
dissimilarities in characteristics of speech and singing voices, and provide
some strategies to address relationships between these characteristics for
converting one to another. We develop benchmark systems, which can be used as
reference for speech-to-singing alignment, spectral mapping, and conversion
using the NHSS database.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:44:37 GMT""},{""version"":""v2"",""created"":""Thu, 5 Aug 2021 11:32:32 GMT""}]","2021-08-06"
"2012.00338","Gabriele Santin","Bernard Haasdonk and Boumediene Hamzi and Gabriele Santin and Dominik
  Wittwar","Kernel methods for center manifold approximation and a data-based
  version of the Center Manifold Theorem",,,"10.1016/j.physd.2021.133007",,"math.NA cs.LG cs.NA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For dynamical systems with a non hyperbolic equilibrium, it is possible to
significantly simplify the study of stability by means of the center manifold
theory. This theory allows to isolate the complicated asymptotic behavior of
the system close to the equilibrium point and to obtain meaningful predictions
of its behavior by analyzing a reduced order system on the so-called center
manifold.
  Since the center manifold is usually not known, good approximation methods
are important as the center manifold theorem states that the stability
properties of the origin of the reduced order system are the same as those of
the origin of the full order system.
  In this work, we establish a data-based version of the center manifold
theorem that works by considering an approximation in place of an exact
manifold. Also the error between the approximated and the original reduced
dynamics are quantified.
  We then use an apposite data-based kernel method to construct a suitable
approximation of the manifold close to the equilibrium, which is compatible
with our general error theory. The data are collected by repeated numerical
simulation of the full system by means of a high-accuracy solver, which
generates sets of discrete trajectories that are then used as a training set.
The method is tested on different examples which show promising performance and
good accuracy.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:45:51 GMT""}]","2021-09-22"
"2012.00339","Ahmed M. A. Sayed","Ahmed M. Abdelmoniem and Brahim Bensaou","Design and Implementation of Fair Congestion Control for Data Centers
  Networks",,,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  In data centers, the nature of the composite bursty traffic along with the
small bandwidth-delay product and switch buffers lead to several congestion
problems that are not handled well by traditional congestion control mechanisms
such as TCP. Existing work try to address the problem by modifying TCP to suit
the operational nature of data centers. This is practically feasible in private
settings, however, in public environments, such modifications are prohibited.
Therefore, in this work, we design simple switch-based queue management to deal
with such congestion issues adequately. This approach entails no modification
to the TCP sender and receiver algorithms which enables easy and seamless
deployment in public data centers. We present a theoretical analysis to show
the stability and effectiveness of the scheme. We also present, three different
real implementations (as a Linux kernel module and as an added feature to
OpenvSwitch) and give numerical results from both NS-2 simulation and
experiments of real deployment in a small test-bed cluster to show its
effectiveness in achieving high throughput overall, a good fairness and short
flow completion times for delay-sensitive flows.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:46:24 GMT""}]","2020-12-02"
"2012.00340","Ryotaro Harada","Yen-Tsung Chen, Ryotaro Harada","On lower bounds of the dimensions of multizeta values in positive
  characteristic","18 pages","Doc. Math. (26), 537-559 (2021)","10.25537/dm.2021v26.537-559",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the linear independence of special values, including
the positive characteristic analogue of multizeta values, alternating multizeta
values and multiple polylogarithms, at algebraic points. Consequently, we
establish linearly independent sets of these values with the same weight
indices and a lower bound on the dimension of the space generated by depth r >
2 multizeta values of the same weight in positive characteristic.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:49:34 GMT""}]","2022-07-12"
"2012.00341","Aparna Upadhyay","Aparna Upadhyay","The Benson-Symonds Invariant for Permutation Modules","18 pages",,,,"math.RT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a recent paper, Dave Benson and Peter Symonds defined a new invariant
$\gamma_G(M)$ for a finite dimensional module $M$ of a finite group $G$ which
attempts to quantify how close a module is to being projective. In this paper,
we determine this invariant for permutation modules of the symmetric group
corresponding to two-part partitions using tools from representation theory and
combinatorics.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:49:35 GMT""}]","2020-12-02"
"2012.00342","Chunying Wang","Chunying Wang, Cong Wang, Yu Lana, and Wenwu Caod","Dependence of functional mechanism of matching layer on excitation
  signal type for ultrasonic transducers-2",,,,,"physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Acoustic matching layers are widely employed in high-frequency transducers
which are excited by different signal types depending on applications. In this
study, a theoretical method has been proposed to investigate the dependence of
functional mechanism of matching layer on excitation signal types, i.e., short
pulse and long pulse. The results indicate that the matching layer acts as a
bandpass frequency filter under the two excitation signal types. In the short
pulse excitation case, the matching layer can improve bandwidth and
transmitting voltage response simultaneously, whereas for the case of long
pulse excitation, the increased bandwidth is at the expense of transmitting
voltage response. To verify our theoretical results, underwater acoustic
transducers with and without matching layer were fabricated and tested. The
thickness design principle of matching layer was modified due to the
frequency-dependent acoustic radiation impedance. The experimental results
verified the theoretical prediction. Our results provide a deep insight into
the fundamental principle of matching layer design according to practical
applications.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:55:30 GMT""}]","2020-12-02"
"2012.00343","Song Guo","S. Guo, C. M. Petrache","Comment on ""First Observation of Multiple Transverse Wobbling Bands of
  Different Kinds in $^{183}$Au [Phys. Rev. Lett. 125, 132501 (2015)]""",,,,,"nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In [S. Nandi et al., Phys. Rev. Lett. 125, 132501 (2020)] two transverse
wobbling bands were reported in $^{183}$Au. The critical experimental proof for
this assignment is the E2 dominated linking transitions between the wobbling
and normal bands, which are supported by fitting the measured DCO ratio and
polarization results. However, the uncertainties are significantly
underestimated according to an analysis on the statistical error. With
reasonable error, the mixing ratios cannot be exclusively decided, and the M1
dominated character cannot be excluded, indicating that the wobbling assignment
is still questionable.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:56:51 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 02:44:33 GMT""}]","2020-12-10"
"2012.00344","Xiaoguang Ma","Fang Yuan, Xiaoguang Ma, Yu Wu, and Chuanlu Yang","Average Doppler Shift of Gamma-ray Spectra of Positron Annihilation
  Process in Molecules",,,,,"physics.atm-clus","http://creativecommons.org/licenses/by/4.0/","  This paper studies the gamma-ray spectra of positron annihilation processes
in a series of molecules. The results show that the average valence electron
energy of the molecules has a linear correlation with the full width at half
maximum (FWHM) of the gamma-ray spectra. In addition, we defined a new physical
quantity Average Doppler Shift (ADS), which can be used as the eigenvalue to
describe the characteristics of the gamma-ray spectra. Since ADS contains all
the information about the gamma-ray spectra, it can more accurately represent
the characteristics of the gamma-ray spectra. For a series of molecules, this
paper compares the ADS and FWHM of their gamma-ray spectra and the average
valence electron energy. The results show that ADS has a linear correlation
with the average valence electron energy and the FWHM. Further, this proves
that the annihilation mainly occurs on valence electrons, and it also
illustrates that the ADS has certain applicability. It is expected that this
will provide us with a deeper understanding of the positron annihilation
process.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:57:54 GMT""}]","2020-12-02"
"2012.00345","Xuedong He","Xue Dong He and Zhaoli Jiang","Optimal Payoff under the Generalized Dual Theory of Choice","arXiv admin note: substantial text overlap with arXiv:2008.10257",,,,"q-fin.MF","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We consider portfolio optimization under a preference model in a
single-period, complete market. This preference model includes Yaari's dual
theory of choice and quantile maximization as special cases. We characterize
when the optimal solution exists and derive the optimal solution in closed form
when it exists. The payoff of the optimal portfolio is a digital option: it
yields an in-the-money payoff when the market is good and zero payoff
otherwise. When the initial wealth increases, the set of good market scenarios
remains unchanged while the payoff in these scenarios increases. Finally, we
extend our portfolio optimization problem by imposing a dependence structure
with a given benchmark payoff and derive similar results.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:04:02 GMT""}]","2020-12-02"
"2012.00346","St\'ephane Lathuili\`ere","Goluck Konuko, Giuseppe Valenzise, St\'ephane Lathuili\`ere","Ultra-low bitrate video conferencing using deep image animation","5 pages",,,,"cs.CV cs.MM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this work we propose a novel deep learning approach for ultra-low bitrate
video compression for video conferencing applications. To address the
shortcomings of current video compression paradigms when the available
bandwidth is extremely limited, we adopt a model-based approach that employs
deep neural networks to encode motion information as keypoint displacement and
reconstruct the video signal at the decoder side. The overall system is trained
in an end-to-end fashion minimizing a reconstruction error on the encoder
output. Objective and subjective quality evaluation experiments demonstrate
that the proposed approach provides an average bitrate reduction for the same
visual quality of more than 80% compared to HEVC.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:06:34 GMT""}]","2020-12-02"
"2012.00347","Wenqiang Yi","Wenqiang Yi, Yuanwei Liu, and Arumugam Nallanathan","Signal Fractions Analysis and Safety-Distance Modeling in V2V Inter-lane
  Communications",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For vehicular networks, safety distances are important, but existing spatial
models fail to characterize this parameter, especially for inter-lane
communications. This work proposes a Matern hard-core processes based framework
to appraise the performance of signal fractions (SF), where the hard-core
distance is used to depict safety distances. By considering both semicircle and
omnidirectional antennas, we derive high-accurate closed-form probability
density functions of communication distances to acquire the complementary
cumulative distribution function of SF. The derived expressions theoretically
demonstrate that the nearest vehicle within the safety distance follows a
uniform distribution and there is an upper limit for SF in terms of the
transmit power.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:09:19 GMT""}]","2020-12-02"
"2012.00348","Song-Kyoo Amang Kim Ph.D.","Song-Kyoo Kim, Chan Yeob Yeun, Paul D. Yoo, Nai-Wei Lo, Ernesto
  Damiani","Deep Learning-Based Arrhythmia Detection Using RR-Interval Framed
  Electrocardiograms","This paper is considered to be submitted to an international journal",,,,"cs.LG eess.SP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning applied to electrocardiogram (ECG) data can be used to achieve
personal authentication in biometric security applications, but it has not been
widely used to diagnose cardiovascular disorders. We developed a deep learning
model for the detection of arrhythmia in which time-sliced ECG data
representing the distance between successive R-peaks are used as the input for
a convolutional neural network (CNN). The main objective is developing the
compact deep learning based detect system which minimally uses the dataset but
delivers the confident accuracy rate of the Arrhythmia detection. This compact
system can be implemented in wearable devices or real-time monitoring equipment
because the feature extraction step is not required for complex ECG waveforms,
only the R-peak data is needed. The results of both tests indicated that the
Compact Arrhythmia Detection System (CADS) matched the performance of
conventional systems for the detection of arrhythmia in two consecutive test
runs. All features of the CADS are fully implemented and publicly available in
MATLAB.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:10:24 GMT""}]","2020-12-02"
"2012.00349","Gabriele Todeschi","Andrea Natale (RAPSODI), Gabriele Todeschi (MOKAPLAN)","Computation of Optimal Transport with Finite Volumes",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct Two-Point Flux Approximation (TPFA) finite volume schemes to
solve the quadratic optimal transport problem in its dynamic form, namely the
problem originally introduced by Benamou and Brenier. We show numerically that
these type of discretizations are prone to form instabilities in their more
natural implementation, and we propose a variation based on nested meshes in
order to overcome these issues. Despite the lack of strict convexity of the
problem, we also derive quantitative estimates on the convergence of the
method, at least for the discrete potential and the discrete cost. Finally, we
introduce a strategy based on the barrier method to solve the discrete
optimization problem.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:13:54 GMT""},{""version"":""v2"",""created"":""Fri, 8 Jan 2021 08:48:10 GMT""},{""version"":""v3"",""created"":""Mon, 30 Aug 2021 07:39:57 GMT""}]","2021-08-31"
"2012.00350","Mark T. Mitchison","Mark T. Mitchison, John Goold, and Javier Prior","Charging a quantum battery with linear feedback control","v1: 10 pages, 8 figures. Comments welcome! v2: Final version; v3:
  Fixed some broken hyperlinks in bibliography","Quantum 5, 500 (2021)","10.22331/q-2021-07-13-500",,"quant-ph cond-mat.mes-hall cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Energy storage is a basic physical process with many applications. When
considering this task at the quantum scale, it becomes important to optimise
the non-equilibrium dynamics of energy transfer to the storage device or
battery. Here, we tackle this problem using the methods of quantum feedback
control. Specifically, we study the deposition of energy into a quantum battery
via an auxiliary charger. The latter is a driven-dissipative two-level system
subjected to a homodyne measurement whose output signal is fed back linearly
into the driving field amplitude. We explore two different control strategies,
aiming to stabilise either populations or quantum coherences in the state of
the charger. In both cases, linear feedback is shown to counteract the
randomising influence of environmental noise and allow for stable and effective
battery charging. We analyse the effect of realistic control imprecisions,
demonstrating that this good performance survives inefficient measurements and
small feedback delays. Our results highlight the potential of continuous
feedback for the control of energetic quantities in the quantum regime.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:15:28 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 12:15:20 GMT""},{""version"":""v3"",""created"":""Tue, 1 Feb 2022 17:40:58 GMT""}]","2022-02-02"
"2012.00351","M\'elodie Boillet","M\'elodie Boillet, Marie-Laurence Bonhomme, Dominique Stutzmann and
  Christopher Kermorvant","HORAE: an annotated dataset of books of hours",,"HIP 5 (2019) 7-12","10.1145/3352631.3352633",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce in this paper a new dataset of annotated pages from books of
hours, a type of handwritten prayer books owned and used by rich lay people in
the late middle ages. The dataset was created for conducting historical
research on the evolution of the religious mindset in Europe at this period
since the book of hours represent one of the major sources of information
thanks both to their rich illustrations and the different types of religious
sources they contain. We first describe how the corpus was collected and
manually annotated then present the evaluation of a state-of-the-art system for
text line detection and for zone detection and typing. The corpus is freely
available for research.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:25:38 GMT""}]","2020-12-02"
"2012.00352","Kai Niklas Hansmann","Kai Niklas Hansmann and Reinhold Walser","Stochastic Simulation of Emission Spectra and Classical Photon
  Statistics of Quantum Dot Superluminescent Diodes","10 pages, 5 figures","Journal of Modern Physics, 12, 22-34 (2021)","10.4236/jmp.2021.121003",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  We present a stochastic procedure to investigate the correlation spectra of
quantum dot superluminescent diodes. The classical electric field of a diode is
formed by a polychromatic superposition of many independent stochastic
oscillators. Assuming fields with individual carrier frequencies, Lorentzian
linewidths and amplitudes we can form any relevant experimental spectrum using
a least square fit. This is illustrated for Gaussian and Lorentzian spectra,
Voigt profiles and box shapes. Eventually, the procedure is applied to an
experimental spectrum of a quantum dot superluminescent diode which determines
the first- and second-order temporal correlation functions of the emission. We
find good agreement with the experimental data and a quantized treatment. Thus,
a stochastic field represents broadband light emitted by quantum dot
superluminescent diodes.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:27:54 GMT""}]","2021-01-19"
"2012.00353","Toru Saito","Toru Saito, Toshimi Okubo, Naoki Takahashi","Robust and Accurate Object Velocity Detection by Stereo Camera for
  Autonomous Driving",,"IEEE Intelligent Vehicles Symposium, 2020",,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Although the number of camera-based sensors mounted on vehicles has recently
increased dramatically, robust and accurate object velocity detection is
difficult. Additionally, it is still common to use radar as a fusion system. We
have developed a method to accurately detect the velocity of object using a
camera, based on a large-scale dataset collected over 20 years by the
automotive manufacturer, SUBARU. The proposed method consists of three methods:
an High Dynamic Range (HDR) detection method that fuses multiple stereo
disparity images, a fusion method that combines the results of monocular and
stereo recognitions, and a new velocity calculation method. The evaluation was
carried out using measurement devices and a test course that can quantitatively
reproduce severe environment by mounting the developed stereo camera on an
actual vehicle.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:29:59 GMT""}]","2020-12-02"
"2012.00354","Erika Michela Dematteis","Erika Michela Dematteis, David Michael Dreistadt, Giovanni Capurso,
  Julian Jepsen, Fermin Cuevas, Michel Latroche","Fundamental hydrogen storage properties of TiFe-alloy with partial
  substitution of Fe by Ti and Mn","39 pages, 9 figure, 4 tables, 3 supplementary figures",,"10.1016/j.jallcom.2021.159925",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  TiFe intermetallic compound has been extensively studied, owing to its low
cost, good volumetric hydrogen density, and easy tailoring of hydrogenation
thermodynamics by elemental substitution. All these positive aspects make this
material promising for large-scale applications of solid-state hydrogen
storage. On the other hand, activation and kinetic issues should be amended and
the role of elemental substitution should be further understood. This work
investigates the thermodynamic changes induced by the variation of Ti content
along the homogeneity range of the TiFe phase (Ti:Fe ratio from 1:1 to 1:0.9)
and of the substitution of Mn for Fe between 0 and 5 at.%. In all considered
alloys, the major phase is TiFe-type together with minor amounts of TiFe2 or
\b{eta}-Ti-type and Ti4Fe2O-type at the Ti-poor and rich side of the TiFe phase
domain, respectively. Thermodynamic data agree with the available literature
but offer here a comprehensive picture of hydrogenation properties over an
extended Ti and Mn compositional range. Moreover, it is demonstrated that
Ti-rich alloys display enhanced storage capacities, as long as a limited amount
of \b{eta}-Ti is formed. Both Mn and Ti substitutions increase the cell
parameter by possibly substituting Fe, lowering the plateau pressures and
decreasing the hysteresis of the isotherms. A full picture of the dependence of
hydrogen storage properties as a function of the composition will be discussed,
together with some observed correlations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:30:02 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 07:34:57 GMT""}]","2021-04-22"
"2012.00355","Wei Chen","Wei Chen, Shang-Hua Teng, Hanrui Zhang","On the Equivalence Between High-Order Network-Influence Frameworks:
  General-Threshold, Hypergraph-Triggering, and Logic-Triggering Models",,,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study several high-order network-influence-propagation
frameworks and their connection to the classical network diffusion frameworks
such as the triggering model and the general threshold model. In one framework,
we use hyperedges to represent many-to-one influence -- the collective
influence of a group of nodes on another node -- and define the hypergraph
triggering model as a natural extension to the classical triggering model. In
another framework, we use monotone Boolean functions to capture the diverse
logic underlying many-to-one influence behaviors, and extend the triggering
model to the Boolean-function triggering model. We prove that the
Boolean-function triggering model, even with refined details of influence
logic, is equivalent to the hypergraph triggering model, and both are
equivalent to the general threshold model. Moreover, the general threshold
model is optimal in the number of parameters, among all models with the same
expressive power. We further extend these three equivalent models by
introducing correlations among influence propagations on different nodes.
Surprisingly, we discover that while the correlated hypergraph-based model is
still equivalent to the correlated Boolean-function-based model, the correlated
general threshold model is more restrictive than the two high-order models. Our
study sheds light on high-order network-influence propagations by providing new
insight into the group influence behaviors in existing models, as well as
diverse modeling tools for understanding influence propagations in networks.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:30:49 GMT""}]","2020-12-02"
"2012.00356","Lorenzo Severini","Francesco Bonchi, Lorenzo Severini, Mauro Sozio","Better Fewer but Better: Community Search with Outliers","2020 IEEE/WIC/ACM International Joint Conference on Web Intelligence
  and Intelligent Agent Technology (WI-IAT'20)",,,,"cs.DS cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a set of vertices in a network, that we believe are of interest for the
application under analysis, community search is the problem of producing a
subgraph potentially explaining the relationships existing among the vertices
of interest. In practice this means that the solution should add some vertices
to the query ones, so to create a connected subgraph that exhibits some
""cohesiveness"" property. This problem has received increasing attention in
recent years: while several cohesiveness functions have been studied, the bulk
of the literature looks for a solution subgraphs containing all the query
vertices. However, in many exploratory analyses we might only have a reasonable
belief about the vertices of interest: if only one of them is not really
related to the others, forcing the solution to include all of them might hide
the existence of much more cohesive and meaningful subgraphs, that we could
have found by allowing the solution to detect and drop the outlier vertex. In
this paper we study the problem of community search with outliers, where we are
allowed to drop up to $k$ query vertices, with $k$ being an input parameter. We
consider three of the most used measures of cohesiveness: the minimum degree,
the diameter of the subgraph and the maximum distance with a query vertex. By
optimizing one and using one of the others as a constraint we obtain three
optimization problems: we study their hardness and we propose different exact
and approximation algorithms.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:31:17 GMT""},{""version"":""v2"",""created"":""Fri, 4 Dec 2020 09:46:58 GMT""}]","2020-12-07"
"2012.00357","Robert Eggersmann","Robert Eggersmann, Laurent Stainier, Michael Ortiz, Stefanie Reese","Efficient Data Structures for Model-free Data-Driven Computational
  Mechanics",,,"10.1016/j.cma.2021.113855",,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The data-driven computing paradigm initially introduced by Kirchdoerfer and
Ortiz (2016) enables finite element computations in solid mechanics to be
performed directly from material data sets, without an explicit material model.
From a computational effort point of view, the most challenging task is the
projection of admissible states at material points onto their closest states in
the material data set. In this study, we compare and develop several possible
data structures for solving the nearest-neighbor problem. We show that
approximate nearest-neighbor (ANN) algorithms can accelerate material data
searches by several orders of magnitude relative to exact searching algorithms.
The approximations are suggested by--and adapted to--the structure of the
data-driven iterative solver and result in no significant loss of solution
accuracy. We assess the performance of the ANN algorithm with respect to
material data set size with the aid of a 3D elasticity test case. We show that
computations on a single processor with up to one billion material data points
are feasible within a few seconds execution time with a speedup of more than
106 with respect to exact k-d trees.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:32:39 GMT""}]","2021-05-19"
"2012.00358","Jeppe C. Dyre","Saeed Mehri, Trond S. Ingebrigtsen, and Jeppe C. Dyre","Single-parameter aging in a binary Lennard-Jones system",,"J. Chem. Phys. 154, 094504 (2021)","10.1063/5.0039250",,"cond-mat.soft cond-mat.mtrl-sci cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  This paper studies physical aging by computer simulations of a 2:1
Kob-Andersen binary Lennard-Jones mixture, a system that is less prone to
crystallization than the standard 4:1 composition. Starting from
thermal-equilibrium states, the time evolution of the following four quantities
is monitored following up and down jumps in temperature: the potential energy,
the virial, the average squared force, and the Laplacian of the potential
energy. Despite the fact that significantly larger temperature jumps are
studied here than in previous experiments, to a good approximation all four
quantities conform to the single-parameter-aging scenario derived and validated
for small jumps in experiments [Hecksher et al., J. Chem. Phys. 142, 241103
(2015)]. As a further confirmation of single-parameter aging with a common
material time for the different quantities monitored, their relaxing parts are
found to be almost identical for all temperature jumps.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:33:47 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 13:16:54 GMT""}]","2021-03-03"
"2012.00359","Delia Coculescu","Delia Coculescu and Aditi Dandapani","Insiders and their Free Lunches: the Role of Short Positions",,,,,"q-fin.MF","http://creativecommons.org/licenses/by/4.0/","  Given a stock price process, we analyse the potential of arbitrage by
insiders in a context of short-selling prohibitions. We introduce the notion of
minimal supermartingale measure, and we analyse its properties in connection to
the minimal martingale measure. In particular, we establish conditions when
both fail to exist. These correspond to the case when the insider's information
set includes some non null events that are perceived as having null
probabilities by the uninformed market investors. These results may have
different applications, such as in problems related to the local
risk-minimisation for insiders whenever strategies are implemented without
short selling.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:36:51 GMT""},{""version"":""v2"",""created"":""Wed, 12 Jan 2022 09:35:25 GMT""}]","2022-01-13"
"2012.00360","Aythami Morales","Alfonso Ortega and Julian Fierrez and Aythami Morales and Zilong Wang
  and Tony Ribeiro","Symbolic AI for XAI: Evaluating LFIT Inductive Programming for Fair and
  Explainable Automatic Recruitment","WACV21 Workshop on Explainable & Interpretable Artificial
  Intelligence for Biometrics (xAI4Biom)",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning methods are growing in relevance for biometrics and personal
information processing in domains such as forensics, e-health, recruitment, and
e-learning. In these domains, white-box (human-readable) explanations of
systems built on machine learning methods can become crucial. Inductive Logic
Programming (ILP) is a subfield of symbolic AI aimed to automatically learn
declarative theories about the process of data. Learning from Interpretation
Transition (LFIT) is an ILP technique that can learn a propositional logic
theory equivalent to a given black-box system (under certain conditions). The
present work takes a first step to a general methodology to incorporate
accurate declarative explanations to classic machine learning by checking the
viability of LFIT in a specific AI application scenario: fair recruitment based
on an automatic tool generated with machine learning methods for ranking
Curricula Vitae that incorporates soft biometric information (gender and
ethnicity). We show the expressiveness of LFIT for this specific problem and
propose a scheme that can be applicable to other domains.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:36:59 GMT""}]","2020-12-02"
"2012.00361","Megandhren Govender","Neeraj Pant, Megandhren Govender, Satyanarayana Gedela","A new class of viable and exact solutions of EFE's with Karmarkar
  conditions: An application to cold star modeling","14 pages, 15 figures",,"10.1088/1674-4527/21/5/109",,"gr-qc","http://creativecommons.org/publicdomain/zero/1.0/","  In this work we present a theoretical framework within Einstein's classical
general relativity which models stellar compact objects such as PSR J1614-2230
and SAX J1808.4-3658. The Einstein field equations are solved by assuming that
the interior of the compact object is described by a class I spacetime. The
so-called Karmarkar condition arising from this requirement is integrated to
reduce the gravitational behaviour to a single generating function. By
appealing to physics we adopt a form for the gravitational potential which is
sufficiently robust to accurately describe compact objects. Our model satisfies
all the requirements for physically realistic stellar structures.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:38:44 GMT""}]","2021-06-23"
"2012.00362","Ashkan Khakzar","Ashkan Khakzar, Soroosh Baselizadeh, Nassir Navab","Rethinking Positive Aggregation and Propagation of Gradients in
  Gradient-based Saliency Methods","ICML 2020 - Workshop on Human Interpretability in Machine Learning -
  Spotlight paper - Video at http://whi2020.online/poster_40.html",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Saliency methods interpret the prediction of a neural network by showing the
importance of input elements for that prediction. A popular family of saliency
methods utilize gradient information. In this work, we empirically show that
two approaches for handling the gradient information, namely positive
aggregation, and positive propagation, break these methods. Though these
methods reflect visually salient information in the input, they do not explain
the model prediction anymore as the generated saliency maps are insensitive to
the predicted output and are insensitive to model parameter randomization.
Specifically for methods that aggregate the gradients of a chosen layer such as
GradCAM++ and FullGrad, exclusively aggregating positive gradients is
detrimental. We further support this by proposing several variants of
aggregation methods with positive handling of gradient information. For methods
that backpropagate gradient information such as LRP, RectGrad, and Guided
Backpropagation, we show the destructive effect of exclusively propagating
positive gradient information.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:38:54 GMT""}]","2020-12-02"
"2012.00363","Chen Zhu","Chen Zhu, Ankit Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli,
  Daliang Li, Felix Yu, Sanjiv Kumar","Modifying Memories in Transformer Models",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large Transformer models have achieved impressive performance in many natural
language tasks. In particular, Transformer based language models have been
shown to have great capabilities in encoding factual knowledge in their vast
amount of parameters. While the tasks of improving the memorization and
generalization of Transformers have been widely studied, it is not well known
how to make transformers forget specific old facts and memorize new ones. In
this paper, we propose a new task of \emph{explicitly modifying specific
factual knowledge in Transformer models while ensuring the model performance
does not degrade on the unmodified facts}. This task is useful in many
scenarios, such as updating stale knowledge, protecting privacy, and
eliminating unintended biases stored in the models. We benchmarked several
approaches that provide natural baseline performances on this task. This leads
to the discovery of key components of a Transformer model that are especially
effective for knowledge modifications. The work also provides insights into the
role that different training phases (such as pretraining and fine-tuning) play
towards memorization and knowledge modification.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:39:13 GMT""}]","2020-12-02"
"2012.00364","Hanting Chen","Hanting Chen, Yunhe Wang, Tianyu Guo, Chang Xu, Yiping Deng, Zhenhua
  Liu, Siwei Ma, Chunjing Xu, Chao Xu, Wen Gao","Pre-Trained Image Processing Transformer","CVPR 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the computing power of modern hardware is increasing strongly, pre-trained
deep learning models (e.g., BERT, GPT-3) learned on large-scale datasets have
shown their effectiveness over conventional methods. The big progress is mainly
contributed to the representation ability of transformer and its variant
architectures. In this paper, we study the low-level computer vision task
(e.g., denoising, super-resolution and deraining) and develop a new pre-trained
model, namely, image processing transformer (IPT). To maximally excavate the
capability of transformer, we present to utilize the well-known ImageNet
benchmark for generating a large amount of corrupted image pairs. The IPT model
is trained on these images with multi-heads and multi-tails. In addition, the
contrastive learning is introduced for well adapting to different image
processing tasks. The pre-trained model can therefore efficiently employed on
desired task after fine-tuning. With only one pre-trained model, IPT
outperforms the current state-of-the-art methods on various low-level
benchmarks. Code is available at https://github.com/huawei-noah/Pretrained-IPT
and https://gitee.com/mindspore/mindspore/tree/master/model_zoo/research/cv/IPT
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:42:46 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 05:02:15 GMT""},{""version"":""v3"",""created"":""Fri, 28 May 2021 02:41:58 GMT""},{""version"":""v4"",""created"":""Mon, 8 Nov 2021 07:08:21 GMT""}]","2021-11-09"
"2012.00365","Dominik Stra{\ss}el","Dominik Strassel, Philipp Reusch and Janis Keuper","Python Workflows on HPC Systems","9 pages with 7 figures, submitted and accepted at the PyHPC Workshop
  at SuperComputing 2020",,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent successes and wide spread application of compute intensive machine
learning and data analytics methods have been boosting the usage of the Python
programming language on HPC systems. While Python provides many advantages for
the users, it has not been designed with a focus on multi-user environments or
parallel programming - making it quite challenging to maintain stable and
secure Python workflows on a HPC system. In this paper, we analyze the key
problems induced by the usage of Python on HPC clusters and sketch appropriate
workarounds for efficiently maintaining multi-user Python software
environments, securing and restricting resources of Python jobs and containing
Python processes, while focusing on Deep Learning applications running on GPU
clusters.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:51:12 GMT""}]","2020-12-02"
"2012.00366","Zhihao Fan","Zhihao Fan, Yeyun Gong, Zhongyu Wei, Siyuan Wang, Yameng Huang, Jian
  Jiao, Xuanjing Huang, Nan Duan, Ruofei Zhang","An Enhanced Knowledge Injection Model for Commonsense Generation","Accepted to COLING 2020",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Commonsense generation aims at generating plausible everyday scenario
description based on a set of provided concepts. Digging the relationship of
concepts from scratch is non-trivial, therefore, we retrieve prototypes from
external knowledge to assist the understanding of the scenario for better
description generation. We integrate two additional modules, namely position
indicator and scaling module, into the pretrained encoder-decoder model for
prototype modeling to enhance the knowledge injection procedure. We conduct
experiment on CommonGen benchmark, and experimental results show that our
method significantly improves the performance on all the metrics.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:51:23 GMT""}]","2020-12-02"
"2012.00367","Dorota Kozie{\l}-Wierzbowska","Dorota Kozie{\l}-Wierzbowska, Natalia Vale Asari, Gra\.zyna
  Stasi\'nska, Fabio R. Herpich, Marek Sikora, Natalia \.Zywucka, Arti Goyal","Identifying radio active galactic nuclei among radio-emitting galaxies","14 pages, 14 figures, submitted to ApJ",,"10.3847/1538-4357/abe308",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Basing our analysis on ROGUE I, a catalog of over 32,000 radio sources
associated with optical galaxies, we provide two diagnostics to select the
galaxies where the radio emission is due to an active galactic nucleus (AGN).
Each of these diagnostics can be applied independently. The first one, dubbed
MIRAD, compares the flux $F_{W3}$ in the $W3$ mid-infrared band of the WISE
telescope, with the radio flux at 1.4 GHz, $\Frad$. MIRAD requires no optical
spectra. The second diagnostic, dubbed DLM, relates the 4000 \AA\ break
strength, $D_{\rm n}(4000)$, with the radio luminosity per unit stellar mass.
The DLM diagram has already been used in the past, but not as standalone. For
these two diagrams, we propose simple, empirical dividing lines that result in
the same classification for the objects in common. These lines correctly
classify as radio-AGN 99.5 percent of the extended radio sources in the ROGUE~I
catalog, and as star-forming (SF) galaxies 98--99 percent of the galaxies
identified as such by their emission line ratios. Both diagrams clearly show
that radio AGNs are preferentially found among elliptical galaxies and among
galaxies hosting the most massive black holes. Most of the radio sources
classified as radio-AGNs in the MIRAD or DLM diagrams are either optically weak
AGNs or retired galaxies.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:51:40 GMT""}]","2021-04-07"
"2012.00368","Angela Andreella","Angela Andreella, Jesse Hemerik, Wouter Weeda, Livio Finos, Jelle
  Goeman","Permutation-based true discovery proportions for functional Magnetic
  Resonance Imaging cluster analysis",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a permutation-based method for testing a large collection of
hypotheses simultaneously. Our method provides lower bounds for the number of
true discoveries in any selected subset of hypotheses. These bounds are
simultaneously valid with high confidence. The methodology is particularly
useful in functional Magnetic Resonance Imaging cluster analysis, where it
provides a confidence statement on the percentage of truly activated voxels
within clusters of voxels, avoiding the well-known spatial specificity paradox.
We offer a user-friendly tool to estimate the percentage of true discoveries
for each cluster while controlling the family-wise error rate for multiple
testing and taking into account that the cluster was chosen in a data-driven
way. The method adapts to the spatial correlation structure that characterizes
functional Magnetic Resonance Imaging data, gaining power over parametric
approaches.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:51:57 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 10:22:07 GMT""},{""version"":""v3"",""created"":""Thu, 26 Jan 2023 21:27:39 GMT""}]","2023-01-30"
"2012.00369","Nikolay Nikolaev Mr","Romeo Ortega, Alexey Bobtsov and Nikolay Nikolaev","Parameter Identification with Finite-Convergence Time Alertness
  Preservation","arXiv admin note: text overlap with arXiv:1908.05125",,,,"math.ST math.DS stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this brief note we present two new parameter identifiers whose estimates
converge in finite time under weak interval excitation assumptions. The main
novelty is that, in contrast with other finite-convergence time (FCT)
estimators, our schemes preserve the FCT property when the parameters change.
The previous versions of our FCT estimators can track the parameter variations
only asymptotically. Continuous-time and discrete-time versions of the new
estimators are presented
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:52:05 GMT""}]","2020-12-02"
"2012.00370","Martin Huber","Hugo Bodory, Martin Huber, Luk\'a\v{s} Laff\'ers","Evaluating (weighted) dynamic treatment effects by double machine
  learning","arXiv admin note: text overlap with arXiv:2002.12710",,,,"econ.EM stat.ME stat.ML","http://creativecommons.org/licenses/by/4.0/","  We consider evaluating the causal effects of dynamic treatments, i.e. of
multiple treatment sequences in various periods, based on double machine
learning to control for observed, time-varying covariates in a data-driven way
under a selection-on-observables assumption. To this end, we make use of
so-called Neyman-orthogonal score functions, which imply the robustness of
treatment effect estimation to moderate (local) misspecifications of the
dynamic outcome and treatment models. This robustness property permits
approximating outcome and treatment models by double machine learning even
under high dimensional covariates and is combined with data splitting to
prevent overfitting. In addition to effect estimation for the total population,
we consider weighted estimation that permits assessing dynamic treatment
effects in specific subgroups, e.g. among those treated in the first treatment
period. We demonstrate that the estimators are asymptotically normal and
$\sqrt{n}$-consistent under specific regularity conditions and investigate
their finite sample properties in a simulation study. Finally, we apply the
methods to the Job Corps study in order to assess different sequences of
training programs under a large set of covariates.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:55:40 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 19:05:21 GMT""},{""version"":""v3"",""created"":""Fri, 8 Jan 2021 13:28:53 GMT""},{""version"":""v4"",""created"":""Tue, 16 Feb 2021 16:05:40 GMT""},{""version"":""v5"",""created"":""Sat, 19 Jun 2021 14:56:54 GMT""}]","2021-06-22"
"2012.00371","Jennifer Sheehan","J Roadnight Sheehan, David Andersson and Astrid S. de Wijn","Thermal effects and spontaneous frictional relaxation in atomically thin
  layered materials","12 pages. 10 figures","Phys. Rev. B 103, 195441 (2021)","10.1103/PhysRevB.103.195441",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We study the thermal effects on the frictional properties of atomically thin
sheets. We simulate a simple model based on the Prandtl-Tomlinson model that
reproduces the layer dependence of friction and strengthening effects seen in
AFM experiments. We investigate sliding at constant speed as well as reversing
direction. We also investigate contact aging: the changes that occur to the
contact when the sliding stops completely. We compare the numerical results to
analytical calculations based on Kramers rates. We find that there is a slower
than exponential contact aging that weakens the contact and that we expect will
be observable in experiments. We discuss the implications for sliding as well
as aging experiments.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:56:40 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 09:37:14 GMT""}]","2021-06-08"
"2012.00372","Kamil Khadiev","Farid Ablayev, Marat Ablayev, Kamil Khadiev, Nailya Salihova and
  Alexander Vasiliev","Quantum Algorithms for String Processing","13 pages","In: Mesh Methods for Boundary-Value Problems and Applications.
  Lecture Notes in Computational Science and Engineering, vol 141.(2022)","10.1007/978-3-030-87809-2_1",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the paper, we investigate two problems on strings. The first one is the
String matching problem, and the second one is the String comparing problem. We
provide a quantum algorithm for the String matching problem that uses
exponentially less quantum memory than existing ones. The algorithm uses the
hashing technique for string matching, quantum parallelism, and ideas of
Grover's search algorithm. Using the same ideas, we provide two algorithms for
the String comparing problem. These algorithms also use exponentially less
quantum memory than existing ones. Additionally, the second algorithm works
exponentially faster than the existing one.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:59:06 GMT""}]","2023-05-19"
"2012.00373","Atharva Pagare","Atharva Pagare, V Sashi Mohan Rao, K Naga Chaithanya Kumar, K S Suresh","Study of involution domain based interfaces in Ni-Ti-Cu Shape Memory
  Alloy","14 pages, 6 Figures, 3 Tables",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An algorithm was made to study the lattice correspondence involved in phase
transformation from cubic B2 to monoclinic B19'. The method is based on
studying the orientation matrices generated from EBSD data. Starting from the
very fundamental, coordinate transformation matrices as well as the vector
transformation matrices have been walked through for a general non-orthogonal
to the orthogonal system. Further, using the defined formulas, orientation
matrices will be used to identify a new, non-generic Involution Domain and the
already accepted Bain Domain.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:00:26 GMT""},{""version"":""v2"",""created"":""Fri, 25 Dec 2020 12:19:04 GMT""}]","2020-12-29"
"2012.00374","Ludovic Biennier","Olivier Durif, Michael Capron, Joey P. Messinger, Abdessamad Benidar,
  Ludovic Biennier, J\'er\'emy Bourgalais, Andr\'e Canosa, Jonathan Courbe,
  Gustavo A. Garcia, Jean-Fran\c{c}ois Gil, Laurent Nahon, Mitchio Okumura,
  Lucile Rutkowski, Ian R. Sims, Jonathan Thi\'evin, S\'ebastien D. Le Picard","A new instrument for kinetics and branching ratio studies of gas phase
  collisional processes at very low temperatures",,,"10.1063/5.0029991",,"physics.chem-ph astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new instrument dedicated to the kinetic study of low-temperature gas phase
neutral-neutral reactions, including clustering processes, is presented. It
combines a supersonic flow reactor with Vacuum Ultra-Violet (VUV) synchrotron
photoionization time of flight mass spectrometry. A photoion-photoelectron
coincidence detection scheme has been adopted to optimize the particle counting
efficiency. The characteristics of the instrument are detailed along with its
capabilities illustrated through a few results obtained at low temperatures (<
100 K) including a {photoionization spectrum} of n-butane, the detection of
formic acid dimer formation as well as the observation of diacetylene molecules
formed by the reaction between the C$_2$H radical and C$_2$H$_2$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:03:30 GMT""}]","2021-02-24"
"2012.00375","Markus Fleschutz","Markus Fleschutz, Markus Bohlayer, Marco Braun, Gregor Henze, Michael
  D. Murphy","The effect of price-based demand response on carbon emissions in
  European electricity markets: The importance of adequate carbon prices",,,"10.1016/j.apenergy.2021.117040",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Price-based demand response (PBDR) has recently been attributed great
economic but also environmental potential. However, the determination of its
short-term effects on carbon emissions requires the knowledge of marginal
emission factors (MEFs), which compared to grid mix emission factors (XEFs),
are cumbersome to calculate due to the complex characteristics of national
electricity markets. This study, therefore, proposes two merit order-based
methods to approximate hourly MEFs and applies it to readily available datasets
from 20 European countries for the years 2017-2019. Based on the resulting
electricity prices, MEFs, and XEFs, standardized daily load shifts were
simulated to quantify their effects on marginal costs and carbon emissions.
Finally, by repeating the load shift simulations for different carbon price
levels, the impact of the carbon price on the resulting carbon emissions was
analyzed. Interestingly, the simulated price-based load shifts led to increases
in operational carbon emissions for 8 of the 20 countries and to an average
increase of 2.1% across all 20 countries. Switching from price-based to
MEF-based load shifts reduced the corresponding carbon emissions to a decrease
of 35%, albeit with 56% lower monetary cost savings compared to the price-based
load shifts. Under specific circumstances, PBDR leads to an increase in carbon
emissions, mainly due to the economic advantage fuel sources such as lignite
and coal have in the merit order. However, as the price of carbon is increased,
the correlation between the carbon intensity and the marginal cost of the fuels
substantially increases. Therefore, with adequate carbon prices, PBDR can be an
effective tool for both economical and environmental improvement.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:04:30 GMT""}]","2021-05-11"
"2012.00376","Kostya Trachenko","K. Trachenko and V. Brazhkin","The Purcell question: why do all viscosities stop at the same place?",,"Physics Today 74, 12 66 (2021)","10.1063/PT.3.4908",,"cond-mat.stat-mech cond-mat.mtrl-sci cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 1977, Purcell asked why liquid viscosities all stop at the same place?
Liquids are hard to understand, yet today we can answer the Purcell question in
terms of fundamental physical constants fixing viscosity minima. With the
Planck constant setting the minimal viscosity, water and life appear to be well
attuned to the degree of quantumness of the physical world.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:07:25 GMT""}]","2021-12-03"
"2012.00377","Joey Hong","Joey Hong and David Dohan and Rishabh Singh and Charles Sutton and
  Manzil Zaheer","Latent Programmer: Discrete Latent Codes for Program Synthesis","ICML 2021; 15 pages, 9 figures",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many sequence learning tasks, such as program synthesis and document
summarization, a key problem is searching over a large space of possible output
sequences. We propose to learn representations of the outputs that are
specifically meant for search: rich enough to specify the desired output but
compact enough to make search more efficient. Discrete latent codes are
appealing for this purpose, as they naturally allow sophisticated combinatorial
search strategies. The latent codes are learned using a self-supervised
learning principle, in which first a discrete autoencoder is trained on the
output sequences, and then the resulting latent codes are used as intermediate
targets for the end-to-end sequence prediction task. Based on these insights,
we introduce the \emph{Latent Programmer}, a program synthesis method that
first predicts a discrete latent code from input/output examples, and then
generates the program in the target language. We evaluate the Latent Programmer
on two domains: synthesis of string transformation programs, and generation of
programs from natural language descriptions. We demonstrate that the discrete
latent representation significantly improves synthesis accuracy.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:11:35 GMT""},{""version"":""v2"",""created"":""Thu, 5 Aug 2021 18:49:02 GMT""}]","2021-08-09"
"2012.00378","Jan Smeddinck","Jan Smeddinck, Markus Krause, Kolja Lubitz","Mobile Game User Research: The World as Your Lab?","CHI Conference on Human Factors in Computing Systems 2013, Workshop
  Paper, 5 pages",,,,"cs.HC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  With the advent of mobile games and the according growing and competitive
market, game user research can provide valuable insights and a competitive edge
if methods and procedures are employed that match the distinct challenges that
mobile devices, games and usage scenarios induce. We present a summary of
parameters that frame the research setup and procedure, focusing on the
trade-offs between lab and field studies and the related decision whether to
pursue large-scale and quantitative or small-scale focused research accompanied
by qualitative methods. We then illustrate the implications of these
considerations on real world projects along the lines of two evaluations of
different input methods for the action-puzzle mobile game Somyeol: a local
study with 37 participants and a mixed design of qualitative and quantitative
methods, and the strictly quantitative analysis of game-play data from 117,118
users. The findings underline the importance of small-scale evaluations prior
to release.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:11:40 GMT""}]","2020-12-02"
"2012.00379","Ana G. Lecuona","Nicolas Bedaride, Franz Gahler and Ana G. Lecuona","Cohomology groups for spaces of 12-fold tilings","64 pages. Article reviewed following the referee's suggestions. New
  final 'Discussion' section added. To appear in IMRN",,,,"math.KT math-ph math.DS math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider tilings of the plane with 12-fold symmetry obtained by the cut
and projection method. We compute their cohomology groups using the techniques
introduced by the second author, Hunton and Kellendonk. To do this we
completely describe the window, the orbits of lines under the group action and
the orbits of 0-singularities. The complete family of generalized 12-fold
tilings can be described using 2-parameters and it presents a surprisingly rich
cohomological structure. To put this finding into perspective, one should
compare our results with the cohomology of the generalized 5-fold tilings (more
commonly known as generalized Penrose tilings). In this case the tilings form a
1-parameter family, which fits in simply one of two types of cohomology.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:12:21 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 13:40:01 GMT""}]","2021-04-15"
"2012.00380","Benjamin Wa{\ss}ermann","Benjamin Wa{\ss}ermann","The $L^2$-torsion for representations of hyperbolic lattices","35 pages, 3 figures",,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  We prove equality of analytic and topological $L^2$-torsion associated with
an odd-dimensional finite volume hyperbolic manifold and a representation of
the fundamental group which extends to the ambient Lie group. This generalizes
a previous result due to L\""uck and Schick. Alternatively, this result can be
regarded as the $L^2$-analogue of recent work by M\""uller and Rochon.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:19:20 GMT""}]","2020-12-02"
"2012.00381","Fred Tomlinson","James Lucietti, Fred Tomlinson","On the nonexistence of a vacuum black lens","v2: minor changes, published version; 23 pages, 3 figures","J. High Energ. Phys. (2021) 2021, 5","10.1007/JHEP02(2021)005","EMPG-20-23","gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate that five-dimensional, asymptotically flat, stationary and
biaxisymmetric, vacuum black holes with lens space $L(n, 1)$ topology,
possessing the simplest rod structure, do not exist. In particular, we show
that the general solution on the axes and horizon, which we recently
constructed by exploiting the integrability of this system, must suffer from a
conical singularity on the inner axis component. We give a proof of this for
two distinct singly spinning configurations and numerical evidence for the
generic doubly spinning solution.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:20:16 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 16:29:48 GMT""}]","2021-02-08"
"2012.00382","Valeria Vignudelli","Matteo Mio, Ralph Sarkis, Valeria Vignudelli","Combining nondeterminism, probability, and termination: equational and
  metric reasoning",,,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study monads resulting from the combination of nondeterministic and
probabilistic behaviour with the possibility of termination, which is essential
in program semantics. Our main contributions are presentation results for the
monads, providing equational reasoning tools for establishing equivalences and
distances of programs.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:21:58 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 11:18:36 GMT""},{""version"":""v3"",""created"":""Wed, 21 Apr 2021 15:25:43 GMT""}]","2021-04-22"
"2012.00383","Zhenglu Duan","Yi Ren, Shouhui Duan, Wenzhi Xie, Yongkang Shao, and Zhenglu Duan","Antibunched photon-pair source based on photon blockade effect in a
  nondegenerate optical parametric oscillator",,"Phys. Rev. A 103, 053710 (2021)","10.1103/PhysRevA.103.053710",,"quant-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Nonclassical light sources, such as correlated photon-pairs, play an
important role in quantum optics and quantum information processing systems.
This study proposes a process to generate antibunched photon-pairs in a
nondegenerate optical parametric oscillator. It is found that when the
parameters of the system satisfy certain conditions, the generated photons in
subharmonic modes exhibit a strong antibunching behavior and are strongly
correlated with one another. In particular, the average photon-pair number is
resonantly enhanced. It is also observed that the conventional photon blockade
contributes to this phenomenon. In addition, it is interesting to note that
fundamental mode photons can blockade the subharmonic mode photons. We refer to
this phenomenon as a heterogeneous photon blockade.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:25:39 GMT""}]","2021-06-02"
"2012.00384","Dimitrios Papageorgiou","Mufeng Liu, Pietro Cataldi, Robert J. Young, Dimitrios G.
  Papageorgiou, Ian A. Kinloch","High-performance fluoroelastomer-graphene nanocomposites for advanced
  sealing applications",,,"10.1016/j.compscitech.2020.108592",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  High-performance sealing materials that can guard key components against high
pressure gases and liquid chemicals while withstanding mechanical deformation
are of utmost importance in a number of industries. In this present work,
graphene nanoplatelets (GNPs) were introduced into a fluoroelastomer (FKM)
matrix to improve its mechanical and barrier properties and test its
suitability for sealing applications. Nanocomposites filled with different
loadings of GNPs were prepared and compared with their counterparts loaded with
carbon black (CB). GNPs were dispersed homogeneously with a high degree of
in-plane alignment. The tensile and barrier properties of the FKM were improved
significantly by the addition of GNPs. Micromechanical modelling based on the
shear-lag/rule-of-mixtures theory was used to analyse the reinforcing
efficiency of the GNPs. Upon the addition of the GNPs, the elastomer was able
to swell anisotropically in liquids, a fact that can be used to tune the
swelling properties for sealing applications. In terms of gas permeability, a
modification of the well-established Nielsen's theory was introduced to analyse
the CO2 permeability for the bulk composite samples. The significantly improved
mechanical, thermal and barrier properties at relatively low filler loadings,
reveal that the FKM/GNP nanocomposites produced are very promising for use in
advanced sealing applications.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:28:21 GMT""}]","2020-12-02"
"2012.00385","Katarzyna Siudzi\'nska","Katarzyna Siudzi\'nska","Markovian semigroup from mixing non-invertible dynamical maps",,"Phys. Rev. A 103, 022605 (2021)","10.1103/PhysRevA.103.022605",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the convex combinations of non-invertible generalized Pauli
dynamical maps. By manipulating the mixing parameters, one can produce a
channel with shifted singularities, additional singularities, or even no
singularities whatsoever. In particular, we show how to use non-invertible
dynamical maps to produce the Markovian semigroup. Interestingly, the maps
whose mixing results in a semigroup are generated by the time-local generators
and time-homogeneous memory kernels that are not regular; i.e., their formulas
contain infinities. Finally, we show how the generators and memory kernels
change after mixing the corresponding dynamical maps.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:28:55 GMT""}]","2021-02-17"
"2012.00386","Joey Hong","Joey Hong, Branislav Kveton, Manzil Zaheer, Yinlam Chow, Amr Ahmed,
  Mohammad Ghavamzadeh, Craig Boutilier","Non-Stationary Latent Bandits","15 pages, 4 figures",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Users of recommender systems often behave in a non-stationary fashion, due to
their evolving preferences and tastes over time. In this work, we propose a
practical approach for fast personalization to non-stationary users. The key
idea is to frame this problem as a latent bandit, where the prototypical models
of user behavior are learned offline and the latent state of the user is
inferred online from its interactions with the models. We call this problem a
non-stationary latent bandit. We propose Thompson sampling algorithms for
regret minimization in non-stationary latent bandits, analyze them, and
evaluate them on a real-world dataset. The main strength of our approach is
that it can be combined with rich offline-learned models, which can be
misspecified, and are subsequently fine-tuned online using posterior sampling.
In this way, we naturally combine the strengths of offline and online learning.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:31:57 GMT""}]","2020-12-02"
"2012.00387","Alireza Gharahighehi","Alireza Gharahighehi, Celine Vens, Konstantinos Pliakos","Fair Multi-Stakeholder News Recommender System with Hypergraph ranking",,,,,"cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recommender systems are typically designed to fulfill end user needs.
However, in some domains the users are not the only stakeholders in the system.
For instance, in a news aggregator website users, authors, magazines as well as
the platform itself are potential stakeholders. Most of the collaborative
filtering recommender systems suffer from popularity bias. Therefore, if the
recommender system only considers users' preferences, presumably it
over-represents popular providers and under-represents less popular providers.
To address this issue one should consider other stakeholders in the generated
ranked lists. In this paper we demonstrate that hypergraph learning has the
natural capability of handling a multi-stakeholder recommendation task. A
hypergraph can model high order relations between different types of objects
and therefore is naturally inclined to generate recommendation lists
considering multiple stakeholders. We form the recommendations in time-wise
rounds and learn to adapt the weights of stakeholders to increase the coverage
of low-covered stakeholders over time. The results show that the proposed
approach counters popularity bias and produces fairer recommendations with
respect to authors in two news datasets, at a low cost in precision.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:37:00 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 08:59:50 GMT""}]","2021-02-10"
"2012.00388","Oleg Lychkovskiy","Oleg Lychkovskiy","Closed hierarchy of Heisenberg equations in integrable models with
  Onsager algebra","Submission to SciPost","SciPost Phys. 10, 124 (2021)","10.21468/SciPostPhys.10.6.124",,"cond-mat.stat-mech cond-mat.quant-gas math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamics of a quantum system can be described by coupled Heisenberg
equations. In a generic many-body system these equations form an exponentially
large hierarchy that is intractable without approximations. In contrast, in an
integrable system a small subset of operators can be closed with respect to
commutation with the Hamiltonian. As a result, the Heisenberg equations for
these operators can form a smaller closed system amenable to an analytical
treatment. We demonstrate that this indeed happens in a class of integrable
models where the Hamiltonian is an element of the Onsager algebra. We
explicitly solve the system of Heisenberg equations for operators from this
algebra. Two specific models are considered as examples: the transverse field
Ising model and the superintegrable chiral 3-state Potts model.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:39:05 GMT""},{""version"":""v2"",""created"":""Mon, 7 Dec 2020 15:55:30 GMT""},{""version"":""v3"",""created"":""Fri, 5 Mar 2021 18:03:32 GMT""},{""version"":""v4"",""created"":""Mon, 26 Apr 2021 15:02:23 GMT""}]","2021-06-02"
"2012.00389","Marco Squassina","Gianluca Ferrari, Marco Squassina","Nonlocal characterizations of variable exponent Sobolev spaces","18 pages",,,,"math.AP math.FA","http://creativecommons.org/licenses/by/4.0/","  We obtain some nonlocal characterizations for a class of variable exponent
Sobolev spaces arising in nonlinear elasticity theory and in the theory of
electrorheological fluids. We also get a singular limit formula extending
Nguyen results to the anisotropic case.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:39:16 GMT""}]","2020-12-02"
"2012.00390","Mathew Owens","Mathew Owens","Reply to comment by Yermolaev and Lodkina on ""Solar Wind and Heavy Ion
  Properties of Interplanetary Coronal Mass Ejections"" by Owens (2018) in
  arXiv:2008.05160","2 pages",,,,"physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Here I reply to the comment by Yermolaev and Lodkina [arXiv:2008.05160] on
""Solar Wind and Heavy Ion Properties of Interplanetary Coronal Mass Ejections""
by Owens (2018).
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:39:16 GMT""}]","2020-12-02"
"2012.00391","Yi Chu","Yi Chu, Paul Mitchell, David Grace, Jonathan Roberts, Dominic White
  and Tautvydas Mickus","IRIS: A Low Duty Cycle Cross-Layer Protocol for Long-Range Wireless
  Sensor Networks with Low Power Budget",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a cross-layer protocol (IRIS) designed for long-range
pipeline Wireless Sensor Networks with extremely low power budget, typically
seen in a range of monitoring applications. IRIS uses ping packets initiated by
a base station to travel through the multi-hop network and carry monitoring
information. The protocol is able to operate with less than 1% duty cycle,
thereby conforming to ISM band spectrum regulations in the 868MHz band. The
duty cycle can be flexibly configured to meet other regulations/power budgets
as well as to improve the route forming performance. Simulation results show
guaranteed route formation in different network topologies with various
protocol configurations. System robustness against unreliable wireless
connections and node failures are also demonstrated by simulations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:40:44 GMT""}]","2020-12-02"
"2012.00392","Enrico Bozzo","E. Bozzo, L. Ducci, and M. Falanga","A semi-analytical treatment to wind accretion in neutron star supergiant
  high mass X-ray binaries: I. eccentric orbits","Accepted for publication in MNRAS",,"10.1093/mnras/staa3761",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present in this paper a first step toward a semi-analytical treatment of
the accretion process in wind-fed neutron star supergiant X-ray binaries with
eccentric orbits. We consider the case of a spherically symmetric wind for the
supergiant star and a simplified model for the accretion onto the compact
object. A self-consistent calculation of the photoionization of the stellar
wind by the X-rays from the accreting neutron star is included. This effect is
convolved with the modulation of the mass accretion rate induced by the
eccentric orbit to obtain the expected X-ray luminosity of a system along the
orbit. As part of our results, we first show that the bi-modality of low and
high X-ray luminosity solutions for supergiant X-ray binaries reported in
previous papers is likely to result from the effect of the neutron star
approaching first and then moving away from the companion (without coexisting
simultaneously). We propose that episodes of strong wind photoionization can
give rise to off-states of the sources. Our calculations are applied to the
case of a few classical supergiant X-ray binary systems with known
eccentricities (Vela X-1, 4U 1907+09, GX 301-2) and to the case of the only
supergiant fast X-ray transient with a confirmed eccentric orbit, IGR
J08408-4503. The results are compared with observational findings on these
sources. We also discuss the next steps needed to expand the calculations
toward a more comprehensive treatment in future publications.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:42:18 GMT""}]","2020-12-16"
"2012.00393","Arijit Saha","Arnob Kumar Ghosh, Tanay Nag, Arijit Saha","Floquet Second Order Topological Superconductor based on Unconventional
  Pairing","This is the published version","Phys. Rev. B 103, 085413 (2021)","10.1103/PhysRevB.103.085413",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically investigate the Floquet generation of second-order
topological superconducting (SOTSC) phase in the high-temperature platform both
in two-dimension (2D) and three-dimension (3D). Starting from a $d$-wave
superconducting pairing gap, we periodically kick the mass term to engineer the
dynamical SOTSC phase within a specific range of the strength of the drive.
Under such dynamical breaking of time-reversal symmetry (TRS), we show the
emergence of the \textit{weak} SOTSC phase, harboring eight corner modes \ie
two zero-energy Majorana per corner, with vanishing Floquet quadrupole moment.
On the other hand, our study interestingly indicates that upon the introduction
of an explicit TRS breaking Zeeman field, the \textit{weak} SOTSC phase can be
transformed into \textit{strong} SOTSC phase, hosting one zero-energy Majorana
mode per corner, with quantized quadrupole moment. We also compute the Floquet
Wannier spectra that further establishes the \textit{weak} and \textit{strong}
nature of these phases. We numerically verify our protocol computing the exact
Floquet operator in open boundary condition and then analytically validate our
findings with the low energy effective theory (in the high-frequency limit).
The above protocol is applicable for 3D as well where we find one dimensional
(1D) hinge mode in the SOTSC phase. We then show that these corner modes are
robust against moderate disorder and the topological invariants continue to
exhibit quantized nature until disorder becomes substantially strong. The
existence of zero-energy Majorana modes in these higher-order phases is
guaranteed by the anti-unitary spectral symmetry.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:47:30 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 10:24:16 GMT""}]","2021-02-10"
"2012.00394","Swapnil Mishra","Samir Bhatt, Neil Ferguson, Seth Flaxman, Axel Gandy, Swapnil Mishra,
  James A. Scott","Semi-Mechanistic Bayesian Modeling of COVID-19 with Renewal Processes",,,,,"stat.AP stat.ME","http://creativecommons.org/licenses/by/4.0/","  We propose a general Bayesian approach to modeling epidemics such as
COVID-19. The approach grew out of specific analyses conducted during the
pandemic, in particular an analysis concerning the effects of
non-pharmaceutical interventions (NPIs) in reducing COVID-19 transmission in 11
European countries. The model parameterizes the time varying reproduction
number $R_t$ through a regression framework in which covariates can e.g be
governmental interventions or changes in mobility patterns. This allows a joint
fit across regions and partial pooling to share strength. This innovation was
critical to our timely estimates of the impact of lockdown and other NPIs in
the European epidemics, whose validity was borne out by the subsequent course
of the epidemic. Our framework provides a fully generative model for latent
infections and observations deriving from them, including deaths, cases,
hospitalizations, ICU admissions and seroprevalence surveys. One issue
surrounding our model's use during the COVID-19 pandemic is the confounded
nature of NPIs and mobility. We use our framework to explore this issue. We
have open sourced an R package epidemia implementing our approach in Stan.
Versions of the model are used by New York State, Tennessee and Scotland to
estimate the current situation and make policy decisions.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:51:09 GMT""},{""version"":""v2"",""created"":""Tue, 29 Dec 2020 09:00:05 GMT""}]","2021-01-01"
"2012.00395","Piotr Wrzosek","Piotr Wrzosek, Krzysztof Wohlfeld","Hole in the 2D Ising Antiferromagnet: Origin of the Incoherent Spectrum","12 pages, 10 figures","Phys. Rev. B 103, 035113 (2021)","10.1103/PhysRevB.103.035113",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a ""self-avoiding walks"" approximation and use it to calculate the
spectral function of a single hole introduced into the 2D square lattice Ising
antiferromagnet. The obtained local spectral function qualitatively agrees with
the exact diagonalisation result and is largely incoherent. Such a result stays
in contrast with the spectrum obtained on a Bethe lattice, which consists of
the well-separated quasiparticle-like peaks and stems from the motion of a hole
in an effective linear potential. We determine that this onset of the
incoherent spectrum on a square lattice (i) is not triggered by the so-called
Trugman loops but (ii) originates in the warping of the linear potential by the
interactions between magnons created along the tangential paths of the moving
hole.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:53:44 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jan 2021 15:08:57 GMT""}]","2021-01-19"
"2012.00396","Qingjie Ye","Changhong Lu and Qingjie Ye","A bridge between the minimal doubly resolving set problem in (folded)
  hypercubes and the coin weighing problem",,"Discrete Appl. Math. 309 (2022) 147-159","10.1016/j.dam.2021.11.016",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the minimal doubly resolving set problem in
Hamming graphs, hypercubes and folded hypercubes. We prove that the minimal
doubly resolving set problem in hypercubes is equivalent to the coin weighing
problem. Then we answer an open question on the minimal doubly resolving set
problem in hypercubes. We disprove a conjecture on the metric dimension problem
in folded hypercubes and give some asymptotic results for the metric dimension
and the minimal doubly resolving set problems in Hamming graphs and folded
hypercubes by establishing connections between these problems. Using the
Lindstr\""{o}m's method for the coin weighing problem, we give an efficient
algorithm for the minimal doubly resolving set problem in hypercubes and report
some new upper bounds. We also prove that the minimal doubly resolving set
problem is NP-hard even restrict on split graphs, bipartite graphs and
co-bipartite graphs.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:53:56 GMT""},{""version"":""v2"",""created"":""Mon, 6 Dec 2021 03:11:41 GMT""}]","2021-12-07"
"2012.00397","Xinyu Wang","Xinyu Wang, Lu Yang, Hong Zhang, Zhouwang Yang and Catherine Liu","Forecasting confirmed cases of the COVID-19 pandemic with a
  migration-based epidemiological model",,,,,"stat.AP physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unprecedented coronavirus disease 2019 (COVID-19) pandemic is still a
worldwide threat to human life since its invasion into the daily lives of the
public in the first several months of 2020. Predicting the size of confirmed
cases is important for countries and communities to make proper prevention and
control policies so as to effectively curb the spread of COVID-19. Different
from the 2003 SARS epidemic and the worldwide 2009 H1N1 influenza pandemic,
COVID-19 has unique epidemiological characteristics in its infectious and
recovered compartments. This drives us to formulate a new infectious dynamic
model for forecasting the COVID-19 pandemic within the human mobility network,
named the SaucIR-model in the sense that the new compartmental model extends
the benchmark SIR model by dividing the flow of people in the infected state
into asymptomatic, pathologically infected but unconfirmed, and confirmed.
Furthermore, we employ dynamic modeling of population flow in the model in
order that spatial effects can be incorporated effectively. We forecast the
spread of accumulated confirmed cases in some provinces of mainland China and
other countries that experienced severe infection during the time period from
late February to early May 2020. The novelty of incorporating the geographic
spread of the pandemic leads to a surprisingly good agreement with published
confirmed case reports. The numerical analysis validates the high degree of
predictability of our proposed SaucIR model compared to existing resemblance.
The proposed forecasting SaucIR model is implemented in Python. A web-based
application is also developed by Dash (under construction).
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:54:18 GMT""}]","2020-12-02"
"2012.00398","Naveen Elango","Naveen Elango, Pawan Prasad K","Introducing Inter-Relatedness between Wikipedia Articles in Explicit
  Semantic Analysis","16 pages",,,,"cs.CL cs.AI cs.IR","http://creativecommons.org/licenses/by/4.0/","  Explicit Semantic Analysis (ESA) is a technique used to represent a piece of
text as a vector in the space of concepts, such as Articles found in Wikipedia.
We propose a methodology to incorporate knowledge of Inter-relatedness between
Wikipedia Articles to the vectors obtained from ESA using a technique called
Retrofitting to improve the performance of subsequent tasks that use ESA to
form vector embeddings. Especially we use an undirected Graph to represent this
knowledge with nodes as Articles and edges as inter relations between two
Articles. Here, we also emphasize how the ESA step could be seen as a
predominantly bottom-up approach using a corpus to come up with vector
representations and the incorporation of top-down knowledge which is the
relations between Articles to further improve it. We test our hypothesis on
several smaller subsets of the Wikipedia corpus and show that our proposed
methodology leads to decent improvements in performance measures including
Spearman's Rank correlation coefficient in most cases.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:55:07 GMT""}]","2020-12-02"
"2012.00399","Emil Akhmedov","E. T. Akhmedov, A. V. Anokhin, D. I. Sadekov","Currents of created pairs in strong electric fields","19 pages, minor changes, clarifying comments are added, misprints
  corrected",,"10.1142/S0217751X21501347",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate tree--level currents of created particles in strong background
electric fields in 4D QED for various initial states. Namely, we do that in
pulse background for initial vacuum and thermal states at past infinity. In
both cases we find that the current grows linearly with the length of the pulse
with coefficients of proportionality containing the characteristic Schwinger's
factor. For the constant electric field background we calculate the current for
several different initial states. We observe that in such a case the current is
either zero or linearly divergent. We explain the reason for such a behaviour
and compare the situation in ordinary and scalar QED. Finally, we calculate the
current in two--dimensional situation in the presence of such settings when the
so called Klein paradox can be observed.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:59:08 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 15:06:23 GMT""},{""version"":""v3"",""created"":""Sat, 8 May 2021 07:51:40 GMT""}]","2021-08-04"
"2012.00400","Felix Lorenz","Felix Lorenz, Morgan Geldenhuys, Harald Sommer, Frauke Jakobs, Carsten
  L\""uring, Volker Skwarek, Ilja Behnke, Lauritz Thamsen","A Scalable and Dependable Data Analytics Platform for Water
  Infrastructure Monitoring",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With weather becoming more extreme both in terms of longer dry periods and
more severe rain events, municipal water networks are increasingly under
pressure. The effects include damages to the pipes, flash floods on the streets
and combined sewer overflows. Retrofitting underground infrastructure is very
expensive, thus water infrastructure operators are increasingly looking to
deploy IoT solutions that promise to alleviate the problems at a fraction of
the cost. In this paper, we report on preliminary results from an ongoing joint
research project, specifically on the design and evaluation of its data
analytics platform. The overall system consists of energy-efficient sensor
nodes that send their observations to a stream processing engine, which
analyzes and enriches the data and transmits the results to a GIS-based
frontend. As the proposed solution is designed to monitor large and critical
infrastructures of cities, several non-functional requirements such as
scalability, responsiveness and dependability are factored into the system
architecture. We present a scalable stream processing platform and its
integration with the other components, as well as the algorithms used for data
processing. We discuss significant challenges and design decisions, introduce
an efficient data enrichment procedure and present empirical results to
validate the compliance with the target requirements. The entire code for
deploying our platform and running the data enrichment jobs is made publicly
available with this paper.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:02:31 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 15:20:32 GMT""}]","2021-02-18"
"2012.00401","Yuriy Demidov","Yu. A. Demidov, E. A. Konovalova, R. T. Imanbaeva, M. G. Kozlov, A. E.
  Barzakh","Atomic calculations of hyperfine structure anomaly in gold",,"Phys. Rev. A 103, 032824 (2021)","10.1103/PhysRevA.103.032824",,"physics.atom-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The magnetic hyperfine structure constants have been calculated for low-lying
levels in neutral gold atom and gold-like ion of mercury taking into account
Bohr--Weisskopf (BW) effect. BW effect is represented as a product of atomic
and nuclear ($d_\mathrm{nuc}$) factors. We have calculated the atomic factors,
which enable one to extract BW-correction values for far from stability gold
nuclei from the experimental data. The possible uncertainty of our atomic
calculations have been estimated by the comparison with the available
experimental data. It has been shown that the standard single-particle approach
in $d_\mathrm{nuc}$ calculation reasonably well describes experimental data for
$11/2^-$ gold isomers and $3/2^+$ ground state of $\rm ^{199}Au$. At the same
time, it fails to describe the hyperfine constant in $^{197}\mathrm{Au}$. This
indicates the more pronounced configuration mixing in $\rm ^{197}Au$ than in
$\rm ^{199}Au$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:04:42 GMT""},{""version"":""v2"",""created"":""Sun, 7 Mar 2021 20:20:27 GMT""}]","2021-03-24"
"2012.00402","Sivaramakrishnan K N","Sivaramakrishnan KN, Lipika Deka, Manik Gupta","Use of Remote Sensing Data to Identify Air Pollution Signatures in India",,,,,"cs.LG cs.CY","http://creativecommons.org/licenses/by/4.0/","  Air quality has major impact on a country's socio-economic position and
identifying major air pollution sources is at the heart of tackling the issue.
Spatially and temporally distributed air quality data acquisition across a
country as varied as India has been a challenge to such analysis. The launch of
the Sentinel-5P satellite has helped in the observation of a wider variety of
air pollutants than measured before at a global scale on a daily basis. In this
chapter, spatio-temporal multi pollutant data retrieved from Sentinel-5P
satellite is used to cluster states as well as districts in India and
associated average monthly pollution signature and trends depicted by each of
the clusters are derived and presented.The clustering signatures can be used to
identify states and districts based on the types of pollutants emitted by
various pollution sources.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:06:23 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jan 2021 08:51:10 GMT""}]","2021-01-19"
"2012.00403","Ziye Yang","Ziye Yang, Shanzheng Guan and Xiao-Lei Zhang","Deep Ad-hoc Beamforming Based on Speaker Extraction for Target-Dependent
  Speech Separation",,,,,"cs.SD cs.CL eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the research on ad-hoc microphone arrays with deep learning has
drawn much attention, especially in speech enhancement and separation. Because
an ad-hoc microphone array may cover such a large area that multiple speakers
may locate far apart and talk independently, target-dependent speech
separation, which aims to extract a target speaker from a mixed speech, is
important for extracting and tracing a specific speaker in the ad-hoc array.
However, this technique has not been explored yet. In this paper, we propose
deep ad-hoc beamforming based on speaker extraction, which is to our knowledge
the first work for target-dependent speech separation based on ad-hoc
microphone arrays and deep learning. The algorithm contains three components.
First, we propose a supervised channel selection framework based on speaker
extraction, where the estimated utterance-level SNRs of the target speech are
used as the basis for the channel selection. Second, we apply the selected
channels to a deep learning based MVDR algorithm, where a single-channel
speaker extraction algorithm is applied to each selected channel for estimating
the mask of the target speech. We conducted an extensive experiment on a
WSJ0-adhoc corpus. Experimental results demonstrate the effectiveness of the
proposed method.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:06:36 GMT""}]","2020-12-02"
"2012.00404","Chen Qian","Chen Qian, Yunhai Xiong and Xiang Chen","Directed Graph Attention Neural Network Utilizing 3D Coordinates for
  Molecular Property Prediction",,,,,"cs.LG cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The prosperity of computer vision (CV) and natural language procession (NLP)
in recent years has spurred the development of deep learning in many other
domains. The advancement in machine learning provides us with an alternative
option besides the computationally expensive density functional theories (DFT).
Kernel method and graph neural networks have been widely studied as two
mainstream methods for property prediction. The promising graph neural networks
have achieved comparable accuracy to the DFT method for specific objects in the
recent study. However, most of the graph neural networks with high precision so
far require fully connected graphs with pairwise distance distribution as edge
information. In this work, we shed light on the Directed Graph Attention Neural
Network (DGANN), which only takes chemical bonds as edges and operates on bonds
and atoms of molecules. DGANN distinguishes from previous models with those
features: (1) It learns the local chemical environment encoding by graph
attention mechanism on chemical bonds. Every initial edge message only flows
into every message passing trajectory once. (2) The transformer blocks
aggregate the global molecular representation from the local atomic encoding.
(3) The position vectors and coordinates are used as inputs instead of
distances. Our model has matched or outperformed most baseline graph neural
networks on QM9 datasets even without thorough hyper-parameters searching.
Moreover, this work suggests that models directly utilizing 3D coordinates can
still reach high accuracies for molecule representation even without rotational
and translational invariance incorporated.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:06:40 GMT""}]","2020-12-02"
"2012.00405","Filippo Fabbri","Olivier Lefebvre, Mireille Lambert, Clotilde Randriamampita, Sandra
  Pinto, Khalid Lahlil, Jacques Peretti, Claire Smadja and Filippo Fabbri","Light-tunable optical cell manipulation via photoactive
  azobenzene-containing thin film bio-substrate",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In-vivo, real-time study of the local and collective cellular biomechanical
responses requires the fine and selective manipulation of the cellular
environment. One innovative pathway is the use of photoactive bio-substrates
such as azobenzene-containing materials, which exhibit spectacular
photomechanical properties, to optically trigger the local, mechanical
stimulation of cells. Excited cells exhibit spectacular morphological
modifications and area shrinkage, which are dependent on the illumination. This
demonstrates the capabilities of photomechanically active substrates to study
the phenomena resulting from the mechanical interaction of cells with their
environment.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:06:56 GMT""},{""version"":""v2"",""created"":""Tue, 28 Dec 2021 20:50:12 GMT""}]","2021-12-30"
"2012.00406","Trond Abrahamsen","Trond A. Abrahamsen, Vegard Lima and Andr\'e Martiny","Delta-points in Banach spaces generated by adequate families","Fixed some misprints. Added Examples 2.4, 2.5 and Corollary 5.4",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study delta-points in Banach spaces $h_{\mathcal{A},p}$ generated by
adequate families $\mathcal A$ where $1 \le p < \infty$. In the case the
familiy $\mathcal A$ is regular and $p=1,$ these spaces are known as
combinatorial Banach spaces. When $p > 1$ we prove that neither
$h_{\mathcal{A},p}$ nor its dual contain delta-points. Under the extra
assumption that $\mathcal A$ is regular, we prove that the same is true when
$p=1.$ In particular the Schreier spaces and their duals fail to have
delta-points. If $\mathcal A$ consists of finite sets only we are able to rule
out the existence of delta-points in $h_{\mathcal{A},1}$ and Daugavet-points in
its dual.
  We also show that if $h_{\mathcal{A},1}$ is polyhedral, then it is either
(I)-polyhedral or (V)-polyhedral (in the sense of Fonf and Vesel\'y).
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:12:35 GMT""},{""version"":""v2"",""created"":""Wed, 31 Mar 2021 18:42:57 GMT""}]","2021-04-02"
"2012.00407","Roy Karasik","Roy Karasik, Osvaldo Simeone, Marco Di Renzo, Shlomo Shamai (Shitz)","Adaptive Coding and Channel Shaping Through Reconfigurable Intelligent
  Surfaces: An Information-Theoretic Analysis","submitted",,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  A communication link aided by a reconfigurable intelligent surface (RIS) is
studied in which the transmitter can control the state of the RIS via a
finite-rate control link. Channel state information (CSI) is acquired at the
receiver based on pilot-assisted channel estimation, and it may or may not be
shared with the transmitter. Considering quasi-static fading channels with
imperfect CSI, capacity-achieving signalling is shown to implement joint
encoding of the transmitted signal and of the response of the RIS. This
demonstrates the information-theoretic optimality of RIS-based modulation, or
""single-RF MIMO"" systems. In addition, a novel signalling strategy based on
separate layered encoding that enables practical successive cancellation-type
decoding at the receiver is proposed. Numerical experiments show that the
conventional scheme that fixes the reflection pattern of the RIS, irrespective
of the transmitted information, as to maximize the achievable rate is strictly
suboptimal, and is outperformed by the proposed adaptive coding strategies at
all practical signal-to-noise ratio (SNR) levels.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:14:15 GMT""}]","2020-12-02"
"2012.00408","Marco Cavallone","Marco Cavallone, Lucas Rovige, Julius Huijts, \'Emilie Bayart, Rachel
  Delorme, Aline Vernier, Patrik Gon\c{c}alves Jorge, Rapha\""el Moeckli, Eric
  Deutsch, J\'er\^ome Faure, Alessandro Flacco","Dosimetric characterisation and application to radiation biology of a
  kHz laser-driven electron beam",,,"10.1007/s00340-021-07610-z",,"physics.acc-ph physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Laser-plasma accelerators can produce ultra short electron bunches in the
femtosecond to picosecond duration range, resulting in high peak dose rates in
comparison with clinical accelerators. This peculiar characteristic motivates
their application to radiation biology studies to elucidate the effect of the
high peak dose rate on the biological response of living cells, which is still
being debated. Electron beams driven by kHz laser systems may represent an
attractive option for such applications, since the high repetition rate can
boost the mean dose rate and improve the stability of the delivered dose in
comparison with J-class laser accelerators running at 10 Hz. In this work, we
present the dosimetric characterisation of a kHz, low energy laser-driven
electron source and preliminary results on in-vitro irradiation of cancer
cells. A shot-to-shot dosimetry protocol enabled to monitor the beam stability
and the irradiation conditions for each cell sample. Results of survival assays
on HCT116 colorectal cancer cells are in good agreement with previous findings
reported in literature and validate the robustness of the dosimetry and
irradiation protocol.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:17:21 GMT""}]","2021-04-14"
"2012.00409","Reinoud Slagter","Reinoud J. Slagter","Conformal Dilaton Gravity and Warped Spacetimes in 5D","V8. Some minor type errors corrected. Comment welcome",,,,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  An exact time-dependent solution of a black hole is found in conformally
invariant gravity on a warped Randall-Sundrum spacetime, by writing the metric
$g_{\mu\nu}=\omega^{\frac{4}{n-2}}\tilde g_{\mu\nu}$. Here $\tilde g_{\mu\nu}$
represents the ""un-physical"" spacetime and $\omega$ the dilaton field, which
will be treated on equal footing as any renormalizable scalar field. In the
case of a five-dimensional warped spacetime, we write $ ^{(4)}{\tilde
g_{\mu\nu}}=\bar\omega^2{ ^{(4)}\bar g_{\mu\nu}}$ Both $\omega$ and
$\bar\omega$ can be used to describe the different notion the in-going and
outside observers have of the Hawking radiation by using different conformal
gauge freedom. The disagreement about the interior of the black hole is
explained by the antipodal map of points on the horizon. The free parameters of
the solution can be chosen in such a way that $\bar g_{\mu\nu}$ is
singular-free and topologically regular, even for $\omega\rightarrow 0$. It is
remarkable that the 5D and 4D effective field equations for the metric
components and dilaton fields can be written in general dimension $ n= 4,5$. It
is conjectured that, in context of quantization procedures in the vicinity of
the horizon, unitarity problems only occur in the bulk at large extra-dimension
scale. The subtraction point in an effective theory will be in the UV only in
the bulk, because the use of a large extra dimension results in a fundamental
Planck scale comparable with the electroweak scale.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:19:26 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 18:35:24 GMT""},{""version"":""v3"",""created"":""Fri, 8 Jan 2021 08:47:40 GMT""},{""version"":""v4"",""created"":""Tue, 12 Jan 2021 21:06:56 GMT""},{""version"":""v5"",""created"":""Tue, 16 Mar 2021 22:46:13 GMT""},{""version"":""v6"",""created"":""Thu, 29 Apr 2021 19:12:34 GMT""},{""version"":""v7"",""created"":""Tue, 25 May 2021 13:51:30 GMT""},{""version"":""v8"",""created"":""Fri, 16 Jul 2021 16:21:33 GMT""}]","2021-07-19"
"2012.00410","Jonas Lima","J. M. Pontes, N. F. Fraz\~ao, David L. Azevedo and Jonas R. F. Lima","Electronic, optical, vibrational and thermodynamic properties of phaBN
  structure: a first principles study",,,"10.1016/j.commatsci.2020.110210",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 2015, a new two dimensional (2D) carbon allotrope, called phagraphene, was
theoretically proposed. Based on this structure, we propose here a new boron
nitride structure called phaBN. It is composed by three types of rings:
pentagons, hexagons and heptagons. We investigate the electronic, optical,
vibrational and thermodynamic properties of phaBN using first-principles
calculations in a density functional theory (DFT) framework. Our calculations
revealed that the phaBN has an energy gap of 2.739 eV, which is almost half of
the energy gap of the hexagonal boron nitride (h-BN), thus being a
semiconductor material. By means of the optical, vibrational and thermodynamic
properties, it was possible to observe the absorption interval, the stability
of the structure and its formation process, respectively.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:25:45 GMT""}]","2020-12-09"
"2012.00411","Vikash Sharma","Vikash Sharma, Gunadhor Singh Okram, Divya Verma, Niranjan Prasad
  Lalla, Yung-Kang Kuo","Ultralow Thermal Conductivity and Large Figure of Merit in Low-Cost and
  Nontoxic Core-Shell Cu@Cu2O Nanocomposites","18 pages, 9 figures",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/publicdomain/zero/1.0/","  Identification of novel materials with enhanced thermoelectric (TE)
performance is critical for advancing TE research. In this direction, this is
the first report on TE properties of low-cost, nontoxic, and abundant
core-shell Cu@Cu2O nanocomposites (NCs) synthesized using a facile and cheap
solution-phase method. They show ultralow thermal conductivity of nearly 10-3
of copper bulk value, large thermopower ~0.373 mVK-1, and consequently, a TE
figure of merit (ZT) of 0.16 at 320 K which is larger than those of many of the
potential TE materials such as PbTe, SnSe and SiGe, showing its potential for
TE applications. The ultralow thermal conductivity is mainly attributed to the
multiscale phonon scattering from intrinsic defects in Cu2O, grain boundaries
(GBs), lattice-mismatched interface as well as dissimilar vibrational
properties. The large thermopower is associated with sharp modulation in
carrier density of states (DOS) due to charge transfer between Cu and Cu2O
nanoparticles (NPs), and carrier energy filtering.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:25:51 GMT""}]","2020-12-02"
"2012.00412","Yukihide Tadano","Yukihide Tadano","Construction of Isozaki-Kitada modifiers for discrete Schr\""odinger
  operators on general lattices","21 pages",,,,"math-ph math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a scattering theory for convolution operators on
$\mathcal{H}=\ell^2(\mathbb{Z}^d; \mathbb{C}^n)$ perturbed with a long-range
potential $V:\mathbb{Z}^d\to\mathbb{R}^n$. One of the motivating examples is
discrete Schr\""odinger operators on $\mathbb{Z}^d$-periodic graphs. We
construct time-independent modifiers, so-called Isozaki-Kitada modifiers, and
we prove that the modified wave operators with the above-mentioned
Isozaki-Kitada modifiers exist and that they are complete.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:31:54 GMT""},{""version"":""v2"",""created"":""Mon, 8 May 2023 10:08:59 GMT""}]","2023-05-09"
"2012.00413","Zhengyan Zhang","Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia
  Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng,
  Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu,
  Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun","CPM: A Large-scale Generative Chinese Pre-trained Language Model",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pre-trained Language Models (PLMs) have proven to be beneficial for various
downstream NLP tasks. Recently, GPT-3, with 175 billion parameters and 570GB
training data, drew a lot of attention due to the capacity of few-shot (even
zero-shot) learning. However, applying GPT-3 to address Chinese NLP tasks is
still challenging, as the training corpus of GPT-3 is primarily English, and
the parameters are not publicly available. In this technical report, we release
the Chinese Pre-trained Language Model (CPM) with generative pre-training on
large-scale Chinese training data. To the best of our knowledge, CPM, with 2.6
billion parameters and 100GB Chinese training data, is the largest Chinese
pre-trained language model, which could facilitate several downstream Chinese
NLP tasks, such as conversation, essay generation, cloze test, and language
understanding. Extensive experiments demonstrate that CPM achieves strong
performance on many NLP tasks in the settings of few-shot (even zero-shot)
learning. The code and parameters are available at
https://github.com/TsinghuaAI/CPM-Generate.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:32:56 GMT""}]","2020-12-02"
"2012.00414","Steve Belon","Steve Belon (CEA), Benjamin Erzar (CEA), \'Elodie Kaeshammer (CEA),
  Lionel Borne (ISL)","Influence of the shape of RDX grains on the creation of hot spots by
  mesoscale modeling",,"Europyro - 44th International Pyrotechnics Society Seminar, Jun
  2019, Tours, France",,,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  CEA-Gramat studies the sensitivity of energetic materials to enhance their
security and reliability. The conditions leading to the initiation of an
explosive must be understood to control its sensitivity. According to the hot
spots theory, the shock initiation of heterogeneous explosives is related to
their microstructure: the shock interacts with the heterogeneities of the
microstructure (pores and inclusions, morphology of grains and fragments,
debonding, etc.) and creates local deposits of energy. To describe these hot
spots, energetic materials have to be modeled at a scale allowing the
discretization of their microstructure: the mesoscale. Micro-computed
tomographies of energetic materials are done at CEA-Gramat and analyzed to
build geometric models used in finite element simulations. Two kinds of models
are studied:-Real models are directly built on the real microstructures
extracted from micro-computed tomographies.-Virtual models are based on the
same microstructures but simplified to study independently the effects of
microstructural parameters (granulometry, porosity, filler content{\ldots}) on
the creation of hot spots. Compositions based on different kind of RDX
particles in an inert binder are studied through numerical simulation. The
influence of particle shape on the inert shock response is investigated at the
mesoscale. Local heterogeneities of pressure and temperature fields appear
intimately related to the morphological properties of the microstructures.
Particles with sharp edges create more hot spots than spherical particles.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:33:29 GMT""}]","2020-12-02"
"2012.00415","Zbigniew Palmowski","Onno Boxma, Esther Frostig, and Zbigniew Palmowski","A dual risk model with additive and proportional gains: ruin probability
  and dividends",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a dual risk model with constant expense rate and i.i.d.
exponentially distributed gains $C_i$ ($i=1,2,\dots$) that arrive according to
a renewal process with general interarrival times. We add to this classical
dual risk model the proportional gain feature, that is, if the surplus process
just before the $i$th arrival is at level $u$, then for $a>0$ the capital jumps
up to the level $(1+a)u+C_i$. The ruin probability and the distribution of the
time to ruin are determined. We furthermore identify the value of discounted
cumulative dividend payments, for the case of a Poisson arrival process of
proportional gains. In the dividend calculations, we also consider a random
perturbation of our basic risk process modeled by an independent Brownian
motion with drift.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:34:59 GMT""}]","2020-12-02"
"2012.00416","Uwe Franz","Biswarup Das, Uwe Franz (LMB), Adam Skalski","The RFD and KAC quotients of the Hopf*-algebras of universal orthogonal
  quantum groups",,,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine the Kac quotient and the RFD (residually finite dimensional)
quotient for the Hopf *-algebras associated to universal orthogonal quantum
groups.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:36:08 GMT""}]","2020-12-02"
"2012.00417","Yuyang Zhao","Yuyang Zhao, Zhun Zhong, Fengxiang Yang, Zhiming Luo, Yaojin Lin,
  Shaozi Li, Nicu Sebe","Learning to Generalize Unseen Domains via Memory-based Multi-Source
  Meta-Learning for Person Re-Identification","CVPR 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in person re-identification (ReID) obtain impressive accuracy
in the supervised and unsupervised learning settings. However, most of the
existing methods need to train a new model for a new domain by accessing data.
Due to public privacy, the new domain data are not always accessible, leading
to a limited applicability of these methods. In this paper, we study the
problem of multi-source domain generalization in ReID, which aims to learn a
model that can perform well on unseen domains with only several labeled source
domains. To address this problem, we propose the Memory-based Multi-Source
Meta-Learning (M$^3$L) framework to train a generalizable model for unseen
domains. Specifically, a meta-learning strategy is introduced to simulate the
train-test process of domain generalization for learning more generalizable
models. To overcome the unstable meta-optimization caused by the parametric
classifier, we propose a memory-based identification loss that is
non-parametric and harmonizes with meta-learning. We also present a meta batch
normalization layer (MetaBN) to diversify meta-test features, further
establishing the advantage of meta-learning. Experiments demonstrate that our
M$^3$L can effectively enhance the generalization ability of the model for
unseen domains and can outperform the state-of-the-art methods on four
large-scale ReID datasets.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:38:16 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 11:14:23 GMT""},{""version"":""v3"",""created"":""Fri, 7 May 2021 09:21:53 GMT""}]","2021-05-10"
"2012.00418","Dennis Meier","Erik D. Roede, Aleksander B. Mosberg, Donald M. Evans, Edith Bourret,
  Zewu Yan, Antonius T. J. van Helvoort, and Dennis Meier","Contact-free reversible switching of improper ferroelectric domains by
  electron and ion irradiation",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Focused ion beam (FIB) and scanning electron microscopy (SEM) are used to
reversibly switch improper ferroelectric domains in the hexagonal manganite
ErMnO$_3$. Surface charging is achieved by local ion (positive charging) and
electron (positive and negative charging) irradiation, which allows controlled
polarization switching without the need for electrical contacts. Polarization
cycling reveals that the domain walls tend to return to the equilibrium
configuration obtained in the as-grown state. The electric field response of
sub-surface domains is studied by FIB cross-sectioning, revealing the 3D
switching behavior. The results clarify how the polarization reversal in
hexagonal manganites progresses at the level of domains, resolving both domain
wall movements and the nucleation and growth of new domains. Our FIB-SEM based
switching approach is applicable to all ferroelectrics where a sufficiently
large electric field can be built up via surface charging, facilitating
contact-free high-resolution studies of the domain and domain wall response to
electric fields in 3D.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:38:47 GMT""}]","2020-12-02"
"2012.00419","Wiebke Toussaint","Wiebke Toussaint and Aaron Yi Ding","Machine Learning Systems in the IoT: Trustworthiness Trade-offs for Edge
  Intelligence","In Proceedings of the Second International Conference on Cognitive
  Machine Intelligence (CogMI 2020)",,"10.1109/CogMI50398.2020.00030",,"cs.LG cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning systems (MLSys) are emerging in the Internet of Things (IoT)
to provision edge intelligence, which is paving our way towards the vision of
ubiquitous intelligence. However, despite the maturity of machine learning
systems and the IoT, we are facing severe challenges when integrating MLSys and
IoT in practical context. For instance, many machine learning systems have been
developed for large-scale production (e.g., cloud environments), but IoT
introduces additional demands due to heterogeneous and resource-constrained
devices and decentralized operation environment. To shed light on this
convergence of MLSys and IoT, this paper analyzes the trade-offs by covering
the latest developments (up to 2020) on scaling and distributing ML across
cloud, edge, and IoT devices. We position machine learning systems as a
component of the IoT, and edge intelligence as a socio-technical system. On the
challenges of designing trustworthy edge intelligence, we advocate a holistic
design approach that takes multi-stakeholder concerns, design requirements and
trade-offs into consideration, and highlight the future research opportunities
in edge intelligence.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:42:34 GMT""}]","2021-06-18"
"2012.00420","Tomohito Tanaka Mr","Tomohito Tanaka, Nozomu Nakamura, Angus J. Wilkinson","High resolution electron backscatter diffraction study on the
  heterogeneities of tetragonal distortion in Fe-C martensite at the
  microstructural scale",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The spatial variation in martensite tetragonality (c/a ratio) in Fe-0.77C
(wt.%) alloy was investigated by means of pattern matching of electron
backscatter diffraction patterns combined with high angular resolution electron
backscatter diffraction analysis. It was found that the c/a ratio varies within
a martensite block and between blocks. The c/a variation within a block is
particularly evident in the vicinity of grain boundaries and shear strains are
also present in addition to tetragonal distortion. The c/a variation between
blocks is more apparent than that within a block. The lattice parameter
frequency profile predicted by our approach well matches with the X-ray
diffraction profile from the same material by assuming reasonable residual
strain acting on a- and b-axes. The heterogeneities of the crystal distortion
are brought by a decrease and scatter in solid solution carbon and in carbon
ordering as a result of the martensite transformation sequence as well as
heterogeneous residual strain.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:43:42 GMT""}]","2020-12-02"
"2012.00421","Ludovic Bellon","Basile Pottier (Phys-ENS), Felipe Aguilar, Micka\""el Geitner
  (Phys-ENS), Francisco Melo, Ludovic Bellon (Phys-ENS)","Silicon cantilevers locally heated from 300K up to the melting point:
  temperature profile measurement from their resonances frequency shift",,"Journal of Applied Physics, American Institute of Physics, 2021,
  129, pp.184503","10.1063/5.0040733",,"cond-mat.mtrl-sci cond-mat.stat-mech physics.class-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When heated, micro-resonators present a shift of their resonance frequencies.
We study specifically silicon cantilevers heated locally by laser absorption,
and evaluate theoretically and experimentally their temperature profile and its
interplay with the mechanical resonances. We present a enhanced version of our
earlier model [F. Aguilar Sandoval et al., J. Appl. Phys. 117, 234503 (2015)]
including both elasticity and geometry temperature dependency, showing that the
latter can account for 20% of the observed shift for the first flexural mode.
The temperature profile description takes into account thermal clamping
conditions, radiation at high temperature, and lower conductivity than bulk
silicon due to phonon confinement. Thanks to a space-power equivalence in the
heat equation, scanning the heating point along the cantilever directly reveals
the temperature profile. Finally, frequency shift measurement can be used to
infer the temperature field with a few percent precision.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:45:08 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 14:09:53 GMT""}]","2021-06-02"
"2012.00422","Young-Pil Choi","Young-Pil Choi, Oliver Tse","Quantified overdamped limit for kinetic Vlasov-Fokker-Planck equations
  with singular interaction forces",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish a quantitfied overdamped limit for kinetic Vlasov-Fokker-Planck
equations with nonlocal interaction forces. We provide explicit bounds on the
error between solutions of that kinetic equation and the limiting equation,
which is known under the names of aggregation-diffusion equation or
McKean-Vlasov equation. Introducing an intermediate system via a
coarse-graining map, we quantitatively estimate the error between the spatial
densities of the Vlasov-Fokker-Planck equation and the intermediate system in
the Wasserstein distance of order 2. We then derive an
evolution-variational-like inequality for Wasserstein gradient flows which
allows us to quantify the error between the intermediate system and the
corresponding limiting equation. Our strategy only requires weak integrability
of the interaction potentials, thus in particular it includes the quantified
overdamped limit of the kinetic Vlasov-Poisson-Fokker-Planck system to the
aggregation-diffusion equation with either repulsive electrostatic or
attractive gravitational interactions.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:45:09 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 23:40:19 GMT""}]","2021-06-01"
"2012.00423","Tom S\""uhr","Tom S\""uhr, Sophie Hilgard, Himabindu Lakkaraju","Does Fair Ranking Improve Minority Outcomes? Understanding the Interplay
  of Human and Algorithmic Biases in Online Hiring",,,,,"cs.LG cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ranking algorithms are being widely employed in various online hiring
platforms including LinkedIn, TaskRabbit, and Fiverr. Prior research has
demonstrated that ranking algorithms employed by these platforms are prone to a
variety of undesirable biases, leading to the proposal of fair ranking
algorithms (e.g., Det-Greedy) which increase exposure of underrepresented
candidates. However, there is little to no work that explores whether fair
ranking algorithms actually improve real world outcomes (e.g., hiring
decisions) for underrepresented groups. Furthermore, there is no clear
understanding as to how other factors (e.g., job context, inherent biases of
the employers) may impact the efficacy of fair ranking in practice. In this
work, we analyze various sources of gender biases in online hiring platforms,
including the job context and inherent biases of employers and establish how
these factors interact with ranking algorithms to affect hiring decisions. To
the best of our knowledge, this work makes the first attempt at studying the
interplay between the aforementioned factors in the context of online hiring.
We carry out a largescale user study simulating online hiring scenarios with
data from TaskRabbit, a popular online freelancing site. Our results
demonstrate that while fair ranking algorithms generally improve the selection
rates of underrepresented minorities, their effectiveness relies heavily on the
job contexts and candidate profiles.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:45:27 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 09:31:51 GMT""}]","2021-04-09"
"2012.00424","Mengbiao Zhao","Mengbiao Zhao, Wei Feng, Fei Yin, Xu-Yao Zhang, Cheng-Lin Liu","Weakly-Supervised Arbitrary-Shaped Text Detection with
  Expectation-Maximization Algorithm",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Arbitrary-shaped text detection is an important and challenging task in
computer vision. Most existing methods require heavy data labeling efforts to
produce polygon-level text region labels for supervised training. In order to
reduce the cost in data labeling, we study weakly-supervised arbitrary-shaped
text detection for combining various weak supervision forms (e.g., image-level
tags, coarse, loose and tight bounding boxes), which are far easier for
annotation. We propose an Expectation-Maximization (EM) based weakly-supervised
learning framework to train an accurate arbitrary-shaped text detector using
only a small amount of polygon-level annotated data combined with a large
amount of weakly annotated data. Meanwhile, we propose a contour-based
arbitrary-shaped text detector, which is suitable for incorporating
weakly-supervised learning. Extensive experiments on three arbitrary-shaped
text benchmarks (CTW1500, Total-Text and ICDAR-ArT) show that (1) using only
10% strongly annotated data and 90% weakly annotated data, our method yields
comparable performance to state-of-the-art methods, (2) with 100% strongly
annotated data, our method outperforms existing methods on all three
benchmarks. We will make the weakly annotated datasets publicly available in
the future.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:45:39 GMT""}]","2020-12-02"
"2012.00425","Shashi Raj Pandey","Shashi Raj Pandey, Minh N.H. Nguyen, Tri Nguyen Dang, Nguyen H. Tran,
  Kyi Thar, Zhu Han, Choong Seon Hong","Edge-assisted Democratized Learning Towards Federated Analytics","Accepted for publication in IEEE Internet of Things Journal",,"10.1109/JIOT.2021.3085429",,"cs.LG cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A recent take towards Federated Analytics (FA), which allows analytical
insights of distributed datasets, reuses the Federated Learning (FL)
infrastructure to evaluate the summary of model performances across the
training devices. However, the current realization of FL adopts single
server-multiple client architecture with limited scope for FA, which often
results in learning models with poor generalization, i.e., an ability to handle
new/unseen data, for real-world applications. Moreover, a hierarchical FL
structure with distributed computing platforms demonstrates incoherent model
performances at different aggregation levels. Therefore, we need to design a
robust learning mechanism than the FL that (i) unleashes a viable
infrastructure for FA and (ii) trains learning models with better
generalization capability. In this work, we adopt the novel democratized
learning (Dem-AI) principles and designs to meet these objectives. Firstly, we
show the hierarchical learning structure of the proposed edge-assisted
democratized learning mechanism, namely Edge-DemLearn, as a practical framework
to empower generalization capability in support of FA. Secondly, we validate
Edge-DemLearn as a flexible model training mechanism to build a distributed
control and aggregation methodology in regions by leveraging the distributed
computing infrastructure. The distributed edge computing servers construct
regional models, minimize the communication loads, and ensure distributed data
analytic application's scalability. To that end, we adhere to a near-optimal
two-sided many-to-one matching approach to handle the combinatorial constraints
in Edge-DemLearn and solve it for fast knowledge acquisition with optimization
of resource allocation and associations between multiple servers and devices.
Extensive simulation results on real datasets demonstrate the effectiveness of
the proposed methods.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:46:03 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 03:08:31 GMT""},{""version"":""v3"",""created"":""Mon, 31 May 2021 06:34:12 GMT""}]","2021-06-01"
"2012.00426","Judith Korth","J. Korth, A. Moharana, M. Pe\v{s}ta, D.R. Czavalinga, K.E. Conroy","Consequences of parameterization choice on eclipsing binary light curve
  solutions","The paper presents the results of a project carried out at the
  ERASMUS+ GATE summer school and is accepted for publication in CAOSP",,"10.31577/caosp.2021.51.1.58",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Eclipsing Binaries (EBs) are known to be the source of most accurate stellar
parameters, which are important for testing theories of stellar evolution. With
improved quality and quantity of observations using space telescopes like {\it
TESS}, there is an urgent need for accuracy in modeling to obtain precise
parameters. We use the soon to be released \texttt{PHOEBE 2.3} EB modeling
package to test the robustness and accuracy of parameters and their dependency
on choice of parameters for optimization.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:56:21 GMT""}]","2021-02-10"
"2012.00427","Kevin Boucher","Kevin Boucher","Limits of complementary series, special representations and cohomology
  of CAT(-1) groups","arXiv admin note: text overlap with arXiv:2007.15369",,,,"math.GR math.DS math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we extend the construction of special representations to
convex-cocompact isometry groups of CAT(-1) spaces which admits complementary
series. We prove that these limits of complementary series have a natural
non-vanishing reduced cohomology class [c]. As a by product we generalize Kuhn
Vershik formula and characterize geometrically CAT(-1) groups that admit
complementary series. Investigating dynamical properties of the cohomology
class [c] we prove an cocycle equidistribution theorem \`a la Roblin-Margulis
and deduce the irreducibility of the associated affine actions. The
constructions and results apply beyond the class of rank 1 linear groups where
the irreducibility of the affine actions associated to the canonical class [c],
even in the case of uniform lattices in SO(n,1), SU(n,1) or SL2(Qp) with n>1
and p prime, had not been established.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:57:11 GMT""}]","2020-12-02"
"2012.00428","Jure Brence","Jure Brence and Ljup\v{c}o Todorovski and Sa\v{s}o D\v{z}eroski","Probabilistic Grammars for Equation Discovery","Submitted to Knowledge-Based Systems, Elsevier. 28 pages + 13 pages
  appendix. 7 figures",,"10.1016/j.knosys.2021.107077",,"cs.LG cs.FL stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Equation discovery, also known as symbolic regression, is a type of automated
modeling that discovers scientific laws, expressed in the form of equations,
from observed data and expert knowledge. Deterministic grammars, such as
context-free grammars, have been used to limit the search spaces in equation
discovery by providing hard constraints that specify which equations to
consider and which not. In this paper, we propose the use of probabilistic
context-free grammars in equation discovery. Such grammars encode soft
constraints, specifying a prior probability distribution on the space of
possible equations. We show that probabilistic grammars can be used to
elegantly and flexibly formulate the parsimony principle, that favors simpler
equations, through probabilities attached to the rules in the grammars. We
demonstrate that the use of probabilistic, rather than deterministic grammars,
in the context of a Monte-Carlo algorithm for grammar-based equation discovery,
leads to more efficient equation discovery. Finally, by specifying prior
probability distributions over equation spaces, the foundations are laid for
Bayesian approaches to equation discovery.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:59:19 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 10:53:27 GMT""}]","2021-04-29"
"2012.00429","Manuel Dibak","Manuel Dibak, Leon Klein and Frank No\'e","Temperature-steerable flows",,,,,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Boltzmann generators approach the sampling problem in many-body physics by
combining a normalizing flow and a statistical reweighting method to generate
samples of a physical system's equilibrium density. The equilibrium
distribution is usually defined by an energy function and a thermodynamic
state, such as a given temperature. Here we propose temperature-steerable flows
(TSF) which are able to generate a family of probability densities parametrized
by a choosable temperature parameter. TSFs can be embedded in a generalized
ensemble sampling framework such as parallel tempering in order to sample a
physical system across thermodynamic states, such as multiple temperatures.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:00:34 GMT""}]","2020-12-02"
"2012.00430","Khansa Rasheed","Khansa Rasheed, Junaid Qadir, Terence J.O'Brien, Levin Kuhlmann, Adeel
  Razi","A Generative Model to Synthesize EEG Data for Epileptic Seizure
  Prediction","10 pages, 5 figures, 6 Tables, Journal paper",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Prediction of seizure before they occur is vital for bringing normalcy to the
lives of patients. Researchers employed machine learning methods using
hand-crafted features for seizure prediction. However, ML methods are too
complicated to select the best ML model or best features. Deep Learning methods
are beneficial in the sense of automatic feature extraction. One of the
roadblocks for accurate seizure prediction is scarcity of epileptic seizure
data. This paper addresses this problem by proposing a deep convolutional
generative adversarial network to generate synthetic EEG samples. We use two
methods to validate synthesized data namely, one-class SVM and a new proposal
which we refer to as convolutional epileptic seizure predictor (CESP). Another
objective of our study is to evaluate performance of well-known deep learning
models (e.g., VGG16, VGG19, ResNet50, and Inceptionv3) by training models on
augmented data using transfer learning with average time of 10 min between true
prediction and seizure onset. Our results show that CESP model achieves
sensitivity of 78.11% and 88.21%, and FPR of 0.27/h and 0.14/h for training on
synthesized and testing on real Epilepsyecosystem and CHB-MIT datasets,
respectively. Effective results of CESP trained on synthesized data shows that
synthetic data acquired the correlation between features and labels very well.
We also show that employment of idea of transfer learning and data augmentation
in patient-specific manner provides highest accuracy with sensitivity of 90.03%
and 0.03 FPR/h which was achieved using Inceptionv3, and that augmenting data
with samples generated from DCGAN increased prediction results of our CESP
model and Inceptionv3 by 4-5% as compared to state-of-the-art traditional
augmentation techniques. Finally, we note that prediction results of CESP
achieved by using augmented data are better than chance level for both
datasets.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:00:36 GMT""}]","2020-12-02"
"2012.00431","Antonio Alex-Amor","Antonio Alex-Amor, Francisco Mesa, \'Angel Palomares-Caballero, Carlos
  Molero, Pablo Padilla","Exploring the Potentials of the Multi-modal Equivalent Circuit Approach
  for Stacks of 2-D Aperture Arrays","15 pages, 12 figures, IEEE Transactions on Antennas and Propagation",,"10.1109/TAP.2021.3070150",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many frequency selective surface (FSS) structures are based on the use of a
single periodic array of slot/apertures in a conducting sheet embedded in a
layered medium. However, it is well known that stacking several conducting
sheets and breaking the alignment of the stack can bring multiple benefits to
the structure. In this paper, the analysis and design of stacks of 2-D aperture
arrays are carried out by exploiting as much as possible all the potentialities
of a rigorous and systematic formulation based on the multi-modal equivalent
circuit approach (ECA). A key feature of the formulation is that linear
transformations between the apertures of adjacent plates (rotation,
translation, and scaling) can be dealt with from a purely analytical
perspective. This fact is of potential interest for many practical
applications, such as the design of polarization converters, absorbers,
filters, and thin matching layers. When the apertures have an arbitrary
geometry, it can be applied a hybrid approach that combines the ability of
commercial simulators to handle arbitrary geometries with the fast computation
times and physical insight of the ECA. In general, either the purely analytical
or the hybrid approach can be applied in those many practical scenarios where
the spatial profile of the electric field on the considered apertures hardly
changes with frequency. As an additional feature of the approach, the
dispersion properties (phase/attenuation constants and Bloch impedance) of
infinite periodic stacks can be derived and, in particular, analytical
expressions for mirror- and glide-symmetric configurations are provided.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:00:58 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 12:12:06 GMT""}]","2021-04-13"
"2012.00432","Michael Wiemeler","Johannes Ebert, Michael Wiemeler","On the homotopy type of the space of metrics of positive scalar
  curvature","final version, to appear in J. Eur. Math. Soc",,,,"math.DG math.AT math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $M^d$ be a simply connected spin manifold of dimension $d \geq 5$
admitting Riemannian metrics of positive scalar curvature. Denote by
$\mathcal{R}^+(M^d)$ the space of such metrics on $M^d$. We show that
$\mathcal{R}^+(M^d)$ is homotopy equivalent to $\mathcal{R}^+(S^d)$, where
$S^d$ denotes the $d$-dimensional sphere with standard smooth structure.
  We also show a similar result for simply connected non-spin manifolds $M^d$
with $d\geq 5$ and $d\neq 8$. In this case let $W^d$ be the total space of the
non-trivial $S^{d-2}$-bundle with structure group $SO(d-1)$ over $S^2$. Then
$\mathcal{R}^+(M^d)$ is homotopy equivalent to $\mathcal{R}^+(W^d)$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:02:32 GMT""},{""version"":""v2"",""created"":""Thu, 3 Mar 2022 17:38:26 GMT""}]","2022-03-04"
"2012.00433","Yao Hu","Yao Hu, Guohua Geng, Kang Li, Wei Zhou","Unsupervised Segmentation for Terracotta Warrior Point Cloud (SRG-Net)",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  The repairing work of terracotta warriors in Emperor Qinshihuang Mausoleum
Site Museum is handcrafted by experts, and the increasing amounts of unearthed
pieces of terracotta warriors make the archaeologists too challenging to
conduct the restoration of terracotta warriors efficiently. We hope to segment
the 3D point cloud data of the terracotta warriors automatically and store the
fragment data in the database to assist the archaeologists in matching the
actual fragments with the ones in the database, which could result in higher
repairing efficiency of terracotta warriors. Moreover, the existing 3D neural
network research is mainly focusing on supervised classification, clustering,
unsupervised representation, and reconstruction. There are few pieces of
researches concentrating on unsupervised point cloud part segmentation. In this
paper, we present SRG-Net for 3D point clouds of terracotta warriors to address
these problems. Firstly, we adopt a customized seed-region-growing algorithm to
segment the point cloud coarsely. Then we present a supervised segmentation and
unsupervised reconstruction networks to learn the characteristics of 3D point
clouds. Finally, we combine the SRG algorithm with our improved CNN(convolution
neural network) using a refinement method. This pipeline is called SRG-Net,
which aims at conducting segmentation tasks on the terracotta warriors. Our
proposed SRG-Net is evaluated on the terracotta warrior data and ShapeNet
dataset by measuring the accuracy and the latency. The experimental results
show that our SRG-Net outperforms the state-of-the-art methods. Our code is
available at https://github.com/hyoau/SRG-Net.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:02:55 GMT""},{""version"":""v2"",""created"":""Sun, 27 Mar 2022 10:23:29 GMT""}]","2022-03-29"
"2012.00434","Fabio Schittler Neves","Fabio Schittler Neves and Marc Timme","Reconfigurable Computation in Spiking Neural Networks",,"IEEE Access, vol. 8, pp. 179648-179655, 2020","10.1109/ACCESS.2020.3027966",,"nlin.AO","http://creativecommons.org/licenses/by/4.0/","  The computation of rank ordering plays a fundamental role in cognitive tasks
and offers a basic building block for computing arbitrary digital functions.
Spiking neural networks have been demonstrated to be capable of identifying the
largest k out of N analog input signals through their collective nonlinear
dynamics. By finding partial rank orderings, they perform k-winners-take-all
computations. Yet, for any given study so far, the value of k is fixed, often
to k equal one. Here we present a concept for spiking neural networks that are
capable of (re)configurable computation by choosing k via one global system
parameter. The spiking network acts via pulse-suppression induced by inhibitory
pulse-couplings. Couplings are proportional to each units' state variable
(neuron voltage), constituting an uncommon but straightforward type of leaky
integrate-and-fire neural network. The result of a computation is encoded as a
stable periodic orbit with k units spiking at some frequency and others at
lower frequency or not at all. Orbit stability makes the resulting
analog-to-digital computation robust to sufficiently small variations of both,
parameters and signals. Moreover, the computation is completed quickly within a
few spike emissions per neuron. These results indicate how reconfigurable
k-winners-take-all computations may be implemented and effectively exploited in
simple hardware relying only on basic dynamical units and spike interactions
resembling simple current leakages to a common ground.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:03:54 GMT""}]","2020-12-02"
"2012.00435","QiZhi Li","Q. Z. Li, P. Elliott, J. K. Dewhurst, S. Sharma, S. Shallcross","Ab-intio study of ultrafast charge dynamics in graphene",,"Phys. Rev. B 103, 081102 (2021)","10.1103/PhysRevB.103.L081102",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.other quant-ph","http://creativecommons.org/licenses/by/4.0/","  Monolayer graphene provides an ideal material to explore one of the
fundamental light-field driven interference effects: Landau-Zener-St\""uckelberg
interference. However, direct observation of the resulting interference
patterns in momentum space has not proven possible, with
Landau-Zener-St\""uckelberg interference observed only indirectly through
optically induced residual currents. Here we show that the transient electron
momentum density (EMD), an object that can easily be obtained in experiment,
provides an excellent description of momentum resolved charge excitation. We
employ state-of-the-art time-dependent density function theory calculations,
demonstrating by direct comparison of EMD with conduction band occupancy,
obtained from projecting the time propagated wavefunction onto the ground
state, that the two quantities are in excellent agreement. For even the most
intense laser pulses we find that the electron dynamics to be almost completely
dominated by the $\pi$-band, with transitions to other bands strongly
suppressed. Simple model based tight-binding approaches can thus be expected to
provide an excellent description for the laser induced electron dynamics in
graphene.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:06:39 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 12:16:17 GMT""}]","2021-02-10"
"2012.00436","Peter Jakob","Peter Jakob and Sebastian Thussing","Vibrational Frequency used as Internal Clock Reference to access
  Molecule -- Metal Charge Transfer Times","11 pages, 3 figures","Phys. Rev. Lett. 126, 116801 (2021)","10.1103/PhysRevLett.126.116801",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamical charge transfer processes at molecule-metal interfaces proceed in
the few fs time scale that renders them highly relevant to electronic
excitations in optoelectronic devices. Yet, knowledge thereof is limited when
electronic ground state situations are considered that implicate charge
transfer directly at the fermi energy. Here we show that such processes can be
accessed by means of vibrational excitations, with non-adiabatic
electron-vibron coupling leading to distinct asymmetric line shapes. Thereby
the characteristic time scale of this interfacial dynamical charge transfer can
be derived by using the vibrational oscillation period as an internal clock
reference.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:09:41 GMT""}]","2021-03-24"
"2012.00437","Peng Peng","Peng Peng, Yong-Jie Li","A Unified Structure for Efficient RGB and RGB-D Salient Object Detection","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Salient object detection (SOD) has been well studied in recent years,
especially using deep neural networks. However, SOD with RGB and RGB-D images
is usually treated as two different tasks with different network structures
that need to be designed specifically. In this paper, we proposed a unified and
efficient structure with a cross-attention context extraction (CRACE) module to
address both tasks of SOD efficiently. The proposed CRACE module receives and
appropriately fuses two (for RGB SOD) or three (for RGB-D SOD) inputs. The
simple unified feature pyramid network (FPN)-like structure with CRACE modules
conveys and refines the results under the multi-level supervisions of saliency
and boundaries. The proposed structure is simple yet effective; the rich
context information of RGB and depth can be appropriately extracted and fused
by the proposed structure efficiently. Experimental results show that our
method outperforms other state-of-the-art methods in both RGB and RGB-D SOD
tasks on various datasets and in terms of most metrics.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:12:03 GMT""}]","2020-12-02"
"2012.00438","Zeren Simon Wang","Sourav Dey, Claudio O. Dib, Juan Carlos Helo, Minakshi Nayak,
  Nicol\'as A. Neill, Abner Soffer, Zeren Simon Wang","Long-lived light neutralinos at Belle II","v1, 15 pages plus appendices, 6 figures, 3 tables; v2, minor changes,
  matched with the published version",,"10.1007/JHEP02(2021)211","APCTP-Pre2020-028","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider light neutralinos of mass about 1 GeV, produced from $\tau$
lepton rare decays at Belle II, in the context of R-parity-violating (RPV)
supersymmetry. With large and clean samples of $\tau$ leptons produced at the
Belle II experiment, excellent sensitivity to such light neutralinos with the
exotic signatures of displaced vertices is expected. We focus on two benchmark
scenarios of single RPV operators, $\lambda'_{311} L_3 Q_1 \bar{D}_1$ and
$\lambda'_{312} L_3 Q_1 \bar{D}_2$, which induce both the production and decay
of the lightest neutralino. For the reconstruction of a displaced vertex, we
require at least two charged pions in the final states. We perform Monte-Carlo
simulations for both signal and background events, and find that Belle II can
explore regions in the parameter space competitive with other probes. In
particular, for the $\lambda'_{311}$ scenario, it can put limits up to two
orders of magnitude stronger than the current bounds.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:15:20 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 10:58:58 GMT""}]","2021-03-17"
"2012.00439","Kazuki Yokomizo","Kazuki Yokomizo, Shuichi Murakami","Non-Bloch band theory in bosonic Bogoliubov-de Gennes systems","9 pages, 3 figures","Phys. Rev. B 103, 165123 (2021)","10.1103/PhysRevB.103.165123",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  In recent research, it has been shown that non-Hermitian systems exhibit
sensitivity to boundaries, and it is caused by the non-Hermitian skin effect.
In this work, we construct the non-Bloch band theory in bosonic Bogoliubov--de
Gennes (BdG) systems. From our theory, we can calculate the generalized
Brillouin zone and the energy spectrum in such systems with open boundary
conditions in the thermodynamic limit, and we can thus discuss its
non-Hermitian nature, despite Hermiticity of an original Hamiltonian. In fact,
we find that the bosonic Kitaev-Majorana chain exhibits rich aspects of the
non-Hermitian skin effect, such as instability against infinitesimal
perturbations and reentrant behavior, in terms of the non-Bloch band theory.
This result indicates that our theory is powerful tool for studying
non-Hermitian nature in bosonic BdG systems.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:21:17 GMT""},{""version"":""v2"",""created"":""Fri, 23 Apr 2021 03:49:59 GMT""}]","2021-04-28"
"2012.00440","Junsheng Fang","Xinyan Cao, Junsheng Fang, Zhaolin Yao","On finite sums of projections and Dixmier's averaging theorem for type
  ${\rm II}_1$ factors","In this new version, some typos are corrected",,,,"math.OA","http://creativecommons.org/licenses/by/4.0/","  Let $\mathcal{M}$ be a type ${\rm II_1}$ factor and let $\tau$ be the
faithful normal tracial state on $\mathcal{M}$. In this paper, we prove that
given an $X \in \mathcal{M}$, $X=X^*$, then there is a decomposition of the
identity into $N \in \mathbb{N}$ mutually orthogonal nonzero projections
$E_j\in\mathcal{M}$, $I=\sum_{j=1}^NE_j$, such that $E_jXE_j=\tau(X) E_j$ for
all $j=1,\cdots,N$. Equivalently, there is a unitary operator $U \in
\mathcal{M}$ with $U^N=I$ and
$\frac{1}{N}\sum_{j=0}^{N-1}{U^*}^jXU^j=\tau(X)I.$ As the first application, we
prove that a positive operator $A\in \mathcal{M}$ can be written as a finite
sum of projections in $\mathcal{M}$ if and only if $\tau(A)\geq \tau(R_A)$,
where $R_A$ is the range projection of $A$. This result answers affirmatively
Question 6.7 of [9]. As the second application, we show that if $X\in
\mathcal{M}$, $X=X^*$ and $\tau(X)=0$, then there exists a nilpotent element $Z
\in \mathcal{M}$ such that $X$ is the real part of $Z$. This result answers
affirmatively Question 1.1 of [4]. As the third application, we show that let
$X_1,\cdots,X_n\in \mathcal{M}$. Then there exist unitary operators
$U_1,\cdots,U_k\in\mathcal{M}$ such that
$\frac{1}{k}\sum_{i=1}^kU_i^{-1}X_jU_i=\tau(X_j)I,\quad \forall 1\leq j\leq n$.
This result is a stronger version of Dixmier's averaging theorem for type ${\rm
II}_1$ factors.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:21:58 GMT""},{""version"":""v2"",""created"":""Sun, 16 May 2021 07:11:42 GMT""}]","2021-05-18"
"2012.00441","Henri Guenancia","Benjamin Bakker and Henri Guenancia and Christian Lehn","Algebraic approximation and the decomposition theorem for K\""ahler
  Calabi-Yau varieties","v2: Minor inaccuracies corrected, main results unchanged. v3:
  Exposition improved, final version, to appear in Invent. Math",,,,"math.AG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the decomposition theorem for numerically $K$-trivial varieties
with log terminal singularities to the K\""ahler setting. Along the way we prove
that all such varieties admit a strong locally trivial algebraic approximation,
thus completing the numerically $K$-trivial case of a conjecture of Campana and
Peternell.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:26:54 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 15:22:43 GMT""},{""version"":""v3"",""created"":""Wed, 26 Jan 2022 09:44:32 GMT""}]","2022-01-27"
"2012.00442","Susmita Bhaduri","Susmita Bhaduri and Anirban Bhaduri","Analysis of Prospective Super-Symmetry Inherent in the $pp$ Collision
  Data at $7$ TeV from CMS Collaboration Using Novel Two-Dimensional
  Multifractal-Detrended Fluctuation Analysis Method with Rectangular Scale",,,,,"hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  Search for SUSY in HEP is of enormous interest for the past few decades.
Continuous searches were conducted at LHC regarding SUSY for prompt,
non-prompt, R-parity conserving and violating generation and decays. The limits
obtained from these analysis to detect the signatures of SUSY particles,
revealed greater possibilities of such experiments in collider. These
signatures are usually derived assuming a bit optimistic conditions of the
decaying process of s-particles to final-states. Moreover, SUSY might have been
in a disguised state in lower-mass scales resulting from challenging
mass-spectra and mixed-modes of decays. The proposed chaos-based, novel method
of 2D-Multifractal-Detrended-Fluctuation-Analysis(2D-MF-DFA), is extended using
rectangular scale. The experimental data-surfaces are constructed using the
component-space(in the X,Y,Z co-ordinates) taken out from the 4-momenta of
final-state-signatures of the produced di-muons from the selected events. Two
publicly-available datasets are used here. First is the data from MultiJet
primary pp collision-data from RunB(2010) at 7TeV, used in analysis of the SUSY
with Razor-variables. Second is the data from primary dataset of pp collisions
at 7TeV from RunA(2011) of CMS-collaboration. The 2D-MF behaviour of particle
production process is studied in terms of symmetry-scaling, the inherent
scale-freeness and multifractality. The analysis outcome for SUSY data is
compared with the same for the non-SUSY data in terms of the generalized
Hurst-exponent and 2D-MF spectrum width. Significantly different scaling
behaviour and long-range correlation is observed between the
final-state-signatures of the di-lepton production-process of the first and
second datasets. This difference may indicate a possible signature of SUSY
which may be missed in the conventional method of analysing the
invariant-mass/transverse-momentum-spectrum.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:29:46 GMT""}]","2020-12-02"
"2012.00443","Luca Gallo","Luca Gallo, Mattia Frasca, Vito Latora, Giovanni Russo","Lack of practical identifiability may hamper reliable predictions in
  COVID-19 epidemic models",,,,,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Compartmental models are widely adopted to describe and predict the spreading
of infectious diseases. The unknown parameters of such models need to be
estimated from the data. Furthermore, when some of the model variables are not
empirically accessible, as in the case of asymptomatic carriers of COVID-19,
they have to be obtained as an outcome of the model. Here, we introduce a
framework to quantify how the uncertainty in the data impacts the determination
of the parameters and the evolution of the unmeasured variables of a given
model. We illustrate how the method is able to characterize different regimes
of identifiability, even in models with few compartments. Finally, we discuss
how the lack of identifiability in a realistic model for COVID-19 may prevent
reliable forecasting of the epidemic dynamics.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:34:30 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jan 2021 11:04:33 GMT""}]","2021-01-18"
"2012.00444","Arlene K. H. Kim","Arlene K. H. Kim, Adityanand Guntuboyina","Minimax bounds for estimating multivariate Gaussian location mixtures",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  We prove minimax bounds for estimating Gaussian location mixtures on
$\mathbb{R}^d$ under the squared $L^2$ and the squared Hellinger loss
functions. Under the squared $L^2$ loss, we prove that the minimax rate is
upper and lower bounded by a constant multiple of $n^{-1}(\log n)^{d/2}$. Under
the squared Hellinger loss, we consider two subclasses based on the behavior of
the tails of the mixing measure. When the mixing measure has a sub-Gaussian
tail, the minimax rate under the squared Hellinger loss is bounded from below
by $(\log n)^{d}/n$. On the other hand, when the mixing measure is only assumed
to have a bounded $p^{\text{th}}$ moment for a fixed $p > 0$, the minimax rate
under the squared Hellinger loss is bounded from below by $n^{-p/(p+d)}(\log
n)^{-3d/2}$. These rates are minimax optimal up to logarithmic factors.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:35:45 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 04:06:01 GMT""}]","2021-05-20"
"2012.00445","Holger Frits Bech Nielsen","Holger Bech Nielsen (Niels Bohr Institutet, giving the talk) and Colin
  D. Froggatt (Glasgow University)","Dark Matter Macroscopic Pearls, 3.55 keV X-ray line, How big ?","A parameter l dropped out after slight miscalculaton correction. A
  previous misreading of the Jeltema Profumo work corrected",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the 3.55 keV X-ray suspected to arise from dark matter in our model
of dark matter consisting of a bubble of a new phase of the vacuum, the surface
tension of which keeps ordinary matter under high pressure inside the bubble.
We consider two versions of the model:
  Old large pearls model :
  We worked for a long time on a pearl picture with pearl / bubbles of cm-size
adjusted so that the impacts of them on earth could be identified with events
of the mysterious type that happened in Tunguska in 1908. We fit both the very
frequency, the 3.55 keV, and the overall intensity of the X-ray line coming
from the center of the Milky Way and from galaxy clusters with one parameter in
the model in which this radiation comes from collisions of pearls.
  New small pearl model:
  Our latest idea is to let the pearls be smaller than atoms but bigger than
nuclei so as to manage to fit the 3.5 keV X-rays coming from the Tycho
supernova remnant in which Jeltema and Profumo observed this line. Further we
also crudely fit the DAMA-LIBRA observation with the small pearls, and even see
a possibility for including the electron-recoil-excess seen by the Xenon1T
experiment as being due to de-excitation via electron emission of our pearls.
The important point of even our small size pearl model is that the cross
section of our ""macroscopic"" pearls is so large that the pearls interact
several times in the shielding but, due to their much larger mass than the
typical nuclei, are {\bf not stopped by only a few interactions}. Nevertheless
only a minute fraction of the relatively strongly interacting pearls reach the
1400 m down to the DAMA experiment, but due to the higher cross section we can
fit the data anyway.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:36:05 GMT""},{""version"":""v2"",""created"":""Fri, 4 Dec 2020 22:21:28 GMT""},{""version"":""v3"",""created"":""Tue, 19 Jan 2021 09:35:09 GMT""},{""version"":""v4"",""created"":""Sat, 20 Feb 2021 09:35:44 GMT""}]","2021-02-23"
"2012.00446","Judit Murak\""ozy","Judit Murak\""ozy","On the Decay of Sunspot Groups and Their Internal Parts in Detail","14 pages, 9 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abcfba",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The decay of sunspot groups is a relatively unknown field since most studies
have focused mainly on the decay of sunspots or sunspot groups, but only on
small samples. As an extension of the recent work of
\citet{2020ApJ...892..107M} which is based on a large verified sample, this
study investigates not only the long-term behavior of the decay of sunspot
groups but also the dynamics of their parts. The aim of the present work is to
search for dependencies of the decay process in order to find physical
conditions that modify or contribute to the decay. The investigations are based
on the catalog of SoHO Debrecen Sunspot Database (SDD ) and the Greenwich
Photoheliographic Results (GPR) as well as the Debrecen Photoheliographic Data
(DPD). Altogether more than 750 sunspot groups were considered. The decay rates
have been calculated for the total, umbral and penumbral area of the groups and
in the case of the SDD's groups they have been calculated for both the leading
and the following parts. The decay rates depend linearly on the maximum areas
and ranged from 30-50 MSH/day for the sunspot groups and penumbrae and 5-10
MSH/day for the umbrae throughout the cycle. The decay rates fall significantly
during the Gnevyshev gap and show 4+4 Schwabe cyclical variations in the
ascending/descending phases, but it is always higher in the northern
hemisphere. There is a slight decrease of the decay rates in the activity range
toward higher latitudes.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:37:06 GMT""}]","2021-02-24"
"2012.00447","Istv\'an Kov\'acs","Istv\'an A. Kov\'acs and R\'obert Juh\'asz","Emergence of disconnected clusters in heterogeneous complex systems","9 pages, 6 figures","Sci Rep 10, 21874 (2020)","10.1038/s41598-020-78769-2",,"cond-mat.dis-nn cond-mat.stat-mech physics.bio-ph physics.comp-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  Percolation theory dictates an intuitive picture depicting correlated regions
in complex systems as densely connected clusters. While this picture might be
adequate at small scales and apart from criticality, we show that highly
correlated sites in complex systems can be inherently disconnected. This
finding indicates a counter-intuitive organization of dynamical correlations,
where functional similarity decouples from physical connectivity. We illustrate
the phenomena on the example of the Disordered Contact Process (DCP) of
infection spreading in heterogeneous systems. We apply numerical simulations
and an asymptotically exact renormalization group technique (SDRG) in 1, 2 and
3 dimensional systems as well as in two-dimensional lattices with long-ranged
interactions. We conclude that the critical dynamics is well captured by mostly
one, highly correlated, but spatially disconnected cluster. Our findings
indicate that at criticality the relevant, simultaneously infected sites
typically do not directly interact with each other. Due to the similarity of
the SDRG equations, our results hold also for the critical behavior of the
disordered quantum Ising model, leading to quantum correlated, yet spatially
disconnected, magnetic domains.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:45:59 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 12:45:20 GMT""}]","2020-12-17"
"2012.00448","Leonardo Novo","Leonardo Novo, Sofia Ribeiro","Floquet engineering of continuous-time quantum walks: towards the
  simulation of complex and next-to-nearest neighbor couplings","14 pages, 10 figures. Comments are welcome!","Phys. Rev. A 103, 042219 (2021)","10.1103/PhysRevA.103.042219",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The formalism of continuous-time quantum walks on graphs has been widely used
in the study of quantum transport of energy and information, as well as in the
development of quantum algorithms. In experimental settings, however, there is
limited control over the coupling coefficients between the different nodes of
the graph (which are usually considered to be real-valued), thereby restricting
the types of quantum walks that can be implemented. In this work, we apply the
idea of Floquet engineering in the context of continuous-time quantum walks,
i.e., we define periodically-driven Hamiltonians which can be used to simulate
the dynamics of certain target continuous-time quantum walks. We focus on two
main applications: i) simulating quantum walks that break time-reversal
symmetry due to complex coupling coefficients; ii) increasing the connectivity
of the graph by simulating the presence of next-to-nearest neighbor couplings.
Our work provides explicit simulation protocols that may be used for directing
quantum transport, engineering the dispersion relation of one-dimensional
quantum walks or investigating quantum dynamics in highly connected structures.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:46:56 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 17:54:08 GMT""}]","2021-05-05"
"2012.00449","Yuzhi Liu","Yuzhi Liu, Zi Yang Meng and Shuai Yin","Fermion enhanced first-order phase transition and chiral Gross-Neveu
  tricritical point","9 pages, 6 figures","Phys. Rev. B 103, 075147 (2021)","10.1103/PhysRevB.103.075147",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fluctuations of massless Dirac fermion can not only turn a first-order
bosonic phase transition (in the Landau sense) to a quantum critical point, but
also work reversely to enhance the first-order transition itself, depending on
the implementation of finite size effects in the coupling corrections. Here, we
report a case study of the latter by employing quantum Monte Carlo simulation
upon a lattice model in which the bosonic part featuring the Landau-Devonshire
first-order phase transition and Yukawa coupled to the Dirac fermions. We find
that the parameter range for the first-order phase transition becomes larger as
the Yukawa coupling increases and the microscopic mechanism of this phenomena
is revealed, at a quantitative level, as the interplay between the critical
fluctuations and the finite-size effects. Moreover, the scaling behavior at the
separation point between the first-order and the continuous phase transitions
is found to belong to the chiral tricritical Gross-Neveu universality. Our
result demonstrates that the interplay of massless Dirac fermions, critical
fluctuations and the finite size effects could trigger a plethora of
interesting phenomena and therefore great care is called for when making
generalizations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:50:24 GMT""},{""version"":""v2"",""created"":""Fri, 4 Dec 2020 01:35:19 GMT""},{""version"":""v3"",""created"":""Sat, 27 Feb 2021 12:13:05 GMT""}]","2021-03-03"
"2012.00450","Vladimir Zolotarev","V. A. Zolotarev","Inverse spectral problem for a third-order differential operator with
  non-local potential",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spectral problem for a self-adjoint third-order differential operator with
non-local potential on a finite interval is studied. Elementary functions that
are analogues of sines and cosines for such operators are described. Direct and
inverse problems for third-order operators with non-local potential are solved.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:51:53 GMT""}]","2020-12-02"
"2012.00451","Antoine Yang","Antoine Yang, Antoine Miech, Josef Sivic, Ivan Laptev, Cordelia Schmid","Just Ask: Learning to Answer Questions from Millions of Narrated Videos","Accepted at ICCV 2021 (Oral); 20 pages; 14 figures",,,,"cs.CV cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent methods for visual question answering rely on large-scale annotated
datasets. Manual annotation of questions and answers for videos, however, is
tedious, expensive and prevents scalability. In this work, we propose to avoid
manual annotation and generate a large-scale training dataset for video
question answering making use of automatic cross-modal supervision. We leverage
a question generation transformer trained on text data and use it to generate
question-answer pairs from transcribed video narrations. Given narrated videos,
we then automatically generate the HowToVQA69M dataset with 69M
video-question-answer triplets. To handle the open vocabulary of diverse
answers in this dataset, we propose a training procedure based on a contrastive
loss between a video-question multi-modal transformer and an answer
transformer. We introduce the zero-shot VideoQA task and show excellent
results, in particular for rare answers. Furthermore, we demonstrate our method
to significantly outperform the state of the art on MSRVTT-QA, MSVD-QA,
ActivityNet-QA and How2QA. Finally, for a detailed evaluation we introduce
iVQA, a new VideoQA dataset with reduced language biases and high-quality
redundant manual annotations. Our code, datasets and trained models are
available at https://antoyang.github.io/just-ask.html.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:59:20 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 14:33:37 GMT""},{""version"":""v3"",""created"":""Thu, 12 Aug 2021 15:15:32 GMT""}]","2021-08-13"
"2012.00452","Weizhe Liu","Weizhe Liu, Mathieu Salzmann, Pascal Fua","Counting People by Estimating People Flows","Accepted to IEEE Transactions on Pattern Analysis and Machine
  Intelligence. Extension of Our ECCV 2020 Paper: arXiv:1911.10782",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern methods for counting people in crowded scenes rely on deep networks to
estimate people densities in individual images. As such, only very few take
advantage of temporal consistency in video sequences, and those that do only
impose weak smoothness constraints across consecutive frames. In this paper, we
advocate estimating people flows across image locations between consecutive
images and inferring the people densities from these flows instead of directly
regressing them. This enables us to impose much stronger constraints encoding
the conservation of the number of people. As a result, it significantly boosts
performance without requiring a more complex architecture. Furthermore, it
allows us to exploit the correlation between people flow and optical flow to
further improve the results. We also show that leveraging people conservation
constraints in both a spatial and temporal manner makes it possible to train a
deep crowd counting model in an active learning setting with much fewer
annotations. This significantly reduces the annotation cost while still leading
to similar performance to the full supervision case.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 12:59:24 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 14:30:28 GMT""}]","2021-08-04"
"2012.00453","Carlo Tiseo","Carlo Tiseo, Sydney Rebecca Charitos, and Michael Mistry","Theoretical Evidence Supporting Harmonic Reaching Trajectories",,"2021 10th International IEEE/EMBS Conference on Neural Engineering
  (NER)","10.1109/NER49283.2021.9441366",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Minimum Jerk trajectories have been long thought to be the reference
trajectories for human movements due to their impressive similarity with human
movements. Nevertheless, minimum jerk trajectories are not the only choice for
$C^\infty$ (i.e., smooth) functions. For example, harmonic trajectories are
smooth functions that can be superimposed to describe the evolution of physical
systems. This paper analyses the possibility that motor control plans using
harmonic trajectories, will be experimentally observed to have a minimum jerk
likeness due to control signals being transported through the Central Nervous
System (CNS) and muscle-skeletal system. We tested our theory on a 3-link arm
simulation using a recently developed planner that we reformulated into a motor
control architecture, inspired by the passive motion paradigm. The arm
performed 100 movements, reaching for each target defined by the clock
experiment. We analysed the shape of the trajectory planned in the CNS and
executed in the physical simulator. We observed that even under ideal
conditions (i.e., absence of delays and noise) the executed trajectories are
similar to a minimum jerk trajectory; thus, supporting the thesis that the
human brain might plan harmonic trajectories.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:00:54 GMT""},{""version"":""v2"",""created"":""Thu, 4 Mar 2021 22:08:36 GMT""}]","2021-06-08"
"2012.00454","Bing-Dong Wan","Bing-Dong Wan and Cong-Feng Qiao","Gluonic Tetracharm Configuration of $X(6900)$","14 pages, 4 figures, published in PLB",,"10.1016/j.physletb.2021.136339",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Recently, a new hadronic structure at around $6.9$ GeV was observed in an
LHCb experiment. From its limited yet known decay mode, one could still
determine that it contains at least four charm quarks and hence belongs to the
category of exotic state. This finding indicates for the first time the
tetracharm exotic states and is therefore quite importance. In this letter, we
propose a nature hybrid interpretation for the structure of $X(6900)$, i.e. in
$[\bar{3}_c]_{c c}\otimes[8_c]_{G}\otimes[3_c]_{\bar{c} \bar{c}}$ configuration
with $J^{PC}=0^{++}$, and by using the QCD Sum Rule technique we performed mass
spectrum calculation. The results showed that the observed $X(6900)$ could be a
gluonic tetracharm state, and some other structures may exist, e.g., one around
$7.2$ GeV in the tetracharm hybrid configuration and with $J^{PC}=0^{-+}$. We
also predict the tetrabottom hybrid states, leaving for future experiment.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:02:57 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 07:25:52 GMT""}]","2021-05-13"
"2012.00455","Sam Curley","Samuel P. M. Curley, Rebecca Scatena, Robert C. Williams, Paul A.
  Goddard, Piero Macchi, Thomas J. Hicken, Tom Lancaster, Fan Xiao, Stephen J.
  Blundell, Vivien Zapf, James C. Eckert, Elizabeth H. Krenkel, Jacqueline A.
  Villa, Melissa L. Rhodehouse, Jamie L. Manson","Magnetic ground-state of the one-dimensional ferromagnetic chain
  compounds $M$(NCS)$_2$(thiourea)$_2$; $M$ = Ni, Co","Main text: 13 pages - 11 figures, 2 tables. Supplemental information:
  6 pages - 2 figures, 6 tables","Phys. Rev. Materials 5, 034401 (2021)","10.1103/PhysRevMaterials.5.034401",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The magnetic properties of the two isostructural molecule-based magnets,
Ni(NCS)$_{2}$(thiourea)$_{2}$, $S$ = 1, [thiourea = SC(NH$_2$)$_2$] and
Co(NCS)$_{2}$(thiourea)$_{2}$, $S$ = 3/2, are characterised using several
techniques in order to rationalise their relationship with structural
parameters and ascertain magnetic changes caused by substitution of the spin.
Zero-field heat capacity and muon-spin relaxation measurements reveal
low-temperature long-range ordering in both compounds, in addition to
Ising-like ($D < 0$) single-ion anisotropy ($D_{\rm{Co}} \sim$ -100 K,
$D_{\rm{Ni}} \sim$ -10 K). Crystal and electronic structure, combined with
DC-field magnetometry, affirm highly quasi-one-dimensional behaviour, with
ferromagnetic intrachain exchange interactions $J_{\rm{Co}}\approx+4$ K and
$J_{\rm{Ni}}\sim+100$ K and weak antiferromagnetic interchain exchange, on the
order of $J'$ $\sim-0.1$ K. Electron charge and spin-density mapping reveals
through-space exchange as a mechanism to explain the large discrepancy in
$J$-values despite, from a structural perspective, the highly similar exchange
pathways in both materials. Both species can be compared to the similar
compounds $M$Cl$_2$(thiourea)$_4$, $M$ = Ni(II) (DTN) and Co(II) (DTC), where
DTN is know to harbour two magnetic field-induced quantum critical points.
Direct comparison of DTN and DTC with the compounds studied here shows that
substituting the halide Cl$^-$ ion, for the NCS$^-$ ion, results in a dramatic
change in both the structural and magnetic properties.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:04:15 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 09:54:04 GMT""}]","2021-03-17"
"2012.00456","Allard Oelen","Allard Oelen, Markus Stocker, S\""oren Auer","Creating a Scholarly Knowledge Graph from Survey Article Tables",,,"10.1007/978-3-030-64452-9_35",,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the lack of structure, scholarly knowledge remains hardly accessible
for machines. Scholarly knowledge graphs have been proposed as a solution.
Creating such a knowledge graph requires manual effort and domain experts, and
is therefore time-consuming and cumbersome. In this work, we present a
human-in-the-loop methodology used to build a scholarly knowledge graph
leveraging literature survey articles. Survey articles often contain manually
curated and high-quality tabular information that summarizes findings published
in the scientific literature. Consequently, survey articles are an excellent
resource for generating a scholarly knowledge graph. The presented methodology
consists of five steps, in which tables and references are extracted from PDF
articles, tables are formatted and finally ingested into the knowledge graph.
To evaluate the methodology, 92 survey articles, containing 160 survey tables,
have been imported in the graph. In total, 2,626 papers have been added to the
knowledge graph using the presented methodology. The results demonstrate the
feasibility of our approach, but also indicate that manual effort is required
and thus underscore the important role of human experts.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:04:27 GMT""}]","2020-12-02"
"2012.00457","Mamadou Yauck","Mamadou Yauck, Erica E. M. Moodie, Herak Apelian, Alain Fourmigue,
  Daniel Grace, Trevor Hart, Gilles Lambert, Joseph Cox","General Regression Methods for Respondent-Driven Sampling Data",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Respondent-Driven Sampling (RDS) is a variant of link-tracing sampling
techniques that aim to recruit hard-to-reach populations by leveraging
individuals' social relationships. As such, an RDS sample has a graphical
component which represents a partially observed network of unknown structure.
Moreover, it is common to observe homophily, or the tendency to form
connections with individuals who share similar traits. Currently, there is a
lack of principled guidance on multivariate modeling strategies for RDS to
address homophilic covariates and the dependence between observations within
the network. In this work, we propose a methodology for general regression
techniques using RDS data. This is used to study the socio-demographic
predictors of HIV treatment optimism (about the value of antiretroviral
therapy) among gay, bisexual and other men who have sex with men, recruited
into an RDS study in Montreal, Canada.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:05:18 GMT""}]","2020-12-02"
"2012.00458","Yaqing Ding","Yaqing Ding, Daniel Barath, Jian Yang, Hui Kong, Zuzana Kukelova","Globally Optimal Relative Pose Estimation with Gravity Prior",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Smartphones, tablets and camera systems used, e.g., in cars and UAVs, are
typically equipped with IMUs (inertial measurement units) that can measure the
gravity vector accurately. Using this additional information, the $y$-axes of
the cameras can be aligned, reducing their relative orientation to a single
degree-of-freedom. With this assumption, we propose a novel globally optimal
solver, minimizing the algebraic error in the least-squares sense, to estimate
the relative pose in the over-determined case. Based on the epipolar
constraint, we convert the optimization problem into solving two polynomials
with only two unknowns. Also, a fast solver is proposed using the first-order
approximation of the rotation. The proposed solvers are compared with the
state-of-the-art ones on four real-world datasets with approx. 50000 image
pairs in total. Moreover, we collected a dataset, by a smartphone, consisting
of 10933 image pairs, gravity directions, and ground truth 3D reconstructions.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:09:59 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 02:38:55 GMT""}]","2021-02-08"
"2012.00459","Cheng Zhang","Cheng Zhang","Improved Variational Bayesian Phylogenetic Inference with Normalizing
  Flows","NeurIPS 2020",,,,"q-bio.PE stat.ML","http://creativecommons.org/licenses/by/4.0/","  Variational Bayesian phylogenetic inference (VBPI) provides a promising
general variational framework for efficient estimation of phylogenetic
posteriors. However, the current diagonal Lognormal branch length approximation
would significantly restrict the quality of the approximating distributions. In
this paper, we propose a new type of VBPI, VBPI-NF, as a first step to empower
phylogenetic posterior estimation with deep learning techniques. By handling
the non-Euclidean branch length space of phylogenetic models with carefully
designed permutation equivariant transformations, VBPI-NF uses normalizing
flows to provide a rich family of flexible branch length distributions that
generalize across different tree topologies. We show that VBPI-NF significantly
improves upon the vanilla VBPI on a benchmark of challenging real data Bayesian
phylogenetic inference problems. Further investigation also reveals that the
structured parameterization in those permutation equivariant transformations
can provide additional amortization benefit.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:10:00 GMT""}]","2020-12-02"
"2012.00460","Yi Yu","Daren Wang, Zifeng Zhao, Yi Yu and Rebecca Willett","Functional Linear Regression with Mixed Predictors",,,,,"math.ST stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a functional linear regression model that deals with functional
responses and allows for both functional covariates and high-dimensional vector
covariates. The proposed model is flexible and nests several functional
regression models in the literature as special cases. Based on the theory of
reproducing kernel Hilbert spaces (RKHS), we propose a penalized least squares
estimator that can accommodate functional variables observed on discrete sample
points. Besides a conventional smoothness penalty, a group Lasso-type penalty
is further imposed to induce sparsity in the high-dimensional vector
predictors. We derive finite sample theoretical guarantees and show that the
excess prediction risk of our estimator is minimax optimal. Furthermore, our
analysis reveals an interesting phase transition phenomenon that the optimal
excess risk is determined jointly by the smoothness and the sparsity of the
functional regression coefficients. A novel efficient optimization algorithm
based on iterative coordinate descent is devised to handle the smoothness and
group penalties simultaneously. Simulation studies and real data applications
illustrate the promising performance of the proposed approach compared to the
state-of-the-art methods in the literature.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:10:15 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 09:34:28 GMT""},{""version"":""v3"",""created"":""Mon, 13 Sep 2021 06:30:43 GMT""},{""version"":""v4"",""created"":""Tue, 23 Aug 2022 07:05:51 GMT""}]","2022-08-24"
"2012.00461","Nima Rafiee","Nima Rafiee, Rahil Gholamipoor, Markus Kollmann","Unsupervised Anomaly Detection From Semantic Similarity Scores","The reported AUROC values are wrong due to an implementation error.
  In short, there was information leakage by Batch Normalisation during
  training the discriminator",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classifying samples as in-distribution or out-of-distribution (OOD) is a
challenging problem of anomaly detection and a strong test of the
generalisation power for models of the in-distribution. In this paper, we
present a simple and generic framework, {\it SemSAD}, that makes use of a
semantic similarity score to carry out anomaly detection. The idea is to first
find for any test example the semantically closest examples in the training
set, where the semantic relation between examples is quantified by the cosine
similarity between feature vectors that leave semantics unchanged under
transformations, such as geometric transformations (images), time shifts (audio
signals), and synonymous word substitutions (text). A trained discriminator is
then used to classify a test example as OOD if the semantic similarity to its
nearest neighbours is significantly lower than the corresponding similarity for
test examples from the in-distribution. We are able to outperform previous
approaches for anomaly, novelty, or out-of-distribution detection in the visual
domain by a large margin. In particular, we obtain AUROC values close to one
for the challenging task of detecting examples from CIFAR-10 as
out-of-distribution given CIFAR-100 as in-distribution, without making use of
label information.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:12:31 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 08:21:22 GMT""},{""version"":""v3"",""created"":""Fri, 26 Mar 2021 08:40:34 GMT""}]","2021-03-29"
"2012.00462","Steven Bos","Steven P. Bos, David S. Doelman, Kelsey L. Miller, and Frans Snik","New concepts in vector-Apodizing Phase Plate coronagraphy","13 pages, 15 figures, published in SPIE. Re-uploaded to fix a
  corrupted figure",,,,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The vector-Apodizing Phase Plate (vAPP) is a pupil-plane coronagraph that
manipulates phase to create dark holes in the stellar PSF. The phase is induced
on the circular polarization states through the inherently achromatic geometric
phase by spatially varying the fast axis orientation of a half-wave
liquid-crystal layer. The two polarized PSFs can be separated, either by a
quarter-wave plate (QWP) followed by a polarizing beamsplitter (PBS) for
broadband operation, or a polarization sensitive grating (PSG) for narrowband
or IFS operation. Here we present new vAPP concepts that lift the restrictions
of previous designs and report on their performance. We demonstrated that the
QWP+PBS combination puts tight tolerances on the components to prevent leakage
of non-coronagraphic light into the dark-hole. We present a new broadband
design using an innovative two-stage patterned liquid-crystal element system
based on multi-color holography, alleviating the leakage problem and relaxing
manufacturing tolerances. Furthermore, we have shown that focal-plane wavefront
sensing (FPWFS) can be integrated into the vAPP by an asymmetric pupil.
However, such vAPPs suffer from a reduced throughput and have only been
demonstrated with a PSG in narrowband operation. We present advanced designs
that maintain throughput and enable phase and amplitude wavefront sensing. We
also present broadband vAPP FPWFS designs and outline a broadband FPWFS
algorithm. Finally, previous dual-beam vAPP designs for sensitive polarimetry
with one-sided dark holes were very complex. We show new dual-beam designs that
significantly reduce the complexity.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:15:30 GMT""},{""version"":""v2"",""created"":""Thu, 7 Jan 2021 09:24:42 GMT""}]","2021-01-08"
"2012.00463","Faisal Hussain","Faisal Hussain, Syed Ghazanfar Abbas, Ubaid U. Fayyaz, Ghalib A. Shah,
  Abdullah Toqeer, Ahmad Ali","Towards a Universal Features Set for IoT Botnet Attacks Detection","Accepted in 2020 IEEE 23rd International Multitopic Conference
  (INMIC), 7 pages, 3 figures, 4 tables",,,,"cs.CR cs.AI","http://creativecommons.org/licenses/by/4.0/","  The security pitfalls of IoT devices make it easy for the attackers to
exploit the IoT devices and make them a part of a botnet. Once hundreds of
thousands of IoT devices are compromised and become the part of a botnet, the
attackers use this botnet to launch the large and complex distributed denial of
service (DDoS) attacks which take down the target websites or services and make
them unable to respond the legitimate users. So far, many botnet detection
techniques have been proposed but their performance is limited to a specific
dataset on which they are trained. This is because the features used to train a
machine learning model on one botnet dataset, do not perform well on other
datasets due to the diversity of attack patterns. Therefore, in this paper, we
propose a universal features set to better detect the botnet attacks regardless
of the underlying dataset. The proposed features set manifest preeminent
results for detecting the botnet attacks when tested the trained machine
learning models over three different botnet attack datasets.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:15:57 GMT""}]","2020-12-02"
"2012.00464","Aleksandr Popov","Milutin Brankovic, Kevin Buchin, Koen Klaren, Andr\'e Nusser,
  Aleksandr Popov, Sampson Wong","(k, l)-Medians Clustering of Trajectories Using Continuous Dynamic Time
  Warping","12 pages, 16 figures. This is the authors' version of the paper
  published in SIGSPATIAL 2020",,"10.1145/3397536.3422245",,"cs.LG cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the massively increasing amount of available geospatial data and the
need to present it in an understandable way, clustering this data is more
important than ever. As clusters might contain a large number of objects,
having a representative for each cluster significantly facilitates
understanding a clustering. Clustering methods relying on such representatives
are called center-based. In this work we consider the problem of center-based
clustering of trajectories.
  In this setting, the representative of a cluster is again a trajectory. To
obtain a compact representation of the clusters and to avoid overfitting, we
restrict the complexity of the representative trajectories by a parameter l.
This restriction, however, makes discrete distance measures like dynamic time
warping (DTW) less suited.
  There is recent work on center-based clustering of trajectories with a
continuous distance measure, namely, the Fr\'echet distance. While the
Fr\'echet distance allows for restriction of the center complexity, it can also
be sensitive to outliers, whereas averaging-type distance measures, like DTW,
are less so. To obtain a trajectory clustering algorithm that allows
restricting center complexity and is more robust to outliers, we propose the
usage of a continuous version of DTW as distance measure, which we call
continuous dynamic time warping (CDTW). Our contribution is twofold:
  1. To combat the lack of practical algorithms for CDTW, we develop an
approximation algorithm that computes it.
  2. We develop the first clustering algorithm under this distance measure and
show a practical way to compute a center from a set of trajectories and
subsequently iteratively improve it.
  To obtain insights into the results of clustering under CDTW on practical
data, we conduct extensive experiments.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:17:27 GMT""}]","2020-12-02"
"2012.00465","Daniel Barath","Yaqing Ding, Daniel Barath, Zuzana Kukelova","Minimal Solutions for Panoramic Stitching Given Gravity Prior",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  When capturing panoramas, people tend to align their cameras with the
vertical axis, i.e., the direction of gravity. Moreover, modern devices, such
as smartphones and tablets, are equipped with an IMU (Inertial Measurement
Unit) that can measure the gravity vector accurately. Using this prior, the
y-axes of the cameras can be aligned or assumed to be already aligned, reducing
their relative orientation to 1-DOF (degree of freedom). Exploiting this
assumption, we propose new minimal solutions to panoramic image stitching of
images taken by cameras with coinciding optical centers, i.e., undergoing pure
rotation. We consider four practical camera configurations, assuming unknown
fixed or varying focal length with or without radial distortion. The solvers
are tested both on synthetic scenes and on more than 500k real image pairs from
the Sun360 dataset and from scenes captured by us using two smartphones
equipped with IMUs. It is shown, that they outperform the state-of-the-art both
in terms of accuracy and processing time.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:17:36 GMT""}]","2020-12-02"
"2012.00466","Deisiane Gon\c{c}alves","Deisiane Lopes Gon\c{c}alves, Bhalchandra D. Thatte","A construction of the abstract induced subgraph poset of a graph from
  its abstract edge subgraph poset","12 pages, 1 figure",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The abstract induced subgraph poset of a graph is the isomorphism class of
the induced subgraph poset of the graph, suitably weighted by subgraph counting
numbers. The abstract bond lattice and the abstract edge-subgraph poset are
defined similarly by considering the lattice of subgraphs induced by connected
partitions and the poset of edge-subgraphs, respectively. Continuing our
development of graph reconstruction theory on these structures, we show that if
a graph has no isolated vertices, then its abstract bond lattice and the
abstract induced subgraph poset can be constructed from the abstract
edge-subgraph poset except for the families of graphs that we characterise. The
construction of the abstract induced subgraph poset from the abstract
edge-subgraph poset generalises a well known result in reconstruction theory
that states that the vertex deck of a graph with at least 4 edges and without
isolated vertices can be constructed from its edge deck.12
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:18:36 GMT""}]","2020-12-02"
"2012.00467","Qianwen Wang","Qianwen Wang, Zhutian Chen, Yong Wang, Huamin Qu","A Survey on ML4VIS: Applying Machine Learning Advances to Data
  Visualization","19 pages, 12 figures, 4 tables","IEEE Transactions on Visualization and Computer Graphics, 2021","10.1109/TVCG.2021.3106142",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by the great success of machine learning (ML), researchers have
applied ML techniques to visualizations to achieve a better design,
development, and evaluation of visualizations. This branch of studies, known as
ML4VIS, is gaining increasing research attention in recent years. To
successfully adapt ML techniques for visualizations, a structured understanding
of the integration of ML4VISis needed. In this paper, we systematically survey
88 ML4VIS studies, aiming to answer two motivating questions: ""what
visualization processes can be assisted by ML?"" and ""how ML techniques can be
used to solve visualization problems?"" This survey reveals seven main processes
where the employment of ML techniques can benefit visualizations:Data
Processing4VIS, Data-VIS Mapping, InsightCommunication, Style Imitation, VIS
Interaction, VIS Reading, and User Profiling. The seven processes are related
to existing visualization theoretical models in an ML4VIS pipeline, aiming to
illuminate the role of ML-assisted visualization in general
visualizations.Meanwhile, the seven processes are mapped into main learning
tasks in ML to align the capabilities of ML with the needs in visualization.
Current practices and future opportunities of ML4VIS are discussed in the
context of the ML4VIS pipeline and the ML-VIS mapping. While more studies are
still needed in the area of ML4VIS, we hope this paper can provide a
stepping-stone for future exploration. A web-based interactive browser of this
survey is available at https://ml4vis.github.io
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:19:59 GMT""},{""version"":""v2"",""created"":""Fri, 25 Jun 2021 00:04:28 GMT""},{""version"":""v3"",""created"":""Sun, 8 Aug 2021 21:04:04 GMT""},{""version"":""v4"",""created"":""Thu, 23 Dec 2021 18:59:31 GMT""}]","2021-12-24"
"2012.00468","Benedetta Tondi","Benedetta Tondi, Andrea Costranzo, Dequ Huang and Bin Li","Boosting CNN-based primary quantization matrix estimation of double JPEG
  images via a classification-like architecture",,,,,"cs.CV cs.GT","http://creativecommons.org/licenses/by/4.0/","  Estimating the primary quantization matrix of double JPEG compressed images
is a problem of relevant importance in image forensics since it allows to infer
important information about the past history of an image. In addition, the
inconsistencies of the primary quantization matrices across different image
regions can be used to localize splicing in double JPEG tampered images.
Traditional model-based approaches work under specific assumptions on the
relationship between the first and second compression qualities and on the
alignment of the JPEG grid. Recently, a deep learning-based estimator capable
to work under a wide variety of conditions has been proposed, that outperforms
tailored existing methods in most of the cases. The method is based on a
Convolutional Neural Network (CNN) that is trained to solve the estimation as a
standard regression problem. By exploiting the integer nature of the
quantization coefficients, in this paper, we propose a deep learning technique
that performs the estimation by resorting to a simil-classification
architecture. The CNN is trained with a loss function that takes into account
both the accuracy and the Mean Square Error (MSE) of the estimation. Results
confirm the superior performance of the proposed technique, compared to the
state-of-the art methods based on statistical analysis and, in particular, deep
learning regression. Moreover, the capability of the method to work under
general operative conditions, regarding the alignment of the second compression
grid with the one of first compression and the combinations of the JPEG
qualities of former and second compression, is very relevant in practical
applications, where these information are unknown a priori.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:20:11 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 19:54:31 GMT""}]","2021-03-19"
"2012.00469","Khristine Haydukivska","Khristine Haydukivska, Ostap Kalyuzhnyi, Viktoria Blavatska, Jaroslav
  Ilnytskyi","On the swelling properties of pom-pom polymers in dilute solutions. Part
  1: symmetric case",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the simplest representative of the class of multiply branched
polymer macromolecules, known as a pom-pom structure. The molecule consists of
a backbone linear chain terminated by two branching points with functionalities
(numbers of side chains) of $f_1$ and $f_2$, respectively. In a symmetrical
case, considered in the present study, one has $f_1=f_2=f$ with the total
number of chains $F=2f+1$. Whereas rheological behaviour of melts of pom-pom
molecules are intensively studied so far, we turn our attention towards
conformational properties of such polymers in a regime of dilute solution. The
universality concept, originated in the critical phenomena and in scaling
properties of polymers, is used in this study. To be able to compare the
outcome of the direct polymer renormalization approach with that obtained via
dissipative particle dynamics simulations, we concentrated on the universal
ratios of the shape characteristics. In this way the differences in the energy
and length scales are eliminated and the universal ratios depend only on space
dimension, solvent quality and a type of molecular branching. Such universal
ratios were evaluated both for a whole molecule and for its individual
branches. For some shape properties, theory and simulations are in excellent
agreement, for other we found the interval of $F$ where both agree reasonably
well. Combination of theoretical and simulation approaches provide thorough
quantitative description of the peculiarities of swelling effects and spatial
extension of pom-pom molecules and are compared with the known results for
simpler molecular topologies.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:20:13 GMT""}]","2020-12-02"
"2012.00470","Shuyang Ling","Shuyang Ling","Improved Performance Guarantees for Orthogonal Group Synchronization via
  Generalized Power Method","SIAM Journal on Optimization, to appear",,,,"cs.IT math.IT math.OC","http://creativecommons.org/licenses/by/4.0/","  Given the noisy pairwise measurements among a set of unknown group elements,
how to recover them efficiently and robustly? This problem, known as group
synchronization, has drawn tremendous attention in the scientific community. In
this work, we focus on orthogonal group synchronization that has found many
applications, including computer vision, robotics, and cryo-electron
microscopy. One commonly used approach is the least squares estimation that
requires solving a highly nonconvex optimization program. The past few years
have witnessed considerable advances in tackling this challenging problem by
convex relaxation and efficient first-order methods. However, one fundamental
theoretical question remains to be answered: how does the recovery performance
depend on the noise strength? To answer this question, we study a benchmark
model: recovering orthogonal group elements from their pairwise measurements
corrupted by Gaussian noise. We investigate the performance of convex
relaxation and the generalized power method (GPM). By applying the
novel~\emph{leave-one-out} technique, we prove that the GPM with spectral
initialization enjoys linear convergence to the global optima to the convex
relaxation that also matches the maximum likelihood estimator. Our result
achieves a near-optimal performance bound on the convergence of the GPM and
improves the state-of-the-art theoretical guarantees on the tightness of convex
relaxation by a large margin.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:21:41 GMT""},{""version"":""v2"",""created"":""Fri, 1 Jan 2021 04:20:10 GMT""},{""version"":""v3"",""created"":""Tue, 28 Dec 2021 02:24:47 GMT""}]","2021-12-30"
"2012.00471","Bartolomeo Silvestri","Maria Pia Fanti, Agostino Marcello Mangini, Michele Roccotelli,
  Bartolomeo Silvestri, Salvatore Digiesi","Electric Vehicle Fleet Relocation Management for Sharing Systems based
  on Incentive Mechanism","This paper has been presented at 2019 IEEE 15th International
  Conference on Automation Science and Engineering (CASE)",,"10.1109/COASE.2019.8842852",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper deals with the electric vehicle fleet relocation management in a
sharing system. The mobility sharing systems efficiency depends on the vehicles
relocation task that strongly affect the company operating cost, and
consequently the service price for users. The proposed approach aims at
minimizing the cost of vehicles relocation for a sharing company by involving
users through an innovative incentive scheme. The idea is to request users of
the sharing service to relocate the EVs, e.g. through an IT application,
incentivizing them by free-of-charge travels and rewards. The proposed
incentive mechanism is based on the application of different levels of
incentive proposal. In addition, in case of user unavailability, the vehicle
relocation is guaranteed by the company staff. To this aim, a first ILP is
formalized to manage the relocation task by the company staff. Moreover, a
second ILP allows the company to involve users in the relocation process by the
proposed incentive mechanism. Finally, a case study is presented to show the
application of the proposed methodology on the relocation of electric cars and
light electric vehicles.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:23:41 GMT""}]","2020-12-02"
"2012.00472","Martin Kleppmann","Martin Kleppmann, Heidi Howard","Byzantine Eventual Consistency and the Fundamental Limits of
  Peer-to-Peer Databases",,,,,"cs.DC cs.CR cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sybil attacks, in which a large number of adversary-controlled nodes join a
network, are a concern for many peer-to-peer database systems, necessitating
expensive countermeasures such as proof-of-work. However, there is a category
of database applications that are, by design, immune to Sybil attacks because
they can tolerate arbitrary numbers of Byzantine-faulty nodes. In this paper,
we characterize this category of applications using a consistency model we call
Byzantine Eventual Consistency (BEC). We introduce an algorithm that guarantees
BEC based on Byzantine causal broadcast, prove its correctness, and demonstrate
near-optimal performance in a prototype implementation.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:24:09 GMT""}]","2020-12-02"
"2012.00473","Mathieu Dutour Sikiri\'c","Mathieu Dutour Sikiri\'c","A variation on the Rubik's cube","7 pages, 4 figures",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  The Rubik's cube is a famous puzzle in which faces can be moved and the
corresponding movement operations define a group. We consider here a
generalization to any $3$-valent map. We prove an upper bound on the size of
the corresponding group which we conjecture to be tight.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:25:34 GMT""}]","2020-12-02"
"2012.00474","Fabian Krinner","Fabian Michael Krinner and Stephan Paul","New developments in model-independent Partial-Wave Analysis","Proceedings for the 23rd High-Energy Physics International Conference
  in Quantum ChromoDynamics (QCD 2020), virtually held from October 27th to
  October 30th in Montpellier, France; five pages, four figures","Nucl.Part.Phys.Proc. 312-317 (2021) 48-52","10.1016/j.nuclphysbps.2021.05.013",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Partial-wave analyses (PWA) are an essential tool for studying resonance
structures in decays with hadronic multi-body final states. For several years,
more model-independent approaches to such analyses have been used for various
decay final states. However, up to now, these methods have mostly been applied
to sub-sets of partial waves, also called freed waves. In this article, we
explore possibilities and limitations of extended model-independent approaches.
We systematically apply various different fit models to the analysis of pseudo
data sets, to study both the impact of the mathematical description used for
the freed waves and the choice of simultaneously freed waves. We can show that
suitable methods exist, which lift restrictions to only sub-sets of freed
partial waves and demonstrate hidden caveats present in previous works.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:26:33 GMT""}]","2021-09-07"
"2012.00475","Rob van Holstein","Rob G. van Holstein, Steven P. Bos, Jasper Ruigrok, Julien Lozi,
  Olivier Guyon, Barnaby Norris, Frans Snik, Jeffrey Chilcote, Thayne Currie,
  Tyler D. Groff, Joost 't Hart, Nemanja Jovanovic, Jeremy Kasdin, Tomoyuki
  Kudo, Frantz Martinache, Ben Mazin, Ananya Sahoo, Motohide Tamura,
  S\'ebastien Vievard, Alex Walter, Jin Zhang","Calibration of the instrumental polarization effects of SCExAO-CHARIS'
  spectropolarimetric mode","14 pages, 7 figures, submitted to SPIE Astronomical Telescopes +
  Instrumentation 2020",,,,"astro-ph.IM astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  SCExAO at the Subaru telescope is a visible and near-infrared high-contrast
imaging instrument employing extreme adaptive optics and coronagraphy. The
instrument feeds the near-infrared light (JHK) to the integral field
spectrograph CHARIS. Recently, a Wollaston prism was added to CHARIS' optical
path, giving CHARIS a spectropolarimetric capability that is unique among
high-contrast imaging instruments. We present a detailed Mueller matrix model
describing the instrumental polarization effects of the complete optical path,
thus the telescope and instrument. The 22 wavelength bins of CHARIS provide a
unique opportunity to investigate in detail the wavelength dependence of the
instrumental polarization effects. From measurements with the internal light
source, we find that the image derotator (K-mirror) produces strong
wavelength-dependent crosstalk, in the worst case converting ~95% of the
incident linear polarization to circularly polarized light that cannot be
measured. Theoretical calculations show that the magnitude of the instrumental
polarization of the telescope varies with wavelength between approximately 0.5%
and 0.7%, and that its angle is exactly equal to the altitude angle of the
telescope. We plan to more accurately determine the instrumental polarization
of the telescope with observations of a polarization standard star, and fit
more comprehensive physical models to all experimental data. In addition, we
plan to integrate the complete Mueller matrix model into the existing CHARIS
post-processing pipeline, with the aim to achieve a polarimetric accuracy of
<0.1% in the degree of linear polarization. Our calibrations of CHARIS'
spectropolarimetric mode will enable unique quantitative polarimetric studies
of circumstellar disks and planetary and brown dwarf companions.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:29:14 GMT""}]","2020-12-02"
"2012.00476","Guillermo Alesandroni","Guillermo Alesandroni","Families of finite sets in which no set is covered by the union of the
  others",,,,,"math.CO math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let F be a finite nonempty family of finite nonempty sets. We prove the
following: (i) F satisfies the condition of the title if and only if for every
pair of distinct subfamilies {A_1,...,A_r}, {B_1,...,B_s} of F, the union of
the A_i is different from the union of the B_i. (ii) If F satisfies the
condition of the title, then the number of subsets of the union of the members
of F containing at least one set of F is odd. We give two applications of these
results, one to number theory and one to commutative algebra.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:29:33 GMT""},{""version"":""v2"",""created"":""Fri, 18 Dec 2020 14:22:15 GMT""}]","2020-12-21"
"2012.00477","Renato Cordeiro de Amorim","Renato Cordeiro de Amorim and Vladimir Makarenkov","Improving cluster recovery with feature rescaling factors",,,"10.1007/s10489-020-02108-1",,"cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  The data preprocessing stage is crucial in clustering. Features may describe
entities using different scales. To rectify this, one usually applies feature
normalisation aiming at rescaling features so that none of them overpowers the
others in the objective function of the selected clustering algorithm. In this
paper, we argue that the rescaling procedure should not treat all features
identically. Instead, it should favour the features that are more meaningful
for clustering. With this in mind, we introduce a feature rescaling method that
takes into account the within-cluster degree of relevance of each feature. Our
comprehensive simulation study, carried out on real and synthetic data, with
and without noise features, clearly demonstrates that clustering methods that
use the proposed data normalization strategy clearly outperform those that use
traditional data normalization.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:29:35 GMT""}]","2021-04-26"
"2012.00478","Dimas Mart\'inez","Victoria Hern\'andez-Mederos, Dimas Mart\'inez, Jorge
  Estrada-Sarlabous and Valia Guerra-Ones","Farthest sampling segmentation of triangulated surfaces",,,,,"cs.GR cs.CV cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  In this paper we introduce Farthest Sampling Segmentation (FSS), a new method
for segmentation of triangulated surfaces, which consists of two fundamental
steps: the computation of a submatrix $W^k$ of the affinity matrix $W$ and the
application of the k-means clustering algorithm to the rows of $W^k$. The
submatrix $W^k$ is obtained computing the affinity between all triangles and
only a few special triangles: those which are farthest in the defined metric.
This is equivalent to select a sample of columns of $W$ without constructing it
completely. The proposed method is computationally cheaper than other
segmentation algorithms, since it only calculates few columns of $W$ and it
does not require the eigendecomposition of $W$ or of any submatrix of $W$.
  We prove that the orthogonal projection of $W$ on the space generated by the
columns of $W^k$ coincides with the orthogonal projection of $W$ on the space
generated by the $k$ eigenvectors computed by Nystr\""om's method using the
columns of $W^k$ as a sample of $W$. Further, it is shown that for increasing
size $k$, the proximity relationship among the rows of $W^k$ tends to
faithfully reflect the proximity among the corresponding rows of $W$.
  The FSS method does not depend on parameters that must be tuned by hand and
it is very flexible, since it can handle any metric to define the distance
between triangles. Numerical experiments with several metrics and a large
variety of 3D triangular meshes show that the segmentations obtained computing
less than the 10% of columns $W$ are as good as those obtained from clustering
the rows of the full matrix $W$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:31:44 GMT""}]","2020-12-02"
"2012.00479","Xin Liang","Xin Liang and Zhen-Chen Guo and Tsung-Ming Huang and Tiexiang Li and
  Wen-Wei Lin","Bifurcation Analysis of the Eigenstructure of the Discrete Single-curl
  Operator in Three-dimensional Maxwell's Equations with Pasteur Media","26 pages, 5 figures","IMA J. Numer. Anal., Volume 424, Issue 4, Pages 3735-3770, 2022","10.1093/imanum/drab081",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on studying the bifurcation analysis of the eigenstructure
of the $\gamma$-parameterized generalized eigenvalue problem ($\gamma$-GEP)
arising in three-dimensional (3D) source-free Maxwell's equations with Pasteur
media, where $\gamma$ is the magnetoelectric chirality parameter. For the
weakly coupled case, namely, $\gamma < \gamma_{*} \equiv$ critical value, the
$\gamma$-GEP is positive definite, which has been well-studied by Chern et.\
al, 2015. For the strongly coupled case, namely, $\gamma > \gamma_{*}$, the
$\gamma$-GEP is no longer positive definite, introducing a totally different
and complicated structure. For the critical strongly coupled case, numerical
computations for electromagnetic fields have been presented by Huang et.\ al,
2018. In this paper, we build several theoretical results on the eigenstructure
behavior of the $\gamma$-GEPs. We prove that the $\gamma$-GEP is regular for
any $\gamma > 0$, and the $\gamma$-GEP has $2 \times 2$ Jordan blocks of
infinite eigenvalues at the critical value $\gamma_{*}$. Then, we show that the
$2 \times 2$ Jordan block will split into a complex conjugate eigenvalue pair
that rapidly goes down and up and then collides at some real point near the
origin. Next, it will bifurcate into two real eigenvalues, with one moving
toward the left and the other to the right along the real axis as $\gamma$
increases. A newly formed state whose energy is smaller than the ground state
can be created as $\gamma$ is larger than the critical value. This stunning
feature of the physical phenomenon would be very helpful in practical
applications. Therefore, the purpose of this paper is to clarify the
corresponding theoretical eigenstructure of 3D Maxwell's equations with Pasteur
media.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:36:15 GMT""}]","2023-03-03"
"2012.00480","Iacopo Pozzana","Iacopo Pozzana, Christos Ellinas, Georgios Kalogridis and Konstantinos
  Sakellariou","Spreading of performance fluctuations on real-world project networks","12 pages, 4 figures",,,,"cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the role of individual nodes is a key challenge in the study of
spreading processes on networks. In this work we propose a novel metric, the
reachability-heterogeneity (RH), to quantify the vulnerability of each node
with respect to a spreading process on a network. We then introduce a dataset
consisting of four large engineering projects described by their activity
networks, including records of the performance of each activity; such data,
describing the spreading of performance fluctuations across activities, can be
used as a reliable ground truth for the study of spreading phenomena on
networks. We test the validity of the RH metric on these project networks, and
discover that nodes scoring low in RH tend to consistently perform better. We
also compare RH and seven other node metrics, showing that the former is highly
interdependent with activity performance. Given the context agnostic nature of
RH, our results, based on real-world data, signify the role that network
structure plays with respect to overall project performance.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:36:29 GMT""}]","2020-12-02"
"2012.00481","Stan Z Li","Stan Z. Li, Lirong Wu and Zelin Zang","Consistent Representation Learning for High Dimensional Data Analysis",,,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  High dimensional data analysis for exploration and discovery includes three
fundamental tasks: dimensionality reduction, clustering, and visualization.
When the three associated tasks are done separately, as is often the case thus
far, inconsistencies can occur among the tasks in terms of data geometry and
others. This can lead to confusing or misleading data interpretation. In this
paper, we propose a novel neural network-based method, called Consistent
Representation Learning (CRL), to accomplish the three associated tasks
end-to-end and improve the consistencies. The CRL network consists of two
nonlinear dimensionality reduction (NLDR) transformations: (1) one from the
input data space to the latent feature space for clustering, and (2) the other
from the clustering space to the final 2D or 3D space for visualization.
Importantly, the two NLDR transformations are performed to best satisfy local
geometry preserving (LGP) constraints across the spaces or network layers, to
improve data consistencies along with the processing flow. Also, we propose a
novel metric, clustering-visualization inconsistency (CVI), for evaluating the
inconsistencies. Extensive comparative results show that the proposed CRL
neural network method outperforms the popular t-SNE and UMAP-based and other
contemporary clustering and visualization algorithms in terms of evaluation
metrics and visualization.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:39:50 GMT""}]","2020-12-02"
"2012.00482","Yu. M. Zinoviev","M. V. Khabarov and Yu. M. Zinoviev","Cubic interaction vertices for massless higher spin supermultiplets in
  d=4","16 pages","JHEP 02 (2021) 167","10.1007/JHEP02(2021)167",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a range of supersymmetric cubic vertices for three massless
higher spin supermultiplets in the four-dimensional space. We use frame-like
multispinor formalism, which allows to avoid most of the technical difficulties
and provides a uniform description for bosons and fermions. Our work is based
on the so-called Fradkin-Vasiliev formalism for construction of the cubic
vertices, which requires the non-zero cosmological constant. Thus we first
construct the vertices in AdS space and then consider the flat limit. We show
that the AdS supersymmetric vertex is a sum of four elementary vertices for
supermultiplet components, while one of the vertices vanishes in the flat limit
in agreement with the Metsaev's classification.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:41:26 GMT""}]","2021-03-17"
"2012.00483","Markus Leippold","Francesco S. Varini and Jordan Boyd-Graber and Massimiliano Ciaramita
  and Markus Leippold","ClimaText: A Dataset for Climate Change Topic Detection","Accepted for the Tackling Climate Change with Machine Learning
  Workshop at NeurIPS 2020",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Climate change communication in the mass media and other textual sources may
affect and shape public perception. Extracting climate change information from
these sources is an important task, e.g., for filtering content and
e-discovery, sentiment analysis, automatic summarization, question-answering,
and fact-checking. However, automating this process is a challenge, as climate
change is a complex, fast-moving, and often ambiguous topic with scarce
resources for popular text-based AI tasks. In this paper, we introduce
\textsc{ClimaText}, a dataset for sentence-based climate change topic
detection, which we make publicly available. We explore different approaches to
identify the climate change topic in various text sources. We find that popular
keyword-based models are not adequate for such a complex and evolving task.
Context-based algorithms like BERT \cite{devlin2018bert} can detect, in
addition to many trivial cases, a variety of complex and implicit topic
patterns. Nevertheless, our analysis reveals a great potential for improvement
in several directions, such as, e.g., capturing the discussion on indirect
effects of climate change. Hence, we hope this work can serve as a good
starting point for further research on this topic.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:42:37 GMT""},{""version"":""v2"",""created"":""Sat, 2 Jan 2021 16:13:06 GMT""}]","2021-01-05"
"2012.00484","Robin Elliott","Robin Elliott","Efficient Cycles in Loop Space","15 pages",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates how the geometry of a cycle in the loop space of a
Riemannian manifold controls its topology. For fixed $\beta \in H^n(\Omega X;
\mathbb{R})$ one can ask how large $|\langle \beta, Z \rangle|$ can be for
cycles $Z$ supported in loops of length $\leq L$ and of volume $\leq L^{n-1}$
for a suitably defined notion of volume of in loop space. We show that an upper
bound to this question provides upper bounds Gromov's distortion of higher
homotopy groups. We also show that we can exhibit better lower bounds than are
currently known for the corresponding questions for Gromov's distortion.
Specifically, we show there exists a $\beta$ detecting the homotopy class of
the puncture in $[(\mathbb{CP}^2)^{\#4} \times S^2]^\circ$ and a family of
cycles $Z_L$ with the geometric bounds above such that $|\langle \beta, Z
\rangle| = \Omega(L^6/\text{log}L)$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:44:24 GMT""}]","2020-12-02"
"2012.00485","Muyang Ma","Muyang Ma and Pengjie Ren and Zhumin Chen and Zhaochun Ren and Lifan
  Zhao and Jun Ma and Maarten de Rijke","Mixed Information Flow for Cross-domain Sequential Recommendations","26 pages, 6 figures, TKDD journal, 7 co-authors",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Cross-domain sequential recommendation is the task of predict the next item
that the user is most likely to interact with based on past sequential behavior
from multiple domains. One of the key challenges in cross-domain sequential
recommendation is to grasp and transfer the flow of information from multiple
domains so as to promote recommendations in all domains. Previous studies have
investigated the flow of behavioral information by exploring the connection
between items from different domains. The flow of knowledge (i.e., the
connection between knowledge from different domains) has so far been neglected.
In this paper, we propose a mixed information flow network for cross-domain
sequential recommendation to consider both the flow of behavioral information
and the flow of knowledge by incorporating a behavior transfer unit and a
knowledge transfer unit. The proposed mixed information flow network is able to
decide when cross-domain information should be used and, if so, which
cross-domain information should be used to enrich the sequence representation
according to users' current preferences. Extensive experiments conducted on
four e-commerce datasets demonstrate that mixed information flow network is
able to further improve recommendation performance in different domains by
modeling mixed information flow.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:45:26 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 08:35:48 GMT""},{""version"":""v3"",""created"":""Sat, 5 Dec 2020 13:22:57 GMT""}]","2020-12-08"
"2012.00486","Weicheng Cai","Weicheng Cai, Ming Li","A Unified Deep Speaker Embedding Framework for Mixed-Bandwidth Speech
  Data",,,,,"eess.AS cs.CL cs.SD","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a unified deep speaker embedding framework for modeling
speech data with different sampling rates. Considering the narrowband
spectrogram as a sub-image of the wideband spectrogram, we tackle the joint
modeling problem of the mixed-bandwidth data in an image classification manner.
From this perspective, we elaborate several mixed-bandwidth joint training
strategies under different training and test data scenarios. The proposed
systems are able to flexibly handle the mixed-bandwidth speech data in a single
speaker embedding model without any additional downsampling, upsampling,
bandwidth extension, or padding operations. We conduct extensive experimental
studies on the VoxCeleb1 dataset. Furthermore, the effectiveness of the
proposed approach is validated by the SITW and NIST SRE 2016 datasets.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:45:38 GMT""}]","2020-12-02"
"2012.00487","Chao-Ming Lin","Chao-Ming Lin","Deformed Hermitian-Yang-Mills Equation on Compact Hermitian Manifolds","30 pages, 3 figures",,,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $(X, \omega)$ be a compact connected Hermitian manifold of dimension $n$.
We consider the Bott-Chern cohomology and let $[\chi ] \in
H^{1,1}_{\text{BC}}(X; \mathbb{R})$. We study the deformed Hermitian-Yang-Mills
equation, which is the following nonlinear elliptic equation $\sum_{i} \arctan
(\lambda_i) = h(x)$, where $\lambda_i$ are the eigenvalues of $\chi$ with
respect to $\omega$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:48:35 GMT""}]","2020-12-02"
"2012.00488","Leon Ladewig","Susanne Albers and Leon Ladewig","New Results for the $k$-Secretary Problem","Full and revised version of ISAAC 2019 paper",,,,"cs.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Suppose that $n$ items arrive online in random order and the goal is to
select $k$ of them such that the expected sum of the selected items is
maximized. The decision for any item is irrevocable and must be made on arrival
without knowing future items. This problem is known as the $k$-secretary
problem, which includes the classical secretary problem with the special case
$k=1$. It is well-known that the latter problem can be solved by a simple
algorithm of competitive ratio $1/e$ which is optimal for $n \to \infty$.
Existing algorithms beating the threshold of $1/e$ either rely on involved
selection policies already for $k=2$, or assume that $k$ is large.
  In this paper we present results for the $k$-secretary problem, considering
the interesting and relevant case that $k$ is small. We focus on simple
selection algorithms, accompanied by combinatorial analyses. As a main
contribution we propose a natural deterministic algorithm designed to have
competitive ratios strictly greater than $1/e$ for small $k \geq 2$. This
algorithm is hardly more complex than the elegant strategy for the classical
secretary problem, optimal for $k=1$, and works for all $k \geq 1$. We derive
its competitive ratios for $k \leq 100$, ranging from $0.41$ for $k=2$ to
$0.75$ for $k=100$.
  Moreover, we consider an algorithm proposed earlier in the literature, for
which no rigorous analysis is known. We show that its competitive ratio is
$0.4168$ for $k=2$, implying that the previous analysis was not tight. Our
analysis reveals a surprising combinatorial property of this algorithm, which
might be helpful to find a tight analysis for all $k$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:49:28 GMT""}]","2020-12-02"
"2012.00489","Massimiliano Luca","Filippo Simini, Gianni Barlacchi, Massimiliano Luca, Luca Pappalardo","Deep Gravity: enhancing mobility flows generation with deep neural
  networks and geographic information",,,,,"cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The movements of individuals within and among cities influence critical
aspects of our society, such as well-being, the spreading of epidemics, and the
quality of the environment. When information about mobility flows is not
available for a particular region of interest, we must rely on mathematical
models to generate them. In this work, we propose the Deep Gravity model, an
effective method to generate flow probabilities that exploits many variables
(e.g., land use, road network, transport, food, health facilities) extracted
from voluntary geographic data, and uses deep neural networks to discover
non-linear relationships between those variables and mobility flows. Our
experiments, conducted on mobility flows in England, Italy, and New York State,
show that Deep Gravity has good geographic generalization capability, achieving
a significant increase in performance (especially in densely populated regions
of interest) with respect to the classic gravity model and models that do not
use deep neural networks or geographic data. We also show how flows generated
by Deep Gravity may be explained in terms of the geographic features using
explainable AI techniques.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:49:46 GMT""},{""version"":""v2"",""created"":""Wed, 30 Dec 2020 19:42:54 GMT""},{""version"":""v3"",""created"":""Mon, 31 May 2021 13:46:17 GMT""},{""version"":""v4"",""created"":""Mon, 9 Aug 2021 07:49:13 GMT""},{""version"":""v5"",""created"":""Fri, 21 Jan 2022 09:55:28 GMT""}]","2022-05-02"
"2012.00490","Paul Appel","Paul Appel, Alexander J. Heilman, Ezekiel W. Wertz, David W. Lyons,
  Marcus Huber, Matej Pivoluska, Giuseppe Vitagliano","Finite-Function-Encoding Quantum States","Comments welcome","Quantum 6, 708 (2022)","10.22331/q-2022-05-09-708",,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We introduce finite-function-encoding (FFE) states which encode arbitrary
$d$-valued logic functions, i.e., multivariate functions over the ring of
integers modulo $d$, and investigate some of their structural properties. We
also point out some differences between polynomial and non-polynomial function
encoding states: The former can be associated to graphical objects, that we dub
tensor-edge hypergraphs (TEH), which are a generalization of hypergraphs with a
tensor attached to each hyperedge encoding the coefficients of the different
monomials. To complete the framework, we also introduce a notion of
finite-function-encoding Pauli (FP) operators, which correspond to elements of
what is known as the generalized symmetric group in mathematics. First, using
this machinery, we study the stabilizer group associated to FFE states and
observe how qudit hypergraph states introduced in arXiv:1612.06418v2 admit
stabilizers of a particularly simpler form. Afterwards, we investigate the
classification of FFE states under local unitaries (LU), and, after showing the
complexity of this problem, we focus on the case of bipartite states and
especially on the classification under local FP operations (LFP). We find all
LU and LFP classes for two qutrits and two ququarts and study several other
special classes, pointing out the relation between maximally entangled FFE
states and complex Butson-type Hadamard matrices. Our investigation showcases
also the relation between the properties of FFE states, especially their LU
classification, and the theory of finite rings over the integers.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:53:23 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 10:08:10 GMT""}]","2022-05-11"
"2012.00491","Dimas G. de Oteyza","Dimas G. de Oteyza, Aran Garcia-Lekue, Manuel Vilas-Varela, Nestor
  Merino, Eduard Carbonell-Sanrom\`a, Martina Corso, Guillaume Vasseur, Celia
  Rogero, Enrique Guitian, Jose Ignacio Pascua, J. Enrique Ortega, Yutaka
  Wakayama, Diego Pe\~na","Substrate-Independent Growth of Atomically Precise Chiral Graphene
  Nanoribbons",,"ACS Nano 2016, 10, 9000-9008","10.1021/acsnano.6b05269",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contributing to the need of new graphene nanoribbon (GNR) structures that can
be synthesized with atomic precision, we have designed a reactant that renders
chiral (3,1) - GNRs after a multi-step reaction including Ullmann coupling and
cyclodehydrogenation. The nanoribbon synthesis has been successfully proved on
different coinage metals, and the formation process, together with the
fingerprints associated to each reaction step, has been studied combining
scanning tunnelling microscopy, core-level spectroscopy and density functional
calculations. In addition to the GNR chiral edge structure, the substantial GNR
lengths achieved and the low processing temperature required to complete the
reaction grant this reactant extremely interesting properties for potential
applications.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:57:15 GMT""}]","2020-12-02"
"2012.00492","Konstantin Ivanov","Ivan V. Zhukov, Alexey S. Kiryutin, Alexandra V. Yurkovskaya, John W.
  Blanchard, Dmitry Budker, Konstantin L. Ivanov","Correlation of high-field and zero- to ultralow-field NMR properties
  using 2D spectroscopy",,,"10.1063/5.0039294",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  The field of zero- to ultralow-field (ZULF) nuclear magnetic resonance (NMR)
is currently experiencing a rapid growth, owing to the progress in optical
magnetometry, and also attractive features of ZULF NMR, such as low hardware
cost and excellent spectral resolution achieved under ZULF conditions. In this
work, an approach is proposed and demonstrated for simultaneous acquisition of
ZULF-NMR spectra of individual 13C-containing isotopomers of chemical compounds
in a complex mixture. The method makes use of fast field cycling, so that the
spin evolution takes place at ZULF conditions, whereas signal detection is
performed in a high-field NMR spectrometer. This method has excellent
sensitivity, also allowing easy assignment of ZULF-NMR spectra to specific
analytes in the mixture. We demonstrate that the spectral information is the
same as that given by ZULF-NMR, which makes the method suitable for creating a
library of ZULF-NMR spectra of various compounds and their isotopomers. The
results of the field-cycling experiments can be presented in a convenient way
as 2D-NMR spectra with the direct detection giving the high-field 13C-NMR
spectrum (carrying the chemical-shift information) and the indirect dimension
giving the ZULF-NMR spectrum (containing information about proton-carbon
J-couplings). Hence, the method can be seen as a variant of heteronuclear
J-resolved spectroscopy, one of the first 2D-NMR techniques.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:59:31 GMT""}]","2021-04-21"
"2012.00493","Iana Sereda","Iana Sereda, Sergey Alekseev, Aleksandra Koneva, Alexey Khorkin,
  Grigory Osipov","Problems of representation of electrocardiograms in convolutional neural
  networks",,,,,"cs.LG eess.SP stat.ML","http://creativecommons.org/licenses/by/4.0/","  Using electrocardiograms as an example, we demonstrate the characteristic
problems that arise when modeling one-dimensional signals containing inaccurate
repeating pattern by means of standard convolutional networks. We show that
these problems are systemic in nature. They are due to how convolutional
networks work with composite objects, parts of which are not fixed rigidly, but
have significant mobility. We also demonstrate some counterintuitive effects
related to generalization in deep networks.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:02:06 GMT""}]","2020-12-02"
"2012.00494","Dimas G. de Oteyza","Dimas G. de Oteyza, Alejandro P\'erez Paz, Yen-Chia Chen, Zahra
  Pedramrazi, Alexander Riss, Sebastian Wickenburg, Hsin-Zon Tsai, Felix R.
  Fischer, Michael F. Crommie, Angel Rubio","Non-Covalent Dimerization after Enediyne Cyclization on Au(111)",,"J. Am. Chem. Soc. 2016, 138, 10963-10967","10.1021/jacs.6b05203",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the thermally-induced cyclization of 1,2 - bis(2 -
phenylethynyl)benzene on Au(111) using scanning tunneling microscopy and
computer simulations. Cyclization of sterically hindered enediynes is known to
proceed via two competing mechanisms in solution: a classic C1 - C6 or a C1 -
C5 cyclization pathway. On Au(111) we find that the C1 - C5 cyclization is
suppressed and that the C1 - C6 cyclization yields a highly strained bicyclic
olefin whose surface chemistry was hitherto unknown. The C1 - C6 product
self-assembles into discrete non-covalently bound dimers on the surface. The
reaction mechanism and driving forces behind non-covalent association are
discussed in light of density functional theory calculations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:02:45 GMT""}]","2020-12-02"
"2012.00495","Jarmo Hietarinta","Jarmo Hietarinta and Da-jun Zhang","Discrete Boussinesq-type equations","45 pages, to appear in the CRC press book ""Nonlinear Systems and
  Their Remarkable Mathematical Structures, Vol. 3"", Norbert Euler and Da-jun
  Zhang (eds.) Added Equation (3.9) and some references",,,,"nlin.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a comprehensive review of the discrete Boussinesq equations based
on their three-component forms on an elementary quadrilateral. These equations
were originally found by Nijhoff et al using the direct linearization method
and later generalized by Hietarinta using a search method based on
multidimensional consistency. We derive from these three-component equations
their two- and one-component variants. From the one-component form we derive
two different semi-continuous limits as well as their fully continuous limits,
which turn out to be PDE's for the regular, modified and Schwarzian Boussinesq
equations. Several kinds of Lax pairs are also provided. Finally we give their
Hirota bilinear forms and multi-soliton solutions in terms of Casoratians.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:04:49 GMT""},{""version"":""v2"",""created"":""Sun, 27 Dec 2020 13:16:15 GMT""}]","2020-12-29"
"2012.00496","Callie Higgins","Callie I. Higgins, Tobin E. Brown, Jason P. Killgore","Digital Light Processing in a Hybrid Atomic Force Microscope: In situ,
  Nanoscale Characterization of the Printing Process","17 pages, 4 figures, 1 table",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Stereolithography (SLA) and digital light processing (DLP) are powerful
additive manufacturing techniques that address a wide range of applications
including regenerative medicine, prototyping, and manufacturing. Unfortunately,
these printing processes introduce micrometer-scale anisotropic inhomogeneities
due to the resin absorptivity, diffusivity, reaction kinetics, and swelling
during the requisite photoexposure. Previously, it has not been possible to
characterize high-resolution mechanical heterogeneity as it develops during the
printing process. By combining DLP 3D printing with atomic force microscopy in
a hybrid instrument, heterogeneity of a single, in situ printed voxel is
characterized. Here, we describe the instrument and demonstrate three
modalities for characterizing voxels during and after printing. Sensing
Modality I maps the mechanical properties of just-printed, resin-immersed
voxels, providing the framework to study the relationships between voxel sizes,
print exposure parameters, and voxel-voxel interactions. Modality II captures
the nanometric, in situ working curve and is the first demonstration of in situ
cure depth measurement. Modality III dynamically senses local rheological
changes in the resin by monitoring the viscoelastic damping coefficient of the
resin during patterning. Overall, this instrument equips researchers with a
tool to develop rich insight into resin development, process optimization, and
fundamental printing limits.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:07:05 GMT""}]","2020-12-02"
"2012.00497","Leon Ladewig","Susanne Albers and Arindam Khan and Leon Ladewig","Improved Online Algorithms for Knapsack and GAP in the Random Order
  Model","Full and revised version of APPROX 2019 paper",,,,"cs.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The knapsack problem is one of the classical problems in combinatorial
optimization: Given a set of items, each specified by its size and profit, the
goal is to find a maximum profit packing into a knapsack of bounded capacity.
In the online setting, items are revealed one by one and the decision, if the
current item is packed or discarded forever, must be done immediately and
irrevocably upon arrival. We study the online variant in the random order model
where the input sequence is a uniform random permutation of the item set.
  We develop a randomized (1/6.65)-competitive algorithm for this problem,
outperforming the current best algorithm of competitive ratio 1/8.06
[Kesselheim et al. SIAM J. Comp. 47(5)]. Our algorithm is based on two new
insights: We introduce a novel algorithmic approach that employs two given
algorithms, optimized for restricted item classes, sequentially on the input
sequence. In addition, we study and exploit the relationship of the knapsack
problem to the 2-secretary problem.
  The generalized assignment problem (GAP) includes, besides the knapsack
problem, several important problems related to scheduling and matching. We show
that in the same online setting, applying the proposed sequential approach
yields a (1/6.99)-competitive randomized algorithm for GAP. Again, our proposed
algorithm outperforms the current best result of competitive ratio 1/8.06
[Kesselheim et al. SIAM J. Comp. 47(5)].
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:08:00 GMT""}]","2020-12-02"
"2012.00498","Alberto Franceschini","Alberto Franceschini","Minimal bandwidth $\mathbb{C}^*$-actions on generalized Grassmannians","version 3",,,,"math.AG math.RT","http://creativecommons.org/licenses/by/4.0/","  The bandwidth of a $\mathbb{C}^*$-action of a polarized pair $(X,L)$ is a
natural measure of its complexity. In this paper we study
$\mathbb{C}^*$-actions on rational homogeneous spaces, determining which
provide minimal bandwidth. We prove that the minimal bandwidth is linked to the
smallest coefficient of the fundamental weight, in a base of simple roots,
which describes the variety as a marked Dynkin diagram. As a direct application
of the results we study the Chow ring of the Cayley plane $\mathrm{E}_6(6)$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:08:31 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 09:47:51 GMT""},{""version"":""v3"",""created"":""Wed, 6 Apr 2022 15:12:51 GMT""}]","2022-04-07"
"2012.00499","Fabian Hinder","Fabian Hinder, Jonathan Jakob, Barbara Hammer","Analysis of Drifting Features",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The notion of concept drift refers to the phenomenon that the distribution,
which is underlying the observed data, changes over time. We are interested in
an identification of those features, that are most relevant for the observed
drift. We distinguish between drift inducing features, for which the observed
feature drift cannot be explained by any other feature, and faithfully drifting
features, which correlate with the present drift of other features. This notion
gives rise to minimal subsets of the feature space, which are able to
characterize the observed drift as a whole. We relate this problem to the
problems of feature selection and feature relevance learning, which allows us
to derive a detection algorithm. We demonstrate its usefulness on different
benchmarks.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:09:19 GMT""}]","2020-12-02"
"2012.00500","Jiang Mingzhi","Mingzhi Jiang, Tianhao Wu, Zhe Wang, Yi Gong, Lin Zhang, Ren Ping Liu","A Multi-intersection Vehicular Cooperative Control based on
  End-Edge-Cloud Computing",,,,,"cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cooperative Intelligent Transportation Systems (C-ITS) will change the modes
of road safety and traffic management, especially at intersections without
traffic lights, namely unsignalized intersections. Existing researches focus on
vehicle control within a small area around an unsignalized intersection. In
this paper, we expand the control domain to a large area with multiple
intersections. In particular, we propose a Multi-intersection Vehicular
Cooperative Control (MiVeCC) to enable cooperation among vehicles in a large
area with multiple unsignalized intersections. Firstly, a vehicular
end-edge-cloud computing framework is proposed to facilitate end-edge-cloud
vertical cooperation and horizontal cooperation among vehicles. Then, the
vehicular cooperative control problems in the cloud and edge layers are
formulated as Markov Decision Process (MDP) and solved by two-stage
reinforcement learning. Furthermore, to deal with high-density traffic, vehicle
selection methods are proposed to reduce the state space and accelerate
algorithm convergence without performance degradation. A multi-intersection
simulation platform is developed to evaluate the proposed scheme. Simulation
results show that the proposed MiVeCC can improve travel efficiency at multiple
intersections by up to 4.59 times without collision compared with existing
methods.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:15:14 GMT""}]","2020-12-02"
"2012.00501","Minhas Kamal","Md Rifat Arefin, Minhas Kamal, Kishan Kumar Ganguly, Tarek Salah Uddin
  Mahmud","A Statistical Real-Time Prediction Model for Recommender System",,,,,"cs.IR","http://creativecommons.org/publicdomain/zero/1.0/","  Recommender system has become an inseparable part of online shopping and its
usability is increasing with the advancement of these e-commerce sites. An
effective and efficient recommender system benefits both the seller and the
buyer significantly. We considered user activities and product information for
the filtering process in our proposed recommender system. Our model has
achieved inspiring result (approximately 58% true-positive and 13%
false-positive) for the data set provided by RecSys Challenge 2015. This paper
aims to describe a statistical model that will help to predict the buying
behavior of a user in real-time during a session.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:16:50 GMT""}]","2020-12-02"
"2012.00502","Hai-Liang Wu","Hai-Liang Wu","Determinants concerning Legendre symbols","7 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The evaluations of determinants with Legendre symbol entries have close
relation with character sums over finite fields. Recently, Sun posed some
conjectures on this topic. In this paper, we prove some conjectures of Sun and
also study some variants. For example, we show the following result:
  Let $p=a^2+4b^2$ be a prime with $a,b$ integers and $a\equiv1\pmod4$. Then
for the determinant $$S(1,p):={\rm
det}\bigg[\left(\frac{i^2+j^2}{p}\right)\bigg]_{1\le i,j\le \frac{p-1}{2}},$$
the number $S(1,p)/a$ is an integral square, which confirms a conjecture posed
by Cohen, Sun and Vsemirnov.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:17:53 GMT""}]","2020-12-02"
"2012.00503","Krzysztof Pachucki","Vojt\v{e}ch Patk\'o\v{s}, Vladimir A. Yerokhin, Krzysztof Pachucki","Radiative $\bm{\alpha^7m}$ QED contribution to the helium Lamb shift","28 pages, corrected numerous misprints","Phys. Rev. A 103, 012803 (2021)","10.1103/PhysRevA.103.012803",,"physics.atom-ph hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present a derivation of the last unknown part of the $\alpha^7m$
contribution to the Lamb shift of a two-electron atom, induced by the radiative
QED effects beyond the Bethe logarithm. This derivation is performed in the
framework of nonrelativistic quantum electrodynamics and is valid for the
triplet (spin $S = 1$) atomic states. The obtained formulas are free from any
divergences and are suitable for a numerical evaluation. This opens a way for a
complete numerical calculation of the $\alpha^7m$ QED effects in helium, which
will allow an accurate determination of the nuclear charge radius from
measurements of helium transition frequencies.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:18:05 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 17:03:01 GMT""}]","2021-01-13"
"2012.00504","Boaz Lerner","Boaz Lerner, Guy Shiran, Daphna Weinshall","Boosting the Performance of Semi-Supervised Learning with Unsupervised
  Clustering",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Semi-Supervised Learning (SSL) has shown much promise in leveraging
unlabeled data while being provided with very few labels. In this paper, we
show that ignoring the labels altogether for whole epochs intermittently during
training can significantly improve performance in the small sample regime. More
specifically, we propose to train a network on two tasks jointly. The primary
classification task is exposed to both the unlabeled and the scarcely annotated
data, whereas the secondary task seeks to cluster the data without any labels.
As opposed to hand-crafted pretext tasks frequently used in self-supervision,
our clustering phase utilizes the same classification network and head in an
attempt to relax the primary task and propagate the information from the labels
without overfitting them. On top of that, the self-supervised technique of
classifying image rotations is incorporated during the unsupervised learning
phase to stabilize training. We demonstrate our method's efficacy in boosting
several state-of-the-art SSL algorithms, significantly improving their results
and reducing running time in various standard semi-supervised benchmarks,
including 92.6% accuracy on CIFAR-10 and 96.9% on SVHN, using only 4 labels per
class in each task. We also notably improve the results in the extreme cases of
1,2 and 3 labels per class, and show that features learned by our model are
more meaningful for separating the data.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:19:14 GMT""}]","2020-12-02"
"2012.00505","Elea Prat","El\'ea Prat, Lars Herre, Jalal Kazempour, Spyros Chatzivasileiadis","Design of a Continuous Local Flexibility Market with Network Constraints","Conference",,"10.1109/PowerTech46648.2021.9494978",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To the best of our knowledge, this paper proposes for the first time a design
of a continuous local flexibility market that explicitly considers network
constraints. Continuous markets are expected to be the most appropriate design
option during the early stages of local flexibility markets, where insufficient
liquidity can hinder market development. At the same time, increasingly loaded
distribution systems require to explicitly consider network constraints in
local flexibility market clearing in order to help resolve rather than
aggravate local network problems, such as line congestion and voltage issues.
This paper defines the essential design considerations, introduces the local
flexibility market clearing algorithm, and -- aiming to establish a starting
point for future research -- discusses design options and research challenges
that emerge during this procedure which require further investigation.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:21:03 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 08:15:00 GMT""}]","2022-10-12"
"2012.00506","Shengguo Li","Shengguo Li, Xinzhe Wu, Jose E. Roman, Ziyang Yuan, Ruibo Wang and
  Lizhi Cheng","A Parallel Direct Eigensolver for Sequences of Hermitian Eigenvalue
  Problems with No Tridiagonalization","19 pages and 9 figures",,,,"math.NA cs.MS cs.NA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, a Parallel Direct Eigensolver for Sequences of Hermitian
Eigenvalue Problems with no tridiagonalization is proposed, denoted by
\texttt{PDESHEP}, and it combines direct methods with iterative methods.
\texttt{PDESHEP} first reduces a Hermitian matrix to its banded form, then
applies a spectrum slicing algorithm to the banded matrix, and finally computes
the eigenvectors of the original matrix via backtransform. Therefore, compared
with conventional direct eigensolvers, \texttt{PDESHEP} avoids
tridiagonalization, which consists of many memory-bounded operations. In this
work, the iterative method in \texttt{PDESHEP} is based on the contour integral
method implemented in FEAST. The combination of direct methods with iterative
methods for banded matrices requires some efficient data redistribution
algorithms both from 2D to 1D and from 1D to 2D data structures. Hence, some
two-step data redistribution algorithms are proposed, which can be $10\times$
faster than ScaLAPACK routine \texttt{PXGEMR2D}. For the symmetric
self-consistent field (SCF) eigenvalue problems, \texttt{PDESHEP} can be on
average $1.25\times$ faster than the state-of-the-art direct solver in ELPA
when using $4096$ processes. Numerical results are obtained for dense Hermitian
matrices from real applications and large real sparse matrices from the
SuiteSparse collection.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:21:18 GMT""},{""version"":""v2"",""created"":""Wed, 29 Dec 2021 14:31:50 GMT""},{""version"":""v3"",""created"":""Fri, 18 Mar 2022 21:46:39 GMT""}]","2022-03-22"
"2012.00507","Yannick Klass","Maximilian B\""uckle, Yannick S. Kla{\ss}, Felix B. N\""agele, R\'emy
  Braive, Eva M. Weig","Universal length dependence of tensile stress in nanomechanical string
  resonators",,"Phys. Rev. Applied 15, 034063 (2021)","10.1103/PhysRevApplied.15.034063",,"cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the tensile stress in freely suspended nanomechanical string
resonators, and observe a material-independent dependence on the resonator
length. We compare strongly stressed sting resonators fabricated from four
different material systems based on amorphous silicon nitride, crystalline
silicon carbide as well as crystalline indium gallium phosphide. The tensile
stress is found to increase by approximately 50% for shorter resonators. We
establish a simple elastic model to describe the observed length dependence of
the tensile stress. The model accurately describes our experimental data. This
opens a perspective for stress-engineering the mechanical quality factor of
nanomechanical string resonators.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:21:55 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 12:56:36 GMT""}]","2021-04-08"
"2012.00508","Rupert Mitchell","Rupert Mitchell, Jan Blumenkamp and Amanda Prorok","Gaussian Process Based Message Filtering for Robust Multi-Agent
  Cooperation in the Presence of Adversarial Communication",,,,,"cs.RO cs.AI cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the problem of providing robustness to adversarial
communication in multi-agent systems. Specifically, we propose a solution
towards robust cooperation, which enables the multi-agent system to maintain
high performance in the presence of anonymous non-cooperative agents that
communicate faulty, misleading or manipulative information. In pursuit of this
goal, we propose a communication architecture based on Graph Neural Networks
(GNNs), which is amenable to a novel Gaussian Process (GP)-based probabilistic
model characterizing the mutual information between the simultaneous
communications of different agents due to their physical proximity and relative
position. This model allows agents to locally compute approximate posterior
probabilities, or confidences, that any given one of their communication
partners is being truthful. These confidences can be used as weights in a
message filtering scheme, thereby suppressing the influence of suspicious
communication on the receiving agent's decisions. In order to assess the
efficacy of our method, we introduce a taxonomy of non-cooperative agents,
which distinguishes them by the amount of information available to them. We
demonstrate in two distinct experiments that our method performs well across
this taxonomy, outperforming alternative methods. For all but the best informed
adversaries, our filtering method is able to reduce the impact that
non-cooperative agents cause, reducing it to the point of negligibility, and
with negligible cost to performance in the absence of adversaries.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:21:58 GMT""}]","2020-12-02"
"2012.00509","Gleb Lukicov","Gleb Lukicov","Alignment of the straw tracking detectors for the Fermilab Muon $g-2$
  experiment and systematic studies for a muon electric dipole moment
  measurement",,,,"FERMILAB-THESIS-2020-17","physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  The Fermilab Muon $g-2$ experiment is currently preparing for its fourth
data-taking period (Run-4). The experiment-wide effort on the analysis of Run-1
data is nearing completion, with the announcement of the first result expected
in the coming months. The final goal of the experiment is to determine the muon
magnetic anomaly to a precision of 140 ppb. This level of precision will
provide indirect evidence of new physics, if the central value agrees with the
previously-measured value of the magnetic anomaly. Essential in reducing the
systematic uncertainty, through measurements of the muon beam profile, are the
in-vacuum straw tracking detectors. A crucial prerequisite in obtaining
accurate distributions of the beam profile is the internal alignment of the
tracking detectors, which is described in this thesis. As a result of this
position calibration, the tracking efficiency has increased by 3%, while the
track quality increased by 4%. This thesis also discusses an additional
measurement that will be made using the tracking detectors: a search for an
electric dipole moment (EDM) of the muon, through the direct detection of an
oscillation in the average vertical angle of the electron from the muon decay.
An observation of a muon EDM would be evidence of new physics and would provide
a new source of CP violation in the charged lepton sector. Essential in
measuring the EDM are accurate and precise estimations of potential non-zero
radial and longitudinal magnetic fields, which were estimated using the Run-1
data. In addition, a preliminary analysis using the Run-1 data was undertaken
to estimate the available precision for the magnetic anomaly measurement using
the tracking detectors.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:22:31 GMT""}]","2020-12-08"
"2012.00510","Sharmila Rani","Sharmila Rani, Annapurni Subramaniam, Sindhu Pandey, Snehalata Sahu,
  Chayan Mondal, Gajendra Pandey","UOCS. V. UV study of the old open cluster NGC 188 using AstroSat","11 pages, 7 figures, 3 tables, Accepted for publication in Journal of
  Astrophysics and Astronomy",,"10.1007/s12036-020-09683-2",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the UV photometry of the old open cluster NGC188 obtained using
images acquired with Ultraviolet Imaging Telescope (UVIT) on board the ASTROSAT
satellite, in two far-UV (FUV) and one near-UV (NUV) filters. UVIT data is
utilised in combination with optical photometric data to construct the optical
and UV colour-magnitude diagrams (CMDs). In the FUV images, we detect only hot
and bright blue straggler stars (BSSs), one hot subdwarf, and one white dwarf
(WD) candidate. In the NUV images, we detect members up to a faintness limit of
~22 mag including 21 BSSs, 2 yellow straggler stars (YSSs), and one WD
candidate. This study presents the first NUV-optical CMDs, and are overlaid
with updated BaSTI-IAC isochrones and WD cooling sequence, which are found to
fit well to the observed CMDs. We use spectral energy distribution (SED)
fitting to estimate the effective temperatures, radii, and luminosities of the
UV-bright stars. We find the cluster to have an HB population with three stars
(Teff = 4750 - 21000 K). We also detect two yellow straggler stars, with one of
them with UV excess connected to its binarity and X-ray emission.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:22:57 GMT""}]","2021-06-23"
"2012.00511","Leon Ladewig","Susanne Albers and Arindam Khan and Leon Ladewig","Best Fit Bin Packing with Random Order Revisited","Full version of MFCS 2020 paper",,,,"cs.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Best Fit is a well known online algorithm for the bin packing problem, where
a collection of one-dimensional items has to be packed into a minimum number of
unit-sized bins. In a seminal work, Kenyon [SODA 1996] introduced the
(asymptotic) random order ratio as an alternative performance measure for
online algorithms. Here, an adversary specifies the items, but the order of
arrival is drawn uniformly at random. Kenyon's result establishes lower and
upper bounds of 1.08 and 1.5, respectively, for the random order ratio of Best
Fit. Although this type of analysis model became increasingly popular in the
field of online algorithms, no progress has been made for the Best Fit
algorithm after the result of Kenyon.
  We study the random order ratio of Best Fit and tighten the long-standing gap
by establishing an improved lower bound of 1.10. For the case where all items
are larger than 1/3, we show that the random order ratio converges quickly to
1.25. It is the existence of such large items that crucially determines the
performance of Best Fit in the general case. Moreover, this case is closely
related to the classical maximum-cardinality matching problem in the fully
online model. As a side product, we show that Best Fit satisfies a monotonicity
property on such instances, unlike in the general case.
  In addition, we initiate the study of the absolute random order ratio for
this problem. In contrast to asymptotic ratios, absolute ratios must hold even
for instances that can be packed into a small number of bins. We show that the
absolute random order ratio of Best Fit is at least 1.3. For the case where all
items are larger than 1/3, we derive upper and lower bounds of 21/16 and 1.2,
respectively.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:23:08 GMT""}]","2020-12-02"
"2012.00512","Shuxiong Zhang","Shuxiong Zhang","On large deviation probabilities for empirical distribution of branching
  random walks with heavy tails",,,,,"math.PR","http://creativecommons.org/licenses/by-sa/4.0/","  Given a branching random walk $(Z_n)_{n\geq0}$ on $\mathbb{R}$, let $Z_n(A)$
be the number of particles located in interval $A$ at generation $n$. It is
well known (e.g., \cite{biggins}) that under some mild conditions, $Z_n(\sqrt
nA)/Z_n(\mathbb{R})$ converges a.s. to $\nu(A)$ as $n\rightarrow\infty$, where
$\nu$ is the standard Gaussian measure. In this work, we investigate its large
deviation probabilities under the condition that the step size or offspring law
has heavy tail, i.e. the decay rate of $$\mathbb{P}(Z_n(\sqrt
nA)/Z_n(\mathbb{R})>p)$$ as $n\rightarrow\infty$, where $p\in(\nu(A),1)$. Our
results complete those in \cite{ChenHe} and \cite{Louidor}.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:23:54 GMT""}]","2020-12-02"
"2012.00513","S{\o}ren B. Vilsen","S{\o}ren B. Vilsen, Torben Tvedebrink, and Poul Svante Eriksen","DNA mixture deconvolution using an evolutionary algorithm with multiple
  populations, hill-climbing, and guided mutation",,,,,"stat.CO stat.AP stat.ML","http://creativecommons.org/licenses/by/4.0/","  DNA samples crime cases analysed in forensic genetics, frequently contain DNA
from multiple contributors. These occur as convolutions of the DNA profiles of
the individual contributors to the DNA sample. Thus, in cases where one or more
of the contributors were unknown, an objective of interest would be the
separation, often called deconvolution, of these unknown profiles. In order to
obtain deconvolutions of the unknown DNA profiles, we introduced a multiple
population evolutionary algorithm (MEA). We allowed the mutation operator of
the MEA to utilise that the fitness is based on a probabilistic model and guide
it by using the deviations between the observed and the expected value for
every element of the encoded individual. This guided mutation operator (GM) was
designed such that the larger the deviation the higher probability of mutation.
Furthermore, the GM was inhomogeneous in time, decreasing to a specified lower
bound as the number of iterations increased. We analysed 102 two-person DNA
mixture samples in varying mixture proportions. The samples were quantified
using two different DNA prep. kits: (1) Illumina ForenSeq Panel B (30 samples),
and (2) Applied Biosystems Precision ID Globalfiler NGS STR panel (72 samples).
The DNA mixtures were deconvoluted by the MEA and compared to the true DNA
profiles of the sample. We analysed three scenarios where we assumed: (1) the
DNA profile of the major contributor was unknown, (2) DNA profile of the minor
was unknown, and (3) both DNA profiles were unknown. Furthermore, we conducted
a series of sensitivity experiments on the ForenSeq panel by varying the
sub-population size, comparing a completely random homogeneous mutation
operator to the guided operator with varying mutation decay rates, and allowing
for hill-climbing of the parent population.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:23:55 GMT""}]","2020-12-02"
"2012.00515","Pablo Arag\'on","Pablo Aragon, Adriana Alvarado Garcia, Christopher A. Le Dantec,
  Claudia Flores-Saviaga, Jorge Saldivar","Civic Technologies: Research, Practice and Open Challenges","Proposal, outcome and position papers of the 23rd ACM Conference on
  Computer-Supported Cooperative Work and Social Computing (CSCW 2020) workshop
  ""Civic Technologies: Research, Practice, and Open Challenges""",,,,"cs.CY","http://creativecommons.org/licenses/by-sa/4.0/","  Over the last years, civic technology projects have emerged around the world
to advance open government and community action. Although Computer-Supported
Cooperative Work (CSCW) and Human-Computer Interaction (HCI) communities have
shown a growing interest in researching issues around civic technologies, yet
most research still focuses on projects from the Global North. The goal of this
workshop is, therefore, to advance CSCW research by raising awareness for the
ongoing challenges and open questions around civic technology by bridging the
gap between researchers and practitioners from different regions.
  The workshop will be organized around three central topics: (1) discuss how
the local context and infrastructure affect the design, implementation,
adoption, and maintenance of civic technology; (2) identify key elements of the
configuration of trust among government, citizenry, and local organizations and
how these elements change depending on the sociopolitical context where
community engagement takes place; (3) discover what methods and strategies are
best suited for conducting research on civic technologies in different
contexts. These core topics will be covered across sessions that will initiate
in-depth discussions and, thereby, stimulate collaboration between the CSCW
research community and practitioners of civic technologies from both Global
North and South.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:26:40 GMT""}]","2020-12-02"
"2012.00516","Samuel Marks","Samuel D. Marks, Peiyu Quan, Rui Liu, Matthew J. Highland, Hua Zhou,
  Thomas F. Keuch, G. Brian Stephenson, and Paul G. Evans","Instrument for in situ hard x-ray nanobeam characterization during
  epitaxial crystallization and materials transformations","28 pages, 6 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Solid-phase epitaxy (SPE) and other three-dimensional epitaxial
crystallization processes pose challenging structural and chemical
characterization problems. The concentration of defects, the spatial
distribution of elastic strain, and the chemical state of ions each vary with
nanoscale characteristic length scales and depend sensitively on the gas
environment and elastic boundary conditions during growth. The lateral or
three-dimensional propagation of crystalline interfaces in SPE has nanoscale or
submicron characteristic distances during typical crystallization times. An in
situ synchrotron hard x-ray instrument allows these features to be studied
during deposition and crystallization using diffraction, resonant scattering,
nanobeam and coherent diffraction imaging, and reflectivity. The instrument
incorporates a compact deposition system allowing the use of
short-working-distance x-ray focusing optics. Layers are deposited using
radio-frequency magnetron sputtering and evaporation sources. The deposition
system provides control of the gas atmosphere and sample temperature. The
sample is positioned using a stable mechanical design to minimize vibration and
drift and employs precise translation stages to enable nanobeam experiments.
Results of in situ x-ray characterization of the amorphous thin film deposition
process for a SrTiO3/BaTiO3 multilayer illustrate implementation of this
instrument.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:26:42 GMT""}]","2020-12-02"
"2012.00517","Tuomo Sipola","Joni Korpihalkola, Tuomo Sipola, Samir Puuska, Tero Kokkonen","One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer",,"2021 4th International Conference on Signal Processing and Machine
  Learning (SPML 2021) (2021) 100-106","10.1145/3483207.3483224",,"cs.CV cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computer vision and machine learning can be used to automate various tasks in
cancer diagnostic and detection. If an attacker can manipulate the automated
processing, the results can be devastating and in the worst case lead to wrong
diagnosis and treatment. In this research, the goal is to demonstrate the use
of one-pixel attacks in a real-life scenario with a real pathology dataset,
TUPAC16, which consists of digitized whole-slide images. We attack against the
IBM CODAIT's MAX breast cancer detector using adversarial images. These
adversarial examples are found using differential evolution to perform the
one-pixel modification to the images in the dataset. The results indicate that
a minor one-pixel modification of a whole slide image under analysis can affect
the diagnosis by reversing the automatic diagnosis result. The attack poses a
threat from the cyber security perspective: the one-pixel method can be used as
an attack vector by a motivated attacker.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:27:28 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 09:42:34 GMT""},{""version"":""v3"",""created"":""Wed, 2 Jun 2021 12:06:48 GMT""},{""version"":""v4"",""created"":""Wed, 16 Jun 2021 12:59:02 GMT""},{""version"":""v5"",""created"":""Tue, 24 Aug 2021 10:29:52 GMT""},{""version"":""v6"",""created"":""Tue, 2 Nov 2021 08:17:03 GMT""}]","2021-11-03"
"2012.00518","Jozef Dudek","Christopher T. Johnson and Jozef J. Dudek","Excited $J^{--}$ meson resonances at the SU(3) flavor point from lattice
  QCD",,"Phys. Rev. D 103, 074502 (2021)","10.1103/PhysRevD.103.074502","JLAB-THY-20-3291","hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first calculation within lattice QCD of excited light meson
resonances with $J^{PC} = 1^{--}$, $2^{--}$ and $3^{--}$. Working with an exact
SU(3) flavor symmetry, for the singlet representation of pseudoscalar-vector
scattering, we find two $1^{--}$ resonances, a lighter broad state and a
heavier narrow state, a broad $2^{--}$ resonance decaying in both $P$- and
$F$-waves, and a narrow $3^{--}$ state. We present connections to experimental
$\omega^\star_J, \phi^\star_J$ resonances decaying into $\pi \rho$,
$K\bar{K}^*$, $\eta \omega$ and other final states.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:30:52 GMT""}]","2021-04-21"
"2012.00519","Carlos Mafra","Hadleigh Frost, Carlos R. Mafra, Lionel Mason","A Lie bracket for the momentum kernel","48 pp",,,,"hep-th math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop new mathematical tools for the study of the double copy and
colour-kinematics duality for tree-level scattering amplitudes using the
properties of Lie polynomials. We show that the $S$-map that was defined to
simplify super-Yang--Mills multiparticle superfields is in fact a new Lie
bracket on the dual space of Lie polynomials. We introduce {\it Lie polynomial
currents} based on Berends-Giele recursion for biadjoint scalar tree amplitudes
that take values in Lie polynomials. Field theory amplitudes are obtained from
the Lie polynomial amplitudes by numerators characterized as homomorphisms from
the free Lie algebra to kinematic data. Examples are presented for the
biadjoint scalar, Yang--Mills theory and the nonlinear sigma model. That these
theories satisfy the Bern-Carrasco-Johansson amplitude relations follows from
the identities we prove for the Lie polynomial amplitudes and the existence of
BCJ numerators.
  A KLT map from Lie polynomials to their dual is obtained by nesting the S-map
Lie bracket; the matrix elements of this map yield a recently proposed
`generalized KLT matrix', and this reduces to the usual KLT matrix when its
entries are restricted to a basis. Using this, we give an algebraic proof for
the cancellation of double poles in the KLT formula for gravity amplitudes. We
finish with some remarks on numerators and colour-kinematics duality from this
perspective.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:32:13 GMT""}]","2020-12-02"
"2012.00520","\'Alvaro Llancaqueo Albornoz","\'A. Llancaqueo Albornoz (1), S. Villanova (1), C.C. Cort\'es (1 and
  2), J.A. Ahumada (3) and C. Parisi (3 and 4) ((1) Departamento de
  Astronom\'ia, Universidad de Concepci\'on, Chile, (2) Departamento de
  F\'isica, Facultad de Ciencias, Universidad del B\'io-B\'io, Chile, (3)
  Observatorio Astron\'omico, Universidad Nacional de C\'ordoba, Argentina, (4)
  Instituto de Astronom\'ia Te\'orica y Experimental (CONICET-UNC), Argentina)","Variability in NGC 3201 giant stars and its impact on their
  spectroscopic [Fe/H] determination","23 pages, 30 idividual figure files distributed in 14 figures (1
  figure is the Orcid figure), accepted in The Astronomical Journal (AJ)",,"10.3847/1538-3881/abcf2f",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present the analysis of 34 light curves in $V$ and $I$ of 17 giant stars
in the globular cluster NGC 3201, to check if such stars are variable and if
their variability has some kind of impact on the iron abundance as obtained
from spectroscopic measurements. First, we computed the Generalized
Lomb-Scargle and Phase Dispersion Minimization periodograms on the sample to
check if the stars were variables. In this way, 7 stars of the sample were
found to be non-variable, 2 stars are considered as possible variables, and 8
stars were found to be variable, with periods ranging from $0.0881\pm0.0001$ to
$0.5418\pm0.0027$ days. According to the literature, the variables have
distinct values of $\text{[Fe I/H]}$: the 3 most metal-rich stars are in the
RGB stage, one has an $\text{[Fe I/H]}=-1.37$ dex, while the other two have
$\text{[Fe I/H]}=-1.31$ dex. The two most metal-poor variables have $\text{[Fe
I/H]}=-1.61$ dex and $\text{[Fe I/H]}=-1.62$ dex, and are AGB stars; the
remaining variables have $\text{[Fe I/H]}=-1.44$, $-1.48$, and $-1.50$ dex, the
first two being RGB while the last is AGB star. On the other hand, stars that
appear to be non-variables have $-1.56\leq\text{[Fe I/H]}\leq-1.40$. We
conclude that variability somehow affects the spectroscopic determination of
the iron content of giant stars in NGC 3201 increasing the iron spread of the
cluster. If variability is not taken into account, this spread could be wrongly
interpreted as due to an intrinsic iron spread affecting the stars of the
cluster.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:32:26 GMT""}]","2021-01-27"
"2012.00521","Victor Francisco Ksoll","Victor F. Ksoll, Dimitrios Gouliermis, Elena Sabbi, Jenna E. Ryon,
  Massimo Robberto, Mario Gennaro, Ralf S. Klessen, Ullrich Koethe, Guido de
  Marchi, C.-H. Rosie Chen, Michele Cignoni, Andrew E. Dolphin","Measuring Young Stars in Space and Time -- I. The Photometric Catalog
  and Extinction Properties of N44","29 pages, 15 figures, accepted for publication in AJ",,"10.3847/1538-3881/abee8b",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to better understand the role of high-mass stellar feedback in
regulating star formation in giant molecular clouds, we carried out a Hubble
Space Telescope (HST) Treasury Program ""Measuring Young Stars in Space and
Time"" (MYSST) targeting the star-forming complex N44 in the Large Magellanic
Cloud (LMC). Using the F555W and F814W broadband filters of both the ACS and
WFC3/UVIS, we built a photometric catalog of 461,684 stars down to
$m_\mathrm{F555W} \simeq 29$ mag and $m_\mathrm{F814W} \simeq 28$ mag,
corresponding to the magnitude of an unreddened 1 Myr pre-main-sequence star of
$\approx0.09$ $M_\odot$ at the LMC distance. In this first paper we describe
the observing strategy of MYSST, the data reduction procedure, and present the
photometric catalog. We identify multiple young stellar populations tracing the
gaseous rim of N44's super bubble, together with various contaminants belonging
to the LMC field population. We also determine the reddening properties from
the slope of the elongated red clump feature by applying the machine learning
algorithm RANSAC, and we select a set of Upper Main Sequence (UMS) stars as
primary probes to build an extinction map, deriving a relatively modest median
extinction $A_{\mathrm{F555W}}\simeq0.77$ mag. The same procedure applied to
the red clump provides $A_{\mathrm{F555W}}\simeq 0.68$ mag.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:33:01 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 11:51:09 GMT""}]","2021-05-19"
"2012.00522","J\'er\'emy L\'etang","J\'er\'emy L\'etang, Claudia de Melo, Charles Guillemard, Aymeric
  Vecchiola, Damien Rontani, S\'ebastien Petit-Watelot, Myoung-Woo Yoo, Thibaut
  Devolder, Karim Bouzehouane, Vincent Cros, St\'ephane Andrieu and Joo-Von Kim","Nanocontact vortex oscillators based on Co$_2$MnGe pseudo-spin valves",,"Phys. Rev. B 103, 224424 (2021)","10.1103/PhysRevB.103.224424",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an experimental study of vortex dynamics in magnetic nanocontacts
based on pseudo spin valves comprising the Co$_2$MnGe Heusler compound. The
films were grown by molecular beam epitaxy, where precise stoichiometry control
and tailored stacking order allowed us to define the bottom ferromagnetic layer
as the reference layer, with minimal coupling between the free and reference
layers. 20-nm diameter nanocontacts were fabricated using a nano-indentation
technique, leading to self-sustained gyration of the vortex generated by
spin-transfer torques above a certain current threshold. By combining
frequency- and time-domain measurements, we show that different types of
spin-transfer induced dynamics related to different modes associated to the
magnetic vortex configuration can be observed, such as mode hopping, mode
coexistence and mode extinction appear in addition to the usual gyration mode.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:33:21 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 06:05:48 GMT""},{""version"":""v3"",""created"":""Mon, 28 Jun 2021 08:16:46 GMT""}]","2021-06-29"
"2012.00523","Mancho Manev","Mancho Manev and Veselina Tavkova","Hyperspheres in Euclidean and Minkowski 4-spaces as almost paracontact
  almost paracomplex Riemannian manifolds","9 pages","Novi Sad Journal of Mathematics, 2021","10.30755/NSJOM.12136",,"math.DG","http://creativecommons.org/licenses/by/4.0/","  Almost paracontact almost paracomplex Riemannian manifolds of the lowest
dimension are studied. Such structures are constructed on hyperspheres in
4-dimensional spaces, Euclidean and pseudo-Euclidean, respectively. The
obtained manifolds are studied and characterised in terms of the classification
used and their geometric properties.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:33:26 GMT""}]","2021-01-22"
"2012.00524","Victor Francisco Ksoll","Victor F. Ksoll, Dimitrios Gouliermis, Elena Sabbi, Jenna E. Ryon,
  Massimo Robberto, Mario Gennaro, Ralf S. Klessen, Ullrich Koethe, Guido de
  Marchi, C.-H. Rosie Chen, Michele Cignoni, Andrew E. Dolphin","Measuring Young Stars in Space and Time -- II. The Pre-Main-Sequence
  Stellar Content of N44","29 pages, 21 figures, accepted for publication in AJ",,"10.3847/1538-3881/abee8c",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Hubble Space Telescope (HST) survey Measuring Young Stars in Space and
Time (MYSST) entails some of the deepest photometric observations of
extragalactic star formation, capturing even the lowest mass stars of the
active star-forming complex N44 in the Large Magellanic Cloud. We employ the
new MYSST stellar catalog to identify and characterize the content of young
pre-main-sequence (PMS) stars across N44 and analyze the PMS clustering
structure. To distinguish PMS stars from more evolved line of sight
contaminants, a non-trivial task due to several effects that alter photometry,
we utilize a machine learning classification approach. This consists of
training a support vector machine (SVM) and a random forest (RF) on a carefully
selected subset of the MYSST data and categorize all observed stars as PMS or
non-PMS. Combining SVM and RF predictions to retrieve the most robust set of
PMS sources, we find $\sim26,700$ candidates with a PMS probability above 95%
across N44. Employing a clustering approach based on a nearest neighbor surface
density estimate, we identify 18 prominent PMS structures at $1$ $\sigma$
significance above the mean density with sub-clusters persisting up to and
beyond $3$ $\sigma$ significance. The most active star-forming center, located
at the western edge of N44's bubble, is a subcluster with an effective radius
of $\sim 5.6$ pc entailing more than 1,100 PMS candidates. Furthermore, we
confirm that almost all identified clusters coincide with known H II regions
and are close to or harbor massive young O stars or YSOs previously discovered
by MUSE and Spitzer observations.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:33:44 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 11:51:16 GMT""}]","2021-05-19"
"2012.00525","Ivan Kaygorodov","Ivan Kaygorodov, Mykola Khrypchenko and Samuel A. Lopes","The algebraic classification of nilpotent algebras","arXiv admin note: text overlap with arXiv:2006.00734,
  arXiv:2001.00253",,"10.1142/S0219498820502205",,"math.RA","http://creativecommons.org/publicdomain/zero/1.0/","  We give the complete algebraic classification of all complex 4-dimensional
nilpotent algebras. The final list has 234 (parametric families of) isomorphism
classes of algebras, 66 of which are new in the literature.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:37:10 GMT""}]","2021-11-02"
"2012.00526","Changliang Ren","Changbo Chen, Changliang Ren, Hongqing Lin, and He Lu","Entanglement Structure Detection via Machine Learning",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Detecting the entanglement structure, such as intactness and depth, of an
n-qubit state is important for understanding the imperfectness of the state
preparation in experiments. However, identifying such structure usually
requires an exponential number of local measurements. In this letter, we
propose an efficient machine learning based approach for predicting the
entanglement intactness and depth simultaneously. The generalization ability of
this classifier has been convincingly proved, as it can precisely distinguish
the whole range of pure generalized GHZ states which never exist in the
training process. In particular, the learned classifier can discover the
entanglement intactness and depth bounds for the noised GHZ state, for which
the exact bounds are only partially known.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:37:56 GMT""},{""version"":""v2"",""created"":""Sat, 12 Dec 2020 12:58:50 GMT""}]","2020-12-15"
"2012.00527","William Giar\`e","William Giar\`e, Fabrizio Renzi, Alessandro Melchiorri","Higher-Curvature Corrections and Tensor Modes","11 pages, 3 figures","Phys. Rev. D 103, 043515 (2021)","10.1103/PhysRevD.103.043515",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Higher-curvature corrections to the effective gravitational action may leave
signatures in the spectrum of primordial tensor perturbations if the
inflationary energy scale is sufficiently high. In this paper we further
investigate the effects of a coupling of the Inflaton field to higher-curvature
tensors in models with a minimal breaking of conformal symmetry. We show that
an observable violation of the tensor consistency relation from
higher-curvature tensors implies also a relatively large running of the tensor
tilt, enhanced even by some order of magnitude with respect to the standard
slow roll case. This may leave signatures in the tensor two-point function that
we could test to recognize higher-curvature effects, above all if they are
translated into a blue tilted spectrum visible by future Gravitational Wave
experiments. Exploiting current cosmic microwave background and gravitational
wave data we also derive constraints on the inflationary parameters, inferring
that large higher-curvature corrections seem to be disfavored.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:38:36 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 15:24:09 GMT""}]","2021-02-15"
"2012.00528","G\'erald Tenenbaum","R\'egis de la Bret\`eche, G\'erald Tenenbaum","On strong and almost sure local limit theorems for a probabilistic model
  of the Dickman distribution",,,,,"math.PR math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\{Z_k\}_{k\geqslant 1}$ denote a sequence of independent Bernoulli
random variables defined by ${\mathbb P}(Z_k=1)=1/k=1-{\mathbb P}(Z_k=0)$
$(k\geqslant 1)$ and put $T_n:=\sum_{1\leqslant k\leqslant n}kZ_k$. It is then
known that $T_n/n$ converges weakly to a real random variable $D$ with density
proportional to the Dickman function, defined by the delay-differential
equation $u\varrho'(u)+\varrho(u-1)=0$ $(u>1)$ with initial condition
$\varrho(u)=1$ $(0\leqslant u\leqslant 1)$. Improving on earlier work, we
propose asymptotic formulae with remainders for the corresponding local and
almost sure limit theorems.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:40:28 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 11:27:06 GMT""},{""version"":""v3"",""created"":""Mon, 21 Dec 2020 10:04:30 GMT""},{""version"":""v4"",""created"":""Mon, 8 Mar 2021 01:57:35 GMT""}]","2021-03-09"
"2012.00529","Suvrat Rao","Suvrat Rao, Marcus Br\""uggen and Jochen Liske","Detection of gravitational waves in circular particle accelerators","9 pages, 2 figures. This manuscript has been accepted for publication
  as a Regular Article in Physical Review D",,"10.1103/PhysRevD.102.122006",,"astro-ph.IM gr-qc physics.acc-ph physics.ins-det","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Here we calculate the effects of astrophysical gravitational waves (GWs) on
the travel times of proton bunch test masses in circular particle accelerators.
We show that a high-precision proton bunch time-tagging detector could turn a
circular particle accelerator facility into a GW observatory sensitive to
millihertz (mHz) GWs. We comment on sources of noise and the technological
feasibility of ultrafast single photon detectors by conducting a case study of
the Large Hadron Collider (LHC) at CERN.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:42:53 GMT""}]","2021-01-06"
"2012.00530","Maria Bada Dr","Maria Bada and Richard Clayton","Online Suicide Games: A Form of Digital Self-harm or A Myth?","7 pages","In Wiederhold, B, & Riva, G. & Debb, S. Annual Review of
  Cybertherapy and Telemedicine (ARCTT) International Association of
  CyberPsychology, Training, and Rehabilitation (iACToR), 2019",,"Conference Proceedings CYPSY24: 24th Annual CyberPsychology,
  CyberTherapy & Social Networking Conference, 2019","cs.CY cs.HC","http://creativecommons.org/licenses/by/4.0/","  Online suicide games are claimed to involve a series of challenges, ending in
suicide. A whole succession of these such as the Blue Whale Challenge, Momo,
the Fire Fairy and Doki Doki have appeared in recent years. The challenge
culture is a deeply rooted online phenomenon, whether the challenge is
dangerous or not, while social media particularly motivates youngsters to take
part because of their desire for attention. Although there is no evidence that
the suicide games are real, authorities around the world have reacted by
releasing warnings and creating information campaigns to warn youngsters and
parents. We interviewed teachers, child protection experts and NGOs, conducted
a systematic review of historical news reports from 2015-2019 and searched
police and other authority websites to identify relevant warning releases. We
then synthesized the existing knowledge on the suicide games phenomenon. A key
finding of our work is that media, social media and warning releases by
authorities are mainly just serving to spread the challenge culture and
exaggerate fears regarding online risk.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:45:47 GMT""}]","2021-02-02"
"2012.00531","Ji Il Kim","Ji il Kim","Energy Band Engineering of Periodic Scatterers by Quasi-1D Confinement","two column, 9 pages, 4 figures","J. Phys. Commun. 5, 055015 (2021)","10.1088/2399-6528/abfff9",,"quant-ph cond-mat.other","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A mechanism to modify the energy band structure is proposed by considering a
chain of periodic scatterers forming a linear lattice around which an external
cylindrical trapping potential is applied along the chain axis. When this
trapping (confining) potential is tight enough, it may modify the bound and
scattering states of the lattice potential, whose three-dimensional nature
around each scattering center is fully taken into account and not resorting to
zero-range pseudo-potentials. Since these states contribute to the formation of
the energy bands, such bands could thereby be continuously tuned by
manipulating the confinement without the need to change the lattice potential.
In particular, such dimensionality reduction by quantum confinement can close
band gaps either at the center or at the edge of the momentum k-space.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:48:04 GMT""}]","2021-07-01"
"2012.00535","Hicham Agueny","Hicham Agueny","Coherent electron displacement for quantum information processing using
  attosecond single cycle pulses","13 pages, 4 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Coherent electron displacement is a conventional strategy for processing
quantum information, as it enables to interconnect distinct sites in a network
of atoms. The efficiency of the processing relies on the precise control of the
mechanism, which has yet to be established. Here, we theoretically demonstrate
a new route to drive the electron displacement on a timescale faster than that
of the dynamical distortion of the electron wavepacket by utilizing attosecond
single-cycle pulses. The characteristic feature of these pulses relies on a
vast momentum transfer to an electron, leading to its displacement following a
unidirectional path. The scenario is illustrated by revealing the
spatiotemporal nature of the displaced wavepacket encoding a quantum
superposition state. We map out the associated phase information and retrieve
it over long distances from the origin. Moreover, we show that a sequence of
such pulses applied to a chain of ions enables attosecond control of the
directionality of the coherent motion of the electron wavepacket back and forth
between the neighbouring sites. An extension to a two-electron spin state
demonstrates the versatility of the use of these pulses. Our findings establish
a promising route for advanced control of quantum states using attosecond
single-cycle pulses, which pave the way towards ultrafast processing of quantum
information as well as imaging.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:50:57 GMT""}]","2020-12-02"
"2012.00539","Ranveer Kumar Singh","Ajit Bhand and Ranveer Kumar Singh","Zagier's weight $3/2$ mock modular form","A new lemma has been added, proofs of some of the lemmas have been
  corrected",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mock modular forms have their origins in Ramanujan's pioneering work on mock
theta functions. In a 1975 paper, Zagier proved certain transformation
properties of the generating function of the Hurwitz class numbers $H(n)$ for
the discriminant $(-n)$. In the modern framework, these results show that the
generating function of $H(n)$ is a mock modular form of weight 3/2 with the
theta function being the shadow. In this expository paper, we provide a
detailed proof of Zagier's result.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:54:33 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 11:18:42 GMT""}]","2022-05-19"
"2012.00540","Carlos Gonzalez-Ballestero","C. Gonzalez-Ballestero, T. van der Sar, O. Romero-Isart","Towards a quantum interface between spin waves and paramagnetic spin
  baths","10 pages, 4 figures + Appendix (34 pages, 12 figures)","Physical Review B 105, 075410 (2022)","10.1103/PhysRevB.105.075410",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spin waves have risen as promising candidate information carriers for the
next generation of information technologies. Recent experimental demonstrations
of their detection using electron spins in diamond pave the way towards
studying the back-action of a controllable paramagnetic spin bath on the spin
waves. Here, we present a quantum theory describing the interaction between
spin waves and paramagnetic spins. As a case study we consider an ensemble of
nitrogen-vacancy spins in diamond in the vicinity of an Yttrium-Iron-Garnet
thin film. We show how the back-action of the ensemble results in strong and
tuneable modifications of the spin-wave spectrum and propagation properties.
These modifications include the full suppression of spin-wave propagation and,
in a different parameter regime, the enhancement of their propagation length by
$\sim 50\%$. Furthermore, we show how the spin wave thermal fluctuations induce
a measurable frequency shift of the paramagnetic spins in the bath. This shift
results in a thermal dispersion force that can be measured optically and/or
mechanically with a diamond mechanical resonator. In addition, we use our
theory to compute the spin wave-mediated interaction between the spins in the
bath. We show that all the above effects are measurable by state-of-the-art
experiments. Our results provide the theoretical foundation for describing
hybrid quantum systems of spin waves and spin baths, and establish the
potential of quantum spins as active control, sensing, and interfacing tools
for spintronics.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:54:43 GMT""}]","2022-02-17"
"2012.00542","Riccardo Pengo","Fabien Pazuki, Riccardo Pengo","On the Northcott property for special values of L-functions","44 pages. Comments are very welcome!",,,"ANR-10-LABX-0070, ANR-17-CE40-0012, GDRI/IRN GANDA","math.NT math.AG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose an investigation on the Northcott, Bogomolov and Lehmer properties
for special values of $L$-functions. We first introduce an axiomatic approach
to these three properties. We then focus on the Northcott property for special
values of $L$-functions. In the case of $L$-functions of pure motives, we prove
a Northcott property for special values located at the left of the critical
strip, assuming that the $L$-functions in question satisfy some expected
properties. Inside the critical strip, focusing on the Dedekind zeta function
of number fields, we prove that such a property does not hold for the special
value at one, but holds for the special value at zero, and we give a related
quantitative estimate in this case.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:56:21 GMT""},{""version"":""v2"",""created"":""Thu, 17 Dec 2020 18:46:12 GMT""},{""version"":""v3"",""created"":""Mon, 26 Jul 2021 18:26:40 GMT""},{""version"":""v4"",""created"":""Thu, 23 Mar 2023 16:13:35 GMT""}]","2023-03-24"
"2012.00544","Nesara Dissanayake","Nesara Dissanayake, Asangi Jayatilaka, Mansooreh Zahedi, M. Ali Babar","Software Security Patch Management -- A Systematic Literature Review of
  Challenges, Approaches, Tools and Practices","45 pages, 7 figures",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Context: Software security patch management purports to support the process
of patching known software security vulnerabilities. Given the increasing
recognition of the importance of software security patch management, it is
important and timely to systematically review and synthesise the relevant
literature on this topic.
  Objective: This paper aims at systematically reviewing the state of the art
of software security patch management to identify the socio-technical
challenges in this regard, reported solutions (i.e., approaches, tools, and
practices), the rigour of the evaluation and the industrial relevance of the
reported solutions, and to identify the gaps for future research.
  Method: We conducted a systematic literature review of 72 studies published
from 2002 to March 2020, with extended coverage until September 2020 through
forward snowballing.
  Results: We identify 14 socio-technical challenges, 18 solution approaches,
tools and practices mapped onto the software security patch management process.
We provide a mapping between the solutions and challenges to enable a reader to
obtain a holistic overview of the gap areas. The findings also reveal that only
20.8% of the reported solutions have been rigorously evaluated in industrial
settings.
  Conclusion: Our results reveal that 50% of the common challenges have not
been directly addressed in the solutions and that most of them (38.9%) address
the challenges in one phase of the process, namely vulnerability scanning,
assessment and prioritisation. Based on the results that highlight the
important concerns in software security patch management and the lack of
solutions, we recommend a list of future research directions. This study also
provides useful insights about different opportunities for practitioners to
adopt new solutions and understand the variations of their practical utility.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:56:43 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 07:58:12 GMT""},{""version"":""v3"",""created"":""Fri, 20 Aug 2021 02:33:40 GMT""}]","2021-08-23"
"2012.00545","Ioannis Manthos","S. Aune, J. Bortfeldt, F. Brunbauer, C. David, D. Desforge, G.
  Fanourakis, M. Gallinaro, F. Garc\'ia, I. Giomataris, T. Gustavsson, F.J.
  Iguaz, M. Kebbiri, K. Kordas, C. Lampoudis, P. Legou, M. Lisowska, J. Liu, M.
  Lupberger, O. Maillard, I. Manthos, H. M\""uller, E. Oliveri, T.
  Papaevangelou, K. Paraschou, M. Pomorski, B. Qi, F. Resnati, L. Ropelewski,
  D. Sampsonidis, L. Scharenberg, T. Schneider, L. Sohl, M. van Stenis, A.
  Tsiamis, Y. Tsipolitis, S.E. Tzamarias, A. Utrobicic, R. Veenhof, X. Wang, S.
  White, Z. Zhang, Y. Zhou","Timing performance of a multi-pad PICOSEC-Micromegas detector prototype","29 pages, 20 figures",,"10.1016/j.nima.2021.165076",,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The multi-pad PICOSEC-Micromegas is an improved detector prototype with a
segmented anode, consisting of 19 hexagonal pads. Detailed studies are
performed with data collected in a muon beam over four representative pads. We
demonstrate that such a device, scalable to a larger area, provides excellent
time resolution and detection efficiency. As expected from earlier single-cell
device studies, we measure a time resolution of approximately 25 picoseconds
for charged particles hitting near the anode pad centers, and up to 30
picoseconds at the pad edges. Here, we study in detail the effect of drift gap
thickness non-uniformity on the timing performance and evaluate impact position
based corrections to obtain a uniform timing response over the full detector
coverage.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:59:33 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 13:22:34 GMT""}]","2021-01-29"
"2012.00552","Cristina Abad","Cristina L. Abad, Eduardo Ortiz-Holguin, Edwin F. Boza","Have We Reached Consensus? An Analysis of Distributed Systems Syllabi","Accepted for publication at ACM SIGCSE Technical Symposium 2021:
  https://sigcse2021.sigcse.org/ Publication DOI (already assigned by ACM):
  10.1145/3408877.3432409 Dataset available at:
  https://zenodo.org/record/4290623#.X8ZaOWjYre8",,"10.1145/3408877.3432409",,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Correctly applying distributed systems concepts is important for software
that seeks to be scalable, reliable and fast. For this reason, Distributed
Systems is a course included in many Computer Science programs. To both
describe current trends in teaching distributed systems and as a reference for
educators that seek to improve the quality of their syllabi, we present a
review of 51 syllabi of distributed systems courses from top Computer Science
programs around the world. We manually curated the syllabi and extracted data
that allowed us to identify approaches used in teaching this subject, including
choice of topics, book, and paper reading list. We present our results and a
discussion on whether what is being taught matches the guidelines of two
important curriculum initiatives.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:00:32 GMT""}]","2020-12-02"
"2012.00554","Xiao-Dong Yu","Xiao-Dong Yu, Timo Simnacher, H. Chau Nguyen, Otfried G\""uhne","Quantum-Inspired Hierarchy for Rank-Constrained Optimization","19 pages, 5 figures, close to the published version","PRX Quantum 3, 010340 (2022)","10.1103/PRXQuantum.3.010340",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many problems in information theory can be reduced to optimizations over
matrices, where the rank of the matrices is constrained. We establish a link
between rank-constrained optimization and the theory of quantum entanglement.
More precisely, we prove that a large class of rank-constrained semidefinite
programs can be written as a convex optimization over separable quantum states
and, consequently, we construct a complete hierarchy of semidefinite programs
for solving the original problem. This hierarchy not only provides a sequence
of certified bounds for the rank-constrained optimization problem, but also
gives pretty good and often exact values in practice when the lowest level of
the hierarchy is considered. We demonstrate that our approach can be used for
relevant problems in quantum information processing, such as the optimization
over pure states, the characterization of mixed unitary channels and faithful
entanglement, and quantum contextuality, as well as in classical information
theory including the maximum cut problem, pseudo-Boolean optimization, and the
orthonormal representation of graphs. Finally, we show that our ideas can be
extended to rank-constrained quadratic and higher-order programming.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:00:52 GMT""},{""version"":""v2"",""created"":""Mon, 14 Mar 2022 01:57:40 GMT""}]","2022-03-15"
"2012.00555","Mohnish Dubey","Nandana Mihindukulasooriya and Mohnish Dubey and Alfio Gliozzo and
  Jens Lehmann and Axel-Cyrille Ngonga Ngomo and Ricardo Usbeck","SeMantic AnsweR Type prediction task (SMART) at ISWC 2020 Semantic Web
  Challenge",,,,,"cs.AI cs.CL cs.IR","http://creativecommons.org/licenses/by/4.0/","  Each year the International Semantic Web Conference accepts a set of Semantic
Web Challenges to establish competitions that will advance the state of the art
solutions in any given problem domain. The SeMantic AnsweR Type prediction task
(SMART) was part of ISWC 2020 challenges. Question type and answer type
prediction can play a key role in knowledge base question answering systems
providing insights that are helpful to generate correct queries or rank the
answer candidates. More concretely, given a question in natural language, the
task of SMART challenge is, to predict the answer type using a target ontology
(e.g., DBpedia or Wikidata).
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:02:11 GMT""}]","2020-12-02"
"2012.00556","Joxan Jaffar","Joxan Jaffar, Rasool Maghareh, Sangharatna Godboley, Xuan-Linh Ha","TracerX: Dynamic Symbolic Execution with Interpolation",,,,,"cs.PL cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamic Symbolic Execution (DSE) is an important method for the testing of
programs. An important system on DSE is KLEE which inputs a C/C++ program
annotated with symbolic variables, compiles it into LLVM, and then emulates the
execution paths of LLVM using a specified backtracking strategy. The major
challenge in symbolic execution is path explosion. The method of abstraction
learning has been used to address this. The key step here is the computation of
an interpolant to represent the learnt abstraction. In this paper, we present a
new interpolation algorithm and implement it on top of the KLEE system. The
main objective is to address the path explosion problem in pursuit of code
penetration: to prove that a target program point is either reachable or
unreachable. That is, our focus is verification. We show that despite the
overhead of computing interpolants, the pruning of the symbolic execution tree
that interpolants provide often brings significant overall benefits. We then
performed a comprehensive experimental evaluation against KLEE, as well as
against one well-known system that is based on Static Symbolic Execution, CBMC.
Our primary experiment shows code penetration success at a new level,
particularly so when the target is hard to determine. A secondary experiment
shows that our implementation is competitive for testing.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:02:38 GMT""}]","2020-12-02"
"2012.00557","Victor Boutin","Victor Boutin, Aimen Zerroug, Minju Jung, Thomas Serre","Iterative VAE as a predictive brain model for out-of-distribution
  generalization",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Our ability to generalize beyond training data to novel, out-of-distribution,
image degradations is a hallmark of primate vision. The predictive brain,
exemplified by predictive coding networks (PCNs), has become a prominent
neuroscience theory of neural computation. Motivated by the recent successes of
variational autoencoders (VAEs) in machine learning, we rigorously derive a
correspondence between PCNs and VAEs. This motivates us to consider iterative
extensions of VAEs (iVAEs) as plausible variational extensions of the PCNs. We
further demonstrate that iVAEs generalize to distributional shifts
significantly better than both PCNs and VAEs. In addition, we propose a novel
measure of recognizability for individual samples which can be tested against
human psychophysical data. Overall, we hope this work will spur interest in
iVAEs as a promising new direction for modeling in neuroscience.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:02:38 GMT""}]","2020-12-02"
"2012.00558","Christian Cosgrove","Christian Cosgrove, Adam Kortylewski, Chenglin Yang, Alan Yuille","Robustness Out of the Box: Compositional Representations Naturally
  Defend Against Black-Box Patch Attacks",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Patch-based adversarial attacks introduce a perceptible but localized change
to the input that induces misclassification. While progress has been made in
defending against imperceptible attacks, it remains unclear how patch-based
attacks can be resisted. In this work, we study two different approaches for
defending against black-box patch attacks. First, we show that adversarial
training, which is successful against imperceptible attacks, has limited
effectiveness against state-of-the-art location-optimized patch attacks.
Second, we find that compositional deep networks, which have part-based
representations that lead to innate robustness to natural occlusion, are robust
to patch attacks on PASCAL3D+ and the German Traffic Sign Recognition
Benchmark, without adversarial training. Moreover, the robustness of
compositional models outperforms that of adversarially trained standard models
by a large margin. However, on GTSRB, we observe that they have problems
discriminating between similar traffic signs with fine-grained differences. We
overcome this limitation by introducing part-based finetuning, which improves
fine-grained recognition. By leveraging compositional representations, this is
the first work that defends against black-box patch attacks without expensive
adversarial training. This defense is more robust than adversarial training and
more interpretable because it can locate and ignore adversarial patches.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:04:23 GMT""}]","2020-12-02"
"2012.00559","Parongama Sen","Indrajit Ghose, Parongama Sen","The variational method applied to the harmonic oscillator in presence of
  a delta function potential","9 pages, 7 figures, accepted version in European Journal of Physics","Eur. J. Phys. 42 045406 (2021)","10.1088/1361-6404/abf8c9",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The problem of the harmonic oscillator with a centrally located delta
function potential can be exactly solved in one dimension where the
eigenfunctions are expressed as superpositions of the Hermite polynomials or as
confluent hypergeometric functions in general. The eigenfunctions obtained
exactly are difficult to visualise and hence to gain more insight, one can
attempt using model wave functions which are explicitly and simply expressed.
Here we apply the variational method to verify how close one can approach the
exact ground state eigenvalues using such trial wave functions. We obtain the
estimates of the ground state energies which are closer to the exact values in
comparison to earlier approximate results for both the repulsive and attractive
delta potentials.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:05:01 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 17:42:44 GMT""}]","2021-08-18"
"2012.00560","Zahra Atashgahi","Zahra Atashgahi, Ghada Sokar, Tim van der Lee, Elena Mocanu, Decebal
  Constantin Mocanu, Raymond Veldhuis, Mykola Pechenizkiy","Quick and Robust Feature Selection: the Strength of Energy-efficient
  Sparse Training for Autoencoders","29 pages",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Major complications arise from the recent increase in the amount of
high-dimensional data, including high computational costs and memory
requirements. Feature selection, which identifies the most relevant and
informative attributes of a dataset, has been introduced as a solution to this
problem. Most of the existing feature selection methods are computationally
inefficient; inefficient algorithms lead to high energy consumption, which is
not desirable for devices with limited computational and energy resources. In
this paper, a novel and flexible method for unsupervised feature selection is
proposed. This method, named QuickSelection, introduces the strength of the
neuron in sparse neural networks as a criterion to measure the feature
importance. This criterion, blended with sparsely connected denoising
autoencoders trained with the sparse evolutionary training procedure, derives
the importance of all input features simultaneously. We implement
QuickSelection in a purely sparse manner as opposed to the typical approach of
using a binary mask over connections to simulate sparsity. It results in a
considerable speed increase and memory reduction. When tested on several
benchmark datasets, including five low-dimensional and three high-dimensional
datasets, the proposed method is able to achieve the best trade-off of
classification and clustering accuracy, running time, and maximum memory usage,
among widely used approaches for feature selection. Besides, our proposed
method requires the least amount of energy among the state-of-the-art
autoencoder-based feature selection methods.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:05:15 GMT""},{""version"":""v2"",""created"":""Mon, 13 Sep 2021 17:24:41 GMT""}]","2021-09-14"
"2012.00561","Arun Sehrawat","Arun Sehrawat, Chirag Srivastava, Ujjwal Sen","Equilibrium and dynamical phase transitions in fully connected quantum
  Ising model: Approximate energy eigenstates and critical time","22 pages, 22 figures, 5 tables","Phys. Rev. B 104, 085105 (2021)","10.1103/PhysRevB.104.085105",,"cond-mat.stat-mech cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study equilibrium as well as dynamical properties of the finite-size fully
connected Ising model with a transverse field at the zero temperature. In
relation to the equilibrium, we present approximate ground and first excited
states that have large overlap -- except near the phase transition point --
with the exact energy eigenstates. For both the approximate and exact
eigenstates, we compute the energy gap, concurrence, and geometric measure of
quantum entanglement. We observe a good match in the case of energy gap and
geometric entanglement between the approximate and exact eigenstates. Whereas,
when the system size is large, the concurrence shows a nice agreement only in
the paramagnetic phase. In a quench dynamics, we study the time period and the
first critical time, which play important roles in the dynamical phase
transitions, based on a dynamical order parameter and the Loschmidt rate,
respectively. When all the spins are initially polarized in the direction of
their mutual interaction, both the time period and critical time diverges
logarithmically with the system size at the dynamical critical point. When all
the spins are initially in the direction of transverse field, both the time
period and critical time exhibit logarithmic or power-law divergences depending
on the final field strength. In the case of convergence, we provide estimates
for the finite-size scaling and converged value.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:09:45 GMT""}]","2021-08-06"
"2012.00562","Olav Galteland","Olav Galteland, Dick Bedeaux, Signe Kjelstrup","Nanothermodynamic description and molecular simulation of a single-phase
  fluid in a slit pore","10 figures, 26 pages",,"10.3390/nano11010165",,"physics.chem-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We describe the thermodynamic state of a highly confined single-phase and
single-component fluid in a slit pore using Hill's thermodynamics of small
systems. This theory was more recently named nanothermodynamics. We start by
constructing an ensemble of slit pores for controlled temperature, volume,
surface area, and chemical potential. We present the integral and differential
properties according to Hill, and use them to define the disjoining pressure.
We identify all thermodynamic pressures by their mechanical counterparts in a
consistent manner, and investigate the identification by molecular dynamics
simulations. We define and compute the disjoining pressure, and show that it
contains the standard definition. We compute the entropy and energy densities,
and find in agreement with the literature, that the forces at the wall are of
an energetic, not entropic nature. The subdivision potential is zero for this
slit pore with large walls, but unequal to zero for related sets of control
variables. We show how Hill's method can be used to find new Maxwell relations
of a confined fluid, in addition to a scaling relation, which applies when the
walls are separated far enough. By this expansion of nanothermodynamics, we set
the stage for further developments of the thermodynamics of confined fluids, a
field that is central in nanotechnology.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:16:08 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 10:06:33 GMT""}]","2021-01-12"
"2012.00564","Andrea Romanoni","Andrea Romanoni and Matteo Matteucci","Facetwise Mesh Refinement for Multi-View Stereo","Accepted as Oral ICPR2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mesh refinement is a fundamental step for accurate Multi-View Stereo. It
modifies the geometry of an initial manifold mesh to minimize the photometric
error induced in a set of camera pairs. This initial mesh is usually the output
of volumetric 3D reconstruction based on min-cut over Delaunay Triangulations.
Such methods produce a significant amount of non-manifold vertices, therefore
they require a vertex split step to explicitly repair them. In this paper, we
extend this method to preemptively fix the non-manifold vertices by reasoning
directly on the Delaunay Triangulation and avoid most vertex splits. The main
contribution of this paper addresses the problem of choosing the camera pairs
adopted by the refinement process. We treat the problem as a mesh labeling
process, where each label corresponds to a camera pair. Differently from the
state-of-the-art methods, which use each camera pair to refine all the visible
parts of the mesh, we choose, for each facet, the best pair that enforces both
the overall visibility and coverage. The refinement step is applied for each
facet using only the camera pair selected. This facetwise refinement helps the
process to be applied in the most evenly way possible.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:16:56 GMT""}]","2020-12-02"
"2012.00565","Gerardo Morsella","Roberto Longo, Gerardo Morsella","The massless modular Hamiltonian","Changes w.r.t. v. 3: only this comment. Changes w.r.t. v. 2: the
  results on the massive modular hamiltonian of a ball contained a gap, and
  have been removed. 23 pages, 1 figure",,,,"math-ph cs.IT hep-th math.AP math.IT math.MP math.OA","http://creativecommons.org/licenses/by/4.0/","  We compute the vacuum local modular Hamiltonian associated with a space ball
region in the free scalar massless Quantum Field Theory. We give an explicit
expression on the one particle Hilbert space in terms of the higher dimensional
Legendre differential operator. The quadratic form of the massless modular
Hamiltonian is expressed in terms of an integral of the energy density with the
parabolic distribution. We then get the formula for the local entropy of a wave
packet. This gives the vacuum relative entropy of a coherent state on the
double cone von Neumann algebras associated with the free scalar QFT. Among
other points, we provide the passivity characterisation of the modular
Hamiltonian within the standard subspace setup.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:17:40 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 10:05:43 GMT""},{""version"":""v3"",""created"":""Tue, 6 Sep 2022 14:44:02 GMT""},{""version"":""v4"",""created"":""Fri, 23 Sep 2022 12:27:31 GMT""}]","2022-09-26"
"2012.00567","Heng Yin","Heng Yin, Hengwei Zhang, Jindong Wang and Ruiyu Dou","Boosting Adversarial Attacks on Neural Networks with Better Optimizer",,,"10.1155/2021/9983309",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional neural networks have outperformed humans in image recognition
tasks, but they remain vulnerable to attacks from adversarial examples. Since
these data are crafted by adding imperceptible noise to normal images, their
existence poses potential security threats to deep learning systems.
Sophisticated adversarial examples with strong attack performance can also be
used as a tool to evaluate the robustness of a model. However, the success rate
of adversarial attacks can be further improved in black-box environments.
Therefore, this study combines a modified Adam gradient descent algorithm with
the iterative gradient-based attack method. The proposed Adam Iterative Fast
Gradient Method is then used to improve the transferability of adversarial
examples. Extensive experiments on ImageNet showed that the proposed method
offers a higher attack success rate than existing iterative methods. By
extending our method, we achieved a state-of-the-art attack success rate of
95.0% on defense models.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:18:19 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 12:40:43 GMT""}]","2021-06-10"
"2012.00568","Dimitra Atri","Dimitra Atri, Caitlin MacArthur and Ian Dobbs-Dixon","Modeling Solar Proton Event-induced Martian Surface Radiation Dose","Submitted",,,,"astro-ph.EP astro-ph.SR physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solar Proton Events (SPEs) can cause abrupt and significant enhancements to
the Martian surface radiation dose. Observations of the impact of SPEs on the
Martian surface are available from satellites and surface detectors, but the
data set is very limited in time, and the energy range is limited in scope,
which makes it insufficient to estimate the impact of major events on the
Martian surface. On the other hand, long-term data of SPEs impacting the Earth
spanning a large energy range is widely available, and can be used to estimate
the impact of major events on Mars on long timescales. Herein, we take major
SPEs observed during the past several decades on Earth (1956 - 2014), along
with PAMELA observations (2006 - 2014) and use the GEANT4 Monte Carlo code to
calculate the Martian surface radiation dose. We study the contribution of
proton fluence and spectral shape of events on the surface radiation dose and
estimated the impact of possible major SPEs on the Martian surface in the
future. These results have major implications for the planned human exploration
of Mars. Overall we find that the radiation dose from extreme events can have a
significant impact on astronaut health, and in rare, worst case scenarios, the
estimated dose can even reach lethal levels.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:19:34 GMT""}]","2020-12-02"
"2012.00569","George Lusztig","G. Lusztig","On the Satake isomorphism","13 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a 1983 paper the author has established a (decategorified) Satake
equivalence for affine Hecke algebras. In this paper we give new proofs for
some results of that paper, one based on the theory of J-rings and one based on
the known character formula for rational representations of a reductive group
in positive, large, characteristic. We also give an extension of that character
formula to disconnected groups.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:20:46 GMT""},{""version"":""v2"",""created"":""Thu, 10 Dec 2020 15:25:42 GMT""}]","2020-12-11"
"2012.00570","C. Douglas Haessig","C. Douglas Haessig","Kloosterman sums and Hecke polynomials in characteristics 2 and 3","6 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we give a modular interpretation of the $k$-th symmetric power
$L$-function of the Kloosterman family of exponential sums in characteristics 2
and 3, and in the case of $p=2$ and $k$ odd give the precise 2-adic Newton
polygon. We also give a $p$-adic modular interpretation of Dwork's unit root
$L$-function of the Kloosterman family, and give the precise 2-adic Newton
polygon when $k$ is odd.
  In a previous paper, we gave an estimate for the $q$-adic Newton polygon of
the symmetric power $L$-function of the Kloosterman family when $p \geq 5$. We
discuss how this restriction on primes was not needed, and so the results of
that paper hold for all $p \geq 2$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:24:13 GMT""}]","2020-12-02"
"2012.00571","S\'ebastien Montella","Sebastien Montella, Betty Fabre, Tanguy Urvoy, Johannes Heinecke, Lina
  Rojas-Barahona","Denoising Pre-Training and Data Augmentation Strategies for Enhanced RDF
  Verbalization with Transformers","Accepted at WebNLG+: 3rd Workshop on Natural Language Generation from
  the Semantic Web",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The task of verbalization of RDF triples has known a growth in popularity due
to the rising ubiquity of Knowledge Bases (KBs). The formalism of RDF triples
is a simple and efficient way to store facts at a large scale. However, its
abstract representation makes it difficult for humans to interpret. For this
purpose, the WebNLG challenge aims at promoting automated RDF-to-text
generation. We propose to leverage pre-trainings from augmented data with the
Transformer model using a data augmentation strategy. Our experiment results
show a minimum relative increases of 3.73%, 126.05% and 88.16% in BLEU score
for seen categories, unseen entities and unseen categories respectively over
the standard training.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:25:47 GMT""}]","2020-12-02"
"2012.00572","Juan Vidal Alegr\'ia","Juan Vidal Alegr\'ia and Fredrik Rusek and Ove Edfors","Trade-offs in Decentralized Multi-Antenna Architectures: The WAX
  Decomposition","14 pages, 9 figures, submitted to IEEE Transactions on Signal
  Processing. arXiv admin note: text overlap with arXiv:2003.01961","IEEE Trans. Sig. Proc., 69, 2021, 3627-3641","10.1109/TSP.2021.3089442",,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current research on multi-antenna architectures is trending towards
increasing the amount of antennas in the base stations (BSs) so as to increase
the spectral efficiency. As a result, the interconnection bandwidth and
computational complexity required to process the data using centralized
architectures is becoming prohibitively high. Decentralized architectures can
reduce these requirements by pre-processing the data before it arrives at a
central processing unit (CPU). However, performing decentralized processing
introduces also cost in complexity/interconnection bandwidth at the antenna end
which is in general being ignored. This paper aims at studying the interplay
between level of decentralization and the associated complexity/interconnection
bandwidth requirement at the antenna end. To do so, we propose a general
framework for centralized/decentralized architectures that can explore said
interplay by adjusting some system parameters, namely the number of connections
to the CPU (level of decentralization), and the number of
multiplications/outputs per antenna (complexity/interconnection bandwidth). We
define a novel matrix decomposition, the WAX decomposition, that allows
information-lossless processing within our proposed framework, and we use it to
obtain the operational limits of the interplay under study. We also look into
some of the limitations of the WAX decomposition.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:27:13 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 15:50:04 GMT""},{""version"":""v3"",""created"":""Sat, 29 May 2021 17:44:03 GMT""}]","2023-05-01"
"2012.00573","Fei Ding","Fei Ding, Yin Yang, Hongxin Hu, Venkat Krovi, Feng Luo","Multi-level Knowledge Distillation via Knowledge Alignment and
  Correlation","15 pages, 11 tables, 4 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Knowledge distillation (KD) has become an important technique for model
compression and knowledge transfer. In this work, we first perform a
comprehensive analysis of the knowledge transferred by different KD methods. We
demonstrate that traditional KD methods, which minimize the KL divergence of
softmax outputs between networks, are related to the knowledge alignment of an
individual sample only. Meanwhile, recent contrastive learning-based KD methods
mainly transfer relational knowledge between different samples, namely,
knowledge correlation. While it is important to transfer the full knowledge
from teacher to student, we introduce the Multi-level Knowledge Distillation
(MLKD) by effectively considering both knowledge alignment and correlation.
MLKD is task-agnostic and model-agnostic, and can easily transfer knowledge
from supervised or self-supervised pretrained teachers. We show that MLKD can
improve the reliability and transferability of learned representations.
Experiments demonstrate that MLKD outperforms other state-of-the-art methods on
a large number of experimental settings including different (a) pretraining
strategies (b) network architectures (c) datasets (d) tasks.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:27:15 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 00:11:35 GMT""}]","2021-06-07"
"2012.00574","Pierpaola Santarsiero","Edoardo Ballico, Alessandra Bernardi, Pierpaola Santarsiero","Terracini locus for three points on a Segre variety","27 pages, 3 figures",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the notion of r-th Terracini locus of a variety and we compute
it for at most three points on a Segre variety.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:27:39 GMT""}]","2020-12-02"
"2012.00575","Naga Manasa Vempati","Ruming Gong, Manasa N. Vempati and Qingyan Wu","A note on two weight commutators of maximal functions on spaces of
  homogeneous type","arXiv admin note: text overlap with arXiv:1809.07942",,,,"math.FA math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the two weight quantitative estimates for the commutator of maximal
functions and the maximal commutators with respect to the symbol in weighted
BMO space on spaces of homogeneous type. These commutators turn out to be
controlled by the sparse operators in the setting of space of homogeneous type.
The lower bound of the maximal commutator is also obtained.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:32:20 GMT""}]","2020-12-02"
"2012.00576","Song Li","Song Li, Ka Shen, Ke Xia","Magnon hybridization in ferrimagnetic heterostructures","9 pages, 5 figures",,"10.1103/PhysRevB.102.224413",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study magnon hybridization in a ferrimagnetic heterostructure consisting
of ultrathin gadolinium iron garnet and yttrium iron garnet layers and show the
localized and extended spatial profiles of the magnon modes with different
polarizations. These modes are expected to have distinct thermal excitation
properties in the presence of a temperature gradient across the
heterostructure. From a quantitative analysis of their consequences on
longitudinal spin Seebeck effect, we predict an observable shift of the
sign-changing temperature with respect to the one previously observed in
gadolinium iron garnet. Moreover, the sign-changing point of spin Seebeck
signal is found to be tunable by YIG thickness. Our results suggest the
necessity of taking into account the temperature difference between the magnon
modes in ferrimagnetic heterostructures.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:34:14 GMT""}]","2020-12-30"
"2012.00577","Vitalijs Brejevs","Vitalijs Brejevs","On slice alternating 3-braid closures","18 pages, 10 figures, 3 tables; added Section 4 and appendix with
  twisted Alexander polynomial computations, changed title, made minor
  corrections and improvements in Sections 1-3, uploaded accompanying code",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct ribbon surfaces of Euler characteristic one for several infinite
families of alternating 3-braid closures. We also use a twisted Alexander
polynomial obstruction to conclude the classification of smoothly slice knots
which are closures of alternating 3-braids with up to 20 crossings.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:34:22 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 10:57:25 GMT""}]","2021-05-21"
"2012.00578","The ATLAS Collaboration","ATLAS Collaboration","Muon reconstruction and identification efficiency in ATLAS using the
  full Run 2 $pp$ collision data set at $\sqrt{s}=13$ TeV","64 pages in total, author list starting page 42, auxiliary material
  starting at page 59, 34 figures, 3 tables. All figures including auxiliary
  figures are available at
  https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/MUON-2018-03/","Eur. Phys. J. C 81 (2021) 578","10.1140/epjc/s10052-021-09233-2","CERN-EP-2020-199","hep-ex","http://creativecommons.org/licenses/by/4.0/","  This article documents the muon reconstruction and identification efficiency
obtained by the ATLAS experiment for 139 fb$^{-1}$ of $pp$ collision data at
$\sqrt{s}=13$ TeV collected between 2015 and 2018 during Run 2 of the LHC. The
increased instantaneous luminosity delivered by the LHC over this period
required a reoptimisation of the criteria for the identification of prompt
muons. Improved and newly developed algorithms were deployed to preserve high
muon identification efficiency with a low misidentification rate and good
momentum resolution. The availability of large samples of $Z\to\mu\mu$ and
$J/\psi\to\mu\mu$ decays, and the minimisation of systematic uncertainties,
allows the efficiencies of criteria for muon identification, primary vertex
association, and isolation to be measured with an accuracy at the per-mille
level in the bulk of the phase space, and up to the percent level in complex
kinematic configurations. Excellent performance is achieved over a range of
transverse momenta from 3 GeV to several hundred GeV, and across the full muon
detector acceptance of $|\eta|<2.7$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:35:17 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 13:27:57 GMT""}]","2021-08-27"
"2012.00579","Lingjing Jiang","Lingjing Jiang, Yuan Zhong, Chris Elrod, Loki Natarajan, Rob Knight,
  Wesley K. Thompson","BayesTime: Bayesian Functional Principal Components for Sparse
  Longitudinal Data",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Modeling non-linear temporal trajectories is of fundamental interest in many
application areas, such as in longitudinal microbiome analysis. Many existing
methods focus on estimating mean trajectories, but it is also often of value to
assess temporal patterns of individual subjects. Sparse principal components
analysis (SFPCA) serves as a useful tool for assessing individual variation in
non-linear trajectories; however its application to real data often requires
careful model selection criteria and diagnostic tools. Here, we propose a
Bayesian approach to SFPCA, which allows users to use the efficient
leave-one-out cross-validation (LOO) with Pareto-smoothed importance sampling
(PSIS) for model selection, and to utilize the estimated shape parameter from
PSIS-LOO and also the posterior predictive checks for graphical model
diagnostics. This Bayesian implementation thus enables careful application of
SFPCA to a wide range of longitudinal data applications.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:35:19 GMT""}]","2020-12-02"
"2012.00580","Martin Bo Nielsen","M. B. Nielsen (1 and 2 and 3), G. R. Davies (1), W. H. Ball (1 and 2),
  A. J. Lyttle (1 and 2), T. Li (1 and 2), O. J. Hall (1 and 2), W. J. Chaplin
  (1 and 2), P. Gaulme (4), L. Carboneau (1 and 2), J. M. J. Ong (5), R. A.
  Garc\'ia (6 and 7), B. Mosser (8), I. W. Roxburgh (9 and 1), E. Corsaro (10),
  O. Benomar (11 and 3), A. Moya (12 and 1), M. N. Lund (2) ((1) School of
  Physics and Astronomy, University of Birmingham, (2) Stellar Astrophysics
  Centre (SAC), Department of Physics and Astronomy, Aarhus University, (3)
  Center for Space Science, NYUAD Institute, New York University Abu Dhabi, (4)
  Max-Planck-Institut f\""ur Sonnensystemforschung, (5) Department of Astronomy,
  Yale University, (6) IRFU, CEA, Universit\'e Paris-Saclay, (7) AIM, CEA,
  CNRS, Universit\'e Paris-Saclay, Universit\'e Paris Diderot, Sorbonne Paris
  Cit\'e, (8) LESIA, Observatoire de Paris, Universit\'e PSL, CNRS, Sorbonne
  Universit\'e, Universit\'e de Paris, (9) Astronomy Unit, School of Physics
  and Astronomy, Queen Mary University of London, (10) INAF - Osservatorio
  Astrofisico di Catania, (11) Solar Science Observatory, NAOJ and Department
  of Astronomical Science, Sokendai (GUAS), (12) Electrical Engineering,
  Electronics, Automation and Applied Physics Department, E.T.S.I.D.I,
  Polytechnic University of Madrid (UPM))","PBjam: A Python package for automating asteroseismology of solar-like
  oscillators","12 Pages, 4 figures. Accepted for publication in AJ. Associated
  software available at https://doi.org/10.5281/zenodo.4300079",,"10.3847/1538-3881/abcd39",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Asteroseismology is an exceptional tool for studying stars by using the
properties of observed modes of oscillation. So far the process of performing
an asteroseismic analysis of a star has remained somewhat esoteric and
inaccessible to non-experts. In this software paper we describe PBjam, an
open-source Python package for analyzing the frequency spectra of solar-like
oscillators in a simple but principled and automated way. The aim of PBjam is
to provide a set of easy-to-use tools to extract information about the radial
and quadrupole oscillations in stars that oscillate like the Sun, which may
then be used to infer bulk properties such as stellar mass, radius and age or
even structure. Asteroseismology and its data analysis methods are becoming
increasingly important as space-based photometric observatories are producing a
wealth of new data, allowing asteroseismology to be applied in a wide range of
contexts such as exoplanet, stellar structure and evolution, and Galactic
population studies.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:36:13 GMT""}]","2021-01-20"
"2012.00581","Marzieh Hashemipour-Nazar","Marzieh Hashemipour-Nazari, Kees Goossens and Alexios
  Balatsoukas-Stimming","Hardware Implementation of Iterative Projection-Aggregation Decoding of
  Reed-Muller Codes",,,,,"cs.IT cs.AR eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present a simplification and a corresponding hardware
architecture for hard-decision recursive projection-aggregation (RPA) decoding
of Reed-Muller (RM) codes. In particular, we transform the recursive structure
of RPA decoding into a simpler and iterative structure with minimal
error-correction degradation. Our simulation results for RM(7,3) show that the
proposed simplification has a small error-correcting performance degradation
(0.005 in terms of channel crossover probability) while reducing the average
number of computations by up to 40%. In addition, we describe the first fully
parallel hardware architecture for simplified RPA decoding. We present FPGA
implementation results for an RM(6,3) code on a Xilinx Virtex-7 FPGA showing
that our proposed architecture achieves a throughput of 171 Mbps at a frequency
of 80 MHz.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:38:06 GMT""}]","2020-12-03"
"2012.00582","Charles-Michel Marle","Charles-Michel Marle","On Gibbs states of mechanical systems with symmetries","59 pages, preprint. This version differs from the previoos one by
  corrections of several typographical errors and addition of the expressions
  of the Liouville measure for the Poincar\'e disk and the Poincar\'e
  half-plane",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  Gibbs states for the Hamiltonian action of a Lie group on a symplectic
manifold were studied, and their possible applications in Physics and Cosmology
were considered, by the French mathematician and physicist Jean-Marie Souriau.
They are presented here with detailed proofs of all the stated results. Using
an adaptation of the cross product for pseudo-Euclidean three-dimensional
vector spaces, we present several examples of such Gibbs states, together with
the associated thermodynamic functions, for various two-dimensional symplectic
manifolds, including the pseudo-spheres, the Poincar\'e disk and the Poincar\'e
half-plane.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:39:20 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jan 2021 17:34:54 GMT""}]","2021-01-14"
"2012.00583","Xiaohan Cheng","Xiaohan Cheng","Obtain Employee Turnover Rate and Optimal Reduction Strategy Based On
  Neural Network and Reinforcement Learning",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays, human resource is an important part of various resources of
enterprises. For enterprises, high-loyalty and high-quality talented persons
are often the core competitiveness of enterprises. Therefore, it is of great
practical significance to predict whether employees leave and reduce the
turnover rate of employees. First, this paper established a multi-layer
perceptron predictive model of employee turnover rate. A model based on Sarsa
which is a kind of reinforcement learning algorithm is proposed to
automatically generate a set of strategies to reduce the employee turnover
rate. These strategies are a collection of strategies that can reduce the
employee turnover rate the most and cost less from the perspective of the
enterprise, and can be used as a reference plan for the enterprise to optimize
the employee system. The experimental results show that the algorithm can
indeed improve the efficiency and accuracy of the specific strategy.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:48:23 GMT""}]","2020-12-02"
"2012.00584","Andres Carvallo","Andres Carvallo, Denis Parra, Gabriel Rada, Daniel Perez, Juan Ignacio
  Vasquez and Camilo Vergara","Neural language models for text classification in evidence-based
  medicine",,,,,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The COVID-19 has brought about a significant challenge to the whole of
humanity, but with a special burden upon the medical community. Clinicians must
keep updated continuously about symptoms, diagnoses, and effectiveness of
emergent treatments under a never-ending flood of scientific literature. In
this context, the role of evidence-based medicine (EBM) for curating the most
substantial evidence to support public health and clinical practice turns
essential but is being challenged as never before due to the high volume of
research articles published and pre-prints posted daily. Artificial
Intelligence can have a crucial role in this situation. In this article, we
report the results of an applied research project to classify scientific
articles to support Epistemonikos, one of the most active foundations worldwide
conducting EBM. We test several methods, and the best one, based on the XLNet
neural language model, improves the current approach by 93\% on average
F1-score, saving valuable time from physicians who volunteer to curate COVID-19
research articles manually.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:53:44 GMT""}]","2020-12-02"
"2012.00585","Ingo M\""unch Prof. Dr.-Ing.","Adam Sky, C\'esar Polindara, Ingo Muench, Carolin Birk","A flexible sparse matrix data format and parallel algorithms for the
  assembly of sparse matrices in general finite element applications using
  atomic synchronisation primitives",,,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finite element methods require the composition of the global stiffness matrix
from local finite element contributions. The composition process combines the
computation of element stiffness matrices and their assembly into the global
stiffness matrix, which is commonly sparse. In this paper we focus on the
assembly process of the global stiffness matrix and explore different
algorithms and their efficiency on shared memory systems using C++. A key
aspect of our investigation is the use of atomic synchronization primitives for
the derivation of data-race free algorithms and data structures. Furthermore,
we propose a new flexible storage format for sparse matrices and compare its
performance with the compressed row storage format using abstract benchmarks
based on common characteristics of finite element problems.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:56:09 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 13:43:08 GMT""}]","2021-07-16"
"2012.00586","Vasilis Oikonomou","V.K. Oikonomou","Unifying of Inflation with Early and Late Dark Energy Epochs in Axion
  $F(R)$ Gravity","Revised version PRD Accepted. The PYTHON code for f(R) Gravity Dark
  Eenrgy Phenomenology can be found in this link:
  https://github.com/VOikonomou?tab=projects","Phys. Rev. D 103, 044036 (2021)","10.1103/PhysRevD.103.044036",,"astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a theoretical model of $F(R)$ gravity in which it is possible to
describe in a unified way inflation, an early and a late dark energy era, in
the presence of a light axion particle which plays the role of the dark matter
component of the Universe. Particularly, the early-time phenomenology is
dominated by an $R^2$ term, while the presence of the other terms $f(R)$ ensure
the occurrence of the early and late-time dark energy eras. The inflationary
phenomenology is compatible with the Planck 2018 data for inflation, while the
late-time dark energy era is compatible with the Planck 2018 constraints on the
cosmological parameters. Also, the model exhibits an early dark energy era, at
$z\sim 2.5$ approximately, followed by a deceleration era, which starts at
approximately $z\sim 1.5$, which in turn is followed by a late-time dark energy
era for redshifts $z\sim 0.5$, which lasts for approximately 5 billion years up
to present time. A notable feature of our model is that the dark energy era is
free from dark energy oscillations, at least in the redshift interval
$z=[0,10]$. In addition, we also discuss several features related to
observational data at $z\sim 2.34$, at which redshift intricate observational
data exist in the literature. Moreover, the numerical code for the dark energy
phenomenology, written in Python 3, is presented in the end of the article.
Finally, the model has another interesting characteristic, a sudden jump of the
value of the Hubble rate in the redshift interval $z\sim [2,2.6]$ where its
value suddenly increases and then decreases until $z\sim 0$.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:56:13 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 18:42:23 GMT""}]","2021-02-24"
"2012.00587","Jens Siewert","Christopher Eltschka, Marcus Huber, Simon Morelli, Jens Siewert","The shape of higher-dimensional state space: Bloch-ball analog for a
  qutrit","10 pages, 5 figures; discussion of results improved, one new figure","Quantum 5, 485 (2021)","10.22331/q-2021-06-29-485",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Geometric intuition is a crucial tool to obtain deeper insight into many
concepts of physics. A paradigmatic example of its power is the Bloch ball, the
geometrical representation for the state space of the simplest possible quantum
system, a two-level system (or qubit). However, already for a three-level
system (qutrit) the state space has eight dimensions, so that its complexity
exceeds the grasp of our three-dimensional space of experience. This is
unfortunate, given that the geometric object describing the state space of a
qutrit has a much richer structure and is in many ways more representative for
a general quantum system than a qubit. In this work we demonstrate that, based
on the Bloch representation of quantum states, it is possible to construct a
three dimensional model for the qutrit state space that captures most of the
essential geometric features of the latter. Besides being of indisputable
theoretical value, this opens the door to a new type of representation, thus
extending our geometric intuition beyond the simplest quantum systems.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:57:13 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 20:07:13 GMT""}]","2021-07-01"
"2012.00588","Amir Adler Dr.","Dimitrios Pantazis, Amir Adler","MEG Source Localization via Deep Learning",,,,,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a deep learning solution to the problem of localization of
magnetoencephalography (MEG) brain signals. The proposed deep model
architectures are tuned for single and multiple time point MEG data, and can
estimate varying numbers of dipole sources. Results from simulated MEG data on
the cortical surface of a real human subject demonstrated improvements against
the popular RAP-MUSIC localization algorithm in specific scenarios with varying
SNR levels, inter-source correlation values, and number of sources.
Importantly, the deep learning models had robust performance to forward model
errors and a significant reduction in computation time, to a fraction of 1 ms,
paving the way to real-time MEG source localization.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:58:06 GMT""}]","2020-12-02"
"2012.00589","William Kuszmaul","William Kuszmaul","Train Tracks with Gaps: Applying the Probabilistic Method to Trains",,"Fun With Algorithms, 2020",,,"cs.LG cs.DS math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We identify a tradeoff curve between the number of wheels on a train car, and
the amount of track that must be installed in order to ensure that the train
car is supported by the track at all times. The goal is to build an elevated
track that covers some large distance $\ell$, but that consists primarily of
gaps, so that the total amount of feet of train track that is actually
installed is only a small fraction of $\ell$. In order so that the train track
can support the train at all points, the requirement is that as the train
drives across the track, at least one set of wheels from the rear quarter and
at least one set of wheels from the front quarter of the train must be touching
the track at all times.
  We show that, if a train car has $n$ sets of wheels evenly spaced apart in
its rear and $n$ sets of wheels evenly spaced apart in its front, then it is
possible to build a train track that supports the train car but uses only
$\Theta( \ell / n )$ feet of track. We then consider what happens if the wheels
on the train car are not evenly spaced (and may even be configured
adversarially). We show that for any configuration of the train car, with $n$
wheels in each of the front and rear quarters of the car, it is possible to
build a track that supports the car for distance $\ell$ and uses only
$O\left(\frac{\ell \log n}{n}\right)$ feet of track. Additionally, we show that
there exist configurations of the train car for which this tradeoff curve is
asymptotically optimal. Both the upper and lower bounds are achieved via
applications of the probabilistic method.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:58:28 GMT""}]","2020-12-02"
"2012.00590","Luis L. Sanchez. Soto","Aaron Z. Goldberg, Andrei B. Klimov, Gerd Leuchs and Luis L.
  Sanchez-Soto","Rotation sensing at the ultimate limit","28 pages, 4 figures. Comments welcome!",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Conventional classical sensors are approaching their maximum sensitivity
levels in many areas. Yet these levels still are far from the ultimate limits
dictated by quantum mechanics. Quantum sensors promise a substantial step ahead
by taking advantage of the salient sensitivity of quantum states to the
environment. Here, we focus on sensing rotations, a topic of broad application.
By resorting to the basic tools of estimation theory, we derive states that
achieve the ultimate sensitivities in estimating both the orientation of an
unknown rotation axis and the angle rotated about it. The critical enhancement
obtained with these optimal states should make of them an indispensable
ingredient in the next generation of rotation sensors that is now blossoming.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:58:40 GMT""}]","2020-12-02"
"2012.00591","James Walton","Henna Koivusalo and James J. Walton","Cut and project sets with polytopal window II: linear repetitivity","52 pages, 1 figure",,,,"math.DS math.NT","http://creativecommons.org/licenses/by/4.0/","  This paper gives a complete classification of linear repetitivity (LR) for a
natural class of aperiodic Euclidean cut and project schemes with convex
polytopal windows. Our results cover those cut and project schemes for which
the lattice projects densely into the internal space and (possibly after
translation) hits each supporting hyperplane of the polytopal window. Our main
result is that LR is satisfied if and only if the patterns are of low
complexity (property C), and the projected lattice satisfies a Diophantine
condition (property D). Property C can be checked by computation of the ranks
and dimensions of linear spans of the stabiliser subgroups of the supporting
hyperplanes, as investigated in Part I to this article. To define the correct
Diophantine condition D, we establish new results on decomposing polytopal cut
and project schemes to factors, developing concepts initiated in the work of
Forrest, Hunton and Kellendonk. This means that, when C is satisfied, the
window splits into components which induce a compatible splitting of the
lattice. Then property D is the requirement that, for any suitable
decomposition, these factors do not project close to the origin in the internal
space, relative to the norm in the total space. On each factor, this
corresponds to the usual notion from Diophantine Approximation of a system of
linear forms being badly approximable. This extends previous work on cubical
cut and project schemes to a very general class of cut and project schemes. We
demonstrate our main theorem on several examples, and derive some further
consequences of our main theorem, such as the equivalence LR, positivity of
weights and satisfying a subadditive ergodic theorem for this class of
polytopal cut and project sets.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:59:16 GMT""}]","2020-12-02"
"2012.00745","Martin Huber","Michela Bia, Martin Huber, Luk\'a\v{s} Laff\'ers","Double machine learning for sample selection models","arXiv admin note: text overlap with arXiv:2012.00370,
  arXiv:2002.12710",,,,"econ.EM stat.ME stat.ML","http://creativecommons.org/licenses/by/4.0/","  This paper considers the evaluation of discretely distributed treatments when
outcomes are only observed for a subpopulation due to sample selection or
outcome attrition. For identification, we combine a selection-on-observables
assumption for treatment assignment with either selection-on-observables or
instrumental variable assumptions concerning the outcome attrition/sample
selection process. We also consider dynamic confounding, meaning that
covariates that jointly affect sample selection and the outcome may (at least
partly) be influenced by the treatment. To control in a data-driven way for a
potentially high dimensional set of pre- and/or post-treatment covariates, we
adapt the double machine learning framework for treatment evaluation to sample
selection problems. We make use of (a) Neyman-orthogonal, doubly robust, and
efficient score functions, which imply the robustness of treatment effect
estimation to moderate regularization biases in the machine learning-based
estimation of the outcome, treatment, or sample selection models and (b) sample
splitting (or cross-fitting) to prevent overfitting bias. We demonstrate that
the proposed estimators are asymptotically normal and root-n consistent under
specific regularity conditions concerning the machine learners and investigate
their finite sample properties in a simulation study. We also apply our
proposed methodology to the Job Corps data for evaluating the effect of
training on hourly wages which are only observed conditional on employment. The
estimator is available in the causalweight package for the statistical software
R.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:40:21 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 12:44:10 GMT""},{""version"":""v3"",""created"":""Sat, 1 May 2021 09:12:02 GMT""},{""version"":""v4"",""created"":""Sat, 19 Jun 2021 14:53:34 GMT""},{""version"":""v5"",""created"":""Thu, 15 Jul 2021 15:55:40 GMT""}]","2021-07-16"
"2012.00746","Alexander Provorov","A. P. Isaev, A. A. Provorov","Projectors on invariant subspaces of representations
  $\operatorname{ad}^{\otimes 2}$ of Lie algebras $so(N)$ and $sp(2r)$ and
  Vogel parametrization","references added","TMF 206:1 (2021) 3-22",,,"math-ph hep-th math.MP","http://creativecommons.org/licenses/by/4.0/","  Explicit formulae for the projectors onto invariant subspaces of the
$\operatorname{ad}^{\otimes 2}$ representation of the Lie algebras $so(N)$ and
$sp(2r)$ have been found by means of the split Casimir operator. These
projectors have also been considered from the viewpoint of the universal
complex simple Lie algebra description by using the Vogel parametrisation.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:28:54 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 14:22:07 GMT""}]","2021-01-25"
"2012.00747","David McConnell","D. McConnell, C. L. Hale, E. Lenc, J. K. Banfield, George Heald, A.W.
  Hotan, James K. Leung, Vanessa A. Moss, Tara Murphy, Andrew O'Brien, Joshua
  Pritchard, Wasim Raja, Elaine M. Sadler, Adam Stewart, Alec J. M. Thomson, M.
  Whiting, James R. Allison, S.W. Amy, C. Anderson, Lewis Ball, Keith W.
  Bannister, Martin Bell, Douglas C.-J. Bock, Russ Bolton, J. D. Bunton, A. P.
  Chippendale, J. D. Collier, F. R. Cooray, T.J. Cornwell, P.J. Diamond, P. G.
  Edwards, N. Gupta, Douglas B. Hayman, Ian Heywood, C. A. Jackson, B\""arbel S.
  Koribalski, Karen Lee-Waddell, N. M. McClure-Griffiths, Alan Ng, Ray P.
  Norris, Chris Phillips, John E. Reynolds, Daniel N. Roxby, Antony E.T.
  Schinckel, Matt Shields, Chenoa Tremblay, A. Tzioumis, M.A. Voronkov, Tobias
  Westmeier","The Rapid ASKAP Continuum Survey I: Design and First Results","24 pages, 17 figures, 4 tables. For associated data see
  https://data.csiro.au/collections/domain/casdaObservation/results/PRAS110%20-%20The%20Rapid%20ASKAP%20Continuum","Publications of the Astronomical Society of Australia, 37, 2020,
  E048","10.1017/pasa.2020.41",,"astro-ph.IM astro-ph.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Rapid ASKAP Continuum Survey (RACS) is the first large-area survey to be
conducted with the full 36-antenna Australian Square Kilometre Array Pathfinder
(ASKAP) telescope. RACS will provide a shallow model of the ASKAP sky that will
aid the calibration of future deep ASKAP surveys. RACS will cover the whole sky
visible from the ASKAP site in Western Australia, and will cover the full ASKAP
band of $700-1800$ MHz. The RACS images are generally deeper than the existing
NRAO VLA Sky Survey (NVSS) and Sydney University Molonglo Sky Survey (SUMSS)
radio surveys and have better spatial resolution. All RACS survey products will
be public, including radio images (with $\sim 15$ arcsecond resolution) and
catalogues of about three million source components with spectral index and
polarisation information. In this paper, we present a description of the RACS
survey and the first data release of 903 images covering the sky south of
declination $+41^\circ$ made over a 288 MHz band centred at 887.5 MHz.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 04:36:02 GMT""}]","2020-12-03"
"2012.00748","Christoph Fuhrmann","Christoph Fuhrmann, Hanns Ludwig Harney, Klaus Harney and Andreas
  M\""uller","On The Gaussian Approximation To Bayesian Posterior Distributions","25 pages, 2 figures",,,,"math.ST stat.TH","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The present article derives the minimal number $N$ of observations needed to
consider a Bayesian posterior distribution as Gaussian. Two examples are
presented. Within one of them, a chi-squared distribution, the observable $x$
as well as the parameter $\xi$ are defined all over the real axis, in the other
one, the binomial distribution, the observable $x$ is an entire number while
the parameter $\xi$ is defined on a finite interval of the real axis. The
required minimal $N$ is high in the first case and low for the binomial model.
In both cases the precise definition of the measure $\mu$ on the scale of $\xi$
is crucial.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:10:10 GMT""}]","2020-12-03"
"2012.00749","Slobodan Nedic","Slobodan Nedic","Keplers's Equation and Angular Momentum: Historical Perspective,
  Critical Analysis and Implications for Development of the Orbital
  Mechanics/Dynamics, Mathematics and Physics","The submission has been revised due to erroneously - wrong sign in
  the second part in the angle-bracket of equation 2 - derived expression for
  the transverse acceleration. While the basic conclusions regarding the
  untenability of the Prime integral of angular momentum and the corresponding
  Cyclic Coordinate have remained unchanged, this leads to investigation of the
  invariance in mechanics",,,,"physics.hist-ph physics.ed-ph","http://creativecommons.org/licenses/by/4.0/","  After some more than four centuries from the formulation and publication (in
Astronomia Nova) of the Kepler's Equation, which relates the eccentric (and,
intermediately, the true) anomaly of the planetary trajectories to the
uniformly flowing time, in accordance with his Second (""Area"") law, the
subsequently -- in course of development of Orbital Mechanics -- to the 2nd law
related and formally derived non-existent (zero-valued) transverse acceleration
is questioned. Certain implications to Elliptic Integration, Symplectic
Integration, Symplectic Geometry/Topology, as well as the connection between
physical and mathematical continua in the context of the multi-level,
scale-invariant mechanics/dynamics (with the augmented central and torquing
forces) are also briefly hinted to.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 09:46:36 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 16:37:01 GMT""},{""version"":""v3"",""created"":""Thu, 2 Sep 2021 09:12:07 GMT""}]","2021-09-03"
"2012.00750","Seong Jin Kim","Seong Jin Kim, Nagisa Oi, Tomotsugu Goto, Hiroyuki Ikeda, Simon C.-C.
  Ho, Hyunjin Shim, Yoshiki Toba, Ho Seong Hwang, Tetsuya Hashimoto, Laia
  Barrufet, Matthew Malkan, Helen K. Kim, Ting-Chi Huang, Hideo Matsuhara,
  Takamitsu Miyaji, Chris Pearson, Stephen Serjeant, Daryl Joe Santos, Eunbin
  Kim, Agnieszka Pollo, Woong-Seob Jeong, Ting-Wen Wang, Rieko Momose, and
  Toshinobu Takagi","Identification of AKARI infrared sources by Deep HSC Optical Survey:
  Construction of New Band-Merged Catalogue in the NEP-Wide field","17 pages, 12 Figures, accepted in MNRAS, (in press)",,"10.1093/mnras/staa3359",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The north ecliptic pole (NEP) field is a natural deep field location for many
satellite observations. It has been targeted manytimes since it was surveyed by
the AKARI space telescope with its unique wavelength coverage from the near- to
mid-infrared(mid-IR). Many follow-up observations have been carried out and
made this field one of the most frequently observed areas witha variety of
facilities, accumulating abundant panchromatic data from X-ray to radio
wavelength range. Recently, a deep opticalsurvey with the Hyper Suprime-Cam
(HSC) at the Subaru telescope covered the NEP-Wide (NEPW) field, which enabled
us toidentify faint sources in the near- and mid-IR bands, and to improve the
photometric redshift (photo-z) estimation. In this work,we present newly
identified AKARI sources by the HSC survey, along with multi-band photometry
for 91,861 AKARI sourcesobserved over the NEPW field. We release a new
band-merged catalogue combining various photometric data from GALEXUV to the
submillimetre (sub-mm) bands (e.g., Herschel/SPIRE, JCMT/SCUBA-2). About 20,000
AKARI sources are newlymatched to the HSC data, most of which seem to be faint
galaxies in the near- to mid-infrared AKARI bands. This cataloguemotivates a
variety of current research, and will be increasingly useful as recently
launched (eROSITA/ART-XC) and futurespace missions (such as JWST, Euclid, and
SPHEREx) plan to take deep observations in the NEP field.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 10:35:57 GMT""}]","2020-12-09"
"2012.00751","Shota Kikuchi","Kouki Hoshiya, Shota Kikuchi, Tatsuo Kobayashi, Yuya Ogawa, Hikaru
  Uchida","Classification of three generation models by orbifolding magnetized $T^2
  \times T^2$","31 pages","Prog Theor Exp Phys (2021)","10.1093/ptep/ptab024","EPHOU-20-013","hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study orbifolding by the $\mathbb{Z}_2^{\rm (per)}$ permutaion of $T^2_1
\times T^2_2$ with magnetic fluxes and its twisted orbifolds. We classify the
possible three generation models which lead to non-vanishing Yukawa couplings
on the magnetized $T^2_1 \times T^2_2$ and orbifolds including the
$\mathbb{Z}_2^{\rm (per)}$ permutation and $\mathbb{Z}_2^{\rm (t)}$ twist. We
also study the modular symmetry on such orbifold models. As an illustrating
model, we examine the realization of quark masses and mixing angles.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:30:15 GMT""}]","2021-04-14"
"2012.00753","Jo\~ao Fernandes","Fernando B. Figueiredo and Jo\~ao M. Fernandes","Jos\'e Monteiro da Rocha (1734-1819) and his work of 1782 on the
  determination of comet orbits","Accepted in Journal for the History of Astronomy","Journal for the History of Astronomy, 2020, Volume: 51 issue: 4,
  page(s): 461-481","10.1177/0021828620947844",,"physics.hist-ph astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In 1782 Jos\'e Monteiro da Rocha, astronomer and professor of the University
of Coimbra, presented in a public session of the Royal Academy of Sciences of
Lisbon a memoir on the problem of the determination of the comets' orbits. Only
in 1799, the ""Determina\c{c}\~ao das Orbitas dos Cometas"" (Determination of the
orbits of comets) would be published in the Academy's memoires. In that work,
Monteiro da Rocha presents a method for solving the problem of the
determination of the parabolic orbit of a comet from three observations.
Monteiro da Rocha's method is essentially the same method proposed by Olbers
and published under von Zach's sponsorship two years before, in 1797. To have
been written and published in Portuguese was certainly a hindrance for its
dissemination among the international astronomical community. In this article,
we intend to present Monteiro da Rocha's method and trying to see to what
extent Gomes Teixeira's assertion (Teixeira 1934) that Monteiro da Rocha and
Olbers must figure together in the history of astronomy, as the first inventors
of a practical and easy method for the determination of parabolic orbits of
comets, is justified.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:41:59 GMT""}]","2020-12-03"
"2012.01144","Carlos Maltzahn","Stephanie Lieggi and Ivo Jimenez and Jeff LeFevre and Carlos Maltzahn","The CROSS Incubator: A Case Study for funding and training RSEs","Presented at RSE-HPC 2020: Research Software Engineers in HPC -
  Creating Community, Building Careers, Addressing Challenges, co-located with
  SC20, Virtual, November 12, 2020",,,,"cs.CY cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The incubator and research projects sponsored by the Center for Research in
Open Source Software (CROSS, cross.ucsc.edu) at UC Santa Cruz have been very
effective at promoting the professional and technical development of research
software engineers. Carlos Maltzahn founded CROSS in 2015 with a generous gift
of $2,000,000 from UC Santa Cruz alumnus Dr. Sage Weil and founding memberships
of Toshiba America Electronic Components, SK Hynix Memory Solutions, and Micron
Technology. Over the past five years, CROSS funding has enabled PhD students to
not only create research software projects but also learn how to draw in new
contributors and leverage established open source software communities. This
position paper will present CROSS fellowships as case studies for how
university-led open source projects can create a real-world, reproducible model
for effectively training, funding and supporting research software engineers.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:16:43 GMT""}]","2020-12-03"
"2012.01145","Jay Roberts","Jay Roberts, Theodoros Tsiligkaridis","Ultrasound Diagnosis of COVID-19: Robustness and Explainability",,,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Diagnosis of COVID-19 at point of care is vital to the containment of the
global pandemic. Point of care ultrasound (POCUS) provides rapid imagery of
lungs to detect COVID-19 in patients in a repeatable and cost effective way.
Previous work has used public datasets of POCUS videos to train an AI model for
diagnosis that obtains high sensitivity. Due to the high stakes application we
propose the use of robust and explainable techniques. We demonstrate
experimentally that robust models have more stable predictions and offer
improved interpretability. A framework of contrastive explanations based on
adversarial perturbations is used to explain model predictions that aligns with
human visual perception.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:26:39 GMT""}]","2020-12-03"
"2012.01171","Bartolomeo Silvestri","Bartolomeo Silvestri, Alessandro Rinaldi, Antonella Berardi, Michele
  Roccotelli, Simone Acquaviva and Maria Pia Fanti","A Serious Game Approach for the Electro-Mobility Sector","This paper has been presented at 2019 IEEE International Conference
  on Systems, Man and Cybernetics (SMC)",,"10.1109/SMC.2019.8914388",,"cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Serious Games (SGs) represent a new approach to improve learning processes
more effectively and economically than traditional methods. This paper aims to
present a SG approach for the electro-mobility context, in order to encourage
the use of electric light vehicles. The design of the SG is based on the
typical elements of the classic ""game"" with a real gameplay with different
purposes. In this work, the proposed SG aims to raise awareness on
environmental issues caused by mobility and actively involve users, on
improving livability in the city and on real savings using alternative means to
traditional vehicles. The objective of the designed tool is to propose elements
of fun and entertainment for tourists or users of electric vehicles in the
cities, while giving useful information about the benefits of using such
vehicles, discovering touristic and interesting places in the city to discover.
In this way, the user is stimulated to explore the artistic and historical
aspects of the city through an effective learning process: he/she is encouraged
to search the origins and the peculiarities of the monuments.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:41:35 GMT""}]","2020-12-03"
"2012.01172","Burak Yildiz","Burak Yildiz, Hayley Hung, Jesse H. Krijthe, Cynthia C. S. Liem, Marco
  Loog, Gosia Migut, Frans Oliehoek, Annibale Panichella, Przemyslaw Pawelczak,
  Stjepan Picek, Mathijs de Weerdt, and Jan van Gemert","ReproducedPapers.org: Openly teaching and structuring machine learning
  reproducibility","Accepted to RRPR 2020: Third Workshop on Reproducible Research in
  Pattern Recognition",,"10.1007/978-3-030-76423-4_1",,"cs.CY cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present ReproducedPapers.org: an open online repository for teaching and
structuring machine learning reproducibility. We evaluate doing a reproduction
project among students and the added value of an online reproduction repository
among AI researchers. We use anonymous self-assessment surveys and obtained 144
responses. Results suggest that students who do a reproduction project place
more value on scientific reproductions and become more critical thinkers.
Students and AI researchers agree that our online reproduction repository is
valuable.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:19:45 GMT""}]","2021-06-11"
"2012.01175","Nikolai Bagraev T.","K. B. Taranets, M. A. Fomin, L. E. Klyachkin, A. M. Malyarenko, N. T.
  Bagraev, A. L. Chernev","Terahertz resonance response of biological tissue placed on a silicon
  nanostructure","9 pages, 6 figures","J.Appl. Phys. 125 (2019) 225702","10.1063/1.5083805",,"physics.app-ph physics.bio-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We present a method for the measurements of the tetrahertz (THz) resonance
response of DNA oligonucleotides deposited on a silicon nanosandwich (SNS). It
is shown that the SNS device can be used to generate a THz resonance response
within living biotissue. The technique we propose measures changes of the
longitudinal conductance and the lateral voltage with the SNS device in a Hall
geometry. The mechanism of the THz response is discussed, with a model of the
generation of Shapiro steps. The THz resonance response from living biotissues
will aid the diagnosis of oncological disease and, in general, form the basis
of a rapid diagnosis in practical medicine.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:44:37 GMT""}]","2020-12-03"
"2012.01185","Alois Pichler","Kipngeno Benard Kirui, Georg Ch. Pflug, Alois Pichler","New Algorithms And Fast Implementations To Approximate Stochastic
  Processes",,,,,"math.OC stat.ML","http://creativecommons.org/licenses/by/4.0/","  We present new algorithms and fast implementations to find efficient
approximations for modelling stochastic processes. For many numerical
computations it is essential to develop finite approximations for stochastic
processes. While the goal is always to find a finite model, which represents a
given knowledge about the real data process as accurate as possible, the ways
of estimating the discrete approximating model may be quite different: (i) if
the stochastic model is known as a solution of a stochastic differential
equation, e.g., one may generate the scenario tree directly from the specified
model; (ii) if a simulation algorithm is available, which allows simulating
trajectories from all conditional distributions, a scenario tree can be
generated by stochastic approximation; (iii) if only some observed trajectories
of the scenario process are available, the construction of the approximating
process can be based on non-parametric conditional density estimates.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:14:16 GMT""}]","2020-12-03"
"2012.01415","Fabio Cermelli","Fabio Cermelli, Massimiliano Mancini, Yongqin Xian, Zeynep Akata,
  Barbara Caputo","Prototype-based Incremental Few-Shot Semantic Segmentation","Accepted at BMVC 2021 (Poster)",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Semantic segmentation models have two fundamental weaknesses: i) they require
large training sets with costly pixel-level annotations, and ii) they have a
static output space, constrained to the classes of the training set. Toward
addressing both problems, we introduce a new task, Incremental Few-Shot
Segmentation (iFSS). The goal of iFSS is to extend a pretrained segmentation
model with new classes from few annotated images and without access to old
training data. To overcome the limitations of existing models iniFSS, we
propose Prototype-based Incremental Few-Shot Segmentation (PIFS) that couples
prototype learning and knowledge distillation. PIFS exploits prototypes to
initialize the classifiers of new classes, fine-tuning the network to refine
its features representation. We design a prototype-based distillation loss on
the scores of both old and new class prototypes to avoid overfitting and
forgetting, and batch-renormalization to cope with non-i.i.d.few-shot data. We
create an extensive benchmark for iFSS showing that PIFS outperforms several
few-shot and incremental learning methods in all scenarios.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 20:45:56 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 16:51:31 GMT""}]","2021-10-19"
"2012.01563","Javier Duarte","Aneesh Heintz and Vesal Razavimaleki and Javier Duarte and Gage
  DeZoort and Isobel Ojalvo and Savannah Thais and Markus Atkinson and Mark
  Neubauer and Lindsey Gray and Sergo Jindariani and Nhan Tran and Philip
  Harris and Dylan Rankin and Thea Aarrestad and Vladimir Loncar and Maurizio
  Pierini and Sioni Summers and Jennifer Ngadiuba and Mia Liu and Edward
  Kreinar and Zhenbin Wu","Accelerated Charged Particle Tracking with Graph Neural Networks on
  FPGAs","8 pages, 4 figures, To appear in Third Workshop on Machine Learning
  and the Physical Sciences (NeurIPS 2020)",,,"FERMILAB-CONF-20-622-CMS-SCD","physics.ins-det cs.LG hep-ex physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  We develop and study FPGA implementations of algorithms for charged particle
tracking based on graph neural networks. The two complementary FPGA designs are
based on OpenCL, a framework for writing programs that execute across
heterogeneous platforms, and hls4ml, a high-level-synthesis-based compiler for
neural network to firmware conversion. We evaluate and compare the resource
usage, latency, and tracking performance of our implementations based on a
benchmark dataset. We find a considerable speedup over CPU-based execution is
possible, potentially enabling such algorithms to be used effectively in future
computing workflows and the FPGA-based Level-1 trigger at the CERN Large Hadron
Collider.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:17:43 GMT""}]","2020-12-04"
"2012.01569","Uwe Aickelin","Hadi A. Khorshidi and Uwe Aickelin","Multicriteria Group Decision-Making Under Uncertainty Using Interval
  Data and Cloud Models","Journal of the Operational Research Society, 2020",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this study, we propose a multicriteria group decision making (MCGDM)
algorithm under uncertainty where data is collected as intervals. The proposed
MCGDM algorithm aggregates the data, determines the optimal weights for
criteria and ranks alternatives with no further input. The intervals give
flexibility to experts in assessing alternatives against criteria and provide
an opportunity to gain maximum information. We also propose a novel method to
aggregate expert judgements using cloud models. We introduce an experimental
approach to check the validity of the aggregation method. After that, we use
the aggregation method for an MCGDM problem. Here, we find the optimal weights
for each criterion by proposing a bilevel optimisation model. Then, we extend
the technique for order of preference by similarity to ideal solution (TOPSIS)
for data based on cloud models to prioritise alternatives. As a result, the
algorithm can gain information from decision makers with different levels of
uncertainty and examine alternatives with no more information from
decision-makers. The proposed MCGDM algorithm is implemented on a case study of
a cybersecurity problem to illustrate its feasibility and effectiveness. The
results verify the robustness and validity of the proposed MCGDM using
sensitivity analysis and comparison with other existing algorithms.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:34:48 GMT""}]","2020-12-04"
"2012.01924","Ram\'on Imad Verd\'es Kairuz","Ram\'on I. Verd\'es Kairuz, Yury Orlov and Luis T. Aguilar","Convergence time estimate and tuning of twisting algorithm","Self-contained material consists of 9 pages, 5 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gain tuning is given for the twisting controller to ensure that the
closed-loop trajectories of the perturbed double integrator, initialized within
a bounded domain and affected by uniformly bounded disturbances, settle at the
origin in prescribed time.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 01:57:56 GMT""}]","2020-12-04"
"2012.01925","Tatiana L\'opez-Guevara","Tatiana Lopez-Guevara, Michael Burke, Nicholas K. Taylor, Kartic Subr","IV-Posterior: Inverse Value Estimation for Interpretable Policy
  Certificates",,,,,"cs.LG cs.AI cs.RO","http://creativecommons.org/licenses/by/4.0/","  Model-free reinforcement learning (RL) is a powerful tool to learn a broad
range of robot skills and policies. However, a lack of policy interpretability
can inhibit their successful deployment in downstream applications,
particularly when differences in environmental conditions may result in
unpredictable behaviour or generalisation failures. As a result, there has been
a growing emphasis in machine learning around the inclusion of stronger
inductive biases in models to improve generalisation. This paper proposes an
alternative strategy, inverse value estimation for interpretable policy
certificates (IV-Posterior), which seeks to identify the inductive biases or
idealised conditions of operation already held by pre-trained policies, and
then use this information to guide their deployment. IV-Posterior uses
MaskedAutoregressive Flows to fit distributions over the set of conditions or
environmental parameters in which a policy is likely to be effective. This
distribution can then be used as a policy certificate in downstream
applications. We illustrate the use of IV-Posterior across a two environments,
and show that substantial performance gains can be obtained when policy
selection incorporates knowledge of the inductive biases that these policies
hold.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 21:45:49 GMT""}]","2020-12-04"
"2012.01940","Ben Sattelberg","Ben Sattelberg, Renzo Cavalieri, Michael Kirby, Chris Peterson, Ross
  Beveridge","Locally Linear Attributes of ReLU Neural Networks","18 pages, 12 figures, 2 tables, submitted to SIMODS",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A ReLU neural network determines/is a continuous piecewise linear map from an
input space to an output space. The weights in the neural network determine a
decomposition of the input space into convex polytopes and on each of these
polytopes the network can be described by a single affine mapping. The
structure of the decomposition, together with the affine map attached to each
polytope, can be analyzed to investigate the behavior of the associated neural
network.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 19:31:23 GMT""}]","2020-12-04"
"2012.01973","Ning Ge","Yi Liu, Li Zhang, Ning Ge, Guanghao Li","A Systematic Literature Review on Federated Learning: From A Model
  Quality Perspective",,,,,"cs.LG cs.CR","http://creativecommons.org/publicdomain/zero/1.0/","  As an emerging technique, Federated Learning (FL) can jointly train a global
model with the data remaining locally, which effectively solves the problem of
data privacy protection through the encryption mechanism. The clients train
their local model, and the server aggregates models until convergence. In this
process, the server uses an incentive mechanism to encourage clients to
contribute high-quality and large-volume data to improve the global model.
Although some works have applied FL to the Internet of Things (IoT), medicine,
manufacturing, etc., the application of FL is still in its infancy, and many
related issues need to be solved. Improving the quality of FL models is one of
the current research hotspots and challenging tasks. This paper systematically
reviews and objectively analyzes the approaches to improving the quality of FL
models. We are also interested in the research and application trends of FL and
the effect comparison between FL and non-FL because the practitioners usually
worry that achieving privacy protection needs compromising learning quality. We
use a systematic review method to analyze 147 latest articles related to FL.
This review provides useful information and insights to both academia and
practitioners from the industry. We investigate research questions about
academic research and industrial application trends of FL, essential factors
affecting the quality of FL models, and compare FL and non-FL algorithms in
terms of learning quality. Based on our review's conclusion, we give some
suggestions for improving the FL model quality. Finally, we propose an FL
application framework for practitioners.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:48:36 GMT""}]","2020-12-04"
"2012.01974","Uwe Aickelin","Xuetong Wu, Hadi Akbarzadeh Khorshidi, Uwe Aickelin, Zobaida Edib,
  Michelle Peate","Transfer learning to enhance amenorrhea status prediction in cancer and
  fertility data with missing values","Artificial Intelligence: Applications in Healthcare Delivery, chapter
  13",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Collecting sufficient labelled training data for health and medical problems
is difficult (Antropova, et al., 2018). Also, missing values are unavoidable in
health and medical datasets and tackling the problem arising from the
inadequate instances and missingness is not straightforward (Snell, et al.
2017, Sterne, et al. 2009). However, machine learning algorithms have achieved
significant success in many real-world healthcare problems, such as regression
and classification and these techniques could possibly be a way to resolve the
issues.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:44:05 GMT""}]","2020-12-04"
"2012.01976","Dianbo Liu Dr","Leyu Dai, He Zhu, Dianbo Liu","Patient similarity: methods and applications",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Patient similarity analysis is important in health care applications. It
takes patient information such as their electronic medical records and genetic
data as input and computes the pairwise similarity between patients. Procedures
of typical a patient similarity study can be divided into several steps
including data integration, similarity measurement, and neighborhood
identification. And according to an analysis of patient similarity, doctors can
easily find the most suitable treatments. There are many methods to analyze the
similarity such as cluster analysis. And during machine learning become more
and more popular, Using neural networks such as CNN is a new hot topic. This
review summarizes representative methods used in each step and discusses
applications of patient similarity networks especially in the context of
precision medicine.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 06:50:15 GMT""}]","2020-12-04"
"2012.02053","Cy Qiu","Yajuan Qi, Chunyin Qiu, Meng Xiao, Hailong He, Manzhu Ke, and Zhengyou
  Liu","Acoustic realization of quadrupole topological insulators","This paper was published in PRL: Phys. Rev. Lett. 124, 206601 (2020)",,"10.1103/PhysRevLett.124.206601",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  A quadrupole topological insulator, being one higher-order topological
insulator with nontrivial quadrupole quantization, has been intensely
investigated very recently. However, the tight-binding model proposed for such
emergent topological insulators demands both positive and negative hopping
coefficients, which imposes an obstacle in practical realizations. Here we
introduce a feasible approach to design the sign of hopping in acoustics, and
construct the first acoustic quadrupole topological insulator that stringently
emulates the tight-binding model. The inherent hierarchy quadrupole topology
has been experimentally confirmed by detecting the acoustic responses at the
bulk, edge and corner of the sample. Potential applications can be anticipated
for the topologically robust in-gap states, such as acoustic sensing and energy
trapping.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 07:10:27 GMT""}]","2020-12-09"
"2012.02054","David Woon","David E. Woon, Dominique M. Maffucci, and Eric Herbst","Theoretical kinetic studies of Venus chemistry. Formation and
  destruction of SCl, SCl2, and HSCl","Includes 3 tables and 5 figures, plus Supplemental Information
  (cartesian structures, energies, and ZPE corrections)","Icarus 354, 114051, 2021","10.1016/j.icarus.2020.114051",,"physics.chem-ph astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Accurate and thorough characterization of the chemistry of compounds
containing the third-row elements sulfur and chlorine is critical for modeling
the composition of the atmosphere of Venus. We have used a combination of ab
initio quantum chemistry and kinetic theory to characterize a group of nine
exothermic reactions that involve the exotic sulfur-chlorine species SCl, SCl2,
and HSCl, which are thought to be present in trace quantities in the atmosphere
of Venus and are included to various degrees in the published atmospheric
models. Reaction pathways were characterized with coupled cluster theory at the
RCCSD(T) level with triple zeta quality correlation consistent basis sets. For
reactions with barriers that lie above the reactant asymptote, the barrier
height was extrapolated to the RCCSD(T) complete basis set level via
single-point calculations with quadruple and quintuple zeta quality sets. Rate
coefficients were predicted with capture theory and transition state theory as
appropriate. We have found that in some cases addition-elimination reactions
can compete with abstraction reactions due to the tendency of sulfur to form
hypervalent compounds and intermediates via recoupled pair bonding.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:40:44 GMT""}]","2020-12-04"
"2012.02105","Guido Sanguinetti","Guido Sanguinetti","Systematic errors in estimates of $R_t$ from symptomatic cases in the
  presence of observation bias","7 pages, 2 figures",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of estimating the reproduction number $R_t$ of an
epidemic for populations where the probability of detection of cases depends on
a known covariate. We argue that in such cases the normal empirical estimator
can fail when the prevalence of cases among groups changes with time. We
propose a Bayesian strategy to resolve the problem, as well as a simple
solution in the case of large number of cases. We illustrate the issue and its
solution on a simple yet realistic simulation study, and discuss the general
relevance of the issue to the current covid19 pandemic.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:05:34 GMT""}]","2020-12-04"
"2012.02300","Damien Bouchabou","Damien Bouchabou (IMT Atlantique - INFO), Sao Nguyen, Christophe Lohr,
  Benoit Leduc, Ioannis Kanellos","Fully Convolutional Network Bootstrapped by Word Encoding and Embedding
  for Activity Recognition in Smart Homes",,,,,"eess.SP cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Activity recognition in smart homes is essential when we wish to propose
automatic services for the inhabitants. However, it poses challenges in terms
of variability of the environment, sensorimotor system, but also user habits.
Therefore, endto-end systems fail at automatically extracting key features,
without extensive pre-processing. We propose to tackle feature extraction for
activity recognition in smart homes by merging methods from the Natural
Language Processing (NLP) and the Time Series Classification (TSC) domains. We
evaluate the performance of our method on two datasets issued from the Center
for Advanced Studies in Adaptive Systems (CASAS). Moreover, we analyze the
contributions of the use of NLP encoding Bag-Of-Word with Embedding as well as
the ability of the FCN algorithm to automatically extract features and
classify. The method we propose shows good performance in offline activity
classification. Our analysis also shows that FCN is a suitable algorithm for
smart home activity recognition and hightlights the advantages of automatic
feature extraction.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:47:07 GMT""}]","2020-12-07"
"2012.02590","Ryan Krueger","Ryan Krueger, Jesse Michael Han and Daniel Selsam","Automatically Building Diagrams for Olympiad Geometry Problems",,,,,"cs.CG cs.MS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a method for automatically building diagrams for olympiad-level
geometry problems and implement our approach in a new open-source software
tool, the Geometry Model Builder (GMB). Central to our method is a new
domain-specific language, the Geometry Model-Building Language (GMBL), for
specifying geometry problems along with additional metadata useful for building
diagrams. A GMBL program specifies (1) how to parameterize geometric objects
(or sets of geometric objects) and initialize these parameterized quantities,
(2) which quantities to compute directly from other quantities, and (3)
additional constraints to accumulate into a (differentiable) loss function. A
GMBL program induces a (usually) tractable numerical optimization problem whose
solutions correspond to diagrams of the original problem statement, and that we
can solve reliably using gradient descent. Of the 39 geometry problems since
2000 appearing in the International Mathematical Olympiad, 36 can be expressed
in our logic and our system can produce diagrams for 94% of them on average. To
the best of our knowledge, our method is the first in automated geometry
diagram construction to generate models for such complex problems.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 05:56:25 GMT""},{""version"":""v2"",""created"":""Sat, 1 May 2021 00:41:22 GMT""}]","2021-05-04"
"2012.02595","Thomas Vetterli","Divyansh Agarwal, Yuta Baba, Pratik Sachdeva, Tanya Tandon, Thomas
  Vetterli, Aziz Alghunaim","Accurate and Scalable Matching of Translators to Displaced Persons for
  Overcoming Language Barriers","Presented at NeurIPS 2020 Workshop on Machine Learning for the
  Developing World",,,,"cs.CY cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Residents of developing countries are disproportionately susceptible to
displacement as a result of humanitarian crises. During such crises, language
barriers impede aid workers in providing services to those displaced. To build
resilience, such services must be flexible and robust to a host of possible
languages. \textit{Tarjimly} aims to overcome the barriers by providing a
platform capable of matching bilingual volunteers to displaced persons or aid
workers in need of translating. However, Tarjimly's large pool of translators
comes with the challenge of selecting the right translator per request. In this
paper, we describe a machine learning system that matches translator requests
to volunteers at scale. We demonstrate that a simple logistic regression,
operating on easily computable features, can accurately predict and rank
translator response. In deployment, this lightweight system matches 82\% of
requests with a median response time of 59 seconds, allowing aid workers to
accelerate their services supporting displaced persons.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:50:00 GMT""}]","2020-12-07"
"2012.03722","Charles Maniere","Charles Mani\`ere (SDSU), Shirley Chan (SDSU), Geuntak Lee (SDSU),
  Joanna Mckittrick (UCSD), Eugene A. Olevsky (SDSU)","Sintering dilatometry based grain growth assessment",,"Results in Physics, Elsevier, 2018, 10, pp.91-93","10.1016/j.rinp.2018.05.014\",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Volume shrinkage, grain growth, and their interaction are major events
occurring during free sintering of ceramics. A high temperature sintering
dilatometry curve is influenced by these both phenomena. It is shown that the
continuum theory of sintering can be utilized in the format enabling the
extraction of the maximum amount of information on the densification and grain
growth kinetics based on a simple dilatometry test. We present here the
capability of such a fast approach (Dilatometry based Grain growth Assessment
DGA) utilized for the modeling of sintering and grain growth of zirconia.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:38:57 GMT""}]","2020-12-08"
"2012.04492","Andrew Thrapp","Andrew D. Thrapp, Michael R. Hughes","Reduced motion artifacts and speed improvements in enhanced
  line-scanning fiber bundle endomicroscopy","Example data available at:
  https://doi.org/10.6084/m9.figshare.13303211",,"10.1117/1.JBO.26.5.056501",,"physics.optics eess.IV","http://creativecommons.org/licenses/by/4.0/","  Significance: Confocal laser scanning enables optical sectioning in fiber
bundle endomicroscopy but limits the frame rate. To be able to better explore
tissue morphology it is useful to stitch sequentially acquired frames into a
mosaic. However, low frame rates limit the maximum probe translation speed.
Line-scanning confocal endomicroscopy provides higher frame rates, but residual
out-of-focus light degrades images. Subtraction based approaches can suppress
this residue at the expense of introducing motion artifacts.
  Aim: To generate high frame rate endomicroscopy images with improved optical
sectioning, we develop a high-speed subtraction method that only requires the
acquisition of a single camera frame.
  Approach: The rolling shutter of a CMOS camera acts as both the aligned and
offset detector slits required for subtraction-based sectioning enhancement.
Two images of the bundle are formed on different regions of the camera,
allowing both images to be acquired simultaneously.
  Results: We confirm improved optical sectioning compared to conventional
line-scanning, particularly far from focus, and show that motion artifacts are
not introduced. We demonstrate high-speed mosaicing at frame rates of up to 240
Hz.
  Conclusion: High-speed acquisition of optically sectioned images using the
new subtraction based approach leads to improved mosaicing at high frame rates.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 22:17:30 GMT""}]","2021-07-14"
"2012.04600","Victor Fadinger","Victor Fadinger and Qinghai Zhong","On product-one sequences over subsets of groups","To appear in Periodica Mathematica Hungarica",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be a group and $G_0 \subseteq G$ be a subset. A sequence over $G_0$
means a finite sequence of terms from $G_0$, where the order of elements is
disregarded and the repetition of elements is allowed. A product-one sequence
is a sequence whose elements can be ordered such that their product equals the
identity element of the group. We study algebraic and arithmetic properties of
monoids of product-one sequences over finite subsets of $G$ and over the whole
group $G$, with a special emphasis on infinite dihedral groups.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 14:15:24 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 17:08:07 GMT""}]","2021-12-02"
"2012.05054","Huansheng Ning Prof","Huansheng Ning and Feifei Shi","Could robots be regarded as humans in future?","4 pages, 1 table",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the overwhelming advances in Artificial Intelligence (AI), brain science
and neuroscience, robots are developing towards a direction of much more
human-like and human-friendly. We can't help but wonder whether robots could be
regarded as humans in future? In this article, we propose a novel perspective
to analyze the essential difference between humans and robots, that is based on
their respective living spaces, particularly the independent and intrinsic
thinking space. We finally come to the conclusion that, only when robots own
the independent and intrinsic thinking space as humans, could they have the
prerequisites to be regarded as humans.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:04:08 GMT""}]","2020-12-10"
"2012.06539","Stanis{\l}aw Szufa","Dariusz Stolicki, Stanis{\l}aw Szufa, Nimrod Talmon","Pabulib: A Participatory Budgeting Library",,,,,"cs.DC cs.MA","http://creativecommons.org/licenses/by-sa/4.0/","  We describe the PArticipatory BUdgeting LIBrary website (in short, Pabulib),
which can be accessed via http://pabulib.org/, and which is a library of
participatory budgeting data. In particular, we describe the file format (.pb)
that is used for instances of participatory budgeting.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 08:23:28 GMT""}]","2020-12-14"
"2012.07516","Shang-Wen Li","Shang-Wen Li, Jason Krone, Shuyan Dong, Yi Zhang, and Yaser Al-onaizan","Meta learning to classify intent and slot labels with noisy few shot
  examples","accepted by IEEE Spoken Language Technology Workshop, 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Recently deep learning has dominated many machine learning areas, including
spoken language understanding (SLU). However, deep learning models are
notorious for being data-hungry, and the heavily optimized models are usually
sensitive to the quality of the training examples provided and the consistency
between training and inference conditions. To improve the performance of SLU
models on tasks with noisy and low training resources, we propose a new SLU
benchmarking task: few-shot robust SLU, where SLU comprises two core problems,
intent classification (IC) and slot labeling (SL). We establish the task by
defining few-shot splits on three public IC/SL datasets, ATIS, SNIPS, and TOP,
and adding two types of natural noises (adaptation example missing/replacing
and modality mismatch) to the splits. We further propose a novel noise-robust
few-shot SLU model based on prototypical networks. We show the model
consistently outperforms the conventional fine-tuning baseline and another
popular meta-learning method, Model-Agnostic Meta-Learning (MAML), in terms of
achieving better IC accuracy and SL F1, and yielding smaller performance
variation when noises are present.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:53:30 GMT""}]","2020-12-15"
"2012.07517","Kashif Ahmad","Abdullah Hamid, Nasrullah Shiekh, Naina Said, Kashif Ahmad, Asma Gul,
  Laiq Hassan, Ala Al-Fuqaha","Fake News Detection in Social Media using Graph Neural Networks and NLP
  Techniques: A COVID-19 Use-case","3 pages",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The paper presents our solutions for the MediaEval 2020 task namely FakeNews:
Corona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task
aims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect
misinformation spreaders. The task is composed of two sub-tasks namely (i)
text-based, and (ii) structure-based fake news detection. For the first task,
we propose six different solutions relying on Bag of Words (BoW) and BERT
embedding. Three of the methods aim at binary classification task by
differentiating in 5G conspiracy and the rest of the COVID-19 related tweets
while the rest of them treat the task as ternary classification problem. In the
ternary classification task, our BoW and BERT based methods obtained an
F1-score of .606% and .566% on the development set, respectively. On the binary
classification, the BoW and BERT based solutions obtained an average F1-score
of .666% and .693%, respectively. On the other hand, for structure-based fake
news detection, we rely on Graph Neural Networks (GNNs) achieving an average
ROC of .95% on the development set.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 16:41:04 GMT""}]","2020-12-15"
"2012.08936","Radoslaw Wojciechowski","Bobo Hua, Jun Masamune and Rados{\l}aw K. Wojciechowski","Essential self-adjointness and the $L^2$-Liouville property",,,,,"math.SP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss connections between the essential self-adjointness of a symmetric
operator and the constancy of functions which are in the kernel of the adjoint
of the operator. We then illustrate this relationship in the case of Laplacians
on both manifolds and graphs. Furthermore, we discuss the Green's function and
when it gives a non-constant harmonic function which is square integrable.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 15:35:49 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 18:52:50 GMT""}]","2021-02-18"
"2012.08937","Robin Elliott","Robin Elliott","Iterated Integrals in Quantitative Topology","16 pages",,,,"math.AT math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let X be a simply connected Riemannian manifold. Until now, quantitative
topology has used Sullivan's rational homotopy theory as the bridge between
geometric information on X and torsion-free homotopy theoretic information on
X. In this paper we introduce Chen's iterated integrals on the based loop space
of X as a new bridge between these two areas. We give two applications: finding
upper bounds for Gromov's distortion of higher homotopy groups on X and also
proving the non-existence of homologically non-trivial small-volume cycles in
the space of loops on X of length at most L.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 13:15:01 GMT""}]","2020-12-17"
"2012.09785","Bahman Moraffah","Bahman Moraffah, Christ Richmond, Raha Moraffah, and Antonia
  Papandreou-Suppappola","Use of Bayesian Nonparametric methods for Estimating the Measurements in
  High Clutter",,,,,"cs.LG eess.SP stat.ML","http://creativecommons.org/licenses/by/4.0/","  Robust tracking of a target in a clutter environment is an important and
challenging task. In recent years, the nearest neighbor methods and
probabilistic data association filters were proposed. However, the performance
of these methods diminishes as the number of measurements increases. In this
paper, we propose a robust generative approach to effectively model multiple
sensor measurements for tracking a moving target in an environment with high
clutter. We assume a time-dependent number of measurements that include sensor
observations with unknown origin, some of which may only contain clutter with
no additional information. We robustly and accurately estimate the trajectory
of the moving target in a high clutter environment with an unknown number of
clutters by employing Bayesian nonparametric modeling. In particular, we employ
a class of joint Bayesian nonparametric models to construct the joint prior
distribution of target and clutter measurements such that the conditional
distributions follow a Dirichlet process. The marginalized Dirichlet process
prior of the target measurements is then used in a Bayesian tracker to estimate
the dynamically-varying target state. We show through experiments that the
tracking performance and effectiveness of our proposed framework are increased
by suppressing high clutter measurements. In addition, we show that our
proposed method outperforms existing methods such as nearest neighbor and
probability data association filters.
","[{""version"":""v1"",""created"":""Mon, 30 Nov 2020 18:32:34 GMT""}]","2020-12-18"
"2012.12090","Sylvain Marinel","Sylvain Marinel (CRISMAT), Charles Mani\`ere (CRISMAT), Anthony Bilot
  (CRISMAT), Christelle Bilot (CRISMAT), Christelle Harnois (CRISMAT),
  Guillaume Riquet (CRISMAT), Fran\c{c}ois Valdivieso (MPE-ENSMSE), Christophe
  Meunier (InTRu), Christophe Coureau, Fran\c{c}ois Barth\'elemy","Microwave Sintering of Alumina at 915 MHz: Modeling, Process Control,
  and Microstructure Distribution",,"Materials, MDPI, 2019, 12 (16), pp.2544","10.3390/ma12162544",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Microwave energy can be advantageously used for materials processing as it
provides high heating rates and homogeneous temperature field distribution.
These features are partly due to the large microwave penetration depth into
dielectric materials which is, at room temperature, a few centimeters in most
dielectric materials. However, up to now, this technology is not widely spread
for high-temperature materials processing applications (>1200{\textdegree}C),
because its reproducibly and ability to sinter large size samples (>30 cm 3)
still needs to be improved. In this context, this paper describes both an
empirically designed 915 MHz single-mode cavity made from SiC susceptors and
refractory thermal insulation, and the 3 D modeling of the process in order to
improve our understanding of it. Different susceptors geometries and coupling
slit position were numerically tested in order to better understand how these
parameters impact the field homogeneity and the process stability. It was found
that positioning the largest surface of the susceptors parallel to the
electrical field allows a very uniform and hybrid heating of the material,
while avoiding plasma or thermal instabilities. This was correlated to the 3 D
modeling results. Finally, thanks to a fully automatized system this apparatus
was used to sinter large size (~30 cm 3) low-loss dielectric alumina samples.
The sintered materials were subsequently characterized in terms of density,
grains size distribution and homogeneity. The reproducibility was also
discussed demonstrating the process efficiency and reliability.
","[{""version"":""v1"",""created"":""Tue, 1 Dec 2020 11:41:12 GMT""}]","2020-12-23"
