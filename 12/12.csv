"2012.06438","Thomas Gastine","T. Gastine and J. Wicht","Stable stratification promotes multiple zonal jets in a turbulent Jovian
  dynamo model","23 pages, 16 figures, 2 tables, accepted for publication in Icarus",,"10.1016/j.icarus.2021.114514",,"astro-ph.EP physics.flu-dyn physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ongoing NASA's Juno mission puts new constraints on the internal dynamics
of Jupiter. Data gathered by its onboard magnetometer reveal a dipole-dominated
surface magnetic field accompanied by strong localised magnetic flux patches.
The gravity measurements indicate that the fierce surface zonal jets extend
several thousands of kilometers below the cloud level before rapidly decaying
below $0.94-0.96\,R_J$, $R_J$ being the mean Jovian radius at the one bar
level. Several internal models suggest an intricate internal structure with a
thin intermediate region in which helium would segregate from hydrogen, forming
a compositionally-stratified layer. Here, we develop the first global Jovian
dynamo which incorporates an intermediate stably-stratified layer between
$0.82\,R_J$ and $0.86\,R_J$. Analysing the energy balance reveals that the
magnetic energy is almost one order of magnitude larger than kinetic energy in
the metallic region, while most of the kinetic energy is pumped into zonal
motions in the molecular envelope. Those result from the different underlying
force hierarchy with a triple balance between Lorentz, Archimedean and
ageostrophic Coriolis forces in the metallic core and inertia, buoyancy and
ageostrophic Coriolis forces controlling the external layers. The simulation
presented here is the first to demonstrate that multiple zonal jets and
dipole-dominated dynamo action can be consolidated in a global simulation. The
inclusion of an stable layer is a necessary ingredient that allows zonal jets
to develop in the outer envelope without contributing to the dynamo action in
the deeper metallic region. Stable stratification however also smooths out the
small-scale features of the magnetic field by skin effect. These constraints
suggest that possible stable layers in Jupiter should be located much closer to
the surface ($0.9-0.95\,R_J$).
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:00:15 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 08:10:09 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 12:00:55 GMT""}]","2021-05-21"
"2012.06439","Wenlong Wang","Wenlong Wang","Systematic vector solitary waves from their linear limits in
  one-dimensional $n$-component Bose-Einstein condensates","12 pages, 8 figures","Phys. Rev. E 104, 014217 (2021)","10.1103/PhysRevE.104.014217",,"cond-mat.quant-gas nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We systematically construct a series of vector solitary waves in harmonically
trapped one-dimensional three-, four-, and five-component Bose-Einstein
condensates. These stationary states are continued in chemical potentials from
the analytically tractable low-density linear limit of respective states, as
independent linear quantum harmonic oscillator states, to the high-density
nonlinear Thomas-Fermi regime. A systematic interpolation procedure is proposed
to achieve this sequential continuation via a trajectory in the
multi-dimensional space of the chemical potentials. The Bogolyubov-de Gennes
(BdG) spectra analysis shows that all of the states considered herein can be
fully stabilized in suitable chemical potential intervals in the Thomas-Fermi
regime. Finally, we present some typical $SU(n)$-rotation-induced and
driving-induced dynamics. This method can be extended to higher dimensions and
shows significant promise for finding a wide range of solitary waves ahead.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:00:54 GMT""}]","2021-08-04"
"2012.06440","Sanath Narayan","Sanath Narayan, Hisham Cholakkal, Munawar Hayat, Fahad Shahbaz Khan,
  Ming-Hsuan Yang, Ling Shao","D2-Net: Weakly-Supervised Action Localization via Discriminative
  Embeddings and Denoised Activations","ICCV 2021. Source code at https://github.com/naraysa/D2-Net",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work proposes a weakly-supervised temporal action localization
framework, called D2-Net, which strives to temporally localize actions using
video-level supervision. Our main contribution is the introduction of a novel
loss formulation, which jointly enhances the discriminability of latent
embeddings and robustness of the output temporal class activations with respect
to foreground-background noise caused by weak supervision. The proposed
formulation comprises a discriminative and a denoising loss term for enhancing
temporal action localization. The discriminative term incorporates a
classification loss and utilizes a top-down attention mechanism to enhance the
separability of latent foreground-background embeddings. The denoising loss
term explicitly addresses the foreground-background noise in class activations
by simultaneously maximizing intra-video and inter-video mutual information
using a bottom-up attention mechanism. As a result, activations in the
foreground regions are emphasized whereas those in the background regions are
suppressed, thereby leading to more robust predictions. Comprehensive
experiments are performed on multiple benchmarks, including THUMOS14 and
ActivityNet1.2. Our D2-Net performs favorably in comparison to the existing
methods on all datasets, achieving gains as high as 2.3% in terms of mAP at
IoU=0.5 on THUMOS14. Source code is available at
https://github.com/naraysa/D2-Net
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:01:56 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 17:57:06 GMT""}]","2021-08-24"
"2012.06442","Walter Ikegami Andersson","W. Ikegami Andersson, A. Akram, T. Johansson, R. Kliemt, M.
  Papenbrock, J. Regina, K. Sch\""onning and T. Stockmanns","A Generalized Approach to Longitudinal Momentum Determination in
  Cylindrical Straw Tube Detectors","Corrected author names",,,,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  The upcoming PANDA experiment at FAIR will be among a new generation of
particle physics experiments to employ a novel event filtering system realised
purely in software, i.e. a software trigger. To educate its triggering
decisions, online reconstruction algorithms need to offer outstanding
performance in terms of efficiency and track quality. We present a method to
reconstruct longitudinal track parameters in PANDA's Straw Tube Tracker, which
is general enough to be easily added to other track finding algorithms that
focus on transversal reconstruction. For the pattern recognition part of this
method, three approaches are employed and compared: A combinatorial path
finding approach, a Hough transformation, and a recursive annealing fit. In a
systematic comparison, the recursive annealing fit was found to outperform the
other approaches in every category of quality parameters and reaches a
reconstruction efficacy of 95% and higher.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:08:19 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 16:22:19 GMT""}]","2020-12-15"
"2012.06443","Montie Avery","Montie Avery and Arnd Scheel","Universal selection of pulled fronts","59 pages, 2 figures",,,,"math.AP math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish selection of critical pulled fronts in invasion processes. Our
result shows convergence to a pulled front with a logarithmic shift for open
sets of steep initial data, including one-sided compactly supported initial
conditions. We rely on robust, conceptual assumptions, namely existence and
marginal spectral stability of a front traveling at the linear spreading speed.
We demonstrate that the assumptions hold for open classes of spatially extended
systems. Previous results relied on comparison principles or probabilistic
tools with implied non-open conditions on initial data and structure of the
equation. Technically, we describe the invasion process through the interaction
of a Gaussian leading edge with the pulled front in the wake. Key ingredients
are sharp linear decay estimates to control errors in the nonlinear matching
and corrections from initial data.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:08:41 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 19:33:44 GMT""},{""version"":""v3"",""created"":""Thu, 3 Feb 2022 20:12:35 GMT""}]","2022-02-07"
"2012.06444","Yang Liu","Yang Liu, Alexandros Neophytou, Sunando Sengupta, Eric Sommerlade","Relighting Images in the Wild with a Self-Supervised Siamese
  Auto-Encoder",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We propose a self-supervised method for image relighting of single view
images in the wild. The method is based on an auto-encoder which deconstructs
an image into two separate encodings, relating to the scene illumination and
content, respectively. In order to disentangle this embedding information
without supervision, we exploit the assumption that some augmentation
operations do not affect the image content and only affect the direction of the
light. A novel loss function, called spherical harmonic loss, is introduced
that forces the illumination embedding to convert to a spherical harmonic
vector. We train our model on large-scale datasets such as Youtube 8M and
CelebA. Our experiments show that our method can correctly estimate scene
illumination and realistically re-light input images, without any supervision
or a prior shape model. Compared to supervised methods, our approach has
similar performance and avoids common lighting artifacts.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:08:50 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 16:53:13 GMT""}]","2021-08-24"
"2012.06445","Samir Siksek","Nuno Freitas, Alain Kraus and Samir Siksek","On the unit equation over cyclic number fields of prime degree",,"Alg. Number Th. 15 (2021) 2647-2653","10.2140/ant.2021.15.2647",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\ell \ne 3$ be a prime. We show that there are only finitely many cyclic
number fields $F$ of degree $\ell$ for which the unit equation $$\lambda + \mu
= 1, \qquad \lambda,~\mu \in \mathcal{O}_F^\times$$ has solutions. Our result
is effective. For example, we deduce that the only cyclic quintic number field
for which the unit equation has solutions is $\mathbb{Q}(\zeta_{11})^+$.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:11:58 GMT""}]","2022-02-09"
"2012.06446","Xiufeng Liu","Xiufeng Liu, Rongling Li, Yi Wang, Per Sieverts Nielsen","SEGSys: A mapping system for segmentation analysis in energy",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Customer segmentation analysis can give valuable insights into the energy
efficiency of residential buildings. This paper presents a mapping system,
SEGSys that enables segmentation analysis at the individual and the
neighborhood levels. SEGSys supports the online and offline classification of
customers based on their daily consumption patterns and consumption intensity.
It also supports the segmentation analysis according to the social
characteristics of customers of individual households or neighborhoods, as well
as spatial geometries. SEGSys uses a three-layer architecture to model the
segmentation system, including the data layer, the service layer, and the
presentation layer. The data layer models data into a star schema within a data
warehouse, the service layer provides data service through a RESTful interface,
and the presentation layer interacts with users through a visual map. This
paper showcases the system on the segmentation analysis using an electricity
consumption data set and validates the effectiveness of the system.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:13:24 GMT""}]","2020-12-14"
"2012.06447","Yue Shao","Yue Shao, Yicheng Hu and Victor M. Zavala","Mitigating Investment Risk Using Modular Technologies",,,,,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study logistical investment flexibility provided by modular processing
technologies for mitigating risk. Specifically, we propose a multi-stage
stochastic programming formulation that determines optimal capacity expansion
plans that mitigate demand uncertainty. The formulation accounts for
multi-product dependencies between small/large units and for trade-offs between
expected profit and risk. The formulation uses a cumulative risk measure to
avoid timeconsistency issues of traditional, per-stage risk-minimization
formulations and we argue that this approach is more compatible with typical
investment metrics such as the net present value. Case studies of different
complexity are presented to illustrate the developments. Our studies reveal
that the Pareto frontier of a flexible setting (allowing for deployment of
small units) dominates the Pareto frontier of an inflexible setting (allowing
only for deployment of large units). Notably, this dominance is prevalent
despite benefits arising from economies of scale of large processing units.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:14:56 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 14:23:01 GMT""}]","2021-02-10"
"2012.06448","Mehmet Ozan Unal","Mehmet Ozan Unal, Metin Ertas, Isa Yildirim","An Unsupervised Reconstruction Method For Low-Dose CT Using Deep
  Generative Regularization Prior",,"Biomedical Signal Processing and Control 75 (2022) 103598","10.1016/j.bspc.2022.103598",,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-dose CT imaging requires reconstruction from noisy indirect measurements
which can be defined as an ill-posed linear inverse problem. In addition to
conventional FBP method in CT imaging, recent compressed sensing based methods
exploit handcrafted priors which are mostly simplistic and hard to determine.
More recently, deep learning (DL) based methods have become popular in medical
imaging field. In CT imaging, DL based methods try to learn a function that
maps low-dose images to normal-dose images. Although the results of these
methods are promising, their success mostly depends on the availability of
high-quality massive datasets. In this study, we proposed a method that does
not require any training data or a learning process. Our method exploits such
an approach that deep convolutional neural networks (CNNs) generate patterns
easier than the noise, therefore randomly initialized generative neural
networks can be suitable priors to be used in regularizing the reconstruction.
In the experiments, the proposed method is implemented with different loss
function variants. Both analytical CT phantoms and real-world CT images are
used with different views. Conventional FBP method, a popular iterative method
(SART), and TV regularized SART are used in the comparisons. We demonstrated
that our method with different loss function variants outperforms the other
methods both qualitatively and quantitatively.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:16:32 GMT""},{""version"":""v2"",""created"":""Sat, 19 Dec 2020 10:02:04 GMT""}]","2022-03-08"
"2012.06449","Michele Giordano","Giulia Di Nunno and Michele Giordano","Maximum principles for stochastic time-changed Volterra games",,,,,"math.PR math.OC","http://creativecommons.org/licenses/by/4.0/","  We study a stochastic differential game between two players, controlling a
forward stochastic Volterra integral equation (FSVIE). Each player has to
optimize his own performance functional which includes a backward stochastic
differential equation (BSDE). The dynamics considered are driven by
time-changed L\'evy noises, with absolutely continuous time-change process. We
prove a sufficient maximum principle to characterize Nash equilibria and the
related optimal strategies. For this we use techniques of control under partial
information, and the non-anticipating stochastic derivative. The zero-sum game
is presented as a particular case.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:16:44 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 15:55:10 GMT""}]","2023-03-07"
"2012.06450","Mari\'an Koles\'ar","Mari\'an Koles\'ar, Ji\v{r}\'i Novotn\'y","Three-flavour order parameters of chiral symmetry in low-energy QCD","Presented at ICHEP2020, Prague, July 31, 2020. 6 pages, 2 tables, 1
  figure",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The current state of knowledge of the order parameters of the spontaneously
broken chiral symmetry, the quark condensate and the pseudoscalar decay
constant in the chiral limit, is briefly reviewed, based on available
phenomenological fits and lattice QCD calculations. We argue that while the
theory is pretty well understood in the two-flavour case, there is still a gap
in the knowledge of the characteristics of the QCD vacuum in the three-flavour
one. Our constraints for the three-flavour parameters obtained by a Bayesian
statistical analysis of the decays of eta to three pions are presented.
Possible implications of a new analysis of subthreshold parameters of pion-pion
scattering is outlined.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:17:30 GMT""}]","2020-12-14"
"2012.06451","Lucas Stanek","Lucas J. Stanek, Raymond C. Clay III, M.W.C. Dharma-wardana, Mitchell
  A. Wood, Kristian R.C. Beckwith, and Michael S. Murillo","Efficacy of the Radial Pair Potential Approximation for Molecular
  Dynamics Simulations of Dense Plasmas",,,"10.1063/5.0040062",,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Macroscopic simulations of dense plasmas rely on detailed microscopic
information that can be computationally expensive and is difficult to verify
experimentally. In this work, we delineate the accuracy boundary between
microscale simulation methods by comparing Kohn-Sham density functional theory
molecular dynamics (KS-MD) and radial pair potential molecular dynamics (RPP-
MD) for a range of elements, temperature, and density. By extracting the
optimal RPP from KS-MD data using force-matching, we constrain its functional
form and dismiss classes of potentials that assume a constant power law for
small interparticle distances. Our results show excellent agreement between
RPP-MD and KS-MD for multiple metrics of accuracy at temperatures of only a few
electron volts. The use of RPPs offers orders of magnitude decrease in
computational cost and indicates that three-body potentials are not required
beyond temperatures of a few eV. Due to its efficiency, the validated RPP-MD
provides an avenue for reducing errors due to finite-size effects that can be
on the order of $\sim20\%$.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:18:09 GMT""}]","2021-03-12"
"2012.06452","Piotr Kicki","Piotr Kicki, Mete Ozay, Piotr Skrzypczy\'nski","A New Neural Network Architecture Invariant to the Action of Symmetry
  Subgroups","Presented as contributed talk at NeurIPS 2020 workshop on
  Differential Geometry meets Deep Learning",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  We propose a computationally efficient $G$-invariant neural network that
approximates functions invariant to the action of a given permutation subgroup
$G \leq S_n$ of the symmetric group on input data. The key element of the
proposed network architecture is a new $G$-invariant transformation module,
which produces a $G$-invariant latent representation of the input data.
Theoretical considerations are supported by numerical experiments, which
demonstrate the effectiveness and strong generalization properties of the
proposed method in comparison to other $G$-invariant neural networks.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:19:46 GMT""}]","2020-12-14"
"2012.06453","Subodip Biswas","Subhodip Biswas, Adam D Cobb, Andreea Sistrunk, Naren Ramakrishnan,
  Brian Jalaian","Better call Surrogates: A hybrid Evolutionary Algorithm for
  Hyperparameter optimization","Accepted at the black box optimization challenge at NeurIPS 2020",,,,"cs.NE cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a surrogate-assisted evolutionary algorithm (EA)
for hyperparameter optimization of machine learning (ML) models. The proposed
STEADE model initially estimates the objective function landscape using
RadialBasis Function interpolation, and then transfers the knowledge to an EA
technique called Differential Evolution that is used to evolve new solutions
guided by a Bayesian optimization framework. We empirically evaluate our model
on the hyperparameter optimization problems as a part of the black box
optimization challenge at NeurIPS 2020 and demonstrate the improvement brought
about by STEADE over the vanilla EA.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:19:59 GMT""}]","2020-12-14"
"2012.06454","Jonathan Labadie-Bartz","Jonathan Labadie-Bartz, Dietrich Baade, Alex C. Carciofi, Amanda
  Rubio, Thomas Rivinius, Camilla C. Borre, Christophe Martayan, Robert J.
  Siverd","Short-term variability and mass loss in Be stars VI. Frequency groups in
  $\gamma$ Cas detected by TESS","19 pages, 11 figures. To be published in MNRAS",,"10.1093/mnras/staa3913",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  In photometry of $\gamma$ Cas (B0.5 IVe) from the SMEI and
BRITE-Constellation satellites, indications of low-order non-radial pulsation
have recently been found, which would establish an important commonality with
the class of classical Be stars at large. New photometry with the TESS
satellite has detected three frequency groups near 1.0 ($g1$), 2.4 ($g2$), and
5.1 ($g3$) d$^{-1}$, respectively. Some individual frequencies are nearly
harmonics or combination frequencies but not exactly so. Frequency groups are
known from roughly three quarters of all classical Be stars and also from
pulsations of $\beta$ Cep, SPB, and $\gamma$ Dor stars and, therefore, firmly
establish $\gamma$ Cas as a non-radial pulsator. The total power in each
frequency group is variable. An isolated feature exists at 7.57 d$^{-1}$ and,
together with the strongest peaks in the second and third groups ordered by
increasing frequency ($g2$ and $g3$), is the only one detected in all three
TESS sectors. The former long-term 0.82 d$^{-1}$ variability would fall into
$g1$ and has not returned at a significant level, questioning its attribution
to rotational modulation. Low-frequency stochastic variability is a dominant
feature of the TESS light curve, possibly caused by internal gravity waves
excited at the core-envelope interface. These are known to be efficient at
transporting angular momentum outward, and may also drive the oscillations that
constitute $g1$ and $g2$. The hard X-ray flux of $\gamma$ Cas is the only
remaining major property that distinguishes this star from the class of
classical Be stars.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:20:41 GMT""}]","2021-01-06"
"2012.06455","Oliver Shah","Oliver Shah, Yann Alibert, Ravit Helled, Klaus Mezger","Internal water storage capacity of terrestrial planets and the effect of
  hydration on the M-R relation","34 pages",,"10.1051/0004-6361/202038839",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the chemical interactions between water and Mg-silicates or
iron is essential to constrain the interiors of water-rich planets. Hydration
effects have, however, been mostly neglected by the astrophysics community so
far. As such effects are unlikely to have major impacts on theoretical
mass-radius relations this is justified as long as the measurement
uncertainties are large. However, upcoming missions, such as the PLATO mission
(scheduled launch 2026), are envisaged to reach a precision of up to $\approx 3
\%$ and $\approx 10 \%$ for radii and masses, respectively. As a result, we may
soon enter an area in exoplanetary research where various physical and chemical
effects such as hydration can no longer be ignored. Our goal is to construct
interior models for planets that include reliable prescriptions for hydration
of the cores and the mantles. These models can be used to refine previous
results for which hydration has been neglected and to guide future
characterization of observed exoplanets. We have developed numerical tools to
solve for the structure of multi-layered planets with variable boundary
conditions and compositions. Here we consider three types of planets: dry
interiors, hydrated interiors and dry interiors + surface ocean where the ocean
mass fraction corresponds to the mass fraction of $\rm H_2 O$ equivalent in the
hydrated case. We find H/OH storage capacities in the hydrated planets
equivalent to $0-6 \rm \ wt\% \ \rm H_{2}O$ corresponding to up to $\approx 800
\rm \ km$ deep ocean layers. In the mass range $0.1 \leq M/M_\oplus \leq 3$ the
effect of hydration on the total radius is found to be $\leq 2.5\%$ whereas the
effect of differentiation into an isolated surface ocean is $\leq 5 \ \%$.
Furthermore, we find that our results are very sensitive to the bulk
composition.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:22:18 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 13:31:23 GMT""},{""version"":""v3"",""created"":""Mon, 11 Jan 2021 18:03:47 GMT""},{""version"":""v4"",""created"":""Mon, 1 Feb 2021 19:06:41 GMT""}]","2021-03-10"
"2012.06456","Jani Taskinen","Jani M. Taskinen, Pavel Kliuiev, Antti J. Moilanen, P\""aivi T\""orm\""a","Polarization and phase textures in lattice plasmon condensates","29 pages, 7 figures",,"10.1021/acs.nanolett.1c01395",,"physics.optics cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polarization textures of light may reflect fundamental phenomena such as
topological defects, and can be utilized in engineering light beams. Three main
routes are applied during their creation: spontaneous appearance in phase
transitions, steering by an excitation beam, or structural engineering of the
medium. We present an approach that uses all three in a platform offering
advantages that are not simultaneously provided in any previous system:
advanced structural engineering, strong-coupling condensate with effective
photonic interactions, as well as room temperature and sub-picosecond
operation. We demonstrate domain wall polarization textures in a plasmonic
lattice Bose-Einstein condensate, by combining the dipole structure of the
lattice with a non-trivial condensate phase revealed by phase retrieval. These
results open new prospects for fundamental studies of non-equilibrium
condensation and sources of polarization-structured beams.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:24:00 GMT""}]","2021-07-07"
"2012.06457","Ke Yu","Li Sun, Ke Yu, Kayhan Batmanghelich","Context Matters: Graph-based Self-supervised Representation Learning for
  Medical Images","Accepted to AAAI 2021",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Supervised learning method requires a large volume of annotated datasets.
Collecting such datasets is time-consuming and expensive. Until now, very few
annotated COVID-19 imaging datasets are available. Although self-supervised
learning enables us to bootstrap the training by exploiting unlabeled data, the
generic self-supervised methods for natural images do not sufficiently
incorporate the context. For medical images, a desirable method should be
sensitive enough to detect deviation from normal-appearing tissue of each
anatomical region; here, anatomy is the context. We introduce a novel approach
with two levels of self-supervised representation learning objectives: one on
the regional anatomical level and another on the patient-level. We use graph
neural networks to incorporate the relationship between different anatomical
regions. The structure of the graph is informed by anatomical correspondences
between each patient and an anatomical atlas. In addition, the graph
representation has the advantage of handling any arbitrarily sized image in
full resolution. Experiments on large-scale Computer Tomography (CT) datasets
of lung images show that our approach compares favorably to baseline methods
that do not account for the context. We use the learnt embedding to quantify
the clinical progression of COVID-19 and show that our method generalizes well
to COVID-19 patients from different hospitals. Qualitative results suggest that
our model can identify clinically relevant regions in the images.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:26:07 GMT""}]","2020-12-14"
"2012.06458","Ruisheng Diao","Ruisheng Diao, Di Shi, Bei Zhang, Siqi Wang, Haifeng Li, Chunlei Xu,
  Tu Lan, Desong Bian, Jiajun Duan","On Training Effective Reinforcement Learning Agents for Real-time Power
  Grid Operation and Control",,,,,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Deriving fast and effectively coordinated control actions remains a grand
challenge affecting the secure and economic operation of today's large-scale
power grid. This paper presents a novel artificial intelligence (AI) based
methodology to achieve multi-objective real-time power grid control for
real-world implementation. State-of-the-art off-policy reinforcement learning
(RL) algorithm, soft actor-critic (SAC) is adopted to train AI agents with
multi-thread offline training and periodic online training for regulating
voltages and transmission losses without violating thermal constraints of
lines. A software prototype was developed and deployed in the control center of
SGCC Jiangsu Electric Power Company that interacts with their Energy Management
System (EMS) every 5 minutes. Massive numerical studies using actual power grid
snapshots in the real-time environment verify the effectiveness of the proposed
approach. Well-trained SAC agents can learn to provide effective and subsecond
control actions in regulating voltage profiles and reducing transmission
losses.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:31:42 GMT""}]","2020-12-14"
"2012.06459","Supanut Thanasilp","Supanut Thanasilp, Jirawat Tangpanitanon, Marc-Antoine Lemonde, Ninnat
  Dangniam and Dimitris G. Angelakis","Quantum supremacy and quantum phase transitions","7 pages of main text, 6 figures","Phys. Rev. B 103, 165132 (2021)","10.1103/PhysRevB.103.165132",,"quant-ph cond-mat.dis-nn cond-mat.quant-gas cond-mat.stat-mech","http://creativecommons.org/publicdomain/zero/1.0/","  Demonstrating the ability of existing quantum platforms to perform certain
computational tasks intractable to classical computers represents a cornerstone
in quantum computing. Despite the growing number of such proposed ""quantum
supreme"" tasks, it remains an important challenge to identify their direct
applications. In this work, we describe how the approach proposed in Ref.
[arXiv:2002.11946] for demonstrating quantum supremacy in generic driven analog
many-body systems, such as those found in cold atom and ion setups, can be
extended to explore dynamical quantum phase transitions. We show how key
quantum supremacy signatures, such as the distance between the output
distribution and the expected Porter Thomas distribution at the supremacy
regime, can be used as effective order parameters. We apply this approach to a
periodically driven disordered 1D Ising model and show that we can accurately
capture the transition between the driven thermalized and many-body localized
phases. This approach also captures the transition towards the Floquet
prethermalized regime for high-frequency driving. Revisiting quantum phases of
matter under the light of the recent discussions about quantum supremacy draws
a link between complexity theory and analog many-body systems.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:32:41 GMT""}]","2021-04-28"
"2012.06460","Ivan Vuli\'c","Marko Vidoni, Ivan Vuli\'c, Goran Glava\v{s}","Orthogonal Language and Task Adapters in Zero-Shot Cross-Lingual
  Transfer",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adapter modules, additional trainable parameters that enable efficient
fine-tuning of pretrained transformers, have recently been used for language
specialization of multilingual transformers, improving downstream zero-shot
cross-lingual transfer. In this work, we propose orthogonal language and task
adapters (dubbed orthoadapters) for cross-lingual transfer. They are trained to
encode language- and task-specific information that is complementary (i.e.,
orthogonal) to the knowledge already stored in the pretrained transformer's
parameters. Our zero-shot cross-lingual transfer experiments, involving three
tasks (POS-tagging, NER, NLI) and a set of 10 diverse languages, 1) point to
the usefulness of orthoadapters in cross-lingual transfer, especially for the
most complex NLI task, but also 2) indicate that the optimal adapter
configuration highly depends on the task and the target language. We hope that
our work will motivate a wider investigation of usefulness of orthogonality
constraints in language- and task-specific fine-tuning of pretrained
transformers.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:32:41 GMT""}]","2020-12-14"
"2012.06461","Christoph Peter Hofmann","Christoph P. Hofmann","Thermomagnetic Properties of QCD","17 pages, 8 figures","Phys. Rev. D 104, 014025 (2021)","10.1103/PhysRevD.104.014025",,"hep-ph hep-lat hep-th","http://creativecommons.org/licenses/by/4.0/","  We explore the low-energy regime of quantum chromodynamics subjected to an
external magnetic field by deriving the two-loop representations for the
entropy density and the magnetization within chiral perturbation theory (CHPT).
At fixed temperature, the entropy density drops when the magnetic field becomes
stronger. The magnetization induced at finite temperature is negative in the
entire parameter region accessible by CHPT. We also point out that the
enhancement of the finite-temperature part in the quark condensate is
correlated with the decrease of the entropy density.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:33:11 GMT""}]","2021-08-04"
"2012.06462","Sepehr Jalali","Federica Freddi, Jezabel R Garcia, Michael Bromberg, Sepehr Jalali,
  Da-Shan Shiu, Alvin Chua, Alberto Bernacchia","Cyclic orthogonal convolutions for long-range integration of features","11 pages, 5 figures",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  In Convolutional Neural Networks (CNNs) information flows across a small
neighbourhood of each pixel of an image, preventing long-range integration of
features before reaching deep layers in the network. We propose a novel
architecture that allows flexible information flow between features $z$ and
locations $(x,y)$ across the entire image with a small number of layers. This
architecture uses a cycle of three orthogonal convolutions, not only in $(x,y)$
coordinates, but also in $(x,z)$ and $(y,z)$ coordinates. We stack a sequence
of such cycles to obtain our deep network, named CycleNet. As this only
requires a permutation of the axes of a standard convolution, its performance
can be directly compared to a CNN. Our model obtains competitive results at
image classification on CIFAR-10 and ImageNet datasets, when compared to CNNs
of similar size. We hypothesise that long-range integration favours recognition
of objects by shape rather than texture, and we show that CycleNet transfers
better than CNNs to stylised images. On the Pathfinder challenge, where
integration of distant features is crucial, CycleNet outperforms CNNs by a
large margin. We also show that even when employing a small convolutional
kernel, the size of receptive fields of CycleNet reaches its maximum after one
cycle, while conventional CNNs require a large number of layers.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:33:48 GMT""}]","2020-12-14"
"2012.06463","Su Houng Lee","Jisu Kim, Su Houng Lee","Vector meson mass in the chiral symmetry restored vacuum","5 pages, 3 figures","Phys. Rev. D 103, 051501 (2021)","10.1103/PhysRevD.103.L051501",,"nucl-th hep-ph nucl-ex","http://creativecommons.org/licenses/by/4.0/","  We calculate the mass of the vector meson in the chiral symmetry restored
vacuum. This is accomplished by separating the four quark operators appearing
in the vector and axial vector meson sum rules into chiral symmetric and
symmetry breaking parts depending on the contribution of the fermion zero
modes. We then identify each part from the fit to the vector and axial vector
meson masses. By taking the chiral symmetry breaking part to be zero while
keeping the symmetric operator to the vacuum value, we find that the chiral
symmetric part of the vector and axial vector meson mass to be between 550 and
600 MeV. This demonstrates that chiral symmetry breaking, while responsible for
the mass difference between chiral partner, accounts only for a small fraction
of the symmetric part of the mass.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:35:09 GMT""}]","2021-03-24"
"2012.06464","Michael A. Perlin","Michael A. Perlin, Diego Barberena, Ana Maria Rey","Spin qudit tomography and state reconstruction error","7 pages, 3 figures (17 pages, 5 figures with appendices)",,"10.1103/PhysRevA.104.062413",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the task of performing quantum state tomography on a $d$-level
spin qudit, using only measurements of spin projection onto different
quantization axes. After introducing a basis of operators closely related to
the spherical harmonics, which obey the rotational symmetries of spin qudits,
we map our quantum tomography task onto the classical problem of signal
recovery on the sphere. We then provide algorithms with $O(rd^3)$ serial
runtime, parallelizable down to $O(rd^2)$, for (i) computing a priori upper
bounds on the expected error with which spin projection measurements along $r$
given axes can reconstruct an unknown qudit state, and (ii) estimating a
posteriori the statistical error in a reconstructed state. Our algorithms
motivate a simple randomized tomography protocol, for which we find that using
more measurement axes can yield substantial benefits that plateau after
$r\approx3d$.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:35:09 GMT""},{""version"":""v2"",""created"":""Fri, 24 Sep 2021 03:03:01 GMT""}]","2021-12-22"
"2012.06465","Julie Rowlett","Zhiqin Lu and Julie Rowlett","One can hear the corners of a drum","This is the author's original manuscript that was submitted to
  Bulletin of the London Mathematical Society. A significantly revised final
  version is published in BLMS","Bull. London Math. Soc., 48, no. 1, (2016), 85-93","10.1112/blms/bdv094",,"math.SP math-ph math.AP math.DG math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the presence or absence of corners is spectrally determined in
the following sense: any simply connected domain with piecewise smooth
Lipschitz boundary cannot be isospectral to any connected domain, of any genus,
which has smooth boundary. Moreover, we prove that amongst all domains with
Lipschitz, piecewise smooth boundary and fixed genus, the presence or absence
of corners is uniquely determined by the spectrum. This means that corners are
an elementary geometric spectral invariant; one can hear corners.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:35:47 GMT""}]","2020-12-14"
"2012.06466","Amee Trivedi","Amee Trivedi, Deepak Vasisht","Digital Contact Tracing: Technologies, Shortcomings, and the Path
  Forward","7 pages","ACM SIGCOMM CCR (2020)","10.1145/3431832.3431841",,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Since the start of the COVID-19 pandemic, technology enthusiasts have pushed
for digital contact tracing as a critical tool for breaking the COVID-19
transmission chains. Motivated by this push, many countries and companies have
created apps that enable digital contact tracing with the goal to identify the
chain of transmission from an infected individual to others and enable early
quarantine. Digital contact tracing applications like AarogyaSetu in India,
TraceTogether in Singapore, SwissCovid in Switzerland, and others have been
downloaded hundreds of millions of times. Yet, this technology hasn't seen the
impact that we envisioned at the start of the pandemic. Some countries have
rolled back their apps, while others have seen low adoption.
  Therefore, it is prudent to ask what the technology landscape of
contact-tracing looks like and what are the missing pieces. We attempt to
undertake this task in this paper. We present a high-level review of
technologies underlying digital contact tracing, a set of metrics that are
important while evaluating different contact tracing technologies, and evaluate
where the different technologies stand today on this set of metrics. Our hope
is two-fold: (a) Future designers of contact tracing applications can use this
review paper to understand the technology landscape, and (b) Researchers can
identify and solve the missing pieces of this puzzle so that we are ready to
face the rest of the COVID-19 pandemic and any future pandemics. A majority of
this discussion is focused on the ability to identify contact between
individuals. The questions of ethics, privacy, and security of such contact
tracing are briefly mentioned but not discussed in detail.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:36:34 GMT""}]","2020-12-14"
"2012.06467","Dor Elimelech","Dor Elimelech, Marcelo Firer and Moshe Schwartz","The Generalized Covering Radii of Linear Codes","Submitted to IEEE Transactions on Information Theory",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by an application to database linear querying, such as private
information-retrieval protocols, we suggest a fundamental property of linear
codes -- the generalized covering radius. The generalized covering-radius
hierarchy of a linear code characterizes the trade-off between storage amount,
latency, and access complexity, in such database systems. Several equivalent
definitions are provided, showing this as a combinatorial, geometric, and
algebraic notion. We derive bounds on the code parameters in relation with the
generalized covering radii, study the effect of simple code operations, and
describe a connection with generalized Hamming weights.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:38:22 GMT""}]","2020-12-14"
"2012.06468","Maurice Laveaux","Maurice Laveaux and Tim A.C. Willemse","Decompositional Minimisation of Monolithic Processes","24 pages, technical report",,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compositional minimisation can be an effective technique to reduce the state
space explosion problem. This technique considers a parallel composition of
several processes. In its simplest form, each sequential process is replaced by
an abstraction, simpler than the corresponding process while still preserving
the property that is checked. However, this technique cannot be applied in a
setting where parallel composition is first translated to a non-deterministic
sequential monolithic process. The advantage of this monolithic process is that
it facilitates static analysis of global behaviour. Therefore, we present a
technique that considers a monolithic process with data and decomposes it into
two processes where each process defines behaviour for a subset of the
parameters of the monolithic process. We prove that these processes preserve
the properties of the monolithic process under a suitable synchronisation
context. Moreover, we prove that state invariants can be used to improve its
effectiveness. Finally, we apply the decomposition technique to several
specifications.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:39:25 GMT""}]","2020-12-14"
"2012.06469","Indra Deep Mastan","Indra Deep Mastan and Shanmuganathan Raman","DILIE: Deep Internal Learning for Image Enhancement",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We consider the generic deep image enhancement problem where an input image
is transformed into a perceptually better-looking image. Recent methods for
image enhancement consider the problem by performing style transfer and image
restoration. The methods mostly fall into two categories: training data-based
and training data-independent (deep internal learning methods). We perform
image enhancement in the deep internal learning framework. Our Deep Internal
Learning for Image Enhancement framework enhances content features and style
features and uses contextual content loss for preserving image context in the
enhanced image. We show results on both hazy and noisy image enhancement. To
validate the results, we use structure similarity and perceptual error, which
is efficient in measuring the unrealistic deformation present in the images. We
show that the proposed framework outperforms the relevant state-of-the-art
works for image enhancement.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:39:44 GMT""}]","2020-12-14"
"2012.06470","Ali Raza","Ali Raza, Hafiz Saud Arshad","Prediction of Hemolysis Tendency of Peptides using a Reliable Evaluation
  Method","5 pages 4 figures",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  There are numerous peptides discovered through past decades, which exhibit
antimicrobial and anti-cancerous tendencies. Due to these reasons, peptides are
supposed to be sound therapeutic candidates. Some peptides can pose low
metabolic stability, high toxicity and high hemolity of peptides. This
highlights the importance for evaluating hemolytic tendencies and toxicity of
peptides, before using them for therapeutics. Traditional methods for
evaluation of toxicity of peptides can be time-consuming and costly. In this
study, we have extracted peptides data (Hemo-DB) from Database of Antimicrobial
Activity and Structure of Peptides (DBAASP) based on certain hemolity criteria
and we present a machine learning based method for prediction of hemolytic
tendencies of peptides (i.e. Hemolytic or Non-Hemolytic). Our model offers
significant improvement on hemolity prediction benchmarks. we also propose a
reliable clustering-based train-tests splitting method which ensures that no
peptide in train set is more than 40% similar to any peptide in test set. Using
this train-test split, we can get reliable estimated of expected model
performance on unseen data distribution or newly discovered peptides. Our model
tests 0.9986 AUC-ROC (Area Under Receiver Operating Curve) and 97.79% Accuracy
on test set of Hemo-DB using traditional random train-test splitting method.
Moreover, our model tests AUC-ROC of 0.997 and Accuracy of 97.58% while using
clustering-based train-test data split. Furthermore, we check our model on an
unseen data distribution (at Hemo-PI 3) and we recorded 0.8726 AUC-ROC and
79.5% accuracy. Using the proposed method, potential therapeutic peptides can
be screened, which may further in therapeutics and get reliable predictions for
unseen amino acids distribution of peptides and newly discovered peptides.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:40:13 GMT""}]","2020-12-14"
"2012.06471","Tim Netzer","Paria Abbasi, Andreas Klingler and Tim Netzer","Approximate Completely Positive Semidefinite Rank","v2: clarified and corrected some citations",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  In this paper we provide an approximation for completely positive
semidefinite (cpsd) matrices with cpsd-rank bounded above (almost)
independently from the cpsd-rank of the initial matrix. This is particularly
relevant since the cpsd-rank of a matrix cannot, in general, be upper bounded
by a function only depending on its size. For this purpose, we make use of the
Approximate Carath\'eodory Theorem in order to construct an approximate matrix
with a low-rank Gram representation. We then employ the Johnson-Lindenstrauss
Lemma to improve to a logarithmic dependence of the cpsd-rank on the size.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:43:29 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 11:33:40 GMT""}]","2020-12-22"
"2012.06472","Joel Berg\'e","Pierre Touboul, Manuel Rodrigues, Gilles M\'etris, Ratana Chhun, Alain
  Robert, Quentin Baghi, Emilie Hardy, Joel Berg\'e, Damien Boulanger, Bruno
  Christophe, Valerio Cipolla, Bernard Foulon, Pierre-Yves Guidotti, Phuong-Anh
  Huynh, Vincent Lebat, Fran\c{c}oise Liorzou, Benjamin Pouilloux, Pascal
  Prieur, Serge Reynaud","MICROSCOPE mission analysis, requirements and expected performance","References updated","Class. Quantum Grav. 39 (2022) 204001","10.1088/1361-6382/abebf1",,"gr-qc astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The MICROSCOPE mission aimed to test the Weak Equivalence Principle (WEP) to
a precision of $10^{-15}$. The WEP states that two bodies fall at the same rate
on a gravitational field independently of their mass or composition. In
MICROSCOPE, two masses of different compositions (titanium and platinum alloys)
are placed on a quasi-circular trajectory around the Earth. They are the
test-masses of a double accelerometer. The measurement of their accelerations
is used to extract a potential WEP violation that would occur at a frequency
defined by the motion and attitude of the satellite around the Earth. This
paper details the major drivers of the mission leading to the specification of
the major subsystems (satellite, ground segment, instrument, orbit...).
Building upon the measurement equation, we derive the objective of the test in
statistical and systematic error allocation and provide the mission's expected
error budget.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:44:42 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 12:30:51 GMT""}]","2023-04-14"
"2012.06474","Alessandro Zonta","A. Zonta, S.K. Smit and A.E. Eiben","Generating Human-Like Movement: A Comparison Between Two Approaches
  Based on Environmental Features","31 pages, 16 figures, submitted to Expert Systems with Applications",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Modelling realistic human behaviours in simulation is an ongoing challenge
that resides between several fields like social sciences, philosophy, and
artificial intelligence. Human movement is a special type of behaviour driven
by intent (e.g. to get groceries) and the surrounding environment (e.g.
curiosity to see new interesting places). Services available online and offline
do not normally consider the environment when planning a path, which is
decisive especially on a leisure trip. Two novel algorithms have been presented
to generate human-like trajectories based on environmental features. The
Attraction-Based A* algorithm includes in its computation information from the
environmental features meanwhile, the Feature-Based A* algorithm also injects
information from the real trajectories in its computation. The human-likeness
aspect has been tested by a human expert judging the final generated
trajectories as realistic. This paper presents a comparison between the two
approaches in some key metrics like efficiency, efficacy, and hyper-parameters
sensitivity. We show how, despite generating trajectories that are closer to
the real one according to our predefined metrics, the Feature-Based A*
algorithm fall short in time efficiency compared to the Attraction-Based A*
algorithm, hindering the usability of the model in the real world.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:45:32 GMT""}]","2020-12-14"
"2012.06475","Viktor Rudnev","Viktor Rudnev and Vladislav Golyanik and Jiayi Wang and Hans-Peter
  Seidel and Franziska Mueller and Mohamed Elgharib and Christian Theobalt","EventHands: Real-Time Neural 3D Hand Pose Estimation from an Event
  Stream","16 pages, 10 figures, 1 table; project page:
  https://4dqv.mpi-inf.mpg.de/EventHands/","International Conference on Computer Vision (ICCV) 2021",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D hand pose estimation from monocular videos is a long-standing and
challenging problem, which is now seeing a strong upturn. In this work, we
address it for the first time using a single event camera, i.e., an
asynchronous vision sensor reacting on brightness changes. Our EventHands
approach has characteristics previously not demonstrated with a single RGB or
depth camera such as high temporal resolution at low data throughputs and
real-time performance at 1000 Hz. Due to the different data modality of event
cameras compared to classical cameras, existing methods cannot be directly
applied to and re-trained for event streams. We thus design a new neural
approach which accepts a new event stream representation suitable for learning,
which is trained on newly-generated synthetic event streams and can generalise
to real data. Experiments show that EventHands outperforms recent monocular
methods using a colour (or depth) camera in terms of accuracy and its ability
to capture hand motions of unprecedented speed. Our method, the event stream
simulator and the dataset are publicly available; see
https://4dqv.mpi-inf.mpg.de/EventHands/
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:45:34 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 16:12:52 GMT""},{""version"":""v3"",""created"":""Mon, 11 Oct 2021 16:37:49 GMT""}]","2021-10-12"
"2012.06479","Joel Berg\'e","Alain Robert, Valerio Cipolla, Pascal Prieur, Pierre Touboul, Gilles
  M\'etris, Manuel Rodrigues, Yves Andr\'e, Joel Berg\'e, Damien Boulanger,
  Ratana Chhun, Bruno Christophe, Pierre-Yves Guidotti, Emilie Hardy, Vincent
  Lebat, Thomas Lienart, Fran\c{c}oise Liorzou, Benjamin Pouilloux","MICROSCOPE Satellite and its Drag-Free and Attitude Control System","References updated",,,,"gr-qc astro-ph.IM physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  This paper focus on the description of the design and performance of the
MICROSCOPE satellite and its Drag-Free and Attitude Control System (DFACS). The
satellite is derived from CNES' Myriade platform family, albeit with
significant upgrades dictated by the unprecedented MICROSCOPE's mission
requirements. The 300kg drag-free microsatellite has completed its 2-year
flight with higher-than-expected performances. Its passive thermal concept
allowed for variations smaller than 1 $\mu$K at the measurement frequency
$f_{\rm{EP}}$. The propulsion system provided a 6 axis continuous and very low
noise thrust from zero to some hundreds of micronewtons. Finally, the
performance of its DFACS (aimed at compensating the disturbing forces and
torques applied to the satellite) is the finest ever achieved in low Earth
orbit, with residual accelerations along the three axes are lower than
$10^{-12} {\rm m/s}^2$ at $f_{\rm{EP}}$ over 8 days.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:46:45 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 12:37:49 GMT""}]","2020-12-23"
"2012.06484","Joel Berg\'e","Joel Berg\'e, Quentin Baghi, Emilie Hardy, Gilles M\'etris, Alain
  Robert, Manuel Rodrigues, Pierre Touboul, Ratana Chhun, Pierre-Yves Guidotti,
  Sandrine Pires, Serge Reynaud, Laura Serron, Jean-Michel Travert","MICROSCOPE mission: Data analysis principle","References updated","Class. Quantum Grav. 39 (2022) 204007","10.1088/1361-6382/ac0235",,"gr-qc astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  After performing highly sensitive acceleration measurements during two years
of drag-free flight around the Earth, MICROSCOPE provided the best constraint
on the Weak Equivalence Principle (WEP) to date. Beside being a technological
challenge, this experiment required a specialised data analysis pipeline to
look for a potential small signal buried in the noise, possibly plagued by
instrumental defects, missing data and glitches. This paper describes the
frequency-domain iterative least-square technique that we developed for
MICROSCOPE. In particular, using numerical simulations, we prove that our
estimator is unbiased and provides correct error bars. This paper therefore
justifies the robustness of the WEP measurements given by MICROSCOPE.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:48:37 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 12:41:53 GMT""}]","2023-04-14"
"2012.06485","Joel Berg\'e","Joel Berg\'e, Quentin Baghi, Alain Robert, Manuel Rodrigues, Bernard
  Foulon, Emilie Hardy, Gilles M\'etris, Sandrine Pires, Pierre Touboul","MICROSCOPE mission: Statistics and impact of glitches on the test of the
  weak equivalence principle","References updated",,,,"gr-qc astro-ph.IM physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  MICROSCOPE's space test of the weak equivalence principle (WEP) is based on
the minute measurement of the difference of accelerations experienced by two
test masses as they orbit the Earth. A detection of a violation of the WEP
would appear at a well-known frequency $f_{\rm EP}$ depending on the
satellite's orbital and spinning frequencies. Consequently, the experiment was
optimised to miminise systematic errors at $f_{\rm EP}$. Glitches are
short-lived events visible in the test masses' measured acceleration, most
likely originating in cracks of the satellite's coating. In this paper, we
characterise their shape and time distribution. Although intrinsically random,
their time of arrival distribution is modulated by the orbital and spinning
periods. They have an impact on the WEP test that must be quantified. However,
the data available prevents us from unequivocally tackling this task. We show
that glitches affect the test of the WEP, up to an a priori unknown level.
Discarding the perturbed data is thus the best way to reduce their effect.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:50:32 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 12:45:27 GMT""}]","2020-12-23"
"2012.06486","Giorgio Volpe","Maria J. Lo Faro, Giovanna Ruello, Antonio A. Leonardi, Dario
  Morganti, Alessia Irrera, Francesco Priolo, Sylvain Gigan, Giorgio Volpe,
  Barbara Fazio","Directional control of weakly localized Raman from a random network of
  fractal nanowires",,"Advanced Science 8, 2100139 (2021)","10.1002/advs.202100139",,"physics.optics cond-mat.dis-nn cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Disordered optical media are an emerging class of materials capable of
strongly scattering light. Their study is relevant to investigate transport
phenomena and for applications in imaging, sensing and energy storage. While
such materials can be used to generate coherent light, their directional
emission is typically hampered by their very multiple scattering nature. Here,
we tune the out-of-plane directionality of coherent Raman light scattered by a
fractal network of silicon nanowires. By visualizing Rayleigh scattering,
photoluminescence and weakly localized Raman light from the random network of
nanowires via real-space microscopy and Fourier imaging, we gain insight on the
light transport mechanisms responsible for the material's inelastic coherent
signal and for its directionality. The possibility of visualizing and
manipulating directional coherent light in such networks of nanowires opens
venues for fundamental studies of light propagation in disordered media as well
as for the development of next generation optical devices based on disordered
structures, inclusive of sensors, light sources and optical switches.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:51:09 GMT""}]","2021-07-26"
"2012.06487","Tau Rasethuntsa Mr","Tau Raphael Rasethuntsa","On the UMVUE and Closed-Form Bayes Estimator for $Pr(X<Y<Z)$ and its
  Generalizations","Manuscript will undergo major modifications",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article considers the parametric estimation of $Pr(X<Y<Z)$ and its
generalizations based on several well-known one-parameter and two-parameter
continuous distributions. It is shown that for some one-parameter distributions
and when there is a common known parameter in some two-parameter distributions,
the uniformly minimum variance unbiased estimator can be expressed as a linear
combination of the Appell hypergeometric function of the first type, $F_{1}$
and the hypergeometric functions $_{2}F_{1}$ and $_{3}F_{2}.$ The Bayes
estimator based on conjugate gamma priors and Jefferys' non-informative priors
under the squared error loss function is also given as a linear combination of
$_{2}F_{1}$ and $F_{1}.$ Alternatively, a convergent infinite series form of
the Bayes estimator involving the $F_{1}$ function is also proposed. In model
generalizations and extensions, it is further shown that the UMVUE can be
expressed as a linear combination of a Lauricella series, $F_{D}^{(n)},$ and
the generalized hypergeometric function, $_{p}F_{q},$ which are generalizations
of $F_{1}$ and $_{2}F_{1}$ respectively. The generalized closed-form Bayes
estimator is also given as a convergent infinite series involving
$F_{D}^{(n)}.$ To gauge the performances of the UMVUE and the closed-form Bayes
estimator for $P$ against other well-known estimators, maximum likelihood
estimates, Lindley approximation estimates and Markov Chain Monte Carlo
estimates for $P$ are also computed. Additionally, asymptotic confidence
intervals and Bayesian highest probability density credible intervals are also
constructed.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:53:20 GMT""},{""version"":""v2"",""created"":""Mon, 23 Jan 2023 20:51:06 GMT""}]","2023-01-25"
"2012.06488","Juhyun Park","Juhyun Park, Jeongyoun Ahn, Yongho Jeon","Sparse Functional Linear Discriminant Analysis",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Functional linear discriminant analysis offers a simple yet efficient method
for classification, with the possibility of achieving a perfect classification.
Several methods are proposed in the literature that mostly address the
dimensionality of the problem. On the other hand, there is a growing interest
in interpretability of the analysis, which favors a simple and sparse solution.
In this work, we propose a new approach that incorporates a type of sparsity
that identifies non-zero sub-domains in the functional setting, offering a
solution that is easier to interpret without compromising performance. With the
need to embed additional constraints in the solution, we reformulate the
functional linear discriminant analysis as a regularization problem with an
appropriate penalty. Inspired by the success of $\ell_1$-type regularization at
inducing zero coefficients for scalar variables, we develop a new
regularization method for functional linear discriminant analysis that
incorporates an $L^1$-type penalty, $\int |f|$, to induce zero regions. We
demonstrate that our formulation has a well defined solution that contains zero
regions, achieving a functional sparsity in the sense of domain selection. In
addition, the misclassification probability of the regularized solution is
shown to converge to the Bayes error if the data are Gaussian. Our method does
not presume that the underlying function has zero regions in the domain, but
produces a sparse estimator that consistently estimates the true function
whether or not the latter is sparse. Numerical comparisons with existing
methods demonstrate this property in finite samples with both simulated and
real data examples.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:53:40 GMT""}]","2020-12-14"
"2012.06489","Julie Rowlett","Nelia Charalambous, Zhiqin Lu, and Julie Rowlett","Eigenvalue Estimates on Bakry-Emery Manifolds","This is a preliminary version of the article by the same name that
  was subsequently revised and published in the Springer Proceedings in
  Mathematics & Statistics book series (PROMS, volume 119)","In: Escher J., Schrohe E., Seiler J., Walker C. (eds) Elliptic and
  Parabolic Equations. Springer Proceedings in Mathematics & Statistics, vol
  119. Springer, Cham. (2015) 45-61","10.1007/978-3-319-12547-3_2",,"math.SP math.AP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate lower bounds for the eigenvalues of compact Bakry-Emery
manifolds with and without boundary. The lower bounds for the first eigenvalue
rely on a generalised maximum principle which allows gradient estimates in the
Riemannian setting to be directly applied to the Bakry-Emery setting. Lower
bounds for all eigenvalues are demonstrated using heat kernel estimates and a
suitable Sobolev inequality.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:54:43 GMT""}]","2020-12-14"
"2012.06490","Pierre Illien","Alexis Poncet, Olivier B\'enichou, Pierre Illien","Cumulant generating functions of a tracer in quenched dense symmetric
  exclusion processes",,"Phys. Rev. E 103, 040103 (2021)","10.1103/PhysRevE.103.L040103",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Symmetric Exclusion Process (SEP), where particles hop on a 1D lattice
with the restriction that there can only be one particle per site, is a
paradigmatic model of interacting particle systems. Recently, it has been shown
that the nature of the initial conditions - annealed or quenched - has a
quantitative impact on the long-time properties of tracer diffusion. However,
so far, all the studies in the quenched case focused on the low-density limit
of the SEP. Here, we derive the cumulant generating function of the tracer
position in the dense limit with quenched initial conditions. Importantly, our
approach also allows us to consider the nonequilibrium situations of (i) a
biased tracer in the SEP and (ii) a symmetric tracer in a step of density. In
the former situation, we show that the initial conditions have a striking
impact, and change the very dependence of the cumulants on the bias.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:55:26 GMT""}]","2021-05-05"
"2012.06491","Hans Rabus","H. Rabus, W.B. Li, C. Villagrasa, J. Schuemann, P.A. Hepperle, L. de
  la Fuente Rosales, M. Beuve, S. Di Maria, A.P. Klapproth, C.Y. Li, F.
  Poignant, B. Rudek, H. Nettelbeck","Intercomparison of Monte Carlo calculated dose enhancement ratios for
  gold nanoparticles irradiated by X-rays: assessing the uncertainty and
  correct methodology for extended beams","15 pages, 9 figures, 4 tables, accepted manuscript in Physica Medica",,"10.1016/j.ejmp.2021.03.005",,"physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Results of a Monte Carlo code intercomparison exercise for simulations of the
dose enhancement from a gold nanoparticle (GNP) irradiated by X-rays have been
recently reported. To highlight potential differences between codes, the dose
enhancement ratios (DERs) were shown for the narrow-beam geometry used in the
simulations, which leads to values significantly higher than unity over
distances in the order of several tens of micrometers from the GNP surface. As
it has come to our attention that the figures in our paper have given rise to
misinterpretation as showing 'the' DERs of GNPs under diagnostic X-ray
irradiation, this article presents estimates of the DERs that would have been
obtained with realistic radiation field extensions and presence of secondary
particle equilibrium (SPE). These DER values are much smaller than those for a
narrow-beam irradiation shown in our paper, and significant dose enhancement is
only found within a few hundred nanometers around the GNP. The approach used to
obtain these estimates required the development of a methodology to identify
and, where possible, correct results from simulations whose implementation
deviated from the initial exercise definition. Based on this methodology,
literature on Monte Carlo simulated DERs has been critically assessed.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:55:43 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 13:49:06 GMT""}]","2021-07-20"
"2012.06492","Chinedu Ezenkwu Pascal","Chinedu Pascal Ezenkwu and Andrew Starkey","Technical Opinion: From Animal Behaviour to Autonomous Robots",,,,,"cs.RO cs.AI","http://creativecommons.org/licenses/by/4.0/","  With the rising applications of robots in unstructured real-world
environments, roboticists are increasingly concerned with the problems posed by
the complexity of such environments. One solution to these problems is robot
autonomy. Since nature has already solved the problem of autonomy it can be a
suitable model for developing autonomous robots. This paper presents a concise
review on robot autonomy from the perspective of animal behaviour. It examines
some state-of-the-art techniques as well as suggesting possible research
directions.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:57:28 GMT""}]","2020-12-14"
"2012.06493","Ivar Stefansson","Ivar Stefansson, Eirik Keilegavlen, S{\ae}unn Halld\'orsd\'ottir, Inga
  Berre","Numerical modelling of convection-driven cooling, deformation and
  fracturing of thermo-poroelastic media",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convection-driven cooling in porous media influences thermo-poro-mechanical
stresses, thereby causing deformation. These processes are strongly influenced
by the presence of fractures, which dominate flow and heat transfer. At the
same time, the fractures deform and propagate in response to changes in the
stress state. Mathematically, the model governing the physics is tightly
coupled and must account for the strong discontinuities introduced by the
fractures. Over the last decade, and motivated by a number of porous media
applications, research into such coupled models has advanced modelling of
processes in porous media substantially.
  Building on this effort, this work presents a novel model that couples flow,
heat transfer, deformation, and propagation of fractures with flow, heat
transfer, and thermo-poroelasticity in the matrix. The model is based on
explicit representation of fractures in the porous medium, and discretised
using multi-point finite volume methods. Frictional contact and non-penetration
conditions for the fractures are handled through active set methods, while a
propagation criterion based on stress intensity factors governs fracture
extension. Considering both forced and natural convection processes, the
numerical results show the intricate nature of thermo-poromechanical fracture
deformation and propagation.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:58:28 GMT""}]","2020-12-14"
"2012.06494","Hongming Li","Hongming Li, Yong Fan","Unsupervised deep learning for individualized brain functional network
  identification",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A novel unsupervised deep learning method is developed to identify
individual-specific large scale brain functional networks (FNs) from
resting-state fMRI (rsfMRI) in an end-to-end learning fashion. Our method
leverages deep Encoder-Decoder networks and conventional brain decomposition
models to identify individual-specific FNs in an unsupervised learning
framework and facilitate fast inference for new individuals with one forward
pass of the deep network. Particularly, convolutional neural networks (CNNs)
with an Encoder-Decoder architecture are adopted to identify
individual-specific FNs from rsfMRI data by optimizing their data fitting and
sparsity regularization terms that are commonly used in brain decomposition
models. Moreover, a time-invariant representation learning module is designed
to learn features invariant to temporal orders of time points of rsfMRI data.
The proposed method has been validated based on a large rsfMRI dataset and
experimental results have demonstrated that our method could obtain
individual-specific FNs which are consistent with well-established FNs and are
informative for predicting brain age, indicating that the individual-specific
FNs identified truly captured the underlying variability of individualized
functional neuroanatomy.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:58:55 GMT""}]","2020-12-14"
"2012.06495","Vyacheslav V. Shokurov","V.V. Shokurov","Existence and boundedness of $n$-complements",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Theory of $n$-complements with applications is presented.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:59:11 GMT""}]","2020-12-14"
"2012.06496","Gabriele Perfetto","Gabriele Perfetto, Benjamin Doyon","Euler-scale dynamical fluctuations in non-equilibrium interacting
  integrable systems","35 pages, 1 figure","SciPost Phys. 10, 116 (2021)","10.21468/SciPostPhys.10.5.116",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We derive an exact formula for the scaled cumulant generating function of the
time-integrated current associated to an arbitrary ballistically transported
conserved charge. Our results rely on the Euler-scale description of
interacting, many-body, integrable models out of equilibrium given by the
generalized hydrodynamics, and on the large deviation theory. Crucially, our
findings extend previous studies by accounting for inhomogeneous and dynamical
initial states in interacting systems. We present exact expressions for the
first three cumulants of the time-integrated current. Considering the
non-interacting limit of our general expression for the scaled cumulant
generating function, we further show that for the partitioning protocol initial
state our result coincides with previous results of the literature. Given the
universality of the generalized hydrodynamics, the expression obtained for the
scaled cumulant generating function is applicable to any interacting integrable
model obeying the hydrodynamic equations, both classical and quantum.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:00:57 GMT""}]","2021-05-31"
"2012.06497","Cosmin Burtea","Didier Bresch and Cosmin Burtea and Fr\'ed\'eric Lagouti\`ere","Physical Relaxation Terms for Compressible Two-Phase Systems",,,,,"math.AP math-ph math.MP physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  In this note, we propose the first mathematical derivation of a macroscopic
Baer-Nunziato type system for compressible two-phase flows allowing two
pressure state laws depending on the different phases. By doing so, we extend
the results obtained by the first author and M. Hillairet (Annales ENS 2019) to
cover this important physical situation. A relaxation term in the mass fraction
equation is obtained without closure assumptions contrarily to
theoretical-physics literature dedicated to mixture theory, see for instance
""Thermo-Fluid dynamics of Two Fluid Flows"" by M. Ishii. The relaxation
parameter is linked to the viscosities of the different fluids (which may be
small for applications) and the relaxed quantity is linked to the laws chosen
at interfaces of the two-fluid system at a mesoscale.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:01:50 GMT""}]","2020-12-14"
"2012.06498","Indra Deep Mastan","Indra Deep Mastan and Shanmuganathan Raman","DeepObjStyle: Deep Object-based Photo Style Transfer",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  One of the major challenges of style transfer is the appropriate image
features supervision between the output image and the input (style and content)
images. An efficient strategy would be to define an object map between the
objects of the style and the content images. However, such a mapping is not
well established when there are semantic objects of different types and numbers
in the style and the content images. It also leads to content mismatch in the
style transfer output, which could reduce the visual quality of the results. We
propose an object-based style transfer approach, called DeepObjStyle, for the
style supervision in the training data-independent framework. DeepObjStyle
preserves the semantics of the objects and achieves better style transfer in
the challenging scenario when the style and the content images have a mismatch
of image features. We also perform style transfer of images containing a word
cloud to demonstrate that DeepObjStyle enables an appropriate image features
supervision. We validate the results using quantitative comparisons and user
studies.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:02:01 GMT""}]","2020-12-14"
"2012.06499","Benjamin Knorr","Benjamin Knorr","Exact solutions and residual regulator dependence in functional
  renormalisation group flows","16 pages, 6+1 figures",,"10.1088/1751-8121/ac00d4",,"hep-th cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct exact solutions to the functional renormalisation group equation
of the O(N) model and the Gross-Neveu model at large N for $2<d<4$, without
specifying the form of the regulator. This allows to investigate which
quantities are independent of the choice of regulator without being plagued by
truncation artefacts. We find that only universal quantities, like critical
exponents, and qualitative features, like the existence of a finite vacuum
expectation value, are regulator-independent, whereas values of coupling
constants are generically arbitrary. We also provide a general algorithm to
construct a concrete operator basis for truncations in the derivative expansion
and the Blaizot-M\'endez-Wschebor scheme.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:02:53 GMT""}]","2021-07-07"
"2012.06500","Mengzhi Chen","Mengzhi Chen, Tong Li, Jacek Dobaczewski, Witold Nazarewicz","Microscopic origin of reflection-asymmetric nuclear shapes","11 pages, 12 figures","Phys. Rev. C 103, 034303 (2021)","10.1103/PhysRevC.103.034303",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background: The presence of nuclear ground states with stable
reflection-asymmetric shapes is supported by rich experimental evidence.
Theoretical surveys of odd-multipolarity deformations predict the existence of
pear-shaped isotopes in several fairly localized regions of the nuclear
landscape in the vicinity of near-lying single-particle shells with
$\Delta\ell=\Delta j=3$. Purpose: We analyze the role of isoscalar, isovector,
neutron-proton, neutron-neutron, and proton-proton multipole interaction
energies in inducing the onset of reflection-asymmetric ground-state
deformations. Methods: The calculations are performed in the framework of axial
reflection-asymmetric Hartree-Fock-Bogoliubov theory using two Skyrme energy
density functionals and density-dependent pairing force. Results: We show that
reflection-asymmetric ground-state shapes of atomic nuclei are driven by the
odd-multipolarity neutron-proton (or isoscalar) part of the nuclear interaction
energy. This result is consistent with the particle-vibration picture, in which
the main driver of octupole instability is the isoscalar octupole-octupole
interaction giving rise to large $E3$ polarizability.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:04:13 GMT""},{""version"":""v2"",""created"":""Thu, 17 Dec 2020 16:38:38 GMT""},{""version"":""v3"",""created"":""Wed, 3 Mar 2021 19:33:09 GMT""}]","2021-03-10"
"2012.06501","James Hamlin","J. M. DeStefano, G. P. Marciaga, J. B. Flahavan, U. S. Shah, T. A.
  Elmslie, M. W. Meisel, and J. J. Hamlin","Absence of superconductivity in topological metal ScInAu$_2$","5 pages, 4 figures",,"10.1016/j.physc.2021.1353928",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Heusler compound ScInAu$_2$ was previously reported to have a
superconducting ground state with a critical temperature of 3.0 K. Recent high
throughput calculations have also predicted that the material harbors a
topologically non-trivial band structure similar to that reported for
beta-PdBi$_2$. In an effort to explore the interplay between the
superconducting and topological properties properties, electrical resistance,
magnetization, and x-ray diffraction measurements were performed on
polycrystalline ScInAu$_2$. The data reveal that high-quality polycrystalline
samples lack the super-conducting transition present samples that have not been
annealed. These results indicate the earlier reported superconductivity is
non-intrinsic. Several compounds in the Au-In-Sc ternary phase space (ScAu$_2$,
ScIn$_3$, and ScInAu$_2$) were explored in an attempt to identify the secondary
phase responsible for the non-intrinsic superconductivity. The results suggest
that elemental In is responsible for the reported superconductivity in
ScInAu$_2$.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:04:17 GMT""}]","2021-08-25"
"2012.06502","Mohammad Mannan","S. Ali, M. Elgharabawy, Q. Duchaussoy, M. Mannan, A. Youssef","Betrayed by the Guardian: Security and Privacy Risks of Parental Control
  Solutions",,"Published at ACSAC 2020","10.1145/3427228.3427287",,"cs.CR cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For parents of young children and adolescents, the digital age has introduced
many new challenges, including excessive screen time, inappropriate online
content, cyber predators, and cyberbullying. To address these challenges, many
parents rely on numerous parental control solutions on different platforms,
including parental control network devices (e.g., WiFi routers) and software
applications on mobile devices and laptops. While these parental control
solutions may help digital parenting, they may also introduce serious security
and privacy risks to children and parents, due to their elevated privileges and
having access to a significant amount of privacy-sensitive data. In this paper,
we present an experimental framework for systematically evaluating security and
privacy issues in parental control software and hardware solutions. Using the
developed framework, we provide the first comprehensive study of parental
control tools on multiple platforms including network devices, Windows
applications, Chrome extensions and Android apps. Our analysis uncovers
pervasive security and privacy issues that can lead to leakage of private
information, and/or allow an adversary to fully control the parental control
solution, and thereby may directly aid cyberbullying and cyber predators.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:06:00 GMT""}]","2020-12-14"
"2012.06503","Julie Rowlett","Julie Rowlett","On the spectral theory and dynamics of asymptotically hyperbolic
  manifolds","This is a preliminary version of the article published in Annales de
  l'Institut Fourier. The final version is freely available online!","Ann. de l'Institut Fourier, vol. 60, no. 7, (2010), 2461 - 2492","10.5802/aif.2615",,"math.SP math-ph math.DG math.DS math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a brief survey of the spectral theory and dynamics of infinite
volume asymptotically hyperbolic manifolds. Beginning with their geometry and
examples, we proceed to their spectral and scattering theories, dynamics, and
the physical description of their quantum and classical mechanics. We conclude
with a discussion of recent results, ideas, and conjectures.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:10:50 GMT""}]","2020-12-14"
"2012.06504","Roberto Taverna","Roberto Taverna, Lorenzo Marra, Stefano Bianchi, Mi\v{c}hal Dovciak,
  Ren\'e Goosmann, Frederic Marin, Giorgio Matt and Wenda Zhang","Spectral and polarization properties of black hole accretion disc
  emission: including absorption effects","13 pages, 9 figures, accepted for publication in MNRAS",,"10.1093/mnras/staa3859",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of radiation emitted from black hole accretion discs represents a
crucial way to understand the main physical properties of these sources, and in
particular the black hole spin. Beside spectral analysis, polarimetry is
becoming more and more important, motivated by the development of new
techniques which will soon allow to perform measurements also in the X- and
{\gamma}-rays. Photons emitted from black hole accretion discs in the soft
state are indeed expected to be polarized, with an energy dependence which can
provide an estimate of the black hole spin. Calculations performed so far,
however, considered scattering as the only process to determine the
polarization state of the emitted radiation, implicitly assuming that the
temperatures involved are such that material in the disc is entirely ionized.
In this work we generalize the problem by calculating the ionization structure
of a surface layer of the disc with the public code CLOUDY , and then by
determining the polarization properties of the emerging radiation using the
Monte Carlo code STOKES . This allows us to account for absorption effects
alongside scattering ones. We show that including absorption can deeply modify
the polarization properties of the emerging radiation with respect to what is
obtained in the pure-scattering limit. As a general rule, we find that the
polarization degree is larger when absorption is more important, which occurs
e.g. for low accretion rates and/or spins when the ionization of the matter in
the innermost accretion disc regions is far from complete.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:14:37 GMT""}]","2020-12-23"
"2012.06505","Angelo Russomanno","Angelo Russomanno, Michele Fava, and Markus Heyl","Quantum chaos and ensemble inequivalence of quantum long-range Ising
  chains","17 pages, 15 figures","Phys. Rev. B 104, 094309 (2021)","10.1103/PhysRevB.104.094309",,"cond-mat.stat-mech cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use large-scale exact diagonalization to study the quantum Ising chain in
a transverse field with long-range power-law interactions decaying with
exponent $\alpha$. We numerically study various probes for quantum chaos and
eigenstate thermalization {on} the level of eigenvalues and eigenstates. The
level-spacing statistics yields a clear sign towards a Wigner-Dyson
distribution and therefore towards quantum chaos across all values of
$\alpha>0$. Yet, for $\alpha<1$ we find that the microcanonical entropy is
nonconvex. This is due to the fact that the spectrum is organized in
energetically separated multiplets for $\alpha<1$. While quantum chaotic
behaviour develops within the individual multiplets, many multiplets don't
overlap and don't mix with each other, as we analytically and numerically
argue. Our findings suggest that a small fraction of the multiplets could
persist at low energies for $\alpha\ll 1$ even for large $N$, giving rise to
ensemble inequivalence.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:16:56 GMT""},{""version"":""v2"",""created"":""Mon, 2 Aug 2021 15:23:18 GMT""},{""version"":""v3"",""created"":""Wed, 29 Sep 2021 16:25:41 GMT""}]","2021-10-04"
"2012.06506","Mike Papadakis","Ahmed Khanfir, Anil Koyuncu, Mike Papadakis, Maxime Cordy, Tegawend\'e
  F. Bissyand\'e, Jacques Klein, Yves Le Traon","IBIR: Bug Report driven Fault Injection",,,"10.1145/3542946",,"cs.SE","http://creativecommons.org/licenses/by-sa/4.0/","  Much research on software engineering and software testing relies on
experimental studies based on fault injection. Fault injection, however, is not
often relevant to emulate real-world software faults since it ""blindly"" injects
large numbers of faults. It remains indeed challenging to inject few but
realistic faults that target a particular functionality in a program. In this
work, we introduce IBIR, a fault injection tool that addresses this challenge
by exploring change patterns associated to user-reported faults. To inject
realistic faults, we create mutants by retargeting a bug report driven
automated program repair system, i.e., reversing its code transformation
templates. IBIR is further appealing in practice since it requires deep
knowledge of neither of the code nor the tests, but just of the program's
relevant bug reports. Thus, our approach focuses the fault injection on the
feature targeted by the bug report. We assess IBIR by considering the Defects4J
dataset. Experimental results show that our approach outperforms the fault
injection performed by traditional mutation testing in terms of semantic
similarity with the original bug, when applied at either system or class levels
of granularity, and provides better, statistically significant, estimations of
test effectiveness (fault detection). Additionally, when injecting 100 faults,
IBIR injects faults that couple with the real ones in 36% of the cases, while
mutants from mutation testing inject less than 1%. Overall, IBIR targets real
functionality and injects realistic and diverse faults.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:19:18 GMT""}]","2022-08-15"
"2012.06507","Csaba Bir\'o","Csaba Bir\'o, Sida Wan","Ramsey properties of products of chains",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathbf{k}$ denote the totally ordered set (or chain) on $k$ elements.
The product $\mathbf{k}^t=\mathbf{k}\times\cdots\times\mathbf{k}$ is a poset
called a grid. This paper discusses several loosely related results on the
Ramsey theory of grids. Most of the results involve some application of the
Product Ramsey Theorem.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:21:03 GMT""},{""version"":""v2"",""created"":""Fri, 3 Dec 2021 05:03:16 GMT""},{""version"":""v3"",""created"":""Tue, 24 May 2022 20:49:16 GMT""},{""version"":""v4"",""created"":""Tue, 28 Jun 2022 20:11:26 GMT""}]","2022-06-30"
"2012.06508","Charles Corbi\`ere","Charles Corbi\`ere, Nicolas Thome, Antoine Saporta, Tuan-Hung Vu,
  Matthieu Cord, Patrick P\'erez","Confidence Estimation via Auxiliary Models","Accepted to TPAMI 2021",,,,"cs.CV cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Reliably quantifying the confidence of deep neural classifiers is a
challenging yet fundamental requirement for deploying such models in
safety-critical applications. In this paper, we introduce a novel target
criterion for model confidence, namely the true class probability (TCP). We
show that TCP offers better properties for confidence estimation than standard
maximum class probability (MCP). Since the true class is by essence unknown at
test time, we propose to learn TCP criterion from data with an auxiliary model,
introducing a specific learning scheme adapted to this context. We evaluate our
approach on the task of failure prediction and of self-training with
pseudo-labels for domain adaptation, which both necessitate effective
confidence estimates. Extensive experiments are conducted for validating the
relevance of the proposed approach in each task. We study various network
architectures and experiment with small and large datasets for image
classification and semantic segmentation. In every tested benchmark, our
approach outperforms strong baselines.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:21:12 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 17:24:34 GMT""}]","2021-06-01"
"2012.06509","Nathan Drenkow","Nathan Drenkow, Philippe Burlina, Neil Fendley, Onyekachi Odoemene,
  Jared Markowitz","Addressing Visual Search in Open and Closed Set Settings",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Searching for small objects in large images is a task that is both
challenging for current deep learning systems and important in numerous
real-world applications, such as remote sensing and medical imaging. Thorough
scanning of very large images is computationally expensive, particularly at
resolutions sufficient to capture small objects. The smaller an object of
interest, the more likely it is to be obscured by clutter or otherwise deemed
insignificant. We examine these issues in the context of two complementary
problems: closed-set object detection and open-set target search. First, we
present a method for predicting pixel-level objectness from a low resolution
gist image, which we then use to select regions for performing object detection
locally at high resolution. This approach has the benefit of not being fixed to
a predetermined grid, thereby requiring fewer costly high-resolution glimpses
than existing methods. Second, we propose a novel strategy for open-set visual
search that seeks to find all instances of a target class which may be
previously unseen and is defined by a single image. We interpret both detection
problems through a probabilistic, Bayesian lens, whereby the objectness maps
produced by our method serve as priors in a maximum-a-posteriori approach to
the detection step. We evaluate the end-to-end performance of both the
combination of our patch selection strategy with this target search approach
and the combination of our patch selection strategy with standard object
detection methods. Both elements of our approach are seen to significantly
outperform baseline strategies.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:21:28 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 21:43:19 GMT""}]","2021-04-16"
"2012.06510","David Kopriva","David A. Kopriva and Gregor J. Gassner","A Split-Form, Stable CG/DG-SEM for Wave Propagation Modeled by Linear
  Hyperbolic Systems",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a hybrid continuous and discontinuous Galerkin spectral element
approximation that leverages the advantages of each approach. The continuous
Galerkin approximation is used on interior element faces where the equation
properties are continuous. A discontinuous Galerkin approximation is used at
physical boundaries and if there is a jump in properties at a face. The
approximation uses a split form of the equations and two-point fluxes to ensure
stability for unstructured quadrilateral/hexahedral meshes with curved
elements. The approximation is also conservative and constant state preserving
on such meshes. Spectral accuracy is obtained for all examples, which include
wave scattering at a discontinuous medium boundary.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:24:41 GMT""}]","2020-12-14"
"2012.06511","Donghwan Shin","Fitash Ul Haq, Donghwan Shin, Lionel C. Briand, Thomas Stifter, Jun
  Wang","Automatic Test Suite Generation for Key-Points Detection DNNs using
  Many-Objective Search (Experience Paper)","to appear in ISSTA 2021",,"10.1145/3460319.3464802",,"cs.CV cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatically detecting the positions of key-points (e.g., facial key-points
or finger key-points) in an image is an essential problem in many applications,
such as driver's gaze detection and drowsiness detection in automated driving
systems. With the recent advances of Deep Neural Networks (DNNs), Key-Points
detection DNNs (KP-DNNs) have been increasingly employed for that purpose.
Nevertheless, KP-DNN testing and validation have remained a challenging problem
because KP-DNNs predict many independent key-points at the same time -- where
each individual key-point may be critical in the targeted application -- and
images can vary a great deal according to many factors.
  In this paper, we present an approach to automatically generate test data for
KP-DNNs using many-objective search. In our experiments, focused on facial
key-points detection DNNs developed for an industrial automotive application,
we show that our approach can generate test suites to severely mispredict, on
average, more than 93% of all key-points. In comparison, random search-based
test data generation can only severely mispredict 41% of them. Many of these
mispredictions, however, are not avoidable and should not therefore be
considered failures. We also empirically compare state-of-the-art,
many-objective search algorithms and their variants, tailored for test suite
generation. Furthermore, we investigate and demonstrate how to learn specific
conditions, based on image characteristics (e.g., head posture and skin color),
that lead to severe mispredictions. Such conditions serve as a basis for risk
analysis or DNN retraining.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:28:03 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 17:11:38 GMT""}]","2021-05-26"
"2012.06512","Baptiste Louf","Baptiste Louf","Planarity and non-separating cycles in uniform high genus
  quadrangulations","21 pages, 15 figures (v2 fixes many issues with the original proofs
  of section 6)",,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study large uniform random quadrangulations whose genus grow linearly with
the number of faces, whose local convergence was recently established by
Budzinski and the author arXiv:1902.00492,arXiv:2012.05813. Here we study
several properties of these objects which are not captured by the local
topology. Namely we show that balls around the root are planar whp up to
logarithmic radius, and we prove that there exists short non-contractible
cycles with positive probability.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:33:04 GMT""},{""version"":""v2"",""created"":""Tue, 4 Oct 2022 19:42:43 GMT""}]","2022-10-06"
"2012.06513","Bonny Banerjee","Bonny Banerjee","String Tightening as a Self-Organizing Phenomenon: Computation of
  Shortest Homotopic Path, Smooth Path, and Convex Hull",,"in IEEE Transactions on Neural Networks, vol. 18, no. 5, pp.
  1463-1471, Sept. 2007","10.1109/TNN.2007.891192",,"cs.AI cs.CG cs.LG cs.RO","http://creativecommons.org/licenses/by/4.0/","  The phenomenon of self-organization has been of special interest to the
neural network community for decades. In this paper, we study a variant of the
Self-Organizing Map (SOM) that models the phenomenon of self-organization of
the particles forming a string when the string is tightened from one or both
ends. The proposed variant, called the String Tightening Self-Organizing Neural
Network (STON), can be used to solve certain practical problems, such as
computation of shortest homotopic paths, smoothing paths to avoid sharp turns,
and computation of convex hull. These problems are of considerable interest in
computational geometry, robotics path planning, AI (diagrammatic reasoning),
VLSI routing, and geographical information systems. Given a set of obstacles
and a string with two fixed terminal points in a two dimensional space, the
STON model continuously tightens the given string until the unique shortest
configuration in terms of the Euclidean metric is reached. The STON minimizes
the total length of a string on convergence by dynamically creating and
selecting feature vectors in a competitive manner. Proof of correctness of this
anytime algorithm and experimental results obtained by its deployment are
presented in the paper.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:33:11 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 01:56:47 GMT""}]","2021-02-17"
"2012.06514","Anton Rebhan","Josef Leutgeb, Anton Rebhan","Axial vector transition form factors in holographic QCD and their
  contribution to the muon $g-2$","6 pages, 3 figures, 2 tables. Proceedings contribution for the 40th
  International Conference on High Energy physics - ICHEP2020, July 28 - August
  6, 2020, Prague, Czech Republic (virtual meeting)",,,,"hep-ph hep-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Whereas the theoretical results for the dominant contributions to hadronic
light-by-light scattering coming from pseudoscalar meson exchange have
converged over the past years, the various published estimates of the
contribution due to axial vector meson exchange differ wildly. Since
holographic AdS/QCD models have proved to provide rather good models of singly
and doubly virtual pion transition form factors, which reproduce remarkably
well the known low-energy data and also the asymptotic leading-order pQCD
behavior, it is of interest to consider their predictions for axial vector
transition form factors. Indeed, we find that these reproduce also very well
existing data from the L3 experiment for $f_1\to\gamma\gamma^*$. Including the
full infinite tower of axial vector mesons of the AdS/QCD models we moreover
show that the Melnikov-Vainshtein short-distance constraint can be satisfied,
while almost all existing models for hadronic light-by-light scattering fail to
incorporate it. The contribution to $g-2$, which is dominated by the first few
resonances, turns out to be significantly larger than estimated previously.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:33:19 GMT""}]","2020-12-14"
"2012.06515","Taekyun Kim","Taekyun Kim, Dae San Kim, Jongkyum Kwon, Hyunseok Lee","Representations of degenerate poly-Bernoulli polynomials","11 pages",,,,"math.NT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  As is well-known, poly-Bernoulli polynomials are defined in terms of
polylogarithm functions. Recently, as degenerate version of such functions and
polynomials, degenerate polylogarithm functions were introduced and degenertae
poly-Bernoulli polynomials were defined by means of the degenerate
polylogarithm functions, and some their properties were investigated. The aim
of this paper is to furthur study some properties of the degenertae
poly-Bernoulli polynomials by using three formulas coming from the recently
developed lambda-umbral calculus. In more detail, among other things, we
represent the degenerate poly-Bernoulli polynomials by higher-order degenertae
Bernoulli polynomials and by higher-order degenerate derangements polynomials.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:34:33 GMT""}]","2020-12-14"
"2012.06516","Hamid Sarmadi","Hamid Sarmadi, Rafael Mu\~noz-Salinas, Miguel A. Olivares-Mendez,
  Rafael Medina-Carnicer","Detection of Binary Square Fiducial Markers Using an Event Camera","An error in the abstract of the IEEE Access version has been
  corrected in this version. Link to the IEEE Access paper:
  https://doi.org/10.1109/ACCESS.2021.3058423",,"10.1109/ACCESS.2021.3058423",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Event cameras are a new type of image sensors that output changes in light
intensity (events) instead of absolute intensity values. They have a very high
temporal resolution and a high dynamic range. In this paper, we propose a
method to detect and decode binary square markers using an event camera. We
detect the edges of the markers by detecting line segments in an image created
from events in the current packet. The line segments are combined to form
marker candidates. The bit value of marker cells is decoded using the events on
their borders. To the best of our knowledge, no other approach exists for
detecting square binary markers directly from an event camera using only the
CPU unit in real-time. Experimental results show that the performance of our
proposal is much superior to the one from the RGB ArUco marker detector. The
proposed method can achieve the real-time performance on a single CPU thread.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:34:47 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 13:53:49 GMT""},{""version"":""v3"",""created"":""Mon, 15 Mar 2021 21:23:51 GMT""}]","2021-03-23"
"2012.06517","Michele  Ciavarella","M.Ciavarella","Improved Muller approximate solution of the pull-off of a sphere from a
  viscoelastic substrate","10 pages; 5 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The detachment of a sphere from a viscoelastic substrate is clearly a
fundamental problem. In the case viscoelastic dissipation is concentrated at
the contact edge, and the work of adhesion follows a quite popular simplified
model, Muller has suggested an approximate solution, which however is based on
an empirical observation. We revisit Muller's solution and show it leads to
very poor fitting of the actual full numerical results, particularly for the
radius of contact at pull-off, and we suggest an improved fitting of the
pull-off which works extremely well over a very wide range of withdrawing
speeds, and correctly converges to the JKR value at very low speeds.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:35:15 GMT""}]","2020-12-14"
"2012.06518","Julie Rowlett","Julie Rowlett","La g\'eom\'etrie de Bakry-\'Emery et l'\'ecart fondamental","in French. This is a preliminary version of the published article of
  the same title, freely available online!","S\'eminaire de th\'eorie spectrale et g\'eom\'etrie, Tome 28
  (2009-2010) , pp. 147-157","10.5802/tsg.282",,"math.SP math.AP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article is a brief presentation of results surrounding the fundamental
gap. We begin by recalling Bakry-Emery geometry and demonstrate connections
between eigenvalues of the Laplacian with the Dirichlet and Neumann boundary
conditions. We then show a connection between the fundamental gap and
Bakry-Emery geometry, concluding with a presentation of the key ideas in
Andrews's and Clutterbuck's proof of the fundamental gap conjecture. We
conclude with a presentation of results for the fundamental gap of triangles
and simplices.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:35:40 GMT""}]","2020-12-14"
"2012.06519","Tongyang Li","Tongyang Li, Chunhao Wang, Shouvanik Chakrabarti, and Xiaodi Wu","Sublinear classical and quantum algorithms for general matrix games","16 pages, 2 figures. To appear in the Thirty-Fifth AAAI Conference on
  Artificial Intelligence (AAAI 2021)",,,,"quant-ph cs.DS cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate sublinear classical and quantum algorithms for matrix games, a
fundamental problem in optimization and machine learning, with provable
guarantees. Given a matrix $A\in\mathbb{R}^{n\times d}$, sublinear algorithms
for the matrix game $\min_{x\in\mathcal{X}}\max_{y\in\mathcal{Y}} y^{\top} Ax$
were previously known only for two special cases: (1) $\mathcal{Y}$ being the
$\ell_{1}$-norm unit ball, and (2) $\mathcal{X}$ being either the $\ell_{1}$-
or the $\ell_{2}$-norm unit ball. We give a sublinear classical algorithm that
can interpolate smoothly between these two cases: for any fixed $q\in (1,2]$,
we solve the matrix game where $\mathcal{X}$ is a $\ell_{q}$-norm unit ball
within additive error $\epsilon$ in time $\tilde{O}((n+d)/{\epsilon^{2}})$. We
also provide a corresponding sublinear quantum algorithm that solves the same
task in time $\tilde{O}((\sqrt{n}+\sqrt{d})\textrm{poly}(1/\epsilon))$ with a
quadratic improvement in both $n$ and $d$. Both our classical and quantum
algorithms are optimal in the dimension parameters $n$ and $d$ up to
poly-logarithmic factors. Finally, we propose sublinear classical and quantum
algorithms for the approximate Carath\'eodory problem and the $\ell_{q}$-margin
support vector machines as applications.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:36:33 GMT""}]","2020-12-14"
"2012.06520","Tom Steele","Amir H. Fariborz, J. Ho, T.G. Steele","Universal Scale Factors: A Bridge Between Chiral Lagrangians and QCD
  Sum-Rules","5 pages. Proceedings article for QCD20: 23rd International Conference
  in Quantum Chromodynamics",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chiral Lagrangian mesonic fields can be connected to QCD quark operators via
matrix operators containing scale factors. These scale factor matrices are
shown to be constrained by chiral symmetry, resulting in a universal scale
factor for each Chiral Lagrangian nonet. QCD sum-rules, combined with mixing
angles from Chiral Lagrangian analyses, are used to determine the scale factors
for the $a_0$ isotriplet and $K_0^*$ isodoublet scalar mesons. The resulting
scale factors verify the universality property, providing a validation of the
scale factor matrices connecting Chiral Lagrangian mesonic fields and quark
operators.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:36:56 GMT""}]","2020-12-14"
"2012.06521","Taj Dyson","T. Dyson, H. C. Chiang, E. Egan, N. Ghazi, T. Menard, R. A. Monsalve,
  T. Moso, J. Peterson, J. L. Sievers, S. Tartakovsky","Radio-Frequency Interference at the McGill Arctic Research Station","7 pages, 4 figures, submitted to the Journal of Astronomical
  Instrumentation",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The frequencies of interest for redshifted 21 cm observations are heavily
affected by terrestrial radio-frequency interference (RFI). We identify the
McGill Arctic Research Station (MARS) as a new RFI-quiet site and report its
RFI occupancy using 122 hours of data taken with a prototype antenna station
developed for the Array of Long-Baseline Antennas for Taking Radio Observations
from the Sub-Antarctic. Using an RFI flagging process tailored to the MARS
data, we find an overall RFI occupancy of 1.8% averaged over 20-125 MHz. In
particular, the FM broadcast band (88-108 MHz) is found to have an RFI
occupancy of at most 1.6%. The data were taken during the Arctic summer, when
degraded ionospheric conditions and an active research base contributed to
increased RFI. The results quoted here therefore represent the maximum-level
RFI environment at MARS.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:38:04 GMT""}]","2020-12-14"
"2012.06522","Supratim Shit","Rachit Chhaya, Jayesh Choudhari, Anirban Dasgupta, Supratim Shit","Online Coresets for Clustering with Bregman Divergences","Work in Progress",,,,"cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present algorithms that create coresets in an online setting for
clustering problems according to a wide subset of Bregman divergences. Notably,
our coresets have a small additive error, similar in magnitude to the
lightweight coresets Bachem et. al. 2018, and take update time $O(d)$ for every
incoming point where $d$ is dimension of the point. Our first algorithm gives
online coresets of size $\tilde{O}(\mbox{poly}(k,d,\epsilon,\mu))$ for
$k$-clusterings according to any $\mu$-similar Bregman divergence. We further
extend this algorithm to show existence of a non-parametric coresets, where the
coreset size is independent of $k$, the number of clusters, for the same
subclass of Bregman divergences. Our non-parametric coresets are larger by a
factor of $O(\log n)$ ($n$ is number of points) and have similar (small)
additive guarantee. At the same time our coresets also function as lightweight
coresets for non-parametric versions of the Bregman clustering like DP-Means.
While these coresets provide additive error guarantees, they are also
significantly smaller (scaling with $O(\log n)$ as opposed to $O(d^d)$ for
points in $\~R^d$) than the (relative-error) coresets obtained in Bachem et.
al. 2015 for DP-Means. While our non-parametric coresets are existential, we
give an algorithmic version under certain assumptions.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:39:21 GMT""}]","2020-12-14"
"2012.06523","Jan Kronenberger H","Jan Kronenberger and Anselm Haselhoff","Dependency Decomposition and a Reject Option for Explainable Models","Accepted at CVPR 2019 Workshop ""DThree19: Dependable Deep Detectors""",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deploying machine learning models in safety-related do-mains (e.g. autonomous
driving, medical diagnosis) demands for approaches that are explainable, robust
against adversarial attacks and aware of the model uncertainty. Recent deep
learning models perform extremely well in various inference tasks, but the
black-box nature of these approaches leads to a weakness regarding the three
requirements mentioned above. Recent advances offer methods to visualize
features, describe attribution of the input (e.g.heatmaps), provide textual
explanations or reduce dimensionality. However,are explanations for
classification tasks dependent or are they independent of each other? For
in-stance, is the shape of an object dependent on the color? What is the effect
of using the predicted class for generating explanations and vice versa? In the
context of explainable deep learning models, we present the first analysis of
dependencies regarding the probability distribution over the desired image
classification outputs and the explaining variables (e.g. attributes, texts,
heatmaps). Therefore, we perform an Explanation Dependency Decomposition (EDD).
We analyze the implications of the different dependencies and propose two ways
of generating the explanation. Finally, we use the explanation to verify
(accept or reject) the prediction
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:39:33 GMT""}]","2020-12-14"
"2012.06524","Emmanuil Saridakis","Fotios K. Anagnostopoulos, Spyros Basilakos, Emmanuel N. Saridakis","Observational constraints on Myrzakulov gravity","24 pages, 6 figures, 2 Tables, version published in Phys.Rev.D","Phys. Rev. D 103, 104013 (2021)","10.1103/PhysRevD.103.104013",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use data from Supernovae (SNIa) Pantheon sample, from Baryonic Acoustic
Oscillations (BAO), and from cosmic chronometers measurements of the Hubble
parameter (CC), alongside arguments from Big Bang Nucleosynthesis (BBN), in
order to extract constraints on Myrzakulov $F(R,T)$ gravity. This is a
connection-based theory belonging to the Riemann-Cartan subclass, that uses a
specific but non-special connection, which then leads to extra degrees of
freedom. Our analysis shows that both considered models lead to $\sim 1 \sigma$
compatibility in all cases. For the involved dimensionless parameter we find
that it is constrained to an interval around zero, however the corresponding
contours are slightly shifted towards positive values. Furthermore, we use the
obtained parameter chains so to reconstruct the corresponding Hubble function,
as well as the dark-energy equation-of-state parameter, as a function of
redshift. As we show, Model 1 is very close to $\Lambda$CDM scenario, while
Model 2 resembles it at low redshifts, however at earlier times deviations are
allowed. Finally, applying the AIC, BIC and the combined DIC criteria, we
deduce that both models present a very efficient fitting behavior, and are
statistically equivalent with $\Lambda$CDM cosmology, despite the fact that
Model 2 does not contain the latter as a limit.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:40:52 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 07:30:13 GMT""}]","2021-05-19"
"2012.06525","Adriano Cerqueira","Adriano Cerqueira, Bertrand Lefloch, Alejandro Esquivel, Pedro
  Rivera-Ortiz, Claudio Codella, Cecilia Ceccarelli and Linda Podio","H$_2$ mass-velocity relationship from 3D numerical simulations of
  jet-driven molecular outflows","15 pages, 11 figures. Accepted for publication in A&A. The abstract
  has been abridged due to the limitations on arXiv. The title has been
  corrected","A&A 645, A135 (2021)","10.1051/0004-6361/202039269",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Previous numerical studies have shown that in protostellar outflows, the
mass-velocity distribution $m(v)$ can be well described by a broken power law
$\propto v^{- \gamma}$. On the other hand, recent observations of a sample of
outflows show that the CO intensity-velocity distribution, closely related to
$m(v)$, follows an exponential law $\propto \exp(-v/v_0)$. In the present work,
we revisit the physical origin of the mass-velocity relationship $m(v)$ in
jet-driven protostellar outflows. We investigate the respective contributions
of the different regions of the outflow, from the swept-up ambient gas to the
jet. We performed 3D numerical simulations of a protostellar jet propagating
into a molecular cloud using the hydrodynamical code Yguazu-a. The code takes
into account atomic and ionic species and was modified to include the H$_2$
gas. We find that by excluding the jet contribution, $m(v)$ is satisfyingly
fitted with a single exponential law, with $v_0$ well in the range of
observational values. The jet contribution results in additional components in
the mass-velocity relationship. This empirical mass-velocity relationship is
found to be valid locally in the outflow. The exponent $v_0$ is almost constant
in time and for a given level of mixing between the ambient medium and the jet
material. In general, $v_0$ displays only a weak spatial dependence. A simple
modeling of the L1157 outflow successfully reproduces the various components of
the observed CO intensity-velocity relationship. Our simulations indicate that
these components trace the outflow cavity of swept-up gas and the material
entrained along the jet, respectively. The CO intensity-velocity exponential
law is naturally explained by the jet-driven outflow model. The entrained
material plays an important role in shaping the mass-velocity profile.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:43:47 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 11:09:27 GMT""}]","2021-02-03"
"2012.06526","Jakob Hartig","Jakob Hartig, Benedict Depp, Manuel Rexer, Peter F. Pelz","Effects of Unsteady Heat Transfer on Behaviour of Commercial
  Hydro-Pneumatic Accumulators","23 pages, 10 figures",,,,"physics.flu-dyn cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Hydraulic accumulators play a central role as energy storage in nearly all
fluid power systems. The accumulators serve as pulsation dampers or energy
storage devices in hydro-pneumatic suspensions. The energy carrying gas is
compressed and decompressed, often periodically. Heat transfer to the outside
significantly determines the transfer behaviour of the accumulator since heat
transfer changes the thermodynamic state of the enclosed gas. The accumulators
operating mode ranges from isothermal to adiabatic. Simulating fluid power
systems adequately requires knowledge of the transfer behaviour of the
accumulators and therefore of the heat transfer. The Engineer's approach to
model heat transfer in technical system is Newton's law. However, research
shows, that in harmonically oscillating gas volumes, heat flux and bulk
temperature difference change their phase. Newton's law is incapable of
representing this physical phenomenon. We performed measurements on two sizes
of commercial membrane accumulators. Experimental data confirm the failure of
Newton's approach. Instead the heat transfer can be modelled with an additional
rate dependent term and independently of the accumulator's size. Correlation
equations for the heat transfer and the correct accumulator transfer behaviour
are given.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:48:12 GMT""}]","2020-12-14"
"2012.06527","Ettore Segreto","Ettore Segreto","Properties of Liquid Argon Scintillation Light Emission",,"Phys. Rev. D 103, 043001 (2021)","10.1103/PhysRevD.103.043001",,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Liquid argon is used as active medium in a variety of neutrino and Dark
Matter experiments thanks to its excellent properties of charge yield and
transport and as a scintillator. Liquid argon scintillation photons are emitted
in a narrow band of 10~nm centered around 127 nm and with a characteristic time
profile made by two components originated by the decay of the lowest lying
singlet and triplet state of the excimer Ar$_2^*$ to the dissociative ground
state. A model is proposed which takes into account the quenching of the long
lived triplet states through the self-interaction with other triplet states or
through the interaction with molecular Ar$_2^+$ ions. The model predicts the
time profile of the scintillation signals and its dependence on the intensity
of an external electric field and on the density of deposited energy, if the
relative abundance of the unquenched fast and slow components is know. The
model successfully explains the experimentally observed dependence of the
characteristic time of the slow component on the intensity of the applied
electric field and the increase of photon yield of liquid argon when doped with
small quantities of xenon (at the ppm level). The model also predicts the
dependence of the pulse shape parameter, F$_{prompt}$, for electron and nuclear
recoils on the recoil energy and the behavior of the relative light yield of
nuclear recoils in liquid argon, $\mathcal{L}_{eff}$
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:50:08 GMT""}]","2021-02-10"
"2012.06528","Alberto Marchesi","Alberto Marchesi, Nicola Gatti","Trembling-Hand Perfection and Correlation in Sequential Games",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We initiate the study of trembling-hand perfection in sequential (i.e.,
extensive-form) games with correlation. We introduce the extensive-form perfect
correlated equilibrium (EFPCE) as a refinement of the classical extensive-form
correlated equilibrium (EFCE) that amends its weaknesses off the equilibrium
path. This is achieved by accounting for the possibility that players may make
mistakes while following recommendations independently at each information set
of the game. After providing an axiomatic definition of EFPCE, we show that one
always exists since any perfect (Nash) equilibrium constitutes an EFPCE, and
that it is a refinement of EFCE, as any EFPCE is also an EFCE. Then, we prove
that, surprisingly, computing an EFPCE is not harder than finding an EFCE,
since the problem can be solved in polynomial time for general n-player
extensive-form games (also with chance). This is achieved by formulating the
problem as that of finding a limit solution (as $\epsilon \rightarrow 0$) to a
suitably defined trembling LP parametrized by $\epsilon$, featuring
exponentially many variables and polynomially many constraints. To this end, we
show how a recently developed polynomial-time algorithm for trembling LPs can
be adapted to deal with problems having an exponential number of variables.
This calls for the solution of a sequence of (non-trembling) LPs with
exponentially many variables and polynomially many constraints, which is
possible in polynomial time by applying an ellipsoid against hope approach.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:51:20 GMT""}]","2020-12-14"
"2012.06529","Amir Algom","Amir Algom, Federico Rodriguez Hertz, Zhiren Wang","Pointwise normality and Fourier decay for self-conformal measures","V3: Revised according to comments made by the referee and P\'{e}ter
  Varj\'{u}. To appear in Adv. Math",,,,"math.DS math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Phi$ be a $C^{1+\gamma}$ smooth IFS on $\mathbb{R}$, where $\gamma>0$.
We provide mild conditions on the derivative cocycle that ensure that every
self conformal measure is supported on points $x$ that are absolutely normal.
That is, for integer $p\geq 2$ the sequence $\lbrace p^k x \rbrace_{k\in
\mathbb{N}}$ equidistributes modulo $1$. We thus extend several state of the
art results of Hochman and Shmerkin about the prevalence of normal numbers in
fractals. When $\Phi$ is self-similar we show that the set of absolutely normal
numbers has full Hausdorff dimension in its attractor, unless $\Phi$ has an
explicit structure that is associated with some integer $n\geq 2$. These
conditions on the derivative cocycle are also shown to imply that every self
conformal measure is a Rajchman measure, that is, its Fourier transform decays
to $0$ at infinity. When $\Phi$ is self similar and satisfies a certain
Diophantine condition, we establish a logarithmic rate of decay.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:51:38 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 14:19:19 GMT""},{""version"":""v3"",""created"":""Wed, 13 Oct 2021 14:12:21 GMT""}]","2021-10-14"
"2012.06530","Tom Hirschowitz","Andr\'e Hirschowitz, Tom Hirschowitz and Ambroise Lafont","Modules over monads and operational semantics (expanded version)",,,,,"cs.PL cs.LO math.CT","http://creativecommons.org/licenses/by/4.0/","  This paper is a contribution to the search for efficient and high-level
mathematical tools to specify and reason about (abstract) programming languages
or calculi. Generalising the reduction monads of Ahrens et al., we introduce
transition monads, thus covering new applications such as
lambda-bar-mu-calculus, pi-calculus, Positive GSOS specifications, differential
lambda-calculus, and the big-step, simply-typed, call-by-value lambda-calculus.
Moreover, we design a suitable notion of signature for transition monads.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:51:50 GMT""},{""version"":""v2"",""created"":""Fri, 18 Feb 2022 08:31:34 GMT""},{""version"":""v3"",""created"":""Wed, 15 Jun 2022 06:23:50 GMT""},{""version"":""v4"",""created"":""Fri, 29 Jul 2022 20:27:55 GMT""}]","2022-08-02"
"2012.06531","Paolo Soda","Paolo Soda, Natascha Claudia D'Amico, Jacopo Tessadori, Giovanni
  Valbusa, Valerio Guarrasi, Chandra Bortolotto, Muhammad Usman Akbar, Rosa
  Sicilia, Ermanno Cordelli, Deborah Fazzini, Michaela Cellina, Giancarlo
  Oliva, Giovanni Callea, Silvia Panella, Maurizio Cariati, Diletta Cozzi,
  Vittorio Miele, Elvira Stellato, Gian Paolo Carrafiello, Giulia Castorani,
  Annalisa Simeone, Lorenzo Preda, Giulio Iannello, Alessio Del Bue, Fabio
  Tedoldi, Marco Al\`i, Diego Sona and Sergio Papa","AIforCOVID: predicting the clinical outcomes in patients with COVID-19
  applying AI to chest-X-rays. An Italian multicentre study",,,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recent epidemiological data report that worldwide more than 53 million people
have been infected by SARS-CoV-2, resulting in 1.3 million deaths. The disease
has been spreading very rapidly and few months after the identification of the
first infected, shortage of hospital resources quickly became a problem. In
this work we investigate whether chest X-ray (CXR) can be used as a possible
tool for the early identification of patients at risk of severe outcome, like
intensive care or death. CXR is a radiological technique that compared to
computed tomography (CT) it is simpler, faster, more widespread and it induces
lower radiation dose. We present a dataset including data collected from 820
patients by six Italian hospitals in spring 2020 during the first COVID-19
emergency. The dataset includes CXR images, several clinical attributes and
clinical outcomes. We investigate the potential of artificial intelligence to
predict the prognosis of such patients, distinguishing between severe and mild
cases, thus offering a baseline reference for other researchers and
practitioners. To this goal, we present three approaches that use features
extracted from CXR images, either handcrafted or automatically by convolutional
neuronal networks, which are then integrated with the clinical data. Exhaustive
evaluation shows promising performance both in 10-fold and leave-one-centre-out
cross-validation, implying that clinical data and images have the potential to
provide useful information for the management of patients and hospital
resources.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:03:08 GMT""}]","2020-12-14"
"2012.06532","Ian Ochs","Ian E. Ochs and Nathaniel J. Fisch","Nonresonant Diffusion in Alpha Channeling","5 pages, 3 figures, plus 4-page supplementary material","Phys. Rev. Lett. 127, 025003 (2021)","10.1103/PhysRevLett.127.025003",,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  The gradient of fusion-born alpha particles that arises in a fusion reactor
can be exploited to amplify waves, which cool the alpha particles while
diffusively extracting them from the reactor. The corresponding extraction of
the resonant alpha particle charge has been suggested as a mechanism to drive
rotation. By deriving a coupled linear-quasilinear theory of alpha channeling,
we show that, for a time-growing wave with a purely poloidal wavevector, a
current in the nonresonant ions cancels the resonant alpha particle current,
preventing the rotation drive but fueling the fusion reaction.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:05:07 GMT""}]","2021-07-14"
"2012.06533","Crist\'obal Gil Canto","Yolanda Cabrera Casado, Crist\'obal Gil Canto, Dolores Mart\'in
  Barquero and C\'andido Mart\'in Gonz\'alez","Simultaneous orthogonalization of inner products over arbitrary fields","15 pages",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give necessary and sufficient conditions for a family of inner products in
a finite-dimensional vector space $V$ over an arbitrary field $\mathbb{K}$ to
have an orthogonal basis relative to all the inner products. Some applications
to evolution algebras are also considered.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:05:12 GMT""}]","2020-12-14"
"2012.06534","Charles Takalana","Charles Mpho Takalana, Paolo Marchegiani, Geoff Beck, Sergio
  Colafrancesco","Simulated differential observations of the Sunyaev-Zel'dovich Effect:
  Probing the Dark Ages and Epoch of Reionization","Accepted Manuscript","Astrophys Space Sci 365:188(2020)","10.1007/s10509-020-03902-6",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents an analytical approach for studying the cosmological 21cm
background signal from the Dark Ages (DA) and subsequent Epoch of Reionization
(EoR). We simulate differential observations of a galaxy cluster to demonstrate
how these epochs can be studied with a specific form of the Sunyaev-Zel'dovich
Effect called the SZE-21cm. This work produces simulated maps of the SZE-21cm
and shows that the SZE-21cm can be extracted from future observations with
low-frequency radio interferometers such as the Hydrogen Epoch of Reionization
Array (HERA) and the Square Kilometre Array (SKA). In order to simulate near
realistic scenarios, we look into cosmic variance noise, incorporate and take
into account the effects of foregrounds, thermal noise, and angular resolution
for our simulated observations. We further extend this exploration by averaging
over a sample of galaxy clusters to mitigate the effects of cosmic variance and
instrumental noise. The impact of point source contamination is also studied.
Lastly, we apply this technique to the results of the EDGES collaboration,
which in 2018 reported an absorption feature of the global 21cm background
signal centred at 78 MHz. The challenges to be addressed in order to achieve
the objectives of this work include errors that arise due to cosmic variation,
instrumental noise and point source contamination. Our approach demonstrates
the potential of the SZE-21cm as an indirect probe for the DA and EoR, and we
conclude that the spectral features of the SZE-21cm from our simulated
observations yield results that are close to prior theoretical predictions and
that the SZE-21cm can be used to test the validity of the EDGES detection.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:11:22 GMT""}]","2020-12-22"
"2012.06543","Peter Nagler","Peter C. Nagler, John E. Sadleir, and Edward J. Wollack","Demonstration of ultra-low noise equivalent power using a longitudinal
  proximity effect transition-edge sensor","11 pages, 3 figures",,,,"astro-ph.IM physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Future far-infrared astronomy missions will need large arrays of detectors
with exceptionally low noise-equivalent power (NEP), with some mission concepts
calling for thousands of detectors with NEPs below a few $\times 10^{-20}$
W/$\sqrt{\mathrm{Hz}}$. Though much progress has been made toward meeting this
goal, such detector systems do not exist today. In this work, we present a
device that offers a compelling path forward: the longitudinal proximity effect
(LoPE) transition-edge sensor (TES). With a chemically-stable and
mechanically-robust architecture, the LoPE TES we designed, fabricated, and
characterized also exhibits unprecedented sensitivity, with a measured
electrical NEP of $8 \times 10^{-22}$ W/$\sqrt{\mathrm{Hz}}$. This represents a
>100x advancement of the state-of-the-art, pushing TES detectors into the
regime where they may be employed the achieve to goals of even the most
ambitious large and cold future space instruments.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:16:47 GMT""}]","2020-12-14"
"2012.06544","Xiangyu Cao","Xiangyu Cao","A statistical mechanism for operator growth","9 pages, 0 figures; v2: accepted version, minor revisions","J. Phys. A: Math. Theor. 54 144001 (2021)","10.1088/1751-8121/abe77c",,"cond-mat.stat-mech hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It was recently conjectured that in generic quantum many-body systems, the
spectral density of local operators has the slowest high-frequency decay as
permitted by locality. We show that the infinite-temperature version of this
""universal operator growth hypothesis"" holds for the quantum Ising spin model
in $d \ge 2$ dimensions, and for the chaotic Ising chain (with longitudinal and
transverse fields) in one dimension. Moreover, the disordered chaotic Ising
chain that exhibits many-body localization can have the same high-frequency
spectral density decay as thermalizing models. Our argument is statistical in
nature, and is based on the observation that the moments of the spectral
density can be written as a sign-problem-free sum over paths of Pauli string
operators.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:17:34 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 09:26:57 GMT""}]","2021-06-11"
"2012.06545","Amartya Bose","Amartya Bose and Salvatore Torquato","Quantum Phase Transitions in Long-Range Interacting Hyperuniform Spin
  Chains in a Transverse Field","SM was missing in the previous version. Added here","Phys. Rev. B 103, 014118 (2021)","10.1103/PhysRevB.103.014118",,"quant-ph cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hyperuniform states of matter are characterized by anomalous suppression of
long-wavelength density fluctuations. While most of interesting cases of
disordered hyperuniformity are provided by complex many-body systems like
liquids or amorphous solids, classical spin chains with certain long-range
interactions have been shown to demonstrate the same phenomenon. It is
well-known that the transverse field Ising model shows a quantum phase
transition (QPT) at zero temperature. Under the quantum effects of a transverse
magnetic field, classical hyperuniform spin chains are expected to lose their
hyperuniformity. High-precision simulations of these cases are complicated
because of the presence of highly nontrivial long-range interactions. We
perform extensive analysis of these systems using density matrix
renormalization group to study the possibilities of phase transitions and the
mechanism by which they lose hyperuniformity. We discover first-order QPTs in
the hyperuniform spin chains. An interesting feature of the phase transitions
in these disordered hyperuniform spin chains is that, depending on the
parameter values, the presence of transverse magnetic field may remarkably lead
to increase in the order of the ground state as measured by the ""$\tau$ order
metric,"" even if hyperuniformity is lost. Therefore, it would be possible to
design materials to target specific novel quantum behaviors in the presence of
a transverse magnetic field. Our numerical investigations suggest that these
spin chains can show no more than two QPTs. We further analyze the long-range
interacting spin chains via the Jordan-Wigner mapping, showing that under the
pairwise interacting approximation and a mean-field treatment, there can be at
most two QPTs. Based on these numerical and theoretical explorations, we
conjecture that these spin chains can show a maximum of two QPTs at zero
temperature.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:21:50 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 17:45:58 GMT""}]","2021-02-03"
"2012.06546","Juergen Volz","Michael Scheucher, J\""urgen Volz, Arno Rauschenbeutel","Cavity quantum electrodynamics and chiral quantum optics","21 pages, 15 figures","Ultra-High-Q Optical Microcavities, World Scientific (2020)","10.1142/8964",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cavity quantum electrodynamics (CQED) investigates the interaction between
light confined in a resonator and particles, such as atoms. In recent years,
CQED experiments have reached the optical domain resulting in many interesting
applications in the realm of quantum information processing. For many of these
application it is necessary to overcome limitations imposed by photon loss. In
this context whispering-gallery mode (WGM) resonators have obtained significant
interest. Besides their small mode volume and their ultra high quality, they
also exhibit favorable polarization properties that give rise to chiral
light--matter interaction. In this chapter, we will discuss the origin and the
consequences of these chiral features and we review recent achievements in this
area.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:22:33 GMT""}]","2020-12-14"
"2012.06547","Akshay Gadi Patil","Akshay Gadi Patil, Manyi Li, Matthew Fisher, Manolis Savva, Hao Zhang","LayoutGMN: Neural Graph Matching for Structural Layout Similarity",,,,,"cs.CV cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a deep neural network to predict structural similarity between 2D
layouts by leveraging Graph Matching Networks (GMN). Our network, coined
LayoutGMN, learns the layout metric via neural graph matching, using an
attention-based GMN designed under a triplet network setting. To train our
network, we utilize weak labels obtained by pixel-wise Intersection-over-Union
(IoUs) to define the triplet loss. Importantly, LayoutGMN is built with a
structural bias which can effectively compensate for the lack of structure
awareness in IoUs. We demonstrate this on two prominent forms of layouts, viz.,
floorplans and UI designs, via retrieval experiments on large-scale datasets.
In particular, retrieval results by our network better match human judgement of
structural layout similarity compared to both IoUs and other baselines
including a state-of-the-art method based on graph neural networks and image
convolution. In addition, LayoutGMN is the first deep model to offer both
metric learning of structural layout similarity and structural matching between
layout elements.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:24:18 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 02:58:30 GMT""}]","2021-04-07"
"2012.06548","Stefano De Angelis","Manuel Accettulli Huber, Andreas Brandhuber, Stefano De Angelis,
  Gabriele Travaglini","From amplitudes to gravitational radiation with cubic interactions and
  tidal effects","21 pages","Phys. Rev. D 103, 045015 (2021)","10.1103/PhysRevD.103.045015","QMUL-PH-20-19, SAGEX-20-19-E","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the effect of cubic and tidal interactions on the spectrum of
gravitational waves emitted in the inspiral phase of the merger of two
non-spinning objects. There are two independent parity-even cubic interaction
terms, which we take to be $I_1 = {R^{\alpha \beta}}_{\mu \nu} {R^{\mu
\nu}}_{\rho \sigma} {R^{\rho \sigma}}_{\alpha \beta}$ and $G_3 = I_1-2
R^{\alpha}\,_{\mu}\,^{\beta}\,_{\nu} R^{\mu}\,_{\rho}\,^{\nu}\,_{\sigma}
R^{\rho}\,_{\alpha}\,^{\sigma}\,_{\beta}$. The latter has vanishing pure
graviton amplitudes but modifies mixed scalar/graviton amplitudes which are
crucial for our study. Working in an effective field theory set-up, we compute
the modifications to the quadrupole moment due to $I_1$, $G_3$ and tidal
interactions, from which we obtain the power of gravitational waves radiated in
the process to first order in the perturbations and leading order in the
post-Minkowskian expansion. The $I_1$ predictions are novel, and we find that
our results for $G_3$ are related to the known quadrupole corrections arising
from tidal perturbations, although the physical origin of the $G_3$ coupling is
unrelated to the finite-size effects underlying tidal interactions. We show
this by recomputing such tidal corrections and by presenting an explicit field
redefinition. In the post-Newtonian expansion our results are complete at
leading order, which for the gravitational-wave flux is 5PN for $G_3$ and tidal
interactions, and 6PN for $I_1$. Finally, we compute the corresponding
modifications to the waveforms.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:25:41 GMT""}]","2021-03-03"
"2012.06549","Peter Nagler","Peter C. Nagler, John E. Sadleir, and Edward J. Wollack","Transition-edge sensor detectors for the Origins Space Telescope","43 pages, 8 figures. Accepted for publication by the Journal of
  Astronomical Telescopes, Instruments, and Systems",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Origins Space Telescope is one of four flagship missions under study for
the 2020 Astrophysics Decadal Survey. With a 5.9 m cold (4.5 K) telescope
deployed from space, Origins promises unprecedented sensitivity in the near-,
mid-, and far-infrared, from 2.8 - 588 $\mu$m. This mandates the use of
ultra-sensitive and stable detectors in all of the Origins instruments. At the
present, no known detectors can meet Origins' stability requirements in the
near- to mid-infrared, or its sensitivity requirements in the far-infrared. In
this work, we discuss the applicability of transition-edge sensors, as both
calorimeters and bolometers, to meet these requirements, and lay out a path
toward improving the present state-of-the-art.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:26:20 GMT""}]","2020-12-14"
"2012.06550","Luce Prignano","Bernat Esquirol, Luce Prignano, Albert D\'iaz-Guilera, Emanuele Cozzo","Characterizing Twitter users behaviour during the Spanish Covid-19 first
  wave","working paper",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  People use Online Social Media to make sense of crisis events. A pandemic
crisis like the Covid-19 outbreak is a complex event, involving numerous
aspects of the social life on multiple temporal scales. Focusing on the Spanish
Twittersphere, we characterized users activity behaviour across the different
phases of the Covid-19 first wave.
  Firstly, we analyzed a sample of timelines of different classes of users from
the Spanish Twittersphere in terms of their propensity to produce new
information or to amplify information produced by others. Secondly, by
performing stepwise segmented regression analysis and Bayesian switchpoint
analysis, we looked for a possible behavioral footprint of the crisis in the
statistics of users' activity.
  We observed that generic Spanish Twitter users and journalists experienced an
abrupt increment of their tweeting activity between March 9 and March 14, in
coincidence with control measures being announced by regional and State level
authorities. However, they displayed a stable proportion of retweets before and
after the switching point.
  On the contrary, politicians represented an exception, being the only class
of users not experimenting this abrupt change and following a completely
endogenous dynamics determined by institutional agenda. On the one hand, they
did not increment their overall activity, displaying instead a slight decrease.
On the other hand, in times of crisis, politicians tended to strengthen their
propensity to amplify information rather than produce it.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:28:04 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 17:29:24 GMT""}]","2021-10-01"
"2012.06551","Syksy Rasanen","Daniel G. Figueroa, Sami Raatikainen, Syksy Rasanen and Eemeli Tomberg","Non-Gaussian tail of the curvature perturbation in stochastic
  ultra-slow-roll inflation: implications for primordial black hole production","6 pages, 2 figures. v2: 5+3 pages, 2 figures. Improved analysis and
  text, gathered 400 times more data. Small change in results. Published
  version","Phys. Rev. Lett. 127, 101302 (2021)","10.1103/PhysRevLett.127.101302","HIP-2020-32/TH","astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  We consider quantum diffusion in ultra-slow-roll (USR) inflation. Using the
$\Delta N$ formalism, we present the first stochastic calculation of the
probability distribution $P(\mathcal{R})$ of the curvature perturbation during
USR. We capture the non-linearity of the system, solving the coupled evolution
of the coarse-grained background with random kicks from the short wavelength
modes, simultaneously with the mode evolution around the stochastic background.
This leads to a non-Markovian process from which we determine the highly
non-Gaussian tail of $P(\mathcal{R})$. Studying the production of primordial
black holes in a viable model, we find that stochastic effects during USR
increase their abundance by a factor $\sim 10^5$ compared to the Gaussian
approximation.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:31:46 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 15:49:53 GMT""}]","2021-09-06"
"2012.06552","Brian Fields","C. Tanner Murphey, Jacob W. Hogan, Brian D. Fields, Gautham Narayan","Witnessing History: Rates and Detectability of Naked-Eye Milky-Way
  Supernovae","18 pages, 17 figures. Comments welcome",,"10.1093/mnras/stab2182",,"astro-ph.SR astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Milky Way hosts on average a few supernova explosions per century, yet in
the past millennium only five supernovae have been identified confidently in
the historical record. This deficit of naked-eye supernovae is at least partly
due to dust extinction in the Galactic plane. We explore this effect
quantitatively, developing a formalism for the supernova probability
distribution, accounting for dust and for the observer's flux limit. We then
construct a fiducial axisymmetric model for the supernova and dust densities,
featuring an exponential dependence on galactocentric radius and height, with
core-collapse events in a thin disk and Type Ia events including a thick disk
component. When no flux limit is applied, our model predicts supernovae are
intrinsically concentrated in the Galactic plane, with Type Ia events extending
to higher latitudes reflecting their thick disk component. We then apply a flux
limit and include dust effects, to predict the sky distribution of historical
supernovae. We use well-observed supernovae as light-curve templates, and
introduce naked-eye discovery criteria. The resulting sky distributions are
strikingly inconsistent with the locations of confident historical supernovae,
none of which lie near our model's central peaks. Indeed, SN 1054 lies off the
plane almost exactly in the anticenter, and SN 1181 is in the 2nd Galactic
quadrant. We discuss possible explanations for these discrepancies. We
calculate the percentage of all supernovae bright enough for historical
discovery: $\simeq 13\%$ of core-collapse and $\simeq 33\%$ of Type Ia events.
Using these and the confident historical supernovae, we estimate the intrinsic
Galactic supernova rates, finding general agreement with other methods.
Finally, we urge searches for supernovae in historical records from
civilizations in the southern hemisphere.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:32:09 GMT""}]","2021-09-08"
"2012.06553","Jonathan Grant-Peters","Jonathan Grant-Peters and Raphael Hauser","A seven-point algorithm for piecewise smooth univariate minimization",,,,,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we construct an algorithm for minimising piecewise smooth
functions for which derivative information is not available. The algorithm
constructs a pair of quadratic functions, one on each side of the point with
smallest known function value, and selects the intersection of these quadratics
as the next test point. This algorithm relies on the quadratic function
underestimating the true function within a specific range, which is
accomplished using a adjustment term that is modified as the algorithm
progresses.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:32:49 GMT""}]","2020-12-14"
"2012.06554","Do Le Quoc","Robert Krahn and Donald Dragoti and Franz Gregor and Do Le Quoc and
  Valerio Schiavoni and Pascal Felber and Clenimar Souza and Andrey Brito and
  Christof Fetzer","TEEMon: A continuous performance monitoring framework for TEEs",,,,,"cs.CR cs.DC cs.PF","http://creativecommons.org/licenses/by/4.0/","  Trusted Execution Environments (TEEs), such as Intel Software Guard
eXtensions (SGX), are considered as a promising approach to resolve security
challenges in clouds. TEEs protect the confidentiality and integrity of
application code and data even against privileged attackers with root and
physical access by providing an isolated secure memory area, i.e., enclaves.
The security guarantees are provided by the CPU, thus even if system software
is compromised, the attacker can never access the enclave's content. While this
approach ensures strong security guarantees for applications, it also
introduces a considerable runtime overhead in part by the limited availability
of protected memory (enclave page cache). Currently, only a limited number of
performance measurement tools for TEE-based applications exist and none offer
performance monitoring and analysis during runtime.
  This paper presents TEEMon, the first continuous performance monitoring and
analysis tool for TEE-based applications. TEEMon provides not only fine-grained
performance metrics during runtime, but also assists the analysis of
identifying causes of performance bottlenecks, e.g., excessive system calls.
Our approach smoothly integrates with existing open-source tools (e.g.,
Prometheus or Grafana) towards a holistic monitoring solution, particularly
optimized for systems deployed through Docker containers or Kubernetes and
offers several dedicated metrics and visualizations. Our evaluation shows that
TEEMon's overhead ranges from 5% to 17%.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:33:23 GMT""}]","2020-12-14"
"2012.06555","Tamal Maharaj","Srinjoy Roy, Saptam Bakshi, Tamal Maharaj","OPAC: Opportunistic Actor-Critic","10 pages. arXiv admin note: text overlap with arXiv:1812.05905 by
  other authors",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Actor-critic methods, a type of model-free reinforcement learning (RL), have
achieved state-of-the-art performances in many real-world domains in continuous
control. Despite their success, the wide-scale deployment of these models is
still a far cry. The main problems in these actor-critic methods are
inefficient exploration and sub-optimal policies. Soft Actor-Critic (SAC) and
Twin Delayed Deep Deterministic Policy Gradient (TD3), two cutting edge such
algorithms, suffer from these issues. SAC effectively addressed the problems of
sample complexity and convergence brittleness to hyper-parameters and thus
outperformed all state-of-the-art algorithms including TD3 in harder tasks,
whereas TD3 produced moderate results in all environments. SAC suffers from
inefficient exploration owing to the Gaussian nature of its policy which causes
borderline performance in simpler tasks. In this paper, we introduce
Opportunistic Actor-Critic (OPAC), a novel model-free deep RL algorithm that
employs better exploration policy and lesser variance. OPAC combines some of
the most powerful features of TD3 and SAC and aims to optimize a stochastic
policy in an off-policy way. For calculating the target Q-values, instead of
two critics, OPAC uses three critics and based on the environment complexity,
opportunistically chooses how the target Q-value is computed from the critics'
evaluation. We have systematically evaluated the algorithm on MuJoCo
environments where it achieves state-of-the-art performance and outperforms or
at least equals the performance of TD3 and SAC.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:33:35 GMT""}]","2020-12-14"
"2012.06556","Julie Rowlett","Susanne Menden-Deuer and Julie Rowlett","Many ways to stay in the game: Individual variability maintains high
  biodiversity in planktonic micro-organisms","This is a preliminary version of the manuscript published in Journal
  of the Royal Society Interfaces and freely available online!","J. R. Soc. Interface, vol. 11, issue 95, 1120140031 (2014)","10.1098/rsif.2014.0031",,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In apparent contradiction to competition theory, the number of known,
co-existing plankton species far exceeds their explicable biodiversity - a
discrepancy termed the Paradox of the Plankton. We introduce a new
game-theoretic model for competing micro-organisms in which one player consists
of all organisms of one species. The stable points for the population dynamics
in our model, known as strategic behavior distributions (SBDs), are probability
distributions of behaviors across all organisms which imply a stable population
of the species as a whole. We find that intra-specific variability is the key
characteristic that ultimately allows co-existence because the outcomes of
competitions between individuals with variable competitive abilities is
unpredictable. Our simulations based on the theoretical model show that up to
100 species can coexist for at least 10000 generations, and that even small
population sizes or species with inferior competitive ability can survive when
there is intra-specific variability. In nature, this variability can be
observed as niche differentiation, variability in environmental and ecological
factors, and variability of individual behaviors or physiology. Therefore
previous specific explanations of the paradox are consistent with and provide
specific examples of our suggestion that individual variability is the
mechanism which solves the paradox.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:37:30 GMT""}]","2020-12-14"
"2012.06557","Karsten Kruse","Nicolas Ecker and Karsten Kruse","Excitable actin dynamics and amoeboid cell migration","29 pages, 7 figures, 6 movies",,"10.1371/journal.pone.0246311",,"physics.bio-ph nlin.PS","http://creativecommons.org/licenses/by/4.0/","  Amoeboid cell migration is characterized by frequent changes of the direction
of motion and resembles a persistent random walk on long time scales. Although
it is well known that cell migration is typically driven by the actin
cytoskeleton, the cause of this migratory behavior remains poorly understood.
We analyze the spontaneous dynamics of actin assembly due to nucleation
promoting factors, where actin filaments lead to an inactivation of the
nucleators. We show that this system exhibits excitable dynamics and can
spontaneously generate waves, which we analyse in detail. By using a
phase-field approach, we show that these waves can generate cellular random
walks. We explore how the characteristics of these persistent random walks
depend on the parameters governing the actin-nucleator dynamics. In particular,
we find that the effective diffusion constant and the persistence time depend
strongly on the speed of filament assembly and the rate of nucleator
inactivation. Our findings point to a deterministic origin of the random walk
behavior and suggest that cells could adapt their migration pattern by
modifying the pool of available actin.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:39:13 GMT""}]","2021-06-09"
"2012.06558","Ugo Rosolia","Ugo Rosolia, Andrew Singletary and Aaron D. Ames","Unified Multi-Rate Control: from Low Level Actuation to High Level
  Planning",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present a hierarchical multi-rate control architecture for
nonlinear autonomous systems operating in partially observable environments.
Control objectives are expressed using syntactically co-safe Linear Temporal
Logic (LTL) specifications and the nonlinear system is subject to state and
input constraints. At the highest level of abstraction, we model the
system-environment interaction using a discrete Mixed Observable Markov
Decision Problem (MOMDP), where the environment states are partially observed.
The high level control policy is used to update the constraint sets and cost
function of a Model Predictive Controller (MPC) which plans a reference
trajectory. Afterwards, the MPC planned trajectory is fed to a low-level
high-frequency tracking controller, which leverages Control Barrier Functions
(CBFs) to guarantee bounded tracking errors. Our strategy is based on model
abstractions of increasing complexity and layers running at different
frequencies. We show that the proposed hierarchical multi-rate control
architecture maximizes the probability of satisfying the high-level
specifications while guaranteeing state and input constraint satisfaction.
Finally, we tested the proposed strategy in simulations and experiments on
examples inspired by the Mars exploration mission, where only partial
environment observations are available.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:39:45 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jan 2021 09:46:00 GMT""},{""version"":""v3"",""created"":""Sat, 11 Sep 2021 02:04:52 GMT""},{""version"":""v4"",""created"":""Thu, 30 Jun 2022 21:54:42 GMT""}]","2022-07-04"
"2012.06559","Markus P. Mueller","Roberto D. Baldijao, Marius Krumm, Andrew J. P. Garner, Markus P.
  Mueller","Quantum Darwinism and the spreading of classical information in
  non-classical theories","17+4 pages, 6 figures. Roberto D. Baldijao and Marius Krumm share
  first authorship of this paper. v2: added several clarifications; accepted by
  Quantum","Quantum 6, 636 (2022)","10.22331/q-2022-01-31-636",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum Darwinism posits that the emergence of a classical reality relies on
the spreading of classical information from a quantum system to many parts of
its environment. But what are the essential physical principles of quantum
theory that make this mechanism possible? We address this question by
formulating the simplest instance of Darwinism - CNOT-like fan-out interactions
- in a class of probabilistic theories that contain classical and quantum
theory as special cases. We determine necessary and sufficient conditions for
any theory to admit such interactions. We find that every theory with
non-classical features that admits this idealized spreading of classical
information must have both entangled states and entangled measurements.
Furthermore, we show that Spekkens' toy theory admits this form of Darwinism,
and so do all probabilistic theories that satisfy principles like strong
symmetry, or contain a certain type of decoherence processes. Our result
suggests the counter-intuitive general principle that in the presence of local
non-classicality, a classical world can only emerge if this non-classicality
can be ""amplified"" to a form of entanglement.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:40:16 GMT""},{""version"":""v2"",""created"":""Mon, 10 Jan 2022 11:23:32 GMT""}]","2022-02-02"
"2012.06560","BaiYang Wang","Bai Yang Wang, Danfeng Li, Berit H. Goodge, Kyuho Lee, Motoki Osada,
  Shannon P. Harvey, Lena F. Kourkoutis, Malcolm R. Beasley, and Harold Y.
  Hwang","Isotropic Pauli-Limited Superconductivity in the Infinite Layer
  Nickelate Nd$_{0.775}$Sr$_{0.225}$NiO$_{2}$","9 pages, 4 figures, 1 supplementary info",,"10.1038/s41567-020-01128-5",,"cond-mat.supr-con cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent observation of superconductivity in thin film infinite-layer
nickelates$^{1-3}$ offers a different angle to investigate superconductivity in
layered oxides$^{4}$. A wide range of candidate models have been
proposed$^{5-10}$, emphasizing single- or multi-orbital electronic structure,
Kondo or Hund's coupling, and analogies to cuprates. Clearly, further
experimental characterization of the superconducting state is needed to develop
a full understanding of the nickelates. Here we use magnetotransport
measurements to probe the superconducting anisotropy in
Nd$_{0.775}$Sr$_{0.225}$NiO$_{2}$. We find that the upper critical field is
surprisingly isotropic at low temperatures despite the layered crystal
structure. In a magnetic field the superconductivity is strongly Pauli-limited,
such that the paramagnetic effect dominates over orbital de-pairing. Underlying
this isotropic response is a substantial anisotropy in the superconducting
coherence length, which is at least four times longer in-plane than
out-of-plane. A prominent low-temperature upturn in the upper critical field
indicates the presence of an unconventional ground state.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:40:18 GMT""}]","2021-04-28"
"2012.06561","Pavel Naumov","Pavel Naumov, Kevin Ros","Comprehension and Knowledge","To appear in Proceedings 35th AAAI Conference on Artificial
  Intelligence (AAAI 21), February 2-9, 2021",,,,"cs.AI cs.CL cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability of an agent to comprehend a sentence is tightly connected to the
agent's prior experiences and background knowledge. The paper suggests to
interpret comprehension as a modality and proposes a complete bimodal logical
system that describes an interplay between comprehension and knowledge
modalities.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:42:08 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 22:24:35 GMT""}]","2021-03-03"
"2012.06562","Achilleas Porfyriadis","Shahar Hadar, Alexandru Lupsasca, Achilleas P. Porfyriadis","Extreme Black Hole Anabasis","20 pages, 4 figures; v2: typo corrected, refs added; v3: minor edits,
  more refs added, matches published version",,"10.1007/JHEP03(2021)223",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the $\mathsf{SL}(2)$ transformation properties of spherically
symmetric perturbations of the Bertotti-Robinson universe and identify an
invariant $\mu$ that characterizes the backreaction of these linear solutions.
The only backreaction allowed by Birkhoff's theorem is one that destroys the
$AdS_2\times S^2$ boundary and builds the exterior of an asymptotically flat
Reissner-Nordstr\""om black hole with $Q=M\sqrt{1-\mu/4}$. We call such
backreaction with boundary condition change an anabasis. We show that the
addition of linear anabasis perturbations to Bertotti-Robinson may be thought
of as a boundary condition that defines a connected $AdS_2\times S^2$. The
connected $AdS_2$ is a nearly-$AdS_2$ with its $\mathsf{SL}(2)$ broken
appropriately for it to maintain connection to the asymptotically flat region
of Reissner-Nordstr\""om. We perform a backreaction calculation with matter in
the connected $AdS_2\times S^2$ and show that it correctly captures the
dynamics of the asymptotically flat black hole.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:46:19 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 03:25:17 GMT""},{""version"":""v3"",""created"":""Wed, 24 Mar 2021 01:32:52 GMT""}]","2021-03-25"
"2012.06563","Aythami Morales","Luis Felipe Gomez-Gomez and Aythami Morales and Julian Fierrez and
  Juan Rafael Orozco-Arroyave","Exploring Facial Expressions and Affective Domains for Parkinson
  Detection",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Parkinson's Disease (PD) is a neurological disorder that affects facial
movements and non-verbal communication. Patients with PD present a reduction in
facial movements called hypomimia which is evaluated in item 3.2 of the
MDS-UPDRS-III scale. In this work, we propose to use facial expression analysis
from face images based on affective domains to improve PD detection. We propose
different domain adaptation techniques to exploit the latest advances in face
recognition and Face Action Unit (FAU) detection. The principal contributions
of this work are: (1) a novel framework to exploit deep face architectures to
model hypomimia in PD patients; (2) we experimentally compare PD detection
based on single images vs. image sequences while the patients are evoked
various face expressions; (3) we explore different domain adaptation techniques
to exploit existing models initially trained either for Face Recognition or to
detect FAUs for the automatic discrimination between PD patients and healthy
subjects; and (4) a new approach to use triplet-loss learning to improve
hypomimia modeling and PD detection. The results on real face images from PD
patients show that we are able to properly model evoked emotions using image
sequences (neutral, onset-transition, apex, offset-transition, and neutral)
with accuracy improvements up to 5.5% (from 72.9% to 78.4%) with respect to
single-image PD detection. We also show that our proposed affective-domain
adaptation provides improvements in PD detection up to 8.9% (from 78.4% to
87.3% detection accuracy).
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:48:53 GMT""}]","2020-12-14"
"2012.06564","Marcos Matabuena","Marcos Matabuena, Paulo F\'elix, Carlos Meijide-Garcia and Francisco
  Gude","Glucose values prediction five years ahead with a new framework of
  missing responses in reproducing kernel Hilbert spaces, and the use of
  continuous glucose monitoring technology",,,,,"stat.ML cs.LG q-bio.QM stat.AP stat.ME","http://creativecommons.org/licenses/by/4.0/","  AEGIS study possesses unique information on longitudinal changes in
circulating glucose through continuous glucose monitoring technology (CGM).
However, as usual in longitudinal medical studies, there is a significant
amount of missing data in the outcome variables. For example, 40 percent of
glycosylated hemoglobin (A1C) biomarker data are missing five years ahead. With
the purpose to reduce the impact of this issue, this article proposes a new
data analysis framework based on learning in reproducing kernel Hilbert spaces
(RKHS) with missing responses that allows to capture non-linear relations
between variable studies in different supervised modeling tasks. First, we
extend the Hilbert-Schmidt dependence measure to test statistical independence
in this context introducing a new bootstrap procedure, for which we prove
consistency. Next, we adapt or use existing models of variable selection,
regression, and conformal inference to obtain new clinical findings about
glucose changes five years ahead with the AEGIS data. The most relevant
findings are summarized below: i) We identify new factors associated with
long-term glucose evolution; ii) We show the clinical sensibility of CGM data
to detect changes in glucose metabolism; iii) We can improve clinical
interventions based on our algorithms' expected glucose changes according to
patients' baseline characteristics.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:51:44 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 18:47:42 GMT""}]","2020-12-15"
"2012.06565","David Yllanes","Paul Z. Hanakata, Sourav S. Bhabesh, Mark J. Bowick, David R. Nelson,
  David Yllanes","Thermal buckling and symmetry breaking in thin ribbons under compression","12 pages, 10 figures","Extreme Mechanics Letters 44, 101270 (2021)","10.1016/j.eml.2021.101270",,"cond-mat.stat-mech cond-mat.mtrl-sci cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding thin sheets, ranging from the macro to the nanoscale, can allow
control of mechanical properties such as deformability. Out-of-plane buckling
due to in-plane compression can be a key feature in designing new materials.
While thin-plate theory can predict critical buckling thresholds for thin
frames and nanoribbons at very low temperatures, a unifying framework to
describe the effects of thermal fluctuations on buckling at more elevated
temperatures presents subtle difficulties. We develop and test a theoretical
approach that includes both an in-plane compression and an out-of-plane
perturbing field to describe the mechanics of thermalised ribbons above and
below the buckling transition. We show that, once the elastic constants are
renormalised to take into account the ribbon's width (in units of the thermal
length scale), we can map the physics onto a mean-field treatment of buckling,
provided the length is short compared to a ribbon persistence length. Our
theoretical predictions are checked by extensive molecular dynamics simulations
of thin thermalised ribbons under axial compression.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:52:12 GMT""}]","2021-03-18"
"2012.06566","Fabrizio Rompineve","Ricardo Z. Ferreira, Alessio Notari, Fabrizio Rompineve","The DFSZ axion in the CMB","14 pages, 10 figures","Phys. Rev. D 103, 063524 (2021)","10.1103/PhysRevD.103.063524",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform for the first time a dedicated analysis of cosmological
constraints on DFSZ QCD axion models. Such constructions are especially
interesting in light of the recent Xenon-1T excess and of hints from stellar
cooling. In DFSZ models, for $m_a\gtrsim 0.1$ eV, scatterings of pions and
muons can produce a sizable cosmic background of thermal axions, that behave
similarly to massive neutrinos. However, the pion coupling depends on the
alignment between the vevs of two Higgs doublets, and can be significantly
suppressed or enhanced with respect to the KSVZ scenario. Using the latest
Planck and BAO data, we find $m_a\leq 0.2~\text{eV}$ at $95\%$ C.L., when the
axion coupling to pions $c_{a\pi}$ is maximal. Constraints on $m_a$, instead,
can be significantly relaxed when $c_{a\pi}$ is small. In particular, we point
out that in the so-called DFSZ-II model, where the axion coupling to leptons
does not vanish simultaneously with $c_{a\pi}$, production via muons gives
$m_a\leq 0.6~\text{eV}$ at $95\%$ C.L., whereas in the DFSZ-I model bounds on
$m_a$ can be fully lifted. We then combine cosmological data with recent hints
of a DFSZ axion coupled to electrons from the Xenon-1T experiment, finding in
this case that the axion mass is constrained to be in the window $0.07
~\text{eV} \lesssim m_a \lesssim 1.8\, (0.3)~\text{eV}$ for the DFSZ-I
(DFSZ-II) model. A similar analysis with stellar cooling hints gives $3
~\text{meV} \lesssim m_a \lesssim 0.2 ~\text{eV}$ for DFSZ-II, while no
constraint arises in the DFSZ-I case. Forthcoming CMB Stage 4 experiments will
be able to further test such scenarios; for instance the Xenon-1T window should
be fully probed at $2\sigma$ for a DFSZ-I axion.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:53:55 GMT""}]","2021-03-31"
"2012.06567","Yi Zhu","Yi Zhu, Xinyu Li, Chunhui Liu, Mohammadreza Zolfaghari, Yuanjun Xiong,
  Chongruo Wu, Zhi Zhang, Joseph Tighe, R. Manmatha, Mu Li","A Comprehensive Study of Deep Video Action Recognition","Technical report. Code and model zoo can be found at
  https://cv.gluon.ai/model_zoo/action_recognition.html",,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video action recognition is one of the representative tasks for video
understanding. Over the last decade, we have witnessed great advancements in
video action recognition thanks to the emergence of deep learning. But we also
encountered new challenges, including modeling long-range temporal information
in videos, high computation costs, and incomparable results due to datasets and
evaluation protocol variances. In this paper, we provide a comprehensive survey
of over 200 existing papers on deep learning for video action recognition. We
first introduce the 17 video action recognition datasets that influenced the
design of models. Then we present video action recognition models in
chronological order: starting with early attempts at adapting deep learning,
then to the two-stream networks, followed by the adoption of 3D convolutional
kernels, and finally to the recent compute-efficient models. In addition, we
benchmark popular methods on several representative datasets and release code
for reproducibility. In the end, we discuss open problems and shed light on
opportunities for video action recognition to facilitate new research ideas.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:54:08 GMT""}]","2020-12-14"
"2012.06568","Xuwang Yin","Xuwang Yin, Shiying Li, Gustavo K. Rohde","Learning Energy-Based Models With Adversarial Training","ECCV2022, code is available at https://github.com/xuwangyin/AT-EBMs",,,,"cs.LG cs.CV cs.GT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study a new approach to learning energy-based models (EBMs) based on
adversarial training (AT). We show that (binary) AT learns a special kind of
energy function that models the support of the data distribution, and the
learning process is closely related to MCMC-based maximum likelihood learning
of EBMs. We further propose improved techniques for generative modeling with
AT, and demonstrate that this new approach is capable of generating diverse and
realistic images. Aside from having competitive image generation performance to
explicit EBMs, the studied approach is stable to train, is well-suited for
image translation tasks, and exhibits strong out-of-distribution adversarial
robustness. Our results demonstrate the viability of the AT approach to
generative modeling, suggesting that AT is a competitive alternative approach
to learning EBMs.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:54:34 GMT""},{""version"":""v2"",""created"":""Thu, 10 Feb 2022 06:50:04 GMT""},{""version"":""v3"",""created"":""Thu, 21 Jul 2022 19:31:19 GMT""},{""version"":""v4"",""created"":""Tue, 27 Dec 2022 23:55:36 GMT""}]","2022-12-29"
"2012.06569","Johannes Hofmann","Johannes Hofmann and Wilhelm Zwerger","Hydrodynamics of a superfluid smectic","20 pages","J. Stat. Mech. (2021) 033104","10.1088/1742-5468/abe598",,"cond-mat.quant-gas cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine the hydrodynamic modes of the superfluid analog of a smectic-A
phase in liquid crystals, i.e., a state in which both gauge invariance and
translational invariance along a single direction are spontaneously broken.
Such a superfluid smectic provides an idealized description of the
incommensurate supersolid state realized in Bose-Einstein condensates with
strong dipolar interactions as well as of the stripe phase in Bose gases with
spin-orbit coupling. We show that the presence of a finite normal fluid density
in the ground state of these systems gives rise to a well-defined second-sound
type mode even at zero temperature. It replaces the diffusive permeation mode
of a normal smectic phase and is directly connected with the classic
description of supersolids by Andreev and Lifshitz in terms of a propagating
defect mode. An analytic expression is derived for the two sound velocities
that appear in the longitudinal excitation spectrum. It only depends on the
low-energy parameters associated with the two independent broken symmetries,
which are the effective layer compression modulus and the superfluid fraction.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:55:44 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 07:22:19 GMT""}]","2021-04-07"
"2012.06570","Nikita G. Misuna","N.G. Misuna","Off-shell higher-spin fields in $AdS_{4}$ and external currents","32 pages. V4: minor typos corrected; short representation-theoretic
  discussions of results added on pp. 10, 12, 25, 26, 29. To appear in JHEP","JHEP 12 (2021) 172","10.1007/JHEP12(2021)172","FIAN/TD/2020-19","hep-th","http://creativecommons.org/licenses/by/4.0/","  We construct an unfolded system for off-shell fields of arbitrary integer
spin in 4d anti-de Sitter space. To this end we couple an on-shell system,
encoding Fronsdal equations, to external Fronsdal currents for which we find an
unfolded formulation. We present a reduction of the Fronsdal current system
which brings it to the unfolded Fierz-Pauli system describing massive fields of
arbitrary integer spin. Reformulating off-shell higher-spin system as the set
of Schwinger-Dyson equations we compute propagators of higher-spin fields in
the de Donder gauge directly from the unfolded equations. We discover operators
that significantly simplify this computation, allowing a straightforward
extraction of wave equations from an unfolded system.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:56:43 GMT""},{""version"":""v2"",""created"":""Thu, 29 Jul 2021 17:50:49 GMT""},{""version"":""v3"",""created"":""Wed, 25 Aug 2021 14:10:22 GMT""},{""version"":""v4"",""created"":""Mon, 20 Dec 2021 14:06:08 GMT""}]","2022-01-03"
"2012.06571","Benito Marcote","B. Marcote, J. R. Callingham, M. De Becker, P. G. Edwards, Y. Han, R.
  Schulz, J. Stevens, P. G. Tuthill","AU-scale radio imaging of the wind collision region in the brightest and
  most luminous non-thermal colliding wind binary Apep","9 pages, 3 figures, accepted for publication in MNRAS",,"10.1093/mnras/staa3863",,"astro-ph.SR astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recently discovered colliding-wind binary (CWB) Apep has been shown to
emit luminously from radio to X-rays, with the emission driven by a binary
composed of two Wolf-Rayet (WR) stars of one carbon-sequence (WC8) and one
nitrogen-sequence (WN4-6b). Mid-infrared imaging revealed a giant spiral dust
plume that is reminiscent of a pinwheel nebula but with additional features
that suggest Apep is a unique system. We have conducted observations with the
Australian Long Baseline Array to resolve Apep's radio emission on
milliarcsecond scales, allowing us to relate the geometry of the wind-collision
region to that of the spiral plume. The observed radio emission shows a
bow-shaped structure, confirming its origin as a wind-collision region. The
shape and orientation of this region is consistent with being originated by the
two stars and with being likely dominated by the stronger wind of the WN4-6b
star. This shape allowed us to provide a rough estimation of the opening angle
of $\sim 150^\circ$ assuming ideal conditions. The orientation and opening
angle of the emission also confirms it as the basis for the spiral dust plume.
We also provide estimations for the two stars in the system to milliarcsecond
precision. The observed radio emission, one order of magnitude brighter and
more luminous than any other known non-thermal radio-emitting CWB, confirms it
is produced by an extremely powerful wind collision. Such a powerful
wind-collision region is consistent with Apep being a binary composed of two WR
stars, so far the first unambiguously confirmed system of its kind.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:57:10 GMT""}]","2020-12-23"
"2012.06572","Eric Hanson","Eric J. Hanson, Kiyoshi Igusa, Moses Kim, and Gordana Todorov","Infinitesimal semi-invariant pictures and co-amalgamation","v2: improved and expanded exposition, notation, and references;
  replaced definition of co-amalgamation with a more general version
  (Definition 2.1.7). 44 pages, 6 figures",,,,"math.RT math.CO math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this paper is to study the local structure of the
semi-invariant picture of a tame hereditary algebra near the null root. Using a
construction that we call co-amalgamation, we show that this local structure is
completely described by the semi-invariant pictures of a collection of
self-injective Nakayama algebras. We then describe the cones of this local
structure using cluster-like structures that we call support regular clusters.
Finally, we show that the local structure is (piecewise linearly) invariant
under cluster tilting.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:57:28 GMT""},{""version"":""v2"",""created"":""Sun, 24 Jul 2022 20:39:14 GMT""}]","2022-07-26"
"2012.06573","Alexis Marchal","Alexis Marchal","Risk & returns around FOMC press conferences: a novel perspective from
  computer vision","20 pages",,,,"stat.ML cs.CV cs.LG q-fin.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I propose a new tool to characterize the resolution of uncertainty around
FOMC press conferences. It relies on the construction of a measure capturing
the level of discussion complexity between the Fed Chair and reporters during
the Q&A sessions. I show that complex discussions are associated with higher
equity returns and a drop in realized volatility. The method creates an
attention score by quantifying how much the Chair needs to rely on reading
internal documents to be able to answer a question. This is accomplished by
building a novel dataset of video images of the press conferences and
leveraging recent deep learning algorithms from computer vision. This
alternative data provides new information on nonverbal communication that
cannot be extracted from the widely analyzed FOMC transcripts. This paper can
be seen as a proof of concept that certain videos contain valuable information
for the study of financial markets.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:59:47 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jan 2021 16:31:18 GMT""}]","2021-01-18"
"2012.06574","Yifan Wang","Yifan Wang","Surface Defect, Anomalies and $b$-Extremization","41 pages, 2 tables",,"10.1007/JHEP11(2021)122",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum field theories (QFT) in the presence of defects exhibit new types of
anomalies which play an important role in constraining the defect dynamics and
defect renormalization group (RG) flows. Here we study surface defects and
their anomalies in conformal field theories (CFT) of general spacetime
dimensions. When the defect is conformal, it is characterized by a conformal
$b$-anomaly analogous to the $c$-anomaly of 2d CFTs. The $b$-theorem states
that $b$ must monotonically decrease under defect RG flows and was proven by
coupling to a spurious defect dilaton. We revisit the proof by deriving
explicitly the dilaton effective action for defect RG flow in the free scalar
theory. For conformal surface defects preserving ${\cal N}=(0,2)$
supersymmetry, we prove a universal relation between the $b$-anomaly and the 't
Hooft anomaly for the $U(1)_r$ symmetry. We also establish the
$b$-extremization principle that identifies the superconformal $U(1)_r$
symmetry from ${\cal N}=(0,2)$ preserving RG flows. Together they provide a
powerful tool to extract the $b$-anomaly of strongly coupled surface defects.
To illustrate our method, we determine the $b$-anomalies for a number of
surface defects in 3d, 4d and 6d SCFTs. We also comment on manifestations of
these defect conformal and 't Hooft anomalies in defect correlation functions.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:59:58 GMT""}]","2021-12-08"
"2012.06582","Yue-Shi Lai","Yue Shi Lai, Duff Neill, Mateusz P{\l}osko\'n, Felix Ringer","Explainable machine learning of the underlying physics of high-energy
  particle collisions","11 pages, 4 figures",,"10.1016/j.physletb.2022.137055",,"hep-ph nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an implementation of an explainable and physics-aware machine
learning model capable of inferring the underlying physics of high-energy
particle collisions using the information encoded in the energy-momentum
four-vectors of the final state particles. We demonstrate the proof-of-concept
of our White Box AI approach using a Generative Adversarial Network (GAN) which
learns from a DGLAP-based parton shower Monte Carlo event generator. We show,
for the first time, that our approach leads to a network that is able to learn
not only the final distribution of particles, but also the underlying parton
branching mechanism, i.e. the Altarelli-Parisi splitting function, the ordering
variable of the shower, and the scaling behavior. While the current work is
focused on perturbative physics of the parton shower, we foresee a broad range
of applications of our framework to areas that are currently difficult to
address from first principles in QCD. Examples include nonperturbative and
collective effects, factorization breaking and the modification of the parton
shower in heavy-ion, and electron-nucleus collisions.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:01 GMT""}]","2022-04-20"
"2012.06583","Tatsu Takeuchi","Djordje Minic, Tatsu Takeuchi, Chia Hsiung Tze","Interference and Oscillation in Nambu Quantum Mechanics","5 pages, no figures, revtex4-2","Phys. Rev. D 104, 051301 (2021)","10.1103/PhysRevD.104.L051301",,"hep-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nambu Quantum Mechanics, proposed in Phys. Lett. B536, 305 (2002), is a
deformation of canonical Quantum Mechanics in which only the time-evolution of
the ""phases"" of energy eigenstates is modified. We discuss the effect this
theory will have on oscillation phenomena, and place a bound on the deformation
parameters utilizing the data on the atmospheric neutrino mixing angle
$\theta_{23}$.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:01 GMT""}]","2021-09-15"
"2012.06584","Lucas Johns","Lucas Johns and Seth Koren","Hydrogen Mixing as a Novel Mechanism for Colder Baryons in 21 cm
  Cosmology","6 pages, 4 figures",,,,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The anomalous 21 cm absorption feature reported by EDGES has galvanized the
study of scenarios in which dark matter (DM) siphons off thermal energy from
the Standard Model (SM) gas. In a departure from the much-discussed models that
achieve cooling by DM scattering directly with SM particles, we show that the
same end can be achieved through neutral atomic hydrogen $H$ mixing with a
degenerate dark sector state $H'$. An analysis of in-medium $H$-$H'$
oscillations reveals viable parameter space for generic types of $H'$-DM
interactions to provide the requisite cooling. This strategy stands in stark
contrast to other proposals in many respects, including its cosmological
dynamics, model building implications, and complementary observational
signatures.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:02 GMT""}]","2020-12-15"
"2012.06585","Chad Bustard","Chad Bustard and Ellen G. Zweibel","Cosmic Ray Transport, Energy Loss, and Influence in the Multiphase
  Interstellar Medium","Accepted to ApJ. Revised version includes 3 tables and additional
  text that clarify the simulation setups and parameters. Figures 3 and 20 have
  been modified to show results from higher resolution simulations",,"10.3847/1538-4357/abf64c",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The bulk propagation speed of GeV-energy cosmic rays is limited by frequent
scattering off hydromagnetic waves. Most galaxy evolution simulations that
account for this confinement assume the gas is fully ionized and cosmic rays
are well-coupled to Alfv\'en waves; however, multiphase density
inhomogeneities, frequently under-resolved in galaxy evolution simulations,
induce cosmic ray collisions and ionization-dependent transport driven by
cosmic ray decoupling and elevated streaming speeds in partially neutral gas.
How do cosmic rays navigate and influence such a medium, and can we constrain
this transport with observations? In this paper, we simulate cosmic ray fronts
impinging upon idealized, partially neutral clouds and lognormally-distributed
clumps, with and without ionization-dependent transport. With these
high-resolution simulations, we identify cloud interfaces as crucial regions
where cosmic ray fronts can develop a stair-step pressure gradient sufficient
to collisionlessly generate waves, overcome ion-neutral damping, and exert a
force on the cloud. We find that the acceleration of cold clouds is hindered by
only a factor of a few when ionization-dependent transport is included, with
additional dependencies on magnetic field strength and cloud dimensionality. We
also probe how cosmic rays sample the background gas and quantify collisional
losses. Hadronic gamma-ray emission maps are qualitatively different when
ionization-dependent transport is included, but the overall luminosity varies
by only a small factor, as the short cosmic ray residence times in cold clouds
are offset by the higher densities that cosmic rays sample.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:02 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 22:54:27 GMT""}]","2021-06-09"
"2012.06586","Sashwat Tanay Mr","Sashwat Tanay, Leo C. Stein, Jos\'e T. G\'alvez Ghersi","Integrability of eccentric, spinning black hole binaries up to second
  post-Newtonian order","11+2 pages, 2 figures, 1 ancillary Mathematica file; v2: Updated to
  match version accepted by PRD","Phys. Rev. D 103, 064066 (2021)","10.1103/PhysRevD.103.064066",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate and efficient modeling of the dynamics of binary black holes (BBHs)
is crucial to their detection and parameter estimation through gravitational
waves, both with LIGO/Virgo and LISA. General BBH configurations will have
misaligned spins and eccentric orbits, eccentricity being particularly relevant
at early times. Modeling these systems is both analytically and numerically
challenging. Even though the 1.5 post-Newtonian (PN) order is Liouville
integrable, numerical work has demonstrated chaos at 2PN order, which impedes
the existence of an analytic solution. In this article we revisit integrability
at both 1.5PN and 2PN orders. At 1.5PN, we construct four (out of five) action
integrals. At 2PN, we show that the system is indeed integrable - but in a
perturbative sense - by explicitly constructing five mutually-commuting
constants of motion. Because of the KAM theorem, this is consistent with the
past numerical demonstration of chaos. Our method extends to higher PN orders,
opening the door for a fully analytical solution to the generic eccentric,
spinning BBH problem.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:02 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 23:48:07 GMT""}]","2021-03-26"
"2012.06587","Amanpreet Kaur","Amanpreet Kaur, Abraham D. Falcone, Michael C. Stroh","Classifying blazar candidates from the 3FGL unassociated catalog into BL
  Lacs and FSRQs using Swift and WISE data","13 pages, 4 figures, 2 tables, accepted for publication in AJ",,"10.3847/1538-4357/abd324",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We utilize machine learning methods to distinguish BL Lacertae objects (BL
Lac) from Flat Spectrum Radio Quasars (FSRQ) within a sample of likely X-ray
blazar counterparts to Fermi 3FGL unassociated gamma-ray sources. From our
previous work, we have extracted 84 sources that were classified as $\geq$ 99%
likley to be blazars. We then utilize Swift$-$XRT, Fermi, and WISE (The
Wide-field Infrared Survey Explorer) data together to distinguish the specific
type of blazar, FSRQs or BL Lacs. Various X-ray and Gamma-ray parameters can be
used to differentiate between these subclasses. These are also known to occupy
different parameter space on the WISE color-color diagram. Using all these data
together would provide more robust results for the classified sources. We
utilized a Random Forest Classifier to calculate the probability for each
blazar to be associated with a BL Lac or an FSRQ. Based on P$_{bll}$, which is
the probability for each source to be a BL Lac, we placed our sources into five
different categories based on this value as follows; P$_{bll}$ $\geq$ 99%:
highly likely BL Lac, P$_{bll}$ $\geq$ 90%: likely BL Lac, P$_{bll}$ $\leq$ 1%:
highly likely FSRQ, P$_{bll}$ $\leq$ 10%: likely FSRQ, and 90% $<$ P$_{bll}$
$<$ 10%: ambiguous. Our results categorize the 84 blazar candidates as 50
likely BL Lacs and the rest 34 being ambiguous. A small subset of these sources
have been listed as associated sources in the most recent Fermi catalog, 4FGL,
and in these cases our results are in agreement on the classification.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:03 GMT""}]","2021-03-03"
"2012.06588","Jordan Mirocha","Jordan Mirocha, Henri Lamarre, Adrian Liu","Systematic uncertainties in models of the cosmic dawn","10 pages, 8 figures, in press","MNRAS, Volume 504 (2021), page 1555","10.1093/mnras/stab949",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Models of the reionization and reheating of the intergalactic medium (IGM) at
redshifts $z \gtrsim 6$ continue to grow more sophisticated in anticipation of
near-future 21-cm, cosmic microwave background, and galaxy survey measurements.
However, there are many potential sources of systematic uncertainty in models
that could bias and/or degrade upcoming constraints if left unaccounted for. In
this work, we examine three commonly-ignored sources of uncertainty in models
for the mean reionization and thermal histories of the IGM: the underlying
cosmology, halo mass function (HMF), and choice of stellar population synthesis
(SPS) model. We find that cosmological uncertainties affect the Thomson
scattering optical depth at the few percent level and the amplitude of the
global 21-cm signal at the $\sim$5-10 mK level. The differences brought about
by choice of HMF and SPS models are more dramatic, comparable to the $1 \sigma$
error-bar on $\tau_e$ and a $\sim 20$ mK effect on the global 21-cm signal
amplitude. Finally, we jointly fit galaxy luminosity functions and global 21-cm
signals for all HMF/SPS combinations and find that (i) doing so requires
additional free parameters to compensate for modeling systematics and (ii) the
spread in constraints on parameters of interest for different HMF and SPS
choices, assuming $5$ mK noise in the global signal, is comparable to those
obtained when adopting the ""true"" HMF and SPS with $\gtrsim 20$ mK errors. Our
work highlights the need for dedicated efforts to reduce modeling uncertainties
in order to enable precision inference with future datasets.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:04 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 18:09:00 GMT""}]","2021-05-11"
"2012.06589","Henry Shackleton","Henry Shackleton, Alexander Wietek, Antoine Georges, Subir Sachdev","Quantum phase transition at non-zero doping in a random $t$-$J$ model","5 pages, 4 figures","Phys. Rev. Lett. 126, 136602 (2021)","10.1103/PhysRevLett.126.136602",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We present exact diagonalization results on finite clusters of a $t$-$J$
model of spin-1/2 electrons with random all-to-all hopping and exchange
interactions. We argue that such random models capture qualitatively the strong
local correlations needed to describe the cuprates and related compounds, while
avoiding lattice space group symmetry breaking orders. The previously known
spin glass ordered phase in the insulator at doping $p=0$ extends to a metallic
spin glass phase up to a transition $p=p_c \approx 1/3$. The dynamic spin
susceptibility shows signatures of the spectrum of the Sachdev-Ye-Kitaev models
near $p_c$. We also find signs of the phase transition in the entropy,
entanglement entropy and compressibility, all of which exhibit a maximum near
$p_c$. The electron energy distribution function in the metallic phase is
consistent with a disordered extension of the Luttinger-volume Fermi surface
for $p>p_c$, while this breaks down for $p<p_c$.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:05 GMT""},{""version"":""v2"",""created"":""Sat, 3 Apr 2021 22:12:49 GMT""}]","2021-04-06"
"2012.06590","Francesca Lucertini","F. Lucertini, D. Nardiello, G. Piotto","The Hubble Space Telescope UV Legacy Survey of Galactic Globular
  Clusters. XXII. Relative ages of multiple populations in five Globular
  Clusters","11 pages, 10 figures, 3 tables. Accepted for publication in A&A on
  December 9, 2020","A&A 646, A125 (2021)","10.1051/0004-6361/202039441",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aims. We present a new technique to estimate the relative ages of multiple
stellar populations hosted by five globular clusters: NGC 104 (47 Tuc), NGC
6121 (M4), NGC 6352, NGC 6362 and NGC 6723. Methods. We used the catalogs of
the database ""HST UV Globular cluster Survey (HUGS)"" to create color-magnitude
and two-color diagrams of the Globular Clusters. We identified the multiple
populations within each globular cluster, and we divided them into two main
stellar populations: POPa or first generation (1G) and POPb, composed of all
the successive generations of stars. The new technique allows us to obtain an
accurate estimate of the relative ages between POPa and POPb. Results. The
multiple populations of NGC 104 and NGC 6121 are coeval within 220 Myr and 214
Myr, while those of NGC 6352, NGC 6362 and NGC 6723 are coeval within 336 Myr,
474 Myr and 634 Myr, respectively. These results were obtained combining all
the sources of uncertainties.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:06 GMT""}]","2021-02-17"
"2012.06591","Lucas Johns","Lucas Johns and Seth Koren","The Hydrogen Mixing Portal, Its Origins, and Its Cosmological Effects","23 pages, 4 figures",,,,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hydrogen oscillation into a dark-sector state $H'$ has recently been proposed
as a novel mechanism through which hydrogen can be cooled during the dark ages
-- without direct couplings between the Standard Model and dark matter. In this
work we demonstrate that the requisite mixing can appear naturally from a
microphysical theory, and argue that the startling deviations from standard
cosmology are nonetheless consistent with observations. A symmetric mirror
model enforces the necessary degeneracy between $H$ and $H'$, and an additional
twisted $B+L'$ symmetry dictates that $H$-$H'$ mixing is the leading connection
between the sectors. We write down a UV completion where $\sim$ TeV-scale
leptoquarks generate the partonic dimension-12 mixing operator, thus linking to
the energy frontier. With half of all $H$ atoms oscillating into $H'$, the
composition of the universe is scandalously different during part of its
history. We qualitatively discuss structure formation: both the modifications
to it in the Standard Model sector and the possibility of it in the mirror
sector, which has recently been proposed as a resolution to the puzzle of early
supermassive black holes. While the egregious loss of SM baryons mostly
self-erases during reionization, to our knowledge this is the first model that
suggests there should be missing baryons in the late universe, and highly
motivates a continued, robust observational program of high-precision searches
for cosmic baryons.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:07 GMT""}]","2020-12-15"
"2012.06592","Alexander Richings","Alexander J. Richings, Claude-Andre Faucher-Giguere, Jonathan Stern","Unravelling the physics of multiphase AGN winds through emission line
  tracers","19 pages, 16 figures (including appendix). Accepted for publication
  in MNRAS; minor changes relative to previous version",,"10.1093/mnras/stab556",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observations of emission lines in Active Galactic Nuclei (AGN) often find
fast (~1000 km s^-1) outflows extending to kiloparsec scales, seen in ionised,
neutral atomic and molecular gas. In this work we present radiative transfer
calculations of emission lines in hydrodynamic simulations of AGN outflows
driven by a hot wind bubble, including non-equilibrium chemistry, to explore
how these lines trace the physical properties of the multiphase outflow. We
find that the hot bubble compresses the line-emitting gas, resulting in higher
pressures than in the ambient ISM or that would be produced by the AGN
radiation pressure. This implies that observed emission line ratios such as
[OIV] 25 ${\mu}$m / [NeII] 12 ${\mu}$m , [NeV] 14 ${\mu}$m / [NeII] 12 ${\mu}$m
and [NIII] 57 ${\mu}$m / [NII] 122 ${\mu}$m constrain the presence of the
bubble and hence the outflow driving mechanism. However, the line-emitting gas
is under-pressurised compared to the hot bubble itself, and much of the line
emission arises from gas that is out of pressure, thermal and/or chemical
equilibrium. Our results thus suggest that assuming equilibrium conditions, as
commonly done in AGN line emission models, is not justified if a hot wind
bubble is present. We also find that >50 per cent of the mass outflow rate,
momentum flux and kinetic energy flux of the outflow are traced by lines such
as [NII] 122 ${\mu}$m and [NeIII] 15 ${\mu}$m (produced in the 10^4 K phase)
and [CII] 158 ${\mu}$m (produced in the transition from 10^4 K to 100 K).
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:09 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 12:08:55 GMT""}]","2021-03-10"
"2012.06593","Stephen Feeney","Stephen M. Feeney, Hiranya V. Peiris, Samaya M. Nissanke, Daniel J.
  Mortlock","Prospects for Measuring the Hubble Constant with Neutron-Star-Black-Hole
  Mergers","Version published in Physical Review Letters. 10 pages, 3 figures.
  Code available at https://github.com/sfeeney/nsbh","Phys. Rev. Lett. 126, 171102 (2021)","10.1103/PhysRevLett.126.171102",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gravitational wave (GW) and electromagnetic (EM) observations of
neutron-star-black-hole (NSBH) mergers can provide precise local measurements
of the Hubble constant ($H_0$), ideal for resolving the current $H_0$ tension.
We perform end-to-end analyses of realistic populations of simulated NSBHs,
incorporating both GW and EM selection for the first time. We show that NSBHs
could achieve unbiased 1.5-2.4% precision $H_0$ estimates by 2030. The
achievable precision is strongly affected by the details of spin precession and
tidal disruption, highlighting the need for improved modeling of NSBH mergers.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:10 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 09:36:11 GMT""},{""version"":""v3"",""created"":""Mon, 15 Mar 2021 10:20:47 GMT""},{""version"":""v4"",""created"":""Thu, 29 Apr 2021 07:38:16 GMT""}]","2021-04-30"
"2012.06594","Sajad Abbar","Sajad Abbar, Francesco Capozzi, Robert Glas, H.-Thomas Janka and Irene
  Tamborra","On the characteristics of fast neutrino flavor instabilities in
  three-dimensional core-collapse supernova models","12 pages, 7 figures; Minor changes to match the published version in
  PRD","Phys. Rev. D 103, 063033 (2021)","10.1103/PhysRevD.103.063033","MPP-2020-224","astro-ph.HE hep-th","http://creativecommons.org/licenses/by/4.0/","  We assess the occurrence of fast neutrino flavor instabilities in two
three-dimensional state-of-the-art core-collapse supernova simulations
performed using a two-moment three-species neutrino transport scheme: one with
an exploding 9$\mathrm{M_{\odot}}$ and one with a non-exploding
20$\mathrm{M_{\odot}}$ model. Apart from confirming the presence of fast
instabilities occurring within the neutrino decoupling and the supernova
pre-shock regions, we detect flavor instabilities in the post-shock region for
the exploding model. These instabilities are likely to be scattering-induced.
In addition, the failure in achieving a successful explosion in the heavier
supernova model seems to seriously hinder the occurrence of fast instabilities
in the post-shock region. This is a consequence of the large matter densities
behind the stalled or retreating shock, which implies high neutrino scattering
rates and thus more isotropic distributions of neutrinos and antineutrinos. Our
findings suggest that the supernova model properties and the fate of the
explosion can remarkably affect the occurrence of fast instabilities. Hence, a
larger set of realistic hydrodynamical simulations of the stellar collapse is
needed in order to make reliable predictions on the flavor conversion physics.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:00:47 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 21:04:26 GMT""}]","2021-03-31"
"2012.06595","Matteo Maltoni","Celine Degrande, Matteo Maltoni","Reviving the interference: framework and proof-of-principle for the
  anomalous gluon self-interaction in the SMEFT","5 pages, 4 figures","Phys. Rev. D 103, 095009 (2021)","10.1103/PhysRevD.103.095009","CP3-20-58","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interferences are not positive-definite and therefore they can change sign
over the phase space. If the contributions of the regions where the
interference is positive and negative nearly cancel each other, interference
effects are hard to measure. In this paper, we propose a method to quantify the
ability of an observable to separate an interference positive and negative
contributions and therefore to revive the interference effects in measurements.
We apply this method to the anomalous gluon operator in the SMEFT for which the
interference suppression is well-known. We show that we can get contraints on
its coefficient, using the interference only, similar to those obtained by
including the square of the new physics amplitude.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:01:05 GMT""}]","2021-05-19"
"2012.06596","Sergio Contreras","Sergio Contreras, Raul Angulo, Matteo Zennaro","A flexible subhalo abundance matching model for galaxy clustering in
  redshift space","14 pages, 12 figures. Submitted to MNRAS",,"10.1093/mnras/stab2560",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop an extension of subhalo abundance matching (SHAM) capable of
accurately reproducing the real and redshift-space clustering of galaxies in a
state-of-the-art hydrodynamical simulation. Our method uses a low-resolution
gravity-only simulation and it includes orphan and tidal disruption
prescriptions for satellite galaxies, and a flexible amount of galaxy assembly
bias. Furthermore, it includes recipes for star formation rate (SFR) based on
the dark matter accretion rate. We test the accuracy of our model against
catalogues of stellar-mass- and SFR-selected galaxies in the TNG300
hydrodynamic simulation. By fitting a small number of free parameters, our
extended SHAM reproduces the projected correlation function and redshift-space
multipoles for number densities $10^{-3} - 10^{-2}\, h^{3}{\rm Mpc}^{-3}$, at
$z=1$ and $z=0$, and for scales $r \in [0.3 - 20] h^{-1}{\rm Mpc}$.
Simultaneously, the SHAM results also retrieve the correct halo occupation
distribution, the level of galaxy assembly bias, and higher-order statistics
present in the TNG300 galaxy catalogues. As an application, we show that our
model simultaneously fits the projected correlation function of the SDSS in 3
disjoint stellar mass bins, with an accuracy similar to that of TNG300
galaxies. This SHAM extension can be used to get accurate clustering prediction
even when using low and moderate-resolution simulations.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:06:55 GMT""}]","2021-09-22"
"2012.06597","Benoit Famaey","H. Al Kazwini, Q. Agobert, A. Siebert, B. Famaey, G. Monari, S.
  Rozier, P. Ramos, R. Ibata, S. Gausland, C. Riviere, D. Spolyar","Perturbed distribution functions with accurate action estimates for the
  Galactic disc","16 pages, 15 figures, conclusions qualitatively unchanged, accepted
  for publication in Astronomy and Astrophysics","A&A 658, A50 (2022)","10.1051/0004-6361/202040118",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  In the Gaia era, understanding the effects of the perturbations of the
Galactic disc is of major importance in the context of dynamical modelling. In
this theoretical paper we extend previous work in which, making use of the
epicyclic approximation, the linearized Boltzmann equation had been used to
explicitly compute, away from resonances, the perturbed distribution function
of a Galactic thin-disc population in the presence of a non-axisymmetric
perturbation of constant amplitude. Here we improve this theoretical framework
in two distinct ways in the new code that we present. First, we use better
estimates for the action-angle variables away from quasi-circular orbits,
computed from the AGAMA software, and we present an efficient routine to
numerically re-express any perturbing potential in these coordinates with a
typical accuracy at the per cent level. The use of more accurate action
estimates allows us to identify resonances such as the outer 1:1 bar resonance
at higher azimuthal velocities than the outer Lindblad resonance (OLR), and to
extend our previous theoretical results well above the Galactic plane, where we
explicitly show how they differ from the epicyclic approximation. In
particular, the displacement of resonances in velocity space as a function of
height can in principle constrain the 3D structure of the Galactic potential.
Second, we allow the perturbation to be time dependent, thereby allowing us to
model the effect of transient spiral arms or a growing bar. The theoretical
framework and tools presented here will be useful for a thorough analytical
dynamical modelling of the complex velocity distribution of disc stars as
measured by past and upcoming Gaia data releases.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:08:39 GMT""},{""version"":""v2"",""created"":""Wed, 10 Nov 2021 15:36:49 GMT""}]","2022-02-02"
"2012.06598","Janusz Gluza Dr","Ievgen Dubovyk, Ayres Freitas, Janusz Gluza, Krzysztof Grzanka, Tord
  Riemann, Johann Usovitsch","Electroweak precision pseudo-observables at the $e^+e^-$ Z-resonance
  peak","Contribution to ICHEP2020",,,"DESY 20-184, KW 20-002","hep-ph","http://creativecommons.org/licenses/by/4.0/","  Phenomenologically relevant electroweak precision pseudo-observables related
to Z-boson physics are discussed in the context of the strong experimental
demands of future $e^+e^-$ colliders. The recent completion of two-loop Z-boson
results is summarized and a prospect for the 3-loop Standard Model calculation
of the Z-boson decay pseudo-observable is given.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:08:56 GMT""}]","2020-12-15"
"2012.06599","Alexis Plascencia","Pavel Fileviez Perez, Clara Murgui, Alexis D. Plascencia","Baryonic Higgs and Dark Matter","24 pages. v2: minor changes to the text, accepted for publication in
  JHEP","JHEP 02 (2021) 163","10.1007/JHEP02(2021)163",,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We discuss the correlation between dark matter and Higgs decays in gauge
theories where the dark matter is predicted from anomaly cancellation. In these
theories, the Higgs responsible for the breaking of the gauge symmetry
generates the mass for the dark matter candidate. We investigate the Higgs
decays in the minimal gauge theory for Baryon number. After imposing the dark
matter density and direct detection constraints, we find that the new Higgs can
have a large branching ratio into two photons or into dark matter. Furthermore,
we discuss the production channels and the unique signatures at the Large
Hadron Collider.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:10:04 GMT""},{""version"":""v2"",""created"":""Thu, 7 Jan 2021 01:05:39 GMT""}]","2021-02-23"
"2012.06600","Carlo Nipoti","Carlo Nipoti, Giacomo Cherchi, Giuliano Iorio, Francesco Calura","Effective N-body models of composite collisionless stellar systems","10 pages, 9 figures, accepted for publication in MNRAS. Figures 3, 7
  and 9 illustrate the method applied to tidal streams",,"10.1093/mnras/stab763",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gas-poor galaxies can be modelled as composite collisionless stellar systems,
with a dark matter halo and one or more stellar components, representing
different stellar populations. The dynamical evolution of such composite
systems is often studied with numerical N-body simulations, whose initial
conditions typically require realizations with particles of stationary galaxy
models. We present a novel method to conceive these N-body realizations, which
allows one to exploit at best a collisionless N-body simulation that follows
their evolution. The method is based on the use of an effective N-body model of
a composite system, which is in fact realized as a one-component system of
particles that is interpreted a posteriori as a multi-component system, by
assigning in post-processing fractions of each particle's mass to different
components. Examples of astrophysical applications are N-body simulations that
aim to reproduce the observed properties of interacting galaxies, satellite
galaxies and stellar streams. As a case study we apply our method to an N-body
simulation of tidal stripping of a two-component (dark matter and stars)
satellite dwarf galaxy orbiting in the gravitational potential of the Milky
Way.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:10:12 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 10:00:44 GMT""}]","2021-03-24"
"2012.06601","Julie Rowlett","Susanne Menden-Deuer and Julie Rowlett","The theory of games and microbe ecology","This article is a preliminary version. The final published article is
  available open access from Theoretical Ecology!","Theor. Ecol. 12, 1-15 (2019)","10.1007/s12080-018-0384-1",,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using game theory we provide mathematical proof that if a species of
asexually reproducing microbes does not possess maximum variability in
competitive abilities amongst its individual organisms, then that species is
vulnerable to replacement by competitors. Furthermore, we prove that such
maximally variable species are neutral towards each other in competition for
limited resources; they coexist. Our proof is constructive: given one species
which does not possess maximum variability, we construct a species with the
same (or lower) mean competitive ability which can invade, in the sense that
its expected value in competition is positive whereas the expected value of the
non-maximally variable species is negative. Our results point towards the
mechanistic underpinnings for the frequent observations that (1) microbes are
characterized by large intra-specific variability and that (2) the number of
extant microbe species is very large.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:10:59 GMT""}]","2020-12-15"
"2012.06602","Sam McArdle","Sam McArdle","Learning from physics experiments, with quantum computers: Applications
  in muon spectroscopy",,"PRX Quantum 2, 020349 (2021)","10.1103/PRXQuantum.2.020349",,"quant-ph cond-mat.mtrl-sci physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computational physics is an important tool for analysing, verifying, and --
at times -- replacing physical experiments. Nevertheless, simulating quantum
systems and analysing quantum data has so far resisted an efficient classical
treatment in full generality. While programmable quantum systems have been
developed to address this challenge, the resources required for classically
intractable problems still lie beyond our reach. In this work, we consider a
new target for quantum simulation algorithms; analysing the data arising from
physics experiments -- specifically, muon spectroscopy experiments. These
experiments can be used to probe the quantum interactions present in condensed
matter systems. However, fully analysing their results can require classical
computational resources scaling exponentially with the simulated system size,
which can limit our understanding of the studied system. We show that this task
may be a natural fit for the coming generations of quantum computers. We use
classical emulations of our quantum algorithm on systems of up to 29 qubits to
analyse real experimental data, and to estimate both the near-term and error
corrected resources required for our proposal. We find that our algorithm
exhibits good noise resilience, stemming from our desire to extract global
parameters from a fitted curve, rather than targeting any individual data
point. In some respects, our resource estimates go further than some prior work
in quantum simulation, by estimating the resources required to solve a complete
task, rather than just to run a given circuit. Taking the overhead of
observable measurement and calculating multiple datapoints into account, we
find that significant challenges still remain if our algorithm is to become
practical for analysing muon spectroscopy data.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:11:04 GMT""}]","2021-07-07"
"2012.06603","Remo Kretschmann","Tapio Helin, Remo Kretschmann","Non-asymptotic error estimates for the Laplace approximation in Bayesian
  inverse problems",,,,,"math.NA cs.NA math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study properties of the Laplace approximation of the
posterior distribution arising in nonlinear Bayesian inverse problems. Our work
is motivated by Schillings et al. (2020), where it is shown that in such a
setting the Laplace approximation error in Hellinger distance converges to zero
in the order of the noise level. Here, we prove novel error estimates for a
given noise level that also quantify the effect due to the nonlinearity of the
forward mapping and the dimension of the problem. In particular, we are
interested in settings in which a linear forward mapping is perturbed by a
small nonlinear mapping. Our results indicate that in this case, the Laplace
approximation error is of the size of the perturbation. The paper provides
insight into Bayesian inference in nonlinear inverse problems, where
linearization of the forward mapping has suitable approximation properties.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:15:15 GMT""},{""version"":""v2"",""created"":""Fri, 18 Dec 2020 19:01:30 GMT""},{""version"":""v3"",""created"":""Wed, 27 Oct 2021 12:38:43 GMT""}]","2021-10-28"
"2012.06604","Varvara Zubyuk V.","Varvara V. Zubyuk, Pavel A. Shafirin, Maxim R. Shcherbakov, Gennady
  Shvets, and Andrey A. Fedyanin","Externally driven nonlinear time-variant metasurfaces","24 pages, 5 figure",,,,"physics.optics cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Resonant photonic nanostructures exhibiting enhanced nonlinear responses and
efficient frequency conversion are an emergent platform in nonlinear optics.
High-index semiconductor metasurfaces with rapidly tuned high-Q resonances
enable a novel class of time-variant metasurfaces, which expands the toolbox of
color management at the nanoscale. Here, we report on the dynamic control of
the nonlinear optical response in time-variant semiconductor metasurfaces
supporting high-quality factor resonances in the near-infrared spectral range.
Pump-probe measurements of germanium metasurfaces at negative pump-probe time
delays reveals frequency conversion in the fundamental beam and a blue-shift of
10~nm (3.05$\omega$) and 40% broadening in the third harmonic signal due to the
photoinduced time-variant refractive index. A time-dependent coupled-mode
theory, in excellent agreement with the experimental data, validated the
time-variant nature of the system. Our findings expand the scope of
time-variant metasurfaces and may serve as base for the next generation of
nanoscale pulse shapers, optical switches and light sources.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:16:09 GMT""}]","2020-12-15"
"2012.06605","Alessandro Pastore","A. Pastore and M. Carnini","Extrapolating from neural network models: a cautionary tale",,,"10.1088/1361-6471/abf08a",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present three different methods to estimate error bars on the predictions
made using a neural network. All of them represent lower bounds for the
extrapolation errors. For example, we did not include an analysis on robustness
against small perturbations of the input data.
  At first, we illustrate the methods through a simple toy model, then, we
apply them to some realistic cases related to nuclear masses. By using
theoretical data simulated either with a liquid-drop model or a Skyrme energy
density functional, we benchmark the extrapolation performance of the neural
network in regions of the Segr\`e chart far away from the ones used for the
training and validation. Finally, we discuss how error bars can help
identifying when the extrapolation becomes too uncertain and thus unreliable
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:23:08 GMT""}]","2021-08-11"
"2012.06606","Arkaitz Zubiaga","Arkaitz Zubiaga","TF-CR: Weighting Embeddings for Text Classification",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text classification, as the task consisting in assigning categories to
textual instances, is a very common task in information science. Methods
learning distributed representations of words, such as word embeddings, have
become popular in recent years as the features to use for text classification
tasks. Despite the increasing use of word embeddings for text classification,
these are generally used in an unsupervised manner, i.e. information derived
from class labels in the training data are not exploited. While word embeddings
inherently capture the distributional characteristics of words, and contexts
observed around them in a large dataset, they aren't optimised to consider the
distributions of words across categories in the classification dataset at hand.
To optimise text representations based on word embeddings by incorporating
class distributions in the training data, we propose the use of weighting
schemes that assign a weight to embeddings of each word based on its saliency
in each class. To achieve this, we introduce a novel weighting scheme, Term
Frequency-Category Ratio (TF-CR), which can weight high-frequency,
category-exclusive words higher when computing word embeddings. Our experiments
on 16 classification datasets show the effectiveness of TF-CR, leading to
improved performance scores over existing weighting schemes, with a performance
gap that increases as the size of the training data grows.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:23:28 GMT""}]","2020-12-15"
"2012.06607","Jan Verschelde","Jan Verschelde","Parallel Software to Offset the Cost of Higher Precision","The paper corresponds to a talk given by the author at the HILT 2020
  Workshop on Safe Languages and Technologies for Structured and Efficient
  Parallel and Distributed/Cloud Computing, 16-17 November 2020",,,,"cs.MS cs.DC cs.NA cs.SC math.AG math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hardware double precision is often insufficient to solve large scientific
problems accurately. Computing in higher precision defined by software causes
significant computational overhead. The application of parallel algorithms
compensates for this overhead. Newton's method to develop power series
expansions of algebraic space curves is the use case for this application.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:23:55 GMT""}]","2020-12-15"
"2012.06608","Jesus Malo","Jose Juan Esteve-Taboada, Guillermo Aguilar, Marianne Maertens, Felix
  A. Wichmann, Jesus Malo","Psychophysical Estimation of Early and Late Noise",,,,,"q-bio.NC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In psychophysics (without access to physiological measurements at retina and
the behaviourally relevant stages within the visual system), early and late
noise in within the visual system seem hard to tell apart because
discrimination depends on the inner noise or effective noise which is a
non-trivial combination of early and late noises. In this work we analyze this
combination in detail in nonlinear vision models and propose a purely
psychophysical methodology to quantify the early noise and the late noise. Our
analysis generalizes classical results from linear systems (Burgess and
Colborne, 1988) by combining the theory of noise propagation through a
nonlinear network (Ahumada, 1987) with the expressions to obtain the perceptual
metric along the nonlinear network (Malo and Simoncelli, 2006; Laparra,
Mu\~noz, and Malo, 2010). The proposed method shows that the scale of the late
noise can only be determined if the experiments include substantial noise in
the input. This means that knowing the magnitude of early noise is necessary as
it is needed as a scaling factor for the late noise. Moreover, it suggests that
the use of external noise in the experiments may be helpful as an extra
reference. Therefore, we propose to use accurate measurements of pattern
discrimination in external noise, where the spectrum of this external noise was
well controlled (Henning, Bird, and Wichmann, 2002). Our psychophysical
estimate of early noise (assuming a conventional cascade of linear+nonlinear
stages) is discussed in light of the noise in cone photocurrents computed via
accurate models of retinal physiology (Brainard and Wandell, 2020). Finally, in
line with Maximum Differentiation (Wang and Simoncelli, 2008), we discuss how
to the proposed method may be used to design stimuli to decide between
alternative vision models.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:25:46 GMT""}]","2020-12-15"
"2012.06609","James Holland","James K Holland and Nicholas Hopper","RegulaTor: A Straightforward Website Fingerprinting Defense",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Website Fingerprinting (WF) attacks are used by local passive attackers to
determine the destination of encrypted internet traffic by comparing the
sequences of packets sent to and received by the user to a previously recorded
data set. As a result, WF attacks are of particular concern to
privacy-enhancing technologies such as Tor. In response, a variety of WF
defenses have been developed, though they tend to incur high bandwidth and
latency overhead or require additional infrastructure, thus making them
difficult to implement in practice. Some lighter-weight defenses have been
presented as well; still, they attain only moderate effectiveness against
recently published WF attacks. In this paper, we aim to present a realistic and
novel defense, RegulaTor, which takes advantage of common patterns in web
browsing traffic to reduce both defense overhead and the accuracy of current WF
attacks. In the closed-world setting, RegulaTor reduces the accuracy of the
state-of-the-art attack, Tik-Tok, against comparable defenses from 66% to
25.4%. To achieve this performance, it requires limited added latency and a
bandwidth overhead 39.3% less than the leading moderate-overhead defense. In
the open-world setting, RegulaTor limits a precision-tuned Tik-Tok attack to an
F-score of .135, compared to .625 for the best comparable defense.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:31:22 GMT""},{""version"":""v2"",""created"":""Sat, 5 Jun 2021 01:02:31 GMT""},{""version"":""v3"",""created"":""Tue, 21 Sep 2021 20:15:46 GMT""}]","2021-09-23"
"2012.06610","Richard M. McLaughlin","Lingyun Ding and Richard M. McLaughlin","Ergodicity and invariant measures for a diffusing passive scalar
  advected by a random channel shear flow and the connection between the
  Kraichnan-Majda model and Taylor-Aris Dispersion",,,,,"math.AP math.PR physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the long time behavior of an advection-diffusion equation with a
random shear flow which depends on a stationary Ornstein-Uhlenbeck (OU) process
in parallel-plate channels enforcing the no-flux boundary conditions. We derive
a closed form formula for the long time asymptotics of the arbitrary $N$-point
correlator using the ground state eigenvalue perturbation approach proposed in
\cite{bronski1997scalar}. In turn, appealing to the conclusion of the Hausdorff
moment problem \cite{shohat1943problem}, we discover a diffusion equation with
a random drift and deterministic enhanced diffusion possessing the exact same
probability distribution function at long times. Such equations enjoy many
ergodic properties which immediately translate to ergodicity results for the
original problem. In particular, we establish that the first two Aris moments
using a single realization of the random field can be used to explicitly
construct all ensemble averaged moments. Also, the first two ensemble averaged
moments explicitly predict any long time centered Aris moment. Our formulae
quantitatively depict the dependence of the deterministic effective diffusion
on the interaction between spatial structure of flow and random temporal
fluctuation. This noteably contrasts the white noise case from the OU case.
Further, this approximation provides many identities regarding the stationary
OU process dependent time integral. We derive explicit formulae for the
decaying passive scalar's long time limiting probability distribution function
(PDF) for different types of initial conditions (e.g. deterministic and
random). All results are verified by Monte-Carlo simulations.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:31:59 GMT""}]","2020-12-15"
"2012.06611","Kevin Andrade","Kevin E. Andrade, Jackson Fuson, Sophia Gad-Nasr, Demao Kong, Quinn
  Minor, M. Grant Roberts and Manoj Kaplinghat","A Stringent Upper Limit on Dark Matter Self-Interaction Cross Section
  from Cluster Strong Lensing","28 pages",,"10.1093/mnras/stab3241",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We analyze strongly lensed images in 8 galaxy clusters to measure their dark
matter density profiles in the radial region between 10 kpc and 150 kpc, and
use this to constrain the self-interaction cross section of dark matter (DM)
particles. We infer the mass profiles of the central DM halos, bright central
galaxies, key member galaxies, and DM subhalos for the member galaxies for all
8 clusters using the Qlens code. The inferred DM halo surface densities are fit
to a self-interacting dark matter (SIDM) model, which allows us to constrain
the self-interaction cross section over mass $\sigma$/m. When our full method
is applied to mock data generated from two clusters in the Illustris-TNG
simulation, we find results consistent with no dark matter self-interactions as
expected. For the eight observed clusters with average relative velocities of
$1458_{-81}^{+80}$ km/s, we infer $\sigma$/m = $0.082_{-0.021}^{+0.027}$
cm$^2$/g and $\sigma$/m < 0.13 cm$^2$/g at the 95% confidence level.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:34:32 GMT""},{""version"":""v2"",""created"":""Sun, 8 Aug 2021 19:49:54 GMT""},{""version"":""v3"",""created"":""Thu, 4 Nov 2021 18:59:55 GMT""}]","2021-11-24"
"2012.06612","Aude Simon Dr","Nadia Ben Amor and Eric Michoulier and Aude Simon","Electronic excited states of benzene in interaction with water clusters
  : influence of structure and size","37 pages, 15 figures, 7 tables",,,,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This work is dedicated to the theoretical investigation of the influence of
water clusters' organisation and size on the electronic spectrum of an
interacting benzene (Bz) molecule using both TD-DFT and CASPT2 approaches. Two
series of geometries, namely $Geo_{IEI}$ and $Geo_{IED}$ were extracted from
two Bz-hexagonal ice configurations leading to maximum and minimum ionization
energies respectively. An appropriate basis set containing atomic diffuse and
polarisation orbitals and describing the Rydberg states of Bz was determined.
The TD-DFT approach was carefully benchmarked against CASPT2 results for the
smallest systems.Despite some discrepancies, the trends were found to be
similar at both levels of theory: the positions and intensities of the main
$\pi \rightarrow \pi^{\star}$ transitions were found slightly split due to
symmetry breaking. For the smallest systems, our results clearly show the
dependence of the electronic transitions on the clusters' structures. Of
particular interest, low energy transitions of non negligible oscillator
strength from a Bz $\pi$ orbital to a virtual orbital of Rydberg character,
also involving atomic diffuse functions and partially expanded on the water
cluster, were found for the $Geo_{IED}$ series. The energies of such
transitions were determined to be more than 2\,eV below the ionization
potential of Bz. When the cluster's size increases, similar transitions were
found for all structures, the virtual orbitals becoming mainly developed on the
H atoms of the water molecules at the edge of the cluster. Given their nature
and energy, such transitions could play a role in the photochemistry of
aromatic species in interaction with water clusters or ice, such processes
being of astrophysical interest.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:36:54 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 15:22:14 GMT""}]","2021-03-10"
"2012.06613","Fnu Hairi","Fnu Hairi, Xin Liu and Lei Ying","Beyond Scaling: Calculable Error Bounds of the Power-of-Two-Choices
  Mean-Field Model in Heavy-Traffic",,,,,"cs.PF math.PR","http://creativecommons.org/licenses/by/4.0/","  This paper provides a recipe for deriving calculable approximation errors of
mean-field models in heavy-traffic with the focus on the well-known load
balancing algorithm -- power-of-two-choices (Po2). The recipe combines Stein's
method for linearized mean-field models and State Space Concentration (SSC)
based on geometric tail bounds. In particular, we divide the state space into
two regions, a neighborhood near the mean-field equilibrium and the complement
of that. We first use a tail bound to show that the steady-state probability
being outside the neighborhood is small. Then, we use a linearized mean-field
model and Stein's method to characterize the generator difference, which
provides the dominant term of the approximation error. From the dominant term,
we are able to obtain an asymptotically-tight bound and a nonasymptotic upper
bound, both are calculable bounds, not order-wise scaling results like most
results in the literature. Finally, we compared the theoretical bounds with
numerical evaluations to show the effectiveness of our results. We note that
the simulation results show that both bounds are valid even for small size
systems such as a system with only ten servers.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:40:19 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 02:59:33 GMT""}]","2021-11-02"
"2012.06614","Qiong Wang","Chen-En Tsai, James Hung, Youxin Hu, Da-Yung Wang, Robert M. Pilliar
  and Rizhi Wang","Improving fretting corrosion resistance of CoCrMo alloy with TiSiN and
  ZrN coatings for orthopedic applications",,"Journal of the Mechanical Behavior of Biomedical Materials, Volume
  114, February 2021, 104233",,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Total hip replacement is the most effective treatment for late stage
osteoarthritis. However, adverse local tissue reactions (ALTRs) associated with
fretting corrosion have been observed in patients with modular total hip
implants. The purpose of this study is to increase the fretting corrosion
resistance of the CoCrMo alloy and the associated metal ion release by applying
hard coatings to the surface. Cathodic arc evaporation technique (arc-PVD) was
used to deposit TiSiN and ZrN hard coatings on to CoCrMo substrates. The
morphology, chemical composition, crystal structures and residual stress of the
coatings were characterized by scanning electron microscopy, energy dispersive
x-ray spectroscopy, and X-ray diffractometry. Hardness, elastic modulus, and
adhesion of the coatings were measured by nano-indentation, nano-scratch test,
and the Rockwell C test. Fretting corrosion resistance tests of coated and
uncoated CoCrMo discs against Ti6Al4V spheres were conducted on a four-station
fretting testing machine in simulated body fluid at 1Hz for 1 million cycles.
Post-fretting samples were analyzed for morphological changes, volume loss and
metal ion release. Our analyses showed better surface finish and lower residual
stress for ZrN coating, but higher hardness and better scratch resistance for
TiSiN coating. Fretting results demonstrated substantial improvement in
fretting corrosion resistance of CoCrMo with both coatings. ZrN and TiSiN
decreased fretting volume loss by more than 10 times and 1000 times,
respectively. Both coatings showed close to 90% decrease of Co ion release
during fretting corrosion tests. Our results suggest that hard coating
deposition on CoCrMo alloy can significantly improve its fretting corrosion
resistance and could thus potentially alleviate ALTRs in metal hip implants.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:48:31 GMT""}]","2020-12-15"
"2012.06615","Meriel Von Stein","Meriel Stein, Sebastian Elbaum, Lu Feng, Shili Sheng","Probabilistic Conditional System Invariant Generation with Bayesian
  Inference",,,,,"cs.RO cs.SE","http://creativecommons.org/licenses/by/4.0/","  Invariants are a set of properties over program attributes that are expected
to be true during the execution of a program. Since developing those invariants
manually can be costly and challenging, there are a myriad of approaches that
support automated mining of likely invariants from sources such as program
traces. Existing approaches, however, are not equipped to capture the rich
states that condition the behavior of autonomous mobile robots, or to manage
the uncertainty associated with many variables in these systems. This means
that valuable invariants that appear only under specific states remain
uncovered. In this work we introduce an approach to infer conditional
probabilistic invariants to assist in the characterization of the behavior of
such rich stateful, stochastic systems. These probabilistic invariants can
encode a family of conditional patterns, are generated using Bayesian inference
to leverage observed trace data against priors gleaned from previous experience
and expert knowledge, and are ranked based on their surprise value and
information content. Our studies on two semi-autonomous mobile robotic systems
show how the proposed approach is able to generate valuable and previously
hidden stateful invariants.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:51:04 GMT""}]","2020-12-15"
"2012.06616","David d'Enterria","David d'Enterria","Experimental QCD summary (ICHEP 2020)","Proceeds. of Science (ICHEP-2020) to appear. 11 pages, 14 figures",,,,"hep-ex hep-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This writeup summarizes the main experimental studies of the strong
interaction, theoretically described by quantum chromodynamics (QCD), that were
presented during the ICHEP-2020 conference. The latest results, measured mostly
in p-p collisions at the LHC, are categorized in seven broad topics: (i)
Extractions of the strong coupling constant $\alpha_s(m_{\rm Z})$; (ii)
Comparison of data to fixed-order (N$^{\rm n}$LO) perturbative QCD
calculations; (iii) Determinations of parton distribution functions (PDFs);
(iv) Comparison of data to resummed (N$^{\rm n}$LL) pQCD calculations; (v)
Parton showering and jet substructure analyses; (vi) Semihard (double parton
interactions, multiparton interactions, hard diffraction), and soft (elastic
and diffractive) QCD scatterings; and (vii) Studies of parton hadronization in
$\rm e^+e^-$ and p-p collisions.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:53:41 GMT""}]","2020-12-15"
"2012.06617","Maykel Belluzi","Maykel Belluzi, Tom\'as Caraballo, Marcelo J. D. Nascimento and Karina
  Schiabel","Pullback and uniform attractors for nonautonomous reaction-diffusion
  equation in Dumbbell domains","29 pages, 1 figure",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  This work is devoted to the study of the asymptotic behavior of nonautonomous
reaction-diffusion equations in Dumbbell domains $\Omega_{\varepsilon} \subset
\mathbb{R}^{N}$. Each $\Omega_{\varepsilon}$ is the union of a fixed open set
$\Omega$ and a channel $R_{\varepsilon}$ that collapses to a line segment $R_0$
as $\varepsilon \rightarrow 0^{+}$. We first establish the global existence of
solution for each problem by using two properties of the parabolic equation
considered, which are the positivity of the solutions and comparison results
for them. We prove the existence of pullback and uniform attractors and we
obtain uniform bounds (in $\varepsilon$) for them.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:54:05 GMT""}]","2020-12-15"
"2012.06618","Nicolas Mora","Octavio Fierro, Nicolas Mora, Julio Oliva","Slowly rotating black holes in Quasi-topological gravity","23 pages, 4 figures. V2: title changed as requested by PRD referee.
  Abstract modified to emphasize the no-go result in Kerr-Schild ansatz","Phys. Rev. D 103, 064004 (2021)","10.1103/PhysRevD.103.064004",,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  While cubic Quasi-topological gravity is unique, there is a family of quartic
Quasi-topological gravities in five dimensions. These theories are defined by
leading to a first order equation on spherically symmetric spacetimes,
resembling the structure of the equations of Lovelock theories in
higher-dimensions, and are also ghost free around AdS. Here we construct slowly
rotating black holes in these theories, and show that the equations for the
off-diagonal components of the metric in the cubic theory are automatically of
second order, while imposing this as a restriction on the quartic theories
allows to partially remove the degeneracy of these theories, leading to a
three-parameter family of Lagrangians of order four in the Riemann tensor. This
shows that the parallel with Lovelock theory observed on spherical symmetry,
extends to the realm of slowly rotating solutions. In the quartic case, the
equations for the slowly rotating black hole are obtained from a consistent,
reduced action principle. These functions admit a simple integration in terms
of quadratures. Finally, in order to go beyond the slowly rotating regime, we
explore the consistency of the Kerr-Schild ansatz in cubic Quasi-topological
gravity. Requiring the spacetime to asymptotically match with the rotating
black hole in GR, for equal oblateness parameters, the Kerr-Schild deformation
of an AdS vacuum, does not lead to a solution for generic values of the
coupling. This result suggests that in order to have solutions with finite
rotation in Quasi-topological gravity, one must go beyond the Kerr-Schild
ansatz.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:55:56 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 20:38:13 GMT""}]","2021-03-10"
"2012.06619","Gustavo E. Medina Toledo","Gustavo E. Medina, Ricardo R. Mu\~noz, Jeffrey L. Carlin, A. Katherina
  Vivas, Camilla J. Hansen, Eva K. Grebel","A systematic DECam search for RR Lyrae in the outer halo of the Milky
  Way","5 pages, 3 figures. Contributed talk to appear on Astronomical
  Society of the Pacific Conference Series Vol. 529 ""RRLyrae/Cepheid2019:
  Frontiers of Classical Pulsators: Theory and Observations"", p. 222.
  Proceedings of the meeting held in Cloudcroft, NM, USA October 13-18, 2019.
  Edited by K. Kinemuchi, C. Lovekin, H. Neilson, and K. Vivas. Revised Figure
  3",,,,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The discovery of very distant stars in the halo of the Milky Way provides
valuable tracers on the Milky Way mass and its formation. Beyond 100 kpc from
the Galactic center, most of the stars are likely to be in faint dwarf galaxies
or tidal debris from recently accreted dwarfs, making the outer reaches of the
Galaxy important for understanding the Milky Way's accretion history. However,
distant stars in the halo are scarce. In that context, RR Lyrae are ideal
probes of the distant halo as they are intrinsically bright and thus can be
seen at large distances, follow well-known period-luminosity relations that
enable precise distance measurements, and are easily identifiable in
time-series data. Therefore, a detailed study of RR Lyrae will help us
understand the accreted outskirts of the Milky Way. In this contribution, we
present the current state of our systematic search for distant RR Lyrae stars
in the halo using the DECam imager at the 4m telescope on Cerro Tololo (Chile).
The total surveyed area consists of more than 110 DECam fields (~ 350 sq. deg)
and includes two recent independent campaigns carried out in 2017 and 2018 with
which we have detected > 650 candidate RR Lyrae stars. Here we describe the
methodology followed to analyze the two latest campaigns. Our catalog contains
a considerable number of candidate RR Lyrae beyond 100 kpc, and reaches out up
to ~ 250 kpc. The number of distant RR Lyrae found is consistent with recent
studies of the outer halo. These stars provide a set of important probes of the
mass of the Milky Way, the nature of the halo, and the accretion history of the
Galactic outskirts.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:59:53 GMT""}]","2020-12-15"
"2012.06620","Rory Bowens","R. Bowens, E. Viges, M. R. Meyer, D. Atkinson, J. Monnier, M.
  Morgenstern, J. Leisenring, W. Hoffmann","The Michigan Infrared Test Thermal ELT N-band (MITTEN) Cryostat","10 pages, 6 figures, To appear in the SPIE Proceedings 'Astronomical
  Telescopes and Instrumentation' (2020)",,,,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We introduce the Michigan Infrared Test Thermal ELT N-band (MITTEN) Cryostat,
a new facility for testing infrared detectors with a focus on mid-infrared
(MIR) wavelengths (8-13 microns). New generations of large format, deep well,
fast readout MIR detectors are now becoming available to the astronomical
community. As one example, Teledyne Imaging Sensors (TIS) has introduced a
long-wave Mercury-Cadmium-Telluride (MCT) array, GeoSnap, with high quantum
efficiency (> 65 %) and improved noise properties compared to previous
generation Si:As blocked impurity band (BIB) detectors. GeoSnap promises
improved sensitivities, and efficiencies, for future background-limited MIR
instruments, in particular with future extremely large telescopes (ELTs). We
describe our new test facility suitable for measuring characteristics of these
detectors, such as read noise, dark current, linearity, gain, pixel
operability, quantum efficiency, and point source imaging performance relative
to a background scene, as well as multiple point sources of differing contrast.
MITTEN has an internal light source, and soon an accompanying filter wheel and
aperture plate, reimaged onto the detector using an Offner relay. The baseline
temperature of the cryostat interior is maintained < 40 K and the optical bench
maintains a temperature of 16 K using a two-stage pulse-tube cryocooler package
from Cryomech. No measurable background radiation from the cryostat interior
has yet been detected.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:02:31 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 04:01:39 GMT""}]","2020-12-16"
"2012.06621","Pablo Santos-Sanz","P. Santos-Sanz, J. L. Ortiz, B. Sicardy, G. Benedetti-Rossi, N.
  Morales, E. Fern\'andez-Valenzuela, R. Duffard, R. Iglesias-Marzoa, J.L.
  Lamadrid, N. Ma\'icas, L. P\'erez, K. Gazeas, J.C. Guirado, V. Peris, F.J.
  Ballesteros, F. Organero, L. Ana-Hern\'andez, F. Fonseca, A. Alvarez-Candal,
  Y. Jim\'enez-Teja, M. Vara-Lubiano, F. Braga-Ribas, J.I.B. Camargo, J.
  Desmars, M. Assafin, R. Vieira-Martins, J. Alikakos, M. Boutet, M. Bretton,
  A. Carbognani, V. Charmandaris, F. Ciabattari, P. Delincak, A. Fuambuena
  Leiva, H. Gonz\'alez, T. Haymes, S. Hellmich, J. Horbowicz, M. Jennings, B.
  Kattentidt, Cs. Kiss, R. Kom\v{z}\'ik, J. Lecacheux, A. Marciniak, S.
  Moindrot, S. Mottola, A. Pal, N. Paschalis, S. Pastor, C. Perello, T.
  Pribulla, C. Ratinaud, J.A. Reyes, J. Sanchez, C. Schnabel, A. Selva, F.
  Signoret, E. Sonbas, V. Al\'i-Lagoa","The 2017 May 20$^{\rm th}$ stellar occultation by the elongated centaur
  (95626) 2002 GZ$_{32}$","Accepted for publication in MNRAS (8-Dec.-2020), 15 pages, 9 figures",,"10.1093/mnras/staa3881",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We predicted a stellar occultation of the bright star Gaia DR1
4332852996360346368 (UCAC4 385-75921) (m$_{\rm V}$= 14.0 mag) by the centaur
2002 GZ$_{32}$ for 2017 May 20$^{\rm th}$. Our latest shadow path prediction
was favourable to a large region in Europe. Observations were arranged in a
broad region inside the nominal shadow path. Series of images were obtained
with 29 telescopes throughout Europe and from six of them (five in Spain and
one in Greece) we detected the occultation. This is the fourth centaur, besides
Chariklo, Chiron and Bienor, for which a multi-chord stellar occultation is
reported. By means of an elliptical fit to the occultation chords we obtained
the limb of 2002 GZ$_{32}$ during the occultation, resulting in an ellipse with
axes of 305 $\pm$ 17 km $\times$ 146 $\pm$ 8 km. From this limb, thanks to a
rotational light curve obtained shortly after the occultation, we derived the
geometric albedo of 2002 GZ$_{32}$ ($p_{\rm V}$ = 0.043 $\pm$ 0.007) and a 3-D
ellipsoidal shape with axes 366 km $\times$ 306 km $\times$ 120 km. This shape
is not fully consistent with a homogeneous body in hydrostatic equilibrium for
the known rotation period of 2002 GZ$_{32}$. The size (albedo) obtained from
the occultation is respectively smaller (greater) than that derived from the
radiometric technique but compatible within error bars. No rings or debris
around 2002 GZ$_{32}$ were detected from the occultation, but narrow and thin
rings cannot be discarded.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:08:05 GMT""}]","2021-01-13"
"2012.06622","Sohrab Rahvar","Mohammad H. Zhoolideh Haghighi, Sohrab Rahvar and M Reza Rahimi Tabar","Phase transition in Modified Newtonian Dynamics (MONDian)
  self-gravitating systems","14 pages, 5 figures","Entropy 2021, 23 (9), 1158","10.3390/e23091158",,"cond-mat.stat-mech astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  We study the statistical mechanics of binary systems under gravitational
interaction of the Modified Newtonian Dynamics (MOND) in three-dimensional
space. Considering the binary systems, in the microcanonical and canonical
ensembles, we show that in the microcanonical systems, unlike the Newtonian
gravity, there is a sharp phase transition, with a high-temperature homogeneous
phase and a low temperature clumped binary one. Defining an order parameter in
the canonical systems, we find a smoother phase transition and identify the
corresponding critical temperature in terms of physical parameters of the
binary system.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:10:33 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 18:47:12 GMT""}]","2021-09-15"
"2012.06623","Fleurianne Bertrand","Fleurianne Bertrand, Daniele Boffi, Henrik Schneider","DPG approximation of eigenvalue problems",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the discontinuous Petrov--Galerkin approximation of the
Laplace eigenvalue problem is discussed. We consider in particular the primal
and ultra weak formulations of the problem and prove the convergence together
with a priori error estimates. Moreover, we propose two possible error
estimators and perform the corresponding a posteriori error analysis. The
theoretical results are confirmed numerically and it is shown that the error
estimators can be used to design an optimally convergent adaptive scheme.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:11:56 GMT""}]","2020-12-15"
"2012.06624","Nadina Gheorghiu","Nadina Gheorghiu, Charles R. Ebbing, and Timothy J. Haugan","Boron Content and the Superconducting Critical Temperature of
  Carbon-Based Materials","5 pages, 10 figures",,,,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present results on magnetization properties of boron
nitride-carbon (BN-C) and boron carbide-carbon (B4C-C) granular mixtures. The
temperature-dependent magnetization for field-cooled during cooling and
field-cooled during warming shows a kind of thermal hysteresis that is always
seen around a metamagnetic phase transition from an antiferromagnetic
martensite to a ferromagnetic austenite phase. The low-temperature
magnetization has an upward turn that can be attributed to superparamagnetism,
diamagnetic shielding, and trapped flux characteristic to high-temperature
superconducting materials. After subtracting the diamagnetic background, the
field-dependent magnetization loops M(B) are ferromagnetic-like, more
significant for the BN-C than for the B4C-C mixture. In addition, the
magnetization loops show the kink feature characteristic to granular
superconductivity. The irreversibility temperature for a B4C-C mixture having
37.5 wt% B is Tc = 76 K. Combining our data with previous results on B-doped
diamond and Q-carbon, we find that Tc increases linearly with the B
concentration.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:15:09 GMT""}]","2020-12-15"
"2012.06625","Carlo Lucibello","Christoph Feinauer, Carlo Lucibello","Reconstruction of Pairwise Interactions using Energy-Based Models",,,"10.1088/1742-5468/ac3a7f",,"cond-mat.dis-nn cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pairwise models like the Ising model or the generalized Potts model have
found many successful applications in fields like physics, biology, and
economics. Closely connected is the problem of inverse statistical mechanics,
where the goal is to infer the parameters of such models given observed data.
An open problem in this field is the question of how to train these models in
the case where the data contain additional higher-order interactions that are
not present in the pairwise model. In this work, we propose an approach based
on Energy-Based Models and pseudolikelihood maximization to address these
complications: we show that hybrid models, which combine a pairwise model and a
neural network, can lead to significant improvements in the reconstruction of
pairwise interactions. We show these improvements to hold consistently when
compared to a standard approach using only the pairwise model and to an
approach using only a neural network. This is in line with the general idea
that simple interpretable models and complex black-box models are not
necessarily a dichotomy: interpolating these two classes of models can allow to
keep some advantages of both.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:15:10 GMT""}]","2022-01-12"
"2012.06626","Lauro Morales Montesinos MsC","Antonio Capella and Lauro Morales","On the symmetric lamination convex and quasiconvex hull for the coplanar
  n-well problem in two dimensions","25 pages, 14 images",,,,"math.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study some particular cases of the $n$-well problem in two-dimensional
linear elasticity. Assuming that every well in
$\mathcal{U}\subset\mathbb{R}^{2\times 2}_\text{sym}$ belong to the same
two-dimensional affine subspace, we characterize the symmetric lamination
convex hull $L^e(\mathcal{U})$ for any number of wells in terms of the
symmetric lamination convex hull of all three-well subsets contained in
$\mathcal{U}$. For a family of four-well sets where two pairs of wells are
rank-one compatible, we show that the symmetric lamination convex and
quasiconvex hulls coincide, but are strictly contained in its convex hull
$C(\mathcal{U})$. We extend this result to some particular configurations of
$n$ wells. Most of the proofs are constructive, and we also present explicit
examples.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:20:25 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 21:13:11 GMT""}]","2021-02-04"
"2012.06627","Junliang Shen","Davesh Maulik, Junliang Shen","Cohomological $\chi$-independence for moduli of one-dimensional sheaves
  and moduli of Higgs bundles","40 Pages. Accepted version. To appear at Geometry and Topology",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We prove that the intersection cohomology (together with the perverse and the
Hodge filtrations) for the moduli space of one-dimensional semistable sheaves
supported in an ample curve class on a toric del Pezzo surface is independent
of the Euler characteristic of the sheaves. We also prove an analogous result
for the moduli space of semistable Higgs bundles with respect to an effective
divisor $D$ of degree $\mathrm{deg}(D)>2g-2$. Our results confirm the
cohomological $\chi$-independence conjecture by Bousseau for $\mathbb{P}^2$,
and verify Toda's conjecture for Gopakumar-Vafa invariants for certain local
curves and local surfaces.
  For the proof, we combine a generalized version of Ng\^o's support theorem, a
dimension estimate for the stacky Hilbert-Chow morphism, and a splitting
theorem for the morphism from the moduli stack to the good GIT quotient.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:20:40 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jan 2021 17:26:31 GMT""},{""version"":""v3"",""created"":""Tue, 9 Nov 2021 21:58:36 GMT""}]","2021-11-11"
"2012.06628","Zuoyue Li","Zuoyue Li, Zhenqiang Li, Zhaopeng Cui, Rongjun Qin, Marc Pollefeys,
  Martin R. Oswald","Sat2Vid: Street-view Panoramic Video Synthesis from a Single Satellite
  Image","Technical Report",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present a novel method for synthesizing both temporally and geometrically
consistent street-view panoramic video from a single satellite image and camera
trajectory. Existing cross-view synthesis approaches focus on images, while
video synthesis in such a case has not yet received enough attention. For
geometrical and temporal consistency, our approach explicitly creates a 3D
point cloud representation of the scene and maintains dense 3D-2D
correspondences across frames that reflect the geometric scene configuration
inferred from the satellite view. As for synthesis in the 3D space, we
implement a cascaded network architecture with two hourglass modules to
generate point-wise coarse and fine features from semantics and per-class
latent vectors, followed by projection to frames and an upsampling module to
obtain the final realistic video. By leveraging computed correspondences, the
produced street-view video frames adhere to the 3D geometric scene structure
and maintain temporal consistency. Qualitative and quantitative experiments
demonstrate superior results compared to other state-of-the-art synthesis
approaches that either lack temporal consistency or realistic appearance. To
the best of our knowledge, our work is the first one to synthesize cross-view
images to video.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:22:38 GMT""},{""version"":""v2"",""created"":""Thu, 17 Dec 2020 08:43:00 GMT""},{""version"":""v3"",""created"":""Thu, 6 May 2021 03:02:44 GMT""}]","2021-05-11"
"2012.06629","Don DeJongh","Don F. DeJongh, Ethan A. DeJongh, Victor Rykalin, Greg DeFillippo,
  Mark Pankuch, Andrew W. Best, George Coutrakon, Kirk L. Duffin, Nicholas T.
  Karonis, Caesar E. Ordo\~nez, Christina Sarosiek, Reinhard W. Schulte, John
  R. Winans, Alec M. Block, Courtney L. Hentz and James S. Welsh","A Comparison of Proton Stopping Power Measured with Proton CT and x-ray
  CT in Fresh Post-Mortem Porcine Structures","Accepted for publication in Medical Physics",,"10.1002/mp.15334",,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Purpose: Currently, calculations of proton range in proton therapy patients
are based on a conversion of CT Hounsfield Units of patient tissues into proton
relative stopping power. Uncertainties in this conversion necessitate larger
proximal and distal planned target volume margins. Proton CT can potentially
reduce these uncertainties by directly measuring proton stopping power. We aim
to demonstrate proton CT imaging with complex porcine samples, to analyze in
detail three-dimensional regions of interest, and to compare proton stopping
powers directly measured by proton CT to those determined from x-ray CT scans.
  Methods: We have used a prototype proton imaging system with single proton
tracking to acquire proton radiography and proton CT images of a sample of
porcine pectoral girdle and ribs, and a pig's head. We also acquired close in
time x-ray CT scans of the same samples, and compared proton stopping power
measurements from the two modalities. In the case of the pig's head, we
obtained x-ray CT scans from two different scanners, and compared results from
high-dose and low-dose settings.
  Results: Comparing our reconstructed proton CT images with images derived
from x-ray CT scans, we find agreement within 1% to 2% for soft tissues, and
discrepancies of up to 6% for compact bone. We also observed large
discrepancies, up to 40%, for cavitated regions with mixed content of air, soft
tissue, and bone, such as sinus cavities or tympanic bullae.
  Conclusions: Our images and findings from a clinically realistic proton CT
scanner demonstrate the potential for proton CT to be used for low-dose
treatment planning with reduced margins.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:24:44 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 21:22:50 GMT""},{""version"":""v3"",""created"":""Fri, 29 Oct 2021 15:46:40 GMT""}]","2021-11-23"
"2012.06630","Maciej Fidrysiak","Maciej Fidrysiak and J\'ozef Spa{\l}ek","Universal collective modes from strong electronic correlations: Modified
  $1/\mathcal{N}_f$ theory with application to high-$T_c$ cuprates",,"Phys. Rev. B 103, 165111 (2021)","10.1103/PhysRevB.103.165111",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A nonzero-temperature technique for strongly correlated electron lattice
systems, combining elements of both variational wave function (VWF) approach
and expansion in the inverse number of fermionic flavors ($1/\mathcal{N}_f$),
is developed. The departure point, VWF method, goes beyond the renormalized
mean-field theory and provides semi-quantitative description of principal
equilibrium properties of high-$T_c$ superconducting cuprates. The developed
here scheme of VWF+$1/\mathcal{N}_f$, in the leading order provides dynamical
spin and charge responses around the VWF solution, generalizing the
weak-coupling spin-fluctuation theory to the regime of strong correlations.
Thermodynamic corrections to the correlated saddle-point state arise
systematically at consecutive orders. Explicitly, VWF+$1/\mathcal{N}_f$ is
applied to evaluate dynamical response functions for the hole-doped Hubbard
model and compared with available determinant quantum-Monte-Carlo data,
yielding a good overall agreement in the regime of coherent collective-mode
dynamics. The emergence of well-defined spin and charge excitations from the
incoherent continua is explicitly demonstrated and a non-monotonic dependence
of the charge-excitation energy on the interaction magnitude is found. The
charge-mode energy saturates slowly when approaching the strong-coupling limit,
which calls for a reevaluation of the $t$-$J$-model approach to the charge
dynamics in favor of more general $t$-$J$-$U$ and $t$-$J$-$U$-$V$ models. The
results are also related to recent inelastic resonant $X$-ray and neutron
scattering experiments for the high-$T_c$ cuprates.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:27:05 GMT""},{""version"":""v2"",""created"":""Fri, 9 Apr 2021 14:41:57 GMT""}]","2021-04-12"
"2012.06631","Carlo Marconi","Carlo Marconi, Albert Aloy, Jordi Tura and Anna Sanpera","Entangled symmetric states and copositive matrices",,"Quantum 5, 561 (2021)","10.22331/q-2021-10-07-561",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Entanglement in symmetric quantum states and the theory of copositive
matrices are intimately related concepts. For the simplest symmetric states,
i.e., the diagonal symmetric (DS) states, it has been shown that there exists a
correspondence between exceptional (non-exceptional) copositive matrices and
non-decomposable (decomposable) Entanglement Witnesses (EWs). Here we show that
EWs of symmetric, but not DS, states can also be constructed from extended
copositive matrices, providing new examples of bound entangled symmetric
states, together with their corresponding EWs, in arbitrary odd dimensions.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:41:12 GMT""},{""version"":""v2"",""created"":""Sun, 27 Dec 2020 15:49:59 GMT""},{""version"":""v3"",""created"":""Mon, 4 Oct 2021 10:41:13 GMT""},{""version"":""v4"",""created"":""Tue, 5 Oct 2021 08:22:58 GMT""}]","2021-10-13"
"2012.06632","Xiang Li","Xiang Li, Rebecca Boll, Daniel Rolles, and Artem Rudenko","Simple model for sequential multiphoton ionization by ultra-intense
  x-rays",,"Phys. Rev. A 104, 033115 (2021)","10.1103/PhysRevA.104.033115",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A simple model for sequential multiphoton ionization by ultra-intense x-rays
is presented. The derived scaling of the ion yield with pulse energy
quantitatively reproduces the experimental data, which shows that the ion yield
increases according to the ""power law"" behavior typical of multiphoton
ionization, followed by saturation at high pulse energies. The calculated
average time interval between ionizations for producing ions at a certain
charge state is found to be proportional to the pulse duration and independent
of all other x-ray pulse parameters. This agrees with previous studies where
the kinetic energy of fragment ions with a given charge state produced by
intense x-ray ionization of molecules was found to be independent of the pulse
energy, but to increase with smaller pulse duration due to the smaller time
interval between ionizations.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:54:13 GMT""}]","2021-09-29"
"2012.06633","Julie Rowlett","Susanne Menden-Deuer, Medet Nursultanov, Sinead Collins, Tatiana
  Rynearson, and Julie Rowlett","Biodiversity of marine microbes is safeguarded by phenotypic variability
  in ecological traits",,,"10.1371/journal.pone.0254799",,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Why, contrary to theoretical predictions, do marine microbe communities
harbor tremendous phenotypic heterogeneity? How can so many marine microbe
species competing in the same niche coexist? We discovered a unifying
explanation for both phenomena by investigating a non-cooperative game that
interpolates between individual-level competitions and species-level outcomes.
We identified all equilibrium strategies of the game. These strategies are
characterized by maximal phenotypic heterogeneity. They are also neutral
towards each other in the sense that an unlimited number of species can
co-exist while competing according to the equilibrium strategies. Whereas prior
theory predicts that natural selection would minimize trait variation around an
optimum value, here we obtained a rigorous mathematical proof that species with
maximally variable traits are those that endure. This discrepancy may reflect a
disparity between predictions from models developed for larger organisms in
contrast to our microbe-centric model. Rigorous mathematics proves that
phenotypic heterogeneity is itself a mechanistic underpinning of microbial
diversity. This discovery has fundamental ramifications for microbial ecology
and may represent an adaptive reservoir sheltering biodiversity in changing
environmental conditions.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:59:21 GMT""},{""version"":""v2"",""created"":""Sun, 17 Jan 2021 14:53:29 GMT""}]","2021-08-06"
"2012.06634","Javier Galan Lacarra","Javier Galan","Axion search with BabyIAXO in view of IAXO","6 pages, ICHEP 2020 Virtual conference",,,,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Axions are a natural consequence of the Peccei-Quinn mechanism, the most
compelling solution to the strong-CP problem. Similar axion-like particles
(ALPs) also appear in a number of possible extensions of the Standard Model,
notably in string theories. Both axions and ALPs are very well motivated
candidates for Dark Matter, and in addition, they would be copiously produced
at the sun's core. A relevant effort during the last decade has been the CAST
experiment at CERN, the most sensitive axion helioscope to-date. The
International Axion Observatory (IAXO) is a large-scale 4th generation
helioscope. As its primary physics goal, IAXO will look for solar axions or
ALPs with a signal to background ratio of about 5 orders of magnitude higher
than CAST. Recently the IAXO collaboration has proposed and intermediate
experimental stage, BabyIAXO, conceived to test all IAXO subsystems (magnet,
optics, detectors and sun-tracking systems) at a relevant scale for the final
system and thus serve as pathfinder for IAXO but at the same time as a
fully-fledged helioscope with record and relevant physics reach in itself with
potential for discovery. BabyIAXO was endorsed by the Physics Review committee
of DESY last May 2019. Here we will review the status and prospects of BabyIAXO
and its potential to probe the most physics motivated regions of the axion &
ALPs parameter space.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:04:57 GMT""}]","2020-12-15"
"2012.06635","Yufeng Luo","Yufeng Luo, Roland Haas, Qian Zhang, Gabrielle Allen","DataVault: A Data Storage Infrastructure for the Einstein Toolkit","17 pages, 3 figures, 2 tables",,"10.1088/1361-6382/abf9b5",,"gr-qc cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data sharing is essential in the numerical simulations research. We introduce
a data repository, DataVault, that is designed for data sharing, search and
analysis. A comparative study of existing repositories is performed to analyze
features that are critical to a data repository. We describe the architecture,
workflow, and deployment of DataVault, and provide three use-case scenarios for
different communities to facilitate the use and application of DataVault.
Potential features are proposed and we outline the future development for these
features.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:05:32 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 16:30:29 GMT""}]","2021-07-07"
"2012.06636","Sergey Victor Ludkowski","Sergey V. Ludkowski","Smashed products of topological left quasigroups","20 pages. arXiv admin note: text overlap with arXiv:1812.04508",,,,"math.GR math.AT","http://creativecommons.org/licenses/by/4.0/","  In this article smashed products of topological left quasigroups are
scrutinized. Quotients of topological fan quasigroups are investigated. Skew
smashed products of fan quasigroups and their structure also are studied.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:05:54 GMT""}]","2020-12-15"
"2012.06637","Satomi Okada","Shinsuke Kawai, Nobuchika Okada, Satomi Okada","Low energy implications of cosmological data in $U(1)_X$ Higgs inflation","10 pages, 5 figures","Phys. Rev. D 103, 035026 (2021)","10.1103/PhysRevD.103.035026",,"hep-ph astro-ph.CO hep-ex","http://creativecommons.org/licenses/by/4.0/","  A scalar field having the Coleman-Weinberg type effective potential arises in
various contexts of particle physics and serves as a useful framework for
discussing cosmic inflation. According to recent studies based on the Markov
chain Monte Carlo analysis, the coefficients of such an effective potential are
severely constrained by the cosmological data. We investigate the impact of
this observation on the physics beyond the Standard Model, focusing on an
inflationary model based on the $U(1)_X$-extended Standard Model as a
well-motivated example. We examine the parameter region that is not excluded by
the Large Hadron Collider (LHC) Run-2 at 139 fb${}^{-1}$ integrated luminosity,
and show that the model parameters can be further constrained by the
High-Luminosity LHC experiments in the near future. We also comment on the
possible reheating mechanism and the dark matter candidates of this scenario.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:10:18 GMT""}]","2021-03-03"
"2012.06638","Nemanja Jovanovic","N. Jovanovic, B. Calvin, M. Porter, T. Schofield, J. Wang, M. Roberts,
  G. Ruane, J. K. Wallace, R. Bartos, J. Pezzato, J. Colborn, J. R. Delorme, D.
  Echeverri, D. Mawet, C. Z. Bond, S. Cetre, S. Lilley, S. Ragland, P.
  Wizinowich, R. Jensen-Clem","Enhanced high-dispersion coronagraphy with KPIC phase II: design,
  assembly and status of sub-modules","12 pages, 8 figures, Proceedings of SPIE",,,,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The Keck Planet Imager and Characterizer (KPIC) is a purpose-built instrument
for high-dispersion coronagraphy in the K and L bands on Keck. This instrument
will provide the first high resolution (R$>$30,000) spectra of known directly
imaged exoplanets and low-mass brown dwarf companions visible in the northern
hemisphere.
  KPIC is developed in phases. Phase I is currently at Keck in the early
operations stage, and the phase II upgrade will deploy in late 2021. The goal
of phase II is to maximize the throughput for planet light and minimize the
stellar leakage, hence reducing the exposure time needed to acquire spectra
with a given signal-to-noise ratio. To achieve this, KPIC phase II exploits
several innovative technologies that have not been combined this way before.
These include a 1000-element deformable mirror for wavefront correction and
speckle control, a set of lossless beam shaping optics to maximize coupling
into the fiber, a pupil apodizer to suppress unwanted starlight, a pupil plane
vortex mask to enable the acquisition of spectra at and within the diffraction
limit, and an atmospheric dispersion compensator. These modules, when combined
with the active fiber injection unit present in phase I, will make for a highly
efficient exoplanet characterization platform.
  In this paper, we will present the final design of the optics and
opto-mechanics and highlight some innovative solutions we implemented to
facilitate all the new capabilities. We will provide an overview of the
assembly and laboratory testing of the sub-modules and some of the results.
Finally, we will outline the deployment timeline.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:13:25 GMT""}]","2020-12-15"
"2012.06639","Sergey Victor Ludkowski","S.V. Ludkowski","Octonion random functions and integration of stochastic PDEs","31 pages",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  In the article random functions in modules over the octonion algebra and
Cayley-Dickson algebras are investigated. For their study transition measures
with values in the octonion algebra and Cayley-Dickson algebras are used.
Stochastic integrals over these algebras are studied. They are applied to
integration of stochastic PDEs. This approach permits subsequently to analyze
and integrate PDEs of orders higher than two of different types including
parabolic, elliptic and hyperbolic.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:14:05 GMT""}]","2020-12-15"
"2012.06640","Hongqi Xu Professor","Yuanjie Chen, Shaoyun Huang, Dong Pan, Jianhong Xue, Li Zhang, Jianhua
  Zhao, and H. Q. Xu","Strong and tunable spin-orbit interaction in a single crystalline InSb
  nanosheet","24 pages, 5 figures, Supplementary Information","npj 2D Mater. Appl. 5, 3 (2021)","10.1038/s41699-020-00184-y",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A dual-gate InSb nanosheet field-effect device is realized and is used to
investigate the physical origin and the controllability of the spin-orbit
interaction in a narrow bandgap semiconductor InSb nanosheet. We demonstrate
that by applying a voltage over the dual gate, efficiently tuning of the
spin-orbit interaction in the InSb nanosheet can be achieved. We also find the
presence of an intrinsic spin-orbit interaction in the InSb nanosheet at zero
dual-gate voltage and identify its physical origin as a build-in asymmetry in
the device layer structure. Having a strong and controllable spin-orbit
interaction in an InSb nanosheet could simplify the design and realization of
spintronic deceives, spin-based quantum devices and topological quantum
devices.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:23:48 GMT""}]","2021-01-05"
"2012.06641","Jiayin Dong","Jiayin Dong, Yan-Fei Jiang and Phil Armitage","Boundary Layer Circumplanetary Accretion: How Fast Could an Unmagnetized
  Planet Spin Up Through Its Disk?","15 pages, 11 figures, submitted to AAS Journals",,"10.3847/1538-4357/ac1941",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gas giant planets are expected to accrete most of their mass via a
circumplanetary disk. If the planet is unmagnetized and initially slowly
rotating, it will accrete gas via a radially narrow boundary layer and rapidly
spin up. Radial broadening of the boundary layer as the planet spins up reduces
the specific angular momentum of accreted gas, allowing the planet to find a
terminal rotation rate short of the breakup rate. Here, we use axisymmetric
viscous hydrodynamic simulations to quantify the terminal rotation rate of
planets accreting from their circumplanetary disks. For an isothermal
planet-disk system with a disk scale height $h/r =0.1$ near the planetary
surface, spin up switches to spin down at between 70\% and 80\% of the planet's
breakup angular velocity. In a qualitative difference from vertically-averaged
models -- where spin down can co-exist with mass accretion -- we observe
\emph{decretion} accompanying solutions where angular momentum is being lost.
The critical spin rate depends upon the disk thickness near the planet. For an
isothermal system with a disk scale height of $h/r = 0.15$ near the planet, the
critical spin rate drops to between 60\% and 70\% of the planet's breakup
angular velocity. In the disk outside the boundary layer, we identify
meridional circulation flows, which are unsteady and instantaneously asymmetric
across the mid-plane. The simulated flows are strong enough to vertically
redistribute solid material in early-stage satellite formation. We discuss how
extrasolar planetary rotation measurements, when combined with spectroscopic
and variability studies of protoplanets with circumplanetary disks, could
determine the role of magnetic and non-magnetic processes in setting giant
planet spins.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:24:58 GMT""}]","2021-11-17"
"2012.06642","Igor Tsukerman","Igor Tsukerman","Trefftz Functions for Nonlocal Electrostatics","17 pages, 6 figures. A known copy-and-paste error in the December
  2020 version corrected",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electrostatic interactions in solvents play a major role in biophysical
systems. There is a consensus in the literature that the dielectric response of
aqueous solutions is nonlocal: polarization depends on the electric field not
only at a given point but in the vicinity of that point as well. This is
typically modeled via a convolution of the electric field with an appropriate
integral kernel.
  A primary problem with nonlocal models is high computational cost. A
secondary problem is restriction of convolution integrals to the solvent, as
opposed to their evaluation over the whole space.
  The paper develops a computational tool alleviating the ""curse of
nonlocality"" and helping to handle the integration correctly. This tool is
Trefftz approximations, which tend to furnish much higher accuracy than
traditional polynomial ones. In the paper, Trefftz approximations are developed
for problems of nonlocal electrostatics, with the goal of numerically
""localizing"" the original nonlocal problem. This approach can be extended to
nonlocal problems in other areas of computational mathematics, physics and
engineering.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:26:51 GMT""},{""version"":""v2"",""created"":""Sat, 13 Feb 2021 01:40:48 GMT""}]","2021-02-16"
"2012.06643","Karla Z. Arellano-C\'ordova","Karla. Z. Arellano-C\'ordova, C\'esar Esteban, Jorge Garc\'ia-Rojas,
  J. Eduardo M\'endez-Delgado","On the radial abundance gradients of nitrogen and oxygen in the inner
  Galactic disc","18 pages, 11 figures, 5 tables. Accepted for publication in MNRAS",,"10.1093/mnras/staa3903",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present optical spectra of nine Galactic H II regions observed with the
10.4 m Gran Telescopio Canarias telescope and located at Galactocentric
distances (RG) from 4 to 8 kpc. The distances of the objects have been revised
using Gaia DR2 parallaxes. We determine the electron temperature for all the
nebulae, which allows a precise computation of their ionic abundances. We have
included published data of an additional sample of Galactic H II regions,
providing a final data set of 42 objects. The shape of the radial gradients of
O/H and N/H is linear and constant, discarding any substantial change of the
slope, at least for RG between 4 and 17 kpc. The small dispersion of the O/H
and N/H values with respect to the computed gradients implies the absence of
significant azimuthal variations of the chemical abundances, at least in the
quadrant covered by our observations. We find an almost flat N/O versus O/H
diagram relation. This result is not observed in other nearby spiral galaxy
except M31. Finally, we compare our computed gradients with those obtained
using far infrared (FIR) spectra. We confirm the significant offset in the N/O
distribution between the optical and FIR observations. Possible explanations
involve ionization correction factors and the strong dependence on density of
the abundance determinations based on FIR lines.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:29:03 GMT""}]","2021-01-27"
"2012.06644","Siddharth Mysore","Siddharth Mysore, Bassel Mabsout, Renato Mancuso, Kate Saenko","Regularizing Action Policies for Smooth Control with Reinforcement
  Learning","Accepted for publication to ICRA 2021",,,,"cs.RO cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A critical problem with the practical utility of controllers trained with
deep Reinforcement Learning (RL) is the notable lack of smoothness in the
actions learned by the RL policies. This trend often presents itself in the
form of control signal oscillation and can result in poor control, high power
consumption, and undue system wear. We introduce Conditioning for Action Policy
Smoothness (CAPS), an effective yet intuitive regularization on action
policies, which offers consistent improvement in the smoothness of the learned
state-to-action mappings of neural network controllers, reflected in the
elimination of high-frequency components in the control signal. Tested on a
real system, improvements in controller smoothness on a quadrotor drone
resulted in an almost 80% reduction in power consumption while consistently
training flight-worthy controllers. Project website: http://ai.bu.edu/caps
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:35:24 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 18:57:02 GMT""}]","2021-05-28"
"2012.06645","Manuel L\'opez Galv\'an","Manuel Lopez Galvan","An approximate closed formula for European Mortgage Options",,,,,"q-fin.CP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to investigate the use of close formula
approximation for pricing European mortgage options. Under the assumption of
logistic duration and normal mortgage rates the underlying price at the option
expiry is approximated by shifted lognormal or regular lognormal distribution
by matching moments. Once the price function is approximated by lognormal
distributions, the option price can be computed directly as an integration of
the distribution function over the payoff at the option expiry by using
Black-Scholes-Merton close formula. We will see that lower curvature levels
correspond to positively skewness price distributions and in this case
lognormal approximation leads to close parametric formula representation in
terms of all model parameters. The proposed methodologies are tested against
Monte Carlo approach under different market and contract parameters and the
tests confirmed that the close form approximation have a very good accuracy.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:35:27 GMT""}]","2020-12-15"
"2012.06646","Andrew Kassen","Andrew Kassen and Varun Shankar and Aaron L Fogelson","A fine-grained parallelization of the immersed boundary method","14 pages, 5 figures",,,,"cs.DC cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  We present new algorithms for the parallelization of Eulerian-Lagrangian
interaction operations in the immersed boundary method. Our algorithms rely on
two well-studied parallel primitives: key-value sort and segmented reduce. The
use of these parallel primitives allows us to implement our algorithms on both
graphics processing units (GPUs) and on other shared memory architectures. We
present strong and weak scaling tests on problems involving scattered points
and elastic structures. Our tests show that our algorithms exhibit near-ideal
scaling on both multicore CPUs and GPUs.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:35:32 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 21:09:03 GMT""},{""version"":""v3"",""created"":""Fri, 29 Oct 2021 19:40:02 GMT""}]","2021-11-02"
"2012.06647","Utkarsh Verma","Utkarsh Verma, Narayan Rangaraj","Analysis of multi-registry kidney exchange program with individual
  rationality constraints",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  Kidney exchange programs have been developed to overcome the compatibility
challenges for the patient with incompatible donors in kidney transplantation.
A registry of such incompatible donor-recipient pairs is created, and
compatibility is achieved through the exchange of donors. Single-center kidney
exchange registries do not have a significant pool size for achieving the full
benefits of the kidney exchange program. Thus multi-registry exchange
transplants seem to be a natural way forward. There are various challenges in
multi-registry exchange programs, such as different constraints for each
registry, varying bound on cycle lengths, and data sharing among registries.
Researchers have proposed different merging mechanisms with a sequential
merger, full merger with fair allocations, and full merger without any
restrictions. To form a stable multi-registry sharing mechanism, registries
should be individually rational both in the long run as well as in the short
run. In this paper, an Integer Programming model for a multi-registry exchange
program has been proposed with individual rationality constraints for each
registry. A simulation study is conducted to compare the benefits of
multi-registry programs with individual registry allocations on Indian data,
and multiple analyses have been done. It was concluded that registries with
lower arrival rates could benefit 7-9\% in terms of the number of transplants
and 4-6\% in terms of quality of matches in a typical kidney exchange registry.
Registry with more hard to match patients will benefit significantly larger
than registries with more easy to match patients.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:36:25 GMT""}]","2020-12-15"
"2012.06648","Zicheng Wang","Pranav Hanagal, Kevin Leder, Zicheng Wang","Large Deviations of Cancer Recurrence Timing",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study large deviation events in the timing of disease recurrence. In
particular, we are interested in modeling cancer treatment failure due to
mutation-induced drug resistance. We first present a two-type branching process
model of this phenomenon, where an initial population of cells that are
sensitive to therapy can produce mutants that are resistant to the therapy. In
this model, we investigate two random times, the recurrence time and the
crossover time. Recurrence time is defined as the first time that the
population size of mutant cells exceeds a given proportion of the initial
population size of drug-sensitive cells. Crossover time is defined as the first
time that the resistant cell population dominates the total population. We
establish convergence in probability results for both recurrence and crossover
time. We then develop expressions for the large deviations rate of early
recurrence and early crossover events. We characterize how the large deviation
rates and rate functions depend on the initial size of the mutant cell
population. We finally look at the large deviations rate of early recurrence
conditioned on the number of mutant clones present at recurrence in the special
case of a deterministically decaying sensitive population. We find that if
recurrence occurs before the predicted law of large numbers limit then there
will likely be an increase in the number of clones present at recurrence time.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:38:23 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 19:24:47 GMT""}]","2021-08-06"
"2012.06649","Mark  Leggett B.Sc.  Ph.D.","L. Mark W. Leggett and David. A. Ball","Forecasts of the trend in global-mean temperature to 2100 arising from
  the scenarios of first-difference CO2 and peak fossil fuel",,,,,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  Two future scenarios that are not explicitly in the range of scenarios (the
Representative Concentration Pathway scenarios) utilised by the IPCC. These two
scenarios are the emissions trend under peak fossil fuel (for example, Mohr et
al., 2015); and the climate sensitivity determinable from the relationship
between first-difference CO2 and temperature recently shown by Leggett and Ball
(2015). This paper provides forecasts of a global surface temperature
trajectory to 2100 resulting from the effect of these two scenarios. The
time-series models developed both displayed high statistical significance and
converged in their forecasts, so adding to the potential robustness of the
findings. Under the effect of the combination of the peak fossil fuel and
first-difference CO2 scenarios, we found that temperature is forecast to
continue to rise, but only gently, until around 2023 where it reaches a level
slightly higher than at present; and from then to display an also gentle steady
decrease. It is shown that this trajectory is markedly lower than that
generated by the IPCC business-as-usual level-of-CO2 (RCP8.5) model (Riahi et
al. 2011). These lower results are evidence that the climate problem may
require less future preventative action than is presently being considered
necessary. If so, it is stressed that the same evidence is support for the case
that the peak fossil fuel problem would require ameliorative action. This
globally required action is the same as it would have been for climate (as
embodied in the Paris Agreement on Climate Change of the 21st Conference of the
Parties of the UNFCCC in Paris adopted in 2015): the rapid transition to a
predominantly renewable global energy system.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:40:21 GMT""}]","2020-12-15"
"2012.06650","Manyi Li","Manyi Li, Hao Zhang","D$^2$IM-Net: Learning Detail Disentangled Implicit Fields from Single
  Images",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first single-view 3D reconstruction network aimed at
recovering geometric details from an input image which encompass both
topological shape structures and surface features. Our key idea is to train the
network to learn a detail disentangled reconstruction consisting of two
functions, one implicit field representing the coarse 3D shape and the other
capturing the details. Given an input image, our network, coined D$^2$IM-Net,
encodes it into global and local features which are respectively fed into two
decoders. The base decoder uses the global features to reconstruct a coarse
implicit field, while the detail decoder reconstructs, from the local features,
two displacement maps, defined over the front and back sides of the captured
object. The final 3D reconstruction is a fusion between the base shape and the
displacement maps, with three losses enforcing the recovery of coarse shape,
overall structure, and surface details via a novel Laplacian term.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:42:52 GMT""},{""version"":""v2"",""created"":""Thu, 17 Dec 2020 13:16:00 GMT""}]","2020-12-18"
"2012.06651","Pavel Naumov","Sophia Epstein, Pavel Naumov","Epistemic Logic of Know-Who","To appear in Proceedings of 35th AAAI Conference on Artificial
  Intelligence (AAAI 21), February 2-9, 2021",,,,"cs.AI cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper suggests a definition of ""know who"" as a modality using
Grove-Halpern semantics of names. It also introduces a logical system that
describes the interplay between modalities ""knows who"", ""knows"", and ""for all
agents"". The main technical result is a completeness theorem for the proposed
system.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:45:04 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 02:09:32 GMT""}]","2021-03-04"
"2012.06652","Stefano Guarino","Stefano Guarino, Enrico Mastrostefano, Massimo Bernaschi, Alessandro
  Celestini, Marco Cianfriglia, Davide Torre, Lena Zastrow","Inferring urban social networks from publicly available data",,"Future Internet 2021, 13(5)","10.3390/fi13050108",,"cs.SI cs.MA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The emergence of social networks and the definition of suitable generative
models for synthetic yet realistic social graphs are widely studied problems in
the literature. By not being tied to any real data, random graph models cannot
capture all the subtleties of real networks and are inadequate for many
practical contexts -- including areas of research, such as computational
epidemiology, which are recently high on the agenda. At the same time, the
so-called contact networks describe interactions, rather than relationships,
and are strongly dependent on the application and on the size and quality of
the sample data used to infer them. To fill the gap between these two
approaches, we present a data-driven model for urban social networks,
implemented and released as open source software. Given a territory of
interest, and only based on widely available aggregated demographic and
social-mixing data, we construct an age-stratified and geo-referenced synthetic
population whose individuals are connected by ""strong ties"" of two types:
intra-household (e.g., kinship) or friendship. While household links are
entirely data-driven, we propose a parametric probabilistic model for
friendship, based on the assumption that distances and age differences play a
role, and that not all individuals are equally sociable. The demographic and
geographic factors governing the structure of the obtained network, under
different configurations, are thoroughly studied through extensive simulations
focused on three Italian cities of different size.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:47:00 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 19:59:01 GMT""}]","2023-02-16"
"2012.06653","Manuel Francisco Catacora Rios","M. Catacora-Rios, G. B. King, A. E. Lovell, F. M. Nunes","Statistical tools for a better optical model",,,"10.1103/PhysRevC.104.064611",,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  Background: Modern statistical tools provide the ability to compare the
information content of observables and provide a path to explore which
experiments would be most useful to give insight into and constrain theoretical
models. Purpose: In this work we study three such tools in the context of
nuclear reactions with the goal of constraining the optical potential. Method:
The three statistical tools examined are: i) the principal component analysis;
ii) the sensitivity analysis based on derivatives; and iii) the Bayesian
evidence. We first apply these tools to a toy-model case, comparing the form of
the imaginary part of the optical potential. Then we consider two different
reaction observables, elastic angular distributions and polarization data for
reactions on 48Ca at two different beam energies. Results: For the toy-model
case, we find significant discrimination power in the sensitivities and the
Bayesian evidence, showing clearly that the volume imaginary term is more
useful to describe scattering at higher energies. When comparing between
elastic cross sections and polarization data using realistic optical models,
sensitivity studies indicate that both observables are roughly equally
sensitive but the variability of the optical model parameters is strongly angle
dependent. The Bayesian evidence shows some variability between the two
observables, but the Bayes factor obtained is not sufficient to discriminate
between angular distributions and polarization. Conclusions: From the cases
considered, we conclude that in general elastic scattering angular
distributions have similar impact in constraining the optical potential
parameters compared to the polarization data. The angular ranges for the
optimum experimental constraints can vary significantly with the observable
considered.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:47:09 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 22:40:46 GMT""}]","2021-12-22"
"2012.06654","arXiv Admin","Souza Marisa","The extension of Elementary Numerical Operator Theory: Simply Generic,
  Right-Stochastically Non-Gaussian, Sub-Canonically H-Positive Definite
  Monoids","This article has been withdrawn by arXiv administrators due to
  disputed authorship",,,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  The concept of polytopes was a milestone in elementary integral group theory.
In this article, we will extend the concept of contra-linearly stochastic lines
to H-Positive Definite Monoids. We will show that by adding the Non-Gaussian
assumption, the problem of ordinary Elementary Numerical Operator will have
Sub-Canonically properties. Moreover, we will discuss the possibility to
classify associative, bijective, and conditionally covariant subalgebras. The
prove is given in each section.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:47:25 GMT""},{""version"":""v2"",""created"":""Thu, 16 Dec 2021 21:03:29 GMT""}]","2022-12-06"
"2012.06655","Flavio Martins","Charles Paulino de Oliveira, Elisangela Martins de S\'a and Fl\'avio
  Vin\'icius Cruzeiro Martins","A multi-period and bi-objective approach for locating ambulances: a case
  study in Belo Horizonte, Brazil",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work aims to apply the Facility Location Problem in the Emergency
Medical Service (EMS) of Belo Horizonte, Brazil. The objective is to improve
two previous optimization models from literature to handle base locations and
ambulances allocation/relocation problems. The proposed multi-period models
introduce the concept of relocation to the local EMS, which allows ambulances
to move among bases in different periods to raise the system coverage. This
paper also proposes a bi-objective approach aiming to minimize the number of
bases and maximize the coverage of demands, which is solved using the
epsilon-constraint method. Results show that coverage levels increase by up to
31% for the deterministic approach and up to 24% for the probabilistic
approach. Ambulances' relocation optimization might improve coverage levels by
up to 21% for the deterministic approach and up to 15% for the probabilistic
approach when change scenarios from static to multi-period. Also, since the
multi-period model solutions result in installing a larger number of bases, the
bi-objective approach is a powerful tool for the decision-maker. Bi-objective
results suggest modest increments in the objective function when the stations'
number exceeds 28 for the deterministic approach. The probabilistic approach
increments in the objective function start to narrow above 30 installed
stations.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:49:30 GMT""}]","2020-12-15"
"2012.06656","Siddharth Mysore","Siddharth Mysore, Bassel Mabsout, Kate Saenko, Renato Mancuso","How to Train your Quadrotor: A Framework for Consistently Smooth and
  Responsive Flight Control via Reinforcement Learning",,"ACM Transactions on Cyber-Physical Systems, Volume 5, Issue 4,
  October 2021","10.1145/3466618",,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We focus on the problem of reliably training Reinforcement Learning (RL)
models (agents) for stable low-level control in embedded systems and test our
methods on a high-performance, custom-built quadrotor platform. A common but
often under-studied problem in developing RL agents for continuous control is
that the control policies developed are not always smooth. This lack of
smoothness can be a major problem when learning controllers %intended for
deployment on real hardware as it can result in control instability and
hardware failure. Issues of noisy control are further accentuated when training
RL agents in simulation due to simulators ultimately being imperfect
representations of reality - what is known as the reality gap. To combat issues
of instability in RL agents, we propose a systematic framework,
`REinforcement-based transferable Agents through Learning' (RE+AL), for
designing simulated training environments which preserve the quality of trained
agents when transferred to real platforms. RE+AL is an evolution of the
Neuroflight infrastructure detailed in technical reports prepared by members of
our research group. Neuroflight is a state-of-the-art framework for training RL
agents for low-level attitude control. RE+AL improves and completes Neuroflight
by solving a number of important limitations that hindered the deployment of
Neuroflight to real hardware. We benchmark RE+AL on the NF1 racing quadrotor
developed as part of Neuroflight. We demonstrate that RE+AL significantly
mitigates the previously observed issues of smoothness in RL agents.
Additionally, RE+AL is shown to consistently train agents that are
flight-capable and with minimal degradation in controller quality upon
transfer. RE+AL agents also learn to perform better than a tuned PID
controller, with better tracking errors, smoother control and reduced power
consumption.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:50:27 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 23:56:48 GMT""}]","2021-10-14"
"2012.06657","Oktay Karakus Dr","Oktay Karaku\c{s}, Igor Rizaev, Alin Achim","A Simulation Study to Evaluate the Performance of the Cauchy Proximal
  Operator in Despeckling SAR Images of the Sea Surface","6 pages, 2 Figures. This work has been presented in IGARSS 2020",,,,"eess.IV eess.SP","http://creativecommons.org/licenses/by/4.0/","  The analysis of ocean surface is widely performed using synthetic aperture
radar (SAR) imagery as it yields information for wide areas under challenging
weather conditions, during day or night, etc. Speckle noise constitutes however
the main reason for reduced performance in applications such as classification,
ship detection, target tracking and so on. This paper presents an investigation
into the despeckling of SAR images of the ocean that include ship wake
structures, via sparse regularisation using the Cauchy proximal operator. We
propose a closed-form expression for calculating the proximal operator for the
Cauchy prior, which makes it applicable in generic proximal splitting
algorithms. In our experiments, we simulate SAR images of moving vessels and
their wakes. The performance of the proposed method is evaluated in comparison
to the L1 and TV norm regularisation functions. The results show a superior
performance of the proposed method for all the utilised images generated.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:58:05 GMT""}]","2020-12-15"
"2012.06658","Pietro Borrello","Pietro Borrello, Emilio Coppa, Daniele Cono D'Elia","Hiding in the Particles: When Return-Oriented Programming Meets Program
  Obfuscation","Published in the proceedings of DSN'21 (51st IEEE/IFIP Int. Conf. on
  Dependable Systems and Networks). Code and BibTeX entry available at
  https://github.com/pietroborrello/raindrop","2021 51st Annual IEEE/IFIP International Conference on Dependable
  Systems and Networks (DSN)","10.1109/DSN48987.2021.00064",,"cs.CR cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Largely known for attack scenarios, code reuse techniques at a closer look
reveal properties that are appealing also for program obfuscation. We explore
the popular return-oriented programming paradigm under this light, transforming
program functions into ROP chains that coexist seamlessly with the surrounding
software stack. We show how to build chains that can withstand popular static
and dynamic deobfuscation approaches, evaluating the robustness and overheads
of the design over common programs. The results suggest a significant amount of
computational resources would be required to carry a deobfuscation attack for
secret finding and code coverage goals.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:01:23 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 15:28:37 GMT""}]","2021-08-12"
"2012.06659","Yuzong Liu","Shaoshi Ling, Yuzong Liu","DeCoAR 2.0: Deep Contextualized Acoustic Representations with Vector
  Quantization","Submitted to ICASSP 2021",,,,"eess.AS cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent success in speech representation learning enables a new way to
leverage unlabeled data to train speech recognition model. In speech
representation learning, a large amount of unlabeled data is used in a
self-supervised manner to learn a feature representation. Then a smaller amount
of labeled data is used to train a downstream ASR system using the new feature
representations. Based on our previous work DeCoAR and inspirations from other
speech representation learning, we propose DeCoAR 2.0, a Deep Contextualized
Acoustic Representation with vector quantization. We introduce several
modifications over the DeCoAR: first, we use Transformers in encoding module
instead of LSTMs; second, we introduce a vector quantization layer between
encoder and reconstruction modules; third, we propose an objective that
combines the reconstructive loss with vector quantization diversity loss to
train speech representations. Our experiments show consistent improvements over
other speech representations in different data-sparse scenarios. Without
fine-tuning, a light-weight ASR model trained on 10 hours of LibriSpeech
labeled data with DeCoAR 2.0 features outperforms the model trained on the full
960-hour dataset with filterbank features.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:07:23 GMT""}]","2020-12-15"
"2012.06660","Xinye Chen","Xinye Chen","Understanding Spectral Graph Neural Network",,,"10.13140/RG.2.2.27579.03364/1",,"math.SP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The graph neural networks have developed by leaps and bounds in recent years
due to the restriction of traditional convolutional filters on non-Euclidean
structured data. Spectral graph theory mainly studies fundamental graph
properties using algebraic methods to analyze the spectrum of the adjacency
matrix of a graph, which lays the foundation of graph convolutional neural
networks. This report is more than notes and self-contained which comes from my
Ph.D. first-year report literature review part, it illustrates how to link
fundamentals of spectral graph theory to graph convolutional neural network
theory, and discusses the major spectral-based graph convolutional neural
networks. The practical applications of the graph neural networks defined in
the spectral domain is also reviewed.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:09:14 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 11:43:29 GMT""},{""version"":""v3"",""created"":""Wed, 29 Sep 2021 08:47:42 GMT""}]","2021-09-30"
"2012.06661","Mykola Khrypchenko","\'Erica Z. Fornaroli, Mykola Khrypchenko and Ednei A. Santulo Jr","Lie automorphisms of incidence algebras","Minor changes. Accepted for publication in Proceedings of the AMS",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X$ be a finite connected poset and $K$ a field. We give a full
description of the Lie automorphisms of the incidence algebra $I(X,K)$. In
particular, we show that they are in general not proper.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:09:41 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 13:52:13 GMT""},{""version"":""v3"",""created"":""Mon, 9 Aug 2021 00:28:26 GMT""}]","2021-08-10"
"2012.06662","Wenhao Yu","Wenhao Yu, C. Karen Liu, Greg Turk","Protective Policy Transfer",,,,,"cs.RO cs.LG","http://creativecommons.org/licenses/by/4.0/","  Being able to transfer existing skills to new situations is a key capability
when training robots to operate in unpredictable real-world environments. A
successful transfer algorithm should not only minimize the number of samples
that the robot needs to collect in the new environment, but also prevent the
robot from damaging itself or the surrounding environment during the transfer
process. In this work, we introduce a policy transfer algorithm for adapting
robot motor skills to novel scenarios while minimizing serious failures. Our
algorithm trains two control policies in the training environment: a task
policy that is optimized to complete the task of interest, and a protective
policy that is dedicated to keep the robot from unsafe events (e.g. falling to
the ground). To decide which policy to use during execution, we learn a safety
estimator model in the training environment that estimates a continuous safety
level of the robot. When used with a set of thresholds, the safety estimator
becomes a classifier for switching between the protective policy and the task
policy. We evaluate our approach on four simulated robot locomotion problems
and a 2D navigation problem and show that our method can achieve successful
transfer to notably different environments while taking the robot's safety into
consideration.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:10:54 GMT""}]","2020-12-15"
"2012.06663","Oktay Karakus Dr","Wanli Ma, Alin Achim, Oktay Karaku\c{s}","Exploiting the Dual-Tree Complex Wavelet Transform for Ship Wake
  Detection in SAR Imagery","9 pages, 3 figures",,,,"eess.IV eess.SP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we analyse synthetic aperture radar (SAR) images of the sea
surface using an inverse problem formulation whereby Radon domain information
is enhanced in order to accurately detect ship wakes. This is achieved by
promoting linear features in the images. For the inverse problem-solving stage,
we propose a penalty function, which combines the dual-tree complex wavelet
transform (DT-CWT) with the non-convex Cauchy penalty function. The solution to
this inverse problem is based on the forward-backward (FB) splitting algorithm
to obtain enhanced images in the Radon domain. The proposed method achieves the
best results and leads to significant improvement in terms of various
performance metrics, compared to state-of-the-art ship wake detection methods.
The accuracy of detecting ship wakes in SAR images with different frequency
bands and spatial resolution reaches more than 90%, which clearly demonstrates
an accuracy gain of 7% compared to the second-best approach.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:30:46 GMT""}]","2020-12-15"
"2012.06664","Pedram Hassanzadeh","Adam Subel, Ashesh Chattopadhyay, Yifei Guan and Pedram Hassanzadeh","Data-driven subgrid-scale modeling of forced Burgers turbulence using
  deep learning with generalization to higher Reynolds numbers via transfer
  learning",,"Physics of Fluids, 2021","10.1063/5.0040286",,"physics.flu-dyn physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  Developing data-driven subgrid-scale (SGS) models for large eddy simulations
(LES) has received substantial attention recently. Despite some success,
particularly in a priori (offline) tests, challenges have been identified that
include numerical instabilities in a posteriori (online) tests and
generalization (i.e., extrapolation) of trained data-driven SGS models, for
example to higher Reynolds numbers. Here, using the stochastically forced
Burgers turbulence as the test-bed, we show that deep neural networks trained
using properly pre-conditioned (augmented) data yield stable and accurate a
posteriori LES models. Furthermore, we show that transfer learning enables
accurate/stable generalization to a flow with 10x higher Reynolds number.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:33:24 GMT""}]","2021-02-05"
"2012.06665","Carlos A. Mar\'in V.","Carlos Mar\'in and Jorge poveda","Spin contribution to the perihelion precession in binary systems like
  OJ287: higher order corrections","20 pages, 1 figure. arXiv admin note: text overlap with
  arXiv:1802.03333",,"10.1007/s10509-021-04011-8",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  Higher order corrections are obtained for the perihelion precession in binary
systems like OJ287, Sagittarius A*-S2 and H1821+643 using both the
Schwarzschild metric and the Kerr metric to take into account the spin effect.
The corrections are performed considering the third root of the motion equation
and developing the expansion in terms of $\epsilon \equiv
r_s/\left(a(1-e^2)\right)$ and $\epsilon^{*} \equiv \left(1- \frac{2 \alpha
E'}{cJ}\right) \epsilon $.The results are compared with those obtained in a
previous paper.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:34:33 GMT""}]","2021-11-24"
"2012.06666","Mohammad Khodaei","Mohammad Khodaei and Panos Papadimitratos","Cooperative Location Privacy in Vehicular Networks: Why Simple Mix-zones
  are not Enough","19 pages, 15 Figures, IEEE Internet of Things Journal","IEEE Internet of Things Journal, 2021","10.1109/JIOT.2020.3043640",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vehicular communications disclose rich information about the vehicles and
their whereabouts. Pseudonymous authentication secures communication while
enhancing user privacy. To enhance location privacy, cryptographic mix-zones
were proposed to facilitate vehicles covertly transition to new ephemeral
credentials. The resilience to (syntactic and semantic) pseudonym linking
(attacks) highly depends on the geometry of the mix-zones, mobility patterns,
vehicle density, and arrival rates. We introduce a tracking algorithm for
linking pseudonyms before and after a cryptographically protected mix-zone. Our
experimental results show that an eavesdropper, leveraging standardized
vehicular communication messages and road layout, could successfully link 73%
of pseudonyms during non-rush hours and 62% of pseudonyms during rush hours
after vehicles change their pseudonyms in a mix-zone. To mitigate such
inference attacks, we present a novel cooperative mix-zone scheme that enhances
user privacy regardless of the vehicle mobility patterns, vehicle density, and
arrival rate to the mix-zone. A subset of vehicles, termed relaying vehicles,
are selected to be responsible for emulating non-existing vehicles. Such
vehicles cooperatively disseminate decoy traffic without affecting
safety-critical operations: with 50% of vehicles as relaying vehicles, the
probability of linking pseudonyms (for the entire interval) drops from 68% to
18%. On average, this imposes 28 ms extra computation overhead, per second, on
the Roadside Units (RSUs) and 4.67 ms extra computation overhead, per second,
on the (relaying) vehicle side; it also introduces 1.46 KB/sec extra
communication overhead by (relaying) vehicles and 45 KB/sec by RSUs for the
dissemination of decoy traffic. Thus, user privacy is enhanced at the cost of
low computation and communication overhead.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:37:22 GMT""}]","2020-12-15"
"2012.06667","Kelvin Kan","Kelvin Kan, James G Nagy and Lars Ruthotto","Avoiding The Double Descent Phenomenon of Random Feature Models Using
  Hybrid Regularization",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the ability of hybrid regularization methods to automatically
avoid the double descent phenomenon arising in the training of random feature
models (RFM). The hallmark feature of the double descent phenomenon is a spike
in the regularization gap at the interpolation threshold, i.e. when the number
of features in the RFM equals the number of training samples. To close this
gap, the hybrid method considered in our paper combines the respective
strengths of the two most common forms of regularization: early stopping and
weight decay. The scheme does not require hyperparameter tuning as it
automatically selects the stopping iteration and weight decay hyperparameter by
using generalized cross-validation (GCV). This also avoids the necessity of a
dedicated validation set. While the benefits of hybrid methods have been
well-documented for ill-posed inverse problems, our work presents the first use
case in machine learning. To expose the need for regularization and motivate
hybrid methods, we perform detailed numerical experiments inspired by image
classification. In those examples, the hybrid scheme successfully avoids the
double descent phenomenon and yields RFMs whose generalization is comparable
with classical regularization approaches whose hyperparameters are tuned
optimally using the test data. We provide our MATLAB codes for implementing the
numerical experiments in this paper at https://github.com/EmoryMLIP/HybridRFM.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:42:34 GMT""}]","2020-12-15"
"2012.06668","Christopher Caruvana","Christopher Caruvana, Jared Holshouser","Selection Games on Hyperspaces",,,"10.1016/j.topol.2021.107771",,"math.GN math.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we connect selection principles on a topological space to
corresponding selection principles on one of its hyperspaces. We unify
techniques and generalize theorems from the known results about selection
principles for common hyperspace constructions. This includes results of
Lj.D.R. Ko\v{c}inac, Z. Li, and others. We use selection games to generalize
selection principles and we work with strategies of various strengths for these
games. The selection games we work with are primarily abstract versions of the
selection principles of Rothberger, Menger, and Hurewicz type, as well as games
of countable fan tightness and selective separability. The hyperspace
constructions that we work with are the Vietoris and Fell topologies, both
upper and full, generated by ideals of closed sets. Using a new technique we
are able to extend straightforward connections between topological constructs
to connections between selection games related to those constructs. This
extension process works regardless of the length of the game, the kind of
selection being performed, or the strength of the strategy being considered.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:47:04 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 03:41:21 GMT""}]","2021-07-13"
"2012.06669","Stefano Markidis Prof.","Stefano Markidis, Vyacheslav Olshevsky, Gabor Toth, Yuxi Chen, Ivy
  Peng, Giovanni Lapenta, Tamas Gombosi","Kinetic Modeling of Magnetospheres","Preprint of accepted chapter in the AGU book ""Magnetospheres in the
  solar system""",,"10.1002/9781119815624.ch38",,"physics.space-ph physics.comp-ph physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents the state of the art of kinetic modeling techniques for
simulating plasma kinetic dynamics in magnetospheres. We describe the critical
numerical techniques for enabling large-scale kinetic simulations of
magnetospheres: parameter scaling, implicit Particle-in-Cell schemes, and
fluid-kinetic coupling. We show an application of these techniques to study
particle acceleration and heating in asymmetric magnetic reconnection in the
Ganymede magnetosphere.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:57:12 GMT""}]","2021-09-15"
"2012.06670","Yuya Ong","Yuya Jeremy Ong, Yi Zhou, Nathalie Baracaldo, Heiko Ludwig","Adaptive Histogram-Based Gradient Boosted Trees for Federated Learning","11 pages with 1 figure",,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated Learning (FL) is an approach to collaboratively train a model
across multiple parties without sharing data between parties or an aggregator.
It is used both in the consumer domain to protect personal data as well as in
enterprise settings, where dealing with data domicile regulation and the
pragmatics of data silos are the main drivers. While gradient boosted tree
implementations such as XGBoost have been very successful for many use cases,
its federated learning adaptations tend to be very slow due to using
cryptographic and privacy methods and have not experienced widespread use. We
propose the Party-Adaptive XGBoost (PAX) for federated learning, a novel
implementation of gradient boosting which utilizes a party adaptive histogram
aggregation method, without the need for data encryption. It constructs a
surrogate representation of the data distribution for finding splits of the
decision tree. Our experimental results demonstrate strong model performance,
especially on non-IID distributions, and significantly faster training run-time
across different data sets than existing federated implementations. This
approach makes the use of gradient boosted trees practical in enterprise
federated learning.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:01:35 GMT""}]","2020-12-15"
"2012.06671","Radim P\'anis","Radim P\'anis, Martin Kolo\v{s} and Zden\v{e}k Stuchl\'ik","Detection of chaotic behavior in time series","11 pages, 2 figures, to appear in the Proceedings of RAGtime 20-22.
  arXiv admin note: text overlap with arXiv:1905.01186",,,,"physics.comp-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deterministic chaos is phenomenon from nonlinear dynamics and it belongs to
greatest advances of twentieth-century science. Chaotic behavior appears apart
of mathematical equations also in wide range in observable nature, so as in
there originating time series. Chaos in time series resembles stochastic
behavior, but apart of randomness it is totally deterministic and therefore
chaotic data can provide us useful information. Therefore it is essential to
have methods, which are able to detect chaos in time series, moreover to
distinguish chaotic data from stochastic one. Here we present and discuss the
performance of standard and machine learning methods for chaos detection and
its implementation on two well known simple chaotic discrete dynamical systems
- Logistic map and Tent map, which fit to the most of the definitions of chaos.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:01:57 GMT""}]","2020-12-15"
"2012.06672","Gabriele Umbriaco Dr.","Gabriele Umbriaco","Exoplanets through extreme optics: from PLATO to SHARK-NIR","326 pages, 252 figures, 59 tables, PhD thesis, 2019, Doctoral School
  in Astronomy University of Padua,
  https://www.dfa.unipd.it/didattica/dottorati-di-ricerca/",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the last years, the Observatory of Padova (Istituto Nazionale di
Astrofisica - Osservatorio Astronomico di Padova) and the University of Padova
have been involved massively in projects dedicated to the exoplanets search,
both ground, and space-based. The activities concerning my Ph.D. have been
exploited both in the framework of the space projects and in the field of
ground instrumentation. PLATO, the acronym of ""PLAnetary Transits and
Oscillations of stars"", is a ESA mission o with the target to detect and
characterize exoplanets utilizing their transit on a bright star. The overall
instrumental layout consists of a multi-telescope concept instrument, composed
by several tens of telescope units, for which it has developed an
all-refractive optical solution. These devices are characterized by a very
large Field of View (>20 degrees on one side) with an optical quality that fits
most of the energy into a single sensor pixel. I participated in the Assembly,
Integration, and Verification (AIV) of the Telescope Optical Unit prototype, to
validate the AIV procedure and the telescope optical performance in-flight
conditions. SHARK-NIR, the acronym of ""System for coronagraphy with High order
Adaptive optics from R to K band - Near-Infrared"", is an instrument designed to
search and characterize the young exo-planetary system and star-forming regions
in the NIR domain, in coronagraphic direct imaging and spectroscopic mode. It
has been selected for the 2nd generation Large Binocular Telescope (LBT)
instruments, and it will take advantage of the excellent performance of the LBT
eXtreme Adaptive Optics (XAO) correction, necessary for SHARK-NIR to achieve
the best possible coronagraphic performance, which is mandatory to detect faint
planets orbiting around bright stars. Concerning SHARK, my activity has been
performing optical alignment and qualification of the instrument.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:08:10 GMT""}]","2020-12-15"
"2012.06673","Yuri  Kabanov","Ernst Eberlain, Yuri Kabanov, Thorsten Schmidt","Ruin Probabilities for a Sparre Andersen Model with Investments","17 pages",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We study a Sparre Andersen model in which the business activity of the
company is described by a compound renewal process with drift assuming that the
capital reserves are invested in a risky asset. The price of the latter is
assumed to evolve according to a geometric L\'evy process. We prove that the
asymptotic behavior of the ruin probability depends to a large extent only on
the properties of the price process.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:09:09 GMT""}]","2020-12-15"
"2012.06674","Azeem Ahmad","Azeem Ahmad, Vishesh Dubey, Nikhil Jayakumar, Anowarul Habib, Ankit
  Butola, Mona Nystad, Ganesh Acharya, Purusotam Basnet, Dalip Singh Mehta, and
  Balpreet Singh Ahluwalia","High throughput spatially sensitive single-shot quantitative phase
  microscopy","15 pages, 7 figures",,,,"physics.optics physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High space-bandwidth product with high spatial phase sensitivity is
indispensable for a single-shot quantitative phase microscopy (QPM) system. It
opens avenue for widespread applications of QPM in the field of biomedical
imaging. Temporally low coherence length light sources are generally
implemented to achieve high spatial phase sensitivity in QPM at the cost of
either reduced temporal resolution or smaller field of view (FOV). On the
contrary, high temporal coherence light sources like lasers are capable of
exploiting the full FOV of the QPM systems at the expense of less spatial phase
sensitivity. In the present work, we employed pseudo-thermal light source
(PTLS) in QPM which overcomes the limitations of conventional light sources.
The capabilities of PTLS over conventional light sources are systematically
studied and demonstrated on various test objects like USAF resolution chart and
thin optical waveguide (height ~ 8 nm). The spatial phase sensitivity of QPM in
case of PTLS is measured to be equivalent to that for white light source. The
high-speed and large FOV capabilities of PTLS based QPM is demonstrated by
high-speed imaging of live sperm cells that is limited by the camera speed and
by imaging extra-ordinary large FOV phase imaging on histopathology placenta
tissue samples.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:16:10 GMT""}]","2020-12-15"
"2012.06675","Mort Naraghi-Pour","Mohammed Rashid and Mort Naraghi-Pour","Clustered Sparse Channel Estimation for Massive MIMO Systems by
  Expectation Maximization-Propagation (EM-EP)",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-sa/4.0/","  We study the problem of downlink channel estimation in multi-user massive
multiple input multiple output (MIMO) systems. To this end, we consider a
Bayesian compressive sensing approach in which the clustered sparse structure
of the channel in the angular domain is employed to reduce the pilot overhead.
To capture the clustered structure, we employ a conditionally independent
identically distributed Bernoulli-Gaussian prior on the sparse vector
representing the channel, and a Markov prior on its support vector. An
expectation propagation (EP) algorithm is developed to approximate the
intractable joint distribution on the sparse vector and its support with a
distribution from an exponential family. The approximate distribution is then
used for direct estimation of the channel. The EP algorithm assumes that the
model parameters are known a priori. Since these parameters are unknown, we
estimate these parameters using the expectation maximization (EM) algorithm.
The combination of EM and EP referred to as EM-EP algorithm is reminiscent of
the variational EM approach. Simulation results show that the proposed EM-EP
algorithm outperforms several recently-proposed algorithms in the literature.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:21:38 GMT""},{""version"":""v2"",""created"":""Sat, 5 Jun 2021 22:32:18 GMT""}]","2021-06-08"
"2012.06676","Frank Garvan","Frank Garvan","A new approach to the Dyson rank conjectures","20 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  In 1944 Dyson defined the rank of a partition as the largest part minus the
number of parts, and conjectured that the residue of the rank mod 5 divides the
partitions of 5n+4 into five equal classes. This gave a combinatorial
explanation of Ramanujan's famous partition congruence mod 5. He made an
analogous conjecture for the rank mod 7 and the partitions of 7n+5. In 1954
Atkin and Swinnerton-Dyer proved Dyson's rank conjectures by constructing
several Lambert-series identities basically using the theory of elliptic
functions. In 2016 the author gave another proof using the theory of weak
harmonic Maass forms. In this paper we describe a new and more elementary
approach using Hecke-Rogers series.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:23:47 GMT""}]","2020-12-15"
"2012.06677","Keith Dillon","Keith Dillon","Focus optimization in a Computational Confocal Microscope",,,,,"eess.SP math.OC physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the numerical optimization of performance for a computational
extension of a confocal microscope. Using a system where the pinhole detector
is replaced with a detector array, we seek to exploit this additional
information for each point in the scan. We derive an optimal estimate of the
light at focus which minimizes the contribution of out-of-focus light. We
estimate the amount of improvement that would be theoretically possible in
point-scanning and line-scanning systems and demonstrate with simulation. We
find that even with a large degree of regularization, a significant improvement
is possible, especially for line-scanning systems.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:26:57 GMT""}]","2020-12-15"
"2012.06678","Xin Huang","Xin Huang, Ashish Khetan, Milan Cvitkovic, Zohar Karnin","TabTransformer: Tabular Data Modeling Using Contextual Embeddings","7 pages, 5 figures",,,,"cs.LG cs.AI","http://creativecommons.org/publicdomain/zero/1.0/","  We propose TabTransformer, a novel deep tabular data modeling architecture
for supervised and semi-supervised learning. The TabTransformer is built upon
self-attention based Transformers. The Transformer layers transform the
embeddings of categorical features into robust contextual embeddings to achieve
higher prediction accuracy. Through extensive experiments on fifteen publicly
available datasets, we show that the TabTransformer outperforms the
state-of-the-art deep learning methods for tabular data by at least 1.0% on
mean AUC, and matches the performance of tree-based ensemble models.
Furthermore, we demonstrate that the contextual embeddings learned from
TabTransformer are highly robust against both missing and noisy data features,
and provide better interpretability. Lastly, for the semi-supervised setting we
develop an unsupervised pre-training procedure to learn data-driven contextual
embeddings, resulting in an average 2.1% AUC lift over the state-of-the-art
methods.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:31:23 GMT""}]","2020-12-15"
"2012.06679","John Burge","John Burge and Matthew Bonanni and Matthias Ihme and Lily Hu","Convolutional LSTM Neural Networks for Modeling Wildland Fire Dynamics",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  As the climate changes, the severity of wildland fires is expected to worsen.
Models that accurately capture fire propagation dynamics greatly help efforts
for understanding, responding to and mitigating the damages caused by these
fires. Machine learning techniques provide a potential approach for developing
such models. The objective of this study is to evaluate the feasibility of
using a Convolutional Long Short-Term Memory (ConvLSTM) recurrent neural
network to model the dynamics of wildland fire propagation. The machine
learning model is trained on simulated wildfire data generated by a
mathematical analogue model. Three simulated datasets are analyzed, each with
increasing degrees of complexity. The simplest dataset includes a constant wind
direction as a single confounding factor, whereas the most complex dataset
includes dynamic wind, complex terrain, spatially varying moisture content and
heterogenous vegetation density distributions. We examine how effective the
ConvLSTM can learn the fire-spread dynamics over consecutive time steps. It is
shown that ConvLSTMs can capture local fire transmission events, as well as the
overall fire dynamics, such as the rate at which the fire spreads. Finally, we
demonstrate that ConvLSTMs outperform other network architectures that have
previously been used to model similar wildland fire dynamics.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:31:43 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 21:07:09 GMT""}]","2021-04-12"
"2012.06680","Adriana Gazol","Adriana Gazol and Marco Villagran","The physical and the geometrical properties of simulated cold HI
  structures","Accepted for publication in MNRAS",,"10.1093/mnras/staa3852",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The objective of this paper is to help shedding some light on the nature and
the properties of the cold structures formed via thermal instability in the
magnetized atomic interstellar medium. To this end, we searched for clumps
formed in forced (magneto)hydrodynamic simulations with an initial magnetic
field ranging from 0 to 8.3$\mu$G. We statistically analyzed, through the use
of Kernel Density Estimations, the physical and the morphological properties of
a sample containing $\sim 1500$ clumps, as well as the relative alignments
between the main direction of clumps and the internal velocity and magnetic
field. The density ($n\sim 50-200$cm$^{-3}$), the thermal pressure
($P_{th}/k\sim 4.9\times 10^3-10^4$K cm$^{-3}$), the mean magnetic field ($\sim
3-11$$\mu$G ), and the sonic Mach number of the selected clumps have values
comparable to those reported in observations. We find, however, that the cloud
sample can not be described by a single regime concerning their pressure
balance and their Alf\'enic Mach number. We measured the morphological
properties of clumps mainly through the asphericity and the prolatness, which
appear to be more sensitive than the aspect ratios. From this analysis we find
that the presence of magnetic field, even if it is weak, does qualitatively
affect the morphology of the clumps by increasing the probability of having
highly aspherical and highly plolate clumps by a factor of two, that is by
producing more filamentary clumps. Finally, we find that the angle between the
main direction of the clumps and the local magnetic field lies between
$\sim\pi/4-\pi/2$ and shifts to more perpendicular alignments as the intensity
of this field increases, while the relative direction between the local density
structure and the local magnetic field transits from parallel to perpendicular.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 23:47:18 GMT""}]","2020-12-23"
"2012.06681","Alexander Engel","Alexander Engel, Graeme Smith, Scott E. Parker","Linear embedding of nonlinear dynamical systems and prospects for
  efficient quantum algorithms","13 pages","Physics of Plasmas 28, 062305 (2021)","10.1063/5.0040313",,"physics.plasm-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The simulation of large nonlinear dynamical systems, including systems
generated by discretization of hyperbolic partial differential equations, can
be computationally demanding. Such systems are important in both fluid and
kinetic computational plasma physics. This motivates exploring whether a future
error-corrected quantum computer could perform these simulations more
efficiently than any classical computer. We describe a method for mapping any
finite nonlinear dynamical system to an infinite linear dynamical system
(embedding) and detail three specific cases of this method that correspond to
previously-studied mappings. Then we explore an approach for approximating the
resulting infinite linear system with finite linear systems (truncation). Using
a number of qubits only logarithmic in the number of variables of the nonlinear
system, a quantum computer could simulate truncated systems to approximate
output quantities if the nonlinearity is sufficiently weak. Other aspects of
the computational efficiency of the three detailed embedding strategies are
also discussed.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 00:01:10 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 18:47:05 GMT""}]","2021-06-14"
"2012.06682","Warut Suksompong","Edith Elkind, Erel Segal-Halevi, Warut Suksompong","Mind the Gap: Cake Cutting With Separation","Appears in the 35th AAAI Conference on Artificial Intelligence
  (AAAI), 2021","Artificial Intelligence, 313:103783 (2022)","10.1016/j.artint.2022.103783",,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of fairly allocating a divisible resource, also known as
cake cutting, with an additional requirement that the shares that different
agents receive should be sufficiently separated from one another. This
captures, for example, constraints arising from social distancing guidelines.
While it is sometimes impossible to allocate a proportional share to every
agent under the separation requirement, we show that the well-known criterion
of maximin share fairness can always be attained. We then provide algorithmic
analysis of maximin share fairness in this setting -- for instance, the maximin
share of an agent cannot be computed exactly by any finite algorithm, but can
be approximated with an arbitrarily small error. In addition, we consider the
division of a pie (i.e., a circular cake) and show that an ordinal relaxation
of maximin share fairness can be achieved. We also prove that an envy-free or
equitable allocation that allocates the maximum amount of resource exists under
separation.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 00:21:16 GMT""},{""version"":""v2"",""created"":""Sun, 21 Nov 2021 07:29:55 GMT""},{""version"":""v3"",""created"":""Wed, 7 Sep 2022 08:19:18 GMT""}]","2022-09-20"
"2012.06683","Vikram Nathan","Vikram Nathan, Jialin Ding, Tim Kraska, Mohammad Alizadeh","Cortex: Harnessing Correlations to Boost Query Performance","13 pages, including references. Under submission",,,,"cs.DB cs.IR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Databases employ indexes to filter out irrelevant records, which reduces scan
overhead and speeds up query execution. However, this optimization is only
available to queries that filter on the indexed attribute. To extend these
speedups to queries on other attributes, database systems have turned to
secondary and multi-dimensional indexes. Unfortunately, these approaches are
restrictive: secondary indexes have a large memory footprint and can only speed
up queries that access a small number of records, and multi-dimensional indexes
cannot scale to more than a handful of columns. We present Cortex, an approach
that takes advantage of correlations to extend the reach of primary indexes to
more attributes. Unlike prior work, Cortex can adapt itself to any existing
primary index, whether single or multi-dimensional, to harness a broad variety
of correlations, such as those that exist between more than two attributes or
have a large number of outliers. We demonstrate that on real datasets
exhibiting these diverse types of correlations, Cortex matches or outperforms
traditional secondary indexes with $5\times$ less space, and it is $2-8\times$
faster than existing approaches to indexing correlations.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 00:22:51 GMT""}]","2020-12-15"
"2012.06684","Samuel Ainsworth","Samuel Ainsworth and Kendall Lowrey and John Thickstun and Zaid
  Harchaoui and Siddhartha Srinivasa","Faster Policy Learning with Continuous-Time Gradients",,"L4DC 2021",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the estimation of policy gradients for continuous-time systems with
known dynamics. By reframing policy learning in continuous-time, we show that
it is possible construct a more efficient and accurate gradient estimator. The
standard back-propagation through time estimator (BPTT) computes exact
gradients for a crude discretization of the continuous-time system. In
contrast, we approximate continuous-time gradients in the original system. With
the explicit goal of estimating continuous-time gradients, we are able to
discretize adaptively and construct a more efficient policy gradient estimator
which we call the Continuous-Time Policy Gradient (CTPG). We show that
replacing BPTT policy gradients with more efficient CTPG estimates results in
faster and more robust learning in a variety of control tasks and simulators.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 00:22:56 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 04:31:03 GMT""}]","2021-06-25"
"2012.06685","Thanh Long Vu Dr","Ankit Singhal and Thanh Long Vu and Wei Du","Coordinated Frequency and Voltage Regulation of Grid-Following and
  Grid-Forming Inverters",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In a purely inverter-based microgrid, both grid-forming (GFM) and
grid-following (GFL) inverters will have a crucial role to play in
frequency/voltage regulation and maintaining power sharing through their grid
support capabilities. Consequently, the coordination between these two
technologies becomes increasingly important for optimal system performance.
However, the existing work does not consider GFL's potential to participate in
a secondary control in coordination with GFM, thus not able to utilize the full
capability of inverter resources. In this paper, we show that it is possible to
fully coordinate the GFL and GFM inverters to achieve accurate power sharing,
frequency/voltage regulation, and circulating var mitigation in networked
microgrids even without the support of any synchronous generators or the bulk
power system. We use the leader-follower consensus framework to develop a
GFM-GFL coordination control. The effectiveness of the proposed coordination is
verified under different disturbances and communication degradation. In
addition, we find that the proposed fully-coordinated secondary control
outperforms other approaches such as un-coordinated and partially-coordinated
secondary controls, in aspects of load sharing and frequency and voltage
regulation. Overall, this study emphasizes the need and benefits of GFL-GFM
coordination in microgrids.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 00:24:48 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 23:02:11 GMT""}]","2021-11-01"
"2012.06687","Jia-Wei Ji","Jia-Wei Ji, Yu-Feng Wu, Stephen C. Wein, Faezeh Kimiaee Asadi,
  Roohollah Ghobadi, and Christoph Simon","Proposal for room-temperature quantum repeaters with nitrogen-vacancy
  centers and optomechanics","This paper has been updated with the identifier: arXiv:2203.06611
  which has been published in Quantum as Quantum 6, 669 (2022) with the related
  DOI: https://doi.org/10.22331/q-2022-03-17-669",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a quantum repeater architecture that can operate under ambient
conditions. Our proposal builds on recent progress towards non-cryogenic
spin-photon interfaces based on nitrogen-vacancy centers, which have excellent
spin coherence times even at room temperature, and optomechanics, which allows
to avoid phonon-related decoherence and also allows the emitted photons to be
in the telecom band. We apply the photon number decomposition method to
quantify the fidelity and the efficiency of entanglement established between
two remote electron spins. We describe how the entanglement can be stored in
nuclear spins and extended to long distances via quasi-deterministic
entanglement swapping operations involving the electron and nuclear spins. We
furthermore propose schemes to achieve high-fidelity readout of the spin states
at room temperature using the spin-optomechanics interface. Our work shows that
long-distance quantum networks made of solid-state components that operate at
room temperature are within reach of current technological capabilities.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 00:41:00 GMT""},{""version"":""v2"",""created"":""Tue, 29 Mar 2022 00:36:55 GMT""}]","2022-03-30"
"2012.06688","Aden Lam","Aden Zhenhao Lam, Claire Warner, Niccol\`o Bigagli, Stephan
  Roschinski, Weijun Yuan, Ian Stevenson, and Sebastian Will","Compact Two-Dimensional Magneto-Optical Trap for Ultracold Atom Setups","6 pages, 5 figures, 2 tables; rewrote introduction, amended format",,,,"physics.atom-ph cond-mat.quant-gas quant-ph","http://creativecommons.org/licenses/by/4.0/","  We report on the design, implementation, and performance of a compact
two-dimensional magneto-optical trap (2D MOT) for cesium. In a small-volume
vacuum chamber, the setup uses cesium dispensers in close proximity to the
trapping region of the 2D MOT and operates at low vapor pressures in the
$10^{-9}$ torr range. We achieve a cold atom flux of $4 \times 10^8$ atoms/s
that is comparable to the performance of more complex atomic sources. The setup
is simple to construct and can be adapted to a broad range of atomic species.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:07:12 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 17:53:27 GMT""}]","2021-07-02"
"2012.06689","Zhiwan Xu","Zhiwan Xu, Xiatong Wu, Caleb Sword, Gang Wang, Sergei A. Voloshin,
  Huan Zhong Huang","Flow-plane decorrelations in heavy-ion collisions with multiple-plane
  cumulants","12 pages, 15 figures","Phys. Rev. C 105 (Feb 2022), 024902. Issue 2","10.1103/PhysRevC.105.024902",,"nucl-ex hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The azimuthal correlations between local flow planes at different
(pseudo)rapidities ($\eta$) may reveal important details of the initial nuclear
matter density distributions in heavy-ion collisions. Extensive experimental
measurements of a factorization ratio ($r_2$) and its derivative ($F_2$) have
shown evidence of the longitudinal flow-plane decorrelation. However, nonflow
effects also affect this observable and prevent a quantitative understanding of
the phenomenon. In this paper, to distinguish decorrelation and nonflow
effects, we propose a new cumulant observable, $T_2$, which largely suppresses
nonflow. The technique sensitivity to different initial-state scenarios and
nonflow effects are tested with a simple Monte Carlo model, and in the end, the
method is applied to events simulated by a multiphase transport model (AMPT)
for Au+Au collisions at $\sqrt{s_{\rm NN}} =200$ GeV. We also emphasize that a
distinct decorrelation signal requires not only the right sign of an
observable, but also its proper dependence on the $\eta$-window of the
reference flow plane, to be consistent with the pertinent decorrelation
picture.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:07:23 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 18:04:12 GMT""}]","2022-02-09"
"2012.06690","Zefang Liu","Zefang Liu","Yelp Review Rating Prediction: Machine Learning and Deep Learning Models","8 pages, 13 figures",,,,"cs.CL cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We predict restaurant ratings from Yelp reviews based on Yelp Open Dataset.
Data distribution is presented, and one balanced training dataset is built. Two
vectorizers are experimented for feature engineering. Four machine learning
models including Naive Bayes, Logistic Regression, Random Forest, and Linear
Support Vector Machine are implemented. Four transformer-based models
containing BERT, DistilBERT, RoBERTa, and XLNet are also applied. Accuracy,
weighted F1 score, and confusion matrix are used for model evaluation. XLNet
achieves 70% accuracy for 5-star classification compared with Logistic
Regression with 64% accuracy.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:07:48 GMT""}]","2020-12-15"
"2012.06691","Johann Rudi","Johann Rudi, Julie Bessac, Amanda Lenzi","Parameter Estimation with Dense and Convolutional Neural Networks
  Applied to the FitzHugh-Nagumo ODE","accepted to MSML21: Mathematical and Scientific Machine Learning",,,,"stat.ML cs.LG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning algorithms have been successfully used to approximate
nonlinear maps under weak assumptions on the structure and properties of the
maps. We present deep neural networks using dense and convolutional layers to
solve an inverse problem, where we seek to estimate parameters of a
FitzHugh-Nagumo model, which consists of a nonlinear system of ordinary
differential equations (ODEs). We employ the neural networks to approximate
reconstruction maps for model parameter estimation from observational data,
where the data comes from the solution of the ODE and takes the form of a time
series representing dynamically spiking membrane potential of a biological
neuron. We target this dynamical model because of the computational challenges
it poses in an inference setting, namely, having a highly nonlinear and
nonconvex data misfit term and permitting only weakly informative priors on
parameters. These challenges cause traditional optimization to fail and
alternative algorithms to exhibit large computational costs. We quantify the
prediction errors of model parameters obtained from the neural networks and
investigate the effects of network architectures with and without the presence
of noise in observational data. We generalize our framework for neural
network-based reconstruction maps to simultaneously estimate ODE parameters and
parameters of autocorrelated observational noise. Our results demonstrate that
deep neural networks have the potential to estimate parameters in dynamical
models and stochastic processes, and they are capable of predicting parameters
accurately for the FitzHugh-Nagumo model.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:20:42 GMT""},{""version"":""v2"",""created"":""Sat, 6 Mar 2021 20:52:55 GMT""},{""version"":""v3"",""created"":""Tue, 4 May 2021 16:27:18 GMT""}]","2021-05-05"
"2012.06692","Hengameh R. Dehkordi","Hengameh R. Dehkordi","Mathematical modeling the wildfire propagation in a Randers space",,,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  The devastating effects of wildfires on the wildlife and their impact on
human lives and properties are undeniable. This shows the importance of
studying the spread of wildfire, predicting its behavior and presenting more
reliable models for its propagation. Here, by using the validity of the
Huygens` envelope principle for wavefronts in Randers spaces, we present some
models for the propagation of wildfire in an n-dimensional smooth manifold
under the presence of wind. In the models, trajectories of fire particles are
tracked and the equations that give the wavefront at each time are provided.
Furthermore, we determine the paths and points of great importance in the
process of wildfire management, called strategic paths and points. Finally, we
consider two examples of spreading the wildfire in some agricultural land or
woodland, for the sake of illustration.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:20:48 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 11:49:42 GMT""},{""version"":""v3"",""created"":""Mon, 4 Jan 2021 15:12:37 GMT""},{""version"":""v4"",""created"":""Wed, 10 Feb 2021 20:52:27 GMT""},{""version"":""v5"",""created"":""Fri, 26 Mar 2021 15:32:29 GMT""}]","2021-03-29"
"2012.06693","Wanxiang Feng","Xiaodong Zhou, Wanxiang Feng, Xiuxian Yang, Guang-Yu Guo, Yugui Yao","Electrically Controllable Crystal Chirality Magneto-Optical Effects in
  Collinear Antiferromagnets","6 pages, 4 figs","Phys. Rev. B 104, 024401 (2021)","10.1103/PhysRevB.104.024401",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spin chirality, created by magnetic atoms, has been comprehensively
understood to generate and control the magneto-optical effects. In comparison,
the role of the crystal chirality that relates to nonmagnetic atoms has
received much less attention. Here, we theoretically discover the crystal
chirality magneto-optical (CCMO) effects, which depend on the chirality of
crystal structures that originates from the rearrangement of nonmagnetic atoms.
We show that the CCMO effects exist in many collinear antiferromagnets, such as
RuO$_{2}$ and CoNb$_{3}$S$_{6}$, which has a local and global crystal
chirality, respectively. The key character of the CCMO effects is the sign
change if the crystal chirality reverses. The magnitudes of the CCMO spectra
can be effectively manipulated by reorienting the N\'eel vector with the help
of an external electric field, and the spectral integrals are found to be
proportional to magnetocrystalline anisotropy energy.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:23:29 GMT""}]","2021-07-05"
"2012.06694","Shima Rahimi Moghaddam","Shima Rahimi Moghaddam, Fanjun Bu, Christopher J. Honey","Consequences of Slow Neural Dynamics for Incremental Learning",,,,,"cs.LG cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the human brain, internal states are often correlated over time (due to
local recurrence and other intrinsic circuit properties), punctuated by abrupt
transitions. At first glance, temporal smoothness of internal states presents a
problem for learning input-output mappings (e.g. category labels for images),
because the internal representation of the input will contain a mixture of
current input and prior inputs. However, when training with naturalistic data
(e.g. movies) there is also temporal autocorrelation in the input. How does the
temporal ""smoothness"" of internal states affect the efficiency of learning when
the training data are also temporally smooth? How does it affect the kinds of
representations that are learned? We found that, when trained with temporally
smooth data, ""slow"" neural networks (equipped with linear recurrence and gating
mechanisms) learned to categorize more efficiently than feedforward networks.
Furthermore, networks with linear recurrence and multi-timescale gating could
learn internal representations that ""un-mixed"" quickly-varying and
slowly-varying data sources. Together, these findings demonstrate how a
fundamental property of cortical dynamics (their temporal autocorrelation) can
serve as an inductive bias, leading to more efficient category learning and to
the representational separation of fast and slow sources in the environment.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:24:36 GMT""},{""version"":""v2"",""created"":""Mon, 22 May 2023 20:07:55 GMT""}]","2023-05-24"
"2012.06695","Udaya Ghai","Udaya Ghai, David Snyder, Anirudha Majumdar, Elad Hazan","Generating Adversarial Disturbances for Controller Verification",,,,,"cs.LG cs.SY eess.SY math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of generating maximally adversarial disturbances for
a given controller assuming only blackbox access to it. We propose an online
learning approach to this problem that \emph{adaptively} generates disturbances
based on control inputs chosen by the controller. The goal of the disturbance
generator is to minimize \emph{regret} versus a benchmark
disturbance-generating policy class, i.e., to maximize the cost incurred by the
controller as well as possible compared to the best possible disturbance
generator \emph{in hindsight} (chosen from a benchmark policy class). In the
setting where the dynamics are linear and the costs are quadratic, we formulate
our problem as an online trust region (OTR) problem with memory and present a
new online learning algorithm (\emph{MOTR}) for this problem. We prove that
this method competes with the best disturbance generator in hindsight (chosen
from a rich class of benchmark policies that includes linear-dynamical
disturbance generating policies). We demonstrate our approach on two simulated
examples: (i) synthetically generated linear systems, and (ii) generating wind
disturbances for the popular PX4 controller in the AirSim simulator. On these
examples, we demonstrate that our approach outperforms several baseline
approaches, including $H_{\infty}$ disturbance generation and gradient-based
methods.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:31:32 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2022 17:59:20 GMT""}]","2022-02-01"
"2012.06696","Zubia Hasan","Zubia Hasan, Michal J. Winiarski, Kathryn E. Arpino, Thomas Halloran,
  Thao T. Tran and Tyrel M. McQueen","Strong Magnetic Interactions and Short Range Magnetic Correlations in
  CuTeO4","9 pages, 7 figures",,,,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  \ch{CuTeO4} has been proposed as a crystallographically distinct, yet
electronic structure analog, of superconducting cuprates. Magnetization
measurements from T = 2-300 K indicate the presence of antiferromagnetic, low
dimensional correlations with J = 148(7) K. Below T $\approx$ 50 K, there is an
upturn in magnetization indicative of enhanced ferromagnetic correlations, with
neutron powder diffraction data showing the emergence of diffuse magnetic
scattering at Q $\approx$ 0.6 \si{\angstrom^{-1}}. A Warren line shape analysis
yields a characteristic magnetic correlation length of $\xi$ = 4.5(9)
\si{\angstrom} at T = 40 K, rising to $\xi$ = 10.1(9) \si{\angstrom} at T = 10
K. Specific heat measurements reveal a sizable T-linear contribution of
$\gamma$ = 8.3 mJ/mol-f.u/K^2 at T < 5 K. Together, these results imply a low
dimensional, antiferromagnetic spin glass state. Structural modeling of the
neutron powder diffraction data reveals the presence of a layered-type of
stacking disorder, providing both a rationale for the lack of long range
magnetic order, as well as being consistent with the computational predictions
of its two-dimensional nature. Unlike the cuprates, we find no evidence of
substantive dopability in this wide band-gap, yellow insulator.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:39:16 GMT""}]","2020-12-15"
"2012.06697","Homayoun Valafar","Xijiang Miao, Michael G. Bryson, Homayoun Valafar","TALI: Protein Structure Alignment Using Backbone Torsion Angles","Seven pages","Published in BIOCOMP 2006: 3-9",,,"q-bio.BM cs.LG","http://creativecommons.org/licenses/by/4.0/","  This article introduces a novel protein structure alignment method (named
TALI) based on the protein backbone torsion angle instead of the more
traditional distance matrix. Because the structural alignment of the two
proteins is based on the comparison of two sequences of numbers (backbone
torsion angles), we can take advantage of a large number of well-developed
methods such as Smith-Waterman or Needleman-Wunsch. Here we report the result
of TALI in comparison to other structure alignment methods such as DALI, CE,
and SSM ass well as sequence alignment based on PSI-BLAST. TALI demonstrated
great success over all other methods in application to challenging proteins.
TALI was more successful in recognizing remote structural homology. TALI also
demonstrated an ability to identify structural homology between two proteins
where the structural difference was due to a rotation of internal domains by
nearly 180$^\circ$.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:45:30 GMT""}]","2020-12-15"
"2012.06698","Yuefang Sun","Yuefang Sun","Extremal results for directed tree connectivity","arXiv admin note: text overlap with arXiv:2005.00849",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a digraph $D=(V(D), A(D))$, and a set $S\subseteq V(D)$ with $r\in S$ and
$|S|\geq 2$, an $(S, r)$-tree is an out-tree $T$ rooted at $r$ with $S\subseteq
V(T)$. Two $(S, r)$-trees $T_1$ and $T_2$ are said to be arc-disjoint if
$A(T_1)\cap A(T_2)=\emptyset$. Two arc-disjoint $(S, r)$-trees $T_1$ and $T_2$
are said to be internally disjoint if $V(T_1)\cap V(T_2)=S$. Let
$\kappa_{S,r}(D)$ and $\lambda_{S,r}(D)$ be the maximum number of internally
disjoint and arc-disjoint $(S, r)$-trees in $D$, respectively. The generalized
$k$-vertex-strong connectivity of $D$ is defined as $$\kappa_k(D)= \min
\{\kappa_{S,r}(D)\mid S\subset V(D), |S|=k, r\in S\}.$$ Similarly, the
generalized $k$-arc-strong connectivity of $D$ is defined as $$\lambda_k(D)=
\min \{\lambda_{S,r}(D)\mid S\subset V(D), |S|=k, r\in S\}.$$ The generalized
$k$-vertex-strong connectivity and generalized $k$-arc-strong connectivity are
also called directed tree connectivity which could be seen as a generalization
of classical connectivity of digraphs.
  A digraph $D=(V(D), A(D))$ is called minimally generalized $(k, \ell)$-vertex
(respectively, arc)-strongly connected if $\kappa_k(D)\geq \ell$ (respectively,
$\lambda_k(D)\geq \ell$) but for any arc $e\in A(D)$, $\kappa_k(D-e)\leq
\ell-1$ (respectively, $\lambda_k(D-e)\leq \ell-1$). In this paper, we study
the minimally generalized $(k, \ell)$-vertex (respectively, arc)-strongly
connected digraphs. We compute the minimum and maximum sizes of these digraphs,
and give characterizations of such digraphs for some pairs of $k$ and $\ell$.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 01:46:22 GMT""}]","2020-12-15"
"2012.06699","Mark Andrews","Mark Andrews","Evolution and invariants of free-particle moments","15 pages, 4 figures",,"10.1088/1751-8121/abf27c",,"quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Moments are expectation values of products of powers of position and
momentum, taken over quantum states (or averages over a set of classical
particles). For free particles, the evolution in the quantum case is closely
related to that of a set of classical particles. Here we consider the evolution
of symmetrized moments for free particles in one dimension, first examining the
geometric properties of the evolution for moments up to the fourth order, as
determined by their extrema and inflections. These properties are specified by
combinations of the moments that are {\it invariant} in that they remain
constant under free evolution. An inequality constrains the fourth-order
moments and shows that some geometric types of evolution are possible for a
quantum particle but not possible classically, and some examples are examined.
Explicit expressions are found for the moments of any order in terms of their
initial values, for the invariant combinations, and for the moments in terms of
these invariants.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 02:02:26 GMT""}]","2021-05-26"
"2012.06700","Ryuki Hyodo","Ryuki Hyodo, Tristan Guillot, Shigeru Ida, Satoshi Okuzumi, Andrew N.
  Youdin","Planetesimal formation around the snow line. II. Dust or pebbles?","18 pages, 6 Figures, 3 Figures in Appendix, accepted for publication
  in Astronomy & Astrophysics (A&A)","A&A 646, A14 (2021)","10.1051/0004-6361/202039894",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Around the snow line, icy pebbles and silicate dust may locally pile-up and
form icy and rocky planetesimals via streaming instability and/or gravitational
instability. We perform 1D diffusion-advection simulations that include the
back-reaction to radial drift and diffusion of icy pebbles and silicate dust,
ice sublimation, release of silicate dust, and their recycling through
recondensation and sticking onto pebbles outside the snow line. We use a
realistic description of the scale height of silicate dust obtained from Ida et
al. and that of pebbles including the effects of a Kelvin-Helmholtz
instability. We study the dependence of solid pile-up on distinct effective
viscous parameters for turbulent diffusions in the radial and vertical
directions ($\alpha_{\rm Dr}$ and $\alpha_{\rm Dz}$) and for the gas accretion
to the star ($\alpha_{\rm acc}$) as well as that on the pebble-to-gas mass flux
($F_{\rm p/g}$). We derive the sublimation width of drifting icy pebbles which
is a critical parameter to characterize the pile-up of silicate dust and
pebbles around the snow line. We identify a parameter space (in the $F_{\rm
p/g}-\alpha_{\rm acc}-\alpha_{\rm Dz}(=\alpha_{\rm Dr})$ space) where pebbles
no longer drift inward to reach the snow line due to the back-reaction that
slows down radial velocity of pebbles. We show that the pile-up of solids
around the snow line occurs in a broader range of parameters for $\alpha_{\rm
acc}=10^{-3}$ than for $\alpha_{\rm acc}=10^{-2}$. Above a critical $F_{\rm
p/g}$ value, the runaway pile-up of silicate dust inside the snow line is
favored for $\alpha_{\rm Dr}/\alpha_{\rm acc} \ll 1$, while that of pebbles
outside the snow line is favored for $\alpha_{\rm Dr}/\alpha_{\rm acc} \sim 1$.
Our results imply that a distinct evolutionary path could produce a diversity
of outcomes in terms of planetesimal formation around the snow line.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 02:06:17 GMT""},{""version"":""v2"",""created"":""Sat, 16 Jan 2021 09:36:08 GMT""}]","2021-02-03"
"2012.06701","Jiahao Yao","Jiahao Yao, Paul K\""ottering, Hans Gundlach, Lin Lin, Marin Bukov","Noise-Robust End-to-End Quantum Control using Deep Autoregressive Policy
  Networks",,"Proceedings of Machine Learning Research vol 145 (2022) 1044-1081",,,"quant-ph cond-mat.quant-gas cs.LG physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Variational quantum eigensolvers have recently received increased attention,
as they enable the use of quantum computing devices to find solutions to
complex problems, such as the ground energy and ground state of
strongly-correlated quantum many-body systems. In many applications, it is the
optimization of both continuous and discrete parameters that poses a formidable
challenge. Using reinforcement learning (RL), we present a hybrid policy
gradient algorithm capable of simultaneously optimizing continuous and discrete
degrees of freedom in an uncertainty-resilient way. The hybrid policy is
modeled by a deep autoregressive neural network to capture causality. We employ
the algorithm to prepare the ground state of the nonintegrable quantum Ising
model in a unitary process, parametrized by a generalized quantum approximate
optimization ansatz: the RL agent solves the discrete combinatorial problem of
constructing the optimal sequences of unitaries out of a predefined set and, at
the same time, it optimizes the continuous durations for which these unitaries
are applied. We demonstrate the noise-robust features of the agent by
considering three sources of uncertainty: classical and quantum measurement
noise, and errors in the control unitary durations. Our work exhibits the
beneficial synergy between reinforcement learning and quantum control.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 02:13:28 GMT""}]","2022-05-13"
"2012.06702","Henry Adams","Henry Adams, Leah Gibson, Jack Pfaffinger","Lions and contamination, triangular grids, and Cheeger constants",,,,,"math.CO cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Suppose each vertex of a graph is originally occupied by contamination,
except for those vertices occupied by lions. As the lions wander on the graph,
they clear the contamination from each vertex they visit. However, the
contamination simultaneously spreads to any adjacent vertex not occupied by a
lion. How many lions are required in order to clear the graph of contamination?
We give a lower bound on the number of lions needed in terms of the Cheeger
constant of the graph. Furthermore, the lion and contamination problem has been
studied in detail on square grid graphs by Brass et al. and Berger et al., and
we extend this analysis to the setting of triangular grid graphs.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 02:17:28 GMT""},{""version"":""v2"",""created"":""Thu, 31 Dec 2020 14:56:06 GMT""},{""version"":""v3"",""created"":""Sat, 3 Jul 2021 15:46:06 GMT""}]","2021-07-06"
"2012.06703","Bin Zou","Zhuo Jin, Zuo Quan Xu, and Bin Zou","A Perturbation Approach to Optimal Investment, Liability Ratio, and
  Dividend Strategies","29 pages",,,,"q-fin.MF math.OC q-fin.PM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study an optimal dividend problem for an insurer who simultaneously
controls investment weights in a financial market, liability ratio in the
insurance business, and dividend payout rate. The insurer seeks an optimal
strategy to maximize her expected utility of dividend payments over an infinite
horizon. By applying a perturbation approach, we obtain the optimal strategy
and the value function in closed form for log and power utility. We conduct an
economic analysis to investigate the impact of various model parameters and
risk aversion on the insurer's optimal strategy.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 02:23:22 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 15:32:23 GMT""}]","2021-05-27"
"2012.06704","Chaohao Chen","Chaohao Chen, Baolei Liu, Yongtao Liu, Jiayan Liao, Xuchen Shan, Fan
  Wang, and Dayong Jin","Heterochromatic nonlinear optical responses in upconversion
  nanoparticles for point spread function engineering","30 pages, 14 figures",,"10.1002/adma.202008847",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Point spread function (PSF) engineering of the emitter can code higher
spatial frequency information of an image to break diffraction limit but suffer
from the complexed optical systems. Here we present a robust strategy to
simultaneously achieve diverse PSFs from upconversion nanoparticles under a
single doughnut-shape scanning beam. By saturating the four-photon state, the
high-frequency information can be extracted through the doughnut emission PSF.
In contrast, the complementary lower frequency information can be carried out
by the Gaussian-like emission PSF, as a result of over-saturated at the
two-photon state. With the Fourier domain heterochromatic fusion, we verify the
capability of the synthesised PSF to cover both low and high-frequency
information, yielding the overall enhanced image quality. We show a spatial
resolution of 40 nm, 1/24th of the excitation wavelength. This work suggests a
new scope for developing nonlinear multi-colour emitting probes to improve
image quality and noise control in nanoscopy.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 02:33:29 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 07:11:46 GMT""}]","2021-02-23"
"2012.06705","Nehali Mhatre","Nehali Mhatre and Daniel Cooley","Transformed-Linear Models for Time Series Extremes",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  In order to capture the dependence in the upper tail of a time series, we
develop non-negative regularly-varying time series models that are constructed
similarly to classical non-extreme ARMA models. Rather than fully
characterizing tail dependence of the time series, we define the concept of
weak tail stationarity which allows us to describe a regularly-varying time
series through the tail pairwise dependence function (TPDF) which is a measure
of pairwise extremal dependencies. We state consistency requirements among the
finite-dimensional collections of the elements of a regularly-varying time
series and show that the TPDF's value does not depend on the dimension being
considered. So that our models take nonnegative values, we use
transformed-linear operations. We show existence and stationarity of these
models, and develop their properties such as the model TPDF's. Additionally, we
show the class of transformed-linear MA($\infty$) models forms an inner product
space. Motivated by investigating conditions conducive to the spread of
wildfires, we fit models to hourly windspeed data and find that the fitted
transformed-linear models produce better estimates of upper tail quantities
than traditional ARMA models or than classical linear regularly varying models.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 02:36:40 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 21:28:02 GMT""},{""version"":""v3"",""created"":""Mon, 25 Oct 2021 19:41:56 GMT""}]","2021-10-27"
"2012.06706","Yuhao Zhou","Yuhao Zhou, Ye Qing, and Jiancheng Lv","Communication-Efficient Federated Learning with Compensated
  Overlap-FedAvg","15 pages, 9 figures",,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Petabytes of data are generated each day by emerging Internet of Things
(IoT), but only few of them can be finally collected and used for Machine
Learning (ML) purposes due to the apprehension of data & privacy leakage, which
seriously retarding ML's growth. To alleviate this problem, Federated learning
is proposed to perform model training by multiple clients' combined data
without the dataset sharing within the cluster. Nevertheless, federated
learning introduces massive communication overhead as the synchronized data in
each epoch is of the same size as the model, and thereby leading to a low
communication efficiency. Consequently, variant methods mainly focusing on the
communication rounds reduction and data compression are proposed to reduce the
communication overhead of federated learning. In this paper, we propose
Overlap-FedAvg, a framework that parallels the model training phase with model
uploading & downloading phase, so that the latter phase can be totally covered
by the former phase. Compared to vanilla FedAvg, Overlap-FedAvg is further
developed with a hierarchical computing strategy, a data compensation mechanism
and a nesterov accelerated gradients~(NAG) algorithm. Besides, Overlap-FedAvg
is orthogonal to many other compression methods so that they can be applied
together to maximize the utilization of the cluster. Furthermore, the
theoretical analysis is provided to prove the convergence of the proposed
Overlap-FedAvg framework. Extensive experiments on both conventional and
recurrent tasks with multiple models and datasets also demonstrate that the
proposed Overlap-FedAvg framework substantially boosts the federated learning
process.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 02:50:09 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 08:43:15 GMT""}]","2021-06-17"
"2012.06707","Zhuangzhuang Cui","Zhuangzhuang Cui, Ke Guan, C\'esar Briso-Rodr\'iguez, Bo Ai, Zhangdui
  Zhong, Claude Oestges","Channel Modeling for UAV Communications: State of the Art, Case Studies,
  and Future Directions",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As essential aerial platforms, unmanned aerial vehicles (UAVs) play an
increasingly important role in broad wireless connectivity and high-data-rate
transmission for future communication systems. Notably, various communication
scenarios are involved in UAV communications, such as intercommunications
between UAVs and communications with the ground user equipment, the cellular
base station, and the ground station, to name a few. However, existing works
mostly focus on a single communication scenario, a designated channel type, and
a specific operating frequency, thus urgently requiring a comprehensive
understanding of multi-scenario, multi-frequency, and multi-type UAV channels.
This article pours attention into the essentials of corresponding air-to-air
(A2A) and air-to-ground (A2G) channels in UAV communications. We first identify
the latest key challenges of channel modeling for UAV communications. We then
provide the state of the art for A2A and A2G channel properties and models
based on extensive measurement campaigns. In particular, we conduct realistic
case studies to further demonstrate critical channel characterizations and
machine learning-based modeling methods. Last but not least, potential
directions are widely discussed for paving the way towards more accurate and
effective channel models for UAV communications.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 02:59:05 GMT""},{""version"":""v2"",""created"":""Fri, 16 Apr 2021 13:18:21 GMT""}]","2021-04-19"
"2012.06708","Ahmed Arif","Anna-Maria Gueorguieva, Gulnar Rakhmetulla, Ahmed Sabbir Arif","Enabling Input on Tiny/Headless Systems Using Morse Code","Poster at the 2nd Annual Center for Cellular and Biomolecular
  Machines Open House, October 22, 2018, University of California, Merced, USA",,,,"cs.HC","http://creativecommons.org/licenses/by-sa/4.0/","  This paper presents results of a pilot study that explored the potential of
Morse code as a method for text entry on mobile devices. In the study,
participants without prior experience with Morse code reached 6.7 wpm with a
Morse code keyboard in three short sessions. Learning was observed both in
terms of text entry speed and accuracy, which suggests that the overall
performance of the keyboard is likely to improve with practice.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 03:00:54 GMT""}]","2020-12-15"
"2012.06709","Yi Feng","Yi Feng, George Hobbs, Di Li, Shi Dai, Weiwei Zhu, Youling Yue, Pei
  Wang, Songbo Zhang, Lei Qian, Lei Zhang, Shuangqiang Wang, Chenchen Miao, Mao
  Yuan, Yongkun Zhang","A single pulse study of PSR J1022+1001","Accepted by ApJ",,"10.3847/1538-4357/abd326",,"astro-ph.HE astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Using the Five-hundred-meter Aperture Spherical radio Telescope (FAST), we
have recorded 10^5 single pulses from PSR J1022+1001. We studied the
polarization properties, their energy distribution and their times of arrival.
This is only possible with the high sensitivity available using FAST. There is
no indication that PSR~J1022+1001 exhibits giant pulse, nulling or traditional
mode changing phenomena. The energy in the leading and trailing components of
the integrated profile is shown to be correlated. The degree of both linear and
circular polarization increases with the pulse flux density for individual
pulses. Our data indicates that pulse jitter leads to an excess noise in the
timing residuals of 67 ns when scaled to one hour, which is consistent with Liu
et al. (2015). We have unsuccessfully trialled various methods to improve
timing precision through the selection of specific single pulses. Our work
demonstrates that FAST can detect individual pulses from pulsars that are
observed in order to detect and study gravitational waves. This capability
enables detailed studies, and parameterisation, of the noise processes that
affect the sensitivity of a pulsar timing array.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 03:08:34 GMT""}]","2022-02-23"
"2012.06710","Ernazar Abdikamalov","E. Abdikamalov, T. Foglizzo, and O. Mukazhanov","Impact of rotation on the evolution of convective vortices in collapsing
  stars","12 pages, 8 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stab715",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the impact of rotation on the hydrodynamic evolution of convective
vortices during stellar collapse. Using linear hydrodynamics equations, we
study the evolution of the vortices from their initial radii in convective
shells down to smaller radii where they are expected to encounter the supernova
shock. We find that the evolution of vortices is mainly governed by two
effects: the acceleration of infall and the accompanying speed up of rotation.
The former effect leads to the radial stretching of vortices, which limits the
vortex velocities. The latter effect leads to the angular deformation of
vortices in the direction of rotation, amplifying their non-radial velocity. We
show that the radial velocities of the vortices are not significantly affected
by rotation. We study acoustic wave emission and find that it is not sensitive
to rotation. Finally, we analyze the impact of the corotation point and find
that it has a small impact on the overall acoustic wave emission.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 03:23:26 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 05:25:10 GMT""}]","2021-03-17"
"2012.06711","Meng Rongye","Rongye Meng, Sanping Zhou, Xingyu Wan, Mengliu Li, Jinjun Wang","Teacher-Student Asynchronous Learning with Multi-Source Consistency for
  Facial Landmark Detection","second version",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Due to the high annotation cost of large-scale facial landmark detection
tasks in videos, a semi-supervised paradigm that uses self-training for mining
high-quality pseudo-labels to participate in training has been proposed by
researchers. However, self-training based methods often train with a gradually
increasing number of samples, whose performances vary a lot depending on the
number of pseudo-labeled samples added.
  In this paper, we propose a teacher-student asynchronous learning~(TSAL)
framework based on the multi-source supervision signal consistency criterion,
which implicitly mines pseudo-labels through consistency constraints.
Specifically, the TSAL framework contains two models with exactly the same
structure. The radical student uses multi-source supervision signals from the
same task to update parameters, while the calm teacher uses a single-source
supervision signal to update parameters. In order to reasonably absorb
student's suggestions, teacher's parameters are updated again through recursive
average filtering. The experimental results prove that asynchronous-learning
framework can effectively filter noise in multi-source supervision signals,
thereby mining the pseudo-labels which are more significant for network
parameter updating. And extensive experiments on 300W, AFLW, and 300VW
benchmarks show that the TSAL framework achieves state-of-the-art performance.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 03:23:30 GMT""}]","2020-12-15"
"2012.06712","Mostafa Rahimi Azghadi","Mohammad Jahanbakht, Wei Xiang, Lajos Hanzo, Mostafa Rahimi Azghadi","Internet of Underwater Things and Big Marine Data Analytics -- A
  Comprehensive Survey","54 pages, 11 figures, 19 tables, IEEE Communications Surveys &
  Tutorials, peer-reviewed academic journal","IEEE Communications Surveys & Tutorials, 2021","10.1109/COMST.2021.3053118",,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  The Internet of Underwater Things (IoUT) is an emerging communication
ecosystem developed for connecting underwater objects in maritime and
underwater environments. The IoUT technology is intricately linked with
intelligent boats and ships, smart shores and oceans, automatic marine
transportations, positioning and navigation, underwater exploration, disaster
prediction and prevention, as well as with intelligent monitoring and security.
The IoUT has an influence at various scales ranging from a small scientific
observatory, to a midsized harbor, and to covering global oceanic trade. The
network architecture of IoUT is intrinsically heterogeneous and should be
sufficiently resilient to operate in harsh environments. This creates major
challenges in terms of underwater communications, whilst relying on limited
energy resources. Additionally, the volume, velocity, and variety of data
produced by sensors, hydrophones, and cameras in IoUT is enormous, giving rise
to the concept of Big Marine Data (BMD), which has its own processing
challenges. Hence, conventional data processing techniques will falter, and
bespoke Machine Learning (ML) solutions have to be employed for automatically
learning the specific BMD behavior and features facilitating knowledge
extraction and decision support. The motivation of this paper is to
comprehensively survey the IoUT, BMD, and their synthesis. It also aims for
exploring the nexus of BMD with ML. We set out from underwater data collection
and then discuss the family of IoUT data communication techniques with an
emphasis on the state-of-the-art research challenges. We then review the suite
of ML solutions suitable for BMD handling and analytics. We treat the subject
deductively from an educational perspective, critically appraising the material
surveyed.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 03:31:55 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jan 2021 03:11:11 GMT""}]","2021-01-25"
"2012.06713","Sami Davies","Sami Davies, Miklos Z. Racz, Cyrus Rashtchian, Benjamin G. Schiffer","Approximate Trace Reconstruction",,,,,"cs.DS cs.CC cs.IT cs.LG math.IT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the usual trace reconstruction problem, the goal is to exactly reconstruct
an unknown string of length $n$ after it passes through a deletion channel many
times independently, producing a set of traces (i.e., random subsequences of
the string). We consider the relaxed problem of approximate reconstruction.
Here, the goal is to output a string that is close to the original one in edit
distance while using much fewer traces than is needed for exact reconstruction.
We present several algorithms that can approximately reconstruct strings that
belong to certain classes, where the estimate is within $n/\mathrm{polylog}(n)$
edit distance, and where we only use $\mathrm{polylog}(n)$ traces (or sometimes
just a single trace). These classes contain strings that require a linear
number of traces for exact reconstruction and which are quite different from a
typical random string. From a technical point of view, our algorithms
approximately reconstruct consecutive substrings of the unknown string by
aligning dense regions of traces and using a run of a suitable length to
approximate each region. To complement our algorithms, we present a general
black-box lower bound for approximate reconstruction, building on a lower bound
for distinguishing between two candidate input strings in the worst case. In
particular, this shows that approximating to within $n^{1/3 - \delta}$ edit
distance requires $n^{1 + 3\delta/2}/\mathrm{polylog}(n)$ traces for $0< \delta
< 1/3$ in the worst case.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 03:34:26 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 18:27:11 GMT""}]","2020-12-17"
"2012.06714","Alexander Sokolov","Samragni Banerjee, Alexander Yu. Sokolov","Efficient implementation of the single-reference algebraic diagrammatic
  construction theory for charged excitations: Applications to the TEMPO
  radical and DNA base pairs",,"J. Chem. Phys. 154, 074105 (2021)","10.1063/5.0040317",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  We present an efficient implementation of the second- and third-order
single-reference algebraic diagrammatic construction theory for electron
attachment (EA) and ionization (IP) energies and spectra (EA/IP-ADC(n), n = 2,
3). Our new EA/IP-ADC program features spin adaptation for closed-shell
systems, density fitting for efficient handling of the two-electron integral
tensors, as well as vectorized and parallel implementation of tensor
contractions. We demonstrate capabilities of our efficient implementation by
applying the EA/IP-ADC(n) (n = 2, 3) methods to compute the photoelectron
spectrum of the TEMPO radical, as well as the vertical and adiabatic electron
affinities of TEMPO and two DNA base pairs (guanine-cytosine and
adenine-thymine). The spectra and electron affinities computed using large
diffuse basis sets with up to 1028 molecular orbitals are found to be in a good
agreement with the best available results from the experiment and theoretical
simulations.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 03:36:11 GMT""},{""version"":""v2"",""created"":""Sun, 17 Jan 2021 21:39:23 GMT""}]","2021-07-12"
"2012.06715","Yishu Xue","Guanyu Hu, Hou-Cheng Yang, Yishu Xue, Dipak K. Dey","Zero Inflated Poisson Model with Clustered Regression Coefficients: an
  Application to Heterogeneity Learning of Field Goal Attempts of Professional
  Basketball Players",,,,,"stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Although basketball is a dynamic process sport, with 5 plus 5 players
competing on both offense and defense simultaneously, learning some static
information is predominant for professional players, coaches and team mangers.
In order to have a deep understanding of field goal attempts among different
players, we propose a zero inflated Poisson model with clustered regression
coefficients to learn the shooting habits of different players over the court
and the heterogeneity among them. Specifically, the zero inflated model
recovers the large proportion of the court with zero field goal attempts, and
the mixture of finite mixtures model learn the heterogeneity among different
players based on clustered regression coefficients and inflated probabilities.
Both theoretical and empirical justification through simulation studies
validate our proposed method. We apply our proposed model to the National
Basketball Association (NBA), for learning players' shooting habits and
heterogeneity among different players over the 2017--2018 regular season. This
illustrates our model as a way of providing insights from different aspects.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 03:43:15 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 00:38:28 GMT""}]","2021-04-05"
"2012.06716","Gyu Hyun Kim","Gyu Hyun Kim","Non-fundamental Home Bias in International Equity Markets",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study investigates the relationship of the equity home bias with 1) the
country-level behavioral unfamiliarity, and 2) the home-foreign return
correlation. We set the hypotheses that 1) unfamiliarity about foreign equities
plays a role in the portfolio set up and 2) the correlation of return on home
and foreign equities affects the equity home bias when there is a lack of
information about foreign equities. For the empirical analysis, the proportion
of respondents to the question ""How much do you trust? - People you meet for
the first time"" is used as a proxy measure for country-specific unfamiliarity.
Based on the eleven developed countries for which such data are available, we
implement a feasible generalized linear squares (FGLS) method. Empirical
results suggest that country-specific unfamiliarity has a significant and
positive correlation with the equity home bias. When it comes to the
correlation of return between home and foreign equities, we identify that there
is a negative correlation with the equity home bias, which is against our
hypothesis. Moreover, an excess return on home equities compared to foreign
ones is found to have a positive correlation with the equity home bias, which
is consistent with the comparative statics only if foreign investors have a
sufficiently higher risk aversion than domestic investors. We check the
robustness of our empirical analysis by fitting alternative specifications and
use a log-transformed measure of the equity home bias, resulting in consistent
results with ones with the original measure.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 03:48:56 GMT""}]","2020-12-15"
"2012.06717","Hsiang-Yun Chien","Hsiang-Yun Sherry Chien, Jinhan Zhang and Christopher. J. Honey","Mapping the Timescale Organization of Neural Language Models","23 pages, 4 main figures, 10 appendix figures; published as a
  conference paper at ICLR 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the human brain, sequences of language input are processed within a
distributed and hierarchical architecture, in which higher stages of processing
encode contextual information over longer timescales. In contrast, in recurrent
neural networks which perform natural language processing, we know little about
how the multiple timescales of contextual information are functionally
organized. Therefore, we applied tools developed in neuroscience to map the
""processing timescales"" of individual units within a word-level LSTM language
model. This timescale-mapping method assigned long timescales to units
previously found to track long-range syntactic dependencies. Additionally, the
mapping revealed a small subset of the network (less than 15% of units) with
long timescales and whose function had not previously been explored. We next
probed the functional organization of the network by examining the relationship
between the processing timescale of units and their network connectivity. We
identified two classes of long-timescale units: ""controller"" units composed a
densely interconnected subnetwork and strongly projected to the rest of the
network, while ""integrator"" units showed the longest timescales in the network,
and expressed projection profiles closer to the mean projection profile.
Ablating integrator and controller units affected model performance at
different positions within a sentence, suggesting distinctive functions of
these two sets of units. Finally, we tested the generalization of these results
to a character-level LSTM model and models with different architectures. In
summary, we demonstrated a model-free technique for mapping the timescale
organization in recurrent neural networks, and we applied this method to reveal
the timescale and functional organization of neural language models.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 03:52:15 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 21:15:45 GMT""}]","2021-03-19"
"2012.06718","Gabriel Hope","Gabriel Hope, Madina Abdrakhmanova, Xiaoyin Chen, Michael C. Hughes,
  Michael C. Hughes and Erik B. Sudderth","Learning Consistent Deep Generative Models from Sparse Data via
  Prediction Constraints",,,,,"cs.LG cs.CV stat.ML","http://creativecommons.org/licenses/by/4.0/","  We develop a new framework for learning variational autoencoders and other
deep generative models that balances generative and discriminative goals. Our
framework optimizes model parameters to maximize a variational lower bound on
the likelihood of observed data, subject to a task-specific prediction
constraint that prevents model misspecification from leading to inaccurate
predictions. We further enforce a consistency constraint, derived naturally
from the generative model, that requires predictions on reconstructed data to
match those on the original data. We show that these two contributions --
prediction constraints and consistency constraints -- lead to promising image
classification performance, especially in the semi-supervised scenario where
category labels are sparse but unlabeled data is plentiful. Our approach
enables advances in generative modeling to directly boost semi-supervised
classification performance, an ability we demonstrate by augmenting deep
generative models with latent variables capturing spatial transformations.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 04:18:50 GMT""}]","2020-12-15"
"2012.06719","Bishal Chhetri","Bishal Chhetri, D.K.K Vamsi and Carani B Sanjeevi","Optimal Control Studies on Age Structural Modeling of COVID-19 in
  Presence of Saturated Medical Treatment of Holling Type III","34 pages, 101 figures. arXiv admin note: text overlap with
  arXiv:2005.02261",,,,"math.DS physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this study initially, we propose an age structured model and calculate the
equilibrium points and basic reproduction number. Later we propose an optimal
control problem to understand the roles of treatment in controlling the
epidemic. From the Stability analysis we see that the infection free
equilibrium remains asymptotically stable whenever $R_0 < 1$ and as $R_0$
crosses unity we have the infected equilibrium to be stable. From the
sensitivity analysis parameters $u_{11}$, $b_1$, $\beta_1$, $d_1$ and $\mu$
were found to be sensitive. Findings from the Optimal Control studies suggests
that the infection among the adult population(age $\geq 30)$ is least
considering the second control $u_{12}$ whereas, when both the controls
$u_{11}$ and $u_{12}$ are considered together the infectives is minimum in case
of young populations(age $ \leq 30$). The cumulative infected population
reduced the maximum when the second control was considered followed by
considering both the controls together. The control $u_{12}$ was effective for
mild epidemic $(R_0 \in(1, 2))$ whereas control $u_{11}$ was found to be highly
effective when epidemic was severe $(R_0 \in(2, 7))$ for the population of age
group $(\leq 30)$. Whereas for age group $(\geq 30)$ the control $u_{12}$ was
highly effective for the entire range of basic reproduction number. The effect
of saturation level in treatment is also explored numerically.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 04:20:55 GMT""}]","2020-12-15"
"2012.06720","Huachuan Wang","Huachuan Wang and James Ting-Ho Lo","Low-Order Model of Biological Neural Networks",,,,,"math.OC cs.NE q-bio.NC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A biologically plausible low-order model (LOM) of biological neural networks
is a recurrent hierarchical network of dendritic nodes/trees,
spiking/nonspiking neurons, unsupervised/ supervised covariance/accumulative
learning mechanisms, feedback connections, and a scheme for maximal
generalization. These component models are motivated and necessitated by making
LOM learn and retrieve easily without differentiation, optimization, or
iteration, and cluster, detect and recognize multiple/hierarchical corrupted,
distorted, and occluded temporal and spatial patterns.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 04:22:09 GMT""}]","2020-12-15"
"2012.06721","Heba Sami","Heba Sami and Amare Abebe","Perturbations of quasi-Newtonian universes in scalar-tensor gravity","30 pages, 25 figures",,"10.1142/S0219887821501589",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this contribution, we consider the equivalence between $f(R)$ gravity and
scalar-tensor theories to study the evolution of scalar cosmological
perturbations in the $1 + 3$ covariant formalism for the classes of shear-free
cosmological dust models with irrotational fluid flows. The $f(R)$ gravity is
considered to be a subclass of Brans-Dicke models, we gave an overview on the
equivalence between $f(R)$ gravity and scalar-tensor theories. We use the $1 +
3$ covariant formalism to present the covariant linearised evolution and
constraint equations. We then derive the integrability conditions describing a
consistent evolution of the linearised field equations of quasi-Newtonian
universes in the scalar-tensor theories of gravity. Finally, we derive the
evolution equations for the density and velocity perturbations of the
quasi-Newtonian universe. We apply the harmonic decomposition and we explore
the behaviour of the matter density contrast by considering $R^{n}$ models. We
introduce the so-called quasi-static approximation to study the approximated
solutions on small scales. The growth of the matter density contrast for both
short- and long- wavelength modes has been examined by applying certain
assumptions of the initial conditions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 04:25:36 GMT""}]","2021-09-22"
"2012.06722","Qihang Yu","Qihang Yu, Jianming Zhang, He Zhang, Yilin Wang, Zhe Lin, Ning Xu,
  Yutong Bai, Alan Yuille","Mask Guided Matting via Progressive Refinement Network","CVPR 2021, code available at https://github.com/yucornetto/MGMatting",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose Mask Guided (MG) Matting, a robust matting framework that takes a
general coarse mask as guidance. MG Matting leverages a network (PRN) design
which encourages the matting model to provide self-guidance to progressively
refine the uncertain regions through the decoding process. A series of guidance
mask perturbation operations are also introduced in the training to further
enhance its robustness to external guidance. We show that PRN can generalize to
unseen types of guidance masks such as trimap and low-quality alpha matte,
making it suitable for various application pipelines. In addition, we revisit
the foreground color prediction problem for matting and propose a surprisingly
simple improvement to address the dataset issue. Evaluation on real and
synthetic benchmarks shows that MG Matting achieves state-of-the-art
performance using various types of guidance inputs. Code and models are
available at https://github.com/yucornetto/MGMatting.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 04:26:14 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 00:57:47 GMT""}]","2021-04-05"
"2012.06723","Sahil Sidheekh","Sahil Sidheekh, Aroof Aimen, Vineet Madan, Narayanan C. Krishnan","On Duality Gap as a Measure for Monitoring GAN Training",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative adversarial network (GAN) is among the most popular deep learning
models for learning complex data distributions. However, training a GAN is
known to be a challenging task. This is often attributed to the lack of
correlation between the training progress and the trajectory of the generator
and discriminator losses and the need for the GAN's subjective evaluation. A
recently proposed measure inspired by game theory - the duality gap, aims to
bridge this gap. However, as we demonstrate, the duality gap's capability
remains constrained due to limitations posed by its estimation process. This
paper presents a theoretical understanding of this limitation and proposes a
more dependable estimation process for the duality gap. At the crux of our
approach is the idea that local perturbations can help agents in a zero-sum
game escape non-Nash saddle points efficiently. Through exhaustive
experimentation across GAN models and datasets, we establish the efficacy of
our approach in capturing the GAN training progress with minimal increase to
the computational complexity. Further, we show that our estimate, with its
ability to identify model convergence/divergence, is a potential performance
measure that can be used to tune the hyperparameters of a GAN.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 04:32:52 GMT""}]","2020-12-15"
"2012.06724","Rajashekhar V S","Rajashekhar V S, Rokesh Laishram, Kaushik Das and Debasish Ghose","Synthesis of a Six-Bar Gripper Mechanism for Aerial Grasping","11 pages, 7 figures, presented at Mohammad Bin Zayed International
  Robotics Competition (MBZIRC) Symposium 2020",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a 1-DoF gripper mechanism has been synthesized for the type of
mechanism, number of links and joints, and the dimensions of length, width and
thickness of links. The type synthesis is done by selecting the proper class of
mechanism from Reuleaux's six classes of mechanisms. The number synthesis is
done by using an algebraic method. The dimensions of the linkages are found
using the geometric programming method. The gripper is then modeled in a
computer aided design software and then fabricated using an additive
manufacturing technique. Finally the gripper mechanism with DC motor as an
actuator is mounted on an Unmanned Aerial Vehicle (UAV) to grip a spherical
object moving in space. This work is related to a task in challenge 1 of
Mohamed Bin Zayed International Robotics Challenge (MBZIRC)-2020.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 04:43:32 GMT""}]","2020-12-15"
"2012.06725","Nikos Vlassis","Nikos Vlassis, Phil Hebda, Stephan McBride, Athanasios Noulas","On Proximal Causal Learning with Many Hidden Confounders",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We generalize the proximal g-formula of Miao, Geng, and Tchetgen Tchetgen
(2018) for causal inference under unobserved confounding using proxy variables.
Specifically, we show that the formula holds true for all causal models in a
certain equivalence class, and this class contains models in which the total
number of levels for the set of unobserved confounders can be arbitrarily
larger than the number of levels of each proxy variable. Although
straightforward to obtain, the result can be significant for applications.
Simulations corroborate our formal arguments.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 04:55:34 GMT""}]","2020-12-15"
"2012.06726","Srikanth Sastry","Srikanth Sastry","Models for the yielding behaviour of amorphous solids",,"Phys. Rev. Lett. 126, 255501 (2021)","10.1103/PhysRevLett.126.255501",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Understanding the mechanical response and failure of solids is of obvious
importance in their use as structural materials. The nature of plastic
deformation leading to yielding of amorphous solids has been vigorously pursued
in recent years. Investigations employing both unidirectional and cyclic
deformation protocols reveal a strong dependence of yielding behaviour on the
degree of annealing. Below a threshold degree of annealing, the nature of
yielding changes qualitatively, to progressively more discontinuous yielding.
Theoretical investigations of yielding in amorphous solids have almost
exclusively focused on yielding under unidirectional deformation, but cyclic
deformation reveals several interesting features that remain largely
un-investigated. Focusing on athermal cyclic deformation, I investigate a
family of models based on an energy landscape description. These models
reproduce key interesting features observed in simulations, and provide an
interpretation for the intriguing presence of a threshold energy.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 04:56:56 GMT""}]","2021-06-30"
"2012.06727","Haoya Li","Haoya Li, Yuehaw Khoo, Yinuo Ren, Lexing Ying","A semigroup method for high dimensional committor functions based on
  neural network","21 pages, 14 figures; Final version accepted at MSML 2021",,,,"math.NA cs.LG cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a new method based on neural networks for computing the
high-dimensional committor functions that satisfy Fokker-Planck equations.
Instead of working with partial differential equations, the new method works
with an integral formulation based on the semigroup of the differential
operator. The variational form of the new formulation is then solved by
parameterizing the committor function as a neural network. There are two major
benefits of this new approach. First, stochastic gradient descent type
algorithms can be applied in the training of the committor function without the
need of computing any mixed second-order derivatives. Moreover, unlike the
previous methods that enforce the boundary conditions through penalty terms,
the new method takes into account the boundary conditions automatically.
Numerical results are provided to demonstrate the performance of the proposed
method.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:00:47 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 19:12:09 GMT""},{""version"":""v3"",""created"":""Wed, 5 May 2021 04:35:37 GMT""}]","2021-05-06"
"2012.06729","Tadahiro Oh","Tadahiro Oh, Kihoon Seong, and Leonardo Tolomeo","A remark on Gibbs measures with log-correlated Gaussian fields","38 pages. We added an argument, showing a precise rate of divergence",,,,"math.PR math-ph math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study Gibbs measures with log-correlated base Gaussian fields on the
$d$-dimensional torus. In the defocusing case, the construction of such Gibbs
measures follows from Nelson's argument. In this paper, we consider the
focusing case with a quartic interaction. Using the variational formulation, we
prove non-normalizability of the Gibbs measure. When $d = 2$, our argument
provides an alternative proof of the non-normalizability result for the
focusing $\Phi^4_2$-measure by Brydges and Slade (1996). Furthermore, we
provide a precise rate of divergence, where the constant is characterized by
the optimal constant for a certain Bernstein's inequality on $\mathbb{R}^d$. We
also go over the construction of the focusing Gibbs measure with a cubic
interaction. In the appendices, we present (a) non-normalizability of the Gibbs
measure for the two-dimensional Zakharov system and (b) the construction of
focusing quartic Gibbs measures with smoother base Gaussian measures, showing a
critical nature of the log-correlated Gibbs measure with a focusing quartic
interaction.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:07:08 GMT""},{""version"":""v2"",""created"":""Thu, 13 Apr 2023 03:02:35 GMT""}]","2023-04-14"
"2012.06730","Yun Meng","Yun Meng, Kai Zou, Nan Hu, Liang Xu, Xiaojian Lan, Stephan Steinhauer,
  Samuel Gyger, Val Zwiller, Xiaolong Hu","Fractal superconducting nanowires detect infrared single photons with
  84% system detection efficiency, 1.02 polarization sensitivity, and 20.8 ps
  timing resolution","8 pages, 4 figures",,"10.1021/acsphotonics.1c00730",,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The near-unity system detection efficiency (SDE) and excellent timing
resolution of superconducting nanowire single-photon detectors (SNSPDs),
combined with their other merits, have enabled many classical and quantum
photonic applications. However, the prevalent design based on meandering
nanowires makes SDE dependent on the polarization states of the incident
photons; for unpolarized light, the major merit of high SDE would get
compromised, which could be detrimental for photon-starved applications. Here,
we create SNSPDs with an arced fractal geometry that almost completely
eliminates this polarization dependence of the SDE, and we experimentally
demonstrate 84$\pm$3$\%$ SDE, 1.02$^{+0.06}_{-0.02}$ polarization sensitivity
at the wavelength of 1575 nm, and 20.8 ps timing jitter in a 0.1-W closed-cycle
Gifford-McMahon cryocooler, at the base temperature of 2.0 K. This
demonstration provides a novel, practical device structure of SNSPDs, allowing
for operation in the visible, near-, and mid-infrared spectral ranges, and
paves the way for polarization-insensitive single-photon detection with high
SDE and high timing resolution
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:07:31 GMT""},{""version"":""v2"",""created"":""Thu, 31 Mar 2022 07:04:30 GMT""}]","2022-04-12"
"2012.06731","Robin Swezey","Robin Swezey, Aditya Grover, Bruno Charron, Stefano Ermon","PiRank: Scalable Learning To Rank via Differentiable Sorting",,"Advances in Neural Information Processing Systems 34
  pre-proceedings (NeurIPS 2021)",,,"cs.LG cs.AI cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A key challenge with machine learning approaches for ranking is the gap
between the performance metrics of interest and the surrogate loss functions
that can be optimized with gradient-based methods. This gap arises because
ranking metrics typically involve a sorting operation which is not
differentiable w.r.t. the model parameters. Prior works have proposed
surrogates that are loosely related to ranking metrics or simple smoothed
versions thereof, and often fail to scale to real-world applications. We
propose PiRank, a new class of differentiable surrogates for ranking, which
employ a continuous, temperature-controlled relaxation to the sorting operator
based on NeuralSort [1]. We show that PiRank exactly recovers the desired
metrics in the limit of zero temperature and further propose a divide
and-conquer extension that scales favorably to large list sizes, both in theory
and practice. Empirically, we demonstrate the role of larger list sizes during
training and show that PiRank significantly improves over comparable approaches
on publicly available internet-scale learning-to-rank benchmarks.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:07:36 GMT""},{""version"":""v2"",""created"":""Sat, 27 Nov 2021 03:12:33 GMT""}]","2021-11-30"
"2012.06732","Tadahiro Oh","Tadahiro Oh and Kihoon Seong","Quasi-invariant Gaussian measures for the cubic fourth order nonlinear
  Schr\""odinger equation in negative Sobolev spaces","40 pages. Updated references","J. Funct. Anal. 281 (2021), no. 9, 109150, 49 pp",,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We continue the study on the transport properties of the Gaussian measures on
Sobolev spaces under the dynamics of the cubic fourth order nonlinear
Schr\""odinger equation. By considering the renormalized equation, we extend the
quasi-invariance results in [30, 27] to Sobolev spaces of negative regularity.
Our proof combines the approach introduced by Planchon, Tzvetkov, and Visciglia
[35] with the normal form approach in [30, 27].
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:09:15 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 14:15:11 GMT""},{""version"":""v3"",""created"":""Sun, 15 Aug 2021 16:55:47 GMT""}]","2021-08-17"
"2012.06733","Ajay Mandlekar","Ajay Mandlekar, Danfei Xu, Roberto Mart\'in-Mart\'in, Yuke Zhu, Li
  Fei-Fei, Silvio Savarese","Human-in-the-Loop Imitation Learning using Remote Teleoperation",,,,,"cs.RO cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Imitation Learning is a promising paradigm for learning complex robot
manipulation skills by reproducing behavior from human demonstrations. However,
manipulation tasks often contain bottleneck regions that require a sequence of
precise actions to make meaningful progress, such as a robot inserting a pod
into a coffee machine to make coffee. Trained policies can fail in these
regions because small deviations in actions can lead the policy into states not
covered by the demonstrations. Intervention-based policy learning is an
alternative that can address this issue -- it allows human operators to monitor
trained policies and take over control when they encounter failures. In this
paper, we build a data collection system tailored to 6-DoF manipulation
settings, that enables remote human operators to monitor and intervene on
trained policies. We develop a simple and effective algorithm to train the
policy iteratively on new data collected by the system that encourages the
policy to learn how to traverse bottlenecks through the interventions. We
demonstrate that agents trained on data collected by our intervention-based
system and algorithm outperform agents trained on an equivalent number of
samples collected by non-interventional demonstrators, and further show that
our method outperforms multiple state-of-the-art baselines for learning from
the human interventions on a challenging robot threading task and a coffee
making task. Additional results and videos at
https://sites.google.com/stanford.edu/iwr .
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:30:35 GMT""}]","2020-12-15"
"2012.06734","Yuliang Guo","Yuliang Guo, Zhong Li, Zekun Li, Xiangyu Du, Shuxue Quan, Yi Xu","PoP-Net: Pose over Parts Network for Multi-Person 3D Pose Estimation
  from a Depth Image",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, a real-time method called PoP-Net is proposed to predict
multi-person 3D poses from a depth image. PoP-Net learns to predict bottom-up
part representations and top-down global poses in a single shot. Specifically,
a new part-level representation, called Truncated Part Displacement Field
(TPDF), is introduced which enables an explicit fusion process to unify the
advantages of bottom-up part detection and global pose detection. Meanwhile, an
effective mode selection scheme is introduced to automatically resolve the
conflicting cases between global pose and part detections. Finally, due to the
lack of high-quality depth datasets for developing multi-person 3D pose
estimation, we introduce Multi-Person 3D Human Pose Dataset (MP-3DHP) as a new
benchmark. MP-3DHP is designed to enable effective multi-person and background
data augmentation in model training, and to evaluate 3D human pose estimators
under uncontrolled multi-person scenarios. We show that PoP-Net achieves the
state-of-the-art results both on MP-3DHP and on the widely used ITOP dataset,
and has significant advantages in efficiency for multi-person processing. To
demonstrate one of the applications of our algorithm pipeline, we also show
results of virtual avatars driven by our calculated 3D joint positions. MP-3DHP
Dataset and the evaluation code have been made available at:
https://github.com/oppo-us-research/PoP-Net.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:32:25 GMT""},{""version"":""v2"",""created"":""Thu, 25 Nov 2021 01:10:34 GMT""}]","2021-11-29"
"2012.06735","Yu Yin","Yu Yin, Joseph P. Robinson, Yun Fu","Multimodal In-bed Pose and Shape Estimation under the Blankets",,,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humans spend vast hours in bed -- about one-third of the lifetime on average.
Besides, a human at rest is vital in many healthcare applications. Typically,
humans are covered by a blanket when resting, for which we propose a multimodal
approach to uncover the subjects so their bodies at rest can be viewed without
the occlusion of the blankets above. We propose a pyramid scheme to effectively
fuse the different modalities in a way that best leverages the knowledge
captured by the multimodal sensors. Specifically, the two most informative
modalities (i.e., depth and infrared images) are first fused to generate good
initial pose and shape estimation. Then pressure map and RGB images are further
fused one by one to refine the result by providing occlusion-invariant
information for the covered part, and accurate shape information for the
uncovered part, respectively. However, even with multimodal data, the task of
detecting human bodies at rest is still very challenging due to the extreme
occlusion of bodies. To further reduce the negative effects of the occlusion
from blankets, we employ an attention-based reconstruction module to generate
uncovered modalities, which are further fused to update current estimation via
a cyclic fashion. Extensive experiments validate the superiority of the
proposed model over others.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:35:23 GMT""}]","2020-12-15"
"2012.06736","Markus Allgaier","Tiemo Landes, Markus Allgaier, Sofiane Merkouche, Brian J. Smith,
  Andrew H. Marcus, Michael G. Raymer","Experimental feasibility of molecular two-photon absorption with
  isolated time-frequency-entangled photon pairs",,"Phys. Rev. Research 3, 033154 (2021)","10.1103/PhysRevResearch.3.033154",,"quant-ph physics.chem-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Entangled photon pairs have been promised to deliver a substantial quantum
advantage for two-photon absorption spectroscopy. However, recent work has
challenged the previously reported magnitude of quantum enhancement in
two-photon absorption. Here, we present an experimental comparison of
sum-frequency generation and molecular absorption, each driven by isolated
photon pairs. We establish an upper bound on the enhancement for
entangled-two-photon absorption in Rhodamine-6G, which lies well below
previously reported values.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:36:50 GMT""}]","2021-08-18"
"2012.06737","Zijian Kuang","Zijian Kuang, Xinran Tie, Lihang Ying, Shi Jin","Computer Vision and Normalizing Flow-Based Defect Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual defect detection is critical to ensure the quality of most products.
However, the majority of small and medium-sized manufacturing enterprises still
rely on tedious and error-prone human manual inspection. The main reasons
include: 1) the existing automated visual defect detection systems require
altering production assembly lines, which is time consuming and expensive 2)
the existing systems require manually collecting defective samples and labeling
them for a comparison-based algorithm or training a machine learning model.
This introduces a heavy burden for small and medium-sized manufacturing
enterprises as defects do not happen often and are difficult and time-consuming
to collect. Furthermore, we cannot exhaustively collect or define all defect
types as any new deviation from acceptable products are defects. In this paper,
we overcome these challenges and design a three-stage plug-and-play fully
automated unsupervised 360-degree defect detection system. In our system,
products are freely placed on an unaltered assembly line and receive 360 degree
visual inspection with multiple cameras from different angles. As such, the
images collected from real-world product assembly lines contain lots of
background noise. The products face different angles. The product sizes vary
due to the distance to cameras. All these make defect detection much more
difficult. Our system use object detection, background subtraction and
unsupervised normalizing flow-based defect detection techniques to tackle these
difficulties. Experiments show our system can achieve 0.90 AUROC in a
real-world non-altered drinkware production assembly line.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:38:21 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 02:50:56 GMT""},{""version"":""v3"",""created"":""Thu, 20 Jan 2022 02:52:36 GMT""},{""version"":""v4"",""created"":""Mon, 14 Feb 2022 04:22:41 GMT""}]","2022-02-15"
"2012.06738","Ajay Mandlekar","Albert Tung, Josiah Wong, Ajay Mandlekar, Roberto Mart\'in-Mart\'in,
  Yuke Zhu, Li Fei-Fei, Silvio Savarese","Learning Multi-Arm Manipulation Through Collaborative Teleoperation","First two authors contributed equally",,,,"cs.RO cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Imitation Learning (IL) is a powerful paradigm to teach robots to perform
manipulation tasks by allowing them to learn from human demonstrations
collected via teleoperation, but has mostly been limited to single-arm
manipulation. However, many real-world tasks require multiple arms, such as
lifting a heavy object or assembling a desk. Unfortunately, applying IL to
multi-arm manipulation tasks has been challenging -- asking a human to control
more than one robotic arm can impose significant cognitive burden and is often
only possible for a maximum of two robot arms. To address these challenges, we
present Multi-Arm RoboTurk (MART), a multi-user data collection platform that
allows multiple remote users to simultaneously teleoperate a set of robotic
arms and collect demonstrations for multi-arm tasks. Using MART, we collected
demonstrations for five novel two and three-arm tasks from several
geographically separated users. From our data we arrived at a critical insight:
most multi-arm tasks do not require global coordination throughout its full
duration, but only during specific moments. We show that learning from such
data consequently presents challenges for centralized agents that directly
attempt to model all robot actions simultaneously, and perform a comprehensive
study of different policy architectures with varying levels of centralization
on our tasks. Finally, we propose and evaluate a base-residual policy framework
that allows trained policies to better adapt to the mixed coordination setting
common in multi-arm manipulation, and show that a centralized policy augmented
with a decentralized residual model outperforms all other models on our set of
benchmark tasks. Additional results and videos at
https://roboturk.stanford.edu/multiarm .
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:43:43 GMT""}]","2020-12-15"
"2012.06739","Sandeep Chinchali","Sandeep Chinchali, Evgenya Pergament, Manabu Nakanoya, Eyal Cidon,
  Edward Zhang, Dinesh Bharadia, Marco Pavone, and Sachin Katti","Sampling Training Data for Continual Learning Between Robots and the
  Cloud","International Symposium on Experimental Robotics (ISER) 2020, Malta",,,,"cs.RO cs.CV cs.DC cs.LG cs.NI","http://creativecommons.org/licenses/by/4.0/","  Today's robotic fleets are increasingly measuring high-volume video and LIDAR
sensory streams, which can be mined for valuable training data, such as rare
scenes of road construction sites, to steadily improve robotic perception
models. However, re-training perception models on growing volumes of rich
sensory data in central compute servers (or the ""cloud"") places an enormous
time and cost burden on network transfer, cloud storage, human annotation, and
cloud computing resources. Hence, we introduce HarvestNet, an intelligent
sampling algorithm that resides on-board a robot and reduces system bottlenecks
by only storing rare, useful events to steadily improve perception models
re-trained in the cloud. HarvestNet significantly improves the accuracy of
machine-learning models on our novel dataset of road construction sites, field
testing of self-driving cars, and streaming face recognition, while reducing
cloud storage, dataset annotation time, and cloud compute time by between
65.7-81.3%. Further, it is between 1.05-2.58x more accurate than baseline
algorithms and scalably runs on embedded deep learning hardware. We provide a
suite of compute-efficient perception models for the Google Edge Tensor
Processing Unit (TPU), an extended technical report, and a novel video dataset
to the research community at https://sites.google.com/view/harvestnet.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 05:52:33 GMT""}]","2020-12-15"
"2012.06740","Emma Dahl","Emma K. Dahl, Nancy J. Chanover, Glenn S. Orton, Kevin H. Baines,
  James A. Sinclair, David G. Voelz, Erandi A. Wijerathna, Paul D. Strycker,
  Patrick G. J. Irwin","Vertical Structure and Color of Jovian Latitudinal Cloud Bands during
  the Juno Era","38 pages, 21 figures; Accepted for publication in AAS Planetary
  Science Journal",,,,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The identity of the coloring agent(s) in Jupiter's atmosphere and the exact
structure of Jupiter's uppermost cloud deck are yet to be conclusively
understood. The Cr\`{e}me Br\^ul\'ee model of Jupiter's tropospheric clouds,
originally proposed by Baines et al. (2014) and expanded upon by Sromovsky et
al. (2017) and Baines et al. (2019), presumes that the chromophore measured by
Carlson et al. (2016) is the singular coloring agent in Jupiter's troposphere.
In this work, we test the validity of the Cr\`{e}me Br\^ul\'ee model of
Jupiter's uppermost cloud deck using spectra measured during the Juno
spacecraft's 5$^{\mathrm{th}}$ perijove pass in March 2017. These data were
obtained as part of an international ground-based observing campaign in support
of the Juno mission using the NMSU Acousto-optic Imaging Camera (NAIC) at the
3.5-m telescope at Apache Point Observatory in Sunspot, NM. We find that the
Cr\`{e}me Br\^ul\'ee model cloud layering scheme can reproduce Jupiter's
visible spectrum both with the Carlson et al. (2016) chromophore and with
modifications to its imaginary index of refraction spectrum. While the
Cr\`{e}me Br\^ul\'ee model provides reasonable results for regions of Jupiter's
cloud bands such as the North Equatorial Belt and Equatorial Zone, we find that
it is not a safe assumption for unique weather events, such as the 2016-2017
Southern Equatorial Belt outbreak that was captured by our measurements.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 06:03:13 GMT""}]","2020-12-15"
"2012.06741","Pavel Levashov","Alexey Kozharin and Pavel Levashov","Thermodynamic Coefficients of Ideal Fermi-gas","9 pages",,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present analytical formulae for the first and second derivatives of the
Helmholtz free energy of non-relativistic ideal Fermi-gas. Important
thermodynamic quantities such as heat capacity, sound velocity, heat capacity
ratio and others can be easily expressed through the derivatives. We
demonstrate correct ideal Boltzmann gas and low--temperature Fermi-gas
asymptotes and derive corrections to thermodynamic functions for these limiting
cases. Numerical computations of thermodynamic properties of ideal Fermi-gas
can be accurately performed using the developed freely available Python module
ifg.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 06:15:34 GMT""}]","2020-12-15"
"2012.06742","Ruda Zhang","Ruda Zhang and Roger Ghanem","Multi-market Oligopoly of Equal Capacity","arXiv admin note: text overlap with arXiv:2008.10775",,,,"math.OC econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a variant of Cournot competition, where multiple firms allocate
the same amount of resource across multiple markets. We prove that the game has
a unique pure-strategy Nash equilibrium (NE), which is symmetric and is
characterized by the maximal point of a ""potential function"". The NE is
globally asymptotically stable under the gradient adjustment process, and is
not socially optimal in general. An application is in transportation, where
drivers allocate time over a street network.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 06:37:49 GMT""}]","2020-12-15"
"2012.06743","Changbo Qu","Xiaoying Wang, Changbo Qu, Weiyuan Wu, Jiannan Wang, Qingqing Zhou","Are We Ready For Learned Cardinality Estimation?",,"PVLDB, 14(9): 1640 - 1654, 2021","10.14778/3461535.3461552",,"cs.DB cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cardinality estimation is a fundamental but long unresolved problem in query
optimization. Recently, multiple papers from different research groups
consistently report that learned models have the potential to replace existing
cardinality estimators. In this paper, we ask a forward-thinking question: Are
we ready to deploy these learned cardinality models in production? Our study
consists of three main parts. Firstly, we focus on the static environment
(i.e., no data updates) and compare five new learned methods with eight
traditional methods on four real-world datasets under a unified workload
setting. The results show that learned models are indeed more accurate than
traditional methods, but they often suffer from high training and inference
costs. Secondly, we explore whether these learned models are ready for dynamic
environments (i.e., frequent data updates). We find that they cannot catch up
with fast data up-dates and return large errors for different reasons. For less
frequent updates, they can perform better but there is no clear winner among
themselves. Thirdly, we take a deeper look into learned models and explore when
they may go wrong. Our results show that the performance of learned methods can
be greatly affected by the changes in correlation, skewness, or domain size.
More importantly, their behaviors are much harder to interpret and often
unpredictable. Based on these findings, we identify two promising research
directions (control the cost of learned models and make learned models
trustworthy) and suggest a number of research opportunities. We hope that our
study can guide researchers and practitioners to work together to eventually
push learned cardinality estimators into real database systems.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 06:52:11 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 07:04:05 GMT""},{""version"":""v3"",""created"":""Mon, 15 Mar 2021 23:35:27 GMT""},{""version"":""v4"",""created"":""Tue, 10 Aug 2021 20:39:03 GMT""}]","2021-08-12"
"2012.06744","KitIan Kou","Z. Cai, K.I. Kou and W. Zhang","Solutions of quaternion-valued differential equations with or without
  commutativity",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most results on quaternion-valued differential equation (QDE) are based on J.
Campos and J. Mawhin's fundamental solution of exponential form for the
homogeneous linear equation, but their result requires a commutativity
property. In this paper we discuss with two problems: What quaternion function
satisfies the commutativity property? Without the commutativity property, what
can we do for the homogeneous equation? We prove that the commutativity
property actually requires quaternionic functions to be complex-like functions.
Without the commutativity property, we reduce the initial value problem of the
homogeneous equation to a real nonautonomous nonlinear differential equation.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 06:53:16 GMT""}]","2020-12-15"
"2012.06745","Ruimeng Hu","Yao Xuan, Robert Balkin, Jiequn Han, Ruimeng Hu, Hector D. Ceniceros","Optimal Policies for a Pandemic: A Stochastic Game Approach and a Deep
  Learning Algorithm",,,,,"math.OC cs.LG math.DS","http://creativecommons.org/licenses/by/4.0/","  Game theory has been an effective tool in the control of disease spread and
in suggesting optimal policies at both individual and area levels. In this
paper, we propose a multi-region SEIR model based on stochastic differential
game theory, aiming to formulate optimal regional policies for infectious
diseases. Specifically, we enhance the standard epidemic SEIR model by taking
into account the social and health policies issued by multiple region planners.
This enhancement makes the model more realistic and powerful. However, it also
introduces a formidable computational challenge due to the high dimensionality
of the solution space brought by the presence of multiple regions. This
significant numerical difficulty of the model structure motivates us to
generalize the deep fictitious algorithm introduced in [Han and Hu, MSML2020,
pp.221--245, PMLR, 2020] and develop an improved algorithm to overcome the
curse of dimensionality. We apply the proposed model and algorithm to study the
COVID-19 pandemic in three states: New York, New Jersey, and Pennsylvania. The
model parameters are estimated from real data posted by the Centers for Disease
Control and Prevention (CDC). We are able to show the effects of the
lockdown/travel ban policy on the spread of COVID-19 for each state and how
their policies affect each other.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:10:46 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 20:15:55 GMT""}]","2021-03-10"
"2012.06746","Yoon Gyo Jung","Yoon Gyo Jung, Jaewoo Park, Cheng Yaw Low, Jacky Chen Long Chai,
  Leslie Ching Ow Tiong, Andrew Beng Jin Teoh","Periocular Embedding Learning with Consistent Knowledge Distillation
  from Face","Submitted to IEEE TIP. The first two authors have contributed equally",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Periocular biometric, the peripheral area of the ocular, is a collaborative
alternative to the face, especially when the face is occluded or masked.
However, in practice, sole periocular biometric capture the least salient
facial features, thereby lacking discriminative information, particularly in
wild environments. To address these problems, we transfer discriminatory
information from the face to support the training of a periocular network by
using knowledge distillation. Specifically, we leverage face images for
periocular embedding learning, but periocular alone is utilized for identity
identification or verification. To enhance periocular embeddings by face
effectively, we proposeConsistent Knowledge Distillation (CKD) that imposes
consistency between face and periocular networks across prediction and feature
layers. We find that imposing consistency at the prediction layer enables (1)
extraction of global discriminative relationship information from face images
and (2) effective transfer of the information from the face network to the
periocular network. Particularly, consistency regularizes the prediction units
to extract and store profound inter-class relationship information of face
images. (3) The feature layer consistency, on the other hand, makes the
periocular features robust against identity-irrelevant attributes. Overall, CKD
empowers the sole periocular network to produce robust discriminative
embeddings for periocular recognition in the wild. We theoretically and
empirically validate the core principles of the distillation mechanism in CKD,
discovering that CKD is equivalent to label smoothing with a novel
sparsity-oriented regularizer that helps the network prediction to capture the
global discriminative relationship. Extensive experiments reveal that CKD
achieves state-of-the-art results on standard periocular recognition benchmark
datasets.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:12:21 GMT""},{""version"":""v2"",""created"":""Sun, 9 Oct 2022 11:50:00 GMT""}]","2022-10-11"
"2012.06747","Rohit Vaish","Elliot Anshelevich, Zack Fitzsimmons, Rohit Vaish, Lirong Xia","Representative Proxy Voting",,,,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  We study a model of proxy voting where the candidates, voters, and proxies
are all located on the real line, and instead of voting directly, each voter
delegates its vote to the closest proxy. The goal is to find a set of proxies
that is $\theta$-representative, which entails that for any voter located
anywhere on the line, its favorite candidate is within a distance $\theta$ of
the favorite candidate of its closest proxy. This property guarantees a strong
form of representation as the set of voters is not required to be fixed in
advance, or even be finite. We show that for candidates located on a line, an
optimal proxy arrangement can be computed in polynomial time. Moreover, we
provide upper and lower bounds on the number of proxies required to form a
$\theta$-representative set, thus showing that a relatively small number of
proxies is enough to capture the preferences of any set of voters. An
additional beneficial property of a $\theta$-representative proxy arrangement
is that for strict-Condorcet voting rules, the outcome of proxy voting is
similarly close to the outcome of direct voting.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:17:01 GMT""}]","2020-12-15"
"2012.06748","Vidhur Kumar","Vidhur Kumar and Andrew Szidon","Efficient Incorporation of Multiple Latency Targets in the Once-For-All
  Network","8 pages, 6 figures",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Neural Architecture Search has proven an effective method of automating
architecture engineering. Recent work in the field has been to look for
architectures subject to multiple objectives such as accuracy and latency to
efficiently deploy them on different target hardware. Once-for-All (OFA) is one
such method that decouples training and search and is able to find
high-performance networks for different latency constraints. However, the
search phase is inefficient at incorporating multiple latency targets. In this
paper, we introduce two strategies (Top-down and Bottom-up) that use warm
starting and randomized network pruning for the efficient incorporation of
multiple latency targets in the OFA network. We evaluate these strategies
against the current OFA implementation and demonstrate that our strategies
offer significant running time performance gains while not sacrificing the
accuracy of the subnetworks that were found for each latency target. We further
demonstrate that these performance gains are generalized to every design space
used by the OFA network.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:34:09 GMT""}]","2020-12-15"
"2012.06749","Yanzhang He","Rohit Prabhavalkar, Yanzhang He, David Rybach, Sean Campbell, Arun
  Narayanan, Trevor Strohman, Tara N. Sainath","Less Is More: Improved RNN-T Decoding Using Limited Label Context and
  Path Merging",,,,,"cs.CL cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  End-to-end models that condition the output label sequence on all previously
predicted labels have emerged as popular alternatives to conventional systems
for automatic speech recognition (ASR). Since unique label histories correspond
to distinct models states, such models are decoded using an approximate
beam-search process which produces a tree of hypotheses.
  In this work, we study the influence of the amount of label context on the
model's accuracy, and its impact on the efficiency of the decoding process. We
find that we can limit the context of the recurrent neural network transducer
(RNN-T) during training to just four previous word-piece labels, without
degrading word error rate (WER) relative to the full-context baseline. Limiting
context also provides opportunities to improve the efficiency of the
beam-search process during decoding by removing redundant paths from the active
beam, and instead retaining them in the final lattice. This path-merging scheme
can also be applied when decoding the baseline full-context model through an
approximation. Overall, we find that the proposed path-merging scheme is
extremely effective allowing us to improve oracle WERs by up to 36% over the
baseline, while simultaneously reducing the number of model evaluations by up
to 5.3% without any degradation in WER.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:39:21 GMT""}]","2020-12-15"
"2012.06750","Philip Thompson","Philip Thompson","Outlier-robust sparse/low-rank least-squares regression and robust
  matrix completion","Correction of typos; addition of simulation results; addition of new
  oracle inequalities for Lasso and Slope in Appendix",,,,"math.ST stat.ML stat.TH","http://creativecommons.org/licenses/by/4.0/","  We study high-dimensional least-squares regression within a subgaussian
statistical learning framework with heterogeneous noise. It includes $s$-sparse
and $r$-low-rank least-squares regression when a fraction $\epsilon$ of the
labels are adversarially contaminated. We also present a novel theory of
trace-regression with matrix decomposition based on a new application of the
product process. For these problems, we show novel near-optimal ""subgaussian""
estimation rates of the form
$r(n,d_{e})+\sqrt{\log(1/\delta)/n}+\epsilon\log(1/\epsilon)$, valid with
probability at least $1-\delta$. Here, $r(n,d_{e})$ is the optimal
uncontaminated rate as a function of the effective dimension $d_{e}$ but
independent of the failure probability $\delta$. These rates are valid
uniformly on $\delta$, i.e., the estimators' tuning do not depend on $\delta$.
Lastly, we consider noisy robust matrix completion with non-uniform sampling.
If only the low-rank matrix is of interest, we present a novel near-optimal
rate that is independent of the corruption level $a$. Our estimators are
tractable and based on a new ""sorted"" Huber-type loss. No information on
$(s,r,\epsilon,a,\delta)$ are needed to tune these estimators. Our analysis
makes use of novel $\delta$-optimal concentration inequalities for the
multiplier and product processes which could be useful elsewhere. For instance,
they imply novel sharp oracle inequalities for Lasso and Slope with optimal
dependence on $\delta$. Numerical simulations confirm our theoretical
predictions. In particular, ""sorted"" Huber regression can outperform classical
Huber regression.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:42:47 GMT""},{""version"":""v2"",""created"":""Tue, 27 Apr 2021 15:02:32 GMT""}]","2021-04-28"
"2012.06751","Jianming Xia","Guangyan Jia, Jianming Xia, Rongjie Zhao","Monetary Risk Measures","21 pages",,,,"q-fin.MF q-fin.RM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study general monetary risk measures (without any convexity
or weak convexity). A monetary (respectively, positively homogeneous) risk
measure can be characterized as the lower envelope of a family of convex
(respectively, coherent) risk measures. The proof does not depend on but easily
leads to the classical representation theorems for convex and coherent risk
measures. When the law-invariance and the SSD (second-order stochastic
dominance)-consistency are involved, it is not the convexity (respectively,
coherence) but the comonotonic convexity (respectively, comonotonic coherence)
of risk measures that can be used for such kind of lower envelope
characterizations in a unified form. The representation of a law-invariant risk
measure in terms of VaR is provided.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:43:40 GMT""}]","2020-12-15"
"2012.06752","Gang Chen Professor","Gang Chen","Dilemma in strongly correlated materials: Hund's metal vs relativistic
  Mott insulator","5 pages, 2 figures",,,,"cond-mat.str-el cond-mat.mtrl-sci cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We point out the generic competition between the Hund's coupling and the
spin-orbit coupling in correlated materials, and this competition leads to an
electronic dilemma between the Hund's metal and the relativistic insulators.
Hund's metals refer to the fate of the would-be insulators where the Hund's
coupling suppresses the correlation and drives the systems into correlated
metals. Relativistic Mott insulators refer to the fate of the would-be metals
where the relativistic spin-orbit coupling enhances the correlation and drives
the systems into Mott insulators. These contradictory trends are naturally
present in many correlated materials. We study the competition between Hund's
coupling and spin-orbit coupling in correlated materials and explore the
interplay and the balance from these two contradictory trends. The system can
become a spin-orbit-coupled Hund's metal or a Hund's assisted relativistic Mott
insulator. Our observation could find a broad application and relevance to many
correlated materials with multiple orbitals.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:48:37 GMT""}]","2020-12-15"
"2012.06753","Jeong-Hyun Cho","Jeong-Hyun Cho, Ji-Hoon Jeong, Myoung-Ki Kim, Seong-Whan Lee","Towards Neurohaptics: Brain-Computer Interfaces for Decoding Intuitive
  Sense of Touch","Submitted IEEE The 9th International Winter Conference on
  Brain-Computer Interface",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noninvasive brain-computer interface (BCI) is widely used to recognize users'
intentions. Especially, BCI related to tactile and sensation decoding could
provide various effects on many industrial fields such as manufacturing
advanced touch displays, controlling robotic devices, and more immersive
virtual reality or augmented reality. In this paper, we introduce haptic and
sensory perception-based BCI systems called neurohaptics. It is a preliminary
study for a variety of scenarios using actual touch and touch imagery
paradigms. We designed a novel experimental environment and a device that could
acquire brain signals under touching designated materials to generate natural
touch and texture sensations. Through the experiment, we collected the
electroencephalogram (EEG) signals with respect to four different texture
objects. Seven subjects were recruited for the experiment and evaluated
classification performances using machine learning and deep learning
approaches. Hence, we could confirm the feasibility of decoding actual touch
and touch imagery on EEG signals to develop practical neurohaptics.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 08:08:47 GMT""},{""version"":""v2"",""created"":""Sun, 20 Dec 2020 13:23:54 GMT""}]","2020-12-22"
"2012.06754","Yichao Luo","Yichao Luo, Zhengyan Li, Bingning Wang, Xiaoyu Xing, Qi Zhang,
  Xuanjing Huang","SenSeNet: Neural Keyphrase Generation with Document Structure",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Keyphrase Generation (KG) is the task of generating central topics from a
given document or literary work, which captures the crucial information
necessary to understand the content. Documents such as scientific literature
contain rich meta-sentence information, which represents the logical-semantic
structure of the documents. However, previous approaches ignore the constraints
of document logical structure, and hence they mistakenly generate keyphrases
from unimportant sentences. To address this problem, we propose a new method
called Sentence Selective Network (SenSeNet) to incorporate the meta-sentence
inductive bias into KG. In SenSeNet, we use a straight-through estimator for
end-to-end training and incorporate weak supervision in the training of the
sentence selection module. Experimental results show that SenSeNet can
consistently improve the performance of major KG models based on seq2seq
framework, which demonstrate the effectiveness of capturing structural
information and distinguishing the significance of sentences in KG task.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 08:21:08 GMT""}]","2020-12-15"
"2012.06755","Davide Buffelli","Davide Buffelli, Fabio Vandin","A Meta-Learning Approach for Graph Representation Learning in Multi-Task
  Settings","Accepted at the NeurIPS Workshop on Meta-Learning (MetaLearn) 2020",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph Neural Networks (GNNs) are a framework for graph representation
learning, where a model learns to generate low dimensional node embeddings that
encapsulate structural and feature-related information. GNNs are usually
trained in an end-to-end fashion, leading to highly specialized node
embeddings. However, generating node embeddings that can be used to perform
multiple tasks (with performance comparable to single-task models) is an open
problem. We propose a novel meta-learning strategy capable of producing
multi-task node embeddings. Our method avoids the difficulties arising when
learning to perform multiple tasks concurrently by, instead, learning to
quickly (i.e. with a few steps of gradient descent) adapt to multiple tasks
singularly. We show that the embeddings produced by our method can be used to
perform multiple tasks with comparable or higher performance than classically
trained models. Our method is model-agnostic and task-agnostic, thus applicable
to a wide variety of multi-task domains.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 08:36:47 GMT""}]","2020-12-15"
"2012.06756","Jinraj Pushpangathan Veliyath","Jinraj V Pushpangathan, Harikumar Kandath, Suresh Sundaram, Narasimhan
  Sundararajan","Gap Reduced Minimum Error Robust Simultaneous Estimation For Unstable
  Nano Air Vehicle",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a novel Gap Reduced Minimum Error Robust Simultaneous
(GRMERS) estimator for resource-constrained Nano Aerial Vehicle (NAV) that
enables a single estimator to provide simultaneous and robust estimation for a
given N unstable and uncertain NAV plant models. The estimated full state
feedback enables a stable flight for NAV. The GRMERS estimator is implemented
utilizing a Minimum Error Robust Simultaneous (MERS) estimator and Gap Reducing
(GR) compensators. The MERS estimator provides robust simultaneous estimation
with minimal largest worst-case estimation error even in the presence of a
bounded energy exogenous disturbance signal. The GR compensators reduce the gap
between the graphs of N linear plant models to decrease the estimation error
generated by the MERS estimator. A sufficient condition for the existence of a
simultaneous estimator is established using LMIs and robust estimation theory.
Further, MERS estimator and GR compensator design are formulated as non-convex
tractable optimization problems and are solved using the population-based
genetic algorithms. The performance of the GRMERS estimator consisting of MERS
estimator and GR compensators from the population-based genetic algorithms is
validated through simulation studies. The study results indicate that a single
GRMERS estimator can produce state estimates with reduced errors for all flight
conditions. The results indicate that the single GRMERS estimator is robust
than the individually designed H inifinity filters.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 08:43:06 GMT""}]","2020-12-15"
"2012.06757","Jiarong Xu","Jiarong Xu, Yizhou Sun, Xin Jiang, Yanhao Wang, Yang Yang, Chunping
  Wang, Jiangang Lu","Blindfolded Attackers Still Threatening: Strict Black-Box Adversarial
  Attacks on Graphs",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Adversarial attacks on graphs have attracted considerable research interests.
Existing works assume the attacker is either (partly) aware of the victim
model, or able to send queries to it. These assumptions are, however,
unrealistic. To bridge the gap between theoretical graph attacks and real-world
scenarios, in this work, we propose a novel and more realistic setting: strict
black-box graph attack, in which the attacker has no knowledge about the victim
model at all and is not allowed to send any queries. To design such an attack
strategy, we first propose a generic graph filter to unify different families
of graph-based models. The strength of attacks can then be quantified by the
change in the graph filter before and after attack. By maximizing this change,
we are able to find an effective attack strategy, regardless of the underlying
model. To solve this optimization problem, we also propose a relaxation
technique and approximation theories to reduce the difficulty as well as the
computational expense. Experiments demonstrate that, even with no exposure to
the model, the Macro-F1 drops 6.4% in node classification and 29.5% in graph
classification, which is a significant result compared with existent works.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 08:52:56 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 16:32:47 GMT""},{""version"":""v3"",""created"":""Tue, 31 Aug 2021 03:52:53 GMT""}]","2021-09-01"
"2012.06758","Gopal Datt","Gopal Datt","Improvements to the Montel-Carath\'eodory Theorem for families of
  $\mathbb{P}^n$-valued holomorphic curves",,,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we establish various sufficient conditions for a family of
holomorphic mappings on a domain $D\subseteq\mathbb{C}$ into $\mathbb{P}^n$ to
be normal. Our results are improvements to the Montel-Carath\'eodory Theorem
for a family of $\mathbb{P}^n$-valued holomorphic curves.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 08:53:06 GMT""}]","2020-12-15"
"2012.06759","Petr Parfenov","P. Parfenov (for the STAR Collaboration)","Elliptic ($v_2$) and triangular ($v_3$) anisotropic flow of identified
  hadrons from the STAR Beam EnergyScan program","6 pages, 6 figures, to be published in the Proceedings of the
  ICPPA-2020 (Moscow, 5-9 October 2020), Journal of Physics: Conference Series",,,,"hep-ex nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Elliptic ($v_2$) and triangular ($v_3$) anisotropic flow coefficients for
inclusive and identified charged hadrons (~$\pi^\pm$, $K^\pm$, $p$, $\bar{p}$~)
at midrapidity in Au+Au collisions, measured by the STAR experiment in the Beam
Energy Scan (BES) at the Relativistic Heavy Ion Collider at $\sqrt{s_{NN}}$ =
$11.5$ - $62.4$ GeV, are presented. We observe that the triangular flow signal
($v_3$) of identified hadrons exhibits similar trends as first observed for
$v_2$ in Au+Au collisions, i.e. (i) mass ordering at low transverse momenta,
$p_T < 2$ GeV/c, (ii) meson/baryon splitting at intermediate $p_T$, $2< p_T <
4$ GeV/c, and (iii) difference in flow signal of protons and antiprotons. New
measurements of $v_3$ excitation function could serve as constraints to test
different models and to aid new information about the temperature dependence of
the transport properties of the strongly interacting matter.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:00:44 GMT""}]","2020-12-15"
"2012.06760","Parvez Ahmad","Saqib Qamar, Parvez Ahmad, Linlin Shen","HI-Net: Hyperdense Inception 3D UNet for Brain Tumor Segmentation","Accepted for MICCAI BraTS 2020",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  The brain tumor segmentation task aims to classify tissue into the whole
tumor (WT), tumor core (TC), and enhancing tumor (ET) classes using multimodel
MRI images. Quantitative analysis of brain tumors is critical for clinical
decision making. While manual segmentation is tedious, time-consuming, and
subjective, this task is at the same time very challenging to automatic
segmentation methods. Thanks to the powerful learning ability, convolutional
neural networks (CNNs), mainly fully convolutional networks, have shown
promising brain tumor segmentation. This paper further boosts the performance
of brain tumor segmentation by proposing hyperdense inception 3D UNet (HI-Net),
which captures multi-scale information by stacking factorization of 3D weighted
convolutional layers in the residual inception block. We use hyper dense
connections among factorized convolutional layers to extract more contexual
information, with the help of features reusability. We use a dice loss function
to cope with class imbalances. We validate the proposed architecture on the
multi-modal brain tumor segmentation challenges (BRATS) 2020 testing dataset.
Preliminary results on the BRATS 2020 testing set show that achieved by our
proposed approach, the dice (DSC) scores of ET, WT, and TC are 0.79457,
0.87494, and 0.83712, respectively.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:09:04 GMT""}]","2020-12-15"
"2012.06761","Pascal Nasahl","Pascal Nasahl, Robert Schilling, Mario Werner, Jan Hoogerbrugge,
  Marcel Medwed, Stefan Mangard","CrypTag: Thwarting Physical and Logical Memory Vulnerabilities using
  Cryptographically Colored Memory",,,"10.1145/3433210.3453684",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Memory vulnerabilities are a major threat to many computing systems. To
effectively thwart spatial and temporal memory vulnerabilities, full logical
memory safety is required. However, current mitigation techniques for memory
safety are either too expensive or trade security against efficiency. One
promising attempt to detect memory safety vulnerabilities in hardware is memory
coloring, a security policy deployed on top of tagged memory architectures.
However, due to the memory storage and bandwidth overhead of large tags,
commodity tagged memory architectures usually only provide small tag sizes,
thus limiting their use for security applications. Irrespective of logical
memory safety, physical memory safety is a necessity in hostile environments
prevalent for modern cloud computing and IoT devices. Architectures from Intel
and AMD already implement transparent memory encryption to maintain
confidentiality and integrity of all off-chip data. Surprisingly, the
combination of both, logical and physical memory safety, has not yet been
extensively studied in previous research, and a naive combination of both
security strategies would accumulate both overheads. In this paper, we propose
CrypTag, an efficient hardware/software co-design mitigating a large class of
logical memory safety issues and providing full physical memory safety. At its
core, CrypTag utilizes a transparent memory encryption engine not only for
physical memory safety, but also for memory coloring at hardly any additional
costs. The design avoids any overhead for tag storage by embedding memory
colors in the upper bits of a pointer and using these bits as an additional
input for the memory encryption. A custom compiler extension automatically
leverages CrypTag to detect logical memory safety issues for commodity programs
and is fully backward compatible.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:13:14 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 10:39:11 GMT""}]","2021-03-10"
"2012.06762","BaoLuo Sun","BaoLuo Sun and Ting Ye","Semiparametric causal mediation analysis with unmeasured
  mediator-outcome confounding","26 pages, 1 figure",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although the exposure can be randomly assigned in studies of mediation
effects, any form of direct intervention on the mediator is often infeasible.
As a result, unmeasured mediator-outcome confounding can seldom be ruled out.
We propose semiparametric identification of natural direct and indirect effects
in the presence of unmeasured mediator-outcome confounding by leveraging
heteroskedasticity restrictions on the observed data law. For inference, we
develop semiparametric estimators that remain consistent under partial
misspecifications of the observed data model. We illustrate the proposed
estimators through both simulations and an application to evaluate the effect
of self-efficacy on fatigue among health care workers during the COVID-19
outbreak.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:16:43 GMT""},{""version"":""v2"",""created"":""Mon, 28 Dec 2020 11:25:46 GMT""},{""version"":""v3"",""created"":""Tue, 20 Jul 2021 16:14:01 GMT""},{""version"":""v4"",""created"":""Wed, 29 Sep 2021 06:12:13 GMT""}]","2021-09-30"
"2012.06763","Petr Parfenov","P. Parfenov, A. Taranenko, D. Idrisov, V. B. Luong, N. Geraksiev, A.
  Demanov, A. Povarov, V. Kireyeu, A. Truttse, E. Volodihin (for the MPD
  Collaboration)","The comparison of methods for anisotropic flow measurements with the MPD
  Experiment at NICA","10 pages, 8 figures, to be published in the Proceedings of the
  Conference ""RFBR Grants for NICA"" (Dubna, 20-23 October 2020), Journal
  Physics of Elementary Particles and Atomic Nuclei",,,,"hep-ex nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The anisotropic collective flow is one of the key observables to study the
properties of dense matter created in heavy-ion collisions. The performance of
Multi-Purpose Detector (MPD) at NICA collider for directed and elliptic flow
measurements is studied with Monte-Carlo simulations of heavy-ion collisions at
energies $\sqrt{s_{NN}}$ = 4 - 11 GeV.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:19:09 GMT""}]","2020-12-15"
"2012.06764","Stefan B\""auml","Koji Azuma, Stefan B\""auml, Tim Coopmans, David Elkouss, Boxi Li","Tools for quantum network design","31 pages, 6 figures. Minor corrections",,"10.1116/5.0024062",,"quant-ph cs.IT cs.NI math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum networks will enable the implementation of communication tasks with
qualitative advantages with respect to the communication networks we know
today. While it is expected that the first demonstrations of small scale
quantum networks will take place in the near term, many challenges remain to
scale them. To compare different solutions, optimize over parameter space and
inform experiments, it is necessary to evaluate the performance of concrete
quantum network scenarios. Here, we review the state of the art of tools for
evaluating the performance of quantum networks. We present them from three
different angles: information-theoretic benchmarks, analytical tools, and
simulation.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:19:25 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 17:34:27 GMT""}]","2021-02-10"
"2012.06765","Sergio Naval Marimont","Sergio Naval Marimont and Giacomo Tarroni","Anomaly detection through latent space restoration using
  vector-quantized variational autoencoders","4 Pages, 4 Figures. Submitted to ISBI 2021",,,,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  We propose an out-of-distribution detection method that combines density and
restoration-based approaches using Vector-Quantized Variational Auto-Encoders
(VQ-VAEs). The VQ-VAE model learns to encode images in a categorical latent
space. The prior distribution of latent codes is then modelled using an
Auto-Regressive (AR) model. We found that the prior probability estimated by
the AR model can be useful for unsupervised anomaly detection and enables the
estimation of both sample and pixel-wise anomaly scores. The sample-wise score
is defined as the negative log-likelihood of the latent variables above a
threshold selecting highly unlikely codes. Additionally, out-of-distribution
images are restored into in-distribution images by replacing unlikely latent
codes with samples from the prior model and decoding to pixel space. The
average L1 distance between generated restorations and original image is used
as pixel-wise anomaly score. We tested our approach on the MOOD challenge
datasets, and report higher accuracies compared to a standard
reconstruction-based approach with VAEs.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:19:59 GMT""}]","2020-12-15"
"2012.06766","Karl Christ","Karl Christ, Xiang He and Ilya Tyomkin","Degeneration of curves on some polarized toric surfaces","v1: 34 pages, 11 figures. v2: improved the bound on the
  characteristic, the result is now sharp for characteristic at least 3. 35
  pages, 12 figures. v3: changes according to a referee report: changes in
  presentation throughout, fixed a gap in Proposition 5.5 and strengthened
  Theorem 6.1 slightly. Final version, to appear in J. Reine Angew. Math.
  (Crelle). 39 pages, 12 figures",,"10.1515/crelle-2022-0006",,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the following question: Given a polarized toric surface (S,L), and
a general integral curve C of geometric genus g in the linear system |L|, do
there exist degenerations of C in |L| to general integral curves of smaller
geometric genera? We give an affirmative answer to this question for surfaces
associated to h-transverse polygons, provided that the characteristic of the
ground field is large enough. We give examples of surfaces in small
characteristic, for which the answer to the question is negative. In case the
answer is affirmative, we deduce that a general curve C as above is nodal. In
characteristic 0, we use the result to show irreducibility of Severi varieties
of a large class of polarized toric surfaces with h-transverse polygon.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:22:24 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 12:06:18 GMT""},{""version"":""v3"",""created"":""Wed, 11 May 2022 11:41:07 GMT""}]","2022-05-12"
"2012.06767","Boris Faleichik","Vasily Repnikov, Boris Faleichik, Andrey Moysa","Stabilized explicit Adams-type methods",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we present explicit Adams-type multistep methods with extended
stability interval, which are analogous to the stabilized Chebyshev
Runge--Kutta methods. It is proved that for any $k\geq 1$ there exists an
explicit $k$-step Adams-type method of order one with stability interval of
length $2k$. The first order methods have remarkably simple expressions for
their coefficients and error constant. A damped modification of these methods
is derived. In general case to construct a $k$-step method of order $p$ it is
necessary to solve a constrained optimization problem in which the objective
function and $p$ constraints are second degree polynomials in $k$ variables. We
calculate higher-order methods up to order six numerically and perform some
numerical experiments to confirm the accuracy and stability of the methods.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:25:53 GMT""}]","2020-12-15"
"2012.06768","Nicolas Capitelli","Nicolas Capitelli and Melina Privitelli","Playing through a noisy channel (and knowing it)","12 pages, 2 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we discuss a theory of combinatorial games that involve
transmitting the moves through a noisy channel that can introduce errors during
the transmission. Players are aware of this interference and incorporate this
variable into the game: the valid move is the received one, regardless of
whether it is the other player's sent move (as long as it is a valid move in
the original game; otherwise, a retransmission is requested). Players know the
probability of introducing an error through communication and can play a
non-optimal (but valid) move that maximizes their chances of winning. We
present some examples and provide the basic definitions and results of this
type of games.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:35:09 GMT""}]","2020-12-15"
"2012.06769","Radu P Horaud","Georgios D. Evangelidis, Miles Hansard, and Radu Horaud","Fusion of Range and Stereo Data for High-Resolution Scene-Modeling",,"IEEE Transactions on Pattern Analysis and Machine Intelligence,
  37(11), 2015","10.1109/TPAMI.2015.2400465",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper addresses the problem of range-stereo fusion, for the construction
of high-resolution depth maps. In particular, we combine low-resolution depth
data with high-resolution stereo data, in a maximum a posteriori (MAP)
formulation. Unlike existing schemes that build on MRF optimizers, we infer the
disparity map from a series of local energy minimization problems that are
solved hierarchically, by growing sparse initial disparities obtained from the
depth data. The accuracy of the method is not compromised, owing to three
properties of the data-term in the energy function. Firstly, it incorporates a
new correlation function that is capable of providing refined correlations and
disparities, via subpixel correction. Secondly, the correlation scores rely on
an adaptive cost aggregation step, based on the depth data. Thirdly, the stereo
and depth likelihoods are adaptively fused, based on the scene texture and
camera geometry. These properties lead to a more selective growing process
which, unlike previous seed-growing methods, avoids the tendency to propagate
incorrect disparities. The proposed method gives rise to an intrinsically
efficient algorithm, which runs at 3FPS on 2.0MP images on a standard desktop
computer. The strong performance of the new method is established both by
quantitative comparisons with state-of-the-art methods, and by qualitative
comparisons using real depth-stereo data-sets.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:37:42 GMT""}]","2020-12-15"
"2012.06770","Jean-Marc Ginoux","Jean-Marc Ginoux","Slow Invariant Manifolds of Slow-Fast Dynamical Systems","arXiv admin note: text overlap with arXiv:1808.08058",,"10.1142/S0218127421501121",,"nlin.CD","http://creativecommons.org/licenses/by/4.0/","  Slow-fast dynamical systems, i.e., singularly or non-singularly perturbed
dynamical systems possess slow invariant manifolds on which trajectories evolve
slowly. Since the last century various methods have been developed for
approximating their equations. This paper aims, on the one hand, to propose a
classification of the most important of them into two great categories:
singular perturbation-based methods and curvature-based methods, and on the
other hand, to prove the equivalence between any methods belonging to the same
category and between the two categories. Then, a deep analysis and comparison
between each of these methods enable to state the efficiency of the Flow
Curvature Method which is exemplified with paradigmatic Van der Pol singularly
perturbed dynamical system and Lorenz slow-fast dynamical system.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:38:56 GMT""}]","2021-06-30"
"2012.06771","Awadelrahman M. A. Ahmed Mr.","Awadelrahman M. A. Ali Ahmed (University of Oslo)","Generative Adversarial Networks for Automatic Polyp Segmentation","MediaEval20, Multimedia Evaluation Workshop, December 14-15 2020,
  Online",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  This paper aims to contribute in bench-marking the automatic polyp
segmentation problem using generative adversarial networks framework.
Perceiving the problem as an image-to-image translation task, conditional
generative adversarial networks are utilized to generate masks conditioned by
the images as inputs. Both generator and discriminator are convolution neural
networks based. The model achieved 0.4382 on Jaccard index and 0.611 as F2
score.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:48:08 GMT""}]","2020-12-15"
"2012.06772","Radu P Horaud","Radu Horaud, Miles Hansard, Georgios Evangelidis and Clement Menier","An Overview of Depth Cameras and Range Scanners Based on Time-of-Flight
  Technologies",,"Machine Vision and Applications, 27(7), 2016","10.1007/s00138-016-0784-4",,"cs.CV cs.RO","http://creativecommons.org/licenses/by/4.0/","  Time-of-flight (TOF) cameras are sensors that can measure the depths of
scene-points, by illuminating the scene with a controlled laser or LED source,
and then analyzing the reflected light. In this paper, we will first describe
the underlying measurement principles of time-of-flight cameras, including: (i)
pulsed-light cameras, which measure directly the time taken for a light pulse
to travel from the device to the object and back again, and (ii)
continuous-wave modulated-light cameras, which measure the phase difference
between the emitted and received signals, and hence obtain the travel time
indirectly. We review the main existing designs, including prototypes as well
as commercially available devices. We also review the relevant camera
calibration principles, and how they are applied to TOF devices. Finally, we
discuss the benefits and challenges of combined TOF and color camera systems.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:48:52 GMT""}]","2020-12-15"
"2012.06773","Thomas Bisbas Dr.","Thomas G. Bisbas, Jonathan C. Tan and Kei E.I. Tanaka","Photodissociation Region Diagnostics Across Galactic Environments","33 pages, 24 figures, 3 tables. Submitted to MNRAS. Comments welcome!",,"10.1093/mnras/stab121",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present three-dimensional astrochemical simulations and synthetic
observations of magnetised, turbulent, self-gravitating molecular clouds. We
explore various galactic interstellar medium environments, including cosmic-ray
ionization rates in the range of $\zeta_{\rm CR}=10^{-17}$-$10^{-14}\,{\rm
s}^{-1}$, far-UV intensities in the range of $G_0=1$-$10^3$ and metallicities
in the range of $Z=0.1$-$2\,{\rm Z}_{\odot}$. The simulations also probe a
range of densities and levels of turbulence, including cases where the gas has
undergone recent compression due to cloud-cloud collisions. We examine: i) the
column densities of carbon species across the cycle of CII, CI and CO, along
with OI, in relation to the HI-to-H$_2$ transition; ii) the velocity-integrated
emission of [CII]~$158\mu$m, [$^{13}$CII]~$158\mu$m, [CI]~$609\mu$m and
$370\mu$m, [OI]~$63\mu$m and $146\mu$m, and of the first ten $^{12}$CO
rotational transitions; iii) the corresponding Spectral Line Energy
Distributions; iv) the usage of [CII] and [OI]~$63\mu$m to describe the
dynamical state of the clouds; v) the behavior of the most commonly used ratios
between transitions of CO and [CI]; and vi) the conversion factors for using CO
and CI as H$_2$-gas tracers. We find that enhanced cosmic-ray energy densities
enhance all aforementioned line intensities. At low metallicities, the emission
of [CII] is well connected with the H$_2$ column, making it a promising new
H$_2$ tracer in metal-poor environments. The conversion factors of $X_{\rm CO}$
and $X_{\rm CI}$ depend on metallicity and the cosmic-ray ionization rate, but
not on FUV intensity. In the era of ALMA, SOFIA and the forthcoming CCAT-prime
telescope, our results can be used to understand better the behaviour of
systems in a wide range of galactic and extragalactic environments.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:51:00 GMT""}]","2021-01-20"
"2012.06774","Martino Trevisan Dr","Andrea Di Domenico, Gianluca Perna, Martino Trevisan, Luca Vassio,
  Danilo Giordano","A network analysis on cloud gaming: Stadia, GeForce Now and PSNow",,"Network 2021, 1, 247-260","10.3390/network1030015",,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Cloud gaming is a new class of services that promises to revolutionize the
videogame market. It allows the user to play a videogame with basic equipment
while using a remote server for the actual execution. The multimedia content is
streamed through the network from the server to the user. This service requires
low latency and a large bandwidth to work properly with low response time and
high-definition video. Three of the leading tech companies, (Google, Sony and
NVIDIA) entered this market with their own products, and others, like Microsoft
and Amazon, are planning to launch their own platforms in the near future.
However, these companies released so far little information about their cloud
gaming operation and how they utilize the network. In this work, we study these
new cloud gaming services from the network point of view. We collect more than
200 packet traces under different application settings and network conditions
for 3 cloud gaming services, namely Stadia from Google, GeForce Now from NVIDIA
and PS Now from Sony. We analyze the employed protocols and the workload they
impose on the network. We find that GeForce Now and Stadia use the RTP protocol
to stream the multimedia content, with the latter relying on the standard
WebRTC APIs. They result in bandwidth-hungry and consume up to 45 Mbit/s,
depending on the network and video quality. PS Now instead uses only
undocumented protocols and never exceeds 13 Mbit/s.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:51:30 GMT""},{""version"":""v2"",""created"":""Mon, 26 Apr 2021 17:07:07 GMT""},{""version"":""v3"",""created"":""Fri, 28 May 2021 14:52:48 GMT""},{""version"":""v4"",""created"":""Thu, 21 Oct 2021 12:28:39 GMT""}]","2021-10-22"
"2012.06775","Jun Dai","Jun Dai, Haisheng Ji, Leping Li, Jun Zhang, Huadong Chen","The Formation and Eruption of A Sigmoidal Filament Driven by Rotating
  Network Magnetic Fields",,,"10.3847/1538-4357/abcaf4",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the formation and eruption of a sigmoidal filament driven by
rotating network magnetic fields (RNFs) near the center of the solar disk,
which was observed by the one-meter aperture New Vacuum Solar Telescope (NVST)
at Fuxian Solar Observatory (FSO) on 2018 July 12. Counterclockwise RNFs twist
two small-scale filaments at their northeastern foot-point region, giving a
rotation of nearly 200 degree within about 140 minutes. The motion of the RNF
has a tendency to accelerate at first and then decelerate obviously, as the
average rotation speed increased from 10 to 150 ,and then slowed down to 50 .
Coalescence then occurs between filaments F1 and F2. Meanwhile the fine
structures in the southwestern region of the filament was involved in another
interaction of coalescence. The subsequent EUV brightening due to plasma
heating is observed in the two interaction regions. These interacting
structures, including F1, F2 and the fine structures in the southwestern
region, eventually evolve into a larger-scale sigmoidal filament twisted in the
same direction as the RNFs gave. The twist of the sigmoidal filament has
exceeded 4{\pi} and the filament erupted finally. The motion of the sigmoidal
filament keeps uniform until a nearby jet collides, causing the filament to
erupt faster. These results provide evidence that RNF plays an important role
in the formation and eruption of the sigmoidal filament. The phenomena also
suggests that the kink instability is the trigger mechanism for the filament
eruption.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:53:28 GMT""}]","2021-01-20"
"2012.06776","Paula Reichert","Paula Reichert","Investigating total collisions of the Newtonian N-body problem on shape
  space",,,"10.1007/s10701-021-00428-x",,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the points of total collision of the Newtonian gravitational
system on shape space (the relational configuration space of the system). While
the Newtonian equations of motion, formulated with respect to absolute space
and time, are singular at the point of total collision due to the singularity
of the Newton potential at that point, this need not be the case on shape space
where absolute scale doesn't exist. We investigate whether, adopting a
relational description of the system, the shape degrees of freedom, which are
merely angles and their conjugate momenta, can be evolved through the points of
total collision. Unfortunately, this is not the case. Even without scale, the
equations of motion are singular at the points of total collision (and only
there). This follows from the special behavior of the shape momenta. While this
behavior induces the singularity, it at the same time provides a purely
shape-dynamical description of total collisions. By help of this, we are able
to discern total-collision solutions from non-collision solutions on shape
space, that is, without reference to (external) scale. We can further use the
shape-dynamical description to show that total-collision solutions form a set
of measure zero among all solutions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 10:25:17 GMT""}]","2021-03-17"
"2012.06777","Dr. Suryansh Kumar","Berk Kaya, Suryansh Kumar, Carlos Oliveira, Vittorio Ferrari, Luc Van
  Gool","Uncalibrated Neural Inverse Rendering for Photometric Stereo of General
  Surfaces","Accepted for publication at CVPR 2021. Document info: 18 pages, 21
  Figures, 5 tables. (Minor typo corrected)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an uncalibrated deep neural network framework for the
photometric stereo problem. For training models to solve the problem, existing
neural network-based methods either require exact light directions or
ground-truth surface normals of the object or both. However, in practice, it is
challenging to procure both of this information precisely, which restricts the
broader adoption of photometric stereo algorithms for vision application. To
bypass this difficulty, we propose an uncalibrated neural inverse rendering
approach to this problem. Our method first estimates the light directions from
the input images and then optimizes an image reconstruction loss to calculate
the surface normals, bidirectional reflectance distribution function value, and
depth. Additionally, our formulation explicitly models the concave and convex
parts of a complex surface to consider the effects of interreflections in the
image formation process. Extensive evaluation of the proposed method on the
challenging subjects generally shows comparable or better results than the
supervised and classical approaches.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 10:33:08 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 13:26:46 GMT""},{""version"":""v3"",""created"":""Sat, 17 Apr 2021 22:10:57 GMT""}]","2021-04-20"
"2012.06778","Leonid Litinskii","Leonid Litinskii and Boris Kryzhanovsky","Inverse problem for Ising connection matrix with long-range interaction","10 pages, 1 fugure",,,,"cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper, we examine Ising systems on d-dimensional hypercube
lattices and solve an inverse problem where we have to determine interaction
constants of an Ising connection matrix when we know a spectrum of it
eigenvalues. In addition, we define restrictions allowing a random number
sequence to be a connection matrix spectrum. We use the previously obtained
analytical expressions for the eigenvalues of Ising connection matrices
accounting for an arbitrary long-range interaction and supposing periodic
boundary conditions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 10:37:35 GMT""}]","2020-12-15"
"2012.06779","Gaurav Sood","Olaf Beyersdorff, Joshua Blinkhorn, Meena Mahajan, Tom\'a\v{s} Peitl,
  Gaurav Sood","Hard QBFs for Merge Resolution",,,,,"cs.CC cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the first proof size lower bounds for the proof system Merge
Resolution (MRes [Olaf Beyersdorff et al., 2020]), a refutational proof system
for prenex quantified Boolean formulas (QBF) with a CNF matrix. Unlike most QBF
resolution systems in the literature, proofs in MRes consist of resolution
steps together with information on countermodels, which are syntactically
stored in the proofs as merge maps. As demonstrated in [Olaf Beyersdorff et
al., 2020], this makes MRes quite powerful: it has strategy extraction by
design and allows short proofs for formulas which are hard for classical QBF
resolution systems.
  Here we show the first exponential lower bounds for MRes, thereby uncovering
limitations of MRes. Technically, the results are either transferred from
bounds from circuit complexity (for restricted versions of MRes) or directly
obtained by combinatorial arguments (for full MRes). Our results imply that the
MRes approach is largely orthogonal to other QBF resolution models such as the
QCDCL resolution systems QRes and QURes and the expansion systems
$\forall$Exp+Res and IR.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 10:39:14 GMT""}]","2020-12-15"
"2012.06780","Hao Zhang","Fuzhao Xue, Aixin Sun, Hao Zhang, Eng Siong Chng","GDPNet: Refining Latent Multi-View Graph for Relation Extraction","To appear at AAAI 2021",,"10.1609/aaai.v35i16.17670",,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Relation Extraction (RE) is to predict the relation type of two entities that
are mentioned in a piece of text, e.g., a sentence or a dialogue. When the
given text is long, it is challenging to identify indicative words for the
relation prediction. Recent advances on RE task are from BERT-based sequence
modeling and graph-based modeling of relationships among the tokens in the
sequence. In this paper, we propose to construct a latent multi-view graph to
capture various possible relationships among tokens. We then refine this graph
to select important words for relation prediction. Finally, the representation
of the refined graph and the BERT-based sequence representation are
concatenated for relation extraction. Specifically, in our proposed GDPNet
(Gaussian Dynamic Time Warping Pooling Net), we utilize Gaussian Graph
Generator (GGG) to generate edges of the multi-view graph. The graph is then
refined by Dynamic Time Warping Pooling (DTWPool). On DialogRE and TACRED, we
show that GDPNet achieves the best performance on dialogue-level RE, and
comparable performance with the state-of-the-arts on sentence-level RE.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 10:43:41 GMT""}]","2023-04-26"
"2012.06781","Safwan Aljbaae","S. Aljbaae, D. M. Sanchez, A. F. B. A. Prado, J. Souchay, M. O. Terra,
  R. B. Negri, L. O. Marchi","First approximation for spacecraft motion relative to (99942) Apophis","24 pages, 20 figures",,,,"astro-ph.EP cs.NA math.NA physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  We aim at providing a preliminary approach on the dynamics of a spacecraft in
orbit about the asteroid (99942) Apophis during its Earth close approach. The
physical properties from the polyhedral shape of the target are derived
assigning each tetrahedron to a point mass in its center. That considerably
reduces the computation processing time compared to previous methods to
evaluate the gravitational potential. The surfaces of section close to Apophis
are build considering or not the gravitational perturbations of the Sun, the
planets, and the SRP. The Earth is the one that most affects the invisticated
region making the vast majority of the orbits to collide or escape from the
system. Moreover, from numerical analysis of orbits started on March 1, 2029,
the less perturbed region is characterized by the variation of the semimajor
axis of 40-days orbits, which do not exceed 2 km very close to the central body
($a < 4$ km, $e < 0.4$). However, no regions investigated could be a possible
option for inserting a spacecraft into natural orbits around Apophis during the
close approach with our planet. Finally, to solve the stabilization problem in
the system, we apply a robust path following control law to control the orbital
geometry of a spacecraft. At last, we present an example of successful
operation of our orbit control with a total $\bigtriangleup v$ of 0.495 m/s for
60 days. All our results are gathered in the CPM-ASTEROID database, which will
be regularly updated by considering other asteroids.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 10:48:15 GMT""}]","2020-12-15"
"2012.06782","Manali Saini Manali","Manali Saini, Udit Satija, Madhur Deo Upadhayay","Light-Weight 1-D Convolutional Neural Network Architecture for Mental
  Task Identification and Classification Based on Single-Channel EEG","11 pages",,"10.1016/j.bspc.2022.103494",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mental task identification and classification using single/limited channel(s)
electroencephalogram (EEG) signals in real-time play an important role in the
design of portable brain-computer interface (BCI) and neurofeedback (NFB)
systems. However, the real-time recorded EEG signals are often contaminated
with noises such as ocular artifacts (OAs) and muscle artifacts (MAs), which
deteriorate the hand-crafted features extracted from EEG signal, resulting
inadequate identification and classification of mental tasks. Therefore, we
investigate the use of recent deep learning techniques which do not require any
manual feature extraction or artifact suppression step. In this paper, we
propose a light-weight one-dimensional convolutional neural network (1D-CNN)
architecture for mental task identification and classification. The robustness
of the proposed architecture is evaluated using artifact-free and
artifact-contaminated EEG signals taken from two publicly available databases
(i.e, Keirn and Aunon ($K$) database and EEGMAT ($E$) database) and in-house
($R$) database recorded using single-channel neurosky mindwave mobile 2 (MWM2)
EEG headset in performing not only mental/non-mental binary task classification
but also different mental/mental multi-tasks classification. Evaluation results
demonstrate that the proposed architecture achieves the highest
subject-independent classification accuracy of $99.7\%$ and $100\%$ for
multi-class classification and pair-wise mental tasks classification
respectively in database $K$. Further, the proposed architecture achieves
subject-independent classification accuracy of $99\%$ and $98\%$ in database
$E$ and the recorded database $R$ respectively. Comparative performance
analysis demonstrates that the proposed architecture outperforms existing
approaches not only in terms of classification accuracy but also in robustness
against artifacts.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 10:50:21 GMT""}]","2022-05-18"
"2012.06783","Jose L Ansorena","Fernando Albiac and Jose L. Ansorena","Uniqueness of unconditional basis of $\ell_{2}\oplus \mathcal{T}^{(2)}$",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a new extension of Pitt's theorem for compact operators between
quasi-Banach lattices, which permits to describe unconditional bases of finite
direct sums of Banach spaces $\mathbb{X}_{1}\oplus\dots\oplus\mathbb{X}_{n}$ as
direct sums of unconditional bases of its summands. The general splitting
principle we obtain yields, in particular, that if each $\mathbb{X}_{i}$ has a
unique unconditional basis (up to equivalence and permutation), then
$\mathbb{X}_{1}\oplus \cdots\oplus\mathbb{X}_{n}$ has a unique unconditional
basis too. Among the novel applications of our techniques to the structure of
Banach and quasi-Banach spaces we have that the space $\ell_2\oplus
\mathcal{T}^{(2)}$ has a unique unconditional basis.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 10:55:13 GMT""}]","2020-12-15"
"2012.06784","Lorenzo Fassina PhD","Lorenzo Fassina, Alessandro Faragli, Francesco Paolo Lo Muzio,
  Sebastian Kelle, Carlo Campana, Burkert Pieske, Frank Edelmann, Alessio
  Alogna","A random shuffle method to expand a narrow dataset and overcome the
  associated challenges in a clinical study: a heart failure cohort example",,"Frontiers in Cardiovascular Medicine 2020;7:599923","10.3389/fcvm.2020.599923",,"q-bio.QM cs.LG stat.ME stat.ML","http://creativecommons.org/licenses/by/4.0/","  Heart failure (HF) affects at least 26 million people worldwide, so
predicting adverse events in HF patients represents a major target of clinical
data science. However, achieving large sample sizes sometimes represents a
challenge due to difficulties in patient recruiting and long follow-up times,
increasing the problem of missing data. To overcome the issue of a narrow
dataset cardinality (in a clinical dataset, the cardinality is the number of
patients in that dataset), population-enhancing algorithms are therefore
crucial. The aim of this study was to design a random shuffle method to enhance
the cardinality of an HF dataset while it is statistically legitimate, without
the need of specific hypotheses and regression models. The cardinality
enhancement was validated against an established random repeated-measures
method with regard to the correctness in predicting clinical conditions and
endpoints. In particular, machine learning and regression models were employed
to highlight the benefits of the enhanced datasets. The proposed random shuffle
method was able to enhance the HF dataset cardinality (711 patients before
dataset preprocessing) circa 10 times and circa 21 times when followed by a
random repeated-measures approach. We believe that the random shuffle method
could be used in the cardiovascular field and in other data science problems
when missing data and the narrow dataset cardinality represent an issue.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 10:59:38 GMT""}]","2020-12-15"
"2012.06785","Matthieu Lin","Matthieu Lin and Chuming Li and Xingyuan Bu and Ming Sun and Chen Lin
  and Junjie Yan and Wanli Ouyang and Zhidong Deng","DETR for Crowd Pedestrian Detection",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Pedestrian detection in crowd scenes poses a challenging problem due to the
heuristic defined mapping from anchors to pedestrians and the conflict between
NMS and highly overlapped pedestrians. The recently proposed end-to-end
detectors(ED), DETR and deformable DETR, replace hand designed components such
as NMS and anchors using the transformer architecture, which gets rid of
duplicate predictions by computing all pairwise interactions between queries.
Inspired by these works, we explore their performance on crowd pedestrian
detection. Surprisingly, compared to Faster-RCNN with FPN, the results are
opposite to those obtained on COCO. Furthermore, the bipartite match of ED
harms the training efficiency due to the large ground truth number in crowd
scenes. In this work, we identify the underlying motives driving ED's poor
performance and propose a new decoder to address them. Moreover, we design a
mechanism to leverage the less occluded visible parts of pedestrian
specifically for ED, and achieve further improvements. A faster bipartite match
algorithm is also introduced to make ED training on crowd dataset more
practical. The proposed detector PED(Pedestrian End-to-end Detector)
outperforms both previous EDs and the baseline Faster-RCNN on CityPersons and
CrowdHuman. It also achieves comparable performance with state-of-the-art
pedestrian detection methods. Code will be released soon.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:02:05 GMT""},{""version"":""v2"",""created"":""Sun, 31 Jan 2021 06:30:10 GMT""},{""version"":""v3"",""created"":""Thu, 18 Feb 2021 09:46:22 GMT""}]","2021-02-19"
"2012.06786","Erbol Zhanpeisov","Erbol Zhanpeisov","Blow-up rate of sign-changing solutions to nonlinear parabolic systems","22 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a blow-up rate estimate for a solution to the parabolic
Gross-Pitaevskii and related systems on entire space with Sobolev subcritical
nonlinearity. We extend the results of [Y. Giga, S. Matsui and S. Sasayama,
Indiana Univ. Math. J. {53} (2004), 483--514] to the parabolic systems.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:03:03 GMT""}]","2020-12-15"
"2012.06787","Leonid Litinskii","Inna Kaganowa, Boris Kryzhanovsky and Leonid Litinskii","n-vicinity method for Ising Model with long-range interaction","7 pages, 3 tables, and 3 figures",,,,"cond-mat.stat-mech cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The previously developed n-vicinity method allows us to calculate accurately
critical values of inverse temperatures for Ising models with short-range
interaction. We generalize the method to the case of long-range interactions in
spin systems and obtain theoretical formulas for the inverse temperatures in
terms of the spin interaction constants. The comparison of our theoretical
estimates with computer simulations for the two- and three-dimensional Ising
models shows that the larger the dimension of the problem the better their
agreement.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:03:30 GMT""}]","2020-12-15"
"2012.06788","A. R. Sricharan","Umang Bhaskar, A. R. Sricharan, Rohit Vaish","On Approximate Envy-Freeness for Indivisible Chores and Mixed Resources","v2 to v3 incorporates changes suggested by reviewers. Accepted at
  APPROX 2021",,,,"cs.GT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the fair allocation of undesirable indivisible items, or chores.
While the case of desirable indivisible items (or goods) is extensively
studied, with many results known for different notions of fairness, less is
known about the fair division of chores. We study the envy-free division of
chores, and make three contributions. First, we show that determining the
existence of an envy-free allocation is NP-complete, even in the simple case
when agents have binary additive valuations. Second, we provide a
polynomial-time algorithm for computing an allocation that satisfies
envy-freeness up to one chore (EF1), correcting an existing proof in the
literature. A straightforward modification of our algorithm can be used to
compute an EF1 allocation for doubly monotone instances (wherein each agent can
partition the set of items into objective goods and objective chores). Our
third result applies to a mixed resources model consisting of indivisible items
and a divisible, undesirable heterogeneous resource (i.e., a bad cake). We show
that there always exists an allocation that satisfies envy-freeness for mixed
resources (EFM) in this setting, complementing a recent result of Bei et al.
(Art. Int. 2021) for indivisible goods and divisible cake.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:19:00 GMT""},{""version"":""v2"",""created"":""Sat, 20 Feb 2021 12:06:51 GMT""},{""version"":""v3"",""created"":""Sat, 27 Aug 2022 15:22:02 GMT""}]","2022-08-30"
"2012.06789","Saisubramaniam Gopalakrishnan","Saisubramaniam Gopalakrishnan, Pranshu Ranjan Singh, Haytham Fayek,
  Savitha Ramasamy, Arulmurugan Ambikapathi","Knowledge Capture and Replay for Continual Learning",,,,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks have shown promise in several domains, and the learned
data (task) specific information is implicitly stored in the network
parameters. Extraction and utilization of encoded knowledge representations are
vital when data is no longer available in the future, especially in a continual
learning scenario. In this work, we introduce {\em flashcards}, which are
visual representations that {\em capture} the encoded knowledge of a network as
a recursive function of predefined random image patterns. In a continual
learning scenario, flashcards help to prevent catastrophic forgetting and
consolidating knowledge of all the previous tasks. Flashcards need to be
constructed only before learning the subsequent task, and hence, independent of
the number of tasks trained before. We demonstrate the efficacy of flashcards
in capturing learned knowledge representation (as an alternative to the
original dataset) and empirically validate on a variety of continual learning
tasks: reconstruction, denoising, task-incremental learning, and new-instance
learning classification, using several heterogeneous benchmark datasets.
Experimental evidence indicates that: (i) flashcards as a replay strategy is {
\em task agnostic}, (ii) performs better than generative replay, and (iii) is
on par with episodic replay without additional memory overhead.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:24:45 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 14:17:52 GMT""}]","2021-04-30"
"2012.06790","Johan Mazoyer","Johan Mazoyer, Pauline Arriaga, Justin Hom, Maxwell A.
  Millar-Blanchaer, Christine Chen, Jason Wang, Gaspard Duch\^ene, Jennifer
  Patience and Laurent Pueyo","DiskFM: A Forward Modeling Tool for Disk Analysis with Coronagraphic
  Instruments","20 pages, 7 figures. Submitted to Proceedings of the SPIE, Volume
  11447, Ground-based and Airborne Instrumentation for Astronomy VIII; 1144759",,"10.1117/12.2560091",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Because of bright starlight leakage in coronagraphic raw images, faint
astrophysical objects such as exoplanets can only be detected using powerful
point spread function (PSF) subtraction algorithms. However, these algorithms
have strong effects on faint objects of interest, and often prevent precise
spectroscopic analysis and scattering property measurements of circumstellar
disks. For this reason, PSF-subtraction effects is currently the main
limitations to the precise characterization of exoplanetary dust with
scattered-light imaging. Forward-modeling techniques have long been developed
for point source objects. However, forward-modeling with disks is complicated
by the fact that the disk cannot be simplified using a simple point source
convolved by the PSF as the astrophysical model; all hypothetical disk
morphologies must be explored to understand the subtle and non-linear effects
of the PSF subtraction algorithm on the shape and local geometry of these
systems. Because of their complex geometries, the forward-modeling process has
to be repeated tens or hundred of thousands of times on disks with slightly
different physical properties. All of these geometries are then compared to the
PSF-subtracted image of the data, within an MCMC or a Chi-square wrapper. In
this paper, we present here DiskFM, a new open-source algorithm included in the
PSF subtraction algorithms package pyKLIP. This code allows to produce fast
forward-modeling for a variety of observation strategies (ADI, SDI, ADI+SDI,
RDI). pyKLIP has already been used for SPHERE/IRDIS and GPI data. It is readily
available on all instruments supported by pyKLIP (SPHERE/IFS, SCExAO/CHARIS),
and can be quickly adapted for other coronagraphic instruments.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:36:41 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 17:46:35 GMT""}]","2020-12-16"
"2012.06791","Charilaos Mylonas Mr.","Charilaos Mylonas, George Tsialiamanis, Keith Worden and Eleni N.
  Chatzi","Bayesian graph neural networks for strain-based crack localization",,,,,"cs.CE physics.data-an","http://creativecommons.org/licenses/by/4.0/","  A common shortcoming of vibration-based damage localization techniques is
that localized damages, i.e. small cracks, have a limited influence on the
spectral characteristics of a structure. In contrast, even the smallest of
defects, under particular loading conditions, cause localized strain
concentrations with predictable spatial configuration. However, the effect of a
small defect on strain decays quickly with distance from the defect, making
strain-based localization rather challenging. In this work, an attempt is made
to approximate, in a fully data-driven manner, the posterior distribution of a
crack location, given arbitrary dynamic strain measurements at arbitrary
discrete locations on a structure. The proposed technique leverages Graph
Neural Networks (GNNs) and recent developments in scalable learning for
Bayesian neural networks. The technique is demonstrated on the problem of
inferring the position of an unknown crack via patterns of dynamic strain field
measurements at discrete locations. The dataset consists of simulations of a
hollow tube under random time-dependent excitations with randomly sampled crack
geometry and orientation.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:42:52 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jan 2021 13:14:08 GMT""},{""version"":""v3"",""created"":""Fri, 19 May 2023 10:23:16 GMT""}]","2023-05-23"
"2012.06792","Alberto Raffero","Alberto Raffero, Luigi Vezzoni","On the dynamical behaviour of the generalized Ricci flow","10 pages",,"10.1007/s12220-021-00656-7",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by M\""uller-Haslhofer results on the dynamical stability and
instability of Ricci-flat metrics under the Ricci flow, we obtain dynamical
stability and instability results for pairs of Ricci-flat metrics and vanishing
3-forms under the generalized Ricci flow.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:46:12 GMT""}]","2021-08-24"
"2012.06793","Deng Weijian","Weijian Deng, Joshua Marsh, Stephen Gould, Liang Zheng","Fine-grained Classification via Categorical Memory Networks","10 pages, 9 figures, 7 tables; this version is not fully edited and
  will be updated soon",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the desire to exploit patterns shared across classes, we present
a simple yet effective class-specific memory module for fine-grained feature
learning. The memory module stores the prototypical feature representation for
each category as a moving average. We hypothesize that the combination of
similarities with respect to each category is itself a useful discriminative
cue. To detect these similarities, we use attention as a querying mechanism.
The attention scores with respect to each class prototype are used as weights
to combine prototypes via weighted sum, producing a uniquely tailored response
feature representation for a given input. The original and response features
are combined to produce an augmented feature for classification. We integrate
our class-specific memory module into a standard convolutional neural network,
yielding a Categorical Memory Network. Our memory module significantly improves
accuracy over baseline CNNs, achieving competitive accuracy with
state-of-the-art methods on four benchmarks, including CUB-200-2011, Stanford
Cars, FGVC Aircraft, and NABirds.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:50:13 GMT""}]","2020-12-15"
"2012.06794","Samuel Corson","Samuel M. Corson","The Griffiths double cone group is isomorphic to the triple",,,,,"math.GR math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that the fundamental group of the Griffiths double cone space is
isomorphic to that of the triple cone. More generally if $\kappa$ is a cardinal
such that $2 \leq \kappa \leq 2^{\aleph_0}$ then the $\kappa$-fold cone has the
same fundamental group as the double cone. The isomorphisms produced are
non-constructive, and no isomorphism between the fundamental group of the $2$-
and of the $\kappa$-fold cones, with $2 < \kappa$, can be realized via
continuous mappings. We also prove a conjecture of James W. Cannon and Gregory
R. Conner which states that the fundamental group of the Griffiths double cone
space is isomorphic to that of the harmonic archipelago.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:53:06 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 08:52:37 GMT""}]","2021-04-02"
"2012.06795","Andres Balaguera-Antol\'inez","Francesco Sinigaglia, Francisco-Shu Kitaura, Andr\'es
  Balaguera-Antol\'inez, Kentaro Nagamine, Metin Ata, Ikkoh Shimizu, Manuel
  S\'anchez-Benavente","The bias from hydrodynamic simulations: mapping baryon physics onto dark
  matter fields","Accepted for publication by ApJ",,"10.3847/1538-4357/ac158b",,"astro-ph.CO","http://creativecommons.org/publicdomain/zero/1.0/","  This paper investigates the hierarchy of baryon physics assembly bias
relations obtained from state-of-the-art hydrodynamic simulations with respect
to the underlying cosmic web spanned by the dark matter field. Using the Bias
Assignment Method (BAM) we find that non-local bias plays a central role. We
classify the cosmic web based on the invariants of the curvature tensor defined
not only by the gravitational potential, but especially by the over-density, as
small scale clustering becomes important in this context. First, the gas
density bias relation can be directly mapped onto the dark matter density field
to high precision exploiting the strong correlation between them. In a second
step, the neutral hydrogen is mapped based on the dark matter and the gas
density fields. Finally, the temperature is mapped based on the previous
quantities. This permits us to statistically reconstruct the baryon properties
within the same simulated volume finding percent-precision in the two-point
statistics and compatible results in the three-point statistics, in general
within 1-$\sigma$, with respect to the reference simulation (with 5 to 6 orders
of magnitude less computing time). This paves the path to establish the best
set-up for the construction of mocks probing the intergalactic medium for the
generation of such key ingredients in the statistical analysis of large
forthcoming missions such as DESI, Euclid, J-PAS and WEAVE.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:57:46 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 08:11:23 GMT""}]","2021-11-17"
"2012.06796","Lorenzo Dello Schiavo","Lorenzo Dello Schiavo, Eva Kopfer, Karl-Theodor Sturm","A Discovery Tour in Random Riemannian Geometry","45 pages, 9 figures. Version 3: several major changes",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study random perturbations of Riemannian manifolds
$(\mathsf{M},\mathsf{g})$ by means of so-called Fractional Gaussian Fields,
which are defined intrinsically by the given manifold. The fields $h^\bullet:
\omega\mapsto h^\omega$ will act on the manifolds via conformal transformation
$\mathsf{g}\mapsto \mathsf{g}^\omega\colon\!\!= e^{2h^\omega}\,\mathsf{g}$. Our
focus will be on the regular case with Hurst parameter $H>0$, the celebrated
Liouville geometry in two dimensions being borderline. We want to understand
how basic geometric and functional analytic quantities like diameter, volume,
heat kernel, Brownian motion, spectral bound, or spectral gap will change under
the influence of the noise. And if so, is it possible to quantify these
dependencies in terms of key parameters of the noise. Another goal is to define
and analyze in detail the Fractional Gaussian Fields on a general Riemannian
manifold, a fascinating object of independent interest.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:01:46 GMT""},{""version"":""v2"",""created"":""Mon, 11 Oct 2021 10:48:18 GMT""},{""version"":""v3"",""created"":""Mon, 24 Oct 2022 20:56:48 GMT""}]","2022-10-26"
"2012.06797","Davor Dragicevic","Lucas Backes and Davor Dragi\v{c}evi\'c","A general approach to nonautonomous shadowing for nonlinear dynamics",,,"10.1016/j.bulsci.2021.102996",,"math.DS math.CA","http://creativecommons.org/publicdomain/zero/1.0/","  Given a nonautonomous and nonlinear differential equation
\begin{equation}\label{DE} x'=A(t)x+f(t,x) \quad t\geq 0, \end{equation} on an
arbitrary Banach space $X$, we formulate very general conditions for the
associated linear equation $x'=A(t)x$ and for the nonlinear term
$f:[0,+\infty)\times X\to X$ under which the above system satisfies an
appropriate version of the shadowing property. More precisely, we require that
$x'=A(t)x$ admits a very general type of dichotomy, which includes the
classical hyperbolic behaviour as a very particular case. In addition, we
require that $f$ is Lipschitz in the second variable with a sufficiently small
Lipschitz constant. Our general framework enables us to treat various settings
in which no shadowing result has been previously obtained. Moreover, we are
able to recover and refine several known results.
  We also show how our main results can be applied to the study of the
shadowing property for higher order differential equations. Finally, we
conclude the paper by presenting a discrete time versions of our results.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:04:09 GMT""}]","2021-05-27"
"2012.06798","Ryo Takahashi","Ryo Takahashi","Grothendieck groups, convex cones and maximal Cohen-Macaulay points","22 pages, to appear in Math. Z., comments welcome",,,,"math.AC math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let A be a commutative noetherian ring. Let H(A) be the quotient of the
Grothendieck group of finitely generated A-modules by the subgroup generated by
pseudo-zero modules. Suppose that the real vector space H(A)_R = H(A) \otimes_Z
R has finite dimension. Let C(A) (resp. C_r(A)) be the convex cone in H(A)_R
spanned by maximal Cohen-Macaulay A-modules (resp. maximal Cohen-Macaulay
A-modules of rank r). We explore the interior, closure and boundary, and convex
polyhedral subcones of C(A). We provide various equivalent conditions for A to
have only finitely many rank r maximal Cohen-Macaulay points in C_r(A) in terms
of topological properties of C_r(A). Finally, we consider maximal
Cohen-Macaulay modules of rank one as elements of the divisor class group
Cl(A).
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:12:13 GMT""}]","2020-12-15"
"2012.06799","Weiming Shen","Qing Han, Xumin Jiang, Weiming Shen","The Loewner-Nirenberg Problem in Cones",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study asymptotic behaviors of solutions to the Loewner-Nirenberg problem
in finite cones and establish optimal asymptotic expansions in terms of the
corresponding solutions in infinite cones. The spherical domains over which
cones are formed are allowed to have singularities. An elliptic operator on
such spherical domains with coefficients singular on boundary play an important
role. Due to the singularity of the spherical domains, extra cares are needed
for the study of the global regularity of the eigenfunctions and solutions of
the associated singular Dirichlet problem.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:15:41 GMT""}]","2020-12-15"
"2012.06800","Srinivas Anumasa","Srinivas Anumasa, P.K. Srijith","Delay Differential Neural Networks",,,,,"cs.LG cs.CV cs.NE","http://creativecommons.org/licenses/by/4.0/","  Neural ordinary differential equations (NODEs) treat computation of
intermediate feature vectors as trajectories of ordinary differential equation
parameterized by a neural network. In this paper, we propose a novel model,
delay differential neural networks (DDNN), inspired by delay differential
equations (DDEs). The proposed model considers the derivative of the hidden
feature vector as a function of the current feature vector and past feature
vectors (history). The function is modelled as a neural network and
consequently, it leads to continuous depth alternatives to many recent ResNet
variants. We propose two different DDNN architectures, depending on the way
current and past feature vectors are considered. For training DDNNs, we provide
a memory-efficient adjoint method for computing gradients and back-propagate
through the network. DDNN improves the data efficiency of NODE by further
reducing the number of parameters without affecting the generalization
performance. Experiments conducted on synthetic and real-world image
classification datasets such as Cifar10 and Cifar100 show the effectiveness of
the proposed models.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:20:54 GMT""}]","2020-12-15"
"2012.06801","Masahiro Futaki","Masahiro Futaki, Hiroshige Kajiura","Homological mirror symmetry of $\mathbb{F}_1$ via Morse homotopy","22 pages",,,,"math.SG hep-th math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is a sequel to our paper arXiv:2008.13462, where we proposed a
definition of the Morse homotopy of the moment polytope of toric manifolds.
Using this as the substitute of the Fukaya category of the toric manifolds, we
proved a version of homological mirror symmetry for the projective spaces and
their products via Strominger-Yau-Zaslow construction of the mirror dual
Landau-Ginzburg model. In this paper we go this way further and extend our
previous result to the case of the Hirzebruch surface $\mathbb{F}_1$.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:21:20 GMT""}]","2020-12-15"
"2012.06802","Li Zeng","Li Zeng and Yan Jiang and Weixin Lu and Lei Zou","Deep Analysis on Subgraph Isomorphism",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Subgraph isomorphism is a well-known NP-hard problem which is widely used in
many applications, such as social network analysis and knowledge graph query.
Its performance is often limited by the inherent hardness. Several insightful
works have been done since 2012, mainly optimizing pruning rules and matching
orders to accelerate enumerating all isomorphic subgraphs. Nevertheless, their
correctness and performance are not well studied. First, different languages
are used in implementation with different compilation flags. Second,
experiments are not done on the same platform and the same datasets. Third,
some ideas of different works are even complementary. Last but not least, there
exist errors when applying some algorithms. In this paper, we address these
problems by re-implementing seven representative subgraph isomorphism
algorithms as well as their improved versions, and conducting comprehensive
experiments on various graphs. The results show pros and cons of
state-of-the-art solutions and explore new approaches to optimization.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:29:38 GMT""},{""version"":""v2"",""created"":""Tue, 20 Apr 2021 15:28:09 GMT""}]","2021-04-21"
"2012.06803","Yujia Wang","Yujia Wang and Tong Wang and Jiae Yang and Xuebo Yang","A Novel Method to Design Controller Parameters by Using Uniform Design
  Algorithm",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parameter selection is one of the most important parts for nearly all the
control strategies. Traditionally, controller parameters are chosen by
utilizing trial and error, which is always tedious and time consuming.
Moreover, such method is highly dependent on the experience of researchers,
which means that it is hard to be popularized. In this light, this paper
proposes a novel parameter searching approach by utilizing uniform design (UD)
algorithm. By which the satisfactory controller parameters under a performance
index could be selected. In this end, two simulation examples are conducted to
verify the effectiveness of proposed scheme. Simulation results show that this
novel approach, as compared to other intelligent tuning algorithms, excels in
efficiency and time saving.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:30:22 GMT""}]","2022-04-13"
"2012.06804","Manas Bhatnagar","Manas Bhatnagar and Hailiang Liu","Sharp critical thresholds in a hyperbolic system with relaxation","19 pages, 2 figures",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We propose and study a one-dimensional $2\times 2$ hyperbolic Eulerian system
with local relaxation from critical threshold phenomena perspective. The system
features dynamic transition between strictly and weakly hyperbolic. For
different classes of relaxation we identify intrinsic critical thresholds for
initial data that distinguish global regularity and finite time blowup. For
relaxation independent of density, we estimate bounds on density in terms of
velocity where the system is strictly hyperbolic.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:35:14 GMT""}]","2020-12-15"
"2012.06805","Wesley Joon-Wie Tann","Wesley Joon-Wie Tann, Jackie Tan Jin Wei, Joanna Purba, Ee-Chien Chang","Filtering DDoS Attacks from Unlabeled Network Traffic Data Using Online
  Deep Learning",,,,,"cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  DDoS attacks are simple, effective, and still pose a significant threat even
after more than two decades. Given the recent success in machine learning, it
is interesting to investigate how we can leverage deep learning to filter out
application layer attack requests. There are challenges in adopting deep
learning solutions due to the ever-changing profiles, the lack of labeled data,
and constraints in the online setting. Offline unsupervised learning methods
can sidestep these hurdles by learning an anomaly detector $N$ from the
normal-day traffic ${\mathcal N}$. However, anomaly detection does not exploit
information acquired during attacks, and their performance typically is not
satisfactory. In this paper, we propose two frameworks that utilize both the
historic ${\mathcal N}$ and the mixture ${\mathcal M}$ traffic obtained during
attacks, consisting of unlabeled requests. We also introduce a machine learning
optimization problem that aims to sift out the attacks using ${\mathcal N}$ and
${\mathcal M}$. First, our proposed approach, inspired by statistical methods,
extends an unsupervised anomaly detector $N$ to solve the problem using
estimated conditional probability distributions. We adopt transfer learning to
apply $N$ on ${\mathcal N}$ and ${\mathcal M}$ separately and efficiently,
combining the results to obtain an online learner. Second, we formulate a
specific loss function more suited for deep learning and use iterative training
to solve it in the online setting. On publicly available datasets, our online
learners achieve a $99.3\%$ improvement on false-positive rates compared to the
baseline detection methods. In the offline setting, our approaches are
competitive with classifiers trained on labeled data.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:39:05 GMT""}]","2020-12-15"
"2012.06806","Ning Jiang","Ning Jiang, Tinggui Wang, Liming Dou, Xinwen Shu, Xueyang Hu, Hui Liu,
  Yibo Wang, Lin Yan, Zhenfeng Sheng, Chenwei Yang, Luming Sun, Hongyan Zhou","Mid-InfraRed Outburst in Nearby Galaxies (MIRONG) I: Sample Selection
  and Characterization","ApJS accepted, 19 Figures, 5 Tables",,"10.3847/1538-4365/abd1dc",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The optical time-domain astronomy has grown rapidly in the past decade but
the dynamic infrared sky is rarely explored. Aiming to construct a sample of
mid-infrared outburst in nearby galaxies (MIRONG), we have conducted a
systematical search of low-redshift ($z<0.35$) SDSS spectroscopic galaxies that
have experienced recent MIR flares using their Wide-field Infrared Survey
Explorer (WISE) light curves. A total of 137 galaxies have been selected by
requiring a brightening amplitude of 0.5 magnitude in at least one WISE band
with respect to their quiescent phases. Only a small faction (10.9%) has
corresponding optical flares. Except for the four supernova (SNe) in our
sample, the MIR luminosity of remaining sources ($L_{\rm 4.6\mu m}>10^{42}~\rm
erg~s^{-1}$) are markedly brighter than known SNe and their physical locations
are very close to the galactic center (median <0.1""). Only four galaxies are
radio-loud indicating that synchrotron radiation from relativistic jets could
contribute MIR variability. We propose that these MIR outburst are dominated by
the dust echoes of transient accretion onto supermassive black holes, such as
tidal disruption events (TDEs) and turn-on (changing-look) AGNs. Moreover, the
inferred peak MIR luminosity function is generally consistent with the X-ray
and optical TDEs at high end albeit with large uncertainties. Our results
suggest that a large population of transients have been overlooked by optical
surveys, probably due to dust obscuration or intrinsically optical weakness.
Thus, a search in the infrared band is crucial for us to obtain a panoramic
picture of nuclear outburst. The multiwavength follow-up observations of the
MIRONG sample are in progress and will be presented in a series of subsequent
papers.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:45:24 GMT""}]","2021-02-17"
"2012.06807","Hongzhe Zhou","Hongzhe Zhou, Eric G. Blackman","Influence of inhomogeneous stochasticity on the falsifiability of
  mean-field theories and examples from accretion disc modeling","10 pages, 4 figures; accepted by MNRAS",,"10.1093/mnras/stab2403",,"astro-ph.HE astro-ph.GA astro-ph.IM astro-ph.SR physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite spatial and temporal fluctuations in turbulent astrophysical systems,
mean-field theories can be used to describe their secular evolution. However,
observations taken over time scales much shorter than dynamical time scales
capture a system in a single state of its turbulence ensemble. Comparing with
mean-field theory can falsify the latter only if the theory is additionally
supplied with a quantified precision. The central limit theorem provides
appropriate estimates to the precision only when fluctuations contribute
linearly to an observable and with constant coherent scales. Here we introduce
an error propagation formula that relaxes both limitations, allowing for
nonlinear functional forms of observables and inhomogeneous coherent scales and
amplitudes of fluctuations. The method is exemplified in the context of
accretion disc theories, where inhomogeneous fluctuations in the surface
temperature are propagated to the disc emission spectrum--the latter being a
nonlinear and non-local function of the former. The derived precision depends
non-monotonically on emission frequency. Using the same method, we investigate
how binned spectral fluctuations in telescope data change with the spectral
resolving power. We discuss the broader implications for falsifiability of a
mean-field theory.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 12:52:10 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 11:14:53 GMT""},{""version"":""v3"",""created"":""Mon, 30 Aug 2021 08:01:06 GMT""}]","2021-09-08"
"2012.06808","Paolo Leonetti","Paolo Leonetti and Michele Caprio","Turnpike in infinite dimension","Example 2.6 has been added",,"10.4153/S0008439521000382",,"math.FA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Phi$ be a correspondence from a normed vector space $X$ into itself,
let $u: X\to \mathbf{R}$ be a function, and $\mathcal{I}$ be an ideal on
$\mathbf{N}$. Also, assume that the restriction of $u$ on the fixed points of
$\Phi$ has a unique maximizer $\eta^\star$. Then, we consider feasible paths
$(x_0,x_1,\ldots)$ with values in $X$ such that $x_{n+1} \in \Phi(x_n)$ for all
$n\ge 0$. Under certain additional conditions, we prove the following turnpike
result: every feasible path $(x_0,x_1,\ldots)$ which maximizes the smallest
$\mathcal{I}$-cluster point of the sequence $(u(x_0),u(x_1),\ldots)$ is
necessarily $\mathcal{I}$-convergent to $\eta^\star$.
  We provide examples that, on the one hand, justify the hypotheses of our
result and, on the other hand, prove that we are including new cases which were
previously not considered in the related literature.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:07:59 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 12:51:44 GMT""}]","2021-07-01"
"2012.06809","Laijin Meng","Laijin Meng, Xinghao Jiang, Zhenzhen Zhang, Zhaohong Li, and Tanfeng
  Sun","Coverless Video Steganography based on Maximum DC Coefficients",,,,,"cs.MM cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coverless steganography has been a great interest in recent years, since it
is a technology that can absolutely resist the detection of steganalysis by not
modifying the carriers. However, most existing coverless steganography
algorithms select images as carriers, and few studies are reported on coverless
video steganography. In fact, video is a securer and more informative carrier.
In this paper, a novel coverless video steganography algorithm based on maximum
Direct Current (DC) coefficients is proposed. Firstly, a Gaussian distribution
model of DC coefficients considering video coding process is built, which
indicates that the distribution of changes for maximum DC coefficients in a
block is more stable than the adjacent DC coefficients. Then, a novel hash
sequence generation method based on the maximum DC coefficients is proposed.
After that, the video index structure is established to speed up the efficiency
of searching videos. In the process of information hiding, the secret
information is converted into binary segments, and the video whose hash
sequence equals to secret information segment is selected as the carrier
according to the video index structure. Finally, all of the selected videos and
auxiliary information are sent to the receiver. Especially, the subjective
security of video carriers, the cost of auxiliary information and the
robustness to video compression are considered for the first time in this
paper. Experimental results and analysis show that the proposed algorithm
performs better in terms of capacity, robustness, and security, compared with
the state-of-the-art coverless steganography algorithms.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:21:30 GMT""}]","2020-12-15"
"2012.06810","David Sanchez","Alberto Blanco-Justicia, Josep Domingo-Ferrer, Sergio Mart\'inez,
  David S\'anchez, Adrian Flanagan and Kuan Eeik Tan","Achieving Security and Privacy in Federated Learning Systems: Survey,
  Research Challenges and Future Directions","40 pages, 19 figures",,,,"cs.CR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning (FL) allows a server to learn a machine learning (ML)
model across multiple decentralized clients that privately store their own
training data. In contrast with centralized ML approaches, FL saves computation
to the server and does not require the clients to outsource their private data
to the server. However, FL is not free of issues. On the one hand, the model
updates sent by the clients at each training epoch might leak information on
the clients' private data. On the other hand, the model learnt by the server
may be subjected to attacks by malicious clients; these security attacks might
poison the model or prevent it from converging. In this paper, we first examine
security and privacy attacks to FL and critically survey solutions proposed in
the literature to mitigate each attack. Afterwards, we discuss the difficulty
of simultaneously achieving security and privacy protection. Finally, we sketch
ways to tackle this open problem and attain both security and privacy.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:23:56 GMT""}]","2020-12-15"
"2012.06811","Usha Bhosle N.","Usha N. Bhosle","Poincar\'e bundle for the fixed determinant moduli space on a nodal
  curve",,,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  Let $Y$ be an integral nodal projective curve of arithmetic genus $g\ge 2$
with $m$ nodes defined over an algebraically closed field $k$ and $x$ a
nonsingular closed point of $Y$. Let $n$ and $d$ be coprime integers with $n\ge
2$. Fix a line bundle $L$ of degree $d$ on $Y$. Let $U_Y(n,d,L)$ denote the
(compactified) ""fixed determinant moduli space"". We prove that the restriction
$\mathcal{U}_{L,x}$ of the Poincare bundle to $x \times U_Y(n,d,L)$ is stable
with respect to the polarisation $\theta_L$ and its restriction to $x \times
U'_Y(n,d,L)$, where $U'_Y(n,d,L)$ is the moduli space of vector bundles of rank
$n$ and determinant $L$, is stable with respect to any polarisation. We show
that the Poincar\'e bundle $\mathcal{U}_{L}$ on $Y \times U_Y(n,d,L)$ is stable
with respect to the polarisation $a \alpha + b \theta_L$ where $\alpha$ is a
fixed ample Cartier divisor on $Y$ and $a, b$ are positive integers.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:25:25 GMT""}]","2020-12-15"
"2012.06812","Bogdan Guster","Bogdan Guster, Miguel Pruneda, Pablo Ordej\'on, Enric Canadell,
  Jean-Paul Pouget","Electron-hole response function of transition metal trichalcogenides
  NbSe$_3$ and monoclinic-TaS$_3$",,,"10.1088/1361-648X/ac238a",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  NbSe$_3$ and monoclinic-TaS$_3$ ($m$-TaS$_3$) are quasi-1D metals containing
three different types of chains and undergoing two different charge density
wave (CDW) Peierls transitions at T$_{P_1}$ and T$_{P_2}$. The nature of these
transitions is discussed on the basis of first-principles DFT calculation of
their electron-hole Lindhard response function. As a result of stronger
inter-chain interactions the Fermi surface (FS) and Lindhard function of
NbSe$_3$ are considerably more complex than those for $m$-TaS$_3$; however a
common scenario can be put forward to rationalize the results. The intra-chain
inter-band nesting processes dominate the strongest response for both type I
and type III chains of the two compounds. Two well-defined maxima of the
Lindhard response for NbSe$_3$ are found with the (0$a$*, 0$c$*) and (1/2$a$*,
1/2$c$*) transverse components at T$_{P_1}$ and T$_{P_2}$, respectively,
whereas the second maximum is not observed for $m$-TaS$_3$ at T$_{P2}$.
Analysis of the different inter-chain coupling mechanisms leads to the
conclusion that FS nesting effects are only relevant to set the transverse $a$*
components in NbSe$_3$. For the transverse coupling along $c$* in NbSe$_3$ and
along both $a$* and $c$* for $m$-TaS$_3$, one must take into account the
strongest inter-chain Coulomb coupling mechanism. Phonon spectrum calculations
show the formation of a giant 2$k_F$ Kohn anomaly in $m$-TaS$_3$. All these
results support the weak coupling scenario for the Peierls transition of
transition metal trichalcogenides.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:26:01 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 12:31:23 GMT""}]","2021-09-17"
"2012.06813","Yu Zhang","Yu Zhang, Tao Zhou, Wei Wu, Hua Xie, Hongru Zhu, Guoxu Zhou, Andrzej
  Cichocki","Improving EEG Decoding via Clustering-based Multi-task Feature Learning",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate electroencephalogram (EEG) pattern decoding for specific mental
tasks is one of the key steps for the development of brain-computer interface
(BCI), which is quite challenging due to the considerably low signal-to-noise
ratio of EEG collected at the brain scalp. Machine learning provides a
promising technique to optimize EEG patterns toward better decoding accuracy.
However, existing algorithms do not effectively explore the underlying data
structure capturing the true EEG sample distribution, and hence can only yield
a suboptimal decoding accuracy. To uncover the intrinsic distribution structure
of EEG data, we propose a clustering-based multi-task feature learning
algorithm for improved EEG pattern decoding. Specifically, we perform affinity
propagation-based clustering to explore the subclasses (i.e., clusters) in each
of the original classes, and then assign each subclass a unique label based on
a one-versus-all encoding strategy. With the encoded label matrix, we devise a
novel multi-task learning algorithm by exploiting the subclass relationship to
jointly optimize the EEG pattern features from the uncovered subclasses. We
then train a linear support vector machine with the optimized features for EEG
pattern decoding. Extensive experimental studies are conducted on three EEG
datasets to validate the effectiveness of our algorithm in comparison with
other state-of-the-art approaches. The improved experimental results
demonstrate the outstanding superiority of our algorithm, suggesting its
prominent performance for EEG pattern decoding in BCI applications.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:31:53 GMT""}]","2020-12-15"
"2012.06814","Hossein T Dinani","Hossein T. Dinani, Enrique Mu\~noz, Jeronimo R. Maze","Sensing electrochemical signals using a nitrogen-vacancy center in
  diamond","17 pages, 7 figures, comments are welcome","Nanomaterials 11, 358 (2021)","10.3390/nano11020358",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chemical sensors with high sensitivity that can be used in extreme conditions
and can be miniaturized are of high interest in science and industry. The
Nitrogen-vacancy (NV) center in diamond is an ideal candidate as a nanosensor
due to the long coherence time of its electron spin and its optical
accessibility. In this theoretical work, we propose to use an NV center to
detect electrochemical signals emerging from an electrolyte solution, thus
obtaining a concentration sensor. For this purpose, we propose to use the
inhomogeneous dephasing rate of the electron spin of the NV center ($1/T^*_2$)
as a signal. We show that for a range of mean ionic concentrations in the bulk
of the electrolyte solution, the electric field fluctuations produced by the
diffusional fluctuations in the local concentration of ions, result in
dephasing rates which can be inferred from free induction decay measurements.
Moreover, we show that for a range of concentrations, the electric field
generated at the position of the NV center can also be used to estimate the
concentration of ions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:32:08 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 11:51:22 GMT""}]","2021-02-16"
"2012.06815","Xinyu Zhang","Bin Yan, Xinyu Zhang, Dong Wang, Huchuan Lu, Xiaoyun Yang","Alpha-Refine: Boosting Tracking Performance by Precise Bounding Box
  Estimation","arXiv admin note: Accepted to CVPR 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual object tracking aims to precisely estimate the bounding box for the
given target, which is a challenging problem due to factors such as deformation
and occlusion. Many recent trackers adopt the multiple-stage tracking strategy
to improve the quality of bounding box estimation. These methods first coarsely
locate the target and then refine the initial prediction in the following
stages. However, existing approaches still suffer from limited precision, and
the coupling of different stages severely restricts the method's
transferability. This work proposes a novel, flexible, and accurate refinement
module called Alpha-Refine (AR), which can significantly improve the base
trackers' box estimation quality. By exploring a series of design options, we
conclude that the key to successful refinement is extracting and maintaining
detailed spatial information as much as possible. Following this principle,
Alpha-Refine adopts a pixel-wise correlation, a corner prediction head, and an
auxiliary mask head as the core components. Comprehensive experiments on
TrackingNet, LaSOT, GOT-10K, and VOT2020 benchmarks with multiple base trackers
show that our approach significantly improves the base trackers' performance
with little extra latency. The proposed Alpha-Refine method leads to a series
of strengthened trackers, among which the ARSiamRPN (AR strengthened SiamRPNpp)
and the ARDiMP50 (ARstrengthened DiMP50) achieve good efficiency-precision
trade-off, while the ARDiMPsuper (AR strengthened DiMP-super) achieves very
competitive performance at a real-time speed. Code and pretrained models are
available at https://github.com/MasterBin-IIAU/AlphaRefine.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:33:25 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 03:53:00 GMT""},{""version"":""v3"",""created"":""Sun, 11 Jul 2021 07:37:19 GMT""}]","2021-07-13"
"2012.06816","Fangqi Li","Fangqi Li","Evaluation and Comparison of Diffusion Models with Motif Features","7 pages, 3 figures",,,,"cs.SI cs.NI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Diffusion models simulate the propagation of influence in networks. The
design and evaluation of diffusion models has been subjective and empirical.
When being applied to a network represented by a graph, the diffusion model
generates a sequence of edges on which the influence flows, such sequence forms
a temporal network. In most scenarios, the statistical properties or the
characteristics of a network are inferred by analyzing the temporal networks
generated by diffusion models. To analyze real temporal networks, the motif has
been proposed as a reliable feature. However, it is unclear how the network
topology and the diffusion model affect the motif feature of a generated
temporal network. In this paper, we adopt the motif feature to evaluate the
temporal graph generated by a diffusion model, thence the diffusion model
itself. Two benchmarks for quantitively evaluating diffusion models with motif,
stability and separability, are proposed and measured on numerous diffusion
models. One motif-based metric is proposed to measure the similarity between
diffusion models. The experiments suggest that the motif of a generated
temporal network is dominated by the diffusion model, while the network
topology is almost ignored. This result indicates that more practical and
reliable diffusion models have to be designed with delicacy in order to capture
the propagation patterns of real temporal networks.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:35:22 GMT""}]","2020-12-15"
"2012.06817","Karol Szczypkowski","Tomasz Jakubowski and Karol Szczypkowski","Sharp and plain estimates for Schr\""odinger perturbation of Gaussian
  kernel",,,,,"math.AP math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate whether a fundamental solution of the Schr\""odinger equation
$\partial_t u =(\Delta +V)\, u$ has local in time sharp Gaussian estimates. We
compare that class with the class of $V$ for which local in time plain Gaussian
estimates hold. We concentrate on $V$ that have fixed sign and we present
certain conclusions for $V$ in the Kato class.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:40:28 GMT""}]","2020-12-15"
"2012.06818","Orhan O\u{g}ulcan Tuncer Mr.","O. Ogulcan Tuncer and Ismail Gok","Pedal curves of hyperbolic frontals and their singularities",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces pedal curves of spacelike frontals in the hyperbolic
2-space. We mainly investigate the singularities of these hyperbolic pedal
curves of spacelike frontals for non-singular and singular dual curve germs. We
then show that for non-singular dual curve germs, the singularities of a pedal
curve are dependent on the singularities of the first hyperbolic Legendrian
curvature germ and the location of the pedal point, while for singular dual
curve germs, they depend upon the singularities of both hyperbolic Legendrian
curvature germs and also the location of the pedal point. We provide several
examples with figures.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:47:10 GMT""},{""version"":""v2"",""created"":""Sat, 11 Feb 2023 09:08:11 GMT""}]","2023-02-14"
"2012.06819","Marco Antonio Aquino-L\'opez","Marco A Aquino-L\'opez and Nicole K. Sanderson and Maarten Blaauw and
  Joan-Albert Sanchez-Cabeza and Ana Carolina Ruiz-Fernandez and J Andr\'es
  Christen Marco A Aquino-L\'opez, Nicole K. Sanderson, Maarten Blaauw,
  Joan-Albert Sanchez-Cabeza, Ana Carolina Ruiz-Fernandez, J Andr\'es Christen","A simulation study to compare 210Pb dating data analyses","15 pages, 6 figures",,,,"stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The increasing interest in understanding anthropogenic impacts on the
environment have led to a considerable number of studies focusing on
sedimentary records for the last $\sim$ 100 - 200 years. Dating this period is
often complicated by the poor resolution and large errors associated with
radiocarbon (14C) ages, which is the most popular dating technique. To improve
age-depth model resolution for the recent period, sediment dating with lead-210
($^{210}$Pb) is widely used as it provides absolute and continuous dates for
the last $\sim$ 100 - 150 years. The $^{210}$Pb dating method has traditionally
relied on the Constant Rate of Supply (CRS, also known as Constant Flux - CF)
model which uses the radioactive decay equation as an age-depth relationship
resulting in a restrictive model to approximate dates. In this work, we compare
the classical approach to $^{210}$Pb dating (CRS) and its Bayesian alternative
(\textit{Plum}). To do so, we created simulated $^{210}$Pb profiles following
three different sedimentation processes, complying with the assumptions imposed
by the CRS model, and analysed them using both approaches. Results indicate
that the CRS model does not capture the true values even with a high dating
resolution for the sediment, nor improves does its accuracy improve as more
information is available. On the other hand, the Bayesian alternative
(\textit{Plum}) provides consistently more accurate results even with few
samples, and its accuracy and precision constantly improves as more information
is available.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:49:37 GMT""}]","2020-12-15"
"2012.06820","Alexander Jurisch","Alexander Jurisch","Lagrangian dynamics in inhomogeneous and thermal environments, An
  application of the Onsager-Machlup theory I","21 pages, 11 figures",,,,"cond-mat.stat-mech nlin.AO physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We straight-forwardly derive the Onsager-Machlup Lagrangian from the
Fokker-Planck equation and show that friction and dissipation are a natural
property of the equation of motion. We develop a method to calculate the local
variance $\sigma_{2}\,b(q)^{2}$ and identify this function as a
Helmholtz-factor. In both meanings the function $b(q)$ describes properties of
the environment. For application, we examine the free fall through a barometric
medium and model a blow of wind by a solitonic pulse running through the
medium. We treat harmonic oscillators immersed in a thermal bath, finding
intuitive as well as counter-intuitive phenomena of friction. By allowing the
temperature to be time-dependent, the dynamical process of cooling and heating
becomes self-consistently available. We find a state of dynamical balance
between system and environment. Last, we show that dynamical balance is related
to adiabatic thermodynamic processes. In a special case, dynamical balance can
induce a real phase-transition.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:54:02 GMT""}]","2020-12-15"
"2012.06821","Michael Schmitz","Michael Schmitz and Andr\'e Streicher","Envelopes are solving machines for quadratics and cubics and certain
  polynomials of arbitrary degree","12 pages, 9 figures",,,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Everybody knows from school how to solve a quadratic equation of the form
$x^2-px+q=0$ graphically. But this method can become tedious if several
equations ought to be solved, as for each pair $(p,q)$ a new parabola has to be
drawn. Stunningly, there is one single curve that can be used to solve every
quadratic equation via drawing tangent lines through a given point $(p,q)$ to
this curve.
  In this article we derive this method in an elementary way and generalize it
to equations of the form $x^n-px+q=0$ for arbitrary $n \ge 2$. Moreover, the
number of solutions of a specific equation of this form can be seen immediately
with this technique. Concluding the article we point out connections to the
duality of points and lines in the plane and to the the concept of Legendre
transformation.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 13:57:01 GMT""}]","2020-12-15"
"2012.06822","Markus Borg","Markus Borg, Raja Ben Abdessalem, Shiva Nejati, Francois-Xavier
  Jegeden, Donghwan Shin","Digital Twins Are Not Monozygotic -- Cross-Replicating ADAS Testing in
  Two Industry-Grade Automotive Simulators","To appear in the Proc. of the IEEE International Conference on
  Software Testing, Verification and Validation (ICST) 2021",,,,"cs.SE cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increasing levels of software- and data-intensive driving automation call
for an evolution of automotive software testing. As a recommended practice of
the Verification and Validation (V&V) process of ISO/PAS 21448, a candidate
standard for safety of the intended functionality for road vehicles,
simulation-based testing has the potential to reduce both risks and costs.
There is a growing body of research on devising test automation techniques
using simulators for Advanced Driver-Assistance Systems (ADAS). However, how
similar are the results if the same test scenarios are executed in different
simulators? We conduct a replication study of applying a Search-Based Software
Testing (SBST) solution to a real-world ADAS (PeVi, a pedestrian vision
detection system) using two different commercial simulators, namely,
TASS/Siemens PreScan and ESI Pro-SiVIC. Based on a minimalistic scene, we
compare critical test scenarios generated using our SBST solution in these two
simulators. We show that SBST can be used to effectively and efficiently
generate critical test scenarios in both simulators, and the test results
obtained from the two simulators can reveal several weaknesses of the ADAS
under test. However, executing the same test scenarios in the two simulators
leads to notable differences in the details of the test outputs, in particular,
related to (1) safety violations revealed by tests, and (2) dynamics of cars
and pedestrians. Based on our findings, we recommend future V&V plans to
include multiple simulators to support robust simulation-based testing and to
base test objectives on measures that are less dependant on the internals of
the simulators.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:00:33 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 08:55:23 GMT""}]","2021-01-29"
"2012.06823","Jean Besbas Dr.","C. Banerjee, K. Rode, G. Atcheson, S. Lenne, P. Stamenov, J. M. D.
  Coey and J. Besbas","Ultra-fast Double Pulse All-Optical Re-switching of a Ferrimagnet","13 pages - 4 figures","Phys. Rev. Lett. 126, 177202 (2021)","10.1103/PhysRevLett.126.177202",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  All-optical re-switching has been investigated in the half-metallic Heusler
ferrimagnet Mn2Ru0.9Ga, where Mn atoms occupy two inequivalent sites in the
XA-type structure. The effect of a second 200 fs 800 nm pump pulse that follows
a first pulse, when both are above the threshold for switching, is studied as a
function of t12, the time between them. The aims are to identify the physical
mechanisms involved and to determine the minimum time needed for re-switching.
The time trajectory of the switching process on a plot of sublattice angular
momentum, S4a vs S4c, is in three stages; When t < 0.1 ps, the sublattice
moments are rapidly disordered, but not destroyed, while conserving net angular
momentum via optical spin-wave excitations. This leads to transient parallel
alignment of the residual Mn spins in the first quadrant. The net angular
momentum associated with the majority sublattice then flips in about 2 ps, and
a fully-reversed ferrimagnetic state is then established via the spin-lattice
interaction, which allows re-switching provided t12 > 10 ps.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:08:25 GMT""}]","2021-05-05"
"2012.06824","Martin Monperrus","Benoit Baudry, Zimin Chen, Khashayar Etemadi, Han Fu, Davide Ginelli,
  Steve Kommrusch, Matias Martinez, Martin Monperrus, Javier Ron, He Ye,
  Zhongxing Yu","A Software-Repair Robot based on Continual Learning",,"IEEE Software, 2021","10.1109/ms.2021.3070743",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Software bugs are common and correcting them accounts for a significant part
of costs in the software development and maintenance process. This calls for
automatic techniques to deal with them. One promising direction towards this
goal is gaining repair knowledge from historical bug fixing examples.
Retrieving insights from software development history is particularly appealing
with the constant progress of machine learning paradigms and skyrocketing `big'
bug fixing data generated through Continuous Integration (CI). In this paper,
we present R-Hero, a novel software repair bot that applies continual learning
to acquire bug fixing strategies from continuous streams of source code
changes, implemented for the single development platform Github/Travis CI. We
describe R-Hero, our novel system for learning how to fix bugs based on
continual training, and we uncover initial successes as well as novel research
challenges for the community.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:12:00 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 07:35:18 GMT""},{""version"":""v3"",""created"":""Tue, 17 Aug 2021 13:52:06 GMT""},{""version"":""v4"",""created"":""Mon, 6 Dec 2021 10:55:03 GMT""}]","2021-12-07"
"2012.06825","Francesco Calisto","Luca Bottero, Francesco Calisto, Giovanni Graziano, Valerio
  Pagliarino, Martina Scauda, Sara Tiengo and Simone Azeglio","Physics-Informed Machine Learning Simulator for Wildfire Propagation","Research presented at the competition ""ProjectX 2020"" by UofT AI (15
  pages)",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The aim of this work is to evaluate the feasibility of re-implementing some
key parts of the widely used Weather Research and Forecasting WRF-SFIRE
simulator by replacing its core differential equations numerical solvers with
state-of-the-art physics-informed machine learning techniques to solve ODEs and
PDEs, in order to transform it into a real-time simulator for wildfire spread
prediction. The main programming language used is Julia, a compiled language
which offers better perfomance than interpreted ones, providing Just in Time
(JIT) compilation with different optimization levels. Moreover, Julia is
particularly well suited for numerical computation and for the solution of
complex physical models, both considering the syntax and the presence of some
specific libraries such as DifferentialEquations.jl and ModellingToolkit.jl.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:13:26 GMT""}]","2020-12-15"
"2012.06826","Varghese Mathai","Lei Yi, Shuai Li, Hechuan Jiang, Detlef Lohse, Chao Sun, Varghese
  Mathai","Water entry of spheres into a rotating liquid","10 pages, 3 figures, Journal of Fluid Mechanics (in press)","J. Fluid Mech. 912 (2021) R1","10.1017/jfm.2020.1147",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The transient cavity dynamics during water entry of a heavy, non-rotating
sphere impacting a rotating pool of liquid is studied experimentally,
numerically, and theoretically. We show that the pool rotation advances the
transition of the cavity type - from deep seal to surface seal - marked by a
reduction in the transitional Froude number. The role of the dimensionless
rotational number $\mathcal{S} \equiv \omega R_0/U_0$ on the transient cavity
dynamics is unveiled, where $R_0$ is the sphere radius, $\omega$ the angular
speed of the liquid, and $U_0$ the impact velocity. The rotating background
liquid has two discernible effects on the cavity evolution. Firstly, an
increase in the underwater pressure field due to centripetal effects, and
secondly a reduction in the pressure of airflow in the cavity neck near the
water surface. The non-dimensional pinch-off time of the deep seal shows a
robust 1/2 power-law dependence on the Froude number, but with a reducing
prefactor for increasing $\omega$. Our findings reveal that the effects of a
rotating background liquid on the water entry can be traced back to the subtle
differences in the initial stage splash and the near-surface cavity dynamics.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:15:02 GMT""}]","2021-02-10"
"2012.06827","Jae Kyu Choi","Jian-Feng Cai, Jae Kyu Choi, Jingyang Li, Ke Wei","Image Restoration: Structured Low Rank Matrix Framework for Piecewise
  Smooth Functions and Beyond",,,,,"math.NA cs.NA","http://creativecommons.org/publicdomain/zero/1.0/","  Recently, mapping a signal/image into a low rank Hankel/Toeplitz matrix has
become an emerging alternative to the traditional sparse regularization, due to
its ability to alleviate the basis mismatch between the true support in the
continuous domain and the discrete grid. In this paper, we introduce a novel
structured low rank matrix framework to restore piecewise smooth functions.
Inspired by the total generalized variation to use sparse higher order
derivatives, we derive that the Fourier samples of higher order derivatives
satisfy an annihilation relation, resulting in a low rank multi-fold Hankel
matrix. We further observe that the SVD of a low rank Hankel matrix corresponds
to a tight wavelet frame system which can represent the image with sparse
coefficients. Based on this observation, we also propose a wavelet frame
analysis approach based continuous domain regularization model for the
piecewise smooth image restoration. Finally, numerical results on image
restoration tasks are presented as a proof-of-concept study to demonstrate that
the proposed approach is compared favorably against several popular discrete
regularization approaches and structured low rank matrix approaches.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:18:35 GMT""}]","2020-12-15"
"2012.06828","Ioannis Dimitriou","Ioannis Dimitriou","On partially homogeneous nearest-neighbour random walks in the quarter
  plane and their application in the analysis of two-dimensional queues with
  limited state-dependency",,,,,"math.PR cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work deals with the stationary analysis of two-dimensional partially
homogeneous nearest-neighbour random walks. Such type of random walks are
characterized by the fact that the one-step transition probabilities are
functions of the state-space. We show that its stationary behaviour is
investigated by solving a finite system of linear equations, two matrix
functional equations, and a functional equation with the aid of the theory of
Riemann (-Hilbert) boundary value problems. This work is strongly motivated by
emerging applications in flow level performance of wireless networks that give
rise in queueing models with scalable service capacity, as well as in
queue-based random access protocols, where the network's parameters are
functions of the queue lengths. A simple numerical illustration, along with
some details on the numerical implementation are also presented.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:25:52 GMT""},{""version"":""v2"",""created"":""Thu, 25 Mar 2021 17:01:18 GMT""}]","2021-03-26"
"2012.06829","Molla Ahamed","Molla Basir Ahamed, Vasudevarao Allu, and Himadri Halder","Bohr radius for certain close-to-convex harmonic mappings","26 pages, 21 figures",,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  Let $ \mathcal{H} $ be the class of harmonic functions $ f=h+\bar{g} $ in the
unit disk $\mathbb{D}:=\{z\in\mathbb{C} : |z|<1\}$, where $ h $ and $ g $ are
analytic in $ \mathbb{D} $. Let
  $$\mathcal{P}_{\mathcal{H}}^{0}(\alpha)=\{f=h+\overline{g} \in \mathcal{H} :
\real (h^{\prime}(z)-\alpha)>|g^{\prime}(z)|\; \mbox{with}\; 0\leq\alpha<1,\;
g^{\prime}(0)=0,\; z \in \mathbb{D}\}
  $$ be the class of close-to-convex mappings defined by Li and Ponnusamy
\cite{Injectivity section}. In this paper, we obtain the sharp Bohr-Rogosinski
radius, improved Bohr radius and refined Bohr radius for the class $
\mathcal{P}_{\mathcal{H}}^{0}(\alpha) $.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:26:07 GMT""}]","2020-12-15"
"2012.06830","Jingxin Zhang","Jingxin Zhang, Hao Chen, Songhang Chen, and Xia Hong","An improved mixture of probabilistic PCA for nonlinear data-driven
  process monitoring",,"IEEE Transactions on Cybernetics, 2019, 49(1):198-210","10.1109/TCYB.2017.2771229",,"stat.ME cs.LG","http://creativecommons.org/licenses/by/4.0/","  An improved mixture of probabilistic principal component analysis (PPCA) has
been introduced for nonlinear data-driven process monitoring in this paper. To
realize this purpose, the technique of a mixture of probabilistic principal
component analysers is utilized to establish the model of the underlying
nonlinear process with local PPCA models, where a novel composite monitoring
statistic is proposed based on the integration of two monitoring statistics in
modified PPCA-based fault detection approach. Besides, the weighted mean of the
monitoring statistics aforementioned is utilised as a metrics to detect
potential abnormalities. The virtues of the proposed algorithm have been
discussed in comparison with several unsupervised algorithms. Finally,
Tennessee Eastman process and an autosuspension model are employed to
demonstrate the effectiveness of the proposed scheme further.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:29:07 GMT""}]","2020-12-15"
"2012.06831","Samuel S\'anchez L\'opez","Konstantinos Dimopoulos and Samuel S\'anchez L\'opez","Quintessential inflation in Palatini $f(R)$ gravity",,"Phys. Rev. D 103, 043533 (2021)","10.1103/PhysRevD.103.043533",,"gr-qc astro-ph.CO hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We investigate in detail a family of quintessential inflation models in the
context of $R+R^2$ Palatini modified gravity. We find that successful inflation
and quintessence are obtained with an inflaton scalar potential that is
approximately quadratic in inflation and inverse quartic in quintessence. We
show that corrections for the kination period due to Palatini modified gravity
are subdominant, while the setup does not challenge constraints on modified
gravity from solar system observations and microscopic experiments, in contrast
to the metric case. We obtain concrete predictions regarding primordial
tensors, to be probed in the near future.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:43:12 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 12:35:55 GMT""},{""version"":""v3"",""created"":""Thu, 25 Feb 2021 18:52:41 GMT""}]","2021-02-26"
"2012.06832","Tielei Zhu","Tielei Zhu and Jiaqing Yang","A non-iterative sampling method for inverse elastic wave scattering by
  rough surfaces","19 pages, 13 figures",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider the two-dimensional inverse elastic wave scattering by an infinite
rough surface with a Dirichlet boundary condition. A non-interative sampling
technique is proposed for detecting the rough surface by taking elastic wave
measurements on a bounded line segment above the surface, based on
reconstructing a modified near-field equation associated with a special
surface, which generalized our pervious work for the Helmholtz equation (SIAM
J. IMAGING. SCI. 10(3)(2017), 1579-1602) to the Navier equation. Several
numerical examples are carried out to illustrate the effectiveness of the
inversion algorithm.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:54:35 GMT""}]","2020-12-15"
"2012.06833","Oleksandra Ivanova","G.I. Kokhirova, O.V. Ivanova, F. Dzh. Rakhmatullaeva, A.M. Buriev,
  U.Kh. Khamroev","Astrometric and photometric observations of comet
  29P/Schwassmann--Wachmann 1 at the Sanglokh international astronomical
  observatory","7 pages, 5 figures",,"10.1016/j.pss.2019.104794",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Astrometric and photometric observations of the comet
29P/Schwassmann-Wachmann 1 were performed at the Zeiss-1000 telescope of the
International Astronomical Observatory Sanglokh (IAOS) of the Institute of
Astrophysics, Academy of Sciences of the Republic of Tajikistan in July and
August 2017. Although the comet has a short period of revolution it is regarded
to be an object of the Centaurs group. Comet was exhibited a new activity this
period which we used for analysis of its features. The coordinates of comet
were determined and the orbit was calculated, the apparent and absolute
magnitudes in BVRI bands were determined, as well the comet color indices and
the estimation of nucleus diameter were obtained.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 14:59:27 GMT""}]","2020-12-15"
"2012.06834","Duc Van Le","Duc Van Le, Rongrong Wang, Yingbo Liu, Rui Tan, Yew-Wah Wong and
  Yonggang Wen","Deep Reinforcement Learning for Tropical Air Free-Cooled Data Center
  Control",,"ACM Transactions on Sensor Networks, Special Issue on
  Computational Intelligence in Internet of Things, 2021",,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Air free-cooled data centers (DCs) have not existed in the tropical zone due
to the unique challenges of year-round high ambient temperature and relative
humidity (RH). The increasing availability of servers that can tolerate higher
temperatures and RH due to the regulatory bodies' prompts to raise DC
temperature setpoints sheds light upon the feasibility of air free-cooled DCs
in tropics. However, due to the complex psychrometric dynamics, operating the
air free-cooled DC in tropics generally requires adaptive control of supply air
condition to maintain the computing performance and reliability of the servers.
This paper studies the problem of controlling the supply air temperature and RH
in a free-cooled tropical DC below certain thresholds. To achieve the goal, we
formulate the control problem as Markov decision processes and apply deep
reinforcement learning (DRL) to learn the control policy that minimizes the
cooling energy while satisfying the requirements on the supply air temperature
and RH. We also develop a constrained DRL solution for performance
improvements. Extensive evaluation based on real data traces collected from an
air free-cooled testbed and comparisons among the unconstrained and constrained
DRL approaches as well as two other baseline approaches show the superior
performance of our proposed solutions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:09:07 GMT""}]","2020-12-15"
"2012.06835","Sayantani Lahiri","Sayantani Lahiri, Sergio Gimeno-Soler, Jos\'e A. Font, and Alejandro
  Mus Mej\'ias","Stationary models of magnetized viscous tori around a Schwarzschild
  black hole","14 pages, 7 figures, some comments and references are added, version
  accepted for publication in PRD","Phys. Rev. D 103, 044034 (2021)","10.1103/PhysRevD.103.044034",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present stationary solutions of magnetized, viscous thick accretion disks
around a Schwarzschild black hole. We assume that the tori are not
self-gravitating, are endowed with a toroidal magnetic field, and obey a
constant angular momentum law. Our study focuses on the role of the black hole
curvature in the shear viscosity tensor and in their potential combined effect
on the stationary solutions. Those are built in the framework of a
causality-preserving, second-order gradient expansion scheme of relativistic
hydrodynamics in the Eckart frame description which gives rise to hyperbolic
equations of motion. The stationary models are constructed by numerically
solving the general relativistic momentum conservation equation using the
method of characteristics. We place constraints in the range of validity of the
second-order transport coefficients of the theory. Our results reveal that the
effects of the shear viscosity and curvature are particularly noticeable only
close to the cusp of the disks. The surfaces of constant pressure are affected
by viscosity and curvature and the self-intersecting isocontour - the cusp -
moves to smaller radii (i.e. towards the black hole horizon) as the effects
become more significant. For highly magnetized disks the shift in the cusp
location is smaller. Our findings might have implications on the dynamical
stability of constant angular momentum tori which, in the inviscid case, are
affected by the runaway instability.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:10:56 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 23:02:51 GMT""},{""version"":""v3"",""created"":""Tue, 19 Jan 2021 17:27:00 GMT""}]","2021-02-24"
"2012.06836","Francesco Barchi","Emanuele Parisi, Francesco Barchi, Andrea Bartolini, Giuseppe
  Tagliavini, Andrea Acquaviva","Source Code Classification for Energy Efficiency in Parallel Ultra
  Low-Power Microcontrollers",,,,,"cs.LG cs.CL","http://creativecommons.org/licenses/by/4.0/","  The analysis of source code through machine learning techniques is an
increasingly explored research topic aiming at increasing smartness in the
software toolchain to exploit modern architectures in the best possible way. In
the case of low-power, parallel embedded architectures, this means finding the
configuration, for instance in terms of the number of cores, leading to minimum
energy consumption. Depending on the kernel to be executed, the energy optimal
scaling configuration is not trivial. While recent work has focused on
general-purpose systems to learn and predict the best execution target in terms
of the execution time of a snippet of code or kernel (e.g. offload OpenCL
kernel on multicore CPU or GPU), in this work we focus on static compile-time
features to assess if they can be successfully used to predict the minimum
energy configuration on PULP, an ultra-low-power architecture featuring an
on-chip cluster of RISC-V processors. Experiments show that using machine
learning models on the source code to select the best energy scaling
configuration automatically is viable and has the potential to be used in the
context of automatic system configuration for energy minimisation.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:12:03 GMT""}]","2020-12-15"
"2012.06837","Ali Frotanpour","Ali Frotanpour, Justin Woods, Barry Farmer, Amrit P. Kaphle, Lance E.
  De Long, Loris Giovannini and Federico Montoncello","Magnetization Dynamics of Fibonacci-Distorted Kagome Artificial Spin Ice",,"Phys. Rev. B 102, 224435 (2020)","10.1103/PhysRevB.102.224435",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We present results of ferromagnetic resonance (FMR) experiments and
micromagnetic simulations for a distorted, 2D Kagome artificial spin ice. The
distorted structure is created by continuously modulating the 2D primitive
lattice translation vectors of a periodic honeycomb lattice, according to an
aperiodic Fibonacci sequence used to generate 1D quasicrystals. Experimental
data and micromagnetic simulations show the Fibonacci distortion causes
broadening and splitting of FMR modes into multiple branches, which accompany
the increasing number of segment lengths and orientations that develop with
increasing distortion. When the applied field is increased in the opposite
direction to the net magnetization of a segment, spin wave modes appear,
disappear or suddenly shift, to signal segment magnetization reversal events.
These results show the complex behavior of reversal events, as well as
well-defined frequencies and frequency-field slopes of FMR modes, can be
precisely tuned by varying the severity of the aperiodic lattice distortion.
This type of distorted structure could therefore provide a new tool for the
design of complicated magnonic systems.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:12:51 GMT""}]","2021-01-04"
"2012.06838","Almabrok Essa","Almabrok Essa and Vijayan Asari","High Order Local Directional Pattern Based Pyramidal Multi-structure for
  Robust Face Recognition","9 pages, 10 figures",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Derived from a general definition of texture in a local neighborhood, local
directional pattern (LDP) encodes the directional information in the small
local 3x3 neighborhood of a pixel, which may fail to extract detailed
information especially during changes in the input image due to illumination
variations. Therefore, in this paper we introduce a novel feature extraction
technique that calculates the nth order direction variation patterns, named
high order local directional pattern (HOLDP). The proposed HOLDP can capture
more detailed discriminative information than the conventional LDP. Unlike the
LDP operator, our proposed technique extracts nth order local information by
encoding various distinctive spatial relationships from each neighborhood layer
of a pixel in the pyramidal multi-structure way. Then we concatenate the
feature vector of each neighborhood layer to form the final HOLDP feature
vector. The performance evaluation of the proposed HOLDP algorithm is conducted
on several publicly available face databases and observed the superiority of
HOLDP under extreme illumination conditions.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:13:07 GMT""}]","2020-12-15"
"2012.06839","Lisa Mickel","Mehdi Assanioussi and Lisa Mickel","Loop effective model for Schwarzschild black hole interior: a modified
  $\bar \mu$ dynamics","25 pages, 6 figures; v2: journal version, calculations in sec. III A
  extended to a more general form of $\bar \mu$, minor comments and references
  added","Phys. Rev. D 103, 124008 (2021)","10.1103/PhysRevD.103.124008",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  In this article, we introduce a new effective model for the Kantowski-Sachs
spacetime in the context of loop quantum gravity, and we use it to evaluate
departures from general relativity in the case of Schwarzschild black hole
interior. The model is based on an effective Hamiltonian constructed via the
regularized Thiemann identities in the $\bar \mu$-scheme. We show that, in
contrast with the $\mu_o$-scheme studied in [1], the classical limit imposes
certain alterations of Thiemann identities as well as restrictions on the
choice of regulators. Once we define the Hamiltonian, we derive the equations
of motion for the relevant variables and proceed with the solving using
numerical methods, focusing on a specific choice of $\bar \mu$. We establish
that for a Schwarzschild black hole interior, the effective dynamics leads to a
resolution of the classical singularity and the emergence of an anti-trapped
region bounded by a second Killing horizon. We then perform a comparison of the
dynamical trajectories and their properties obtained in the new model and some
models present in the literature. We finally conclude with few comments on
other choices of the regulators and their consequences.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:19:01 GMT""},{""version"":""v2"",""created"":""Fri, 18 Jun 2021 13:28:24 GMT""}]","2021-06-21"
"2012.06840","Jeffrey Shallit","Luke Schaeffer and Jeffrey Shallit","String Attractors for Automatic Sequences","revision adding significant new results due to Luke Schaeffer",,,,"cs.FL cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that it is decidable, given an automatic sequence $\bf s$ and a
constant $c$, whether all prefixes of $\bf s$ have a string attractor of size
$\leq c$. Using a decision procedure based on this result, we show that all
prefixes of the period-doubling sequence of length $\geq 2$ have a string
attractor of size $2$. We also prove analogous results for other sequences,
including the Thue-Morse sequence and the Tribonacci sequence.
  We also provide general upper and lower bounds on string attractor size for
different kinds of sequences. For example, if $\bf s$ has a finite appearance
constant, then there is a string attractor for ${\bf s}[0..n-1]$ of size
$O(\log n)$. If further $\bf s$ is linearly recurrent, then there is a string
attractor for ${\bf s}[0..n-1]$ of size $O(1)$. For automatic sequences, the
size of the smallest string attractor for ${\bf s}[0..n-1]$ is either
$\Theta(1)$ or $\Theta(\log n)$, and it is decidable which case occurs.
Finally, we close with some remarks about greedy string attractors.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:34:12 GMT""},{""version"":""v2"",""created"":""Wed, 23 Dec 2020 18:33:39 GMT""},{""version"":""v3"",""created"":""Thu, 24 Dec 2020 18:31:08 GMT""},{""version"":""v4"",""created"":""Sat, 26 Dec 2020 11:05:32 GMT""},{""version"":""v5"",""created"":""Thu, 7 Jan 2021 21:42:26 GMT""}]","2021-01-11"
"2012.06841","Christian Gaetz","Christian Gaetz and Yibo Gao","The hull metric on Coxeter groups","12 pages, comments welcome; v2: minor edits and updated references,
  to appear in Combinatorial Theory","Combinatorial Theory 2 (2)(2022), #7","10.5070/C62257870",,"math.CO math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We reinterpret an inequality, due originally to Sidorenko, for linear
extensions of posets in terms of convex subsets of the symmetric group
$\mathfrak{S}_n$. We conjecture that the analogous inequalities hold in
arbitrary (not-necessarily-finite) Coxeter groups $W$, and prove this for the
hyperoctahedral groups $B_n$ and all right-angled Coxeter groups. Our proof for
$B_n$ (and new proof for $\mathfrak{S}_n$) use a combinatorial insertion map
closely related to the well-studied promotion operator on linear extensions;
this map may be of independent interest. We also note that the inequalities in
question can be interpreted as a triangle inequalities, so that convex hulls
can be used to define a new invariant metric on $W$ whenever our conjecture
holds. Geometric properties of this metric are an interesting direction for
future research.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:36:56 GMT""},{""version"":""v2"",""created"":""Thu, 12 May 2022 18:49:07 GMT""}]","2022-11-02"
"2012.06842","Sourav Pal","Neelima Agarwal, Ayan Mukhopadhyay, Sourav Pal, Anurag Tripathi","Power corrections to event shapes using eikonal dressed gluon
  exponentiation","13 pages, 1 figure, one section added, conclusions remain unchanged,
  matches published version",,"10.1007/JHEP03(2021)155",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Event shapes are classical tools for the determination of the strong coupling
and for the study of hadronization effects in electron-positron annihilation.
In the context of analytical studies, hadronization corrections take the form
of power-suppressed contributions to the cross-section, which can be extracted
from the perturbative ambiguity of Borel-resummed distributions. We propose a
simplified version of the well-established method of Dressed Gluon
Exponentiation (DGE), which we call Eikonal DGE (EDGE), which determines all
dominant power corrections to event shapes by means of strikingly elementary
calculations. We believe our method can be generalized to hadronic event shapes
and jet shapes of relevance for LHC physics.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:37:32 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 09:10:38 GMT""}]","2021-06-22"
"2012.06843","Can Zhang","Can Zhang, Hong Liu, Wei Guo, Mang Ye","Multi-Scale Cascading Network with Compact Feature Learning for
  RGB-Infrared Person Re-Identification","8 pages, 5 figures, ICPR2020 conference",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  RGB-Infrared person re-identification (RGB-IR Re-ID) aims to match persons
from heterogeneous images captured by visible and thermal cameras, which is of
great significance in the surveillance system under poor light conditions.
Facing great challenges in complex variances including conventional
single-modality and additional inter-modality discrepancies, most of the
existing RGB-IR Re-ID methods propose to impose constraints in image level,
feature level or a hybrid of both. Despite the better performance of hybrid
constraints, they are usually implemented with heavy network architecture. As a
matter of fact, previous efforts contribute more as pioneering works in new
cross-modal Re-ID area while leaving large space for improvement. This can be
mainly attributed to: (1) lack of abundant person image pairs from different
modalities for training, and (2) scarcity of salient modality-invariant
features especially on coarse representations for effective matching. To
address these issues, a novel Multi-Scale Part-Aware Cascading framework
(MSPAC) is formulated by aggregating multi-scale fine-grained features from
part to global in a cascading manner, which results in a unified representation
containing rich and enhanced semantic features. Furthermore, a marginal
exponential centre (MeCen) loss is introduced to jointly eliminate mixed
variances from intra- and inter-modal examples. Cross-modality correlations can
thus be efficiently explored on salient features for distinctive
modality-invariant feature learning. Extensive experiments are conducted to
demonstrate that the proposed method outperforms all the state-of-the-art by a
large margin.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:39:11 GMT""}]","2020-12-15"
"2012.06844","Aude Simon Dr","J. Douady and A. Simon and M. Rapacioli and F. Calvo and E. Yurtsever
  and A. Tekin","The structure of 1,3-butadiene clusters","20 pages, 8 figures, 2 tables",,,,"physics.chem-ph","http://creativecommons.org/licenses/by-sa/4.0/","  Molecular clusters of 1,3-butadiene were theoretically investigated using a
variety of approaches, encompassing classical force fields and different
quantum chemical (QC) methods, as well as density-functional based
tight-binding (DFTB) in its self-consistent-charge (SCC) version. Upon suitable
reparametrization, SCC-DFTB reproduces the energy difference and torsional
barrier of the trans and gauche conformers of the 1,3-butadiene monomer
predicted at the QC level. Clusters of pure trans and gauche conformers
containing up to 20 monomers were studied separately, their energy landscapes
being explored using the force fields, then locally reoptimized using DFT or
SCC-DFTB. The all-trans clusters are generally found to be lower in energy and
produce well-ordered structures in which the planar molecules are arranged
according to a herringbone motif. Clusters of molecules in the gauche
configuration are comparatively much more isotropic. Mixed clusters containing
a single gauche molecule were also studied and found to keep the herringbone
motif, the gauche impurity usually residing outside. In those clusters, the
strain exerted by the cluster on the gauche molecule leads to significant
geometrical distortion of the dihedral angle already at zero temperature.
Finally, the finite temperature properties were addressed at the force field
level, and the results indicate that the more ordered all-trans clusters are
also prone to sharper melting mechanisms.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:53:06 GMT""}]","2020-12-15"
"2012.06845","Yifan Xu","Yifan Xu, Pan Xu, Jianping Pan and Jun Tao","A Unified Model for the Two-stage Offline-then-Online Resource
  Allocation","Accepted by IJCAI 2020
  (http://static.ijcai.org/2020-accepted_papers.html) and SOLE copyright holder
  is IJCAI (International Joint Conferences on Artificial Intelligence), all
  rights reserved","IJCAI 2020","10.24963/ijcai.2020/581",,"cs.AI cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the popularity of the Internet, traditional offline resource allocation
has evolved into a new form, called online resource allocation. It features the
online arrivals of agents in the system and the real-time decision-making
requirement upon the arrival of each online agent. Both offline and online
resource allocation have wide applications in various real-world matching
markets ranging from ridesharing to crowdsourcing. There are some emerging
applications such as rebalancing in bike sharing and trip-vehicle dispatching
in ridesharing, which involve a two-stage resource allocation process. The
process consists of an offline phase and another sequential online phase, and
both phases compete for the same set of resources. In this paper, we propose a
unified model which incorporates both offline and online resource allocation
into a single framework. Our model assumes non-uniform and known arrival
distributions for online agents in the second online phase, which can be
learned from historical data. We propose a parameterized linear programming
(LP)-based algorithm, which is shown to be at most a constant factor of $1/4$
from the optimal. Experimental results on the real dataset show that our
LP-based approaches outperform the LP-agnostic heuristics in terms of
robustness and effectiveness.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:55:13 GMT""}]","2020-12-17"
"2012.06846","Alessio Benavoli","Alessio Benavoli and Dario Azzimonti and Dario Piga","A unified framework for closed-form nonparametric regression,
  classification, preference and mixed problems with Skew Gaussian Processes",,,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Skew-Gaussian processes (SkewGPs) extend the multivariate Unified Skew-Normal
distributions over finite dimensional vectors to distribution over functions.
SkewGPs are more general and flexible than Gaussian processes, as SkewGPs may
also represent asymmetric distributions. In a recent contribution we showed
that SkewGP and probit likelihood are conjugate, which allows us to compute the
exact posterior for non-parametric binary classification and preference
learning. In this paper, we generalize previous results and we prove that
SkewGP is conjugate with both the normal and affine probit likelihood, and more
in general, with their product. This allows us to (i) handle classification,
preference, numeric and ordinal regression, and mixed problems in a unified
framework; (ii) derive closed-form expression for the corresponding posterior
distributions. We show empirically that the proposed framework based on SkewGP
provides better performance than Gaussian processes in active learning and
Bayesian (constrained) optimization. These two tasks are fundamental for design
of experiments and in Data Science.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 15:58:16 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 10:47:59 GMT""}]","2021-01-28"
"2012.07566","Julie Rowlett","Julie Rowlett","The level sets of typical games","This is the author original manuscript. The final version is
  published in Notices of the American Mathematical Society","Notices of the AMS, 61, no. 8, (2014), 840-847",,,"math.HO cs.GT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a non-cooperative game, players do not communicate with each other. Their
only feedback is the payoff they receive resulting from the strategies they
execute. It is important to note that within each level set of the total payoff
function the payoff to each player is unchanging, and therefore understanding
the structure of these level sets plays a key role in understanding
non-cooperative games. This note, intended for both experts and non-experts,
not only introduces non-cooperative game theory but also shows its fundamental
connection to real algebraic geometry. We prove here a general result about the
structure of the level sets, which although likely to be known by experts, has
interesting implications, including our recent application to provide a new
mathematical explanation for the ""paradox of the plankton."" We hope to
encourage communication between these interrelated areas and stimulate further
work in similar directions.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:10:06 GMT""}]","2020-12-15"
"2012.07585","Huachuan Wang","Huachuan Wang and Yuanfei Bi","Building Deep Learning Models to Predict Mortality in ICU Patients",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Mortality prediction in intensive care units is considered one of the
critical steps for efficiently treating patients in serious condition. As a
result, various prediction models have been developed to address this problem
based on modern electronic healthcare records. However, it becomes increasingly
challenging to model such tasks as time series variables because some
laboratory test results such as heart rate and blood pressure are sampled with
inconsistent time frequencies. In this paper, we propose several deep learning
models using the same features as the SAPS II score. To derive insight into the
proposed model performance. Several experiments have been conducted based on
the well known clinical dataset Medical Information Mart for Intensive Care
III. The prediction results demonstrate the proposed model's capability in
terms of precision, recall, F1 score, and area under the receiver operating
characteristic curve.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:27:04 GMT""}]","2020-12-15"
"2012.07611","Jingjun Zhu","JingJun Zhu and Xi Chen","Fast-forward scaling of atom-molecule conversion in Bose-Einstein
  condensates",,"Phys. Rev. A 103, 023307 (2021)","10.1103/PhysRevA.103.023307",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robust stimulated Raman exact passages are requisite for controlling
nonlinear quantum systems, with the wide applications ranging from ultracold
molecules, non-linear optics to superchemistry. Inspired by shortcuts to
adiabaticity, we propose the fast-forward scaling of stimulated Raman adiabatic
processes with the nonlinearity involved, describing the transfer from an
atomic Bose-Einstein condensate to a molecular one by controllable external
fields. The fidelity and robustness of atom-molecule conversion are shown to
surpass those of conventional adiabatic passages, assisted by fast-forward
driving field. Finally, our results are extended to the fractional stimulated
Raman adiabatic processes for the coherent superposition of atomic and
molecular states.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:21:48 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 14:28:13 GMT""}]","2021-02-16"
"2012.07621","Ximena Fern\'andez","Ximena Fern\'andez, Eugenio Borghini, Gabriel Mindlin, Pablo Groisman","Intrinsic persistent homology via density-based metric learning","37 pages. v3: major revision. Final version accepted for publication
  at Journal of Machine Learning Research",,,,"stat.ML cs.LG math.AT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of estimating topological features from data in high
dimensional Euclidean spaces under the manifold assumption. Our approach is
based on the computation of persistent homology of the space of data points
endowed with a sample metric known as Fermat distance. We prove that such
metric space converges almost surely to the manifold itself endowed with an
intrinsic metric that accounts for both the geometry of the manifold and the
density that produces the sample. This fact implies the convergence of the
associated persistence diagrams. The use of this intrinsic distance when
computing persistent homology presents advantageous properties such as
robustness to the presence of outliers in the input data and less sensitiveness
to the particular embedding of the underlying manifold in the ambient space. We
use these ideas to propose and implement a method for pattern recognition and
anomaly detection in time series, which is evaluated in applications to real
data.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:54:36 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 17:50:30 GMT""},{""version"":""v3"",""created"":""Fri, 20 Jan 2023 17:59:14 GMT""}]","2023-01-23"
"2012.07622","Nabeel Riza","Mohsin A. Mazhar and Nabeel A. Riza","CAOS Spectral Imager Design and Advanced High Dynamic Range FDMA-TDMA
  CAOS Mode","10 pages",,"10.1364/AO.417472",,"eess.IV physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the first part of the paper, a CAOS line camera is introduced for spectral
imaging of one dimensional (1-D) or line targets. The proposed spectral camera
uses both a diffraction grating as well as a cylindrical lens optics system to
provide line imaging along the line pixels direction of the image axis and
Fourier transforming operations in the orthogonal direction to provide line
pixels optical spectrum analysis. The imager incorporates the Digital
Micro-mirror Device (DMD)-based Coded Access Optical Sensor (CAOS) structure.
The design includes a line-by-line scan option to enable two dimensional (2-D)
spectral imaging. For the first time, demonstrated is line style spectral
imaging using a 2850 K color temperature white light target illumination source
along with visible band color bandpass filters and a moving mechanical pinhole
to simulate a line target with individual pixels along 1-D that have unique
spectral content. A ~412 nm to ~732 nm input target spectrum is measured using
a 38 by 52 CAOS pixels spatial sampling grid providing a test image line of 38
pixels with each pixel providing a designed spectral resolution of ~6.2 nm. The
spectral image is generated using the robust Code Division Multiple Access
(CDMA) mode of the camera. The second part of the paper demonstrates for the
first time the High Dynamic Range (HDR) operation of the Frequency Division
Multiple Access (FDMA)-Time Division Multiple Access (TDMA) mode of the CAOS
camera. The FDMA-TDMA mode also feature HDR recovery like the Frequency
Modulation (FM)-TDMA mode, although at a much faster imaging rate and a higher
Signal-to-Noise Ratio (SNR) as more than one CAOS pixel is extracted at a time.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:16:32 GMT""},{""version"":""v2"",""created"":""Sat, 20 Feb 2021 15:05:47 GMT""}]","2021-04-07"
"2012.07627","Thai-Bao Duong-Nguyen","Thai-Bao Duong-Nguyen, Thien-Nu Hoang, Phong Vo and Hoai-Bac Le","Water Level Estimation Using Sentinel-1 Synthetic Aperture Radar Imagery
  And Digital Elevation Models",,,,,"eess.IV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hydropower dams and reservoirs have been identified as the main factors
redefining natural hydrological cycles. Therefore, monitoring water status in
reservoirs plays a crucial role in planning and managing water resources, as
well as forecasting drought and flood. This task has been traditionally done by
installing sensor stations on the ground nearby water bodies, which has
multiple disadvantages in maintenance cost, accessibility, and global coverage.
And to cope with these problems, Remote Sensing, which is known as the science
of obtaining information about objects or areas without making contact with
them, has been actively studied for many applications. In this paper, we
propose a novel water level extracting approach, which employs Sentinel-1
Synthetic Aperture Radar imagery and Digital Elevation Model data sets.
Experiments show that the algorithm achieved a low average error of 0.93 meters
over three reservoirs globally, proving its potential to be widely applied and
furthermore studied.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:42:15 GMT""},{""version"":""v2"",""created"":""Mon, 28 Dec 2020 09:38:11 GMT""}]","2020-12-29"
"2012.07631","Andrey Chabanov","Rodion Kononchuk, Suwun Suwunnarat, Martin S. Hilario, Anthony E.
  Baros, Brad W. Hoff, Vladimir Vasilyev, Ilya Vitebskiy, Tsampikos Kottos,
  Andrey A. Chabanov","A reflective mm-wave photonic limiter","18 pages, 6 figures, 3 supplementary figures and 1 supplementary
  table","Sci. Adv. 8, eabh1827 (2022)","10.1126/sciadv.abh1827",,"physics.app-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Millimeter wave (mm-wave) communications and radar receivers capable of
processing small signals must be protected from high-power signals, which can
damage sensitive receiver components. Many of these systems arguably can be
protected by using photonic limiting techniques, in addition to electronic
limiting circuits in receiver front-ends. Here we demonstrate, experimentally
and numerically, a free-space, reflective mm-wave limiter based on a multilayer
structure involving a nanolayer of vanadium dioxide (VO2), experiencing a
thermal insulator-to-metal transition. The multilayer acts as a variable
reflector, controlled by the input power. At low input power levels, VO2
remains dielectric, and the multilayer exhibits resonant transmittance. When
the input power exceeds a threshold level, the emerging metallic phase renders
the multilayer highly reflective while dissipating a small portion of the input
power without damage to the limiter. In the case of a Gaussian beam, the
limiter has a nearly constant output above the limiting threshold input.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 17:17:26 GMT""}]","2023-06-02"
"2012.07741","Elaine Nsoesie","Adyasha Maharana, Morine Amutorine, Moinina David Sengeh, Elaine O.
  Nsoesie","Use of Technology and Innovations in the COVID-19 Pandemic Response in
  Africa","29 pages",,,,"cs.CY cs.SI","http://creativecommons.org/licenses/by/4.0/","  The use of technology has been ubiquitous in efforts to combat the ongoing
public health crisis due to emergence and spread of the SARS-CoV-2 virus.
African countries have made tremendous use of technology to disseminate
information, counter the spread of COVID-19, and develop cutting-edge
techniques to help with diagnosis, treatment and management of patients. The
nature and outcomes of these efforts sometimes differ in Africa compared to
other areas of the world due to its unique challenges and opportunities.
Several countries have developed innovative technology-driven solutions to
cater to a diverse population with varying access to technology. Much of the
efforts are also earmarked by a flexible approach to problem solving, local
tech entrepreneurship, and swift adoption of cutting-edge technology.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:59:13 GMT""}]","2020-12-15"
"2012.07832","Guillaume Lavigne","Guillaume Lavigne and Christophe Caloz","Generalized Brewster Effect using Bianisotropic Metasurfaces",,,"10.1364/OE.423078",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that a properly designed bianisotropic metasurface placed at the
interface between two arbitrary different media, or coating a dielectric medium
exposed to the air, provides Brewster (reflectionless) transmission at
arbitrary angles and for both the TM and TE polarizations. We present a
rigorous derivation of the corresponding surface susceptibility tensors based
on the Generalized Sheet Transition Conditions (GSTCs), and demonstrate the
system with planar microwave metasurfaces designed for polarization-independent
and azimuth-independent operations. Moreover, we reveal that such a system
leads to the concept of effective refractive media with engineerable impedance.
The proposed bianisotropic metasurfaces provide deeply subwavelength matching
solutions for initially mismatched media, and alternatively lead to the
possibility of on-demand manipulation of the conventional Fresnel coefficients.
The reported generalized Brewster effect represents a fundamental advance in
optical technology, where it may both improve the performance of conventional
components and enable the development of novel devices.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:32:49 GMT""}]","2021-04-07"
"2012.07833","Edward Haeusler","Edward Hermann Haeusler","Going from the huge to the small: Efficient succinct representation of
  proofs in Minimal implicational logic","Companion to arXiv:2009.09802v1. This versions explains better
  Lemma14. This Lemma now is Lemma16. Two new lemmas were introduced in the new
  version to help writing the better explanation on former Lemma14. Some reader
  asked a better explanation. I am grateful to prof. Lew Gordeev to have raised
  questions that help me to deliver this version",,,,"cs.CC cs.LO","http://creativecommons.org/licenses/by/4.0/","  A previous article shows that any linear height bounded normal proof of a
tautology in the Natural Deduction for Minimal implicational logic
$M_{\supset}$ is as huge as it is redundant. More precisely, any proof in a
family of super-polynomially sized and linearly height bounded proofs have a
sub-derivation that occurs super-polynomially many times in it. In this
article, we show that by collapsing all the repeated sub-derivations we obtain
a smaller structure, a rooted Directed Acyclic Graph (r-DAG), that is
polynomially upper-bounded on the size of $\alpha$ and it is a certificate that
$\alpha$ is a tautology that can be verified in polynomial time. In other
words, for every huge proof of a tautology in $M_{\supset}$, we obtain a
succinct certificate for its validity. Moreover, we show an algorithm able to
check this validity in polynomial time on the certificate's size. Comments on
how the results in this article are related to a proof of the conjecture
$NP=CoNP$ appears in conclusion.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 21:13:58 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 15:19:51 GMT""}]","2021-01-26"
"2012.07834","Mohammad Murshed","Mohammad N. Murshed, M. Monir Uddin","Towards an Adaptive Dynamic Mode Decomposition","15 pages. arXiv admin note: substantial text overlap with
  arXiv:2001.03332",,,,"eess.SP cs.LG cs.NA math.DS math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamic Mode Decomposition (DMD) is a data based modeling tool that
identifies a matrix to map a quantity at some time instant to the same quantity
in future. We design a new version which we call Adaptive Dynamic Mode
Decomposition (ADMD) that utilizes time delay coordinates, projection methods
and filters as per the nature of the data to create a model for the available
problem. Filters are very effective in reducing the rank of high-dimensional
dataset. We have incorporated 'discrete Fourier transform' and 'augmented
lagrangian multiplier' as filters in our method. The proposed ADMD is tested on
several datasets of varying complexities and its performance appears to be
promising.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:50:09 GMT""}]","2020-12-16"
"2012.08302","Matthew Mewes","Matthew Mewes","Nonminimal Lorentz Violation in Macroscopic Matter","27 pages","Symmetry 12, 2026 (2020)","10.3390/sym12122026",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The effects of Lorentz and CPT violations on macroscopic objects are
explored. Effective composite coefficients for Lorentz violation are derived in
terms of coefficients for electrons, protons, and neutrons in the
Standard-Model Extension, including all minimal and nonminimal violations. The
hamiltonian and modified Newton's second law for a test body are derived. The
framework is applied to free-fall and torsion-balance tests of the weak
equivalence principle and to orbital motion. The effects on continuous media
are studied, and the frequency shifts in acoustic resonators are calculated.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 00:07:21 GMT""}]","2020-12-16"
"2012.08305","Ross Greenwood","Ross N. Greenwood","On Computable Geometric Expressions in Quantum Theory","This is a pre-print of an article published in Advances in Applied
  Clifford Algebras. The final authenticated version is available online at:
  https://doi.org/10.1007/s00006-019-1031-7","Adv. Appl. Clifford Algebras 30, 7 (2020)","10.1007/s00006-019-1031-7",,"quant-ph hep-th math-ph math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Geometric Algebra and Calculus are mathematical languages encoding
fundamental geometric relations that theories of physics seem to respect. We
propose criteria given which statistics of expressions in geometric algebra are
computable in quantum theory, in such a way that preserves their algebraic
properties. They are that one must be able to arbitrarily transform the basis
of the Clifford algebra, via multiplication by elements of the algebra that act
trivially on the state space; all such elements must be neighbored by operators
corresponding to factors in the original expression and not the state vectors.
We explore the consequences of these criteria for a physics of dynamical
multivector fields.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:07:57 GMT""}]","2020-12-16"
"2012.08321","Li Yang","Hui Liu, Li Yang","Quantum Key Recovery Attack on SIMON Block Cipher",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quantum security of lightweight block ciphers is receiving more and more
attention. However, the existing quantum attacks on lightweight block ciphers
mainly focused on the quantum exhaustive search, while the quantum dedicated
attacks combined with classical cryptanalysis methods haven't been well
studied. In this paper, we study quantum key recovery attack on SIMON block
cipher using Quantum Amplitude Amplification algorithm in Q1 model. At first,
we reanalyze the quantum circuit complexity of quantum master key exhaustive
search on SIMON block cipher. The Clifford gates count is estimated more
accurately and the T gate count is reduced. We also reduce the T-depth and
Full-depth due to some minor modifications to the circuit. Then, based on the
differential cryptanalysis on SIMON32, SIMON48 and SIMON64 given by Biryukov et
al. in FSE 2014, we give quantum round key recovery attacks on these SIMON
variants and analyze quantum circuit complexity separately. We take the quantum
attack on 19-round SIMON32/64 for an example and design the quantum circuit of
the key recovery process. The two phases of this attack could be regarded as
two QAA instances separately, and the first QAA instance consists of four
sub-QAA instances. We conclude that the encryption complexity and circuit
complexity of quantum dedicated attacks on 19-round SIMON32/64, 19-round SIMON
48 and 26-round SIMON64/128 are both lower than those of the quantum exhaustive
search on these variants separately. Our work firstly studies the quantum
dedicated attack on SIMON block cipher from the perspective of quantum circuit
complexity, which is a more fine-grained analysis of quantum dedicated attacks'
complexity.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 02:15:47 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 11:03:06 GMT""}]","2021-06-03"
"2012.08322","W. A. Rojas C. Mr.","W. A. Rojas C. and J. R. Arenas S","A Conceptual Model for the Origin of the Cutoff Parameter in Exotic
  Compact Objects","11 pages, 3 figures",,"10.1134/S0202289321020122",,"gr-qc","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A Black Hole (BH) is a spacetime region with a horizon and where geodesics
converge to a singularity. At such a point, the gravitational field equations
fail. As an alternative to the problem of the singularity arises the existence
of Exotic Compact Objects (ECOs) that prevent the problem of the singularity
through a transition phase of matter once it has crossed the horizon. ECOs are
characterized by a closeness parameter or cutoff, $\epsilon$, which measures
the degree of compactness of the object. This parameter is established as the
difference between the radius of the ECO's surface and the gravitational
radius. Thus, different values of $\epsilon$ correspond to different types of
ECOs. If $\epsilon$ is very big, the ECO behaves more like a star than a black
hole. On the contrary, if $\epsilon$ tends to a very small value, the ECO
behaves like a black hole. It is considered a conceptual model of the origin of
the cutoff for ECOs, when a dust shell contracts gravitationally from an
initial position to near the Schwarzschild radius. This allowed us to find that
the cutoff makes two types of contributions: a classical one governed by
General Relativity and one of a quantum nature, if the ECO is very close to the
horizon, when estimating that the maximum entropy is contained within the
material that composes the shell. Such entropy coincides with the
Bekenstein--Hawking entropy. The established cutoff corresponds to a dynamic
quantity dependent on coordinate time that is measured by a Fiducial Observer
(FIDO). Without knowing the details about quantum gravity, parameter $\epsilon$
is calculated, which, in general, allows distinguishing the ECOs from BHs.
Specifically, a black shell (ECO) is undistinguishable from a BH.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 22:48:33 GMT""}]","2021-07-07"
"2012.08327","Raban Iten","Raban Iten","Relations between different quantum R\'enyi divergences","33 pages + 12 pages appendix. This Master thesis has some overlap
  with the paper that resulted from this works (arXiv:1608.08229)",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum generalizations of R\'enyi's entropies are a useful tool to describe
a variety of operational tasks in quantum information processing. Two families
of such generalizations turn out to be particularly useful: the Petz quantum
R\'enyi divergence $\bar{D}_{\alpha}$ and the minimal quantum R\'enyi
divergence $\widetilde{D}_{\alpha}$. Moreover, the maximum quantum R\'enyi
divergence $\widehat{D}_{\alpha}$ is of particular mathematical interest. In
this Master thesis, we investigate relations between these divergences and
their applications in quantum information theory. Our main result is a reverse
Araki-Lieb-Thirring inequality that implies a new relation between the minimal
and the Petz divergence, namely that $\alpha \bar{D}_{\alpha}(\rho \| \sigma)
\leqslant \widetilde{D}_{\alpha}(\rho \| \sigma)$ for $\alpha \in [0,1]$ and
where $\rho$ and $\sigma$ are density operators. This bound suggests defining a
""pretty good fidelity"", whose relation to the usual fidelity implies the known
relations between the optimal and pretty good measurement as well as the
optimal and pretty good singlet fraction. In addition, we provide a new proof
of the inequality $\widetilde{D}_{1}(\rho \| \sigma) \leqslant
\widehat{D}_{1}(\rho \| \sigma)\, ,$ based on the Araki-Lieb-Thirring
inequality. This leads to an elegant proof of the logarithmic form of the
reverse Golden-Thompson inequality.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:30:07 GMT""}]","2020-12-16"
"2012.08333","Weronika Hryniewska","Weronika Hryniewska, Przemys{\l}aw Bombi\'nski, Patryk Szatkowski,
  Paulina Tomaszewska, Artur Przelaskowski, Przemys{\l}aw Biecek","Checklist for responsible deep learning modeling of medical images based
  on COVID-19 detection studies",,"Pattern Recognition 118 (2021) 108035","10.1016/j.patcog.2021.108035","2021","eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The sudden outbreak and uncontrolled spread of COVID-19 disease is one of the
most important global problems today. In a short period of time, it has led to
the development of many deep neural network models for COVID-19 detection with
modules for explainability. In this work, we carry out a systematic analysis of
various aspects of proposed models. Our analysis revealed numerous mistakes
made at different stages of data acquisition, model development, and
explanation construction. In this work, we overview the approaches proposed in
the surveyed Machine Learning articles and indicate typical errors emerging
from the lack of deep understanding of the radiography domain. We present the
perspective of both: experts in the field - radiologists and deep learning
engineers dealing with model explanations. The final result is a proposed
checklist with the minimum conditions to be met by a reliable COVID-19
diagnostic model.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 18:42:46 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 10:20:16 GMT""},{""version"":""v3"",""created"":""Fri, 23 Apr 2021 23:00:13 GMT""}]","2021-08-09"
"2012.08975","Glynn Dennis Jr","Arvind Pillai, Halsey Lea, Faisal Khan, Glynn Dennis","Personalized Step Counting Using Wearable Sensors: A Domain Adapted LSTM
  Network Approach","5 Pages, 1 Figure, 1 Table, Accepted for proceedings in PharML-2020",,,,"cs.LG eess.SP","http://creativecommons.org/licenses/by/4.0/","  Activity monitors are widely used to measure various physical activities (PA)
as an indicator of mobility, fitness and general health. Similarly, real-time
monitoring of longitudinal trends in step count has significant clinical
potential as a personalized measure of disease related changes in daily
activity. However, inconsistent step count accuracy across vendors, body
locations, and individual gait differences limits clinical utility. The
tri-axial accelerometer inside PA monitors can be exploited to improve step
count accuracy across devices and individuals. In this study, we hypothesize:
(1) raw tri-axial sensor data can be modeled to create reliable and accurate
step count, and (2) a generalized step count model can then be efficiently
adapted to each unique gait pattern using very little new data. Firstly,
open-source raw sensor data was used to construct a long short term memory
(LSTM) deep neural network to model step count. Then we generated a new, fully
independent data set using a different device and different subjects. Finally,
a small amount of subject-specific data was domain adapted to produce
personalized models with high individualized step count accuracy. These results
suggest models trained using large freely available datasets can be adapted to
patient populations where large historical data sets are rare.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:52:43 GMT""}]","2020-12-17"
"2012.09112","C\'edric Goeury","Cedric Goeury, Yoann Audouin and Fabrice Zaoui","Interoperability and computational framework for simulating open channel
  hydraulics: application to sensitivity analysis and calibration of Gironde
  Estuary model",,"Environmental Modelling and Software 2021","10.1016/j.envsoft.2021.105243",,"cs.CE physics.data-an stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Water resource management is of crucial societal and economic importance,
requiring a strong capacity for anticipating environmental change. Progress in
physical process knowledge, numerical methods and computational power, allows
us to address hydro-environmental problems of growing complexity. Modeling of
river and marine flows is no exception. With the increase in IT resources,
environmental modeling is evolving to meet the challenges of complex real-world
problems. This paper presents a new distributed Application Programming
Interface (API) of the open source TELEMAC-MASCARET system to run
hydro-environmental simulations with the help of the interoperability concept.
Use of the API encourages and facilitates the combination of worldwide
reference environmental libraries with the hydro-informatic system.
Consequently, the objective of the paper is to promote the interoperability
concept for studies dealing with such issues as uncertainty propagation, global
sensitivity analysis, optimization, multi-physics or multi-dimensional
coupling. To illustrate the capability of the API, an operational problem for
improving the navigation capacity of the Gironde Estuary is presented. The API
potential is demonstrated in a re-calibration context. The API is used for a
multivariate sensitivity analysis to quickly reveal the most influential
parameters which can then be optimally calibrated with the help of a data
assimilation technique.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:14:05 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 11:22:36 GMT""}]","2021-11-12"
"2012.09155","Maverick Woo","Kaiyuan Li and Maverick Woo and Limin Jia","On the Generation of Disassembly Ground Truth and the Evaluation of
  Disassemblers","Revised and extended version of our publication that first appeared
  in the 2020 Workshop on Forming an Ecosystem Around Software Transformation
  (FEAST '20), November 13, 2020",,,,"cs.PL cs.CR cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When a software transformation or software security task needs to analyze a
given program binary, the first step is often disassembly. Since many modern
disassemblers have become highly accurate on many binaries, we believe reliable
disassembler benchmarking requires standardizing the set of binaries used and
the disassembly ground truth about these binaries. This paper presents (i) a
first version of our work-in-progress disassembly benchmark suite, which
comprises 879 binaries from diverse projects compiled with multiple compilers
and optimization settings, and (ii) a novel disassembly ground truth generator
leveraging the notion of ""listing files"", which has broad support by Clang,
GCC, ICC, and MSVC. In additional, it presents our evaluation of four prominent
open-source disassemblers using this benchmark suite and a custom evaluation
system. Our entire system and all generated data are maintained openly on
GitHub to encourage community adoption.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 20:03:40 GMT""}]","2020-12-17"
"2012.09609","Jatin Sharma","Jatin Sharma and Shobha Lata","Draw your Neural Networks",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Deep Neural Networks are the basic building blocks of modern Artificial
Intelligence. They are increasingly replacing or augmenting existing software
systems due to their ability to learn directly from the data and superior
accuracy on variety of tasks. Existing Software Development Life Cycle (SDLC)
methodologies fall short on representing the unique capabilities and
requirements of AI Development and must be replaced with Artificial
Intelligence Development Life Cycle (AIDLC) methodologies. In this paper, we
discuss an alternative and more natural approach to develop neural networks
that involves intuitive GUI elements such as blocks and lines to draw them
instead of complex computer programming. We present Sketch framework, that uses
this GUI-based approach to design and modify the neural networks and provides
interoperability with traditional frameworks. The system provides popular
layers and operations out-of-the-box and could import any supported pre-trained
model making it a faster method to design and train complex neural networks and
ultimately democratizing the AI by removing the learning curve.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:44:03 GMT""}]","2020-12-18"
"2012.10397","Alvaro Moreno","Francisco Javier Garc\'ia-Haro, Manuel Campos-Taberner, \'Alvaro
  Moreno, H{\aa}kan Torbern Tagesson, Fernando Camacho, Beatriz Mart\'inez,
  Sergio S\'anchez, Mar\'ia Piles, Gustau Camps-Valls, Marta Yeba, Mar\'ia
  Amparo Gilabert","A global Canopy Water Content product from AVHRR/Metop",,"ISPRS Journal of Photogrammetry and Remote Sensing (2020)","10.1016/j.isprsjprs.2020.02.007",,"physics.ao-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Spatially and temporally explicit canopy water content (CWC) data are
important for monitoring vegetation status, and constitute essential
information for studying ecosystem-climate interactions. Despite many efforts
there is currently no operational CWC product available to users. In the
context of the Satellite Application Facility for Land Surface Analysis
(LSA-SAF), we have developed an algorithm to produce a global dataset of CWC
based on data from the Advanced Very High Resolution Radiometer (AVHRR) sensor
on board Meteorological Operational (MetOp) satellites forming the EUMETSAT
Polar System (EPS). CWC reflects the water conditions at the leaf level and
information related to canopy structure. An accuracy assessment of the
EPS/AVHRR CWC indicated a close agreement with multi-temporal ground data from
SMAPVEX16 in Canada and Dahra in Senegal. The present study further evaluates
the consistency of the LSA-SAF product with respect to the Simplified Level 2
Product Prototype Processor (SL2P) product, and demonstrates its applicability
at different spatio-temporal resolutions using optical data from MSI/Sentinel-2
and MODIS/Terra and Aqua. We conclude that the EPS/AVHRR CWC product is a
promising tool for monitoring vegetation water status at regional and global
scales.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:15:13 GMT""}]","2020-12-21"
"2012.10398","Iman Bahmani Jafarloo","Iman Bahmani Jafarloo","Hadamard",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the Hadamard package for Macaulay2 which computes the Hadamard
product of projective subvarieties.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:19:36 GMT""}]","2020-12-21"
"2012.12071","Ho Yin Chau","Ho Yin Chau, Frank Qiu, Yubei Chen, Bruno Olshausen","Disentangling images with Lie group transformations and sparse coding",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Discrete spatial patterns and their continuous transformations are two
important regularities contained in natural signals. Lie groups and
representation theory are mathematical tools that have been used in previous
works to model continuous image transformations. On the other hand, sparse
coding is an important tool for learning dictionaries of patterns in natural
signals. In this paper, we combine these ideas in a Bayesian generative model
that learns to disentangle spatial patterns and their continuous
transformations in a completely unsupervised manner. Images are modeled as a
sparse superposition of shape components followed by a transformation that is
parameterized by n continuous variables. The shape components and
transformations are not predefined, but are instead adapted to learn the
symmetries in the data, with the constraint that the transformations form a
representation of an n-dimensional torus. Training the model on a dataset
consisting of controlled geometric transformations of specific MNIST digits
shows that it can recover these transformations along with the digits. Training
on the full MNIST dataset shows that it can learn both the basic digit shapes
and the natural transformations such as shearing and stretching that are
contained in this data.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 19:11:32 GMT""}]","2020-12-23"
"2012.12864","Jian Luo","Mingde Qin, Qizhang Yan, Haoren Wang, Kenneth S. Vecchio, Jian Luo","High-Entropy Rare Earth Tetraborides",,"Journal of the European Ceramic Society (12/8/2020)",,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Six high-entropy rare earth tetraborides of the tetragonal UB4-prototyped
structure have been successfully synthesized for the first time. The specimens
are prepared from elemental precursors via high-energy ball mill and in-situ
reactive spark plasma sintering. The sintered specimens are >98% in relative
densities without detectable oxide impurities (albeit the presence of minor
hexaborides in some compositions). No detectable secondary phase is observed in
the composition (Y$_{0.2}$Nd$_{0.2}$Sm$_{0.2}$Gd$_{0.2}$Tb$_{0.2}$)B$_{4}$,
which is proven homogeneous at both microscale and nanoscale. The Vickers
microhardness are determined to be ~13-15 GPa at a standard indentation load of
9.8 N. A scientifically interesting observation is represented by the
anisotropic lattice distortion from the rule-of-mixture averages. This work
expands the family of high-entropy ceramics via fabricating a new class of
high-entropy borides with a unique tetragonal quasi-layered crystal structure.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:24:54 GMT""}]","2020-12-24"
"2012.12865","Jian Luo","Chongze Hu, Jian Luo","Decoding Grain Boundary Thermodynamics in High-Entropy Alloys in a 5D
  Space: Coupled Segregation and Disordering",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Grain boundaries (GBs) can critically influence the microstructural evolution
and various materials properties. However, a fundamental understanding of GBs
in high-entropy alloys (HEAs) is lacking because of the complex couplings of
the segregations of multiple elements and interfacial disordering, which can
generate new phenomena and challenge the classical theories. Here, by combining
large-scale atomistic simulations and machine learning, we demonstrate the
feasibility of predicting the GB properties as functions of four independent
compositional degrees of freedoms and temperature in a 5D space. Subsequently,
GB counterparts to bulk phase diagrams are constructed for the first time for
quinary HEAs. A data-driven discovery further reveals new coupled segregation
and disordering effects in HEAs. Notably, an analysis of a large dataset
discovers a critical compensation temperature at which the segregations of all
elements virtually vanish simultaneously. While the machine learning model can
predict GB properties via a black-box approach, a surrogate data-based
analytical model (DBAM) is constructed to provide more physics insights and
better transferability, with good accuracies. This study not only provides a
new paradigm enabling prediction of GB properties in a 5D space, but also
uncovers new GB segregation phenomena in HEAs beyond the classical GB
segregation models.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 06:56:33 GMT""},{""version"":""v2"",""created"":""Tue, 29 Dec 2020 05:45:59 GMT""},{""version"":""v3"",""created"":""Sat, 20 Feb 2021 20:14:14 GMT""},{""version"":""v4"",""created"":""Sun, 11 Apr 2021 19:32:56 GMT""}]","2021-04-13"
"2012.12866","Jian Luo","Andrew J. Wright, Qingyang Wang, Chongze Hu, Yi-Ting Yeh, Renkun Chen,
  Jian Luo","Single-Phase Duodenary High-Entropy Fluorite/Pyrochlore Oxides with an
  Order-Disorder Transition",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Improved thermomechanical properties have been reported for various
high-entropy oxides containing typically five metal cations. This study further
investigates a series of duodenary (11 metals + oxygen) high-entropy oxides by
mixing different fractions of a five-cation fluorite-structured niobate and a
seven-cation pyrochlore (both containing Yb) with matching lattice constants.
Nine compositions of duodenary high-entropy oxides have been examined. All of
them exhibit single high-entropy phases of either disordered fluorite or
ordered pyrochlore structure. An order-disorder transition (ODT) is evident
with changing composition, accompanied by a reduction in thermal conductivity
(k). In comparison with the ODT criteria developed from ternary oxides, these
duodenary oxides are more prone to disorder, but the ODT is still controlled by
similar factors (but at different thresholds). Interestingly, there are abrupt
increases in Young's modulus (E) at low mixing concentrations near both
endmembers. The E/k ratios are increased, in comparison with both endmembers.
This study suggests a new route to tailor high-entropy ceramics via controlling
cation ordering vs. disordering.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 06:49:14 GMT""}]","2020-12-24"
"2012.14274","Kiran Garimella","Kirill Martynov, Kiran Garimella, Robert West","Darks and Stripes: Effects of Clothing on Weight Perception","Accepted at the IEEE Journal of Social Computing","Journal of Social Computing (Volume: 1, Issue: 1, September 2020)
  pg. 53-70","10.23919/JSC.2020.0006",,"cs.CY cs.SI","http://creativecommons.org/licenses/by/4.0/","  In many societies, appearing slim is considered attractive. The fashion
industry has been attempting to cater to this trend by designing outfits that
can enhance the appearance of slimness. Two anecdotal rules, widespread in the
world of fashion, are (1) choose dark clothes and (2) avoid horizontal stripes,
in order to appear slim. Thus far, empirical evidence has been unable to
conclusively determine the validity of these rules, and there is consequently
much controversy regarding the impact of both color and patterns on the visual
perception of weight. In this paper, we aim to close this gap by presenting the
results from a series of large-scale crowdsourcing studies that investigate the
above two claims. We gathered a dataset of around 1,000 images of people from
the Web together with their ground-truth weight and height, as well as clothing
attributes about colors and patterns. To elicit the effects of colors and
patterns, we asked crowd workers to estimate the weight in each image. For the
analysis, we controlled potential confounds by matching images in pairs where
the two images differ with respect to color or pattern, but are similar with
respect to other relevant aspects. We created image pairs in two ways: first,
observationally, i.e., from two real images; and second, experimentally, by
manipulating the color or pattern of clothing in a real image via photo
editing. Based on our analysis, we conclude that (1) dark clothes indeed
decrease perceived weight slightly but statistically significantly, and (2)
horizontal stripes have no discernible effect compared to solid light-colored
clothes. These results contribute to advancing the debate around the effect of
specific clothing colors and patterns and thus provide empirical grounds for
everyday fashion decisions. Moreover, our work gives an outlook on the vast
opportunities of using crowd sourcing in the modern fashion industry.
","[{""version"":""v1"",""created"":""Fri, 11 Dec 2020 16:14:40 GMT""}]","2020-12-29"
"2012.14276","Vazgen Sargsyan Dr.","G. G. Adamian, N. V. Antonenko, H. Lenske, and V. V. Sargsyan","Application of Regge-theory to astronomical objects","12 pages. arXiv admin note: text overlap with arXiv:1907.01877",,,,"physics.class-ph astro-ph.SR gr-qc hep-ph","http://creativecommons.org/licenses/by/4.0/","  Using the model based on the Regge-like laws, new analytical formulas are
obtained for the moment of inertia, the rotation frequency, and the radius of
astronomical non-exotic objects (planets, stars, galaxies, and clusters of
galaxies). The rotation frequency and moment of inertia of neutron star and the
observable Universe are estimated. The estimates of the average numbers of
stars and galaxies in the observable Universe are given. The Darwin instability
effect in the binary systems (di-planets, di-stars, and di-galaxies) is also
analyzed.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 09:09:58 GMT""},{""version"":""v2"",""created"":""Thu, 31 Dec 2020 18:23:08 GMT""},{""version"":""v3"",""created"":""Mon, 4 Jan 2021 08:25:08 GMT""},{""version"":""v4"",""created"":""Thu, 11 Feb 2021 09:12:49 GMT""},{""version"":""v5"",""created"":""Fri, 5 Mar 2021 07:06:27 GMT""},{""version"":""v6"",""created"":""Tue, 11 May 2021 07:15:26 GMT""}]","2021-05-12"
"2012.15862","Jian Luo","Jiuyuan Nie, Chongze Hu, Qizhang Yan, Jian Luo","Discovery of Electrochemically Induced Grain Boundary Transitions","70 pages, 26 (6 main + 20 Supplementary) Figures",,"10.1038/s41467-021-22669-0",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Electric fields and currents, which are used in innovative materials
processing and electrochemical energy conversion, can often alter
microstructures in unexpected ways. However, little is known about the
underlying mechanisms. Using ZnO-Bi2O3 as a model system, this study uncovers
how an applied electric current can change the microstructural evolution
through an electrochemically induced grain boundary (GB) transition. By
combining aberration-corrected electron microscopy, photoluminescence
spectroscopy, first-principles calculations, a generalizable thermodynamic
model, and ab initio molecular dynamics, this study reveals that
electrochemical reduction can cause a GB disorder-to-order transition to
markedly increase GB diffusivities and mobilities. Consequently, abruptly
enhanced or abnormal grain growth takes place. These findings advance our
fundamental knowledge of GB complexion (phase-like) transitions and electric
field effects on microstructural stability and evolution, with broad scientific
and technological impacts. A new method to tailor the GB structures and
properties, as well as the microstructures, electrochemically can also be
envisioned.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 07:01:31 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 20:29:12 GMT""}]","2021-05-12"
"2101.01115","Yunus Camg\""ozl\""u","Yunus Camg\""ozl\""u, Yakup Kutlu","Analysis of Filter Size Effect In Deep Learning","10 Pages, 9 Figures, Journal of Artificial Intelligence with
  Applications, published","Journal of Artificial Intelligence with Applications, 1(1), 20-29,
  2020",,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  With the use of deep learning in many areas, how to improve this technology
or how to develop the structure used more effectively and in a shorter time is
an issue that is of interest to many people working in this field. Many studies
are carried out on this subject, it is aimed to reduce the duration of the
operation and the processing power required, except to obtain the best result
with the changes made in the variables, functions and data in the models used.
In this study, in the leaf classification made using Mendeley data set
consisting of leaf images with a fixed background, all other variables such as
layer number, iteration, number of layers in the model and pooling process were
kept constant, except for the filter dimensions of the convolution layers in
the determined model. Convolution layers in 3 different filter sizes and in
addition to this, many results obtained in 2 different structures, increasing
and decreasing, and 3 different image sizes were examined. In the literature,
it is seen that different uses of pooling layers, changes due to increase or
decrease in the number of layers, the difference in the size of the data used,
and the results of many functions used with different parameters are evaluated.
In the leaf classification of the determined data set with CNN, the change in
the filter size of the convolution layer together with the change in different
filter combinations and in different sized images was focused. Using the data
set and data reproduction methods, it was aimed to make the differences in
filter sizes and image sizes more distinct. Using the fixed number of
iterations, model and data set, the effect of different filter sizes has been
observed.
","[{""version"":""v1"",""created"":""Sat, 12 Dec 2020 11:05:47 GMT""}]","2021-01-05"
