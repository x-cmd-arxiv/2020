"2007.01218","Miguel Mendez A","Mikhael Balabane, Miguel A Mendez, Sara Najem","On Koopman Operator for Burgers' Equation",,"Phys. Rev. Fluids 6, 064401 (2021)","10.1103/PhysRevFluids.6.064401",,"math.DS math-ph math.MP physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the flow of Burgers' equation on an open set of (small) functions
in $L^2([0,1])$. We derive explicitly the Koopman decomposition of the Burgers'
flow. We identify the frequencies and the coefficients of this decomposition as
eigenvalues and eigenfunctionals of the Koopman operator. We prove the
convergence of the Koopman decomposition for $t>0$ for small Cauchy data, and
up to $t=0$ for regular Cauchy data. The convergence up to $t=0$} leads to a
`completeness' property for the basis of Koopman modes. We construct all modes
and eigenfunctionals, including the eigenspaces involved in geometric
multiplicity. This goes beyond the summation formulas provided by (Page &
Kerswell, 2018), where only one term per eigenvalue was given. A numeric
illustration of the Koopman decomposition is given and the Koopman eigenvalues
compared to the eigenvalues of a Dynamic Mode Decomposition (DMD).
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:00:16 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 18:15:59 GMT""},{""version"":""v3"",""created"":""Sat, 24 Apr 2021 09:15:05 GMT""}]","2021-07-07"
"2007.01219","Zhan Gao","Zhan Gao and Alec Koppel and Alejandro Ribeiro","Balancing Rates and Variance via Adaptive Batch-Size for Stochastic
  Optimization Problems",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic gradient descent is a canonical tool for addressing stochastic
optimization problems, and forms the bedrock of modern machine learning and
statistics. In this work, we seek to balance the fact that attenuating
step-size is required for exact asymptotic convergence with the fact that
constant step-size learns faster in finite time up to an error. To do so,
rather than fixing the mini-batch and the step-size at the outset, we propose a
strategy to allow parameters to evolve adaptively. Specifically, the batch-size
is set to be a piecewise-constant increasing sequence where the increase occurs
when a suitable error criterion is satisfied. Moreover, the step-size is
selected as that which yields the fastest convergence. The overall algorithm,
two scale adaptive (TSA) scheme, is developed for both convex and non-convex
stochastic optimization problems. It inherits the exact asymptotic convergence
of stochastic gradient method. More importantly, the optimal error decreasing
rate is achieved theoretically, as well as an overall reduction in
computational cost. Experimentally, we observe that TSA attains a favorable
tradeoff relative to standard SGD that fixes the mini-batch and the step-size,
or simply allowing one to increase or decrease respectively.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:02:02 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 15:43:37 GMT""}]","2020-07-10"
"2007.01220","Zhiang Chen","Zhiang Chen, Sarah Bearman, J Ramon Arrowsmith, Jnaneshwar Das","Localization and Mapping of Sparse Geologic Features with Unpiloted
  Aircraft Systems",,,,,"cs.RO physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  Robotic mapping is attractive in many scientific applications that involve
environmental surveys. This paper presents a system for localization and
mapping of sparsely distributed surface features such as precariously balanced
rocks (PBRs), whose geometric fragility parameters provide valuable information
on earthquake processes and landscape development. With this geomorphologic
problem as the test domain, we carry out a lawn-mower search pattern from a
high elevation using an Unpiloted Aerial Vehicle (UAV) equipped with a flight
controller, GPS module, stereo camera, and onboard computer. Once a potential
PBR target is detected by a deep neural network in real time, we track its
bounding box in the image coordinates by applying a Kalman filter that fuses
the deep learning detection with Kanade-Lucas-Tomasi (KLT) tracking. The target
is localized in world coordinates using depth filtering where a set of 3D
points are filtered by object bounding boxes from different camera
perspectives. The 3D points also provide a strong prior on target shape, which
is used for UAV path planning to closely map the target using RGBD SLAM. After
target mapping, the UAS resumes the lawn-mower search pattern to locate and map
the next target.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:05:07 GMT""},{""version"":""v2"",""created"":""Sun, 1 Nov 2020 07:29:07 GMT""}]","2020-11-03"
"2007.01221","Mariami Gachechiladze","Mariami Gachechiladze, Nikolai Miklin, and Rafael Chaves","Quantifying causal influences in the presence of a quantum common cause","13 pages, 2 figures","Phys. Rev. Lett. 125, 230401 (2020)","10.1103/PhysRevLett.125.230401",,"quant-ph stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum mechanics challenges our intuition on the cause-effect relations in
nature. Some fundamental concepts, including Reichenbach's common cause
principle or the notion of local realism, have to be reconsidered.
Traditionally, this is witnessed by the violation of a Bell inequality. But are
Bell inequalities the only signature of the incompatibility between quantum
correlations and causality theory? Motivated by this question we introduce a
general framework able to estimate causal influences between two variables,
without the need of interventions and irrespectively of the classical, quantum,
or even post-quantum nature of a common cause. In particular, by considering
the simplest instrumental scenario -- for which violation of Bell inequalities
is not possible -- we show that every pure bipartite entangled state violates
the classical bounds on causal influence, thus answering in negative to the
posed question and opening a new venue to explore the role of causality within
quantum theory.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:07:18 GMT""}]","2020-12-04"
"2007.01222","Alim Ul Gias","Alim Ul Gias and Giuliano Casale","COCOA: Cold Start Aware Capacity Planning for Function-as-a-Service
  Platforms","8 pages, 9 figures",,,,"cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Function-as-a-Service (FaaS) is increasingly popular in the software industry
due to the implied cost-savings in event-driven workloads and its synergy with
DevOps. To size an on-premise FaaS platform, it is important to estimate the
required CPU and memory capacity to serve the expected loads. Given the
service-level agreements, it is however challenging to take the cold start
issue into account during the sizing process. We have investigated the
similarity of this problem with the hit rate improvement problem in TTL caches
and concluded that solutions for TTL cache, although potentially applicable,
lead to over-provisioning in FaaS. Thus, we propose a novel approach, COCOA, to
solve this issue. COCOA uses a queueing-based approach to assess the effect of
cold starts on FaaS response times. It also considers different memory
consumption values depending on whether the function is idle or in execution.
Using an event-driven FaaS simulator, FaasSim, we have developed, we show that
COCOA can reduce over-provisioning by over 70% in some workloads, while
satisfying the service-level agreements.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:11:03 GMT""}]","2020-07-03"
"2007.01223","Nathan Fulton","Nathan Hunt, Nathan Fulton, Sara Magliacane, Nghia Hoang, Subhro Das,
  Armando Solar-Lezama","Verifiably Safe Exploration for End-to-End Reinforcement Learning",,,,,"cs.AI cs.LG cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deploying deep reinforcement learning in safety-critical settings requires
developing algorithms that obey hard constraints during exploration. This paper
contributes a first approach toward enforcing formal safety constraints on
end-to-end policies with visual inputs. Our approach draws on recent advances
in object detection and automated reasoning for hybrid dynamical systems. The
approach is evaluated on a novel benchmark that emphasizes the challenge of
safely exploring in the presence of hard constraints. Our benchmark draws from
several proposed problem sets for safe learning and includes problems that
emphasize challenges such as reward signals that are not aligned with safety
constraints. On each of these benchmark problems, our algorithm completely
avoids unsafe behavior while remaining competitive at optimizing for as much
reward as is safe. We also prove that our method of enforcing the safety
constraints preserves all safe policies from the original environment.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:12:20 GMT""}]","2020-07-03"
"2007.01224","Roman Pasechnik","Torbj\""orn Lundberg and Roman Pasechnik","Thermal Field Theory in real-time formalism: concepts and applications
  for particle decays","87 pages, 11 figures",,"10.1140/epja/s10050-020-00288-5",,"hep-th hep-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This review represents a detailed and comprehensive discussion of the Thermal
Field Theory (TFT) concepts and key results in Yukawa-type theories. We start
with a general pedagogical introduction into the TFT in the imaginary- and
real-time formulation. As phenomenologically relevant implications, we present
a compendium of thermal decay rates for several typical reactions calculated
within the framework of the real-time formalism and compared to the
imaginary-time results found in the literature. Processes considered here are
those of a neutral (pseudo)scalar decaying into two distinct (pseudo)scalars or
into a fermion-antifermion pair. These processes are extended from earlier
works to include chemical potentials and distinct species in the final state.
In addition, a (pseudo)scalar emission off a fermion line is also discussed.
These results demonstrate the importance of thermal effects in particle decay
observables relevant in many phenomenological applications in systems at high
temperatures and densities.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:16:59 GMT""}]","2021-03-17"
"2007.01225","Timofey Mukha","Timofey Mukha and Rickard E. Bensow","Flow dynamics in the closure region of an internal ship air cavity",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work is dedicated to providing a detailed account of the flow dynamics
in the closure region of an internal ship air cavity. A geometrically simple
multiwave test cavity is considered, and a simulation of the flow is conducted
using large-eddy simulation coupled with an algebraic Volume of Fluid interface
capturing method. Results reveal that the flow in the closure region is highly
unsteady and turbulent. The main cause of this is established to be the
pressure gradient occurring due to the stagnation of the flow on the beach wall
of the cavity. The pressure gradient leads to a steep incline in the mean
location of the air-water interface, which, in turn, leads to the flow
separating from it and forming a recirculation zone, in which air and water are
mixed. The separated flow becomes turbulent, which further facilitates the
mixing and entrainment of air. Swarms of air bubbles leak periodically.
Upstream of the closure region, the phase and length of the wave are found to
be well-predicted using existing approximations based on linear flow theory.
However, for the corresponding prediction of the amplitude of the wave the
agreement is worse, with the estimates under-predicting the simulation results.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:18:36 GMT""}]","2020-07-03"
"2007.01226","Emil Prodan Dr.","Thomas D. K\""uhne, Julian Heske and Emil Prodan","Disordered Crystals from First Principles II: Transport Coefficients",,"Annals of Physics 421, 168290 (2020)","10.1016/j.aop.2020.168290",,"physics.comp-ph cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the second part of a project on the foundations of first-principle
calculations of the electron transport in crystals at finite temperatures,
aiming at a predictive first-principles platform that combines ab-initio
molecular dynamics (AIMD) and a finite-temperature Kubo-formula with
dissipation for thermally disordered crystalline phases. The latter are encoded
in an ergodic dynamical system $(\Omega,\mathbb G,{\rm d}\mathbb P)$, where
$\Omega$ is the configuration space of the atomic degrees of freedom, $\mathbb
G$ is the space group acting on $\Omega$ and ${\rm d}\mathbb P$ is the ergodic
Gibbs measure relative to the $\mathbb G$-action. We first demonstrate how to
pass from the continuum Kohn-Sham theory to a discrete atomic-orbitals based
formalism without breaking the covariance of the physical observables w.r.t.
$(\Omega,\mathbb G,{\rm d}\mathbb P)$. Then we show how to implement the
Kubo-formula, investigate its self-averaging property and derive an optimal
finite-volume approximation for it. We also describe a numerical innovation
that made possible AIMD simulations with longer orbits and elaborate on the
details of our simulations. Lastly, we present numerical results on the
transport coefficients of crystal silicon at different temperatures.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:18:40 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jul 2020 18:28:57 GMT""}]","2020-09-10"
"2007.01227","Noah Riggenbach","Noah Riggenbach","On The Algebraic $K$-Theory of Double Points","24 pages. Added the case p=2. Also added section 4 to fix a mistake
  pointed out to me by Martin Speirs. Changed the numbering of theorems to be
  more readable. Comments welcome","Algebr. Geom. Topol. 22 (2022) 373-403","10.2140/agt.2022.22.373",,"math.KT math.AG math.AT math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we use trace methods to study the algebraic $K$-theory of
rings of the form $R[x_1,\ldots, x_d]/(x_1,\ldots, x_d)^2$. We compute the
relative $p$-adic $K$ groups for $R$ a perfectoid ring. In particular, we get
the integral $K$ groups when $R$ is a finite field, and the integral relative
$K$ groups $K_*(R[x_1,\ldots, x_d]/(x_1,\ldots, x_d)^2, (x_1,\ldots, x_d))$
when $R$ is a perfect $\mathbb{F}_p$-algebra. We conclude the paper with some
other notable computations, including some rings which are not quite of the
above form.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:19:52 GMT""},{""version"":""v2"",""created"":""Mon, 23 Nov 2020 16:23:41 GMT""}]","2022-05-04"
"2007.01228","Bharath Keshavamurthy","Bharath Keshavamurthy, Matthew Bliss, Nicol\`o Michelusi","MAESTRO-X: Distributed Orchestration of Rotary-Wing UAV-Relay Swarms","32 pages, 12 figures, and 3 tables | Submitted to the IEEE
  Transactions on Cognitive Communications and Networking (TCCN)",,,"Manuscript ID TCCN-TPS-22-0168","cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This work details a scalable framework to orchestrate a swarm of rotary-wing
UAVs serving as cellular relays to facilitate beyond line-of-sight connectivity
and traffic offloading for ground users. First, a Multiscale Adaptive
Energy-conscious Scheduling and TRajectory Optimization (MAESTRO) framework is
developed for a single UAV. Aiming to minimize the time-averaged latency to
serve user requests, subject to an average UAV power constraint, it is shown
that the optimization problem can be cast as a semi-Markov decision process,
and exhibits a multiscale structure: outer actions on radial wait velocities
and terminal service positions minimize the long-term delay-power trade-off,
optimized via value iteration; given these outer actions, inner actions on
angular wait velocities and service trajectories minimize a short-term
delay-energy cost. A novel hierarchical competitive swarm optimization scheme
is developed in the inner optimization, to devise high-resolution trajectories
via iterative pair-wise updates. Next, MAESTRO is eXtended to UAV swarms
(MAESTRO-X) via scalable policy replication: enabled by a decentralized
command-and-control network, the optimal single-agent policy is augmented with
spread maximization, consensus-driven conflict resolution, adaptive frequency
reuse, and piggybacking. Numerical evaluations show that, for user requests of
10 Mbits, generated according to a Poisson arrival process with rate 0.2
req/min/UAV, single-agent MAESTRO offers 3.8x faster service than a
high-altitude platform and 29% faster than a static UAV deployment; moreover,
for a swarm of 3 UAV-relays, MAESTRO-X delivers data payloads 4.7x faster than
a successive convex approximation scheme; and remarkably, a single UAV
optimized via MAESTRO outclasses 3 UAVs optimized via a deep-Q network by 38%.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:20:46 GMT""},{""version"":""v2"",""created"":""Wed, 12 Jan 2022 16:05:36 GMT""},{""version"":""v3"",""created"":""Tue, 3 Jan 2023 17:44:58 GMT""},{""version"":""v4"",""created"":""Sun, 5 Feb 2023 00:31:22 GMT""}]","2023-02-07"
"2007.01229","Shenyang Huang","Shenyang Huang, Yasmeen Hitti, Guillaume Rabusseau, Reihaneh Rabbany","Laplacian Change Point Detection for Dynamic Graphs","in KDD 2020, 10 pages",,"10.1145/3394486.3403077",,"cs.LG cs.SI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamic and temporal graphs are rich data structures that are used to model
complex relationships between entities over time. In particular, anomaly
detection in temporal graphs is crucial for many real world applications such
as intrusion identification in network systems, detection of ecosystem
disturbances and detection of epidemic outbreaks. In this paper, we focus on
change point detection in dynamic graphs and address two main challenges
associated with this problem: I) how to compare graph snapshots across time,
II) how to capture temporal dependencies. To solve the above challenges, we
propose Laplacian Anomaly Detection (LAD) which uses the spectrum of the
Laplacian matrix of the graph structure at each snapshot to obtain low
dimensional embeddings. LAD explicitly models short term and long term
dependencies by applying two sliding windows. In synthetic experiments, LAD
outperforms the state-of-the-art method. We also evaluate our method on three
real dynamic networks: UCI message network, US senate co-sponsorship network
and Canadian bill voting network. In all three datasets, we demonstrate that
our method can more effectively identify anomalous time points according to
significant real world events.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:24:24 GMT""}]","2020-07-03"
"2007.01230","Zichang Liu","Zichang Liu, Zhaozhuo Xu, Alan Ji, Jonathan Li, Beidi Chen, Anshumali
  Shrivastava","Climbing the WOL: Training for Cheaper Inference",,,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Efficient inference for wide output layers (WOLs) is an essential yet
challenging task in large scale machine learning. Most approaches reduce this
problem to approximate maximum inner product search (MIPS), which relies
heavily on the observation that for a given model, ground truth labels
correspond to logits of highest value during full model inference. However,
such an assumption is restrictive in practice. In this paper, we argue that
approximate MIPS subroutines, despite having sub-linear computation time, are
sub-optimal because they are tailored for retrieving large inner products with
high recall instead of retrieving the correct labels. With WOL, the labels
often have moderate inner products, which makes approximate MIPS more
challenging. We propose an alternative problem formulation, called Label
Superior Sampling (LSS), where the objective is to tailor the system to ensure
retrieval of the correct label. Accordingly, we propose a novel learned hash
approach, which is significantly more efficient and sufficient for high
inference accuracy than MIPS baselines. Our extensive evaluation indicates that
LSS can match or even outperform full inference accuracy with around 5x speed
up and 87% energy reduction.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:26:26 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 03:11:54 GMT""}]","2020-07-06"
"2007.01231","Kian Ahrabian","Kian Ahrabian, Daniel Tarlow, Hehuimin Cheng, Jin L.C. Guo","Software Engineering Event Modeling using Relative Time in Temporal
  Knowledge Graphs","11 pages, 1 figure. 37th International Conference on Machine Learning
  (ICML 2020) - Workshop on Graph Representation Learning and Beyond",,,,"cs.LG cs.SE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a multi-relational temporal Knowledge Graph based on the daily
interactions between artifacts in GitHub, one of the largest social coding
platforms. Such representation enables posing many user-activity and project
management questions as link prediction and time queries over the knowledge
graph. In particular, we introduce two new datasets for i) interpolated
time-conditioned link prediction and ii) extrapolated time-conditioned
link/time prediction queries, each with distinguished properties. Our
experiments on these datasets highlight the potential of adapting knowledge
graphs to answer broad software engineering questions. Meanwhile, it also
reveals the unsatisfactory performance of existing temporal models on
extrapolated queries and time prediction queries in general. To overcome these
shortcomings, we introduce an extension to current temporal models using
relative temporal information with regards to past events.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:28:43 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 01:07:23 GMT""}]","2020-07-14"
"2007.01232","Shajid Haque","Arpan Bhattacharyya, Wissam Chemissany, S. Shajidul Haque, Jeff
  Murugan, Bin Yan","The Multi-faceted Inverted Harmonic Oscillator: Chaos and Complexity","12 pages, 2 figures, version to appear in SciPost Physics Core","SciPost Phys. Core 4, 002 (2021)","10.21468/SciPostPhysCore.4.1.002","LA-UR-20-24798","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The harmonic oscillator is the paragon of physical models; conceptually and
computationally simple, yet rich enough to teach us about physics on scales
that span classical mechanics to quantum field theory. This multifaceted nature
extends also to its inverted counterpart, in which the oscillator frequency is
analytically continued to pure imaginary values. In this article we probe the
inverted harmonic oscillator (IHO) with recently developed quantum chaos
diagnostics such as the out-of-time-order correlator (OTOC) and the circuit
complexity. In particular, we study the OTOC for the displacement operator of
the IHO with and without a non-Gaussian cubic perturbation to explore genuine
and quasi scrambling respectively. In addition, we compute the full quantum
Lyapunov spectrum for the inverted oscillator, finding a paired structure among
the Lyapunov exponents. We also use the Heisenberg group to compute the
complexity for the time evolved displacement operator, which displays chaotic
behaviour. Finally, we extended our analysis to N-inverted harmonic oscillators
to study the behaviour of complexity at the different timescales encoded in
dissipation, scrambling and asymptotic regimes.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:30:41 GMT""},{""version"":""v2"",""created"":""Thu, 15 Oct 2020 19:41:58 GMT""},{""version"":""v3"",""created"":""Sun, 7 Feb 2021 19:49:24 GMT""}]","2021-02-10"
"2007.01233","Bartosz Bednarczyk","Bartosz Bednarczyk, Jakub Michaliszyn","""Most of"" leads to undecidability: Failure of adding frequencies to LTL","Full version of FOSSACS 2021 paper",,,,"cs.LO cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Linear Temporal Logic (LTL) interpreted on finite traces is a robust
specification framework popular in formal verification. However, despite the
high interest in the logic in recent years, the topic of their quantitative
extensions is not yet fully explored. The main goal of this work is to study
the effect of adding weak forms of percentage constraints (e.g. that most of
the positions in the past satisfy a given condition, or that sigma is the
most-frequent letter occurring in the past) to fragments of LTL. Such
extensions could potentially be used for the verification of influence networks
or statistical reasoning. Unfortunately, as we prove in the paper, it turns out
that percentage extensions of even tiny fragments of LTL have undecidable
satisfiability and model-checking problems. Our undecidability proofs not only
sharpen most of the undecidability results on logics with arithmetics
interpreted on words known from the literature, but also are fairly simple. We
also show that the undecidability can be avoided by restricting the allowed
usage of the negation, and briefly discuss how the undecidability results
transfer to first-order logic on words.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:31:01 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 14:46:34 GMT""},{""version"":""v3"",""created"":""Tue, 20 Oct 2020 10:36:21 GMT""},{""version"":""v4"",""created"":""Sun, 3 Jan 2021 13:51:21 GMT""}]","2021-01-05"
"2007.01234","Artur Izmaylov","Tzu-Ching Yen and Artur F. Izmaylov","Cartan sub-algebra approach to efficient measurements of quantum
  observables",,"PRX Quantum, 2, 040320 (2021)","10.1103/PRXQuantum.2.040320",,"quant-ph physics.chem-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An arbitrary operator corresponding to a physical observable cannot be
measured in a single measurement on currently available quantum hardware. To
obtain the expectation value of the observable, one needs to partition its
operator to measurable fragments. However, the observable and its fragments
generally do not share any eigenstates, and thus the number of measurements
needed to obtain the expectation value of the observable can grow rapidly even
when the wavefunction prepared is close to an eigenstate of the observable. We
provide a unified Lie algebraic framework for developing efficient measurement
schemes for quantum observables, it is based on two elements: 1) embedding the
observable operator in a Lie algebra and 2) transforming Lie algebra elements
into those of a Cartan sub-algebra (CSA) using unitary operators. The CSA plays
the central role because all its elements are mutually commutative and thus can
be measured simultaneously. We illustrate the framework on measuring
expectation values of Hamiltonians appearing in the Variational Quantum
Eigensolver approach to quantum chemistry. The CSA approach puts many recently
proposed methods for the measurement optimization within a single framework,
and allows one not only to reduce the number of measurable fragments but also
the total number of measurements.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:32:48 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jul 2020 20:33:11 GMT""},{""version"":""v3"",""created"":""Wed, 30 Sep 2020 20:03:25 GMT""},{""version"":""v4"",""created"":""Tue, 21 Sep 2021 01:40:46 GMT""}]","2021-12-07"
"2007.01235","Viktoriya Ozornova","Viktoriya Ozornova, Martina Rovelli, Dominic Verity","Gray tensor product and saturated $N$-complicial sets",,,,,"math.AT math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the pretensor and tensor products of simplicial sets with
marking are compatible with the homotopy theory of saturated $N$-complicial
sets (which are a proposed model of $(\infty,N)$-categories), in the form of a
Quillen bifunctor and a homotopical bifunctor, respectively.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:34:08 GMT""}]","2020-07-03"
"2007.01236","Klaudius Scheufele","Klaudius Scheufele, Shashank Subramanian, George Biros","Calibration of Biophysical Models for tau-Protein Spreading in
  Alzheimer's Disease from PET-MRI","22 pages, 11 figures",,,,"q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aggregates of misfolded tau proteins (or just 'tau' for brevity) play a
crucial role in the progression of Alzheimer's disease (AD) as they correlate
with cell death and accelerated tissue atrophy. Longitudinal positron emission
tomography (PET) scans can be used quantify the extend of abnormal tau spread.
Such PET-based image biomarkers are a promising technology for AD diagnosis and
prognosis. Here, we propose to calibrate an organ-scale biophysical
mathematical model using longitudinal PET scans to extract characteristic
growth patterns and spreading of tau. The biophysical model is a
reaction-advection-diffusion partial differential equation (PDE) with only two
scalar unknown parameters, one representing the spreading (the diffusion part
of the PDE) and the other one the growth of tau (the reaction part of the PDE).
The advection term captures tissue atrophy and is obtained from diffeomorphic
registration of longitudinal magnetic resonance imaging (MRI) scans. We
describe the method, present a numerical scheme for the calibration of the
growth and spreading parameters, perform a sensitivity study using synthetic
data, and we perform a preliminary evaluation on clinical scans from the ADNI
dataset. We study whether such model calibration is possible and investigate
the sensitivity of such calibration to the time between consecutive scans and
the presence of atrophy. Our findings show that despite using only two
calibration parameters, the model can reconstruct clinical scans quite
accurately. We discovered that small time intervals between scans and the
presence of background noise create difficulties. Our reconstructed model fits
the data well, yet the study on clinical data also reveals shortcomings of the
simplistic model. Interestingly, the parameters show significant variability
across patients, an indication that these parameters could be useful
biomarkers.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:34:20 GMT""},{""version"":""v2"",""created"":""Sat, 5 Dec 2020 20:30:32 GMT""}]","2020-12-08"
"2007.01237","Chenguang Dai","Chenguang Dai, Buyu Lin, Xin Xing, Jun S. Liu","A Scale-free Approach for False Discovery Rate Control in Generalized
  Linear Models","60 pages, 13 pages",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The generalized linear models (GLM) have been widely used in practice to
model non-Gaussian response variables. When the number of explanatory features
is relatively large, scientific researchers are of interest to perform
controlled feature selection in order to simplify the downstream analysis. This
paper introduces a new framework for feature selection in GLMs that can achieve
false discovery rate (FDR) control in two asymptotic regimes. The key step is
to construct a mirror statistic to measure the importance of each feature,
which is based upon two (asymptotically) independent estimates of the
corresponding true coefficient obtained via either the data-splitting method or
the Gaussian mirror method. The FDR control is achieved by taking advantage of
the mirror statistic's property that, for any null feature, its sampling
distribution is (asymptotically) symmetric about 0. In the moderate-dimensional
setting in which the ratio between the dimension (number of features) p and the
sample size n converges to a fixed value, we construct the mirror statistic
based on the maximum likelihood estimation. In the high-dimensional setting
where p is much larger than n, we use the debiased Lasso to build the mirror
statistic. Compared to the Benjamini-Hochberg procedure, which crucially relies
on the asymptotic normality of the Z statistic, the proposed methodology is
scale free as it only hinges on the symmetric property, thus is expected to be
more robust in finite-sample cases. Both simulation results and a real data
application show that the proposed methods are capable of controlling the FDR,
and are often more powerful than existing methods including the
Benjamini-Hochberg procedure and the knockoff filter.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:37:13 GMT""}]","2020-07-03"
"2007.01238","Gustau Camps-Valls","Gustau Camps-Valls and Dino Sejdinovic and Jakob Runge and Markus
  Reichstein","A Perspective on Gaussian Processes for Earth Observation","1 figure","National Science Review, Volume 6, Issue 4, July 2019, Pages
  616-618","10.1093/nsr/nwz028",,"cs.LG stat.AP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Earth observation (EO) by airborne and satellite remote sensing and in-situ
observations play a fundamental role in monitoring our planet. In the last
decade, machine learning and Gaussian processes (GPs) in particular has
attained outstanding results in the estimation of bio-geo-physical variables
from the acquired images at local and global scales in a time-resolved manner.
GPs provide not only accurate estimates but also principled uncertainty
estimates for the predictions, can easily accommodate multimodal data coming
from different sensors and from multitemporal acquisitions, allow the
introduction of physical knowledge, and a formal treatment of uncertainty
quantification and error propagation. Despite great advances in forward and
inverse modelling, GP models still have to face important challenges that are
revised in this perspective paper. GP models should evolve towards data-driven
physics-aware models that respect signal characteristics, be consistent with
elementary laws of physics, and move from pure regression to observational
causal inference.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:44:11 GMT""}]","2020-07-03"
"2007.01239","Xiaocong Ai","Xiaocong Ai (for the ACTS developers)","Tracking with A Common Tracking Software",,,,,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In high energy physics (HEP) experiments, the reconstruction of charged
particle trajectories is one of the most fundamental yet computationally
expensive parts of event processing. At future hadron colliders such as the
High-Luminosity Large Hadron Collider (HL-LHC), there can be up to ten thousand
particles per event. This increases the track reconstruction time by a factor
about 5 compared to the current tracking environment. Efficient and fast
tracking software is necessary to maintain and improve the tracking
performance. This can benefit from both fast tracking algorithms and modern
computing architectures with many cores and accelerators.
  The Acts (A Common Tracking Software) project encapsulates the current ATLAS
tracking software into an experiment-independent software designed for modern
computing architectures. It provides a set of high-level track reconstruction
tools agnostic to the details of the detector and magnetic field configuration.
Particular emphasis is placed on thread-safety of the code in order to support
concurrent event processing with context-dependent detector conditions, such as
detector alignments or calibrations. Acts aims in addition to be a research and
development platform for studying innovative tracking techniques and exploiting
modern hardware architectures.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:47:38 GMT""}]","2020-07-03"
"2007.01240","Marco Vicedomini","M. Vicedomini, M. Brescia, S. Cavuoti, G. Longo, G. Riccio","Statistical characterization and classification of astronomical
  transients with Machine Learning in the era of the Vera C. Rubin Observatory","Preprint version of the manuscript to appear in the Volume
  ""Intelligent Astrophysics"" of the series ""Emergence, Complexity and
  Computation"", Book eds. I. Zelinka, D. Baron, M. Brescia, Springer Nature
  Switzerland, ISSN: 2194-7287",,"10.1007/978-3-030-65867-0_4",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Astronomy has entered the multi-messenger data era and Machine Learning has
found widespread use in a large variety of applications. The exploitation of
synoptic (multi-band and multi-epoch) surveys, like LSST (Legacy Survey of
Space and Time), requires an extensive use of automatic methods for data
processing and interpretation. With data volumes in the petabyte domain, the
discrimination of time-critical information has already exceeded the
capabilities of human operators and crowds of scientists have extreme
difficulty to manage such amounts of data in multi-dimensional domains. This
work is focused on an analysis of critical aspects related to the approach,
based on Machine Learning, to variable sky sources classification, with special
care to the various types of Supernovae, one of the most important subjects of
Time Domain Astronomy, due to their crucial role in Cosmology. The work is
based on a test campaign performed on simulated data. The classification was
carried out by comparing the performances among several Machine Learning
algorithms on statistical parameters extracted from the light curves. The
results make in evidence some critical aspects related to the data quality and
their parameter space characterization, propaedeutic to the preparation of
processing machinery for the real data exploitation in the incoming decade.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:49:37 GMT""},{""version"":""v2"",""created"":""Wed, 5 Aug 2020 15:43:07 GMT""},{""version"":""v3"",""created"":""Wed, 30 Sep 2020 17:12:13 GMT""}]","2021-05-12"
"2007.01241","Andrzej Sitarz","Arkadiusz Bochniak, Andrzej Sitarz and Pawe{\l} Zalecki","Riemannian Geometry of a Discretized Circle and Torus",,"SIGMA 16 (2020), 143, 28 pages","10.3842/SIGMA.2020.143",,"math-ph gr-qc hep-th math.MP math.QA","http://creativecommons.org/licenses/by-sa/4.0/","  We extend the results of Riemannian geometry over finite groups and provide a
full classification of all linear connections for the minimal noncommutative
differential calculus over a finite cyclic group. We solve the torsion-free and
metric compatibility condition in general and show that there are several
classes of solutions, out of which only special ones are compatible with a
metric that gives a Hilbert $C^\ast$-module structure on the space of the
one-forms. We compute curvature and scalar curvature for these metrics and find
their continuous limits.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:50:04 GMT""},{""version"":""v2"",""created"":""Wed, 23 Dec 2020 08:35:55 GMT""}]","2020-12-24"
"2007.01242","Benjamin Zorn","Benjamin Zorn, Tom Conte, Keith Marzullo, and Suresh
  Venkatasubramanian","Evolving Methods for Evaluating and Disseminating Computing Research","A Computing Community Consortium (CCC) white paper, 12 pages",,,"ccc2020whitepaper_2","cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social and technical trends have significantly changed methods for evaluating
and disseminating computing research. Traditional venues for reviewing and
publishing, such as conferences and journals, worked effectively in the past.
Recently, trends have created new opportunities but also put new pressures on
the process of review and dissemination. For example, many conferences have
seen large increases in the number of submissions. Likewise, dissemination of
research ideas has become dramatically through publication venues such as
arXiv.org and social media networks. While these trends predate COVID-19, the
pandemic could accelerate longer term changes. Based on interviews with leading
academics in computing research, our findings include: (1) Trends impacting
computing research are largely positive and have increased the participation,
scope, accessibility, and speed of the research process. (2) Challenges remain
in securing the integrity of the process, including addressing ways to scale
the review process, avoiding attempts to misinform or confuse the dissemination
of results, and ensuring fairness and broad participation in the process
itself. Based on these findings, we recommend: (1) Regularly polling members of
the computing research community, including program and general conference
chairs, journal editors, authors, reviewers, etc., to identify specific
challenges they face to better understand these issues. (2) An influential
body, such as the Computing Research Association regularly issues a ""State of
the Computing Research Enterprise"" report to update the community on trends,
both positive and negative, impacting the computing research enterprise. (3) A
deeper investigation, specifically to better understand the influence that
social media and preprint archives have on computing research, is conducted.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:50:28 GMT""}]","2020-07-03"
"2007.01243","Juan I. Forcen","J.I.Forcen, Miguel Pagola, Edurne Barrenechea and Humberto Bustince","Learning ordered pooling weights in image classification",,,"10.1016/j.neucom.2020.06.028",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spatial pooling is an important step in computer vision systems like
Convolutional Neural Networks or the Bag-of-Words method. The spatial pooling
purpose is to combine neighbouring descriptors to obtain a single descriptor
for a given region (local or global). The resultant combined vector must be as
discriminant as possible, in other words, must contain relevant information,
while removing irrelevant and confusing details. Maximum and average are the
most common aggregation functions used in the pooling step. To improve the
aggregation of relevant information without degrading their discriminative
power for image classification, we introduce a simple but effective scheme
based on Ordered Weighted Average (OWA) aggregation operators. We present a
method to learn the weights of the OWA aggregation operator in a Bag-of-Words
framework and in Convolutional Neural Networks, and provide an extensive
evaluation showing that OWA based pooling outperforms classical aggregation
operators.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:51:05 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 16:38:56 GMT""}]","2021-06-11"
"2007.01244","Alberto De Sole","Alberto De Sole, Mamuka Jibladze, Victor G. Kac, Daniele Valeri","Integrability of classical affine W-algebras","18 pages",,,,"math-ph math.MP math.RA math.RT nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that all classical affine W-algebras W(g,f), where g is a simple Lie
algebra and f is its non-zero nilpotent element, admit an integrable hierarchy
of bi-Hamiltonian PDEs, except possibly for one nilpotent conjugacy class in
G_2, one in F_4, and five in E_8.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:51:43 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 19:23:15 GMT""}]","2021-01-28"
"2007.01245","Fernanda Pinheiro","Fernanda Pinheiro, Omar Warsi, Dan I. Andersson, Michael L\""assig","Predicting trajectories and mechanisms of antibiotic resistance
  evolution","joint first authors: Fernanda Pinheiro, Omar Warsi; corresponding
  authors: Dan I. Andersson, Michael L\""assig",,,,"q-bio.PE physics.bio-ph q-bio.CB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bacteria evolve resistance to antibiotics by a multitude of mechanisms. A
central, yet unsolved question is how resistance evolution affects cell growth
at different drug levels. Here we develop a fitness model that predicts growth
rates of common resistance mutants from their effects on cell metabolism. We
map metabolic effects of resistance mutations in drug-free environments and
under drug challenge; the resulting fitness trade-off defines a Pareto surface
of resistance evolution. We predict evolutionary trajectories of
dosage-dependent growth rates and resistance levels, as well as the prevalent
resistance mechanism depending on drug and nutrient levels. These predictions
are confirmed by empirical growth curves and genomic data of E. coli
populations. Our results show that resistance evolution, by coupling major
metabolic pathways, is strongly intertwined with systems biology and ecology of
microbial populations.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:52:00 GMT""}]","2020-07-03"
"2007.01246","Ahmed Refaey Hussein","Jaspreet Singh, Yahuza Bello, Ahmed Refaey, and Amr Mohamed","Five-Layers SDP-Based Hierarchical Security Paradigm for Multi-access
  Edge Computing",,,,,"cs.NI cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rise in embedded and IoT device usage comes with an increase in LTE usage
as well. About 70\% of an estimated 18 billion IoT devices will be using
cellular LTE networks for efficient connections. This introduces several
challenges such as security, latency, scalability, and quality of service, for
which reason Edge Computing or Fog Computing has been introduced. The edge is
capable of offloading resources to the edge to reduce workload at the cloud.
Several security challenges come with Multi-access Edge Computing (MEC) such as
location-based attacks, the man in the middle attacks, and sniffing. This paper
proposes a Software-Defined Perimeter (SDP) framework to supplement MEC and
provide added security. The SDP is capable of protecting the cloud from the
edge by only authorizing authenticated users at the edge to access services in
the cloud. The SDP is implemented within a Mobile Edge LTE network. Delay
analysis of the implementation is performed, followed by a DoS attack to
demonstrate the resilience of the proposed SDP. Further analyses such as CPU
usage and Port Scanning were performed to verify the efficiency of the proposed
SDP. This analysis is followed by concluding remarks with insight into the
future of the SDP in MEC.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:52:36 GMT""}]","2020-07-03"
"2007.01247","Athanasios Kapoutsis Ch.","Dimitrios I. Koutras, Athanasios Ch. Kapoutsis and Elias B.
  Kosmatopoulos","Autonomous and cooperative design of the monitor positions for a team of
  UAVs to maximize the quantity and quality of detected objects","8 pages, 8 figures",,"10.1109/LRA.2020.3004780",,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper tackles the problem of positioning a swarm of UAVs inside a
completely unknown terrain, having as objective to maximize the overall
situational awareness. The situational awareness is expressed by the number and
quality of unique objects of interest, inside the UAVs' fields of view. YOLOv3
and a system to identify duplicate objects of interest were employed to assign
a single score to each UAVs' configuration. Then, a novel navigation algorithm,
capable of optimizing the previously defined score, without taking into
consideration the dynamics of either UAVs or environment, is proposed. A
cornerstone of the proposed approach is that it shares the same convergence
characteristics as the block coordinate descent (BCD) family of approaches. The
effectiveness and performance of the proposed navigation scheme were evaluated
utilizing a series of experiments inside the AirSim simulator. The experimental
evaluation indicates that the proposed navigation algorithm was able to
consistently navigate the swarm of UAVs to ""strategic"" monitoring positions and
also adapt to the different number of swarm sizes. Source code is available at
https://github.com/dimikout3/ConvCAOAirSim.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:52:57 GMT""}]","2020-07-03"
"2007.01248","Tan Nhat Tran","Tan Nhat Tran and Akiyoshi Tsuchiya","Worpitzky-compatible subarrangements of braid arrangements and
  cocomparability graphs","11 pages, comments are welcome!","Comptes Rendus. Math\'ematique 359 (2021), 665--674","10.5802/crmath.210",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The class of Worpitzky-compatible subarrangements of a Weyl arrangement
together with an associated Eulerian polynomial was recently introduced by
Ashraf, Yoshinaga and the first author, which brings the characteristic and
Ehrhart quasi-polynomials into one formula. The subarrangements of the braid
arrangement, the Weyl arrangement of type $A$, are known as the graphic
arrangements. We prove that the Worpitzky-compatible graphic arrangements are
characterized by cocomparability graphs. Our main result yields new formulas
for the chromatic and graphic Eulerian polynomials of cocomparability graphs.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:53:20 GMT""}]","2022-01-26"
"2007.01249","Markus Grassl","Markus Grassl","Entanglement-Assisted Quantum Communication Beating the Quantum
  Singleton Bound",,"Phys. Rev. A 103, 020601 (2021)","10.1103/PhysRevA.103.L020601",,"quant-ph cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Brun, Devetak, and Hsieh [Science 314, 436 (2006)] demonstrated that
pre-shared entanglement between sender and receiver enables quantum
communication protocols that have better parameters than schemes without the
assistance of entanglement. Subsequently, the same authors derived a version of
the so-called quantum Singleton bound that relates the parameters of the
entanglement-assisted quantum-error correcting codes proposed by them. We
present a new entanglement-assisted quantum communication scheme with
parameters violating this bound in certain ranges.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 16:57:07 GMT""}]","2021-03-03"
"2007.01250","David Hasler","David Hasler, Oliver Siebert","Ground States for translationally invariant Pauli-Fierz Models at zero
  Momentum",,,,,"math-ph math.FA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the translationally invariant Pauli-Fierz model describing a
charged particle interacting with the electromagnetic field. We show under
natural assumptions that the fiber Hamiltonian at zero momentum has a ground
state.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:00:57 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 15:15:24 GMT""}]","2021-07-05"
"2007.01251","Nicolas Basty","Nicolas Basty, Yi Liu, Madeleine Cule, E. Louise Thomas, Jimmy D. Bell
  and Brandon Whitcher","Image Processing and Quality Control for Abdominal Magnetic Resonance
  Imaging in the UK Biobank","Fixed 2 references",,,,"eess.IV cs.CV q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An end-to-end image analysis pipeline is presented for the abdominal MRI
protocol used in the UK Biobank on the first 38,971 participants. Emphasis is
on the processing steps necessary to ensure a high-level of data quality and
consistency is produced in order to prepare the datasets for downstream
quantitative analysis, such as segmentation and parameter estimation. Quality
control procedures have been incorporated to detect and, where possible,
correct issues in the raw data. Detection of fat-water swaps in the Dixon
series is performed by a deep learning model and corrected automatically. Bone
joints are predicted using a hybrid atlas-based registration and deep learning
model for the shoulders, hips and knees. Simultaneous estimation of proton
density fat fraction and transverse relaxivity (R2*) is performed using both
the magnitude and phase information for the single-slice multiecho series.
Approximately 98.1% of the two-point Dixon acquisitions were successfully
processed and passed quality control, with 99.98% of the high-resolution
T1-weighted 3D volumes succeeding. Approximately 99.98% of the single-slice
multiecho acquisitions covering the liver were successfully processed and
passed quality control, with 97.6% of the single-slice multiecho acquisitions
covering the pancreas succeeding. At least one fat-water swap was detected in
1.8% of participants. With respect to the bone joints, approximately 3.3% of
participants were missing at least one knee joint and 0.8% were missing at
least one shoulder joint. For the participants who received both single-slice
multiecho acquisition protocols for the liver a systematic difference between
the two protocols was identified and modeled using multiple linear regression.
The findings presented here will be invaluable for scientists who seek to use
image-derived phenotypes from the abdominal MRI protocol.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:01:25 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 07:29:04 GMT""}]","2020-07-17"
"2007.01252","Leon Kellerhals","Danny Hermelin, Leon Kellerhals, Rolf Niedermeier, and Rami Pugatch","Approximating Sparse Quadratic Programs",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a matrix $A \in \mathbb{R}^{n\times n}$, we consider the problem of
maximizing $x^TAx$ subject to the constraint $x \in \{-1,1\}^n$. This problem,
called MaxQP by Charikar and Wirth [FOCS'04], generalizes MaxCut and has
natural applications in data clustering and in the study of disordered magnetic
phases of matter. Charikar and Wirth showed that the problem admits an
$\Omega(1/\lg n)$ approximation via semidefinite programming, and Alon,
Makarychev, Makarychev, and Naor [STOC'05] showed that the same approach yields
an $\Omega(1)$ approximation when $A$ corresponds to a graph of bounded
chromatic number. Both these results rely on solving the semidefinite
relaxation of MaxQP, whose currently best running time is
$\tilde{O}(n^{1.5}\cdot \min\{N,n^{1.5}\})$, where $N$ is the number of nonzero
entries in $A$ and $\tilde{O}$ ignores polylogarithmic factors.
  In this sequel, we abandon the semidefinite approach and design purely
combinatorial approximation algorithms for special cases of MaxQP where $A$ is
sparse (i.e., has $O(n)$ nonzero entries). Our algorithms are superior to the
semidefinite approach in terms of running time, yet are still competitive in
terms of their approximation guarantees. More specifically, we show that:
  - MaxQP admits a $(1/2\Delta)$-approximation in $O(n \lg n)$ time, where
$\Delta$ is the maximum degree of the corresponding graph.
  - UnitMaxQP, where $A \in \{-1,0,1\}^{n\times n}$, admits a
$(1/2d)$-approximation in $O(n)$ time when the corresponding graph is
$d$-degenerate, and a $(1/3\delta)$-approximation in $O(n^{1.5})$ time when the
corresponding graph has $\delta n$ edges.
  - MaxQP admits a $(1-\varepsilon)$-approximation in $O(n)$ time when the
corresponding graph and each of its minors have bounded local treewidth.
  - UnitMaxQP admits a $(1-\varepsilon)$-approximation in $O(n^2)$ time when
the corresponding graph is $H$-minor free.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:02:04 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 10:16:30 GMT""},{""version"":""v3"",""created"":""Tue, 25 Aug 2020 16:41:30 GMT""},{""version"":""v4"",""created"":""Tue, 15 Dec 2020 11:11:09 GMT""}]","2020-12-16"
"2007.01253","Shasha Han","Shasha Han and Donald Rubin","Contrast Specific Propensity Scores",,"Biostatistics & Epidemiology 2021","10.1080/24709360.2021.1936421",,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Basic propensity score methodology is designed to balance multivariate
pre-treatment covariates when comparing one active treatment with one control
treatment. Practical settings often involve comparing more than two treatments,
where more complicated contrasts than the basic treatment-control one,(1,-1),
are relevant. Here, we propose the use of contrast-specific propensity scores
(CSPS). CSPS allow the creation of treatment groups of units that are balanced
with respect to bifurcations of the specified contrasts and the multivariate
space spanned by them.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:02:52 GMT""}]","2021-11-09"
"2007.01254","Martin Kilian","Frank Aurzada and Martin Kilian","Asymptotics of the persistence exponent of integrated fractional
  Brownian motion and fractionally integrated Brownian motion","Minor corrections",,"10.1137/S0040585X97T990769",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the persistence probability for the integrated fractional
Brownian motion and the fractionally integrated Brownian motion with parameter
$H,$ respectively. For the integrated fractional Brownian motion, we discuss a
conjecture of Molchan and Khokhlov and determine the asymptotic behavior of the
persistence exponent as $H\to 0$ and $H\to 1,$ which is in accordance with the
conjecture. For the fractionally integrated Brownian motion, also called
Riemann-Liouville process, we find the asymptotic behavior of the persistence
exponent as $H\to 0$.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:04:50 GMT""},{""version"":""v2"",""created"":""Fri, 4 Feb 2022 15:24:11 GMT""}]","2022-05-10"
"2007.01255","Toshiaki Koike-Akino","Andac Demir, Toshiaki Koike-Akino, Ye Wang, Deniz Erdogmus","AutoBayes: Automated Bayesian Graph Exploration for Nuisance-Robust
  Inference","24 pages, 11 figures, under review in ICLR2021",,,,"cs.LG eess.SP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning data representations that capture task-related features, but are
invariant to nuisance variations remains a key challenge in machine learning.
We introduce an automated Bayesian inference framework, called AutoBayes, that
explores different graphical models linking classifier, encoder, decoder,
estimator and adversarial network blocks to optimize nuisance-invariant machine
learning pipelines. AutoBayes also enables learning disentangled
representations, where the latent variable is split into multiple pieces to
impose various relationships with the nuisance variation and task labels. We
benchmark the framework on several public datasets, and provide analysis of its
capability for subject-transfer learning with/without variational modeling and
adversarial training. We demonstrate a significant performance improvement with
ensemble learning across explored graphical models.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:06:26 GMT""},{""version"":""v2"",""created"":""Mon, 5 Oct 2020 23:01:04 GMT""},{""version"":""v3"",""created"":""Mon, 30 Nov 2020 16:39:32 GMT""}]","2020-12-01"
"2007.01256","Kevin Conley","Kevin M. Conley, Vaibhav Thakore, Fahime Seyedheydari, Mikko Karttunen
  and Tapio Ala-Nissila","Directing Near-Infrared Photon Transport with Core@Shell Particles","10 pages, 7 figures",,,,"physics.app-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Directing the propagation of near-infrared radiation is a major concern in
improving the efficiency of solar cells and thermal insulators. A facile
approach to scatter light in the near-infrared region without excessive heating
is to embed compact layers with semiconductor particles. The directional
scattering by semiconductor@oxide (core@shell) spherical particles (containing
Si, InP, TiO$_2$, SiO$_2$, or ZrO$_2$) with a total radius varying from 0.1 to
4.0 {\mu}m and in an insulating medium at low volume fraction is investigated
using Lorenz-Mie theory and multiscale modelling. The optical response of each
layers is calculated under irradiation by the sun or a blackbody emitter at
1180 K. Reflectance efficiency factors of up to 83.7% and 63.9% are achieved
for near-infrared solar and blackbody radiation in 200 {\mu}m thick compact
layers with only 1% volume fraction of bare Si particles with a radius of 0.23
{\mu}m and 0.50 {\mu}m, respectively. The maximum solar and blackbody
efficiency factors of layers containing InP particles was slightly less (80.2%
and 60.7% for bare particles with a radius of 0.25 {\mu}m and 0.60 {\mu}m,
respectively). The addition of an oxide coating modifies the surrounding
dielectric environment, which improves the solar reflectance efficiency factor
to over 90% provided it matches the scattering mode energies with the incident
spectral density. The layers are spectrally-sensitive and can be applied as a
back or front reflector for solar devices, high temperature thermal insulators,
and optical filters in Gradient Heat Flux Sensors for fire safety applications.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:07:42 GMT""}]","2020-07-03"
"2007.01257","Mahdi Godazgar","Hadi Godazgar, Mahdi Godazgar, Malcolm J. Perry","Asymptotic gravitational charges","5 pages","Phys. Rev. Lett. 125, 101301 (2020)","10.1103/PhysRevLett.125.101301",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a method for finding, in principle, all asymptotic gravitational
charges. The basic idea is that one must consider all possible contributions to
the action that do not affect the equations of motion for the theory of
interest; such terms include topological terms. As a result we observe that the
first order formalism is best suited to an analysis of asymptotic charges. In
particular, this method can be used to provide a Hamiltonian derivation of
recently found dual charges.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:09:48 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 19:31:11 GMT""},{""version"":""v3"",""created"":""Fri, 18 Sep 2020 15:58:39 GMT""}]","2020-09-21"
"2007.01258","Tam\'as Rudas","Ori Davidov, Tamas Rudas","On the use of historical estimates",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of historical estimates in current studies is common in a wide
variety of application areas. Nevertheless, despite their routine use the
uncertainty associated with historical estimates is rarely properly accounted
for in the analysis. In this communication we review common practices and then
provide a mathematical formulation and a principled methodology for addressing
the problem of drawing inferences in the presence of historical data. Three
distinct variants are investigated in detail; the corresponding limiting
distributions are found and compared. The design of future studies, given
historical data, is also explored and relations with a variety of other
well--studied statistical problems discussed.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:10:30 GMT""}]","2020-07-03"
"2007.01259","Hui Xie","Hui Xie, Zhe Pan, Leixin Zhou, Fahim A Zaman, Danny Chen, Jost B
  Jonas, Yaxing Wang, and Xiaodong Wu","Globally Optimal Segmentation of Mutually Interacting Surfaces using
  Deep Learning","11 pages main content and reference, plus 10 pages appendix, total 21
  pages",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Segmentation of multiple surfaces in medical images is a challenging problem,
further complicated by the frequent presence of weak boundary and mutual
influence between adjacent objects. The traditional graph-based optimal surface
segmentation method has proven its effectiveness with its ability of capturing
various surface priors in a uniform graph model. However, its efficacy heavily
relies on handcrafted features that are used to define the surface cost for the
""goodness"" of a surface. Recently, deep learning (DL) is emerging as powerful
tools for medical image segmentation thanks to its superior feature learning
capability. Unfortunately, due to the scarcity of training data in medical
imaging, it is nontrivial for DL networks to implicitly learn the global
structure of the target surfaces, including surface interactions. In this work,
we propose to parameterize the surface cost functions in the graph model and
leverage DL to learn those parameters. The multiple optimal surfaces are then
simultaneously detected by minimizing the total surface cost while explicitly
enforcing the mutual surface interaction constraints. The optimization problem
is solved by the primal-dual Internal Point Method, which can be implemented by
a layer of neural networks, enabling efficient end-to-end training of the whole
network. Experiments on Spectral Domain Optical Coherence Tomography (SD-OCT)
retinal layer segmentation and Intravascular Ultrasound (IVUS) vessel wall
segmentation demonstrated very promising results. All source code is public to
facilitate further research at this direction.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:13:35 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 19:54:06 GMT""},{""version"":""v3"",""created"":""Tue, 21 Jul 2020 16:08:35 GMT""}]","2020-07-22"
"2007.01260","Nicolas Kourtellis Ph.D.","Nicolas Kourtellis and Herodotos Herodotou and Maciej Grzenda and
  Piotr Wawrzyniak and Albert Bifet","S2CE: A Hybrid Cloud and Edge Orchestrator for Mining Exascale
  Distributed Streams","11 pages, 4 figures, 2 tables",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The explosive increase in volume, velocity, variety, and veracity of data
generated by distributed and heterogeneous nodes such as IoT and other devices,
continuously challenge the state of art in big data processing platforms and
mining techniques. Consequently, it reveals an urgent need to address the
ever-growing gap between this expected exascale data generation and the
extraction of insights from these data. To address this need, this paper
proposes Stream to Cloud & Edge (S2CE), a first of its kind, optimized,
multi-cloud and edge orchestrator, easily configurable, scalable, and
extensible. S2CE will enable machine and deep learning over voluminous and
heterogeneous data streams running on hybrid cloud and edge settings, while
offering the necessary functionalities for practical and scalable processing:
data fusion and preprocessing, sampling and synthetic stream generation, cloud
and edge smart resource management, and distributed processing.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:14:57 GMT""}]","2020-07-03"
"2007.01261","Luyu Yang","Luyu Yang, Yogesh Balaji, Ser-Nam Lim, Abhinav Shrivastava","Curriculum Manager for Source Selection in Multi-Source Domain
  Adaptation",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The performance of Multi-Source Unsupervised Domain Adaptation depends
significantly on the effectiveness of transfer from labeled source domain
samples. In this paper, we proposed an adversarial agent that learns a dynamic
curriculum for source samples, called Curriculum Manager for Source Selection
(CMSS). The Curriculum Manager, an independent network module, constantly
updates the curriculum during training, and iteratively learns which domains or
samples are best suited for aligning to the target. The intuition behind this
is to force the Curriculum Manager to constantly re-measure the transferability
of latent domains over time to adversarially raise the error rate of the domain
discriminator. CMSS does not require any knowledge of the domain labels, yet it
outperforms other methods on four well-known benchmarks by significant margins.
We also provide interpretable results that shed light on the proposed method.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:15:01 GMT""}]","2020-07-03"
"2007.01262","Riccardo Catena","Riccardo Catena, Joakim Hagel and Carlos E. Yaguna","Probing P- and CP-violation in dark matter interactions","16 pages, 5 figures",,"10.1088/1475-7516/2021/05/016",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Discrete symmetries played a central role in elucidating the structure of the
weak interactions, and they will probably be equally crucial regarding the
interactions of the dark matter (DM) particle -- whose nature remains elusive.
In this work we show that signals in future direct detection experiments can be
used to test, in a model-independent way, for P- and CP-violation in DM-nucleus
interactions. The analysis is performed within the most general effective
theory for non-relativistic spin-0 DM-nucleus interactions mediated by the
exchange of a heavy particle. Assuming an idealised xenon detector, we
calculate the expected number of DM signal events required to reject P and CP
invariant DM-nucleus interactions. For a DM mass of 30 GeV (or higher), this
number lies between about 10 and 300 DM signal events, depending on how P and
CP invariance are modeled. Future direct detection experiments, therefore, have
the potential to reveal P- and CP-violation in DM interactions, making a
decisive step toward the identification of the DM particle.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:15:57 GMT""}]","2021-05-19"
"2007.01263","Matthew Cook","Matthew Cook, Alina Zare, Paul Gader","Outlier Detection through Null Space Analysis of Neural Networks","6 pages, 4 figures, Presented at the ICML 2020 Workshop on
  Uncertainty and Robustness in Deep Learning",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-sa/4.0/","  Many machine learning classification systems lack competency awareness.
Specifically, many systems lack the ability to identify when outliers (e.g.,
samples that are distinct from and not represented in the training data
distribution) are being presented to the system. The ability to detect outliers
is of practical significance since it can help the system behave in an
reasonable way when encountering unexpected data. In prior work, outlier
detection is commonly carried out in a processing pipeline that is distinct
from the classification model. Thus, for a complete system that incorporates
outlier detection and classification, two models must be trained, increasing
the overall complexity of the approach. In this paper we use the concept of the
null space to integrate an outlier detection method directly into a neural
network used for classification. Our method, called Null Space Analysis (NuSA)
of neural networks, works by computing and controlling the magnitude of the
null space projection as data is passed through a network. Using these
projections, we can then calculate a score that can differentiate between
normal and abnormal data. Results are shown that indicate networks trained with
NuSA retain their classification performance while also being able to detect
outliers at rates similar to commonly used outlier detection algorithms.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:17:21 GMT""}]","2020-07-03"
"2007.01264","Rico Zacher","Frederic Weber and Rico Zacher","The entropy method under curvature-dimension conditions in the spirit of
  Bakry-\'Emery in the discrete setting of Markov chains","60 pages",,,,"math.PR math.AP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider continuous-time (not necessarily finite) Markov chains on
discrete spaces and identify a curvature-dimension inequality, the condition
$CD_\Upsilon(\kappa,\infty)$, which serves as a natural analogue of the
classical Bakry-\'Emery condition $CD(\kappa,\infty)$ in several respects. In
particular, it is tailor-made to the classical approach of proofing the
modified logarithmic Sobolev inequality via computing and estimating the second
time derivative of the entropy along the heat flow generated by the generator
of the Markov chain. We prove that curvature bounds in the sense of
$CD_\Upsilon$ are preserved under tensorization, discuss links to other notions
of discrete curvature and consider a variety of examples including complete
graphs, the hypercube and birth-death processes. We further consider power type
entropies and determine, in the same spirit, a natural CD condition which leads
to Beckner inequalities. The $CD_\Upsilon$ condition is also shown to be
compatible with the diffusive setting, in the sense that corresponding hybrid
processes enjoy a tensorization property.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:18:35 GMT""}]","2020-07-03"
"2007.01265","Zhenyu Cai","Zhenyu Cai","Multi-exponential Error Extrapolation and Combining Error Mitigation
  Techniques for NISQ Applications",,"npj Quantum Inf 7, 80 (2021)","10.1038/s41534-021-00404-3",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noise in quantum hardware remains the biggest roadblock for the
implementation of quantum computers. To fight the noise in the practical
application of near-term quantum computers, instead of relying on quantum error
correction which requires large qubit overhead, we turn to quantum error
mitigation, in which we make use of extra measurements. Error extrapolation is
an error mitigation technique that has been successfully implemented
experimentally. Numerical simulation and heuristic arguments have indicated
that exponential curves are effective for extrapolation in the large circuit
limit with an expected circuit error count around unity. In this article, we
extend this to multi-exponential error extrapolation and provide more rigorous
proof for its effectiveness under Pauli noise. This is further validated via
our numerical simulations, showing orders of magnitude improvements in the
estimation accuracy over single-exponential extrapolation. Moreover, we develop
methods to combine error extrapolation with two other error mitigation
techniques: quasi-probability and symmetry verification, through exploiting
features of these individual techniques. As shown in our simulation, our
combined method can achieve low estimation bias with a sampling cost multiple
times smaller than quasi-probability while without needing to be able to adjust
the hardware error rate as required in canonical error extrapolation.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:18:47 GMT""},{""version"":""v2"",""created"":""Thu, 4 Mar 2021 17:38:54 GMT""}]","2021-10-14"
"2007.01266","Sven Linker","Sven Linker and Fabio Papacchini and Michele Sevegnani","Analysing Spatial Properties on Neighbourhood Spaces",,,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a bisimulation relation for neighbourhood spaces, a generalisation
of topological spaces. We show that this notion, path preserving bisimulation,
preserves formulas of the spatial logic SLCS. We then use this preservation
result to show that SLCS cannot express standard topological properties such as
separation and connectedness. Furthermore, we compare the bisimulation relation
with standard modal bisimulation and modal bisimulation with converse on graphs
and prove it coincides with the latter.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:18:58 GMT""}]","2020-07-03"
"2007.01267","Piotr Rozmej","Anna Karczewska and Piotr Rozmej","Generalized KdV-type equations versus Boussinesq's equations for uneven
  bottom -- numerical study","16 pages, 38 figures. Several misprints and references corrected","CMST 26(4) 121-136 (2020)","10.12921/cmst.2020.0000036",,"nlin.PS physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper's main goal is to compare the motion of solitary surface waves
resulting from two similar but slightly different approaches. In the first
approach, the numerical evolution of soliton surface waves moving over the
uneven bottom is obtained using single wave equations. In the second approach,
the numerical evolution of the same initial conditions is obtained by the
solution of a coupled set of the Boussinesq equations for the same Euler
equations system. We discuss four physically relevant cases of relationships
between small parameters $\alpha,\beta,\delta$. For the flat bottom, these
cases imply the Korteweg-de Vries equation (KdV), the extended KdV (KdV2),
fifth-order KdV (KdV5), and the Gardner equation (GE). In all studied cases,
the influence of the bottom variations on the amplitude and velocity of a
surface wave calculated from the Boussinesq equations is substantially more
significant than that obtained from single wave equations.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:21:57 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jul 2020 16:31:06 GMT""}]","2021-01-19"
"2007.01268","Fabiana Zama","Villiam Bortolotti, Germana Landi, Fabiana Zama","2DNMR data inversion using locally adapted multi-penalty regularization",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A crucial issue in two-dimensional Nuclear Magnetic Resonance (NMR) is the
speed and accuracy of the data inversion. This paper proposes a multi-penalty
method with locally adapted regularization parameters for fast and accurate
inversion of 2DNMR data.
  The method solves an unconstrained optimization problem whose objective
contains a data-fitting term, a single $L1$ penalty parameter and a multiple
parameter $L2$ penalty. We propose an adaptation of the Fast Iterative
Shrinkage and Thresholding (FISTA) method to solve the multi-penalty
minimization problem, and an automatic procedure to compute all the penalty
parameters. This procedure generalizes the Uniform Penalty principle introduced
in [Bortolotti et al., \emph{Inverse Problems}, 33(1), 2016].
  The proposed approach allows us to obtain accurate relaxation time
distributions while keeping short the computation time. Results of numerical
experiments on synthetic and real data prove that the proposed method is
efficient and effective in reconstructing the peaks and the flat regions that
usually characterize NMR relaxation time distributions.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:23:49 GMT""}]","2020-07-03"
"2007.01269","Adam Levine","John A. Baldwin, Nathan Dowlin, Adam Simon Levine, Tye Lidman, and
  Radmila Sazdanovic","Khovanov homology detects the figure-eight knot",,,"10.1112/blms.12467",,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using Dowlin's spectral sequence from Khovanov homology to knot Floer
homology, we prove that reduced Khovanov homology (over $\mathbb{Q}$) detects
the figure-eight knot.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:23:50 GMT""}]","2021-02-03"
"2007.01270","Alessio Maiezza","Alessio Maiezza, Juan Carlos Vasquez","Non-Wilsonian ultraviolet completion via transseries","25 pages, 1 figure, expanded version, accepted in Int. J. Mod. Phys.
  A",,"10.1142/S0217751X21500160",,"hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study some of the implications for the perturbative renormalization
program when augmented with the Borel-Ecalle resummation. We show the emergence
of a new kind of non-perturbative fixed point for the scalar $\phi^4$ model,
representing an ultraviolet self-completion by transseries. We argue that this
completion is purely non-Wilsonian and it depends on one arbitrary constant
stemming from the transseries solution of the renormalization group equation.
On the other hand, if no fixed points are demanded through the adjustment of
this arbitrary constant, we end up with an effective theory in which the scalar
mass is quadratically-sensitive to the cut-off, even working in dimensional
regularization. Complete decoupling of the scalar mass to this energy scale can
be used to determine a physical prescription for the Borel-Laplace resummation
of the renormalons in non-asymptotically free models. We also comment on
possible orthogonal scenarios available in the literature that might play a
role when no fixed points exist.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:24:05 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 13:57:34 GMT""},{""version"":""v3"",""created"":""Sat, 28 Nov 2020 15:46:06 GMT""}]","2021-02-24"
"2007.01271","Michael Fox","Michael F. J. Fox, Alexandra Werth, Jessica R. Hoehn, H. J.
  Lewandowski","Teaching labs during a pandemic: Lessons from Spring 2020 and an outlook
  for the future","24 pages, 6 figures",,,,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report results from a survey of lab instructors on how they adapted their
courses in the transition to emergency remote teaching due to the COVID-19
pandemic. The purpose of this report is to share the experiences of instructors
in order to prepare for future remote teaching of labs. We include summaries of
responses to help illustrate the types of lab activities that were done,
learning goals for the remote labs, motivations for instructors' choices,
challenges instructors faced, and ways in which instructors and students
communicated. This is a first step in a larger project as part of an NSF RAPID
grant to understand what happened during the switch to remote labs and how it
impacted teaching methods and student learning.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:24:11 GMT""}]","2020-07-03"
"2007.01272","S\'ebastien Ehrhardt","Sebastien Ehrhardt and Oliver Groth and Aron Monszpart and Martin
  Engelcke and Ingmar Posner and Niloy Mitra and Andrea Vedaldi","RELATE: Physically Plausible Multi-Object Scene Synthesis Using
  Structured Latent Spaces",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present RELATE, a model that learns to generate physically plausible
scenes and videos of multiple interacting objects. Similar to other generative
approaches, RELATE is trained end-to-end on raw, unlabeled data. RELATE
combines an object-centric GAN formulation with a model that explicitly
accounts for correlations between individual objects. This allows the model to
generate realistic scenes and videos from a physically-interpretable
parameterization. Furthermore, we show that modeling the object correlation is
necessary to learn to disentangle object positions and identity. We find that
RELATE is also amenable to physically realistic scene editing and that it
significantly outperforms prior art in object-centric scene generation in both
synthetic (CLEVR, ShapeStacks) and real-world data (cars). In addition, in
contrast to state-of-the-art methods in object-centric generative modeling,
RELATE also extends naturally to dynamic scenes and generates videos of high
visual fidelity. Source code, datasets and more results are available at
http://geometry.cs.ucl.ac.uk/projects/2020/relate/.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:27:27 GMT""},{""version"":""v2"",""created"":""Mon, 9 Nov 2020 18:03:58 GMT""}]","2020-11-10"
"2007.01273","Waleed Raza","Waleed Raza, Xuefei Ma, Amir Ali, Zubair Ali Shah, Ghazanfar Mehdi","An Implementation of Partial Transmit Sequences to Design Energy
  Efficient Underwater Acoustic OFDM Communication System",,"International Journal of Computer Science and Information Security
  (IJCSIS), Vol. 18, No. 4, April 2020",,,"eess.SP cs.CE cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we research about underwater acoustics transceivers. As
Underwater acoustic transceivers consume more power than Radio frequency
transceivers. The techniques which are being utilized in radio frequency cannot
be implemented directly in underwater acoustic system it needs to be re
investigated to design new methods. To achieve reliable acoustic data
transmission new techniques should be achieved or the traditional Orthogonal
frequency divisional multiplexing techniques should be revised. The power
consumption also relies upon underwater acoustic signal propagation and
transmission distances. Several underwater acoustic applications require
long-term monitoring of the sea. For the battery powered modems, it becomes
very serious problem. By designing an Energy efficient OFDM Communication
system we can solve this problem. We study about peak to average power ratio in
an Orthogonal frequency divisional multiplexing system by reducing the major
draw-back of OFDM system. The PAPR reduction utilized in this paper is Partial
Transmit Sequences for underwater acoustic OFDM communication system which has
lesser complexity. The results have provided better performance in underwater
acoustic OFDM communication system.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:29:06 GMT""}]","2020-07-03"
"2007.01274","Vitalii Makogin","Vitalii Makogin, Yuliya Mishura, Hanna Zhelezniak","Approximate solution of the integral equations involving kernel with
  additional singularity",,,,,"math.PR cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper is devoted to the approximate solutions of the Fredholm integral
equations of the second kind with the weak singular kernel that can have
additional singularity in the numerator. We describe two problems that lead to
such equations. They are the problem of minimization of small deviation and the
entropy minimization problem. Both of them appear when considering dynamical
system involving mixed fractional Brownian motion. In order to deal with the
kernel with additional singularity applying well-known methods for weakly
singular kernels, we prove the theorem on the approximation of solution of
integral equation with the kernel containing additional singularity by the
solutions of the integral equations whose kernels are weakly singular but the
numerator is continuous. We demonstrate numerically how our methods work being
applied to our specific integral equations.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:32:01 GMT""}]","2020-07-03"
"2007.01275","Yujie Xu","Yujie Xu","Normalization in integral models of Shimura varieties of Hodge type","15 pages",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $(G,X)$ be a Shimura datum of Hodge type, and $\mathscr{S}_K(G,X)$ its
integral model with hyperspecial (resp. parahoric, assuming the group is
unramified) level structure. We prove that $\mathscr{S}_K(G,X)$ admits a closed
embedding, which is compatible with moduli interpretations, into the integral
model $\mathscr{S}_{K'}(\mathrm{GSp},S^{\pm})$ for a Siegel modular variety. In
particular, the normalization step in the construction of $\mathscr{S}_K(G,X)$
is redundant. In particular, our results apply to the earlier integral models
constructed by Rapoport, Kottwitz etc. (resp. Rapoport-Zink etc.), as those
models agree with the Hodge type integral models for appropriately chosen
Shimura data.
  Moreover, combined with a result of Lan's on the boundary components of
toroidal compactifications of integral models, our result also implies that
there exist closed embeddings of toroidal compactifications of integral models
of Hodge type into toroidal compactifications of Siegel integral models, for
suitable choices of cone decompositions.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:33:49 GMT""},{""version"":""v2"",""created"":""Thu, 2 Dec 2021 18:53:48 GMT""}]","2021-12-03"
"2007.01276","Navid Ghassemi","Afshin Shoeibi, Marjane Khodatars, Navid Ghassemi, Mahboobeh Jafari,
  Parisa Moridian, Roohallah Alizadehsani, Maryam Panahiazar, Fahime Khozeimeh,
  Assef Zare, Hossein Hosseini-Nejad, Abbas Khosravi, Amir F. Atiya, Diba
  Aminshahidi, Sadiq Hussain, Modjtaba Rouhani, Saeid Nahavandi, Udyavara
  Rajendra Acharya","Epileptic Seizures Detection Using Deep Learning Techniques: A Review",,"International Journal of Environmental Research and Public Health.
  2021; 18(11):5780","10.3390/ijerph18115780",,"cs.LG eess.SP stat.ML","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A variety of screening approaches have been proposed to diagnose epileptic
seizures, using electroencephalography (EEG) and magnetic resonance imaging
(MRI) modalities. Artificial intelligence encompasses a variety of areas, and
one of its branches is deep learning (DL). Before the rise of DL, conventional
machine learning algorithms involving feature extraction were performed. This
limited their performance to the ability of those handcrafting the features.
However, in DL, the extraction of features and classification are entirely
automated. The advent of these techniques in many areas of medicine, such as in
the diagnosis of epileptic seizures, has made significant advances. In this
study, a comprehensive overview of works focused on automated epileptic seizure
detection using DL techniques and neuroimaging modalities is presented. Various
methods proposed to diagnose epileptic seizures automatically using EEG and MRI
modalities are described. In addition, rehabilitation systems developed for
epileptic seizures using DL have been analyzed, and a summary is provided. The
rehabilitation tools include cloud computing techniques and hardware required
for implementation of DL algorithms. The important challenges in accurate
detection of automated epileptic seizures using DL with EEG and MRI modalities
are discussed. The advantages and limitations in employing DL-based techniques
for epileptic seizures diagnosis are presented. Finally, the most promising DL
models proposed and possible future works on automated epileptic seizure
detection are delineated.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:34:02 GMT""},{""version"":""v2"",""created"":""Sun, 26 Jul 2020 17:50:58 GMT""},{""version"":""v3"",""created"":""Sat, 29 May 2021 14:18:28 GMT""}]","2021-06-01"
"2007.01277","Ao Li","Ao Li, Bojian Zheng, Gennady Pekhimenko, and Fan Long","Automatic Horizontal Fusion for GPU Kernels",,,,,"cs.DC cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present automatic horizontal fusion, a novel optimization technique that
complements the standard kernel fusion techniques for GPU programs. Unlike the
standard fusion, whose goal is to eliminate intermediate data round trips, our
horizontal fusion technique aims to increase the thread-level parallelism to
hide instruction latencies. We also present HFuse, a new source to source CUDA
compiler that implements automatic horizontal fusion. Our experimental results
show that horizontal fusion can speed up the running time by 2.5%-60.8%. Our
results reveal that the horizontal fusion is especially beneficial for fusing
kernels with instructions that require different kinds of GPU resources (e.g.,
a memory-intensive kernel and a compute-intensive kernel).
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:34:07 GMT""}]","2020-07-03"
"2007.01278","Quanhao Zhang","Quanhao Zhang, Yuming Wang, Rui Liu, Jie Zhang, Youqiu Hu, Wensi Wang,
  Bin Zhuang, Xiaolei Li","Eruption of Solar Magnetic Flux Ropes Caused by Flux Feeding","This paper has been accepted by ApJL",,"10.3847/2041-8213/aba1f3",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale solar eruptions are believed to have a magnetic flux rope as the
core structure. However, it remains elusive as to how the flux rope builds up
and what triggers its eruption. Recent observations found that a prominence
erupted following multiple episodes of ""flux feeding"". During each episode, a
chromospheric fibril rose and merged with the prominence lying above. In this
letter, we carried out 2.5-dimensional magnetohydrodynamic (MHD) numerical
simulations to investigate whether the flux-feeding mechanism can explain such
an eruption. The simulations demonstrate that the discrete emergence of small
flux ropes can initiate eruptions by feeding axial flux into the preexistent
flux rope until its total axial flux reaches a critical value. The onset of the
eruption is dominated by an ideal MHD process. Our simulation results
corroborate that the flux feeding is a viable mechanism to cause the eruption
of solar magnetic flux ropes.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:34:13 GMT""}]","2020-07-29"
"2007.01279","Rasmus Tamstorf","Joseph Benzaken, John A. Evans, Stephen McCormick, Rasmus Tamstorf","Weak Boundary Condition Enforcement for Linear Kirchhoff-Love Shells:
  Formulation, Error Analysis, and Verification","51 pages, 9 figures",,"10.1016/j.cma.2020.113544",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stable and accurate modeling of thin shells requires proper enforcement of
all types of boundary conditions. Unfortunately, for Kirchhoff-Love shells,
strong enforcement of Dirichlet boundary conditions is difficult because both
functional and derivative boundary conditions must be applied. A popular
alternative is to employ Nitsche's method to weakly enforce all boundary
conditions. However, while many Nitsche-based formulations have been proposed
in the literature, they lack comprehensive error analyses and verifications. In
fact, existing formulations are variationally inconsistent and yield
sub-optimal convergence rates when used with common boundary condition
specifications. In this paper, we present a novel Nitsche-based formulation for
the linear Kirchhoff-Love shell that is provably stable and optimally
convergent for general sets of admissible boundary conditions. To arrive at our
formulation, we first present a framework for constructing Nitsche's method for
any abstract variational constrained minimization problem. We then apply this
framework to the linear Kirchhoff-Love shell and, for the particular case of
NURBS-based isogeometric analysis, we prove that the resulting formulation
yields optimal convergence rates in both the shell energy norm and the standard
$L^2$-norm. In the process, we derive the Euler-Lagrange equations for general
sets of admissible boundary conditions and show that the Euler-Lagrange
boundary conditions typically presented in the literature is incorrect. We
verify our formulation by manufacturing solutions for a new shell obstacle
course that encompasses flat, parabolic, hyperbolic, and elliptic geometric
configurations. These manufactured solutions allow us to robustly measure the
error across the entire shell in contrast with current best practices where
displacement and stress errors are only measured at specific locations.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:35:35 GMT""}]","2020-12-30"
"2007.01280","Nikhil Kumar","Nikhil Kumar","Multicommodity Flows in Planar Graphs with Demands on Faces",,,,,"cs.DS cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of multicommodity flows in planar graphs. Seymour
showed that if the union of supply and demand graphs is planar, then the cut
condition is sufficient for routing demands. Okamura-Seymour showed that if all
demands are incident on one face, then again cut condition is sufficient for
routing demands. We consider a common generalization of these settings where
the end points of each demand are on the same face of the planar graph. We show
that if the source sink pairs on each face of the graph are such that sources
and sinks appear contiguously on the cycle bounding the face, then the flow cut
gap is at most 3. We come up with a notion of approximating demands on a face
by convex combination of laminar demands to prove this result.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:37:01 GMT""}]","2020-07-03"
"2007.01281","Art Owen","Christopher Hoyt and Art B. Owen","Efficient estimation of the ANOVA mean dimension, with an application to
  neural net classification",,,,,"stat.ME cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mean dimension of a black box function of $d$ variables is a convenient
way to summarize the extent to which it is dominated by high or low order
interactions. It is expressed in terms of $2^d-1$ variance components but it
can be written as the sum of $d$ Sobol' indices that can be estimated by leave
one out methods. We compare the variance of these leave one out methods: a
Gibbs sampler called winding stairs, a radial sampler that changes each
variable one at a time from a baseline, and a naive sampler that never reuses
function evaluations and so costs about double the other methods. For an
additive function the radial and winding stairs are most efficient. For a
multiplicative function the naive method can easily be most efficient if the
factors have high kurtosis. As an illustration we consider the mean dimension
of a neural network classifier of digits from the MNIST data set. The
classifier is a function of $784$ pixels. For that problem, winding stairs is
the best algorithm. We find that inputs to the final softmax layer have mean
dimensions ranging from $1.35$ to $2.0$.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:44:10 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jul 2020 05:43:20 GMT""},{""version"":""v3"",""created"":""Mon, 28 Sep 2020 17:43:56 GMT""},{""version"":""v4"",""created"":""Wed, 30 Dec 2020 20:54:40 GMT""}]","2021-01-01"
"2007.01282","Gautier Izacard","Gautier Izacard and Edouard Grave","Leveraging Passage Retrieval with Generative Models for Open Domain
  Question Answering",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative models for open domain question answering have proven to be
competitive, without resorting to external knowledge. While promising, this
approach requires to use models with billions of parameters, which are
expensive to train and query. In this paper, we investigate how much these
models can benefit from retrieving text passages, potentially containing
evidence. We obtain state-of-the-art results on the Natural Questions and
TriviaQA open benchmarks. Interestingly, we observe that the performance of
this method significantly improves when increasing the number of retrieved
passages. This is evidence that generative models are good at aggregating and
combining evidence from multiple passages.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:44:57 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 09:18:34 GMT""}]","2021-02-04"
"2007.01283","Lu Zhang","Lu Zhang and Lucas Janson","Floodgate: inference for model-free variable importance",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many modern applications seek to understand the relationship between an
outcome variable $Y$ and a covariate $X$ in the presence of a (possibly
high-dimensional) confounding variable $Z$. Although much attention has been
paid to testing \emph{whether} $Y$ depends on $X$ given $Z$, in this paper we
seek to go beyond testing by inferring the \emph{strength} of that dependence.
We first define our estimand, the minimum mean squared error (mMSE) gap, which
quantifies the conditional relationship between $Y$ and $X$ in a way that is
deterministic, model-free, interpretable, and sensitive to nonlinearities and
interactions. We then propose a new inferential approach called
\emph{floodgate} that can leverage any working regression function chosen by
the user (allowing, e.g., it to be fitted by a state-of-the-art machine
learning algorithm or be derived from qualitative domain knowledge) to
construct asymptotic confidence bounds, and we apply it to the mMSE gap.
\acc{We additionally show that floodgate's accuracy (distance from confidence
bound to estimand) is adaptive to the error of the working regression
function.} We then show we can apply the same floodgate principle to a
different measure of variable importance when $Y$ is binary. Finally, we
demonstrate floodgate's performance in a series of simulations and apply it to
data from the UK Biobank to infer the strengths of dependence of platelet count
on various groups of genetic mutations.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:47:58 GMT""},{""version"":""v2"",""created"":""Fri, 28 Aug 2020 20:19:41 GMT""},{""version"":""v3"",""created"":""Tue, 27 Apr 2021 03:00:55 GMT""},{""version"":""v4"",""created"":""Fri, 15 Oct 2021 00:44:47 GMT""},{""version"":""v5"",""created"":""Mon, 12 Sep 2022 04:28:39 GMT""}]","2022-09-13"
"2007.01284","Zichong Li","Zichong Li and Pin-Yu Chen and Sijia Liu and Songtao Lu and Yangyang
  Xu","Rate-improved Inexact Augmented Lagrangian Method for Constrained
  Nonconvex Optimization","AISTATS 2021",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  First-order methods have been studied for nonlinear constrained optimization
within the framework of the augmented Lagrangian method (ALM) or penalty
method. We propose an improved inexact ALM (iALM) and conduct a unified
analysis for nonconvex problems with either affine equality or nonconvex
constraints. Under certain regularity conditions (that are also assumed by
existing works), we show an $\tilde{O}(\varepsilon^{-\frac{5}{2}})$ complexity
result for a problem with a nonconvex objective and affine equality constraints
and an $\tilde{O}(\varepsilon^{-3})$ complexity result for a problem with a
nonconvex objective and nonconvex constraints, where the complexity is measured
by the number of first-order oracles to yield an $\varepsilon$-KKT solution.
Both results are the best known. The same-order complexity results have been
achieved by penalty methods. However, two different analysis techniques are
used to obtain the results, and more importantly, the penalty methods generally
perform significantly worse than iALM in practice. Our improved iALM and
analysis close the gap between theory and practice. Numerical experiments on
nonconvex problems with affine equality or nonconvex constraints are provided
to demonstrate the effectiveness of our proposed method.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:49:17 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 01:03:23 GMT""}]","2021-03-25"
"2007.01285","Navid Ghassemi","Marjane Khodatars, Afshin Shoeibi, Delaram Sadeghi, Navid Ghassemi,
  Mahboobeh Jafari, Parisa Moridian, Ali Khadem, Roohallah Alizadehsani, Assef
  Zare, Yinan Kong, Abbas Khosravi, Saeid Nahavandi, Sadiq Hussain, U. Rajendra
  Acharya, Michael Berk","Deep Learning for Neuroimaging-based Diagnosis and Rehabilitation of
  Autism Spectrum Disorder: A Review",,"Computers in Biology and Medicine, Volume 139, 2021, 104949","10.1016/j.compbiomed.2021.104949",,"cs.LG eess.IV stat.ML","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Accurate diagnosis of Autism Spectrum Disorder (ASD) followed by effective
rehabilitation is essential for the management of this disorder. Artificial
intelligence (AI) techniques can aid physicians to apply automatic diagnosis
and rehabilitation procedures. AI techniques comprise traditional machine
learning (ML) approaches and deep learning (DL) techniques. Conventional ML
methods employ various feature extraction and classification techniques, but in
DL, the process of feature extraction and classification is accomplished
intelligently and integrally. DL methods for diagnosis of ASD have been focused
on neuroimaging-based approaches. Neuroimaging techniques are non-invasive
disease markers potentially useful for ASD diagnosis. Structural and functional
neuroimaging techniques provide physicians substantial information about the
structure (anatomy and structural connectivity) and function (activity and
functional connectivity) of the brain. Due to the intricate structure and
function of the brain, proposing optimum procedures for ASD diagnosis with
neuroimaging data without exploiting powerful AI techniques like DL may be
challenging. In this paper, studies conducted with the aid of DL networks to
distinguish ASD are investigated. Rehabilitation tools provided for supporting
ASD patients utilizing DL networks are also assessed. Finally, we will present
important challenges in the automated detection and rehabilitation of ASD and
propose some future works.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:49:19 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jul 2020 17:23:17 GMT""},{""version"":""v3"",""created"":""Sun, 26 Jul 2020 17:31:24 GMT""},{""version"":""v4"",""created"":""Mon, 1 Nov 2021 08:04:11 GMT""}]","2021-11-02"
"2007.01286","Bruno Bertini","Bruno Bertini and Pasquale Calabrese","Prethermalisation and Thermalisation in the Entanglement Dynamics","15 pages, 8 figures; v2 as appears in Phys. Rev. B","Phys. Rev. B 102, 094303 (2020)","10.1103/PhysRevB.102.094303",,"cond-mat.stat-mech cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the crossover of the entanglement entropy towards its thermal
value in nearly integrable systems. We employ equation of motion techniques to
study the entanglement dynamics in a lattice model of weakly interacting
spinless fermions after a quantum quench. For weak enough interactions we
observe a two-step relaxation of the entanglement entropies of finite
subsystems. Initially the entropies follow a nearly integrable evolution,
approaching the value predicted by the Generalized Gibbs Ensemble (GGE) of the
unperturbed model. Then, they start a slow drift towards the thermal stationary
value described by a standard Gibbs Ensemble (GE). While the initial relaxation
to the GGE is independent of the interaction, the slow drift from GGE to GE
values happens on time scales proportional to the inverse interaction squared.
For asymptotically large times and subsystem sizes the dynamics of the
entropies can be predicted using a modified quasiparticle picture that keeps
track of the evolution of the fermionic occupations caused by the integrability
breaking. This picture gives a quantitative description of the results as long
as the integrability-breaking timescale is much larger than the one associated
with the (quasi) saturation to the GGE. In the opposite limit the quasiparticle
picture still provides the correct late-time behaviour, but it underestimates
the initial slope of the entanglement entropy.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:52:25 GMT""},{""version"":""v2"",""created"":""Wed, 9 Sep 2020 17:30:06 GMT""}]","2020-09-10"
"2007.01287","Sergey Filippov","Ilia A. Luchnikov, Mikhail E. Krechetov, Sergey N. Filippov","Riemannian geometry and automatic differentiation for optimization
  problems of quantum physics and quantum technologies","27 pages, 15 figures, a note on relevant research is added","New J. Phys. 23, 073006 (2021)","10.1088/1367-2630/ac0b02",,"quant-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimization with constraints is a typical problem in quantum physics and
quantum information science that becomes especially challenging for
high-dimensional systems and complex architectures like tensor networks. Here
we use ideas of Riemannian geometry to perform optimization on manifolds of
unitary and isometric matrices as well as the cone of positive-definite
matrices. Combining this approach with the up-to-date computational methods of
automatic differentiation, we demonstrate the efficacy of the Riemannian
optimization in the study of the low-energy spectrum and eigenstates of
multipartite Hamiltonians, variational search of a tensor network in the form
of the multiscale entanglement-renormalization ansatz, preparation of arbitrary
states (including highly entangled ones) in the circuit implementation of
quantum computation, decomposition of quantum gates, and tomography of quantum
states. Universality of the developed approach together with the provided open
source software enable one to apply the Riemannian optimization to complex
quantum architectures well beyond the listed problems, for instance, to the
optimal control of noisy quantum systems.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:53:01 GMT""},{""version"":""v2"",""created"":""Thu, 10 Dec 2020 16:50:17 GMT""},{""version"":""v3"",""created"":""Thu, 1 Jul 2021 10:16:26 GMT""},{""version"":""v4"",""created"":""Wed, 17 Nov 2021 12:17:50 GMT""}]","2021-11-18"
"2007.01288","David Mestel","David Mestel","Robust ambiguity for contact tracing","5 pages",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A known drawback of `decentralised' contact tracing architectures is that
users who have been in contact with an infected person are able to precisely
identify the relevant contact, and thereby perhaps identify the infected
person. In their proposal, the PACT team discuss a simple DH-based protocol to
mitigate this problem, but dismiss it because it is vulnerable to a malicious
user who may deviate from the specified behaviour. This note presents a
modified protocol which achieves robustness against a fully malicious user, and
establishes some simple security properties.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:54:05 GMT""}]","2020-07-03"
"2007.01289","Eliahu Horwitz","Yael Vinker and Eliahu Horwitz and Nir Zabari and Yedid Hoshen","Image Shape Manipulation from a Single Augmented Training Sample","ICCV 2021 (Oral). Project page: http://www.vision.huji.ac.il/deepsim/",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present DeepSIM, a generative model for conditional image
manipulation based on a single image. We find that extensive augmentation is
key for enabling single image training, and incorporate the use of
thin-plate-spline (TPS) as an effective augmentation. Our network learns to map
between a primitive representation of the image to the image itself. The choice
of a primitive representation has an impact on the ease and expressiveness of
the manipulations and can be automatic (e.g. edges), manual (e.g. segmentation)
or hybrid such as edges on top of segmentations. At manipulation time, our
generator allows for making complex image changes by modifying the primitive
input representation and mapping it through the network. Our method is shown to
achieve remarkable performance on image manipulation tasks.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:55:27 GMT""},{""version"":""v2"",""created"":""Thu, 25 Nov 2021 14:02:24 GMT""}]","2021-11-30"
"2007.01290","Luofeng Liao","Luofeng Liao, You-Lin Chen, Zhuoran Yang, Bo Dai, Zhaoran Wang, Mladen
  Kolar","Provably Efficient Neural Estimation of Structural Equation Model: An
  Adversarial Approach","- v1: Submitted to NeurIPS 2020. Under review - v2: Revised after
  NeurIPS reviews. Major updates: (i) clean presentation of consistency
  results; (ii) more references for conditional moment problems - v3: Add
  references",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Structural equation models (SEMs) are widely used in sciences, ranging from
economics to psychology, to uncover causal relationships underlying a complex
system under consideration and estimate structural parameters of interest. We
study estimation in a class of generalized SEMs where the object of interest is
defined as the solution to a linear operator equation. We formulate the linear
operator equation as a min-max game, where both players are parameterized by
neural networks (NNs), and learn the parameters of these neural networks using
the stochastic gradient descent. We consider both 2-layer and multi-layer NNs
with ReLU activation functions and prove global convergence in an
overparametrized regime, where the number of neurons is diverging. The results
are established using techniques from online learning and local linearization
of NNs, and improve in several aspects the current state-of-the-art. For the
first time we provide a tractable estimation procedure for SEMs based on NNs
with provable convergence and without the need for sample splitting.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:55:47 GMT""},{""version"":""v2"",""created"":""Tue, 18 Aug 2020 17:07:08 GMT""},{""version"":""v3"",""created"":""Tue, 20 Oct 2020 16:56:32 GMT""}]","2020-10-21"
"2007.01291","Janne Nevalaita Dr","Janne Nevalaita and Pekka Koskinen","Free-standing 2D metals from binary metal alloys","4 pages, 4 figures","AIP Advances 10, 065327 (2020)","10.1063/5.0010884",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experiment demonstrated the formation of free-standing Au monolayers
by exposing Au-Ag alloy to electron beam irradiation. Inspired by this
discovery, we used semi-empirical effective medium theory simulations to
investigate monolayer formation in 30 different binary metal alloys composed of
late d-series metals Ni, Cu, Pd, Ag, Pt, and Au. In qualitative agreement with
the experiment, we find that the beam energy required to dealloy Ag atoms from
Au-Ag alloy is smaller than the energy required to break the dealloyed Au
monolayer. Our simulations suggest that similar method could also be used to
form Au monolayers from Au-Cu alloy and Pt monolayers from Pt-Cu, Pt-Ni, and
Pt-Pd alloys.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:57:33 GMT""}]","2020-07-03"
"2007.01292","Roger Ianjamasimanana","Roger Ianjamasimanana, Brenda Namumba, Athanaseus J. T. Ramaila, Anna
  S. Saburova, Gyula I. G. Jozsa, Talon Myburgh, Kshitij Thorat, Claude
  Carignan, Eric Maina, W. J. G. de Blok, Lexy A. L. Andati, Benjamin V. Hugo,
  Dane Kleiner, Peter Kamphuis, Paolo Serra, Oleg M. Smirnov, Filippo M.
  Maccagni, Sphesihle Makhathini, Daniel Cs. Molnar, Simon Perkins, Mpati
  Ramatsoku, Sarah V. White","MeerKAT-16 HI observation of the dIrr galaxy WLM","Accepted for publication in MNRAS, 25 pages, 21 figures, 5 tables",,"10.1093/mnras/staa1967",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present observations and models of the kinematics and the distribution of
the neutral hydrogen (HI) in the isolated dwarf irregular galaxy,
Wolf-Lundmark-Melotte (WLM). We observed WLM with the Green Bank Telescope
(GBT) and as part of the MeerKAT Early Science Programme, where 16 dishes were
available. The HI disc of WLM extends out to a major axis diameter of 30 arcmin
(8.5 kpc), and a minor axis diameter of 20 arcmin (5.6 kpc) as measured by the
GBT. We use the MeerKAT data to model WLM using the TiRiFiC software suite,
allowing us to fit different tilted-ring models and select the one that best
matches the observation. Our final best-fitting model is a flat disc with a
vertical thickness, a constant inclination and dispersion, and a
radially-varying surface brightness with harmonic distortions. To simulate
bar-like motions, we include second-order harmonic distortions in velocity in
the tangential and the vertical directions. We present a model with only
circular motions included and a model with non-circular motions. The latter
describes the data better. Overall, the models reproduce the global
distribution and the kinematics of the gas, except for some faint emission at
the 2-sigma level. We model the mass distribution of WLM with a
pseudo-isothermal (ISO) and a Navarro-Frenk-White (NFW) dark matter halo
models. The NFW and the ISO models fit the derived rotation curves within the
formal errors, but with the ISO model giving better reduced chi-square values.
The mass distribution in WLM is dominated by dark matter at all radii.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:58:39 GMT""}]","2020-07-15"
"2007.01293","Zhongzheng Ren","Zhongzheng Ren, Raymond A. Yeh, Alexander G. Schwing","Not All Unlabeled Data are Equal: Learning to Weight Data in
  Semi-supervised Learning","NeurIPS camera ready",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing semi-supervised learning (SSL) algorithms use a single weight to
balance the loss of labeled and unlabeled examples, i.e., all unlabeled
examples are equally weighted. But not all unlabeled data are equal. In this
paper we study how to use a different weight for every unlabeled example.
Manual tuning of all those weights -- as done in prior work -- is no longer
possible. Instead, we adjust those weights via an algorithm based on the
influence function, a measure of a model's dependency on one training example.
To make the approach efficient, we propose a fast and effective approximation
of the influence function. We demonstrate that this technique outperforms
state-of-the-art methods on semi-supervised image and language classification
tasks.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:59:05 GMT""},{""version"":""v2"",""created"":""Thu, 29 Oct 2020 04:29:54 GMT""}]","2020-10-30"
"2007.01294","Han Hu","Ze Liu and Han Hu and Yue Cao and Zheng Zhang and Xin Tong","A Closer Look at Local Aggregation Operators in Point Cloud Analysis","Code available at https://github.com/zeliu98/CloserLook3D",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances of network architecture for point cloud processing are mainly
driven by new designs of local aggregation operators. However, the impact of
these operators to network performance is not carefully investigated due to
different overall network architecture and implementation details in each
solution. Meanwhile, most of operators are only applied in shallow
architectures. In this paper, we revisit the representative local aggregation
operators and study their performance using the same deep residual
architecture. Our investigation reveals that despite the different designs of
these operators, all of these operators make surprisingly similar contributions
to the network performance under the same network input and feature numbers and
result in the state-of-the-art accuracy on standard benchmarks. This finding
stimulate us to rethink the necessity of sophisticated design of local
aggregation operator for point cloud processing. To this end, we propose a
simple local aggregation operator without learnable weights, named Position
Pooling (PosPool), which performs similarly or slightly better than existing
sophisticated operators. In particular, a simple deep residual network with
PosPool layers achieves outstanding performance on all benchmarks, which
outperforms the previous state-of-the methods on the challenging PartNet
datasets by a large margin (7.4 mIoU). The code is publicly available at
https://github.com/zeliu98/CloserLook3D
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:59:12 GMT""}]","2020-07-03"
"2007.01295","Diego Paolo Ferruzzo Correa PhD.","Cristiane M. Batistela, Diego P. F. Correa, \'Atila M Bueno, and
  Jos\'e R. C. Piqueira","Compartmental model with loss of immunity: analysis and parameters
  estimation for Covid-19","Second version. Under review",,,,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The outbreak of Covid-19 led the world to an unprecedent health and
economical crisis. In an attempt to responde to this emergency researchers
worldwide are intensively studying the Covid-19 pandemic dynamics. In this
work, a SIRSi compartmental model is proposed, which is a modification of the
known classical SIR model. The proposed SIRSi model considers differences in
the immunization within a population, and the possibility of unreported or
asymptomatic cases. The model is adjusted to three major cities of S\~ao Paulo
State, in Brazil, namely, S\~ao Paulo, Santos and Campinas, providing estimates
on the duration and peaks of the outbreak.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:59:37 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jul 2020 11:46:25 GMT""},{""version"":""v3"",""created"":""Thu, 6 Aug 2020 17:10:50 GMT""}]","2020-08-07"
"2007.01296","Samuel Homiller","Sally Dawson, Samuel Homiller, and Samuel D. Lane","Putting SMEFT Fits to Work","28+14 pages, 11 figures, plots updated","Phys. Rev. D 102, 055012 (2020)","10.1103/PhysRevD.102.055012","YITP-SB-20-18","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Standard Model Effective Field Theory (SMEFT) provides a consistent
framework for comparing precision measurements at the LHC to the Standard
Model. The observation of statistically significant non-zero SMEFT coefficients
would correspond to physics beyond the Standard Model (BSM) of some sort. A
more difficult question to answer is what, if any, detailed information about
the nature of the underlying high scale model can be obtained from these
measurements. In this work, we consider the patterns of SMEFT operators present
in five example models and discuss the assumptions inherent in using global
fits to make BSM conclusions. We find that including renormalization group
effects has a significant impact on the interpretation of the results. As a
by-product of our study, we present an up-dated global fit to SMEFT
coefficients in the Warsaw basis including some next-to-leading order QCD
corrections in the SMEFT theory.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:59:55 GMT""},{""version"":""v2"",""created"":""Thu, 27 Aug 2020 11:44:04 GMT""},{""version"":""v3"",""created"":""Mon, 26 Apr 2021 17:21:58 GMT""}]","2021-04-27"
"2007.01297","Richard Hoppe","R. Hoppe, M. Bergemann, B. Bitsch and A. Serenelli","The solar abundance problem and eMSTOs in clusters","10 pages, 7 figures, 1 table. Accepted for publication in A&A","A&A 641, A73 (2020)","10.1051/0004-6361/201936932",,"astro-ph.SR astro-ph.EP astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the impact of accretion from protoplanetary discs on stellar
evolution of AFG-type stars. We use a simplified disc model computed using the
Two-Pop-Py code that contains the growth and drift of dust particles in the
protoplanetary disc. It is used to model the accretion scenarios for a range of
physical conditions of protoplanetary discs. Two limiting cases are combined
with the evolution of stellar convective envelopes computed using the Garstec
stellar evolution code. We find that the accretion of metal-poor (gas) or
metal-rich (dust) material has a significant impact on the chemical composition
of the stellar convective envelope. As a consequence, the evolutionary track of
the star diverts from the standard scenario predicted by canonical stellar
evolution models, which assume a constant and homogeneous chemical composition
after the assembly of the star has finished. In the case of the Sun, we find a
modest impact on the solar chemical composition. Accretion of metal-poor
material indeed reduces the overall metallicity of the solar atmosphere, and it
is consistent, within the uncertainty, with the solar Z reported by Caffau et
al. (2011), but our model is not consistent with the measurement by Asplund et
al. (2009). Another effect is the change of the position of the star in the
colour-magnitude diagram. We compare our predictions to a set of open clusters
from the Gaia DR2 and show that it is possible to produce a scatter close to
the turn-off of young clusters that could contribute to explain the observed
scatter in CMDs. Detailed measurements of metallicities and abundances in the
nearby open clusters will provide a stringent observational test of our
proposed scenario.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:59:58 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 07:39:30 GMT""}]","2020-09-16"
"2007.01300","Ricardo Alberto Podest\'a","Ricardo A. Podest\'a, Denis E. Videla","Integral equienergetic non-isospectral unitary Cayley graphs","Small typos corrected from v2 (warning: v2 is different from v1, see
  the comments in v2)",,"10.1016/j.laa.2020.12.001",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the Cayley graphs $X(G,S)$ and $X^+(G,S)$ are equienergetic for
any abelian group $G$ and any symmetric subset $S$. We then focus on the family
of unitary Cayley graphs $G_R=X(R,R^*)$, where $R$ is a finite commutative ring
with identity. We show that under mild conditions, $\{G_R, G_R^+\}$ are pairs
of integral equienergetic non-isospectral graphs (generically connected and
non-bipartite). Then, we obtain conditions such that $\{G_R, \bar G_R\}$ are
equienergetic non-isospectral graphs. Finally, we characterize all integral
equienergetic non-isospectral triples $\{G_R, G_R^+, \bar G_R \}$ such that all
the graphs are also Ramanujan.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:47:02 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jul 2020 17:47:43 GMT""},{""version"":""v3"",""created"":""Mon, 24 Aug 2020 17:38:12 GMT""},{""version"":""v4"",""created"":""Mon, 30 Nov 2020 19:11:50 GMT""}]","2020-12-25"
"2007.01301","Liang Dai","Liang Dai","Statistical Microlensing Toward Magnified High-Redshift Star Clusters","16 pages including references, 8 figures, and 1 table. Match version
  accepted to MNRAS",,"10.1093/mnras/stab017",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study light variability of gravitationally magnified high-redshift star
clusters induced by a foreground population of microlenses. This arises as the
incoherent superposition of light variations from a large number of source
stars traversing the random magnification pattern on the source plane. The
light curve resembles a scale-invariant, Gaussian process on timescales of
years to decades, while exhibits rapid and frequent micro-caustic crossing
flares of larger amplitudes on timescales of days to months. For a concrete
example, we study a young Lyman-continuum-leaking star cluster recently
discovered in the lensed Sunburst Arc at $z=2.37$. We show that one magnified
image happens to be intervened by a faint foreground galaxy, and hence should
exhibit a variable flux at the $1$--$2\%$ level, which is measurable in space
with $\sim 1$--$3\,$ks exposures on the Hubble Space Telescope and more easily
with the James Webb Space Telescope, or from the ground using a $\sim$4-meter
telescope without adaptive optics. Detailed measurement of this variability
will enable us to determine the absolute macro magnification and hence the
intrinsic mass and length scales of the star cluster, test synthetic models of
stellar population, and probe multiplicity of massive stars. We furthermore
suggest that monitoring the other lensed images of the star cluster, which are
free from significant intervention by foreground stellar microlenses, will
allow us to probe planetary to stellar mass compact objects constituting as
little as just a few percent of the dark matter. Given the typical surface
density of intracluster stars, we expect this phenomenon to be relevant for
many other gravitationally magnified star clusters at Cosmic Noon behind galaxy
cluster lenses.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 31 Dec 2020 21:08:24 GMT""}]","2021-01-13"
"2007.01302","Carmelo Evoli","Carmelo Evoli, Pasquale Blasi, Elena Amato, Roberto Aloisio","Signature of Energy Losses on the Cosmic Ray Electron Spectrum","5 pages, 3 figures, minor updates in the text, fixed a typo in Eq. 4","Phys. Rev. Lett. 125, 051101 (2020)","10.1103/PhysRevLett.125.051101",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the fine structure of the electron spectrum in cosmic rays,
especially the excess claimed by AMS-02 at energies $\sim$42 GeV, is fully
accounted for in terms of inverse Compton losses in the photon background
dominated by ultraviolet, infrared and CMB photons, plus the standard
synchrotron losses in the Galactic magnetic field. The transition to the
Klein-Nishina regime on the ultraviolet background causes the feature. Hence,
contrary to previous statements, observations do not require the overlap of
different components. We stress that the feature observed by AMS-02 at energies
$\sim$42 GeV is not related to the positron excess, which instead requires the
existence of positron sources, such as pulsars. Because energy losses are the
physical explanation of this feature, we indirectly confirm that the transport
of leptons in the Galaxy is loss-dominated down to energies of the order of
tens of GeV. This finding imposes strong constraints on the feasibility of
alternative theories of cosmic transport in which the grammage is accumulated
in cocoons concentrated around sources, requiring that electrons and positrons
become loss dominated only at very high energies.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jul 2020 18:00:01 GMT""}]","2020-07-30"
"2007.01303","Christopher White","Christopher David White and ChunJun Cao and Brian Swingle","Conformal field theories are magical",,"Phys. Rev. B 103, 075145 (2021)","10.1103/PhysRevB.103.075145",,"quant-ph cond-mat.stat-mech cond-mat.str-el hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  ""Magic"" is the degree to which a state cannot be approximated by Clifford
gates. We study mana, a measure of magic, in the ground state of the $\mathbb
Z_3$ Potts model, and argue that it is a broadly useful diagnostic for
many-body physics. In particular we find that the $q = 3$ ground state has
large mana at the model's critical point, and that this mana resides in the
system's correlations. We explain the form of the mana by a simple
tensor-counting calculation based on a MERA representation of the state.
Because mana is present at all length scales, we conclude that the conformal
field theory describing the 3-state Potts model critical point is magical.
These results control the difficulty of preparing the Potts ground state on an
error-corrected quantum computer, and constrain tensor network models of
AdS-CFT.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:00 GMT""}]","2021-03-03"
"2007.01304","Derek Harland","Chris Halcrow and Derek Harland","An attractive spin-orbit potential from the Skyrme model","7 pages, 3 figures. v2 includes an erratum, which corrects some
  errors in the original paper","Phys. Rev. Lett. 125, 042501 (2020)","10.1103/PhysRevLett.125.042501",,"hep-th nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive the nucleon-nucleon isoscalar spin-orbit potential from the Skyrme
model and find good agreement with the Paris potential. This solves a problem
that has been open for more than thirty years and gives a new geometric
understanding of the spin-orbit force. Our calculation is based on the dipole
approximation to skyrmion dynamics and higher order perturbation theory.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 9 Aug 2022 16:34:37 GMT""}]","2022-08-10"
"2007.01305","Benjamin Lillard","Peter Adshead, Patrick Draper, and Benjamin Lillard","Time-domain properties of electromagnetic signals in a dynamical axion
  background","24 pages, 6 figures, 2 appendices","Phys. Rev. D 102, 123011 (2020)","10.1103/PhysRevD.102.123011",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electromagnetic waves in a dynamical axion background exhibit superluminal
group velocities at high frequencies and instabilities at low frequencies,
altering how photons propagate through space. Local disturbances propagate
causally, but unlike in ordinary Maxwell theory, propagation occurs inside as
well as on the lightcone. For the unstable modes, the energy density in the
electromagnetic field grows exponentially along timelike displacements. In this
paper we derive retarded Green functions in axion electrodynamics in various
limits and study the time-domain properties of propagating signals.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:01 GMT""}]","2021-01-04"
"2007.01306","Annabelle Richard-Laferri\`ere","A. Richard-Laferri\`ere, J. Hlavacek-Larrondo, R. S. Nemmen, C. L.
  Rhea, G. B. Taylor, M. Prasow-\'Emond, M. Gendron-Marsolais, M. Latulippe, A.
  C. Edge, A. C. Fabian, J. S. Sanders, M. T. Hogan, G. Demontigny","On the relation between mini-halos and AGN feedback in clusters of
  galaxies","26 pages, 9 figures, 8 tables, accepted for publication in MNRAS",,"10.1093/mnras/staa2877",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A variety of large-scale diffuse radio structures have been identified in
many clusters with the advent of new state-of-the-art facilities in radio
astronomy. Among these diffuse radio structures, radio mini-halos are found in
the central regions of cool core clusters. Their origin is still unknown and
they are challenging to discover; less than thirty have been published to date.
Based on new VLA observations, we confirmed the mini-halo in the massive strong
cool core cluster PKS 0745$-$191 ($z=0.1028$) and discovered one in the massive
cool core cluster MACS J1447.4+0827 ($z=0.3755$). Furthermore, using a detailed
analysis of all known mini-halos, we explore the relation between mini-halos
and AGN feedback processes from the central galaxy. We find evidence of strong,
previously unknown correlations between mini-halo radio power and X-ray cavity
power, and between mini-halo and the central galaxy radio power related to the
relativistic jets when spectrally decomposing the AGN radio emission into a
component for past outbursts and one for on-going accretion. Overall, our study
indicates that mini-halos are directly connected to the central AGN in
clusters, following previous suppositions. We hypothesize that AGN feedback may
be one of the dominant mechanisms giving rise to mini-halos by injecting energy
into the intra-cluster medium and reaccelerating an old population of
particles, while sloshing motion may drive the overall shape of mini-halos
inside cold fronts. AGN feedback may therefore not only play a vital role in
offsetting cooling in cool core clusters, but may also play a fundamental role
in re-energizing non-thermal particles in clusters.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 28 Sep 2020 15:42:18 GMT""}]","2020-10-07"
"2007.01307","Emanuel Schwarzhans","Emanuel Schwarzhans, Maximilian P. E. Lock, Paul Erker, Nicolai Friis,
  Marcus Huber","Autonomous Temporal Probability Concentration: Clockworks and the Second
  Law of Thermodynamics","12+11 pages, 8 figures","Phys. Rev. X 11, 011046 (2021)","10.1103/PhysRevX.11.011046",,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  According to thermodynamics, the inevitable increase of entropy allows the
past to be distinguished from the future. From this perspective, any clock must
incorporate an irreversible process that allows this flow of entropy to be
tracked. In addition, an integral part of a clock is a clockwork, that is, a
system whose purpose is to temporally concentrate the irreversible events that
drive this entropic flow, thereby increasing the accuracy of the resulting
clock ticks compared to counting purely random equilibration events. In this
article, we formalise the task of autonomous temporal probability concentration
as the inherent goal of any clockwork based on thermal gradients. Within this
framework, we show that a perfect clockwork can be approximated arbitrarily
well by increasing its complexity. Furthermore, we combine such an idealised
clockwork model, comprised of many qubits, with an irreversible decay mechanism
to showcase the ultimate thermodynamic limits to the measurement of time.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 11:44:07 GMT""}]","2021-03-18"
"2007.01308","Daniel Gilman","Daniel Gilman, Simon Birrer, Tommaso Treu","TDCOSMO III: Dark matter substructure meets dark energy -- the effects
  of (sub)halos on strong-lensing measurements of $H_0$","accepted by Astronomy and Astrophysics","A&A 642, A194 (2020)","10.1051/0004-6361/202038829",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time delay cosmography uses the arrival time delays between images in strong
gravitational lenses to measure cosmological parameters, in particular the
Hubble constant $H_0$. The lens models used in time delay cosmography omit dark
matter subhalos and line-of-sight halos because their effects are assumed to be
negligible. We explicitly quantify this assumption by analyzing mock lens
systems that include full populations of dark matter subhalos and line-of-sight
halos, applying the same modeling assumptions used in the literature to infer
$H_0$. We base the mock lenses on six quadruply-imaged quasars that have
delivered measurements of the Hubble constant, and quantify the additional
uncertainties and/or bias on a lens-by-lens basis. We show that omitting dark
substructure does not bias inferences of $H_0$. However, perturbations from
substructure contribute an additional source of random uncertainty in the
inferred value of $H_0$ that scales as the square root of the lensing volume
divided by the longest time delay. This additional source of uncertainty, for
which we provide a fitting function, ranges from $0.7 - 2.4\%$. It may need to
be incorporated in the error budget as the precision of cosmographic inferences
from single lenses improves, and sets a precision limit on inferences from
single lenses.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 17:51:06 GMT""},{""version"":""v3"",""created"":""Mon, 31 Aug 2020 18:30:55 GMT""}]","2020-10-21"
"2007.01309","Nik Dennler","Nik Dennler, Antonio Foncubierta-Rodriguez, Titus Neupert, Marilyne
  Sousa","Learning-based Defect Recognition for Quasi-Periodic Microscope Images","11 pages + references and appendix, 5 figures. V2: Added references.
  Corrected typos. Elaborated methodology. In sample figure, replaced grain
  boundary image with more representative image. Results are unchanged",,"10.1016/j.micron.2021.103069",,"cond-mat.mtrl-sci cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Controlling crystalline material defects is crucial, as they affect
properties of the material that may be detrimental or beneficial for the final
performance of a device. Defect analysis on the sub-nanometer scale is enabled
by high-resolution (scanning) transmission electron microscopy [HR(S)TEM],
where the identification of defects is currently carried out based on human
expertise. However, the process is tedious, highly time consuming and, in some
cases, yields ambiguous results. Here we propose a semi-supervised machine
learning method that assists in the detection of lattice defects from atomic
resolution microscope images. It involves a convolutional neural network that
classifies image patches as defective or non-defective, a graph-based heuristic
that chooses one non-defective patch as a model, and finally an automatically
generated convolutional filter bank, which highlights symmetry breaking such as
stacking faults, twin defects and grain boundaries. Additionally, we suggest a
variance filter to segment amorphous regions and beam defects. The algorithm is
tested on III-V/Si crystalline materials and successfully evaluated against
different metrics, showing promising results even for extremely small training
data sets. By combining the data-driven classification generality, robustness
and speed of deep learning with the effectiveness of image filters in
segmenting faulty symmetry arrangements, we provide a valuable open-source tool
to the microscopist community that can streamline future HR(S)TEM analyses of
crystalline materials.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Sun, 9 Aug 2020 11:14:57 GMT""}]","2021-06-03"
"2007.01310","Brian Lemaux","B. C. Lemaux, S. Fuller, M. Brada\v{c}, L. Pentericci, A. Hoag, V.
  Strait, T. Treu, C. Alvarez, P. Bolan, P. J. Gandhi, T. Jones, C. Mason, D.
  Pelliccia, B. Ribeiro, R. E. Ryan, K. B. Schmidt, E. Vanzella, Y. Khusanova,
  O. Le F\`evre, L. Guaita, N. P. Hathi, A. Koekemoer, and J. Pforr","The Size and Pervasiveness of Ly$\alpha$-UV Spatial Offsets in
  Star-Forming Galaxies at $z\sim6$","21 pages, 7 figures, 2 tables. Updated with the accepted MNRAS
  version that includes minor changes to the text and two tables",,"10.1093/mnras/stab924",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the projected spatial offset between the ultraviolet continuum and
Ly$\alpha$ emission for 65 lensed and unlensed galaxies in the Epoch of
Reionization ($5\leq z\leq7$), the first such study at these redshifts, in
order to understand the potential for these offsets to confuse estimates of the
Ly$\alpha$ properties of galaxies observed in slit spectroscopy. While we find
that ~40% of galaxies in our sample show significant projected spatial offsets
($|\Delta_{Ly\alpha-UV}|$), we find a modest average offset of 0.61$\pm$0.08
kpc. A small fraction of our sample, ~10%, exhibits offsets of 2-4 kpc, sizes
that are larger than the effective radii of typical galaxies at these
redshifts. An internal comparison and a comparison to studies at lower redshift
yielded no significant evidence of evolution of $|\Delta_{Ly\alpha-UV}|$ with
redshift. In our own sample, UV-bright galaxies showed offsets a factor of
three greater than their fainter counterparts, 0.89$\pm$0.18 vs. 0.27$\pm$0.05
kpc, respectively. We argue that offsets are likely not the result of merging
processes, but are rather due to internal anisotropic processes resulting from
stellar feedback facilitates Ly$\alpha$ fluorescence and/or backscattering from
nearby or outflowing gas. The reduction in the Ly$\alpha$ flux due to offset
effects for various observational setups was quantified through mock
observations of simple simulations. It was found that the loss of Ly$\alpha$
photons for galaxies with average offsets is not, if corrected for, a limiting
factor for all but the narrowest slit widths (<0.4''). However, for the largest
offsets, if such offsets are mostly perpendicular to the slit major axis, slit
losses were found to be extremely severe in cases where slit widths of
$\leq$1'' were employed, such as those planned for James Webb Space
Telescope/NIRSpec observations. (abridged)
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 01:26:04 GMT""}]","2021-05-12"
"2007.01311","Paul McClarty","Paul A. McClarty, Masudul Haque, Arnab Sen, Johannes Richter","Disorder-Free Localization and Many-Body Quantum Scars from Magnetic
  Frustration","15 pages, 8 figures; revised version, new figures; accepted for
  publication in Physical Review B","Phys. Rev. B 102, 224303 (2020)","10.1103/PhysRevB.102.224303",,"cond-mat.stat-mech cond-mat.quant-gas cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The concept of geometrical frustration has led to rich insights into
condensed matter physics, especially as a mechansim to produce exotic low
energy states of matter. Here we show that frustration provides a natural
vehicle to generate models exhibiting anomalous thermalization of various types
within high energy states. We consider three classes of non-integrable
frustrated spin models: (I) systems with local conserved quantities where the
number of symmetry sectors grows exponentially with the system size but more
slowly than the Hilbert space dimension, (II) systems with exact eigenstates
that are singlet coverings, and (III) flat band systems hosting magnon
crystals. We argue that several 1D and 2D models from class (I) exhibit
disorder-free localization in high energy states so that information
propagation is dynamically inhibited on length scales greater than a few
lattice spacings. We further show that models of class (II) and (III) exhibit
quantum many-body scars -- eigenstates of non-integrable Hamiltonians with
finite energy density and anomalously low entanglement entropy. Our results
demonstrate that magnetic frustration supplies a means to systematically
construct classes of non-integrable models exhibiting anomalous thermalization
in mid-spectrum states.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:04 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 08:30:47 GMT""}]","2020-12-17"
"2007.01312","Nicholas Fantin","Nicholas J. Fantin, Patrick C\^ot\'e, Alan McConnachie","White Dwarfs in the Era of the LSST and its Synergies with Space-Based
  Missions","23 pages, 12 figures",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the imminent start of the Legacy Survey for Space and Time (LSST) on the
Vera C. Rubin Observatory, and several new space telescopes expected to begin
operations later in this decade, both time domain and wide-field astronomy are
on the threshold of a new era. In this paper, we use a new, multi-component
model for the distribution of white dwarfs (WDs) in our Galaxy to simulate the
WD populations in four upcoming wide-field surveys (i.e., LSST, Euclid, the
Roman Space Telescope and CASTOR) and use the resulting samples to explore some
representative WD science cases. Our results confirm that LSST will provide a
wealth of information for Galactic WDs, detecting more than 150 million WDs at
the final depth of its stacked, 10-year survey. Within this sample, nearly
300,000 objects will have 5$\sigma$ parallax measurements and nearly 7 million
will have 5$\sigma$ proper motion measurements, allowing the detection of the
turn-off in the halo WD luminosity function and the discovery of more than
200,000 ZZ Ceti stars. The wide wavelength coverage that will be possible by
combining LSST data with observations from Euclid, and/or the Roman Space
Telescope, will also discover more than 3,500 WDs with debris disks,
highlighting the advantages of combining data between the ground- and
space-based missions.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:04 GMT""},{""version"":""v2"",""created"":""Tue, 1 Sep 2020 03:11:06 GMT""}]","2020-09-02"
"2007.01313","Jessica Rigley","Jessica K. Rigley, Mark C. Wyatt","Dust size and spatial distributions in debris discs: predictions for
  exozodiacal dust dragged in from an exo-Kuiper belt","25 pages, 20 figures, 2 tables. Accepted for publication in MNRAS",,"10.1093/mnras/staa2029",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The SEDs of some nearby stars show mid-infrared excesses from warm habitable
zone dust, known as exozodiacal dust. This dust may originate in collisions in
a planetesimal belt before being dragged inwards. This paper presents an
analytical model for the size distribution of particles at different radial
locations in such a scenario, considering evolution due to destructive
collisions and Poynting-Robertson (P-R) drag. Results from more accurate but
computationally expensive numerical simulations of this process are used to
validate the model and fit its free parameters. The model predicts 11 $\mu$m
excesses ($R_{11}$) for discs with a range of dust masses and planetesimal belt
radii using realistic grain properties. We show that P-R drag should produce
exozodiacal dust levels detectable with the Large Binocular Telescope
Interferometer (LBTI) ($R_{11} > 0.1\%$) in systems with known outer belts;
non-detection may indicate dust depletion, e.g. by an intervening planet. We
also find that LBTI could detect exozodiacal dust dragged in from a belt too
faint to detect at far-infrared wavelengths, with fractional luminosity $f\sim
10^{-7}$ and radius $\sim 10-80$ au. Application to systems observed with LBTI
shows that P-R drag can likely explain most (5/9) of the exozodiacal dust
detections in systems with known outer belts; two systems ($\beta$ Uma and
$\eta$ Corvi) with bright exozodi may be due to exocomets. We suggest that the
three systems with exozodiacal dust detections but no known belt may have cold
planetesimal belts too faint to be detectable in the far-infrared. Even systems
without outer belt detections could have exozodiacal dust levels $R_{11} >
0.04\%$ which are problematic for exo-Earth imaging.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:05 GMT""}]","2020-07-22"
"2007.01314","Ariel Werle","Ariel Werle, Roberto Cid Fernandes, Natalia Vale Asari, Paula R. T.
  Coelho, Gustavo Bruzual, Stephane Charlot, Reinaldo R. de Carvalho, F\'abio
  R. Herpich, Clauda Mendes de Oliveira, Laerte Sodr\'e Jr., Daniel Ruschel
  Dutra, Andr\'e de Amorim and Vitor M. Sampaio","Clues on the history of early-type galaxies from SDSS spectra and GALEX
  photometry","Accepted for publication in MNRAS",,"10.1093/mnras/staa2217",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stellar population studies of early-type galaxies (ETGs) based on their
optical stellar continuum suggest that these are quiescent systems. However,
emission lines and ultraviolet photometry reveal a diverse population. We use a
new version of the STARLIGHT spectral synthesis code and state-of-the-art
stellar population models to simultaneously fit SDSS spectra and GALEX
photometry for a sample of 3453 galaxies at $z < 0.1$ with $NUV-r > 5$ that are
classified as elliptical by Galaxy Zoo. We reproduce $FUV$ magnitudes for 80
per cent of UV upturn galaxies selected using criteria from the literature,
suggesting that additional stellar population ingredients such as binaries and
extreme horizontal branch stars may have a limited contribution to the UV
upturn. The addition of ultraviolet data leads to a broadening of the
distributions of mean stellar ages, metallicities and attenuation. Stellar
populations younger than $1\,$Gyr are required to reproduce the ultraviolet
emission in 17 per cent of our sample. These systems represent 43 per cent of
the sample at $5<NUV-r<5.5$ and span the same stellar mass range as other ETGs
in our sample. ETGs with young stellar components have larger $H\alpha$
equivalent widths ($W_{H\alpha}$) and larger dust attenuation. Emission line
ratios and $W_{H\alpha}$ indicate that the ionising source in these systems is
a mixture of young and old stellar populations. Their young stellar populations
are metal-poor, especially for high-mass galaxies, indicating recent star
formation associated with rejuvenation events triggered by external processes,
such as minor mergers.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:06 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jul 2020 14:10:09 GMT""}]","2020-07-31"
"2007.01315","Sebastian Steinhaus","Sebastian Steinhaus","Coarse graining spin foam quantum gravity -- a review","31 pages, 15 figures, accepted for publication in ""Frontiers in
  Physics"" as part of the issue on ""Coarse Graining in Quantum Gravity:
  Bridging the Gap between Microscopic Models and Spacetime-Physics """,,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In quantum gravity, we envision renormalization as the key tool for bridging
the gap between microscopic models and observable scales. For spin foam quantum
gravity, which is defined on a discretisation akin to lattice gauge theories,
the goal is to derive an effective theory on a coarser discretisation from the
dynamics on the finer one, coarse graining the system in the process and thus
relating physics at different scales. In this review I will discuss the
motivation for studying renormalization in spin foam quantum gravity, e.g. to
restore diffeomorphism symmetry, and explain how to define renormalization in a
background independent setting by formulating it in terms of boundary data. I
will motivate the importance of the boundary data by studying coarse graining
of a concrete example and extending this to the spin foam setting. This will
naturally lead me to the methods currently used for renormalizing spin foam
quantum gravity, such as tensor network renormalization, and a discussion of
recent results. I will conclude with an overview of future prospects and
research directions.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:07 GMT""}]","2020-07-06"
"2007.01316","Matteo Nori","Matteo Nori and Marco Baldi","Scaling relations of Fuzzy Dark Matter haloes I: individual systems in
  their cosmological environment","20 pages, 9 Figures, 4 Tables. Submitted to MNRAS",,"10.1093/mnras/staa3772",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dark matter models involving a very light bosonic particle, generally known
as Fuzzy Dark Matter (FDM), have been recently attracting great interest in the
cosmology community, as their wave-like phenomenology would simultaneously
explain the longstanding mis-detection of a dark matter particle and help
easing the small-scale issues related to the standard Cold Dark Matter (CDM)
scenario. With the present work, we initiate a series of papers aiming at
investigating the evolution of FDM structures in a cosmological framework
performed with our N-body code AX-GADGET, detailing for the first time in the
literature how the actual scaling relations between solitonic cores and host
haloes properties are significantly affected by the dynamical state, morphology
and merger history of the individual systems. In particular, in this first
paper we confirm the ability of AX-GADGET to correctly reproduce the typical
FDM solitonic core and we employ it to study the non-linear evolution of eight
FDM haloes in their cosmological context through the zoom-in simulation
approach. We find that the scaling relations identified in previous works for
isolated systems are generally modified for haloes evolving in a realistic
cosmological environment, and appear to be valid only as a limit for the most
relaxed and spherically symmetric systems.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:08 GMT""}]","2020-12-23"
"2007.01317","Maryam Arabsalmani","M. Arabsalmani, F. Renaud, S. Roychowdhury, V. Arumugam, E. Le Floc'h,
  F. Bournaud, D. Cormier, M. A. Zwaan, L. Christensen, E. Pian, S. Madden, A.
  Levan","Local starburst conditions and formation of GRB 980425 / SN 1998bw
  within a collisional ring","ApJ (in press), 12 pages, 4 figures, 1 table",,"10.3847/1538-4357/aba3c0",,"astro-ph.GA astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first spatially resolved study of molecular gas in the
vicinity of a Gamma Ray Burst, using CO(2-1) emission line observations with
the Atacama Large Millimetre Array (ALMA) at ~50 pc scales. The host galaxy of
GRB 980425 contains a ring of high column density HI gas which is likely to
have formed due to a collision between the GRB host and its companion galaxy,
within which the GRB is located. We detect eleven molecular gas clumps in the
galaxy, seven of which are within the gas ring. The clump closest to the GRB
position is at a projected separation of ~280 pc. Although it is plausible that
the GRB progenitor was ejected from clusters formed in this clump, we argue
that the in situ formation of the GRB progenitor is the most likely scenario.
We measure the molecular gas masses of the clumps and find them to be
sufficient for forming massive star clusters. The molecular gas depletion times
of the clumps show a variation of ~2 dex, comparable with the large variation
in depletion times found in starburst galaxies in the nearby Universe. This
demonstrates the presence of starburst modes of star formation on local scales
in the galaxy, even while the galaxy as a whole cannot be categorised as a
starburst based on its global properties. Our findings suggest that the
progenitor of GRB 9802425 was originated in a young massive star cluster formed
in the starburst mode of star formation.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:12 GMT""}]","2020-09-02"
"2007.01318","J. Piilo","Zhao-Di Liu, Yong-Nan Sun, Bi-Heng Liu, Chuan-Feng Li, Guang-Can Guo,
  Sina Hamedani Raja, Henri Lyyra, Jyrki Piilo","Experimental realization of high-fidelity teleportation via
  non-Markovian open quantum system","v2: added more experimental results, minor text modifications","Phys. Rev. A 102, 062208 (2020)","10.1103/PhysRevA.102.062208",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Open quantum systems and study of decoherence are important for our
fundamental understanding of quantum physical phenomena. For practical
purposes, there exists a large number of quantum protocols exploiting quantum
resources, e.g. entanglement, which allows to go beyond what is possible to
achieve by classical means. We combine concepts from open quantum systems and
quantum information science, and give a proof-of-principle experimental
demonstration -- with teleportation -- that it is possible to implement
efficiently a quantum protocol via non-Markovian open system. The results show
that, at the time of implementation of the protocol, it is not necessary to
have the quantum resource in the degree of freedom used for the basic protocol
-- as long as there exists some other degree of freedom, or environment of an
open system, which contains useful resources. The experiment is based on a pair
of photons, where their polarizations act as open system qubits and frequencies
as their environments -- while the path degree of freedom of one of the photons
represents the state of Alice's qubit to be teleported to Bob's polarization
qubit.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:19 GMT""},{""version"":""v2"",""created"":""Thu, 17 Dec 2020 14:56:08 GMT""}]","2020-12-18"
"2007.01319","Mar\'ia Teresa Valdivia Mena","M. T. Valdivia-Mena, M. Rubio, A. D. Bolatto, H. P. Salda\~no, and C.
  Verdugo","ALMA resolves molecular clouds in the metal poor Magellanic Bridge A","Astronomy & Astrophysics in press. 14 pages, 6 figures, 7 tables","A&A 641, A97 (2020)","10.1051/0004-6361/201937232",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  (Abridged)We characterize gas and dust emission in Magellanic Bridge A, which
has the highest 870$\mu$m excess of emission found in single dish surveys.
Using the ALMA telescope, we mapped the Magellanic Bridge A molecular cloud
with sub-parsec resolution, in 1.3 mm continuum and CO(2-1) line emission. We
also map the cloud in 870$\mu$m continuum and CO(2-1) line emission at ~6 pc
resolution with APEX. We combine the ALMA and APEX CO(2-1) line cubes to study
the molecular gas emission. Magellanic Bridge A breaks up into two distinct
molecular clouds in dust and CO(2-1) emission, which we call North and South.
Dust emission in the North source, according to our best parameters from
fitting the far-infrarred fluxes, is ~3 K colder than in the South source in
correspondence to its less developed star formation. Both dust sources present
large submillimeter excesses in LABOCA data: according to our best fits the
excess over the modified blackbody (MBB) fit to the Spitzer/Herschel continuum
are ~7 and ~3 for the North and South sources respectively. Nonetheless, we do
not detect the corresponding 1.3 mm continuum with ALMA. Our limits are
compatible with the extrapolation of the MBB fits and therefore we cannot
independently confirm the excess at this longer wavelength. The CO(2-1)
emission is in two parsec-sized clouds with virial masses around 400 and 700 Mo
each. Their volume densities are ~700-2600 cm$^{-3}$, larger than typical bulk
densities of Galactic molecular clouds. The CO-to-H2 conversion factor is 6.5
and 15 M$_{\odot}$ (K km s$^{-1}$ pc$^2$)$^{-1}$ for the North and South
clouds, calculated using their respective virial masses and CO(2-1)
luminosities. Gas mass estimates from our MBB fits to dust emission yields
masses $M\sim1.3\times10^3$ M$_{\odot}$ and $2.9\times10^3$ M$_{\odot}$ for
North and South respectively, a factor ~4 larger than the virial masses we
infer from CO.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:28 GMT""}]","2020-09-16"
"2007.01320","Sam S. C. Wong","Justin Khoury, Mark Trodden, Sam S. C. Wong","Existence and Instability of Novel Hairy Black Holes in Shift-symmetric
  Horndeski Theories","25 pages",,"10.1088/1475-7516/2020/11/044",,"astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Shift-symmetric Horndeski theories admit an interesting class of
Schwarzschild black hole solutions exhibiting time-dependent scalar hair. By
making use of Lema\^{i}tre coordinates, we analyze perturbations around these
types of black holes, and demonstrate that scalar perturbations around black
hole backgrounds inevitably have gradient instabilities. Taken together with
previously established results, this newly-discovered instability rules out
black holes with time-dependent scalar hair in Horndeski theories.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:00:32 GMT""}]","2020-12-09"
"2007.01321","Antoine Hocquet","Antoine Hocquet and Alexander Vogler","Optimal control of mean field equations with monotone coefficients and
  applications in neuroscience","32 pages; 11 figures",,,,"math.PR cs.NA math.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are interested in the optimal control problem associated with certain
quadratic cost functionals depending on the solution $X=X^\alpha$ of the
stochastic mean-field type evolution equation in $\mathbb R^d$
$dX_t=b(t,X_t,\mathcal L(X_t),\alpha_t)dt+\sigma(t,X_t,\mathcal
L(X_t),\alpha_t)dW_t,$ $X_0\sim \mu$ given, under assumptions that enclose a
sytem of FitzHugh-Nagumo neuron networks, and where for practical purposes the
control $\alpha_t$ is deterministic. To do so, we assume that we are given a
drift coefficient that satisfies a one-sided Lipshitz condition, and that the
dynamics is subject to a (convex) level set constraint of the form
$\pi(X_t)\leq0$. The mathematical treatment we propose follows the lines of the
recent monograph of Carmona and Delarue for similar control problems with
Lipshitz coefficients. After addressing the existence of minimizers via a
martingale approach, we show a maximum principle and then numerically
investigate a gradient algorithm for the approximation of the optimal control.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:03:07 GMT""}]","2020-07-06"
"2007.01322","Bruno Ribeiro","B. Ribeiro, O. Le F\`evre, A. Paulino-Afonso, P. Cassata, V. Le Brun,
  B. C. Lemaux, D. Maccagni, L. Pentericci, R. Thomas, G. Zamorani, E. Zucca,
  R. Amor\'in, S. Bardelli, L. P. Cassar\`a, L. Guaita, N.P. Hathi, A.
  Koekemoer, D. Schaerer, M. Talia, J. Pforr, L. Tresse, S. Fotopoulou, D.
  Vergani","The VIMOS Ultra-Deep Survey: the Ly$\alpha$ emission line morphology at
  $2 < z < 6$","18 pages, 13 figures, submitted to A&A",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Lyman-$\alpha$ (Ly$\alpha$) emission line has been ubiquitously used to
confirm and study high redshift galaxies. We report on the line morphology as
seen in the 2D spectra from the VIMOS Ultra Deep Survey in a sample of 914
Ly$\alpha$ emitters from a parent sample of 4192 star-forming galaxies at
$2<z_\mathrm{spec}\lesssim6$. The study of the spatial extent of Ly$\alpha$
emission provides insight into the escape of Ly$\alpha$ photons from galaxies.
We classify the line emission as either non-existent, coincident, projected
spatial offset, or extended with respect to the observed 2D UV continuum
emission. The line emitters in our sample are classified as ~45% coincident,
~24% extended and ~11% offset emitters. For galaxies with detected UV
continuum, we show that extended Ly$\alpha$ emitters (LAEs) correspond to the
highest equivalent width galaxies (with an average
$W_\mathrm{Ly\alpha}\sim-22${\AA}). This means that this class of objects is
the most common in narrow-band selected samples, which usually select high
equivalent width LAEs, $<-20${\AA}. Extended Ly$\alpha$ emitters are found to
be less massive, less star-forming, with lower dust content, and smaller UV
continuum sizes ($r_{50}\sim0.9$kpc) of all the classes considered here. We
also find that galaxies with larger UV-sizes have lower fractions of Ly$\alpha$
emitters. By stacking the spectra per emitter class we find that the weaker
Ly$\alpha$ emitters have stronger low ionization inter-stellar medium (ISM)
absorption lines. Interestingly, we find that galaxies with Ly$\alpha$ offset
emission (median separation of $1.1_{-0.8}^{+1.3}$kpc from UV continuum) show
similar velocity offsets in the ISM as those with no visible emission (and
different from other Ly$\alpha$ emitting classes). This class of objects may
hint at episodes of gas accretion, bright offset clumps, or on-going merging
activity into the larger galaxies.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:03:34 GMT""}]","2020-07-06"
"2007.01323","Marco Fazzi","Antonio Amariti and Marco Fazzi","Dualities for three-dimensional $\mathcal{N} = 2$ $SU(N_c)$ chiral
  adjoint SQCD","49 pages, 4 appendices, 4 figures; v2: typos fixed; v3: minor
  comments added, references added, figures fixed, version published in JHEP",,"10.1007/JHEP11(2020)030",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study dualities for 3d $\mathcal{N} = 2$ $SU(N_c)$ SQCD at Chern-Simons
level $k$ in presence of an adjoint with polynomial superpotential. The
dualities are dubbed chiral because there is a different amount of fundamentals
$N_f$ and antifundamentals $N_a$. We build a complete classification of such
dualities in terms of $ |N_f - N_a| $ and $k$. The classification is obtained
by studying the flow from the non-chiral case, and we corroborate our proposals
by matching the three-sphere partition functions. Finally, we revisit the case
of $SU(N_c)$ SQCD without the adjoint, comparing our results with previous
literature.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:03:59 GMT""},{""version"":""v2"",""created"":""Thu, 13 Aug 2020 15:03:56 GMT""},{""version"":""v3"",""created"":""Wed, 30 Sep 2020 17:27:00 GMT""}]","2020-12-02"
"2007.01324","Jasel Berra-Montiel","Jasel Berra-Montiel, Alberto Molgado","Quasi-probability distributions in Loop Quantum Cosmology","12 pages, no figures",,"10.1088/1361-6382/abb57a",,"gr-qc math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a complete family of parametrized
quasi-probability distributions in phase space and their corresponding Weyl
quantization maps with the aim to generalize the recently developed Wigner-Weyl
formalism within the Loop Quantum Cosmology program (LQC). In particular, we
intend to define those quasi-distributions for states valued on the Bohr
compactification of the real line in such a way that they are labeled by a
parameter that accounts for the ordering ambiguity corresponding to
non-commutative quantum operators. Hence, we notice that the projections of the
parametrized quasi-probability distributions result in marginal probability
densities which are invariant under any ordering prescription. We also note
that, in opposition to the standard Schr\""odinger representation, for an
arbitrary character the quasi-distributions determine a positive function
independently of the ordering. Further, by judiciously implementing a
parametric-ordered Weyl quantization map for LQG, we are able to recover in a
simple manner the relevant cases of the standard, anti-standard, and Weyl
symmetric orderings, respectively. We expect that our results may serve to
analyze several fundamental aspects within the LQC program, in special those
related to coherence, squeezed states, and the convergence of operators, as
extensively analyzed in the quantum optics and in the quantum information
frameworks.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:05:32 GMT""}]","2020-10-28"
"2007.01325","Vitali Kapovitch","Vitali Kapovitch and Alexander Lytchak","Structure of Submetries",,"Geom. Topol. 26 (2022) 2649-2711","10.2140/gt.2022.26.2649",,"math.DG math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the geometric and topological structure of equidistant
decompositions of Riemannian manifolds.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:06:49 GMT""}]","2022-12-21"
"2007.01326","Laszlo Arpad Gergely","Cec\'ilia Gergely, Zolt\'an Keresztes, L\'aszl\'o \'Arp\'ad Gergely","Minimally coupled scalar fields as imperfect fluids","6 pages, to appear in Physical Review D","Phys. Rev. D 102, 024044 (2020)","10.1103/PhysRevD.102.024044",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the issue of the fluid description of minimally coupled scalar
fields. While in a cosmological setup the interpretation of a time-evolving
scalar field as a perfect fluid is well-understood, the situation is more
intricate when the scalar field is static, but has a spatial gradient, a
situation motivated by black hole perturbations in scalar-tensor theories. Then
the scalar field is interpreted as either a particular imperfect fluid of type
I or a superposition of a pair of leftgoing (incoming) and rightgoing
(outgoing) null dusts with a perfect fluid. Finally, when the scalar gradient
is null, it is equivalent to an imperfect fluid of type II, degenerating into
null dust when the energy conditions are imposed. We also propose the suitable
action in terms of the fluid pressure components for each case and discuss the
variational principle for a generic class of minimally coupled scalar fields.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:08:00 GMT""}]","2020-07-21"
"2007.01327","Micha{\l} Derezi\'nski","Micha{\l} Derezi\'nski, Burak Bartan, Mert Pilanci and Michael W.
  Mahoney","Debiasing Distributed Second Order Optimization with Surrogate Sketching
  and Scaled Regularization",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In distributed second order optimization, a standard strategy is to average
many local estimates, each of which is based on a small sketch or batch of the
data. However, the local estimates on each machine are typically biased,
relative to the full solution on all of the data, and this can limit the
effectiveness of averaging. Here, we introduce a new technique for debiasing
the local estimates, which leads to both theoretical and empirical improvements
in the convergence rate of distributed second order methods. Our technique has
two novel components: (1) modifying standard sketching techniques to obtain
what we call a surrogate sketch; and (2) carefully scaling the global
regularization parameter for local computations. Our surrogate sketches are
based on determinantal point processes, a family of distributions for which the
bias of an estimate of the inverse Hessian can be computed exactly. Based on
this computation, we show that when the objective being minimized is
$l_2$-regularized with parameter $\lambda$ and individual machines are each
given a sketch of size $m$, then to eliminate the bias, local estimates should
be computed using a shrunk regularization parameter given by
$\lambda^{\prime}=\lambda\cdot(1-\frac{d_{\lambda}}{m})$, where $d_{\lambda}$
is the $\lambda$-effective dimension of the Hessian (or, for quadratic
problems, the data matrix).
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:08:14 GMT""}]","2020-07-06"
"2007.01328","Le Qiao Mr.","Le Qiao, Maxime Ignacio, and Gary W. Slater","An efficient Kinetic Monte Carlo to study analyte capture by a nanopore:
  Transients, boundary conditions and time-dependent fields",,"Phys. Chem. Chem. Phys., 2021,23, 1489-1499","10.1039/D0CP03638B",,"physics.bio-ph physics.chem-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To better understand the capture process by a nanopore, we introduce an
efficient Kinetic Monte Carlo (KMC) algorithm that can simulate long times and
large system sizes by mapping the dynamic of a point-like particle in a 3D
spherically symmetric system onto the 1D biased random walk. Our algorithm
recovers the steady-state analytical solution and allows us to study
time-dependent processes such as transients. Simulation results show that the
steady-state depletion zone near pore is barely larger than the pore radius and
narrows at higher field intensities; as a result, the time to reach
steady-state is much smaller than the time required to empty a zone of the size
of the capture radius $\lambda_e$. When the sample reservoir has a finite size,
a second depletion region propagates inward from the outer wall, and the
capture rate starts decreasing when it reaches the capture radius $\lambda_e$.
We also note that the flatness of the electric field near the pore, which is
often neglected, induces a traffic jam that can increase the transient time by
several orders of magnitude. Finally, we propose a new proof-of-concept scheme
to separate two analytes of the same mobility but different diffusion
coefficients using time-varying fields.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:10:11 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2021 21:33:16 GMT""}]","2021-03-22"
"2007.01329","John Cullinan","John Cullinan, Nick Scheel","On the arithmetic of Pad\'e approximants to the exponential function","13 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $(u,v)$-Pad\'e approximation to a function $f$ is the (unique, up to
scaling) rational approximation $f(x) = P(x)/Q(x) + O(x^{u+v+1})$, where $P$
has degree $u$ and $Q$ has degree $v$. Motivated by recent work of Molin,
Pazuki, and Rabarison, we study the arithmetic of the Pad\'e approximants of
the exponential polynomials. By viewing the approximants as certain Generalized
Laguerre Polynomials, we determine the Galois groups of the diagonal
approximants and prove some special cases of irreducibility.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:15:30 GMT""}]","2020-07-06"
"2007.01330","Qian Zhang","Lixiu Wang, Qian Zhang, Jiguang Sun, and Zhimin Zhang","A priori and a posteriori error estimates for the quad-curl eigenvalue
  problem","26 pages, 9 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a new family of H(curl^2)-conforming elements for
the quad-curl eigenvalue problem in 2D. The accuracy of this family is one
order higher than that in [32]. We prove a priori and a posteriori error
estimates. The a priori estimate of the eigenvalue with a convergence order
2(s-1) is obtained if the eigenvector u\in H^{s+1}(\Omega). For the a
posteriori estimate, by analyzing the associated source problem, we obtain
lower and upper bounds for the eigenvector in an energy norm and an upper bound
for the eigenvalues. Numerical examples are presented for validation.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:23:37 GMT""}]","2020-07-06"
"2007.01331","Sara Rezaei Kh.","Sara Rezaei Kh., Coryn A.L. Bailer-Jones, Juan D. Soler, and Eleonora
  Zari","Detailed 3D structure of OrionA in dust with Gaia DR2","Accepted for publication in Astronomy and Astrophysics. 9 pages, 12
  figures","A&A 643, A151 (2020)","10.1051/0004-6361/202038708",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unprecedented astrometry from Gaia DR2 provides us with an opportunity to
study in detail molecular clouds in the solar neighbourhood. Extracting the
wealth of information in these data remains a challenge, however. We have
further improved our Gaussian Processes-based, three-dimensional dust mapping
technique to allow us to study molecular clouds in more detail. These
improvements include a significantly better scaling of the computational cost
with the number of stars, and taking into account distance uncertainties to
individual stars. Using Gaia DR2 astrometry together with 2MASS and WISE
photometry for 30 000 stars, we infer the distribution of dust out to 600 pc in
the direction of the Orion A molecular cloud. We identify a bubble-like
structure in front of Orion A, centred at a distance of about 350 pc from the
Sun. The main Orion A structure is visible at slightly larger distances, and we
clearly see a tail extending over 100 pc that is curved and slightly inclined
to the line-of-sight. The location of our foreground structure coincides with
5-10 Myr old stellar populations, suggesting a star formation episode that
predates that of the Orion Nebula Cluster itself. We identify also the main
structure of the Orion B molecular cloud, and in addition discover a background
component to this at a distance of about 460 pc from the Sun. Finally, we
associate our dust components at different distances with the plane-of-the-sky
magnetic field orientation as mapped by Planck. This provides valuable
information for modelling the magnetic field in 3D around star forming regions.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:24:24 GMT""},{""version"":""v2"",""created"":""Mon, 28 Sep 2020 14:41:31 GMT""}]","2020-11-18"
"2007.01332","Andrew Y. K. Foong","Andrew Y. K. Foong, Wessel P. Bruinsma, Jonathan Gordon, Yann Dubois,
  James Requeima, Richard E. Turner","Meta-Learning Stationary Stochastic Process Prediction with
  Convolutional Neural Processes","NeurIPS 2020",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stationary stochastic processes (SPs) are a key component of many
probabilistic models, such as those for off-the-grid spatio-temporal data. They
enable the statistical symmetry of underlying physical phenomena to be
leveraged, thereby aiding generalization. Prediction in such models can be
viewed as a translation equivariant map from observed data sets to predictive
SPs, emphasizing the intimate relationship between stationarity and
equivariance. Building on this, we propose the Convolutional Neural Process
(ConvNP), which endows Neural Processes (NPs) with translation equivariance and
extends convolutional conditional NPs to allow for dependencies in the
predictive distribution. The latter enables ConvNPs to be deployed in settings
which require coherent samples, such as Thompson sampling or conditional image
completion. Moreover, we propose a new maximum-likelihood objective to replace
the standard ELBO objective in NPs, which conceptually simplifies the framework
and empirically improves performance. We demonstrate the strong performance and
generalization capabilities of ConvNPs on 1D regression, image completion, and
various tasks with real-world spatio-temporal data.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:25:27 GMT""},{""version"":""v2"",""created"":""Fri, 20 Nov 2020 10:52:35 GMT""}]","2020-11-23"
"2007.01333","Gregory L. Eyink","Gregory L. Eyink and Dmytro Bandak","A Renormalization Group Approach to Spontaneous Stochasticity","25 pages, 8 figures. Version 2 has reordered some of the exposition
  in version 1, for improved readability","Phys. Rev. Research 2, 043161 (2020)","10.1103/PhysRevResearch.2.043161",,"cond-mat.stat-mech math-ph math.MP nlin.CD physics.ao-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a theoretical approach to ``spontaneous stochasticity'' in
classical dynamical systems that are nearly singular and weakly perturbed by
noise. This phenomenon is associated to a breakdown in uniqueness of solutions
for fixed initial data and underlies many fundamental effects of turbulence
(unpredictability, anomalous dissipation, enhanced mixing). Based upon analogy
with statistical-mechanical critical points at zero temperature, we elaborate a
renormalization group (RG) theory that determines the universal statistics
obtained for sufficiently long times after the precise initial data are
``forgotten''. We apply our RG method to solve exactly the ``minimal model'' of
spontaneous stochasticity given by a 1D singular ODE. Generalizing prior
results for the infinite-Reynolds limit of our model, we obtain the RG fixed
points that characterize the spontaneous statistics in the near-singular,
weak-noise limit, determine the exact domain of attraction of each fixed point,
and derive the universal approach to the fixed points as a singular
large-deviations scaling, distinct from that obtained by the standard
saddle-point approximation to stochastic path-integrals in the zero-noise
limit. We present also numerical simulation results that verify our analytical
predictions, propose possible experimental realizations of the ``minimal
model'', and discuss more generally current empirical evidence for ubiquitous
spontaneous stochasticity in Nature. Our RG method can be applied to more
complex, realistic systems and some future applications are briefly outlined.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:27:35 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 11:46:13 GMT""}]","2020-11-04"
"2007.01334","Muhammad Aneeq Uz Zaman","Muhammad Aneeq uz Zaman and Aamer Iqbal Bhatti","Multi-agent Planning for thermalling gliders using multi level
  graph-search",,,,,"math.OC cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper solves a path planning problem for a group of gliders. The gliders
are tasked with visiting a set of interest points. The gliders have limited
range but are able to increase their range by visiting special points called
thermals. The problem addressed in this paper is of path planning for the
gliders such that, the total number of interest points visited by the gliders
is maximized. This is referred to as the multi-agent problem. The problem is
solved by first decomposing it into several single-agent problems. In a
single-agent problem a set of interest points are allocated to a single glider.
This problem is solved by planning a path which maximizes the number of visited
interest points from the allocated set. This is achieved through a uniform cost
graph search, as shown in our earlier work. The multi-agent problem now
consists of determining the best allocation (of interest points) for each
glider. Two ways are presented of solving this problem, a brute force search
approach as shown in earlier work and a Branch\&Bound type graph search. The
Branch&Bound approach is the main contribution of the paper. This approach is
proven to be optimal and shown to be faster than the brute force search using
simulations.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:30:15 GMT""}]","2020-07-06"
"2007.01335","Francois Drielsma","Francois Drielsma, Qing Lin, Pierre C\^ote de Soux, Laura Domin\'e,
  Ran Itay, Dae Heun Koh, Bradley J. Nelson, Kazuhiro Terao, Ka Vang Tsang,
  Tracy L. Usher","Clustering of Electromagnetic Showers and Particle Interactions with
  Graph Neural Networks in Liquid Argon Time Projection Chambers Data",,,,,"physics.ins-det cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Liquid Argon Time Projection Chambers (LArTPCs) are a class of detectors that
produce high resolution images of charged particles within their sensitive
volume. In these images, the clustering of distinct particles into
superstructures is of central importance to the current and future neutrino
physics program. Electromagnetic (EM) activity typically exhibits spatially
detached fragments of varying morphology and orientation that are challenging
to efficiently assemble using traditional algorithms. Similarly, particles that
are spatially removed from each other in the detector may originate from a
common interaction. Graph Neural Networks (GNNs) were developed in recent years
to find correlations between objects embedded in an arbitrary space. The Graph
Particle Aggregator (GrapPA) first leverages GNNs to predict the adjacency
matrix of EM shower fragments and to identify the origin of showers, i.e.
primary fragments. On the PILArNet public LArTPC simulation dataset, the
algorithm achieves achieves a shower clustering accuracy characterized by a
mean adjusted Rand index (ARI) of 97.8 % and a primary identification accuracy
of 99.8 %. It yields a relative shower energy resolution of $(4.1+1.4/\sqrt{E
(\text{GeV})})\,\%$ and a shower direction resolution of
$(2.1/\sqrt{E(\text{GeV})})^{\circ}$. The optimized algorithm is then applied
to the related task of clustering particle instances into interactions and
yields a mean ARI of 99.2 % for an interaction density of
$\sim\mathcal{O}(1)\,m^{-3}$.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:32:25 GMT""},{""version"":""v2"",""created"":""Tue, 22 Sep 2020 16:34:10 GMT""},{""version"":""v3"",""created"":""Tue, 15 Dec 2020 04:42:41 GMT""}]","2020-12-16"
"2007.01336","Andrew Fiori","Andrew Fiori and Cameron Franc","The unbounded denominator conjecture for the noncongruence subgroups of
  index $7$",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study modular forms for the minimal index noncongruence subgroups of the
modular group. Our main theorem is a proof of the unbounded denominator
conjecture for these groups, and we also provide a study of the Fourier
coefficients of Eisenstein series for one of these minimal groups.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:33:24 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jul 2020 03:00:26 GMT""}]","2020-07-13"
"2007.01337","Lucas Laird","Lucas Laird","Metric Dimension of Hamming Graphs and Applications to Computational
  Biology",,,,,"math.CO q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Genetic sequencing has become an increasingly affordable and accessible
source of genomic data in computational biology. This data is often represented
as $k$-mers, i.e., strings of some fixed length $k$ with symbols chosen from a
reference alphabet. In contrast, some of the most effective and well-studied
machine learning algorithms require numerical representations of the data. The
concept of metric dimension of the so-called Hamming graphs presents a
promising way to address this issue. A subset of vertices in a graph is said to
be resolving when the distances to those vertices uniquely characterize every
vertex in the graph. The metric dimension of a graph is the size of a smallest
resolving subset of vertices. Finding the metric dimension of a general graph
is a challenging problem, NP-complete in fact. Recently, an efficient algorithm
for finding resolving sets in Hamming graphs has been proposed, which suffices
to uniquely embed $k$-mers into a real vector space. Since the dimension of the
embedding is the cardinality of the associated resolving set, determining
whether or not a node can be removed from a resolving set while keeping it
resolving is of great interest. This can be quite challenging for large graphs
since only a brute-force approach is known for checking whether a set is a
resolving set or not. In this thesis, we characterize resolvability of Hamming
graphs in terms of a linear system over a finite domain: a set of nodes is
resolving if and only if the linear system has only a trivial solution over
said domain. We can represent the domain as the roots of a polynomial system so
the apparatus of Gr\""obner bases comes in handy to determine, whether or not a
set of nodes is resolving. As proof of concept, we study the resolvability of
Hamming graphs associated with octapeptides i.e. proteins sequences of length
eight.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:36:51 GMT""}]","2020-07-06"
"2007.01338","Nazar Arakelian","Nazar Arakelian and Pietro Speziali","Algebraic curves with automorphism groups of large prime order",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathcal{X}$ be an algebraic curve of genus $g$ defined over an
algebraically closed field $K$ of characteristic $p \geq 0$, and $q$ a prime
dividing $|\mbox{Aut}(\mathcal{X})|$. We say that $\mathcal{X}$ is a $q$-curve.
Homma proved that either $q \leq g+1$ or $q = 2g+1$, and classified
$(2g+1)$-curves. In this note, we classify $(g+1)$-curves, and fully
characterize the automorphism groups of $q$-curves for $q= 2g+1, g+1$. We also
give some partial results on $q$-curves for $q = g, g-1$.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:38:53 GMT""}]","2020-07-06"
"2007.01339","Jordan Moxon","Jordan Moxon, Mark A. Scheel, Saul A. Teukolsky","Improved Cauchy-characteristic evolution system for high-precision
  numerical relativity waveforms",,"Phys. Rev. D 102, 044052 (2020)","10.1103/PhysRevD.102.044052",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present several improvements to the Cauchy-characteristic evolution
procedure that generates high-fidelity gravitational waveforms at
$\mathcal{I}^+$ from numerical relativity simulations. Cauchy-characteristic
evolution combines an interior solution of the Einstein field equations based
on Cauchy slices with an exterior solution based on null slices that extend to
$\mathcal{I}^+$. The foundation of our improved algorithm is a comprehensive
method of handling the gauge transformations between the arbitrarily specified
coordinates of the interior Cauchy evolution and the unique (up to BMS
transformations) Bondi-Sachs coordinate system of the exterior characteristic
evolution. We present a reformulated set of characteristic evolution equations
better adapted to numerical implementation. In addition, we develop a method to
ensure that the angular coordinates used in the volume during the
characteristic evolution are asymptotically inertial. This provides a direct
route to an expanded set of waveform outputs and is guaranteed to avoid
pure-gauge logarithmic dependence that has caused trouble for previous spectral
implementations of the characteristic evolution equations. We construct a set
of Weyl scalars compatible with the Bondi-like coordinate systems used in
characteristic evolution, and determine simple, easily implemented forms for
the asymptotic Weyl scalars in our suggested set of coordinates.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:47:36 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 21:31:37 GMT""}]","2021-08-24"
"2007.01340","Branden Olson","Julia Fukuyama, Branden J Olson, Frederick A Matsen IV","Lack of evidence for a substantial rate of templated mutagenesis in B
  cell diversification",,,,,"q-bio.PE stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  B cell receptor sequences diversify through mutations introduced by
purpose-built cellular machinery. A recent paper has concluded that a
""templated mutagenesis"" process is a major contributor to somatic
hypermutation, and therefore immunoglobulin diversification, in mice and
humans. In this proposed process, mutations in the immunoglobulin locus are
introduced by copying short segments from other immunoglobulin genes. If true,
this would overturn decades of research on B cell diversification, and would
require a complete re-write of computational methods to analyze B cell data for
these species.
  In this paper, we re-evaluate the templated mutagenesis hypothesis. By
applying the original inferential method using potential donor templates absent
from B cell genomes, we obtain estimates of the methods's false positive rates.
We find false positive rates of templated mutagenesis in murine and human
immunoglobulin loci that are similar to or even higher than the original rate
inferences, and by considering the bases used in substitution we find evidence
that if templated mutagenesis occurs, it is at a low rate. We also show that
the statistically significant results in the original paper can easily result
from a slight misspecification of the null model.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:50:09 GMT""}]","2020-07-06"
"2007.01341","King-Yeung Lam","Robert Stephen Cantrell, Chris Cosner and King-Yeung Lam","Ideal Free Dispersal under General Spatial heterogeneity and Time
  Periodicity",,"SIAM J. Appl. Math., 81 (2021) 789-813","10.1137/20M1332712",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A population is said to have an ideal free distribution in a spatially
heterogeneous but temporally constant environment if each of its members have
chosen a fixed spatial location in a way that optimizes its individual fitness,
allowing for the effects of crowding. In this paper, we extend the idea of
individual fitness associated with a specific location in space to account for
the full path that an individual organism takes in space and time over a
periodic cycle, and extend the mathematical formulation of an ideal free
distribution to general time periodic environments. We find that, as in many
other cases, populations using dispersal strategies that can produce a
generalized ideal free distribution have a competitive advantage relative to
populations using strategies that do not produce an ideal free distribution. A
sharp criterion on the environmental functions is found to be necessary and
sufficient for such ideal free distribution to be feasible. In the case the
criterion is met, we showed that there exist dispersal strategies that can be
identified as producing a time-periodic version of an ideal free distribution,
and such strategies are evolutionarily steady and are neighborhood invaders
from the viewpoint of adaptive dynamics. Our results extend previous works in
which the environments are either temporally constant, or temporally periodic
but the total carrying capacity is temporally constant.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:59:41 GMT""}]","2021-07-26"
"2007.01342","Bradford Snios","Bradford Snios, Aneta Siemiginowska, Ma{\l}gosia Sobolewska, C. C.
  Cheung, Vinay Kashyap, Giulia Migliori, Daniel A. Schwartz, {\L}ukasz
  Stawarz, Diana M. Worrall","X-ray Properties of Young Radio Quasars at z > 4.5","Accepted to ApJ, 13 pages, 5 figures, 4 tables",,"10.3847/1538-4357/aba2ca",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a comprehensive analysis of Chandra X-ray observations of 15 young
radio quasars at redshifts $4.5 < z < 5.0$. All sources are detected in the
$0.5-7.0$ keV energy band. Emission spectra are extracted, and the average
photon index for the sample is measured to be $1.5\pm0.1$. Unabsorbed
rest-frame $2-10$ keV luminosities are found to range between $(0.5-23.2)
\times 10^{45}$ erg s$^{-1}$. The optical-X-ray power-law spectral index
$\alpha_{ox}$ is calculated for each source using optical/UV data available in
the literature. The $\alpha_{ox}$-UV relationship is compared with other quasar
surveys, and an anticorrelation is observed that agrees with independent
estimates. Rest-frame radio and X-ray luminosities are established for the
sample, and a correlation between the luminosities is detected. These
multiwavelength results reinforce a lack of spectral evolution for quasars over
a broad redshift range. We additionally identify three quasars from our
multiwavelength analysis that are statistically significant outliers, with one
source being a Compton-thick candidate in the early universe, and discuss each
in detail.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:07:06 GMT""},{""version"":""v2"",""created"":""Mon, 3 Aug 2020 18:03:15 GMT""}]","2020-08-26"
"2007.01343","Raymond Kapral","Bryan Robertson, Jeremy Schofield, Pierre Gaspard and Raymond Kapral","Molecular theory of Langevin dynamics for active self-diffusiophoretic
  colloids","15 pages, 2 figures",,"10.1063/5.0020553",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active colloidal particles that are propelled by a self-diffusiophoretic
mechanism are often described by Langevin equations that are either postulated
on physical grounds or derived using the methods of fluctuating hydrodynamics.
While these descriptions are appropriate for colloids of micrometric and larger
size, they will break down for very small active particles. A fully microscopic
derivation of Langevin equations for self-diffusiophoretic particles powered by
chemical reactions catalyzed asymmetrically by the colloid is given in this
paper. The derivation provides microscopic expressions for the translational
and rotational friction tensors, as well as reaction rate coefficients
appearing in the Langevin equations. The diffusiophoretic force and torque are
expressed in terms of nonequilibrium averages of fluid fields that satisfy
generalized transport equations. The results provide a description of active
motion on small scales where descriptions in terms of coarse grained continuum
fluid equations combined with boundary conditions that account for the presence
of the colloid may not be appropriate.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:07:26 GMT""}]","2020-10-28"
"2007.01344","Rui Wang","Rui Wang, Yuta Hozumi, Changchuan Yin, and Guo-Wei Wei","Decoding asymptomatic COVID-19 infection and transmission","18 pages, 5 figures",,,,"q-bio.PE q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coronavirus disease 2019 (COVID-19) is a continuously devastating public
health and the world economy. One of the major challenges in controlling the
COVID-19 outbreak is its asymptomatic infection and transmission, which are
elusive and defenseless in most situations. The pathogenicity and virulence of
asymptomatic COVID-19 remain mysterious. Based on the genotyping of 20656
Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) genome isolates,
we reveal that asymptomatic infection is linked to SARS-CoV-2 11083G>T
mutation, i.e., leucine (L) to phenylalanine (F) substitution at the residue 37
(L37F) of nonstructure protein 6 (NSP6). By analyzing the distribution of
11083G>T in various countries, we unveil that 11083G>T may correlate with the
hypotoxicity of SARS-CoV-2. Moreover, we show a global decaying tendency of the
11083G>T mutation ratio indicating that 11083G>T hinders SARS-CoV-2
transmission capacity. Sequence alignment found both NSP6 and residue 37
neighborhoods are relatively conservative over a few coronaviral species,
indicating their importance in regulating host cell autophagy to undermine
innate cellular defense against viral infection. Using machine learning and
topological data analysis, we demonstrate that mutation L37F has made NSP6
energetically less stable. The rigidity and flexibility index and several
network models suggest that mutation L37F may have compromised the NSP6
function, leading to a relatively weak SARS-CoV subtype. This assessment is a
good agreement with our genotyping of SARS-CoV-2 evolution and transmission
across various countries and regions over the past few months.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:09:26 GMT""}]","2020-07-06"
"2007.01345","Abdellah Lahdili","Abdellah Lahdili","Convexity of the weighted Mabuchi functional and the uniqueness of
  weighted extremal metrics","21 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the uniqueness, up to a pull-back by an element of a suitable
subgroup of complex automorphisms, of the weighted extremal K\""ahler metrics on
a compact K\""ahler manifold introduced in our previous work. This extends a
result by Berman--Berndtsson and Chen--Paun--Zeng in the extremal K\""ahler
case. Furthermore, we show that a weighted extremal K\""ahler metric is a global
minimum of a suitable weighted version of the modified Mabuchi energy. This
implies a suitable notion of weighted K-semistability of a K\""ahler manifold
admitting a weighted extremal K\""ahler metric.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:09:58 GMT""}]","2020-07-06"
"2007.01346","Umang Varma","Umang Varma, Lalit Jain, Anna C. Gilbert","Spectral Methods for Ranking with Scarce Data","To appear in Proceedings of Uncertainty in Artificial Intelligence
  (UAI) 2020",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Given a number of pairwise preferences of items, a common task is to rank all
the items. Examples include pairwise movie ratings, New Yorker cartoon caption
contests, and many other consumer preferences tasks. What these settings have
in common is two-fold: a scarcity of data (it may be costly to get comparisons
for all the pairs of items) and additional feature information about the items
(e.g., movie genre, director, and cast). In this paper we modify a popular and
well studied method, RankCentrality for rank aggregation to account for few
comparisons and that incorporates additional feature information. This method
returns meaningful rankings even under scarce comparisons. Using diffusion
based methods, we incorporate feature information that outperforms
state-of-the-art methods in practice. We also provide improved sample
complexity for RankCentrality in a variety of sampling schemes.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:17:35 GMT""}]","2020-07-06"
"2007.01347","Parthapratim  Pradhan","Parthapratim Pradhan","Distinguishing Black Hole and Naked Singularity in MOG via Inertial
  Frame Dragging Effect","44 pages",,,,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We analyze the generalized spin precession of a test gyroscope around a
stationary spacetime i.e. for Kerr-MOG black hole~(BH) in scalar-tensor-vector
gravity or modified gravity~(MOG). A detailed study of generalized spin
frequency has been done for \emph{non} extremal Kerr-MOG BH, \emph{extremal}
Kerr-MOG BH and \emph{naked singularity~(NS)} in comparison to non-extremal BH,
extremal BH, and NS of Kerr spacetime. The generalized spin frequency that {we
have} computed could be expressed in terms of {the} BH mass parameter, the
angular momentum parameter, and the MOG parameter. Moreover, we differentiate
the non-extremal BH, extremal BH, and NS via computation of the said precession
frequency. The Lense-Thirring~(LT) frequency {can} obtain from generalized spin
frequency by taking the limit as $\Omega=0$ i. e. {when the} angular frequency
is set to zero limit. Furthermore, we compute the LT frequency for various
{values of} angular coordinates i.e. starting from polar to {the} equatorial
plane. We show that the LT frequency diverges at the horizon for extremal BH.
Finally, we study the accretion disk physics by computing three epicyclic
frequencies namely the Keplerian frequency, {the} radial epicyclic frequency
and {the} vertical epicyclic frequency. We also compute the periastron
frequency and nodal frequency. With the aid of these frequency profiles, {one}
can distinguish three compact objects i. e. \emph{non-extremal BH, extremal BH}
{and} \emph{NS}.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:19:53 GMT""}]","2020-07-06"
"2007.01348","Hasan Unlu","Hasan Unlu","Efficient Neural Network Deployment for Microcontroller",,,,,"cs.AR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Edge computing for neural networks is getting important especially for low
power applications and offline devices. TensorFlow Lite and PyTorch Mobile were
released for this purpose. But they mainly support mobile devices instead of
microcontroller level yet. Microcontroller support is an emerging area now.
There are many approaches to reduce network size and compute load like pruning,
binarization and layer manipulation i.e. operator reordering. This paper is
going to explore and generalize convolution neural network deployment for
microcontrollers with two novel optimization proposals offering memory saving
and compute efficiency in 2D convolutions as well as fully connected layers.
The first one is in-place max-pooling, if the stride is greater than or equal
to pooling kernel size. The second optimization is to use ping-pong buffers
between layers to reduce memory consumption significantly. The memory savings
and performance will be compared with CMSIS-NN framework developed for ARM
Cortex-M CPUs. The final purpose is to develop a tool consuming PyTorch model
with trained network weights, and it turns into an optimized inference
engine(forward pass) in C/C++ for low memory(kilobyte level) and limited
computing capable microcontrollers.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:21:05 GMT""}]","2020-07-06"
"2007.01349","Fabiano L. Ribeiro","Gabriel G. Piva, Fabiano L. Ribeiro and Angelica S. Mata","Networks with Growth and Preferential Attachment: Modeling and
  Applications",,,,,"physics.soc-ph cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we presented a brief study of the main network models with
growth and preferential attachment. Such models are interesting because they
present several characteristics of real systems. We started with the classical
model proposed by Barabasi and Albert: nodes are added to the network
connecting preferably to other nodes that are more connected. We also presented
models that consider more representative elements from social perspectives,
such as the homophily between the vertices or the fitness that each node has to
build connections. Furthermore, we showed a version of these models including
the Euclidean distance between the nodes as a preferential attachment rule. Our
objective is to investigate the basic properties of these networks as
distribution of connectivity, degree correlation, shortest path, cluster
coefficient and how these characteristics are affected by the preferential
attachment rules. Finally, we also provided a comparison of these synthetic
networks with real ones. We found that characteristics as homophily, fitness
and geographic distance are significant preferential attachment rules to
modeling real networks. These rules can change the degree distribution form of
these synthetic network models and make them more suitable to model real
networks.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:23:15 GMT""}]","2020-07-06"
"2007.01350","Jiri Navratil","Jiri Navratil, Matthew Arnold, Benjamin Elder","Uncertainty Prediction for Deep Sequential Regression Using Meta Models",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generating high quality uncertainty estimates for sequential regression,
particularly deep recurrent networks, remains a challenging and open problem.
Existing approaches often make restrictive assumptions (such as stationarity)
yet still perform poorly in practice, particularly in presence of real world
non-stationary signals and drift. This paper describes a flexible method that
can generate symmetric and asymmetric uncertainty estimates, makes no
assumptions about stationarity, and outperforms competitive baselines on both
drift and non drift scenarios. This work helps make sequential regression more
effective and practical for use in real-world applications, and is a powerful
new addition to the modeling toolbox for sequential uncertainty quantification
in general.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:27:17 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 21:59:50 GMT""}]","2021-07-26"
"2007.01351","Andrea Blanco Redondo PhD","Joshua P. Lourdesamy, Antoine F. J. Runge, Tristram J. Alexander,
  Darren D. Hudson, Andrea Blanco-Redondo, C. Martijn de Sterke","Polychromatic soliton molecules",,,,,"physics.optics nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Soliton molecules, bound states composed of interacting fundamental solitons,
exhibit remarkable resemblance with chemical compounds and phenomena in quantum
mechanics. Whereas optical molecules composed of two or more temporally locked
solitons have been observed in a variety of platforms, soliton molecules formed
by bound solitons at different frequencies have only recently been
theoretically proposed. Here, we report the observation of polychromatic
soliton molecules within a mode-locked laser cavity, achieving the desired
dispersion by implementing a spectral pulse-shaper. This system supports two or
more coincident solitons with different frequencies, but common group
velocities. Our results open new directions of exploration in nonlinear
dynamics within systems with complex dispersion and offer a convenient platform
for optical analogies to mutual trapping and spectral tunneling in quantum
mechanics.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:27:48 GMT""}]","2020-07-06"
"2007.01352","Mohamad Maassarani","Mohamad Maassarani","Algebraic invariants of orbit configuration spaces in genus zero
  associated to finite groups",,,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider orbit configuration spaces associated to finite groups acting
freely by orientation preserving homeomorphisms on the $2$-sphere minus a
finite number of points. Such action is equivalent to a homography action of a
finite subgroup $G\subset \mathrm{PGL}(\mathbb{C}^2)$ on the complex projective
line $\mathbb{P}^1$ minus a finite set $Z$ stable under $G$. We compute the
cohomology ring and the Poincar\'e series of the orbit configuration space
$C_n^G(\mathbb{P}^1 \setminus Z)$. This can be seen as a generalization of the
work of Arnold for the classical configuration space $C_n(\mathbb{C})$
($(G,Z)=(\{1\},\infty$)). It follows from the work that
$C_n^G(\mathbb{P}^1\setminus Z)$ is formal in the sense of rational homotopy
theory. We also prove the existence of an LCS formula relating the Poincar\'e
series of $C_n^G(\mathbb{P}^1\setminus Z)$ to the ranks of quotients of
successive terms of the lower central series of the fundamental group of
$C_n^G(\mathbb{P}^1 \setminus Z)$. The successive quotients correspond to
homogenous elements of graded Lie algebras introduced by the author in an
earlier work. Such formula is also known for classical configuration spaces of
$\mathbb{C}$, where fundamental groups are Artin braid groups and the ranks
correspond to dimensions of homogenous elements of the Kohno-Drinfeld Lie
algebras.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:28:04 GMT""}]","2020-07-06"
"2007.01353","Deaglan Bartlett","Deaglan J. Bartlett, Harry Desmond, Julien Devriendt, Pedro G.
  Ferreira and Adrianne Slyz","Spatially offset black holes in the Horizon-AGN simulation and
  comparison to observations","19 pages, 15 figures, accepted for publication in MNRAS",,"10.1093/mnras/staa3516",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the displacements between the centres of galaxies and their
supermassive black holes (BHs) in the cosmological hydrodynamical simulation
Horizon-AGN, and in a variety of observations from the literature. The BHs in
Horizon-AGN feel a sub-grid dynamical friction force, sourced by the
surrounding gas, which prevents recoiling BHs being ejected from the galaxy. We
find that i) the fraction of spatially offset BHs increases with cosmic time,
ii) BHs live on prograde orbits in the plane of the galaxy with an orbital
radius that decays with time but stalls near $z=0$, and iii) the magnitudes of
offsets from the galaxy centres are substantially larger in the simulation than
in observations. We attribute the stalling of the infall and excessive offset
magnitudes to the fact that dynamical friction from stars and dark matter is
not modelled in the simulation, and hence provide a way to improve the black
hole dynamics of future simulations.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:37:06 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 14:29:00 GMT""}]","2020-12-04"
"2007.01354","Timothy Burness","Timothy C. Burness and Elisa Covato","On the involution fixity of simple groups","14 pages; to appear in Proc. Edinb. Math. Soc",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be a finite permutation group of degree $n$ and let ${\rm ifix}(G)$
be the involution fixity of $G$, which is the maximum number of fixed points of
an involution. In this paper we study the involution fixity of almost simple
primitive groups whose socle $T$ is an alternating or sporadic group; our main
result classifies the groups of this form with ${\rm ifix}(T) \leqslant
n^{4/9}$. This builds on earlier work of Burness and Thomas, who studied the
case where $T$ is an exceptional group of Lie type, and it strengthens the
bound ${\rm ifix}(T) > n^{1/6}$ (with prescribed exceptions), which was proved
by Liebeck and Shalev in 2015. A similar result for classical groups will be
established in a sequel.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:38:01 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 10:59:45 GMT""}]","2021-05-11"
"2007.01356","Yifei Wang","Yifei Wang, Dan Peng, Furui Liu, Zhenguo Li, Zhitang Chen, Jiansheng
  Yang","Decoder-free Robustness Disentanglement without (Additional) Supervision",,,,,"stat.ML cs.CV cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial Training (AT) is proposed to alleviate the adversarial
vulnerability of machine learning models by extracting only robust features
from the input, which, however, inevitably leads to severe accuracy reduction
as it discards the non-robust yet useful features. This motivates us to
preserve both robust and non-robust features and separate them with
disentangled representation learning. Our proposed Adversarial Asymmetric
Training (AAT) algorithm can reliably disentangle robust and non-robust
representations without additional supervision on robustness. Empirical results
show our method does not only successfully preserve accuracy by combining two
representations, but also achieve much better disentanglement than previous
work.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:51:40 GMT""}]","2020-07-06"
"2007.01357","Yongchan Kwon","Yongchan Kwon, Manuel A. Rivas, James Zou","Efficient computation and analysis of distributional Shapley values","24 pages, accepted for AISTATS 2021",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributional data Shapley value (DShapley) has recently been proposed as a
principled framework to quantify the contribution of individual datum in
machine learning. DShapley develops the foundational game theory concept of
Shapley values into a statistical framework and can be applied to identify data
points that are useful (or harmful) to a learning algorithm. Estimating
DShapley is computationally expensive, however, and this can be a major
challenge to using it in practice. Moreover, there has been little mathematical
analyses of how this value depends on data characteristics. In this paper, we
derive the first analytic expressions for DShapley for the canonical problems
of linear regression, binary classification, and non-parametric density
estimation. These analytic forms provide new algorithms to estimate DShapley
that are several orders of magnitude faster than previous state-of-the-art
methods. Furthermore, our formulas are directly interpretable and provide
quantitative insights into how the value varies for different types of data. We
demonstrate the practical efficacy of our approach on multiple real and
synthetic datasets.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:51:54 GMT""},{""version"":""v2"",""created"":""Sat, 17 Oct 2020 10:30:57 GMT""},{""version"":""v3"",""created"":""Wed, 17 Feb 2021 21:38:22 GMT""}]","2021-02-19"
"2007.01358","S. A. Kuzmichev","Z. Popovic, S. Kuzmichev, T. Kuzmicheva","Amplitudes of minima in dynamic conductance spectra of the SNS Andreev
  contact","9 pages, 8 figures","Journal of Applied Physics 128, 013901 (2020)","10.1063/5.0010883",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite several theoretical approaches describing multiple Andreev
reflections (MAR) effect in superconductor-normal metal-superconductor (SNS)
junction are elaborated, the problem of comprehensive and adequate description
of MAR is highly actual. In particular, a broadening parameter $\Gamma$ is
still unaccounted at all, whereas a ballistic condition (the mean free path for
inelastic scattering $l$ to the barrier width $d$ ratio) is considered only in
the framework of K\""{u}mmel, Gunsenheimer, and Nikolsky (KGN), as well as
Gunsenheimer-Zaikin approaches, for an isotropic case and fully-transparent
constriction. Nonetheless, an influence of $l/d$ ratio to the dynamic
conductance spectrum ($dI/dV$) features remains disregarded, thus being one of
the aims of the current work. Our numerical calculations in the framework of an
extended KGN approach develop the $l/d$ variation to determine both the number
of the Andreev features and their amplitudes in the $dI/dV$ spectrum. We show,
in the spectrum of a diffusive SNS junction ($l/d \rightarrow 1$) a suppression
of the Andreev excess current, dramatic change in the current voltage
$I(V)$-curve slope at low bias, with only the main harmonic at $eV=2\Delta$
bias voltage remains well-distinguished in the $dI/dV$-spectrum. Additionally,
we attempt to make a first-ever comparison between experimental data for the
high-transparency SNS junctions (more than $ 85~\%$) and theoretical
predictions. As a result, we calculate the temperature dependences of
amplitudes and areas of Andreev features within the extended KGN approach,
which qualitatively agrees with our experimental data obtained using a
""break-junction"" technique.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:54:38 GMT""}]","2020-07-06"
"2007.01359","Santosh Kesiraju","Santosh Kesiraju, Sangeet Sagar, Ond\v{r}ej Glembek, Luk\'a\v{s}
  Burget, Suryakanth V Gangashetty","Bayesian multilingual topic model for zero-shot cross-lingual topic
  identification","Requires a major revision",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a Bayesian multilingual topic model for learning
language-independent document embeddings. Our model learns to represent the
documents in the form of Gaussian distributions, thereby encoding the
uncertainty in its covariance. We propagate the learned uncertainties through
linear classifiers for zero-shot cross-lingual topic identification. Our
experiments on 5 language Europarl and Reuters (MLDoc) corpora show that the
proposed model outperforms multi-lingual word embedding and BiLSTM sentence
encoder based systems with significant margins in the majority of the transfer
directions. Moreover, our system trained under a single day on a single GPU
with much lower amounts of data performs competitively as compared to the
state-of-the-art universal BiLSTM sentence encoder trained on 93 languages. Our
experimental analysis shows that the amount of parallel data improves the
overall performance of embeddings. Nonetheless, exploiting the uncertainties is
always beneficial.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:55:08 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 12:46:45 GMT""}]","2020-12-03"
"2007.01360","Connor Dowd","Connor Dowd","A New ECDF Two-Sample Test Statistic",,,,,"stat.ME stat.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Empirical cumulative distribution functions (ECDFs) have been used to test
the hypothesis that two samples come from the same distribution since the
seminal contribution by Kolmogorov and Smirnov. This paper describes a
statistic which is usable under the same conditions as Kolmogorov-Smirnov, but
provides more power than other extant tests in that vein. I demonstrate a valid
(conservative) procedure for producing finite-sample p-values. I outline the
close relationship between this statistic and its two main predecessors. I also
provide a public R package (CRAN: twosamples [2018]) implementing the testing
procedure in $O(N\log(N))$ time with $O(N)$ memory. Using the package's
functions, I perform several simulation studies showing the power improvements.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:55:37 GMT""}]","2020-07-06"
"2007.01361","Shaolin Liao Dr.","Yu Peng and Shaolin Liao","Bound States in Continuum and Zero-Index Metamaterials: A Review","14 pages, 23 figures",,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bound states in the continuum (BICs) are waves that remain localized even
though they coexist with a continuous spectrum of radiating waves that can
carry energy away. Their very existence defies conventional wisdom. Although
BICs were first proposed in quantum mechanics, they are a general wave
phenomenon and have since been identified in electromagnetic waves, acoustic
waves in air, water waves and elastic waves in solids. These states have been
studied in a wide range of material systems, such as piezoelectric materials,
dielectric photonic crystals, optical waveguides and fibers, quantum dots,
graphene and topological insulators. In this Review, we describe recent
developments in this field with an emphasis on the physical mechanisms that
lead to BICs across seemingly very different materials and types of waves. We
also discuss experimental realizations, existing applications and directions
for future work. At last, we present our recent effort to design a novel type
of silicon (Si) based mu-Near-Zero (uNZ) metamaterials that reduces radiative
loss through destructive interference of multiple loss channels, resulting in a
bound state in the continuum. This design consists of Si pillars array. By
adjusting the unit-cell dimensions including radius, pitch and height, we can
eliminate the out-of-plane radiation.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:57:56 GMT""}]","2020-07-06"
"2007.01362","Themis Matsoukas","Themis Matsoukas","Thermodynamics and the Evolution of Stochastic Populations","Presented at Thermodynamics 2.0, June 20-22, originally planned in
  Worchester MA but switched on zoom due to covid-19",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The appeal of thermodynamics to problems outside physics is undeniable, as is
the growing recognition of its apparent universality, yet in the absence of a
rigorous formalism divorced from the peculiarities of molecular systems all
attempts to generalize thermodynamics remain qualitative and heuristic at best.
In this paper we formulate a probabilistic theory of thermodynamics and and set
the basis for its application to generic stochastic populations.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:02:14 GMT""}]","2020-07-06"
"2007.01363","Armita Nourmohammad","Oskar H Schnaack, Armita Nourmohammad","Optimal evolutionary decision-making to store immune memory",,,,,"q-bio.PE physics.bio-ph q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The adaptive immune system provides a diverse set of molecules that can mount
specific responses against a multitude of pathogens. Memory is a key feature of
adaptive immunity, which allows organisms to respond more readily upon
re-infections. However, differentiation of memory cells is still one of the
least understood cell fate decisions. Here, we introduce a mathematical
framework to characterize optimal strategies to store memory to maximize the
utility of immune response over an organism's lifetime. We show that memory
production should be actively regulated to balance between affinity and
cross-reactivity of immune receptors for an effective protection against
evolving pathogens. Moreover, we predict that specificity of memory should
depend on the organism's lifespan, and shorter-lived organisms with fewer
pathogenic encounters should store more cross-reactive memory. Our framework
provides a baseline to gauge the efficacy of immune memory in light of an
organism's coevolutionary history with pathogens.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:03:11 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 23:14:52 GMT""}]","2021-04-14"
"2007.01364","Tobias Schmidt","C\'edric P\'epin and Tobias Schmidt","Generic and Mod p Kazhdan-Lusztig Theory for GL_2","46 pages, some typos/minor inaccuracies fixed, added a subsection on
  central characters",,,,"math.NT math.AG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $F$ be a non-archimedean local field with residue field $\mathbb{F}_q$
and let $G = GL_{2/F}$. Let $\mathbf{q}$ be an indeterminate and let
$H^{(1)}(\mathbf{q})$ be the generic pro-p Iwahori-Hecke algebra of the group
$G(F)$. Let $V_{\widehat{G}}$ be the Vinberg monoid of the dual group
$\widehat{G}$. We establish a generic version for $H^{(1)}(\mathbf{q})$ of the
Kazhdan-Lusztig-Ginzburg spherical representation, the Bernstein map and the
Satake isomorphism. We define the flag variety for the monoid $V_{\widehat{G}}$
and establish the characteristic map in its equivariant K-theory. These generic
constructions recover the classical ones after the specialization $\mathbf{q} =
q \in \mathbb{C}$. At $\mathbf{q} = q = 0 \in\overline{\mathbb{F}}_q$, the
spherical map provides a dual parametrization of all the irreducible
$H^{(1)}_{\overline{\mathbb{F}}_q}(0)$-modules.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:06:04 GMT""},{""version"":""v2"",""created"":""Thu, 23 Sep 2021 16:34:25 GMT""}]","2021-09-24"
"2007.01365","Vincent Hocd\'e","V. Hocd\'e, N. Nardetto, S. Borgniet, E. Lagadec, P. Kervella, A.
  M\'erand, N. Evans, D. Gillet, Ph. Mathias, A. Chiavassa, A. Gallenne, L.
  Breuval, B. Javanmardi","Pulsating chromosphere of classical Cepheids. Calcium infrared triplet
  and H$\alpha$ profile variations","25 pages, 30 figures",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been shown recently that the infrared emission of Cepheids, which is
constant over the pulsation cycle, might be due to a pulsating shell of ionized
gas of about 15\% of the stellar radius, which could be attributed to the
chromospheric activity of Cepheids. The aim of this paper is to investigate the
dynamical structure of the chromosphere of Cepheids along the pulsation cycle
and quantify its size. We present H$\alpha$ and Calcium Near InfraRed triplet
(Ca IR) profile variations using high-resolution spectroscopy with the UVES
spectrograph of a sample of 24 Cepheids with a good period coverage from
$\approx$ 3 to 60 days. After a qualitative analysis of the spectral lines
profiles, we quantify the Van Hoof effect (velocity gradient between the
H$\alpha$ and Ca IR) as a function of the period of the Cepheids. Then, we use
the Schwarzschild mechanism (a line doubling due to a shock wave) to quantify
the size of the chromosphere. We find a significant Van Hoof effect for
Cepheids with period larger than $P=10$ days, in particular H$\alpha$ lines are
delayed with a velocity gradient up to $\Delta v \approx$30 km/s compared to Ca
IR. We find that the size of the chromosphere of long-period Cepheids is of at
least $\approx$ 50\% of the stellar radius, which is consistent at first order
with the size of the shell made of ionized gas previously found from the
analysis of infrared excess. Last, for most of the long-period Cepheids in the
sample, we report a motionless absorption feature in the H$\alpha$ line that we
attribute to a circumstellar envelope that surrounds the chromosphere.
Analyzing the Ca~IR lines of Cepheids is of importance to potentially unbias
the period-luminosity relation from their infrared excess, particularly in the
context of forthcoming observations from the Radial Velocity Spectrometer (RVS)
on board \textit{Gaia}, that could be sensitive to their chromosphere.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:06:58 GMT""}]","2020-07-06"
"2007.01366","Siu-Hung Ng","Siu-Hung Ng, Yilong Wang and Qing Zhang","Modular categories with transitive Galois actions","Minor errors in proposition 5.11 and the associated parts in this
  version of the paper have been corrected","Comm. Math. Phys. 390, 1271-1310 (2022)","10.1007/s00220-021-04287-5",,"math.QA math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study modular categories whose Galois group actions on
their simple objects are transitive. We show that such modular categories admit
unique factorization into prime transitive factors. The representations of
$SL_2(\mathbb{Z})$ associated with transitive modular categories are proven to
be minimal and irreducible. Together with the Verlinde formula, we characterize
prime transitive modular categories as the Galois conjugates of the adjoint
subcategory of the quantum group modular category
$\mathcal{C}(\mathfrak{sl}_2,p-2)$ for some prime $p > 3$. As a consequence, we
completely classify transitive modular categories. Transitivity of
super-modular categories can be similarly defined. A unique factorization of
any transitive super-modular category into s-simple transitive factors is
obtained, and the split transitive super-modular categories are completely
classified.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:07:56 GMT""},{""version"":""v2"",""created"":""Sun, 24 Jan 2021 23:06:50 GMT""},{""version"":""v3"",""created"":""Tue, 22 Jun 2021 04:22:30 GMT""}]","2022-04-12"
"2007.01367","Sean Meyn","Tamer Basar and Sean Meyn, and William R. Perkins","Lecture Notes on Control System Theory and Design",,,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is a collection of the lecture notes of the three authors for a
first-year graduate course on control system theory and design (ECE 515 ,
formerly ECE 415) at the ECE Department of the University of Illinois at
Urbana-Champaign. This is a fundamental course on the modern theory of
dynamical systems and their control, and builds on a first-level course in
control that emphasizes frequency-domain methods (such as the course ECE 486 ,
formerly ECE 386, at UIUC ). The emphasis in this graduate course is on state
space techniques, and it encompasses modeling , analysis (of structural
properties of systems, such as stability, controllability, and observability),
synthesis (of observers/compensators and controllers) subject to design
specifications, and optimization . Accordingly, this set of lecture notes is
organized in four parts, with each part dealing with one of the issues
identified above. Concentration is on linear systems , with nonlinear systems
covered only in some specific contexts, such as stability and dynamic
optimization. Both continuous-time and discrete-time systems are covered, with
the former, however, in much greater depth than the latter.
  The main objective of this course is to teach the student some fundamental
principles within a solid conceptual framework, that will enable her/him to
design feedback loops compatible with the information available on the ""states""
of the system to be controlled, and by taking into account considerations such
as stability, performance, energy conservation, and even robustness. A second
objective is to familiarize her/him with the available modern computational,
simulation, and general software tools that facilitate the design of effective
feedback loops
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:08:04 GMT""}]","2020-07-06"
"2007.01368","Quanzhi Ye","Quanzhi Ye, Tony L. Farnham, Matthew M. Knight, Carrie E. Holt, Lori
  M. Feaga","Recovery of Returning Halley-Type Comet 12P/Pons-Brooks With the Lowell
  Discovery Telescope","Submitted to RNAAS",,,,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the recovery of returning Halley-type comet 12P/Pons-Brooks using
the 4.3 m Lowell Discovery Telescope, at a heliocentric distance of 11.89 au.
Comparative analysis with a dust model suggests that the comet may have been
active since $\sim30$ au from the Sun. We derive a nucleus radius of $17\pm6$
km from the nucleus photometry, though this number is likely an overestimation
due to the contamination from dust and gas. Continuing monitoring is encouraged
in anticipation of the comet's forthcoming perihelion in 2024 April.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:08:19 GMT""}]","2020-07-06"
"2007.01369","Abhinav Goel","Abhinav Goel, Caleb Tung, Sara Aghajanzadeh, Isha Ghodgaonkar, Shreya
  Ghosh, George K. Thiruvathukal, Yung-Hsiang Lu","Low-Power Object Counting with Hierarchical Neural Networks","Paper accepted to ISLPED 2020: ACM/IEEE International Symposium on
  Low Power Electronics and Design",,"10.1145/3370748.3406569",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep Neural Networks (DNNs) can achieve state-of-the-art accuracy in many
computer vision tasks, such as object counting. Object counting takes two
inputs: an image and an object query and reports the number of occurrences of
the queried object. To achieve high accuracy on such tasks, DNNs require
billions of operations, making them difficult to deploy on
resource-constrained, low-power devices. Prior work shows that a significant
number of DNN operations are redundant and can be eliminated without affecting
the accuracy. To reduce these redundancies, we propose a hierarchical DNN
architecture for object counting. This architecture uses a Region Proposal
Network (RPN) to propose regions-of-interest (RoIs) that may contain the
queried objects. A hierarchical classifier then efficiently finds the RoIs that
actually contain the queried objects. The hierarchy contains groups of visually
similar object categories. Small DNNs are used at each node of the hierarchy to
classify between these groups. The RoIs are incrementally processed by the
hierarchical classifier. If the object in an RoI is in the same group as the
queried object, then the next DNN in the hierarchy processes the RoI further;
otherwise, the RoI is discarded. By using a few small DNNs to process each
image, this method reduces the memory requirement, inference time, energy
consumption, and number of operations with negligible accuracy loss when
compared with the existing object counters.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:13:01 GMT""}]","2020-07-06"
"2007.01370","Thomas Webster","Thomas F. Webster and Marc G. Weisskopf","Epidemiology of exposure to mixtures: we cant be casual about causality
  when using or testing methods","28 pages, 2 figures",,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  Background: There is increasing interest in approaches for analyzing the
effect of exposure mixtures on health. A key issue is how to simultaneously
analyze often highly collinear components of the mixture, which can create
problems such as confounding by co-exposure and co-exposure amplification bias
(CAB). Evaluation of novel mixtures methods, typically using synthetic data, is
critical to their ultimate utility. Objectives: This paper aims to answer two
questions. How do causal models inform the interpretation of statistical models
and the creation of synthetic data used to test them? Are novel mixtures
methods susceptible to CAB? Methods: We use directed acyclic graphs (DAGs) and
linear models to derive closed form solutions for model parameters to examine
how underlying causal assumptions affect the interpretation of model results.
Results: The same beta coefficients estimated by a statistical model can have
different interpretations depending on the assumed causal structure. Similarly,
the method used to simulate data can have implications for the underlying DAG
(and vice versa), and therefore the identification of the parameter being
estimated with an analytic approach. We demonstrate that methods that can
reproduce results of linear regression, such as Bayesian kernel machine
regression and the new quantile g-computation approach, will be subject to CAB.
However, under some conditions, estimates of an overall effect of the mixture
is not subject to CAB and even has reduced uncontrolled bias. Discussion: Just
as DAGs encode a priori subject matter knowledge allowing identification of
variable control needed to block analytic bias, we recommend explicitly
identifying DAGs underlying synthetic data created to test statistical mixtures
approaches. Estimates of the total effect of a mixture is an important but
relatively underexplored topic that warrants further investigation.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:14:34 GMT""}]","2020-07-06"
"2007.01371","Avrajit Bandyopadhyay","Avrajit Bandyopadhyay, Thirupathi Sivarani, Timothy C. Beers","Abundance Analysis of New $r$-Process-Enhanced Stars from the HESP-GOMPA
  Survey","22 pages, 10 figures, 9 tables, Accepted for publication in The
  Astrophysical Journal",,"10.3847/1538-4357/ab9c9d",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a study on the detailed chemical abundances of five new relatively
bright $r$-process-enhanced stars that were initially observed as part of the
SDSS/MARVELS pre-survey. These stars were selected, on the basis of their
metallicities and carbon abundances, among a total of 60 stars, for
high-resolution spectroscopic follow-up as part of the HESP-GOMPA survey (Hanle
Echelle SPectrograph -- Galactic survey Of Metal Poor stArs). Here we discuss
the three new $r$-I and two new $r$-II stars found in this survey. We have
carried out a detailed abundance analysis for each of these stars, at a
resolving power of $R \sim 30,000$, and compare our results to the existing
literature. We could measure three of the first $r$-process-peak elements (Sr,
Y and Zr) in all five stars, while Ba, Ce, Nd, Sm, Eu, and Dy could be detected
among the second $r$-process-peak elements. Thorium could also be detected in
one of the targets, which is found to be an actinide-boost star. We have
carried out a comparative study among the sub-populations of the
$r$-process-enhanced stars and other stars of the Milky Way halo population to
constrain the origin of this class of objects. These bright
$r$-process-enhanced stars provide an excellent opportunity to study the
nucleosynthesis history of this population in great detail, and shed light on
their chemical-enrichment histories.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:18:47 GMT""}]","2020-08-19"
"2007.01372","Reed Essick","Reed Essick, Philippe Landry","Discriminating between Neutron Stars and Black Holes with Imperfect
  Knowledge of the Maximum Neutron Star Mass","20 pages, 3 figures, 4 tables",,"10.3847/1538-4357/abbd3b",,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although gravitational-wave signals from exceptional low-mass compact binary
coalescences, like GW170817, may carry matter signatures that differentiate the
source from a binary black hole system, only one out of every eight events
detected by the current Advanced LIGO and Virgo observatories are likely to
have signal-to-noise ratios large enough to measure matter effects, even if
they are present. Nonetheless, the systems' component masses will generally be
constrained precisely. Constructing an explicit mixture model for the total
rate density of merging compact objects, we develop a hierarchical Bayesian
analysis to classify gravitational-wave sources according to the posterior odds
that their component masses are drawn from different subpopulations. Accounting
for current uncertainty in the maximum neutron star mass, and adopting
different reasonable models for the total rate density, we examine two recent
events from the LIGO-Virgo Collaboration's third observing run, GW190425 and
GW190814. For population models with no overlap between the neutron star and
black hole mass distributions, we typically find that there is a $\gtrsim 70\%$
chance that GW190425 was a binary neutron star merger rather than a
neutron-star--black-hole merger. On the other hand, we find that there is a
$\lesssim 6\%$ chance that GW190814 involved a slowly spinning neutron star,
regardless of our assumed population model.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:25:52 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 20:59:41 GMT""},{""version"":""v3"",""created"":""Sun, 8 Nov 2020 20:34:32 GMT""}]","2020-12-02"
"2007.01373","Jon Lawrence","Andrew D. Christianson, Victor R. Fanelli, and Lucas Lindsay, Sai Mu,
  Marein C. Rahn, Daniel G. Mazzone, Ayman H. Said, Filip Ronning, Eric D.
  Bauer, and Jon M. Lawrence","Phonons, Q-dependent Kondo spin fluctuations, and 4$\textit{f}$/phonon
  resonance in YbAl$_3$",,,"10.1103/PhysRevB.102.205135",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The intermediate valence (IV) compound YbAl$_3$ exhibits nonintegral valence
(Yb 4$f^{14-n_f}$ (5d6s)$^z$ where z = 2+n$_f$ = 2.75) in a moderately heavy
(m* = 20-30me) ground state with a large Kondo temperature (T$_K$ ~ 500-600K).
We have measured the magnetic fluctuations and the phonon spectra on single
crystals of this material by time-of-flight inelastic neutron scattering (INS)
and inelastic x-ray scattering (IXS). We find that at low temperature, the
Kondo-scale spin fluctuations have a momentum (Q) dependence similar to that
seen recently in the IV compound CePd$_3$ and which can be attributed to
particle-hole excitations in a coherent itinerant 4$f$ correlated ground state.
The Q-dependence disappears as the temperature is raised towards room
temperature and the 4$f$ electron band states become increasingly incoherent.
The measured phonons can be described adequately by a calculation based on
standard DFT+$U$ density functional theory, without recourse to considering
4$f$ correlations dynamically. A low temperature magnetic peak observed in the
neutron scattering at ~ 30meV shows dispersion identical to an optic phonon
branch. This 4$f$/phonon resonance disappears for T > 150K. The phonons appear
to remain unaffected by the resonance. We discuss several possibilities for the
origin of this unusual excitation, including the idea that it arises from the
large amplitude beating of the light Al atoms against the heavy Yb atoms,
resulting in a dynamic 4$f$/3$p$ hybridization.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:27:11 GMT""}]","2020-12-03"
"2007.01374","Makai Mann","Makai Mann, Amalee Wilson, Cesare Tinelli, Clark Barrett","Smt-Switch: a solver-agnostic C++ API for SMT Solving","This version adds a reference to metaSMT. 11 pages, 1 figure, to be
  included in SMT Workshop 2020: http://smt-workshop.cs.uiowa.edu/2020/",,,,"cs.LO","http://creativecommons.org/licenses/by-sa/4.0/","  This extended abstract describes work in progress on Smt-Switch, an
open-source, solver-agnostic API for SMT solving. Smt-Switch provides an
abstract interface, which can be implemented by different SMT solvers.
Smt-Switch provides simple, uniform, and high-performance access to SMT solving
for applications in areas such as automated reasoning, planning, and formal
verification. The interface allows the user to create, traverse, and manipulate
terms, as well as to dynamically dispatch queries to different underlying SMT
solvers.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:29:47 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jul 2020 16:52:04 GMT""}]","2020-07-14"
"2007.01375","Christen Ford","Christen Ford","LSTFCoDel: CoDel with LSTF-Style Priority Queuing",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Congestion control is vastly important in computer networks. Arising
naturally from the bursty nature of Internet traffic, congestion plagues not
only the network edge, but also the network core. Many remedies have been
proposed to fight congestion; active queue management (AQM) is one such
proposal. AQM seeks to prevent congestion by actively avoiding it. Some queuing
disciplines such as Random Early Detection (RED) will prematurely drop a random
packet (with some probability) when the queue nears capacity to signal the
sender to back off. However, RED utilizes queue length as a mechanism to
indicate congestion. On the other hand, the Controlled Delay (CoDel) queuing
discipline uses queuing delay as an indication of congestion. The problem with
both RED and CoDel are that they indiscriminately treat all packets the same.
Normally implemented using a FIFO queue, CoDel simply enqueues and dequeues
packets in a first-come, first-served manner. Priority queuing can be carefully
utilized to selectively service packets utilizing the very same metric CoDel
uses for AQM, queuing delay. That said, Least Slack Time First (LSTF), a
multi-processor scheduling algorithm employs priority scheduling, which
coincidentally, is also based on delay. In the context of computer networks
LSTF can be applied in the control plane or in the data plane. At the control
plane, LSTF functions across the entire network, but in doing so requires all
intermediary routers to implement it; LSTF also requires support at the packet
level in terms of a slack entry. Within the data plane, LSTF can be implemented
as a queuing mechanism based on delay spent in the router (just like CoDel
AQM). This paper applies data plane level LSTF to CoDel AQM to enable
delay-based packet classification within the confines of the CoDel AQM
algorithm.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:32:19 GMT""}]","2020-07-06"
"2007.01376","Oliver Johnson","Oliver Gebhard, Oliver Johnson, Philipp Loick, Maurice Rolvien","Improved bounds for noisy group testing with constant tests per item",,,,,"cs.IT cs.DM math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The group testing problem is concerned with identifying a small set of
infected individuals in a large population. At our disposal is a testing
procedure that allows us to test several individuals together. In an idealized
setting, a test is positive if and only if at least one infected individual is
included and negative otherwise. Significant progress was made in recent years
towards understanding the information-theoretic and algorithmic properties in
this noiseless setting. In this paper, we consider a noisy variant of group
testing where test results are flipped with certain probability, including the
realistic scenario where sensitivity and specificity can take arbitrary values.
Using a test design where each individual is assigned to a fixed number of
tests, we derive explicit algorithmic bounds for two commonly considered
inference algorithms and thereby naturally extend the results of Scarlett \&
Cevher (2016) and Scarlett \& Johnson (2020). We provide improved performance
guarantees for the efficient algorithms in these noisy group testing models --
indeed, for a large set of parameter choices the bounds provided in the paper
are the strongest currently proved.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:36:30 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 13:33:49 GMT""},{""version"":""v3"",""created"":""Tue, 21 Dec 2021 09:10:10 GMT""}]","2021-12-22"
"2007.01377","Somdip Dey Mr.","Somdip Dey, Amit Kumar Singh, Xiaohang Wang, and Klaus Dieter
  McDonald-Maier","DATE: Defense Against TEmperature Side-Channel Attacks in DVFS Enabled
  MPSoCs","13 pages, 18 figures, 3 tables",,,,"cs.CR cs.AR cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given the constant rise in utilizing embedded devices in daily life, side
channels remain a challenge to information flow control and security in such
systems. One such important security flaw could be exploited through
temperature side-channel attacks, where heat dissipation and propagation from
the processing elements are observed over time in order to deduce security
flaws. In our proposed methodology, DATE: Defense Against TEmperature
side-channel attacks, we propose a novel approach of reducing spatial and
temporal thermal gradient, which makes the system more secure against
temperature side-channel attacks, and at the same time increases the
reliability of the device in terms of lifespan. In this paper, we have also
introduced a new metric, Thermal-Security-in-Multi-Processors (TSMP), which is
capable of quantifying the security against temperature side-channel attacks on
computing systems, and DATE is evaluated to be 139.24% more secure at the most
for certain applications than the state-of-the-art, while reducing thermal
cycle by 67.42% at the most.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:41:23 GMT""}]","2020-07-06"
"2007.01378","Enzo Tagliazucchi","Yonatan Sanz Perl, Hern\'an Boccacio, Ignacio P\'erez-Ipi\~na,
  Federico Zamberl\'an, Helmut Laufs, Morten Kringelbach, Gustavo Deco, Enzo
  Tagliazucchi","Generative embeddings of brain collective dynamics using variational
  autoencoders",,,,,"q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of encoding pairwise correlations between coupled
dynamical systems in a low-dimensional latent space based on few distinct
observations. We used variational autoencoders (VAE) to embed temporal
correlations between coupled nonlinear oscillators that model brain states in
the wake-sleep cycle into a two-dimensional manifold. Training a VAE with
samples generated using two different parameter combinations resulted in an
embedding that represented the whole repertoire of collective dynamics, as well
as the topology of the underlying connectivity network. We first followed this
approach to infer the trajectory of brain states measured from wakefulness to
deep sleep from the two endpoints of this trajectory; next, we showed that the
same architecture was capable of representing the pairwise correlations of
generic Landau-Stuart oscillators coupled by complex network topology
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:43:52 GMT""}]","2020-07-06"
"2007.01379","Mariano Maisonnave","Mariano Maisonnave, Fernando Delbianco, Fernando Tohm\'e, Ana
  Maguitman, Evangelos Milios","Detecting Ongoing Events Using Contextual Word and Sentence Embeddings",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces the Ongoing Event Detection (OED) task, which is a
specific Event Detection task where the goal is to detect ongoing event
mentions only, as opposed to historical, future, hypothetical, or other forms
or events that are neither fresh nor current. Any application that needs to
extract structured information about ongoing events from unstructured texts can
take advantage of an OED system. The main contribution of this paper are the
following: (1) it introduces the OED task along with a dataset manually labeled
for the task; (2) it presents the design and implementation of an RNN model for
the task that uses BERT embeddings to define contextual word and contextual
sentence embeddings as attributes, which to the best of our knowledge were
never used before for detecting ongoing events in news; (3) it presents an
extensive empirical evaluation that includes (i) the exploration of different
architectures and hyperparameters, (ii) an ablation test to study the impact of
each attribute, and (iii) a comparison with a replication of a state-of-the-art
model. The results offer several insights into the importance of contextual
embeddings and indicate that the proposed approach is effective in the OED
task, outperforming the baseline models.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:44:05 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 19:51:11 GMT""}]","2021-02-09"
"2007.01380","Charalampos Andriotis","C.P. Andriotis, K.G. Papakonstantinou","Deep reinforcement learning driven inspection and maintenance planning
  under incomplete information and constraints",,,,,"cs.AI cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Determination of inspection and maintenance policies for minimizing long-term
risks and costs in deteriorating engineering environments constitutes a complex
optimization problem. Major computational challenges include the (i) curse of
dimensionality, due to exponential scaling of state/action set cardinalities
with the number of components; (ii) curse of history, related to exponentially
growing decision-trees with the number of decision-steps; (iii) presence of
state uncertainties, induced by inherent environment stochasticity and
variability of inspection/monitoring measurements; (iv) presence of
constraints, pertaining to stochastic long-term limitations, due to resource
scarcity and other infeasible/undesirable system responses. In this work, these
challenges are addressed within a joint framework of constrained Partially
Observable Markov Decision Processes (POMDP) and multi-agent Deep Reinforcement
Learning (DRL). POMDPs optimally tackle (ii)-(iii), combining stochastic
dynamic programming with Bayesian inference principles. Multi-agent DRL
addresses (i), through deep function parametrizations and decentralized control
assumptions. Challenge (iv) is herein handled through proper state augmentation
and Lagrangian relaxation, with emphasis on life-cycle risk-based constraints
and budget limitations. The underlying algorithmic steps are provided, and the
proposed framework is found to outperform well-established policy baselines and
facilitate adept prescription of inspection and intervention actions, in cases
where decisions must be made in the most resource- and risk-aware manner.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:44:07 GMT""}]","2020-07-06"
"2007.01381","Renu Sharma","Renu Sharma and Arun Ross","D-NetPAD: An Explainable and Interpretable Iris Presentation Attack
  Detector",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  An iris recognition system is vulnerable to presentation attacks, or PAs,
where an adversary presents artifacts such as printed eyes, plastic eyes, or
cosmetic contact lenses to circumvent the system. In this work, we propose an
effective and robust iris PA detector called D-NetPAD based on the DenseNet
convolutional neural network architecture. It demonstrates generalizability
across PA artifacts, sensors and datasets. Experiments conducted on a
proprietary dataset and a publicly available dataset (LivDet-2017) substantiate
the effectiveness of the proposed method for iris PA detection. The proposed
method results in a true detection rate of 98.58\% at a false detection rate of
0.2\% on the proprietary dataset and outperfoms state-of-the-art methods on the
LivDet-2017 dataset. We visualize intermediate feature distributions and
fixation heatmaps using t-SNE plots and Grad-CAM, respectively, in order to
explain the performance of D-NetPAD. Further, we conduct a frequency analysis
to explain the nature of features being extracted by the network. The source
code and trained model are available at https://github.com/iPRoBe-lab/D-NetPAD.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:44:36 GMT""}]","2020-07-06"
"2007.01382","Srinivasan Iyengar","Srinivasan Iyengar, Stephen Lee, David Irwin, Prashant Shenoy,
  Benjamin Weil","WattScale: A Data-driven Approach for Energy Efficiency Analytics of
  Buildings at Scale","This paper appeared in the Journal ACM Transactions on Data Science",,"10.1145/3406961",,"cs.CY cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Buildings consume over 40% of the total energy in modern societies, and
improving their energy efficiency can significantly reduce our energy
footprint. In this paper, we present \texttt{WattScale}, a data-driven approach
to identify the least energy-efficient buildings from a large population of
buildings in a city or a region. Unlike previous methods such as least-squares
that use point estimates, \texttt{WattScale} uses Bayesian inference to capture
the stochasticity in the daily energy usage by estimating the distribution of
parameters that affect a building. Further, it compares them with similar homes
in a given population. \texttt{WattScale} also incorporates a fault detection
algorithm to identify the underlying causes of energy inefficiency. We validate
our approach using ground truth data from different geographical locations,
which showcases its applicability in various settings. \texttt{WattScale} has
two execution modes -- (i) individual, and (ii) region-based, which we
highlight using two case studies. For the individual execution mode, we present
results from a city containing >10,000 buildings and show that more than half
of the buildings are inefficient in one way or another indicating a significant
potential from energy improvement measures. Additionally, we provide probable
cause of inefficiency and find that 41\%, 23.73\%, and 0.51\% homes have poor
building envelope, heating, and cooling system faults, respectively. For the
region-based execution mode, we show that \texttt{WattScale} can be extended to
millions of homes in the US due to the recent availability of representative
energy datasets.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:45:33 GMT""}]","2020-07-06"
"2007.01383","David Ho","David Joon Ho, Narasimhan P. Agaram, Peter J. Schueffler, Chad M.
  Vanderbilt, Marc-Henri Jean, Meera R. Hameed, Thomas J. Fuchs","Deep Interactive Learning: An Efficient Labeling Approach for Deep
  Learning-Based Osteosarcoma Treatment Response Assessment","Accepted at MICCAI 2020",,"10.1007/978-3-030-59722-1_52",,"eess.IV cs.CV q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Osteosarcoma is the most common malignant primary bone tumor. Standard
treatment includes pre-operative chemotherapy followed by surgical resection.
The response to treatment as measured by ratio of necrotic tumor area to
overall tumor area is a known prognostic factor for overall survival. This
assessment is currently done manually by pathologists by looking at glass
slides under the microscope which may not be reproducible due to its subjective
nature. Convolutional neural networks (CNNs) can be used for automated
segmentation of viable and necrotic tumor on osteosarcoma whole slide images.
One bottleneck for supervised learning is that large amounts of accurate
annotations are required for training which is a time-consuming and expensive
process. In this paper, we describe Deep Interactive Learning (DIaL) as an
efficient labeling approach for training CNNs. After an initial labeling step
is done, annotators only need to correct mislabeled regions from previous
segmentation predictions to improve the CNN model until the satisfactory
predictions are achieved. Our experiments show that our CNN model trained by
only 7 hours of annotation using DIaL can successfully estimate ratios of
necrosis within expected inter-observer variation rate for non-standardized
manual surgical pathology task.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:46:53 GMT""}]","2021-01-06"
"2007.01384","Yang Li","Yang Li","Metric SYZ conjecture and non-archimedean geometry","38 pages",,,,"math.DG math.AG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that assuming a conjecture in non-archimedean geometry, then a metric
formulation of the SYZ conjecture can be proved in large generality.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:52:45 GMT""}]","2020-07-06"
"2007.01385","Alexander Vitanov","Alexander Vitanov","Trace Densities and Algebraic Index Theorems for Sheaves of Formal
  Cherednik Algebras","29 pages; Lemma 2.3 and Lemma 2.4 interchanged; All localizations in
  Section 4 removed; The statement in Theorem 4.3 completed; A subtle error in
  the proof of Lemma 4.5 corrected and the statement of Theorem 4.6 adapted;
  Other minor technical improvements throughout the manuscript; Additional
  references added; Acknowledgements extended;",,,,"math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how a novel construction of the sheaf of Cherednik algebras on a
quotient orbifold Y=X/G by virtue of formal geometry in author's prior work
leads to results for the sheaf of Cherednik algebra which until recently were
viewed as intractable. First, for every orbit type stratum in $X$, we define a
trace density map for the Hochschild chain complex of the sheaf of Cherednik
algebras, which generalises the standard Engeli-Felder's trace density
construction for the sheaf of differential operators. Second, by means of the
newly obtained trace density maps, we prove an isomorphism in the derived
category of complexes of $\mathbb C_Y[[\hbar]]$-modules which computes the
hypercohomology of the Hochschild chain complex $\mathcal{C}_{\bullet}$ of the
sheaf of formal Cherednik algebras. We show that this hypercohomology is
isomorphic to the Chen-Ruan cohomology of the orbifold $X/G$ with values in the
ring of formal power series $\mathbb C[[\hbar]]$. We infer that the Hochschild
chain complex of the sheaf of skew group algebras $\mathcal{D}_X\rtimes G$ has
a well-defined Euler characteristic which is proportional to the topological
Euler characteristic of $X/G$. Finally, we prove an algebraic index theorem.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:59:14 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 06:29:44 GMT""},{""version"":""v3"",""created"":""Fri, 8 Jan 2021 18:42:51 GMT""},{""version"":""v4"",""created"":""Fri, 1 Oct 2021 11:34:51 GMT""}]","2021-10-04"
"2007.01386","James Davis","Jim Davis","Posterior Adaptation With New Priors",,,,,"cs.LG cs.CV stat.ML","http://creativecommons.org/licenses/by/4.0/","  Classification approaches based on the direct estimation and analysis of
posterior probabilities will degrade if the original class priors begin to
change. We prove that a unique (up to scale) solution is possible to recover
the data likelihoods for a test example from its original class posteriors and
dataset priors. Given the recovered likelihoods and a set of new priors, the
posteriors can be re-computed using Bayes' Rule to reflect the influence of the
new priors. The method is simple to compute and allows a dynamic update of the
original posteriors.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:07:05 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 00:59:26 GMT""},{""version"":""v3"",""created"":""Mon, 17 Jan 2022 01:08:25 GMT""},{""version"":""v4"",""created"":""Tue, 25 Jan 2022 13:26:42 GMT""}]","2022-01-26"
"2007.01387","Emad Gad","Emad Gad and Julio Pimentel","An Algebraic Approach for the Stability Analysis of BLDC Motor
  Controllers","12 pages",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an algebraic technique to compute the maximum time-delay
that can be accepted in the control loop of a Brushless DC Motor (BLDCM) speed
controller before the closed loop response becomes unstable. Using a recently
proposed time-delay stability analysis methodology, we derive accurate
stability conditions for the BLDCM speed controller. The results of applying
the new method show that tuning the PI controller for very fast response in the
order of magnitude of the BLDCM mechanical time constant cause the time-delay
to significantly affect the system stability.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:13:04 GMT""}]","2020-07-06"
"2007.01388","Farshid Varno","Farshid Varno and Lucas May Petry and Lisa Di Jorio and Stan Matwin","Learn Faster and Forget Slower via Fast and Stable Task Adaptation","52 pages, 15 figures, 1 table",,,,"cs.NE cs.CV cs.LG stat.ML","http://creativecommons.org/licenses/by-sa/4.0/","  Training Deep Neural Networks (DNNs) is still highly time-consuming and
compute-intensive. It has been shown that adapting a pretrained model may
significantly accelerate this process. With a focus on classification, we show
that current fine-tuning techniques make the pretrained models catastrophically
forget the transferred knowledge even before anything about the new task is
learned. Such rapid knowledge loss undermines the merits of transfer learning
and may result in a much slower convergence rate compared to when the maximum
amount of knowledge is exploited. We investigate the source of this problem
from different perspectives and to alleviate it, introduce Fast And Stable
Task-adaptation (FAST), an easy to apply fine-tuning algorithm. The paper
provides a novel geometric perspective on how the loss landscape of source and
target tasks are linked in different transfer learning strategies. We
empirically show that compared to prevailing fine-tuning practices, FAST learns
the target task faster and forgets the source task slower.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:13:55 GMT""},{""version"":""v2"",""created"":""Sun, 29 Nov 2020 16:01:50 GMT""}]","2020-12-01"
"2007.01389","Kannan Soundararajan","K. Soundararajan","Bertrand's postulate and the existence of finite fields","4 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is an expository note discussing how the Erdos--Ramanujan proof of
Bertrand's postulate may be adapted to show the existence of finite fields.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:19:53 GMT""}]","2020-07-06"
"2007.01390","Olli Saarela","Olli Saarela, Christian Rohrbeck, Elja Arjas","Bayesian non-parametric ordinal regression under a monotonicity
  constraint",,"Bayesian Analysis, Advance Publication 1-29 (2022)","10.1214/22-BA1310",,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compared to the nominal scale, the ordinal scale for a categorical outcome
variable has the property of making a monotonicity assumption for the covariate
effects meaningful. This assumption is encoded in the commonly used
proportional odds model, but there it is combined with other parametric
assumptions such as linearity and additivity. Herein, the considered models are
non-parametric and the only condition imposed is that the effects of the
covariates on the outcome categories are stochastically monotone according to
the ordinal scale. We are not aware of the existence of other comparable
multivariable models that would be suitable for inference purposes. We
generalize our previously proposed Bayesian monotonic multivariable regression
model to ordinal outcomes, and propose an estimation procedure based on
reversible jump Markov chain Monte Carlo. The model is based on a marked point
process construction, which allows it to approximate arbitrary monotonic
regression function shapes, and has a built-in covariate selection property. We
study the performance of the proposed approach through extensive simulation
studies, and demonstrate its practical application in two real data examples.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:22:06 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 15:53:10 GMT""},{""version"":""v3"",""created"":""Thu, 21 Oct 2021 02:33:17 GMT""},{""version"":""v4"",""created"":""Fri, 22 Oct 2021 03:07:20 GMT""},{""version"":""v5"",""created"":""Fri, 11 Feb 2022 21:16:47 GMT""}]","2022-04-26"
"2007.01391","Omer Waqar","Omer Waqar, Hina Tabassum and Raviraj Adve","Secure Beamforming and Ergodic Secrecy Rate Analysis for
  Amplify-and-Forward Relay Networks with Wireless Powered Jammer","5 pages, 3 Figures, Submitted to IEEE Transactions on Vehicular
  Technology",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this correspondence, we consider an amplify-and-forward relay network in
which relayed information is overheard by an eavesdropper. In order to confound
the eavesdropper, a wireless-powered jammer is also considered which harvests
energy from a multiple-antenna source. We proposed a new secure beamforming
scheme in which beamforming vector is a linear combination of the energy
beamforming (EB) and information beamforming (IB) vectors. We also present a
new closed-form solution for the proposed beamforming vector which is shown to
achieve a higher secrecy rate as compared to the trivial EB and IB vectors.
Moreover, a tight closed-form approximation for the ergodic secrecy rate is
also derived for the asymptotic regime of a large number of antennas at the
source. Finally, numerical examples and simulations are provided which validate
our analytical results.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:24:44 GMT""}]","2020-07-06"
"2007.01393","Bryce Gadway","Fangzhao Alex An, Karmela Padavi\'c, Eric J. Meier, Suraj Hegde,
  Sriram Ganeshan, J.H. Pixley, Smitha Vishveshwara, and Bryce Gadway","Observation of tunable mobility edges in generalized Aubry-Andr\'{e}
  lattices","6 pages, 3 figures, and ancillary Supplementary Materials file","Phys. Rev. Lett. 126, 040603 (2021)","10.1103/PhysRevLett.126.040603",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using synthetic lattices of laser-coupled atomic momentum modes, we
experimentally realize a recently proposed family of nearest-neighbor
tight-binding models having quasiperiodic site energy modulation that host an
exact mobility edge protected by a duality symmetry. These one-dimensional
tight-binding models can be viewed as a generalization of the well-known
Aubry-Andr\'{e} (AA) model, with an energy-dependent self duality condition
that constitutes an analytical mobility edge relation. By adiabatically
preparing the lowest and highest energy eigenstates of this model system and
performing microscopic measurements of their participation ratio, we track the
evolution of the mobility edge as the energy-dependent density of states is
modified by the model's tuning parameter. Our results show strong deviations
from single-particle predictions, consistent with attractive interactions
causing both enhanced localization of the lowest energy state due to
self-trapping and inhibited localization of the highest energy state due to
screening. This study paves the way for quantitative studies of interaction
effects on self duality induced mobility edges.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:25:19 GMT""}]","2021-02-03"
"2007.01396","Riccardo Messina","Marta Reina, Riccardo Messina, Philippe Ben-Abdallah","Conduction-radiation coupling between two closely-separated solids","6 pages, 4 figures","Phys. Rev. Lett. 125, 224302 (2020)","10.1103/PhysRevLett.125.224302",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the theory of radiative heat exchanges between two closely-spaced bodies
introduced by Polder and van Hove, no interplay between the heat carriers
inside the materials and the photons crossing the separation gap is assumed.
Here we release this constraint by developing a general theory to describe the
conduction-radiation coupling between two solids of arbitrary size separated by
a subwavelength separation gap. We show that, as a result of the temperature
profile induced by the coupling with conduction, the radiative heat flux
exchanged between two parallel slabs at nanometric distances can be several
orders of magnitude smaller than the one predicted by the conventional theory.
These results could have important implications in the fields of nanoscale
thermal management, near-field solid-state cooling and nanoscale energy
conversion.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:25:41 GMT""},{""version"":""v2"",""created"":""Fri, 9 Oct 2020 09:06:07 GMT""}]","2022-06-03"
"2007.01397","Vitaliy Chiley","Abhinav Venigalla and Atli Kosson and Vitaliy Chiley and Urs K\""oster","Adaptive Braking for Mitigating Gradient Delay","In Beyond First Order Methods in ML Systems workshop at the 37th
  International Conference on Machine Learning, 2020",,,,"cs.LG cs.DC math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural network training is commonly accelerated by using multiple
synchronized workers to compute gradient updates in parallel. Asynchronous
methods remove synchronization overheads and improve hardware utilization at
the cost of introducing gradient delay, which impedes optimization and can lead
to lower final model performance. We introduce Adaptive Braking (AB), a
modification for momentum-based optimizers that mitigates the effects of
gradient delay. AB dynamically scales the gradient based on the alignment of
the gradient and the velocity. This can dampen oscillations along high
curvature directions of the loss surface, stabilizing and accelerating
asynchronous training. We show that applying AB on top of SGD with momentum
enables training ResNets on CIFAR-10 and ImageNet-1k with delays $D \geq$ 32
update steps with minimal drop in final test accuracy.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:26:27 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jul 2020 17:12:25 GMT""}]","2020-07-13"
"2007.01398","Luciano Iv\'an Pereira Valenzuela","Leonardo Zambrano, Luciano Pereira, Sebastian Niklitschek, and Aldo
  Delgado","Estimation of pure quantum states in high dimension at the limit of
  quantum accuracy through complex optimization and statistical inference","10 pages, 2 figures",,"10.1038/s41598-020-69646-z",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum tomography has become a key tool for the assessment of quantum
states, processes, and devices. This drives the search for tomographic methods
that achieve greater accuracy. In the case of mixed states of a single
2-dimensional quantum system adaptive methods have been recently introduced
that achieve the theoretical accuracy limit deduced by Hayashi and Gill and
Massar. However, accurate estimation of higher-dimensional quantum states
remains poorly understood. This is mainly due to the existence of incompatible
observables, which makes multiparameter estimation difficult. Here we present
an adaptive tomographic method and show through numerical simulations that,
after a few iterations, it is asymptotically approaching the fundamental
Gill-Massar lower bound for the estimation accuracy of pure quantum states in
high dimension. The method is based on a combination of stochastic optimization
on the field of the complex numbers and statistical inference, exceeds the
accuracy of any mixed-state tomographic method, and can be demonstrated with
current experimental capabilities. The proposed method may lead to new
developments in quantum metrology.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:33:16 GMT""}]","2021-07-14"
"2007.01399","Alexander Vitanov","Alexander Vitanov","Sheaves of Twisted Cherednik Algebras as Universal Filtered Formal
  Deformations","26 pages; The title was shortened. The abstract was slightly altered.
  Sections 3.2.1 and 3.2.2 were newly added. Section 3.2.3 and 3.2.4 were
  slightly improved and expanded. Technical errors and typos were corrected",,,,"math.KT math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  According to a statement by Pavel Etingof, in the special case of an affine
variety $X$ with a faithful action by a finite group $G$, the sheaf of
(twisted) Cherednik algebras $\mathcal{H}_{1, c, \psi, X, G}$ with formal
parameters $c, \psi$ is a universal formal deformation of $\mathcal{D}_X\rtimes
G$ where $\mathcal{D}_X$ is the sheaf of differential operators on $X$. In the
current note, we generalize Etingof's result to the non-affine case. We prove
that for a generic smooth analytic or algebraic variety $X$, the sheaf
$\mathcal{H}_{1, c, \psi, X, G}$ with formal $c$ and $\psi$ is a universal
filtered formal deformation of $\mathcal{D}_X\rtimes G$. To that aim, we first
construct quasi-isomorphisms between the Hochschild (co)chain complex of
$\mathcal{D}_X\rtimes G$ and the $G$-invariant part of the direct sum over all
elements $g$ in $G$ of sheaves of holomorphic differential forms on the
cotangent bundles of the $g$-fixed point submanifolds in $X$. Finally, we
combine these quasi-isomorphisms with results from the theory of algebraic
extensions for sheaves of filtered associative algebras to establish a
bijective correspondence between the space of isomorphism classes of filtered
infinitesimal deformations of $\mathcal{D}_X\rtimes G$ and the parameter space
of $\mathcal{H}_{1, c, \psi, X, G}$.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:38:11 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 20:25:19 GMT""}]","2021-02-04"
"2007.01400","Ra\'ul Emilio Vidal","Gonzalo H. Iba\~nez-Firnkorn, Mar\'ia Silvina Riveros and Ra\'ul E.
  Vidal","Necessary condition on the weight for maximal and integral operators
  with rough kernels",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $0\leq \alpha<n$, $m\in \mathbb{N}$ and let consider $T_{\alpha,m}$ be a
of integral operator, given by kernel of the form
$$K(x,y)=k_1(x-A_1y)k_2(x-A_2y)\dots k_m(x-A_my),$$ where $A_i$ are invertible
matrices and each $k_i$ satisfies a fractional size and generalized fractional
H\""ormander condition. In [Iba\~nez-Firnkorn, G. H., and Riveros, M. S. (2018).
Certain fractional type operators with H\""ormander conditions. To appear in
Ann. Acad. Sci. Fenn. Math.] it was proved that $T_{\alpha,m}$ is controlled in
$L^p(w)$-norms, $w\in A_{\infty}$, by the sum of maximal operators
$M_{A_i^{-1},\alpha}$. In this paper we present the class of weights
$\mathcal{A}_{A,p,q}$, where $A$ is an invertible matrix. This class are the
good weights for the weak-type estimate of $M_{A^{-1},\alpha}$. For certain
kernels $k_i$ we can characterize the weights for the strong-type estimate of
$T_{\alpha,m}$. Also, we give a the strong-type estimate using testing
conditions.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:40:41 GMT""}]","2020-07-06"
"2007.01401","Jinxiang Zhu","J.X. Zhu, C. Rea, K. Montes, R.S. Granetz, R. Sweeney, R.A. Tinguely","Hybrid deep learning architecture for general disruption prediction
  across tokamaks",,,"10.1088/1741-4326/abc664",,"physics.plasm-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a new deep learning disruption prediction algorithm
based on important findings from explorative data analysis which effectively
allows knowledge transfer from existing devices to new ones, thereby predicting
disruptions using very limited disruptive data from the new devices. The
explorative data analysis conducted via unsupervised clustering techniques
confirms that time-sequence data are much better separators of disruptive and
non-disruptive behavior than the instantaneous plasma state data with further
advantageous implications for a sequence-based predictor. Based on such
important findings, we have designed a new algorithm for multi-machine
disruption prediction that achieves high predictive accuracy on the C-Mod
(AUC=0.801), DIII-D (AUC=0.947) and EAST (AUC=0.973) tokamaks with limited
hyperparameter tuning. Through numerical experiments, we show that boosted
accuracy (AUC=0.959) is achieved on EAST predictions by including in the
training only 20 disruptive discharges, thousands of non-disruptive discharges
from EAST, and combining this with more than a thousand discharges from DIII-D
and C-Mod. The improvement of predictive ability obtained by combining
disruptive data from other devices is found to be true for all permutations of
the three devices. Furthermore, by comparing the predictive performance of each
individual numerical experiment, we find that non-disruptive data are
machine-specific while disruptive data from multiple devices contain
device-independent knowledge that can be used to inform predictions for
disruptions occurring on a new device.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:42:00 GMT""},{""version"":""v2"",""created"":""Sat, 18 Jul 2020 04:47:45 GMT""},{""version"":""v3"",""created"":""Fri, 30 Oct 2020 13:15:56 GMT""},{""version"":""v4"",""created"":""Thu, 26 Nov 2020 07:54:35 GMT""}]","2020-11-30"
"2007.01402","David Damanik","David Damanik (Rice University), Jake Fillman (Texas State University)","Schr\""odinger Operators with Thin Spectra","23 pages",,,,"math.SP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The determination of the spectrum of a Schr\""odinger operator is a
fundamental problem in mathematical quantum mechanics. We discuss a series of
results showing that Schr\""odinger operators can exhibit spectra that are
remarkably thin in the sense of Lebesgue measure and fractal dimensions. We
begin with a brief discussion of results in the periodic theory, and then move
to a discussion of aperiodic models with thin spectra.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:42:09 GMT""}]","2020-07-06"
"2007.01403","Andrea Colcelli","Andrea Colcelli, Nicol\`o Defenu, Giuseppe Mussardo, Andrea
  Trombettoni","Finite Temperature Off-Diagonal Long-Range Order for Interacting Bosons","13 pages, 6 figures","Phys. Rev. B 102, 184510 (2020)","10.1103/PhysRevB.102.184510",,"cond-mat.stat-mech cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Characterizing the scaling with the total particle number ($N$) of the
largest eigenvalue of the one--body density matrix ($\lambda_0$), provides
informations on the occurrence of the off-diagonal long-range order (ODLRO)
according to the Penrose-Onsager criterion. Setting $\lambda_0\sim
N^{\mathcal{C}_0}$, then $\mathcal{C}_0=1$ corresponds to ODLRO. The
intermediate case, $0<\mathcal{C}_0<1$, corresponds for translational invariant
systems to the power-law decaying of (non-connected) correlation functions and
it can be seen as identifying quasi-long-range order. The goal of the present
paper is to characterize the ODLRO properties encoded in $\mathcal{C}_0$ [and
in the corresponding quantities $\mathcal{C}_{k \neq 0}$ for excited natural
orbitals] exhibited by homogeneous interacting bosonic systems at finite
temperature for different dimensions. We show that $\mathcal{C}_{k \neq 0}=0$
in the thermodynamic limit. In $1D$ it is $\mathcal{C}_0=0$ for non-vanishing
temperature, while in $3D$ $\mathcal{C}_0=1$ ($\mathcal{C}_0=0$) for
temperatures smaller (larger) than the Bose-Einstein critical temperature. We
then focus our attention to $D=2$, studying the $XY$ and the Villain models,
and the weakly interacting Bose gas. The universal value of $\mathcal{C}_0$
near the Berezinskii--Kosterlitz--Thouless temperature $T_{BKT}$ is $7/8$. The
dependence of $\mathcal{C}_0$ on temperatures between $T=0$ (at which
$\mathcal{C}_0=1$) and $T_{BKT}$ is studied in the different models. An
estimate for the (non-perturbative) parameter $\xi$ entering the equation of
state of the $2D$ Bose gases, is obtained using low temperature expansions and
compared with the Monte Carlo result. We finally discuss a double jump
behaviour for $\mathcal{C}_0$, and correspondingly of the anomalous dimension
$\eta$, right below $T_{BKT}$ in the limit of vanishing interactions.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:42:47 GMT""}]","2020-11-20"
"2007.01404","Chaoyang Song","Chaoyang Song, Jianxi Luo, Katja H\""oltt\""a-Otto, Warren Seering,
  Kevin Otto","Crowdfunding for Design Innovation: Prediction Model with Critical
  Factors","12 pages, 3 figures, 7 tables, accepted by IEEE TEM",,"10.1109/TEM.2020.3001764",,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Online reward-based crowdfunding campaigns have emerged as an innovative
approach for validating demands, discovering early adopters, and seeking
learning and feedback in the design processes of innovative products. However,
crowdfunding campaigns for innovative products are faced with a high degree of
uncertainty and suffer meager rates of success to fulfill their values for
design. To guide designers and innovators for crowdfunding campaigns, this
paper presents a data-driven methodology to build a prediction model with
critical factors for crowdfunding success, based on public online crowdfunding
campaign data. Specifically, the methodology filters 26 candidate factors in
the Real-Win-Worth framework and identifies the critical ones via step-wise
regression to predict the amount of crowdfunding. We demonstrate the
methodology via deriving prediction models and identifying essential factors
from 3D printer and smartwatch campaign data on Kickstarter and Indiegogo. The
critical factors can guide campaign developments, and the prediction model may
evaluate crowdfunding potential of innovations in contexts, to increase the
chance of crowdfunding success of innovative products.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:44:40 GMT""}]","2020-07-06"
"2007.01405","Alexandru Chirv\u{a}situ L.","Alexandru Chirvasitu","Rigidity results for automorphisms of Hardy-Toeplitz $C^*$-algebras","18 pages + references",,,,"math.OA math.CV math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a number of results on the automorphisms of and isomorphisms between
Hardy-Toeplitz algebras $\mathcal{T}(D)$ associated to bounded symmetric
domains $D$: that the stable isomorphism class of $\mathcal{T}(D)$ determines
$D$ (even when it is reducible), that for reducible domains $D=D_1\times\cdots
\times D_s$ the automorphisms of the Shilov boundary $\check{S}(D)$ induced by
those of $\mathcal{T}(D)$ permute the Shilov boundaries $\check{S}(D_i)$, and
that by contrast to arbitrary solvable algebras, automorphisms of
$\mathcal{T}(D)$ that are trivial on their character spaces $\check{S}(D)$ are
trivial on the entire spectrum $\widehat{\mathcal{T}(D)}$.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:53:53 GMT""}]","2020-07-06"
"2007.01406","Marius Ghergu","Marius Ghergu and Yasuhito Miyamoto","Radial regular and rupture solutions for a MEMS model with fringing
  field","14 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate radial solutions for the problem \[ \begin{cases}
\displaystyle -\Delta U=\frac{\lambda+\delta|\nabla U|^2}{1-U},\; U>0 &
\textrm{in}\ B,\\ U=0 & \textrm{on}\ \partial B, \end{cases} \] which is
related to the study of Micro-Electromechanical Systems (MEMS). Here, $B\subset
\mathbb{R}^N$ $(N\geq 2)$ denotes the open unit ball and $\lambda, \delta>0$
are real numbers. Two classes of solutions are considered in this work: (i)
{\it regular solutions}, which satisfy $0<U<1$ in $B$ and (ii) {\it rupture
solutions} which satisfy $U(0)=1$, and thus make the equation singular at the
origin. Bifurcation with respect to parameter $\lambda>0$ is also discussed.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:57:11 GMT""}]","2020-07-06"
"2007.01407","Carmine Antonio Perroni","Carmine Antonio Perroni and Giuliano Benenti","Theoretical approaches for nanoscale thermoelectric phenomena","20 pages, 7 figures, to be published as chapter in the Proceedings of
  Varenna Summer Course 207 - Advances in thermoelectricity: foundational
  issues, materials and nanotechnology",,,,"cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Focus of the chapter is on the theoretical approaches aimed to analyze
thermoelectric properties at the nanoscale. We discuss several relevant
theoretical approaches for different set-ups of nano-devices providing
estimations of the thermoelectric parameters in the linear and non-linear
regime, in particular the thermoelectric figure of merit and the
power-efficiency trade-off. Moreover, we analyze the role of not only
electronic, but also of vibrational degrees of freedom. First, nanoscale
thermoelectric phenomena are considered in the quantum coherent regime using
the Landauer-B\""uttiker method and focusing on effects of energy filtering.
Then, we analyze the effects of many-body couplings between nano-structure
degrees of freedom, such as electron-electron and electron-vibration
interactions, which can strongly affect the thermoelectric conversion. In
particular, we discuss the enhancement of the thermoelectric figure of merit in
the Coulomb blockade regime for a quantum dot model starting from the master
equation for charge state probabilities and the tunneling rates through the
electrodes. Finally, within the non-equilibrium Green function formalism, we
quantify the reduction of the thermoelectric performance in simple models of
molecular junctions due to the effects of the electron-vibration coupling and
phonon transport at room temperature.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:01:16 GMT""}]","2020-07-06"
"2007.01408","Derek Weitzel","Edgar Fajardo, Marian Zvada, Derek Weitzel, Mats Rynge, John Hicks,
  Mat Selmeci, Brian Lin, Pascal Paschos, Brian Bockelman, Igor Sfiligoi,
  Andrew Hanushevsky, and Frank W\""urthwein","Creating a content delivery network for general science on the internet
  backbone using XCaches",,,"10.1051/epjconf/202024504041",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A general problem faced by computing on the grid for opportunistic users is
that delivering cycles is simpler than delivering data to those cycles. In this
project we show how we integrated XRootD caches placed on the internet backbone
to implement a content delivery network for general science workflows. We will
show that for some workflows on different science domains like high energy
physics, gravitational waves, and others the combination of data reuse from the
workflows together with the use of caches increases CPU efficiency while
decreasing network bandwidth use.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:06:09 GMT""},{""version"":""v2"",""created"":""Mon, 28 Sep 2020 13:14:05 GMT""}]","2021-02-03"
"2007.01409","Nathan Klein","Anna R. Karlin and Nathan Klein and Shayan Oveis Gharan","A (Slightly) Improved Approximation Algorithm for Metric TSP",,,,,"cs.DS math.CO math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For some $\epsilon > 10^{-36}$ we give a $3/2-\epsilon$ approximation
algorithm for metric TSP.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:07:03 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jul 2020 01:53:34 GMT""},{""version"":""v3"",""created"":""Sun, 30 Aug 2020 20:24:01 GMT""},{""version"":""v4"",""created"":""Sat, 8 May 2021 16:16:15 GMT""},{""version"":""v5"",""created"":""Tue, 15 Mar 2022 00:48:42 GMT""}]","2022-03-16"
"2007.01410","Nataliya Mayko","V. L. Makarov and N. V. Mayko","Weighted estimates of the Cayley transform method for boundary value
  problems in a Banach space",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the boundary value problems (BVPs) for linear secondorder ODEs
with a strongly positive operator coefficient in a Banach space. The solutions
are given in the form of the infinite series by means of the Cayley transform
of the operator, the Meixner type polynomials of the independent variable, the
operator Green function and the Fourier series representation for the
right-hand side of the equation. The approximate solution of each problem is a
partial sum of N (or expressed through N) summands. We prove the weighted error
estimates depending on the discretization parameter N, the distance of the
independent variable to the boundary points of the interval and some smoothness
properties of the input data.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:11:36 GMT""}]","2020-07-06"
"2007.01411","Gregory Kozyreff","Gregory Kozyreff","Hospitalization dynamics during the first COVID-19 pandemic wave: SIR
  modelling compared to Belgium, France, Italy, Switzerland and New York City
  data",,"Infectious Disease Modelling, Vol. 6, 2021, Pages 398-404","10.1016/j.idm.2021.01.006",,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the classical Susceptible-Infected-Recovered epidemiological model, an
analytical formula is derived for the number of beds occupied by Covid-19
patients. The analytical curve is fitted to data in Belgium, France, New York
City and Switzerland, with a correlation coefficient exceeding 98.8%,
suggesting that finer models are unnecessary with such macroscopic data. The
fitting is used to extract estimates of the doubling time in the ascending
phase of the epidemic, the mean recovery time and, for those who require
medical intervention, the mean hospitalization time. Large variations can be
observed among different outbreaks.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:12:17 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 13:47:46 GMT""}]","2021-02-22"
"2007.01412","Delio Mugnolo","Matthias Hofmann and James B. Kennedy and Delio Mugnolo and Marvin
  Pl\""umer","Asymptotics and estimates for spectral minimal partitions of metric
  graphs",,,,,"math-ph math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study properties of spectral minimal partitions of metric graphs within
the framework recently introduced in [Kennedy et al, Calc. Var. 60 (2021), 61].
We provide sharp lower and upper estimates for minimal partition energies in
different classes of partitions; while the lower bounds are reminiscent of the
classic isoperimetric inequalities for metric graphs, the upper bounds are more
involved and mirror the combinatorial structure of the metric graph as well.
Combining them, we deduce that these spectral minimal energies also satisfy a
Weyl-type asymptotic law similar to the well-known one for eigenvalues of
quantum graph Laplacians with various vertex conditions. Drawing on two
examples we show that in general no second term in the asymptotic expansion for
minimal partition energies can exist, but show that various kinds of behaviour
are possible. We also study certain aspects of the asymptotic behaviour of the
minimal partitions themselves.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:12:36 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 07:52:20 GMT""}]","2021-04-09"
"2007.01413","Ridwan Alam","Ridwan Alam, David B. Peden, and John C. Lach","Wearable Respiration Monitoring: Interpretable Inference with Context
  and Sensor Biomarkers","10 pages, 10 figures",,"10.1109/JBHI.2020.3035776",,"eess.SP cs.AI cs.CY cs.HC cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Breathing rate (BR), minute ventilation (VE), and other respiratory
parameters are essential for real-time patient monitoring in many acute health
conditions, such as asthma. The clinical standard for measuring respiration,
namely Spirometry, is hardly suitable for continuous use. Wearables can track
many physiological signals, like ECG and motion, yet not respiration. Deriving
respiration from other modalities has become an area of active research. In
this work, we infer respiratory parameters from wearable ECG and wrist motion
signals. We propose a modular and generalizable classification-regression
pipeline to utilize available context information, such as physical activity,
in learning context-conditioned inference models. Morphological and power
domain novel features from the wearable ECG are extracted to use with these
models. Exploratory feature selection methods are incorporated in this pipeline
to discover application-specific interpretable biomarkers. Using data from 15
subjects, we evaluate two implementations of the proposed pipeline: for
inferring BR and VE. Each implementation compares generalized linear model,
random forest, support vector machine, Gaussian process regression, and
neighborhood component analysis as contextual regression models. Permutation,
regularization, and relevance determination methods are used to rank the ECG
features to identify robust ECG biomarkers across models and activities. This
work demonstrates the potential of wearable sensors not only in continuous
monitoring, but also in designing biomarker-driven preventive measures.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:12:49 GMT""}]","2020-11-26"
"2007.01414","Marlon Moresco","Marlon Moresco, Marcelo Righi and Eduardo Horta","Minkowski gauges and deviation measures",,,,,"q-fin.RM q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose to derive deviation measures through the Minkowski gauge of a
given set of acceptable positions. We show that, given a suitable acceptance
set, any positive homogeneous deviation measure can be accommodated in our
framework. In doing so, we provide a new interpretation for such measures,
namely, that they quantify how much one must shrink or deleverage a position
for it to become acceptable. In particular, the Minkowski Deviation of a set
which is convex, stable under scalar addition, and radially bounded at
non-constants, is a generalized deviation measure. Furthermore, we explore the
relations existing between mathematical and financial properties attributable
to an acceptance set, and the corresponding properties of the induced measure.
Hence, we fill the gap that is the lack of an acceptance set for deviation
measures. Dual characterizations in terms of polar sets and support functionals
are provided.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:17:05 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 16:57:14 GMT""},{""version"":""v3"",""created"":""Sat, 24 Jul 2021 19:55:32 GMT""}]","2021-07-27"
"2007.01415","Knox S. Long","Knox S. Long, William P. Blair, P. Frank Winkler and Christina K.
  Lacey","The Supernova Remnant Population of NGC6946 as Observed in [Fe II] 1.644
  $\mu$m with HST","43 pages, 9 figures, 2 tables, accepted for publication in ApJ",,"10.3847/1538-4357/aba2e9",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  NGC6946 is a high star formation rate face-on spiral galaxy that has hosted
ten supernovae since 1917. Not surprisingly, a large number of supernova
remnants and candidates have been identified either as optical nebulae with
high [S II]:H$\alpha$ line ratios (147) or as compact non-thermal radio sources
(35). However, there are only seven overlaps between these two samples. Here,
we apply [Fe II] 1.644 $\mu$m emission as a new diagnostic to search for
supernova remnants in an attempt to resolve this discrepancy. [Fe II] is
expected to be relatively strong in the radiative shocks of supernova remnants
and almost absent in HII regions. It is less susceptible to the effects of
absorption along the line of sight than the optical lines normally used to
identify remnants. Using data from the WFC3 camera on HST}, we identify 132 [Fe
II] emission nebulae in NGC6946 as likely supernova remnants. Of these, 54
align with previously known optical supernova remnants. The remaining 78
objects are new; of these 44 are visible in new HST imagery in H$\alpha$ and [S
II]. This brings the total number of supernova remnant candidates (from optical
and/or IR data) in NGC6946 to 225. A total of 14 coincidences with radio
supernova remnant candidates (out of 30 in our search area) are found in this
expanded list. The identification of so many new remnant candidates validates
the use of [Fe II] imagery for finding remnants, and suggests that previous
remnant searches in other galaxies may be far from complete.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:18:11 GMT""}]","2020-08-19"
"2007.01416","Hugo Carrillo Mr.","H. Carrillo, E. Macca, G. Russo, C. Par\'es, D. Zor\'io","An order-adaptive compact approximation Taylor method for systems of
  conservation laws",,,"10.1016/j.jcp.2021.110358",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new family of high-order shock-capturing finite difference
numerical methods for systems of conservation laws. These methods, called
Adaptive Compact Approximation Taylor (ACAT) schemes, use centered $(2p +
1)$-point stencils, where $p$ may take values in $\{1, 2, \dots, P\}$ according
to a new family of smoothness indicators in the stencils. The methods are based
on a combination of a robust first order scheme and the Compact Approximate
Taylor (CAT) methods of order $2p$-order, $p=1,2,\dots, P$ so that they are
first order accurate near discontinuities and have order $2p$ in smooth
regions, where $(2p +1)$ is the size of the biggest stencil in which large
gradients are not detected. CAT methods, introduced in \cite{CP2019}, are an
extension to nonlinear problems of the Lax-Wendroff methods in which the
Cauchy-Kovalesky (CK) procedure is circumvented following the strategy
introduced in \cite{ZBM2017} that allows one to compute time derivatives in a
recursive way using high-order centered differentiation formulas combined with
Taylor expansions in time. The expression of ACAT methods for 1D and 2D systems
of balance laws are given and the performance is tested in a number of test
cases for several linear and nonlinear systems of conservation laws, including
Euler equations for gas dynamics.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:27:32 GMT""}]","2021-06-02"
"2007.01417","Daan Camps","Daan Camps, Roel Van Beeumen","Approximate Quantum Circuit Synthesis using Block-Encodings",,"Phys. Rev. A 102, 052411 (2020)","10.1103/PhysRevA.102.052411",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the challenges in quantum computing is the synthesis of unitary
operators into quantum circuits with polylogarithmic gate complexity. Exact
synthesis of generic unitaries requires an exponential number of gates in
general. We propose a novel approximate quantum circuit synthesis technique by
relaxing the unitary constraints and interchanging them for ancilla qubits via
block-encodings. This approach combines smaller block-encodings, which are
easier to synthesize, into quantum circuits for larger operators. Due to the
use of block-encodings, our technique is not limited to unitary operators and
can also be applied for the synthesis of arbitrary operators. We show that
operators which can be approximated by a canonical polyadic expression with a
polylogarithmic number of terms can be synthesized with polylogarithmic gate
complexity with respect to the matrix dimension.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:30:28 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 20:52:44 GMT""}]","2020-11-24"
"2007.01418","Brian Okorn","Brian Okorn, Mengyun Xu, Martial Hebert, David Held","Learning Orientation Distributions for Object Pose Estimation",,,"10.1109/IROS45743.2020.9340860",,"cs.CV cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For robots to operate robustly in the real world, they should be aware of
their uncertainty. However, most methods for object pose estimation return a
single point estimate of the object's pose. In this work, we propose two
learned methods for estimating a distribution over an object's orientation. Our
methods take into account both the inaccuracies in the pose estimation as well
as the object symmetries. Our first method, which regresses from deep learned
features to an isotropic Bingham distribution, gives the best performance for
orientation distribution estimation for non-symmetric objects. Our second
method learns to compare deep features and generates a non-parameteric
histogram distribution. This method gives the best performance on objects with
unknown symmetries, accurately modeling both symmetric and non-symmetric
objects, without any requirement of symmetry annotation. We show that both of
these methods can be used to augment an existing pose estimator. Our evaluation
compares our methods to a large number of baseline approaches for uncertainty
estimation across a variety of different types of objects.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:30:56 GMT""},{""version"":""v2"",""created"":""Tue, 11 Aug 2020 01:12:11 GMT""}]","2021-05-21"
"2007.01419","Yimeng Min","Yimeng Min","Persistent Neurons","add some new results",,,,"cs.LG cs.CV cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural networks (NN)-based learning algorithms are strongly affected by the
choices of initialization and data distribution. Different optimization
strategies have been proposed for improving the learning trajectory and finding
a better optima. However, designing improved optimization strategies is a
difficult task under the conventional landscape view. Here, we propose
persistent neurons, a trajectory-based strategy that optimizes the learning
task using information from previous converged solutions. More precisely, we
utilize the end of trajectories and let the parameters explore new landscapes
by penalizing the model from converging to the previous solutions under the
same initialization. Persistent neurons can be regarded as a stochastic
gradient method with informed bias where individual updates are corrupted by
deterministic error terms. Specifically, we show that persistent neurons, under
certain data distribution, is able to converge to more optimal solutions while
initializations under popular framework find bad local minima. We further
demonstrate that persistent neurons helps improve the model's performance under
both good and poor initializations. We evaluate the full and partial persistent
model and show it can be used to boost the performance on a range of NN
structures, such as AlexNet and residual neural network (ResNet).
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:36:49 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2021 09:16:24 GMT""}]","2021-03-19"
"2007.01420","Mohannad Elhamod","Mohannad Elhamod, Jie Bu, Christopher Singh, Matthew Redell, Abantika
  Ghosh, Viktor Podolskiy, Wei-Cheng Lee, Anuj Karpatne","CoPhy-PGNN: Learning Physics-guided Neural Networks with Competing Loss
  Functions for Solving Eigenvalue Problems",,,,,"cs.LG physics.comp-ph quant-ph stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physics-guided Neural Networks (PGNNs) represent an emerging class of neural
networks that are trained using physics-guided (PG) loss functions (capturing
violations in network outputs with known physics), along with the supervision
contained in data. Existing work in PGNNs has demonstrated the efficacy of
adding single PG loss functions in the neural network objectives, using
constant trade-off parameters, to ensure better generalizability. However, in
the presence of multiple PG functions with competing gradient directions, there
is a need to adaptively tune the contribution of different PG loss functions
during the course of training to arrive at generalizable solutions. We
demonstrate the presence of competing PG losses in the generic neural network
problem of solving for the lowest (or highest) eigenvector of a physics-based
eigenvalue equation, which is commonly encountered in many scientific problems.
We present a novel approach to handle competing PG losses and demonstrate its
efficacy in learning generalizable solutions in two motivating applications of
quantum mechanics and electromagnetic propagation. All the code and data used
in this work is available at https://github.com/jayroxis/Cophy-PGNN.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:39:02 GMT""},{""version"":""v2"",""created"":""Tue, 4 Aug 2020 01:06:26 GMT""},{""version"":""v3"",""created"":""Fri, 23 Oct 2020 15:24:01 GMT""},{""version"":""v4"",""created"":""Thu, 5 Nov 2020 17:16:04 GMT""},{""version"":""v5"",""created"":""Thu, 17 Jun 2021 19:12:59 GMT""},{""version"":""v6"",""created"":""Tue, 24 Aug 2021 00:20:58 GMT""},{""version"":""v7"",""created"":""Tue, 14 Dec 2021 14:37:33 GMT""},{""version"":""v8"",""created"":""Thu, 16 Dec 2021 16:13:37 GMT""}]","2021-12-17"
"2007.01421","Ali A. K. Tehrani","Ali K. Z. Tehrani, Morteza Mirzaei and Hassan Rivaz","Semi-Supervised Training of Optical Flow Convolutional Neural Networks
  in Ultrasound Elastography",,,,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional Neural Networks (CNN) have been found to have great potential
in optical flow problems thanks to an abundance of data available for training
a deep network. The displacement estimation step in UltraSound Elastography
(USE) can be viewed as an optical flow problem. Despite the high performance of
CNNs in optical flow, they have been rarely used for USE due to unique
challenges that both input and output of USE networks impose. Ultrasound data
has much higher high-frequency content compared to natural images. The outputs
are also drastically different, where displacement values in USE are often
smooth without sharp motions or discontinuities. The general trend is currently
to use pre-trained networks and fine-tune them on a small simulation ultrasound
database. However, realistic ultrasound simulation is computationally
expensive. Also, the simulation techniques do not model complex motions,
nonlinear and frequency-dependent acoustics, and many sources of artifact in
ultrasound imaging. Herein, we propose an unsupervised fine-tuning technique
which enables us to employ a large unlabeled dataset for fine-tuning of a CNN
optical flow network. We show that the proposed unsupervised fine-tuning method
substantially improves the performance of the network and reduces the artifacts
generated by networks trained on computer vision databases.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:39:07 GMT""}]","2020-07-06"
"2007.01422","Xin H. H. Zhang","Xin H. H. Zhang and Harold U. Baranger","Driven-dissipative phase transition in a Kerr oscillator: From
  semiclassical $\mathcal{PT}$ symmetry to quantum fluctuations","published version, 12 pages","Phys. Rev. A 103, 033711 (2021)","10.1103/PhysRevA.103.033711",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a minimal model that has a driven-dissipative quantum phase
transition, namely a Kerr non-linear oscillator subject to driving and
dissipation. Using mean-field theory, exact diagonalization, and the Keldysh
formalism, we analyze the critical phenomena in this system, showing which
aspects can be captured by each approach and how the approaches complement each
other. Then critical scaling and finite-size scaling are calculated
analytically using the quantum Langevin equation. The physics contained in this
simple model is surprisingly rich: it includes a continuous phase transition,
$Z_{2}$ symmetry breaking, $\mathcal{PT}$ symmetry, state squeezing, and
critical fluctuations. Due to its simplicity and solvability, this model can
serve as a paradigm for exploration of open quantum many-body physics.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:39:35 GMT""},{""version"":""v2"",""created"":""Mon, 9 Nov 2020 23:21:37 GMT""},{""version"":""v3"",""created"":""Wed, 24 Mar 2021 14:37:10 GMT""}]","2021-03-26"
"2007.01423","M. Maruf","M. Maruf and Anuj Karpatne","Maximizing Cohesion and Separation in Graph Representation Learning: A
  Distance-aware Negative Sampling Approach","14 pages, 9 figures, 3 tables, full length version with appendix;
  Published in Proceedings of the 2021 SIAM International Conference on Data
  Mining",,,,"cs.LG cs.SI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The objective of unsupervised graph representation learning (GRL) is to learn
a low-dimensional space of node embeddings that reflect the structure of a
given unlabeled graph. Existing algorithms for this task rely on negative
sampling objectives that maximize the similarity in node embeddings at nearby
nodes (referred to as ""cohesion"") by maintaining positive and negative corpus
of node pairs. While positive samples are drawn from node pairs that co-occur
in short random walks, conventional approaches construct negative corpus by
uniformly sampling random pairs, thus ignoring valuable information about
structural dissimilarity among distant node pairs (referred to as
""separation""). In this paper, we present a novel Distance-aware Negative
Sampling (DNS) which maximizes the separation of distant node-pairs while
maximizing cohesion at nearby node-pairs by setting the negative sampling
probability proportional to the pair-wise shortest distances. Our approach can
be used in conjunction with any GRL algorithm and we demonstrate the efficacy
of our approach over baseline negative sampling methods over downstream node
classification tasks on a number of benchmark datasets and GRL algorithms. All
our codes and datasets are available at
https://github.com/Distance-awareNS/DNS/.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:40:38 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 08:27:06 GMT""}]","2021-01-22"
"2007.01424","Yunxiu Zhou","Yunxiu Zhou, Simon A. Levin, Naomi E. Leonard","Active Control and Sustained Oscillations in actSIS Epidemic Dynamics",,,,,"physics.soc-ph math.DS q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An actively controlled Susceptible-Infected-Susceptible (actSIS) contagion
model is presented for studying epidemic dynamics with continuous-time feedback
control of infection rates. Our work is inspired by the observation that
epidemics can be controlled through decentralized disease-control strategies
such as quarantining, sheltering in place, social distancing, etc., where
individuals actively modify their contact rates with others in response to
observations of infection levels in the population. Accounting for a time lag
in observations and categorizing individuals into distinct sub-populations
based on their risk profiles, we show that the actSIS model manifests
qualitatively different features as compared with the SIS model. In a
homogeneous population of risk-averters, the endemic equilibrium is always
reduced, although the transient infection level can exhibit overshoot or
undershoot. In a homogeneous population of risk-tolerating individuals, the
system exhibits bistability, which can also lead to reduced infection. For a
heterogeneous population comprised of risk-tolerators and risk-averters, we
prove conditions on model parameters for the existence of a Hopf bifurcation
and sustained oscillations in the infected population.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:43:40 GMT""}]","2020-07-06"
"2007.01425","Giuseppe Di Molfetta Prof.","Michael Manighalam and Giuseppe Di Molfetta","Continuous Time Limit of the DTQW in 2D+1 and Plasticity",,,,,"quant-ph hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Plastic Quantum Walk admits both continuous time and continuous spacetime.
The model has been recently proposed by one of the authors in
\cite{molfetta2019quantum}, leading to a general quantum simulation scheme for
simulating fermions in the relativistic and non relativistic regimes. The
extension to two physical dimensions is still missing and here, as a novel
result, we demonstrate necessary and sufficient conditions concerning which
discrete time quantum walks can admit plasticity, showing the resulting
Hamiltonians. We consider coin operators as general $4$ parameter unitary
matrices, with parameters which are function of the lattice step size
$\varepsilon$. This dependence on $\varepsilon$ encapsulates all functions of
$\varepsilon$ for which a Taylor series expansion in $\varepsilon$ is well
defined, making our results very general.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:44:00 GMT""},{""version"":""v2"",""created"":""Tue, 24 Nov 2020 15:03:00 GMT""}]","2020-11-25"
"2007.01426","Wenyuan Wang Dr.","Aili Zhang, Ping Chen, Shuanming Li, Wenyuan Wang","Risk Modelling on Liquidations with L\'{e}vy Processes","4 figures",,,,"q-fin.RM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been decades since the academic world of ruin theory defined the
insolvency of an insurance company as the time when its surplus falls below
zero. This simplification, however, needs careful adaptions to imitate the
real-world liquidation process. Inspired by Broadie et al. (2007) and Li et al.
(2020), this paper uses a three-barrier model to describe the financial stress
towards bankruptcy of an insurance company. The financial status of the insurer
is divided into solvent, insolvent and liquidated three states, where the
insurer's surplus process at the state of solvent and insolvent is modelled by
two spectrally negative L\'{e}vy processes, which have been taken as good
candidates to model insurance risks. We provide a rigorous definition of the
time of liquidation ruin in this three-barrier model. By adopting the
techniques of excursions in the fluctuation theory, we study the joint
distribution of the time of liquidation, the surplus at liquidation and the
historical high of the surplus until liquidation, which generalizes the known
results on the classical expected discounted penalty function in Gerber and
Shiu (1998). The results have semi-explicit expressions in terms of the scale
functions and the L\'{e}vy triplets associated with the two underlying L\'{e}vy
processes. The special case when the two underlying L\'{e}vy processes coincide
with each other is also studied, where our results are expressed compactly via
only the scale functions. The corresponding results have good consistency with
the existing literatures on Parisian ruin with (or without) a lower barrier in
Landriault et al. (2014), Baurdoux et al. (2016) and Frostig and Keren-Pinhasik
(2019). Besides, numerical examples are provided to illustrate the underlying
features of liquidation ruin.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:46:04 GMT""}]","2020-07-06"
"2007.01427","Farbod Shafiei","Farbod Shafiei, Tommaso Orzali, Alexey Vert, Mohammad-Ali Miri, P. Y.
  Hung, Man Hoi Wong, Andrea Al\`u, Gennadi Bersuker and Michael C. Downer","Atomic-Scale Defect Detection by Nonlinear Light Scattering and
  Localization","23 pages-4 figures-5 Supplementary figures",,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hetero-epitaxial crystalline films underlie many electronic and optical
technologies but are prone to forming defects at their hetero-interfaces.
Atomic-scale defects such as threading dislocations that propagate into a film
impede the flow of charge carriers and light degrading electrical-optical
performance of devices. Diagnosis of subsurface defects traditionally requires
time consuming invasive techniques such as cross sectional transmission
electron microscopy. Using III-V films grown on Si, we have demonstrated
noninvasive, bench-top diagnosis of sub-surface defects by optical
second-harmonic scanning probe microscope. We observed a high-contrast pattern
of sub-wavelength hot spots caused by scattering and localization of
fundamental light by defect scattering sites. Size of these observed hotspots
are strongly correlated to the density of dislocation defects. Our results not
only demonstrate a global and versatile method for diagnosing sub-surface
scattering sites but uniquely elucidate optical properties of disordered media.
An extension to third harmonics would enable irregularities detection in
non-X(2) materials making the technique universally applicable.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:47:29 GMT""},{""version"":""v2"",""created"":""Sun, 2 Aug 2020 20:22:28 GMT""}]","2020-08-04"
"2007.01428","Paul Zhang","Paul Zhang, Daryl Deford, Justin Solomon","Medial Axis Isoperimetric Profiles","Code and supplemental available here:
  https://github.com/pzpzpzp1/isoperimetric_profile",,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently proposed as a stable means of evaluating geometric compactness, the
isoperimetric profile of a planar domain measures the minimum perimeter needed
to inscribe a shape with prescribed area varying from 0 to the area of the
domain. While this profile has proven valuable for evaluating properties of
geographic partitions, existing algorithms for its computation rely on
aggressive approximations and are still computationally expensive. In this
paper, we propose a practical means of approximating the isoperimetric profile
and show that for domains satisfying a ""thick neck"" condition, our
approximation is exact. For more general domains, we show that our bound is
still exact within a conservative regime and is otherwise an upper bound. Our
method is based on a traversal of the medial axis which produces efficient and
robust results. We compare our technique with the state-of-the-art
approximation to the isoperimetric profile on a variety of domains and show
significantly tighter bounds than were previously achievable.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:48:42 GMT""}]","2020-07-06"
"2007.01429","Dawei Li","Ruoyu Sun, Dawei Li, Shiyu Liang, Tian Ding, R Srikant","The Global Landscape of Neural Networks: An Overview","16 pages. 8 figures",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the major concerns for neural network training is that the
non-convexity of the associated loss functions may cause bad landscape. The
recent success of neural networks suggests that their loss landscape is not too
bad, but what specific results do we know about the landscape? In this article,
we review recent findings and results on the global landscape of neural
networks. First, we point out that wide neural nets may have sub-optimal local
minima under certain assumptions. Second, we discuss a few rigorous results on
the geometric properties of wide networks such as ""no bad basin"", and some
modifications that eliminate sub-optimal local minima and/or decreasing paths
to infinity. Third, we discuss visualization and empirical explorations of the
landscape for practical neural nets. Finally, we briefly discuss some
convergence results and their relation to landscape results.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:50:20 GMT""}]","2020-07-06"
"2007.01430","Clark Alexander","Jeffrey Cohen, Alex Khan, Clark Alexander","Portfolio Optimization of 40 Stocks Using the DWave Quantum Annealer","15 pages, 8 figures",,,,"q-fin.GN quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the use of quantum computers for building a portfolio out of a
universe of U.S. listed, liquid equities that contains an optimal set of
stocks. Starting from historical market data, we look at various problem
formulations on the D-Wave Systems Inc. D-Wave 2000Q(TM) System (hereafter
called DWave) to find the optimal risk vs return portfolio; an optimized
portfolio based on the Markowitz formulation and the Sharpe ratio, a simplified
Chicago Quantum Ratio (CQR), then a new Chicago Quantum Net Score (CQNS). We
approach this first classically, then by our new method on DWave. Our results
show that practitioners can use a DWave to select attractive portfolios out of
40 U.S. liquid equities.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:51:31 GMT""}]","2020-07-06"
"2007.01431","Celso Aimbir\'e Weffort-Santos","C. A. Weffort-Santos and R. C. S. Schouery","Graphs without gap-vertex-labellings: families and bounds","Submitted to Discrete Applied Mathematics",,,,"cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A proper labelling of a graph $G$ is a pair $({\pi},c_{\pi})$ in which
${\pi}$ is an assignment of numeric labels to some elements of $G$, and
$c_{\pi}$ is a colouring induced by ${\pi}$ through some mathematical function
over the set of labelled elements. In this work, we consider
gap-vertex-labellings, in which the colour of a vertex is determined by a
function considering the largest difference between the labels assigned to its
neighbours. We present the first upper-bound for the vertex-gap number of
arbitrary graphs, which is the least number of labels required to properly
label a graph. We investigate families of graphs which do not admit any
gap-vertex-labelling, regardless of the number of labels. Furthermore, we
introduce a novel parameter associated with this labelling and provide bounds
for it for complete graphs ${K_n}$.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:52:10 GMT""}]","2020-07-06"
"2007.01432","Jason Jackiewicz","Jason Jackiewicz","Probabilistic Inversions for Time-Distance Helioseismology","25 pages, 14 figures. Accepted to Solar Physics (the arxiv version
  contains an added appendix C, and a shortened abstract)","Sol Phys 295, 137 (2020)","10.1007/s11207-020-01667-3",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time-distance helioseismology is a set of powerful tools to study features
below the Sun's surface. Inverse methods are needed to interpret time-distance
measurements, with many examples in the literature. However, techniques that
utilize a more statistical approach to inferences, and broadly used in the
astronomical community, are less-commonly found in helioseismology. This
article aims to introduce a potentially powerful inversion scheme based on
Bayesian probability theory and Monte Carlo sampling that is suitable for local
helioseismology. We describe the probabilistic method and how it is
conceptually different from standard inversions used in local helioseismology.
Several example calculations are carried out to compare and contrast the setup
of the problems and the results that are obtained. The examples focus on two
important phenomena studied with helioseismology: meridional circulation and
supergranulation. Numerical models are used to compute synthetic observations,
providing the added benefit of knowing the solution against which the results
can be tested. For demonstration purposes, the problems are formulated in two
and three dimensions, using both ray- and Born-theoretical approaches. The
results seem to indicate that the probabilistic inversions not only find a
better solution with much more realistic estimation of the uncertainties, but
they also provide a broader view of the range of solutions possible for any
given model, making the interpretation of the inversion more quantitative in
nature. Unlike the progress being made in fundamental measurement schemes in
local helioseismology that image the far side of the Sun, or have detected
signatures of global Rossby waves, among many others, inversions of those
measurements have had significantly less success. Such statistical methods may
help overcome some of these barriers to move the field forward.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:57:06 GMT""}]","2020-10-14"
"2007.01433","Bohumir Jelinek","Bohumir Jelinek, William J. Young, Matthew Dantin, William Furr, Haley
  Doude, Matthew W. Priddy","Two-dimensional thermal finite element model of directed energy
  deposition: matching melt pool temperature profile with pyrometer measurement","for associated animations and source code, see
  https://gitlab.com/bohumir1/2d-heat-ded/","Journal of Manufacturing Processes (2020), vol. 57, pp. 187-195","10.1016/j.jmapro.2020.06.021",,"physics.app-ph cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An open source two-dimensional (2D) thermal finite element (FE) model of the
Directed Energy Deposition (DED) process is developed using the Python-based
FEniCS framework. The model incrementally deposits material ahead of the laser
focus point according to the geometry of the part. The laser heat energy is
supplied by a Gaussian-distributed heat source while the phase change is
represented by increased heat capacity around the solidus-liquidus temperature
range. Experimental validation of the numerical model is performed by matching
with the melt pool temperature measurements taken by a dual wavelength
pyrometer during the build process of a box-shaped Ti--6Al--4V part with large
geometrical voids. Effects of large geometrical voids on the melt pool shape
and maximum melt pool temperature are examined. Both the numerical and
experimental data show an increase in the melt pool size and temperature during
deposition above large voids. The trailing edge of the melt pool's temperature
profile obtained using the developed numerical model closely matches pyrometer
measurements.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:59:48 GMT""}]","2020-07-06"
"2007.01434","David Lopez-Paz","Ishaan Gulrajani, David Lopez-Paz","In Search of Lost Domain Generalization",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of domain generalization algorithms is to predict well on
distributions different from those seen during training. While a myriad of
domain generalization algorithms exist, inconsistencies in experimental
conditions -- datasets, architectures, and model selection criteria -- render
fair and realistic comparisons difficult. In this paper, we are interested in
understanding how useful domain generalization algorithms are in realistic
settings. As a first step, we realize that model selection is non-trivial for
domain generalization tasks. Contrary to prior work, we argue that domain
generalization algorithms without a model selection strategy should be regarded
as incomplete. Next, we implement DomainBed, a testbed for domain
generalization including seven multi-domain datasets, nine baseline algorithms,
and three model selection criteria. We conduct extensive experiments using
DomainBed and find that, when carefully implemented, empirical risk
minimization shows state-of-the-art performance across all datasets. Looking
forward, we hope that the release of DomainBed, along with contributions from
fellow researchers, will streamline reproducible and rigorous research in
domain generalization.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 23:08:07 GMT""}]","2020-07-06"
"2007.01435","Renate Sachse","Renate Sachse and Manfred Bischoff","A variational formulation for motion design of adaptive compliant
  structures","Submitted to International Journal for Numerical Methods in
  Engineering (IJNME)",,"10.1002/nme.6570",,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adaptive structures are characterized by their ability to adjust their
geometrical and other properties to changing loads or requirements during
service. This contribution deals with a method for the design of quasi-static
motions of structures between two prescribed geometrical configurations that
are optimal with regard to a specified quality function while taking large
deformations into account. It is based on a variational formulation and the
solution by two finite element discretizations, the spatial discretization (the
standard finite element mesh) and an additional discretization of the
deformation path or trajectory. For the investigations, an exemplary objective
function, the minimization of the internal energy, integrated along the
deformation path, is used. The method for motion design presented herein uses
the Newton-Raphson method as a second order optimization algorithm and allows
for analytical sensitivity analysis. The proposed method is verified and its
properties are investigated by benchmark examples including rigid body motions,
instability phenomena and determination of inextensible deformations of shells.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 23:15:08 GMT""}]","2020-12-08"
"2007.01436","Vikram Sundar","Vikram Sundar (1) and Lucy Colwell (1 and 2) ((1) Google Research, (2)
  Department of Chemistry, University of Cambridge)","Attribution Methods Reveal Flaws in Fingerprint-Based Virtual Screening","4 pages, 5 figures. In proceedings for the 2020 ICML workshop on
  Machine Learning Interpretability for Scientific Discovery",,,,"q-bio.BM q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fingerprint-based models for protein-ligand binding have demonstrated
outstanding success on benchmark datasets; however, these models may not learn
the correct binding rules. To assess this concern, we use in silico datasets
with known binding rules to develop a general framework for evaluating model
attribution. This framework identifies fragments that a model considers
necessary to achieve a particular score, sidestepping the need for a model to
be differentiable. Our results confirm that high-performing models may not
learn the correct binding rule, and suggest concrete steps that can remedy this
situation. We show that adding fragment-matched inactive molecules (decoys) to
the data reduces attribution false negatives, while attribution false positives
largely arise from the background correlation structure of molecular data.
Normalizing for these background correlations helps to reveal the true binding
logic. Our work highlights the danger of trusting attributions from
high-performing models and suggests that a closer examination of fingerprint
correlation structure and better decoy selection may help reduce
misattributions.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 23:23:47 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 22:34:00 GMT""}]","2020-07-10"
"2007.01437","Marcelo Amanajas Pires","Marcelo A. Pires and S\'ilvio M. Duarte Queir\'os","Genuine Parrondo's paradox in quantum walks with time-dependent coin
  operators",,"Phys. Rev. E 102, 042124 (2020)","10.1103/PhysRevE.102.042124",,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that a genuine Parrondo paradox can emerge in two-state quantum walks
without resorting to experimentally intricate high-dimensional coins. To
achieve such goal we employ a time-dependent coin operator without breaking the
translation spatial invariance of the system.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 23:23:57 GMT""}]","2020-10-28"
"2007.01438","Harshitha K Bhat","Harshitha K. Bhat, Susmita Chakravorty, Dhrubojyoti Sengupta, Martin
  Elvis, Sudeb Ranjan Datta, Nirupam Roy, Caroline Bertemes, Gary Ferland,
  Savithri H. Ezhikode","Hyper-massive Black Holes have Faint Broad and Narrow Emission Lines","20 pages, 26 figures, to be published in MNRAS","2020, MNRAS, 497, 2992","10.1093/mnras/staa2002",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The EUV provides most of the ionization that creates the high equivalent
width (EW) broad and narrow emission lines (BELs, NELs) of quasars. Spectra of
Hypermassive Schwarzschild black holes (HMBHs, $M_{BH} \geq 10^{10} M_{\odot}$)
with $\alpha$-discs, decline rapidly in the EUV suggesting much lower EWs.
Model spectra for black holes of mass $10^{6}-10^{12} M_{\odot}$ and accretion
rates $0.03 \leq L_{bol}/L_{edd} \leq 1.0$ were input to the CLOUDY
photoionization code. BELs become $\sim$100 times weaker in EW from $M_{BH}
\sim 10^8 M_{\odot}$ to $M_{BH} \sim 10^{10} M_{\odot}$. The high ionization
BELs (O VI 1034 $\overset{\circ}{\mathrm {A}}$, C IV 1549
$\overset{\circ}{\mathrm {A}}$, He II 1640 $\overset{\circ}{\mathrm {A}}$)
decline in EW from ($M_{BH} \geq 10^6 M_{\odot}$, reproducing the Baldwin
effect, but regain EW for $M_{BH} \geq 10^{10} M_{\odot}$). The low ionization
lines (MgII 2798 $\overset{\circ}{\mathrm {A}}$, H$\beta$ 4861
$\overset{\circ}{\mathrm {A}}$ and H$\alpha$ 6563 $\overset{\circ}{\mathrm
{A}}$) remain weak. Lines for maximally spinning HMBHs behave similarly. Line
ratio diagrams for the BELs show that high OVI/H$\beta$ and low CIV/H$\alpha$
may pick out HMBH, although OVI is often hard to observe. In NEL BPT diagrams
HMBHs lie among star-forming regions, except for highly spinning, high
accretion rate HMBHs. In summary, the BELs expected from HMBHs would be hard to
detect using the current optical facilities. From 100 to $10^{12} M_{\odot}$,
the emission lines used to detect AGN only have high EW in the $10^6 - 10^9
M_{\odot}$ window, where most AGN are found. This selection effect may be
distorting reported distributions of $M_{BH}$.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 23:26:11 GMT""}]","2021-01-13"
"2007.01439","Janice Coen","J. L. Coen, W. Schroeder, S. Conway, L. Tarnay","Computational modeling of extreme wildland fire events: a synthesis of
  scientific understanding with applications to forecasting, land management,
  and firefighter safety",,"Journal of Computational Science Article 101152 (2020)","10.1016/j.jocs.2020.101152",,"physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The understanding and prediction of large wildland fire events around the
world is a growing interdisciplinary research area advanced rapidly by
development and use of computational models. Recent models bidirectionally
couple computational fluid dynamics models including weather prediction models
with modules containing algorithms representing fire spread and heat release,
simulating fire-atmosphere interactions across scales spanning three orders of
magnitude. Integrated with weather data and airborne and satellite remote
sensing data on wildland fuels and active fire detection, modern coupled
weather-fire modeling systems are being used to solve current science problems.
Compared to legacy tools, these dynamic computational modeling systems increase
cost and complexity but have produced breakthrough insights notably into the
mechanisms underlying extreme wildfire events such as fine-scale extreme winds
associated with interruptions of the electricity grid and have been configured
to forecast a fire's growth, expanding our ability to anticipate how they will
unfold. We synthesize case studies of recent extreme events, expanding
applications, and the challenges and limitations in our remote sensing systems,
fire prediction tools, and meteorological models that add to wildfires' mystery
and apparent unpredictability.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 23:31:02 GMT""}]","2020-07-06"
"2007.01440","Aritra Basu","Aritra Basu, Jishnu Goswami, Dominik J. Schwarz, Yuko Urakawa","Searching for axion-like particles under strong gravitational lenses","6 pages, 3 figures, reference updated, Submitted","Phys. Rev. Lett. 126, 191102 (2021)","10.1103/PhysRevLett.126.191102",,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish strong gravitational lens systems as robust probes of axion-like
particles (ALPs) -- a candidate for dark matter. A tiny interaction of photons
with ALPs induces birefringence. Multiple images of gravitationally lensed
polarised objects allow differential birefringence measurement, alleviating
systematics and astrophysical dependencies. We apply this novel method to the
lens system CLASS B1152+199 and constrain ALP-photon coupling $\le 9.2\times
10^{-11}\, {\rm GeV}^{-1} \textrm{ to } 7.7\times 10^{-8}\, {\rm GeV}^{-1}$
($95\%$ C.L.) for ALP mass between $3.6\times 10^{-21} \,{\rm eV}$ and $4.6
\times 10^{-18} \,{\rm eV}$. A larger sample will improve the constraints.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 23:33:42 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jul 2020 14:03:02 GMT""}]","2021-05-19"
"2007.01441","Nalini Singh","Nalini M. Singh, Juan Eugenio Iglesias, Elfar Adalsteinsson, Adrian V.
  Dalca, Polina Golland","Joint Frequency and Image Space Learning for MRI Reconstruction and
  Analysis","Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://www.melba-journal.org/papers/2022:018.html",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose neural network layers that explicitly combine frequency and image
feature representations and show that they can be used as a versatile building
block for reconstruction from frequency space data. Our work is motivated by
the challenges arising in MRI acquisition where the signal is a corrupted
Fourier transform of the desired image. The proposed joint learning schemes
enable both correction of artifacts native to the frequency space and
manipulation of image space representations to reconstruct coherent image
structures at every layer of the network. This is in contrast to most current
deep learning approaches for image reconstruction that treat frequency and
image space features separately and often operate exclusively in one of the two
spaces. We demonstrate the advantages of joint convolutional learning for a
variety of tasks, including motion correction, denoising, reconstruction from
undersampled acquisitions, and combined undersampling and motion correction on
simulated and real world multicoil MRI data. The joint models produce
consistently high quality output images across all tasks and datasets. When
integrated into a state of the art unrolled optimization network with
physics-inspired data consistency constraints for undersampled reconstruction,
the proposed architectures significantly improve the optimization landscape,
which yields an order of magnitude reduction of training time. This result
suggests that joint representations are particularly well suited for MRI
signals in deep learning networks. Our code and pretrained models are publicly
available at https://github.com/nalinimsingh/interlacer.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 23:54:46 GMT""},{""version"":""v2"",""created"":""Thu, 26 Nov 2020 06:22:39 GMT""},{""version"":""v3"",""created"":""Wed, 16 Feb 2022 15:58:29 GMT""},{""version"":""v4"",""created"":""Sat, 18 Jun 2022 02:22:11 GMT""}]","2022-06-22"
"2007.01442","Ronshee Chawla","Ronshee Chawla, Abishek Sankararaman and Sanjay Shakkottai","Multi-Agent Low-Dimensional Linear Bandits","To appear in IEEE Transactions on Automatic Control",,,,"cs.LG cs.DC cs.SI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a multi-agent stochastic linear bandit with side information,
parameterized by an unknown vector $\theta^* \in \mathbb{R}^d$. The side
information consists of a finite collection of low-dimensional subspaces, one
of which contains $\theta^*$. In our setting, agents can collaborate to reduce
regret by sending recommendations across a communication graph connecting them.
We present a novel decentralized algorithm, where agents communicate subspace
indices with each other and each agent plays a projected variant of LinUCB on
the corresponding (low-dimensional) subspace. By distributing the search for
the optimal subspace across users and learning of the unknown vector by each
agent in the corresponding low-dimensional subspace, we show that the per-agent
finite-time regret is much smaller than the case when agents do not
communicate. We finally complement these results through simulations.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 23:54:56 GMT""},{""version"":""v2"",""created"":""Fri, 30 Oct 2020 01:10:50 GMT""},{""version"":""v3"",""created"":""Sun, 16 May 2021 04:55:24 GMT""},{""version"":""v4"",""created"":""Wed, 25 May 2022 04:52:37 GMT""}]","2022-05-26"
"2007.01443","Terence Musho","Robert Tempke, Liam Thomas, Christina Wildfire, Dushyant Shekhawat,
  Terence Musho","Machine Learning Approach for Transforming Scattering Parameters to
  Complex Permittivity",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study investigates the application of an artificial neural network to
predict the complex dielectric properties of granular catalysts commonly used
in microwave reaction chemistry. The study utilizes finite element
electromagnetic simulations and two-dimensional convolutional neural networks
to solve for a large solution space of varying dielectrics. This convolutional
neural network was trained using a supervised learning approach and a common
backpropagation. The frequency range of interest was between 0.1 to 13.5 GHz
with the real part of the dielectric constants ranging from 1 to 100 and the
imaginary part ranging from 0.0 to 0.2. The network was double validated using
experimental data collected from a coaxial airline. The model was demonstrated
to convert either experimental or computational derived scattering parameter to
complex permittivities. Moreover, the model eliminates the need for iterative
solutions that often have difficulty with the piecewise continuous nature of
frequency dependent scattering parameters.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 00:08:55 GMT""}]","2020-07-06"
"2007.01444","Griffin Mooers","Griffin Mooers, Jens Tuyls, Stephan Mandt, Michael Pritchard, Tom
  Beucler","Generative Modeling for Atmospheric Convection","8 Pages, 6 Figures. Accepted into ACM International Conference
  Proceedings Series",,,,"physics.ao-ph cs.LG physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While cloud-resolving models can explicitly simulate the details of
small-scale storm formation and morphology, these details are often ignored by
climate models for lack of computational resources. Here, we explore the
potential of generative modeling to cheaply recreate small-scale storms by
designing and implementing a Variational Autoencoder (VAE) that performs
structural replication, dimensionality reduction, and clustering of
high-resolution vertical velocity fields. Trained on ~6*10^6 samples spanning
the globe, the VAE successfully reconstructs the spatial structure of
convection, performs unsupervised clustering of convective organization
regimes, and identifies anomalous storm activity, confirming the potential of
generative modeling to power stochastic parameterizations of convection in
climate models.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 00:24:09 GMT""},{""version"":""v2"",""created"":""Sat, 24 Oct 2020 22:43:46 GMT""}]","2020-10-27"
"2007.01445","Haotian Jiang","Haotian Jiang","Minimizing Convex Functions with Rational Minimizers","To appear in the Journal of the ACM. This journal version simplifies
  and significantly strengthens the results in an earlier version of this paper
  which appeared in SODA 2021",,,,"cs.DS cs.DM cs.IT math.IT math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a separation oracle $\mathsf{SO}$ for a convex function $f$ defined on
$\mathbb{R}^n$ that has an integral minimizer inside a box with radius $R$, we
show how to find an exact minimizer of $f$ using at most (a) $O(n (n \log \log
(n)/\log (n) + \log(R)))$ calls to $\mathsf{SO}$ and $\mathsf{poly}(n,
\log(R))$ arithmetic operations, or (b) $O(n \log(nR))$ calls to $\mathsf{SO}$
and $\exp(O(n)) \cdot \mathsf{poly}(\log(R))$ arithmetic operations. When the
set of minimizers of $f$ has integral extreme points, our algorithm outputs an
integral minimizer of $f$. This improves upon the previously best oracle
complexity of $O(n^2 (n + \log(R)))$ for polynomial time algorithms and
$O(n^2\log(nR))$ for exponential time algorithms obtained by [Gr\""otschel,
Lov\'asz and Schrijver, Prog. Comb. Opt. 1984, Springer 1988] over thirty years
ago. Our improvement on Gr\""otschel, Lov\'asz and Schrijver's result
generalizes to the setting where the set of minimizers of $f$ is a rational
polyhedron with bounded vertex complexity.
  For the Submodular Function Minimization problem, our result immediately
implies a strongly polynomial algorithm that makes at most $O(n^3 \log \log
(n)/\log (n))$ calls to an evaluation oracle, and an exponential time algorithm
that makes at most $O(n^2 \log(n))$ calls to an evaluation oracle. These
improve upon the previously best $O(n^3 \log^2(n))$ oracle complexity for
strongly polynomial algorithms given in [Lee, Sidford and Wong, FOCS 2015] and
[Dadush, V\'egh and Zambelli, SODA 2018], and an exponential time algorithm
with oracle complexity $O(n^3 \log(n))$ given in the former work.
  Our result is achieved via a reduction to the Shortest Vector Problem in
lattices. We analyze its oracle complexity using a potential function that
simultaneously captures the size of the search set and the density of the
lattice.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 00:51:12 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 20:28:36 GMT""},{""version"":""v3"",""created"":""Wed, 11 Nov 2020 08:15:28 GMT""},{""version"":""v4"",""created"":""Mon, 23 Nov 2020 01:45:45 GMT""},{""version"":""v5"",""created"":""Tue, 20 Sep 2022 18:14:12 GMT""}]","2022-09-22"
"2007.01446","Hilke Schlichting","John B. Biersteker (MIT) and Hilke E. Schlichting (UCLA, MIT)","Losing Oceans: The Effects of Composition on the Thermal Component of
  Impact-driven Atmospheric Loss","submitted to MNRAS, 9 pages, 4 figures",,"10.1093/mnras/staa3614",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The formation of the solar system's terrestrial planets concluded with a
period of giant impacts. Previous works examining the volatile loss caused by
the impact shock in the moon-forming impact find atmospheric losses of at most
20-30 per cent and essentially no loss of oceans. However, giant impacts also
result in thermal heating, which can lead to significant atmospheric escape via
a Parker-type wind. Here we show that H2O and other high-mean molecular weight
outgassed species can be efficiently lost through this thermal wind if present
in a hydrogen-dominated atmosphere, substantially altering the final volatile
inventory of terrestrial planets. Specifically, we demonstrate that a giant
impact of a Mars-sized embryo with a proto-Earth can remove several Earth
oceans' worth of H2O, and other heavier volatile species, together with a
primordial hydrogen-dominated atmosphere. These results may offer an
explanation for the observed depletion in Earth's light noble gas budget and
for its depleted xenon inventory, which suggest that Earth underwent
significant atmospheric loss by the end of its accretion. Because planetary
embryos are massive enough to accrete primordial hydrogen envelopes and because
giant impacts are stochastic and occur concurrently with other early
atmospheric evolutionary processes, our results suggest a wide diversity in
terrestrial planet volatile budgets.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:03:24 GMT""}]","2020-12-02"
"2007.01447","Jinshan Xu","Jinshan Xu, Zhenqin Chen, Yanpei Lu, Xi Yang, Alain Pumir","Improved Preterm Prediction Based on Optimized Synthetic Sampling of EHG
  Signal",,,,,"cs.LG eess.SP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Preterm labor is the leading cause of neonatal morbidity and mortality and
has attracted research efforts from many scientific areas. The
inter-relationship between uterine contraction and the underlying electrical
activities makes uterine electrohysterogram (EHG) a promising direction for
preterm detection and prediction. Due the scarcity of EHG signals, especially
those of preterm patients, synthetic algorithms are applied to create
artificial samples of preterm type in order to remove prediction bias towards
term, at the expense of a reduction of the feature effectiveness in
machine-learning based automatic preterm detecting. To address such problem, we
quantify the effect of synthetic samples (balance coefficient) on features'
effectiveness, and form a general performance metric by utilizing multiple
feature scores with relevant weights that describe their contributions to class
separation. Combined with the activation/inactivation functions that
characterizes the effect of the abundance of training samples in term and
preterm prediction precision, we obtain an optimal sample balance coefficient
that compromise the effect of synthetic samples in removing bias towards the
majority and the side-effect of reducing features' importance. Substantial
improvement in prediction precision has been achieved through a set of
numerical tests on public available TPEHG database, and it verifies the
effectiveness of the proposed method.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:12:31 GMT""}]","2020-07-06"
"2007.01448","Yanying Sheng","Runjing Lu and Yanying Sheng","From Fear to Hate: How the Covid-19 Pandemic Sparks Racial Animus in the
  United States","34 pages, 12 figures, 7 tables",,,,"econ.GN cs.SI q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We estimate the effect of the Coronavirus (Covid-19) pandemic on racial
animus, as measured by Google searches and Twitter posts including a commonly
used anti-Asian racial slur. Our empirical strategy exploits the plausibly
exogenous variation in the timing of the first Covid-19 diagnosis across
regions in the United States. We find that the first local diagnosis leads to
an immediate increase in racist Google searches and Twitter posts, with the
latter mainly coming from existing Twitter users posting the slur for the first
time. This increase could indicate a rise in future hate crimes, as we document
a strong correlation between the use of the slur and anti-Asian hate crimes
using historic data. Moreover, we find that the rise in the animosity is
directed at Asians rather than other minority groups and is stronger on days
when the connection between the disease and Asians is more salient, as proxied
by President Trump's tweets mentioning China and Covid-19 at the same time. In
contrast, the negative economic impact of the pandemic plays little role in the
initial increase in racial animus. Our results suggest that de-emphasizing the
connection between the disease and a particular racial group can be effective
in curbing current and future racial animus.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:21:44 GMT""}]","2020-07-06"
"2007.01449","Mario I. Molina","Mario I. Molina","The Two-Dimensional Fractional Discrete Nonlinear Schrodinger Equation","6 pages, 6 figures",,"10.1016/j.physleta.2019.126180",,"nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a fractional version of the two-dimensional discrete nonlinear
Schr\""{o}dinger (DNLS) equation, where the usual discrete Laplacian is replaced
by its fractional form that depends on a fractional exponent $s$ that
interpolates between the case of an identity operator ($s=0$) and that of the
usual discrete 2D Laplacian ($s=1$). This replacement leads to a long-range
coupling among sites that, at low values of $s$, decreases the bandwidth and
leads to quasi-degenerate states. The mean square displacement of an
initially-localized excitation is shown to be ballistic at all times with a
`speed' that increases monotonically with the fractional exponent $s$. We also
compute the nonlinear modes and their stability for both, bulk and surface
modes. The modulational stability is seen to increase with an increase in the
fractional exponent. The trapping of an initially localized excitation shows a
selftrapping transition as a function of nonlinearity strength, whose threshold
increases with the value of $s$. In the linear limit, there persists a linear
trapping at small $s$ values. This behavior is connected with the decrease of
the bandwidth and its associated increase in quasi-degeneracy.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:26:09 GMT""}]","2020-07-08"
"2007.01450","Chengze Duan","Chengze Duan","Perfect submonoids of dominant weights",,,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let G be a connected semisimple group. Vinberg introduced the notion of
perfect submonoids of dominant weights of G in the study of Vinberg monoids. In
this paper, we give explicit descriptions of the perfect submonoids.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:27:45 GMT""}]","2020-07-06"
"2007.01451","Yun-Bin Zhao Y.B.","Yun-Bin Zhao and Zhi-Quan Luo","Improved RIP-Based Bounds for Guaranteed Performance of two Compressed
  Sensing Algorithms",,,,,"eess.SP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Iterative hard thresholding (IHT) and compressive sampling matching pursuit
(CoSaMP) are two types of mainstream compressed sensing algorithms using hard
thresholding operators for signal recovery and approximation. The guaranteed
performance for signal recovery via these algorithms has mainly been analyzed
under the condition that the restricted isometry constant of a sensing matrix,
denoted by $ \delta_K$ (where $K$ is an integer number), is smaller than a
certain threshold value in the interval $(0,1).$ The condition $ \delta_{K}<
\delta^*$ for some constant $ \delta^* \leq 1 $ ensuring the success of signal
recovery with a specific algorithm is called the
restricted-isometry-property-based (RIP-based) bound for guaranteed performance
of the algorithm. At the moment, the best known RIP-based bound for the
guaranteed recovery of $k$-sparse signals via IHT is $\delta_{3k}<
1/\sqrt{3}\approx 0.5774,$ and the bound for guaranteed recovery via CoSaMP is
$\delta_{4k} < 0.4782. $ A fundamental question in this area is whether such
theoretical results can be further improved. The purpose of this paper is to
affirmatively answer this question and rigorously show that the RIP-based
bounds for guaranteed performance of IHT can be significantly improved to $
\delta_{3k} < (\sqrt{5}-1)/2 \approx 0.618, $ and the bound for CoSaMP can be
improved and pushed to $ \delta_{4k}< 0.5102. $ These improvements are achieved
through a deep property of the hard thresholding operator.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:29:47 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 01:48:57 GMT""},{""version"":""v3"",""created"":""Tue, 22 Sep 2020 08:32:06 GMT""}]","2020-09-23"
"2007.01452","Cong Fang","Cong Fang, Jason D. Lee, Pengkun Yang, Tong Zhang","Modeling from Features: a Mean-field Framework for Over-parameterized
  Deep Neural Networks",,,,,"stat.ML cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a new mean-field framework for over-parameterized deep
neural networks (DNNs), which can be used to analyze neural network training.
In this framework, a DNN is represented by probability measures and functions
over its features (that is, the function values of the hidden units over the
training data) in the continuous limit, instead of the neural network
parameters as most existing studies have done. This new representation
overcomes the degenerate situation where all the hidden units essentially have
only one meaningful hidden unit in each middle layer, and further leads to a
simpler representation of DNNs, for which the training objective can be
reformulated as a convex optimization problem via suitable re-parameterization.
Moreover, we construct a non-linear dynamics called neural feature flow, which
captures the evolution of an over-parameterized DNN trained by Gradient
Descent. We illustrate the framework via the standard DNN and the Residual
Network (Res-Net) architectures. Furthermore, we show, for Res-Net, when the
neural feature flow process converges, it reaches a global minimal solution
under suitable conditions. Our analysis leads to the first global convergence
proof for over-parameterized neural network training with more than $3$ layers
in the mean-field regime.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:37:16 GMT""}]","2020-07-06"
"2007.01453","Mate Hartstein","Mate Hartstein, Hsu Liu, Yu-Te Hsu, Beng S. Tan, Monica Ciomaga
  Hatnean, Geetha Balakrishnan, Suchitra E. Sebastian","Intrinsic bulk quantum oscillations in a bulk unconventional insulator
  SmB$_6$",,"iScience 23(11):101632 (2020)","10.1016/j.isci.2020.101632",,"cond-mat.str-el","http://creativecommons.org/publicdomain/zero/1.0/","  The finding of bulk quantum oscillations in the bulk Kondo insulator SmB$_6$,
which has been proposed to be a correlated topological insulator, proved a
considerable surprise. The subsequent measurement of bulk quantum oscillations
in other correlated insulators including YbB$_{12}$ have lent support to our
discovery of a class of unconventional insulators that are host to bulk quantum
oscillations, of which SmB$_6$ was the first example. Here we perform a series
of experiments to examine evidence for the intrinsic character of bulk quantum
oscillations in floating zone-grown single crystals of SmB$_6$ that have been
the subject of our quantum oscillation studies thus far. We present results of
experiments including chemical composition analysis, magnetisation, thermal
conductivity, electrical transport, and heat capacity on floating zone-grown
single crystals of SmB$_6$, and a series of quantum oscillation experiments as
a function of magnetic field, temperature, and magnetic field-orientation on
single crystals of floating-zone grown SmB$_6$, LaB$_6$, and elemental
Aluminium. Results of these experimental studies establish the intrinsic origin
of quantum oscillations from the bulk of pristine floating zone-grown single
crystals of SmB$_6$. The origin of the underlying bulk Fermi surface that bears
close similarity with the unhybridised Fermi surface in metallic hexaborides
despite the bulk insulating character of SmB$_6$ is thus at the heart of a
theoretical mystery.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:38:47 GMT""}]","2021-01-06"
"2007.01454","Iz-Iddine EL-Fassi","Iz-iddine EL-Fassi","A new fixed point approach to hyperstability of radical-type functional
  equations in quasi-$(2,\beta)$-Banach spaces",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  The main focus of this paper is to define the notion of
quasi-$(2,\beta)$-Banach space and show some properties in this new space, by
help of it and under some natural assumptions, we prove that the fixed point
theorem [16, Theorem 2.1] is still valid in the setting of
quasi-$(2,\beta)$-Banach spaces, this is also an extension of the fixed point
result of Brzd\k{e}k et al. [12, Theorem 1] in $2$-Banach spaces to
quasi-$(2,\beta)$-Banach spaces. In the next part, we give a general solution
of the radical-type functional equation (1.2). In addition, we study the
hyperstability results for these functional equation by applying the
aforementioned fixed point theorem, and at the end of this paper we will derive
some consequences.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:40:20 GMT""}]","2020-07-06"
"2007.01455","John Leung","John Kalung Leung, Igor Griva, William G. Kennedy","Text-based Emotion Aware Recommender","13 pages, 8 tables, International Conference on Natural Language
  Computing and AI (NLCAI2020) July25-26, London, United Kingdom","David C. Wyld et al. (Eds): CCSEA, BIoT, DKMP, CLOUD, NLCAI, SIPRO
  - 2020 pp. 101-114, 2020","10.5121/csit.2020.101009",,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply the concept of users' emotion vectors (UVECs) and movies' emotion
vectors (MVECs) as building components of Emotion Aware Recommender System. We
built a comparative platform that consists of five recommenders based on
content-based and collaborative filtering algorithms. We employed a Tweets
Affective Classifier to classify movies' emotion profiles through movie
overviews. We construct MVECs from the movie emotion profiles. We track users'
movie watching history to formulate UVECs by taking the average of all the
MVECs from all the movies a user has watched. With the MVECs, we built an
Emotion Aware Recommender as one of the comparative platforms' algorithms. We
evaluated the top-N recommendation lists generated by these Recommenders and
found the top-N list of Emotion Aware Recommender showed serendipity
recommendations.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:43:29 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jul 2020 13:02:01 GMT""}]","2020-07-29"
"2007.01456","Xiuwen Zhang","Pu Huang, Zhiguo Xia, Xiaoqing Gao, James M. Rondinelli, Xiuwen Zhang,
  Han Zhang, Kenneth R. Poeppelmeier, and Alex Zunger","Ferri-chiral compounds with potentially switchable Dresselhaus spin
  split-ting","27 pages, 12 figures","Phys. Rev. B 102, 235127 (2020)","10.1103/PhysRevB.102.235127",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spin splitting of energy bands can be induced by relativistic spin-orbit
interactions in materials without inversion symmetry. Whereas polar space group
symmetries permit Rashba (R-1) spin splitting with helical spin textures in
momentum space, which could be reversed upon switching a ferroelectric
polarization via applied electric fields, the ordinary Dresselhaus effect
(D-1A) is ac-tive only in materials exhibiting nonpolar noncentrosymmetric
crystal classes with atoms occupy-ing exclusively non-polar lattice sites.
Consequently, the spin-momentum locking induced by D-1A is not electric
field-switchable. An alternative type of Dresselhaus symmetry, referred to as
D-1B, exhibits crystal class constraints similar to D-1A (all dipoles add up to
zero), but unlike D-1A, at least one polar site is occupied. We find that this
behavior exists in a class of ferri-chiral crys-tals, which in principle could
be reversed upon a change in chirality. Focusing on alkali metal chalcogenides,
we identify NaCu5S3 in the nonentiamorphic ferri-chiral structure, which
exhibits CuS3 chiral units differing in the magnitude of their Cu
displacements. We then synthesize NaCu5S3 (space group P6322) and confirm its
ferri-chiral structure with power x-ray diffraction. Our electronic structure
calculations demonstrate it exhibits D-1B spin splitting as well as a
ferri-chiral phase transition, revealing spin splitting interdependent on
chirality. Our electronic struc-ture calculations show that a few percent
biaxial tensile strain can reduce (or nearly quench) the switching barrier
separating the monodomain ferri-chiral P6322 states. We discuss what type of
external stimuli might switch the chirality so as to reverse the (non-helical)
Dresselhaus D-1B spin texture, offering an alternative to the traditional
reversal of the (helical) Rashba spin texture.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:46:30 GMT""}]","2021-01-04"
"2007.01457","Hidekazu Yoshioka","H. Yoshioka, M. Tsujimura","A generalized stochastic control problem of bounded noise process under
  ambiguity arising in biological management",,,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The objectives and contributions of this paper are mathematical and numerical
analyses of a stochastic control problem of bounded population dynamics under
ambiguity, an important but not well-studied problem, focusing on the
optimality equation as a nonlinear degenerate parabolic partial
integro-differential equation (PIDE). The ambiguity comes from lack of
knowledge on the continuous and jump noises in the dynamics, and its
optimization appears as nonlinear and nonlocal terms in the PIDE. Assuming a
strong dynamic programming principle for continuous value functions, we
characterize its solutions from both viscosity and distribution viewpoints.
Numerical computation focusing on an ergodic case are presented as well to
complement the mathematical analysis.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:49:18 GMT""}]","2020-07-06"
"2007.01458","Sangheum Hwang","Jooyoung Moon, Jihyo Kim, Younghak Shin, Sangheum Hwang","Confidence-Aware Learning for Deep Neural Networks","ICML 2020. The first two authors contributed equally",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the power of deep neural networks for a wide range of tasks, an
overconfident prediction issue has limited their practical use in many
safety-critical applications. Many recent works have been proposed to mitigate
this issue, but most of them require either additional computational costs in
training and/or inference phases or customized architectures to output
confidence estimates separately. In this paper, we propose a method of training
deep neural networks with a novel loss function, named Correctness Ranking
Loss, which regularizes class probabilities explicitly to be better confidence
estimates in terms of ordinal ranking according to confidence. The proposed
method is easy to implement and can be applied to the existing architectures
without any modification. Also, it has almost the same computational costs for
training as conventional deep classifiers and outputs reliable predictions by a
single inference. Extensive experimental results on classification benchmark
datasets indicate that the proposed method helps networks to produce
well-ranked confidence estimates. We also demonstrate that it is effective for
the tasks closely related to confidence estimation, out-of-distribution
detection and active learning.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:00:35 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 04:56:43 GMT""},{""version"":""v3"",""created"":""Thu, 13 Aug 2020 03:16:37 GMT""}]","2020-08-14"
"2007.01459","Quan-Lin Li","Quan-Lin Li, Yan-Xia Chang, Xiaole Wu and Guoqing Zhang","A New Theoretical Framework of Pyramid Markov Processes for Blockchain
  Selfish Mining","70 pages, 15 figures",,,,"cs.CR cs.DC cs.PF math.DS math.PR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we provide a new theoretical framework of pyramid Markov
processes to solve some open and fundamental problems of blockchain selfish
mining under a rigorous mathematical setting. We first describe a more general
model of blockchain selfish mining with both a two-block leading competitive
criterion and a new economic incentive mechanism. Then we establish a pyramid
Markov process and show that it is irreducible and positive recurrent, and its
stationary probability vector is matrix-geometric with an explicitly
representable rate matrix. Also, we use the stationary probability vector to
study the influence of many orphan blocks on the waste of computing resource.
Next, we set up a pyramid Markov reward process to investigate the long-run
average profits of the honest and dishonest mining pools, respectively. As a
by-product, we build three approximative Markov processes and provide some new
interesting interpretation on the Markov chain and the revenue analysis
reported in the seminal work by Eyal and Sirer (2014). Note that the pyramid
Markov (reward) processes can open up a new avenue in the study of blockchain
selfish mining. Thus we hope that the methodology and results developed in this
paper shed light on the blockchain selfish mining such that a series of
promising research can be developed potentially.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:02:35 GMT""},{""version"":""v2"",""created"":""Mon, 19 Oct 2020 16:58:57 GMT""},{""version"":""v3"",""created"":""Sat, 4 Sep 2021 12:15:39 GMT""},{""version"":""v4"",""created"":""Sun, 12 Sep 2021 07:44:56 GMT""}]","2021-09-14"
"2007.01460","Jingjun Guo","Cuiyun Zhang, Jingjun Guo, Aiqin Ma, Bo Peng","Least Squares Estimator for Vasicek Model Driven by Sub-fractional
  Brownian Processes from Discrete Observations",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the parameter estimation problem of Vasicek Model driven by
sub-fractional Brownian processes from discrete observations, and let
{S_t^H,t>=0} denote a sub-fractional Brownian motion whose Hurst parameter
1/2<H<1 . The studies are as follows: firstly, two unknown parameters in the
model are estimated by the least squares method. Secondly, the strong
consistency and the asymptotic distribution of the estimators are studied
respectively. Finally, our estimators are validated by numerical simulation.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:05:53 GMT""}]","2020-07-06"
"2007.01461","Hai-Liang Li","Hai-Liang Li, Tong Yang, Mingying Zhong","Diffusion Limit of the Vlasov-Poisson-Boltzmann System",,,"10.1007/s00205-021-01652-5",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper, we study the diffusion limit of the classical solution
to the unipolar Vlasov-Poisson-Boltzmann (VPB) system with initial data near a
global Maxwellian. We prove the convergence and establish the convergence rate
of the global strong solution to the unipolar VPB system towards the solution
to an incompressible Navier-Stokes-Poisson-Fourier system based on the spectral
analysis with precise estimation on the initial layer.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:24:02 GMT""}]","2021-06-09"
"2007.01462","Shaolin Liao Dr.","Shaolin Liao and Lu Ou","Rigorous Quantum Formulation of Parity-Time Symmetric Coupled Resonators","10 pages, 2 figures, preprint of a paper submitted to PIER B
  (http://www.jpier.org/PIERB/), July 2, 2020",,,,"eess.SY cs.SY physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rigorous quantum formulation of the Parity-Time (PT) symmetry phenomenon in
the RF/microwave regime for a coupled coil resonators with lump elements has
been presented. The coil resonator is described by the lump-element model that
consists of an inductor (L), a resistor (R) and a capacitor (C). Rigorous
quantum Hamiltonian for the coupled LRC coil resonators system has been derived
through twice basis transforms of the original basis. The first basis transform
rotates the original basis such that off-diagonal terms of the governing matrix
of the equation system of the coupled coil resonators reduces to constants.
Then a second basis transform obtains the quantum Hamiltonian, including the
diagonal effective complex frequencies and the off-diagonal coupling terms,
together with the transformed basis. With the obtain quantum Hamiltonian, the
eigenvalues and eigenvectors of the coupled coil resonators can be obtained as
usual as the quantum Hamiltonian. Finally, numerical simulation verifies the
correctness of the theory. The quantum formulation of the coupled coil
resonators can provide better guideline to design a better PT-symmetric system.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:28:50 GMT""}]","2020-07-06"
"2007.01463","Yanting Chen","Yanting Chen, Jingui Xie, Taozeng Zhu","Flexibility in an asymmetric system with prolonged service time at
  non-dedicated servers","8 pages, 2 figures",,,,"cs.PF math.OC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The prolonged service time at non-dedicated servers has been observed in [1].
Motivated by such real problems, we propose a stylized model which
characterizes the feature of the prolonged service time at non-dedicated
servers in an asymmetric system. We study the independent system, the full
flexibility system and the partial flexibility system when the occupation rate
of the system, the degree of the prolonged service time and the degree of the
asymmetry are allowed to change. We show that under certain circumstances, the
partial flexibility scheme outperforms the full flexibility system and the
independent system in such a model. Our results also provide instructions on
how to introduce flexibility when the service time at non-dedicated servers is
prolonged in an asymmetric system.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:31:09 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 06:49:22 GMT""}]","2021-03-02"
"2007.01464","Yirui Wang","Haomin Chen, Yirui Wang, Kang Zheng, Weijian Li, Chi-Tung Cheng, Adam
  P. Harrison, Jing Xiao, Gregory D. Hager, Le Lu, Chien-Hung Liao, Shun Miao","Anatomy-Aware Siamese Network: Exploiting Semantic Asymmetry for
  Accurate Pelvic Fracture Detection in X-ray Images","ECCV 2020 (camera-ready)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual cues of enforcing bilaterally symmetric anatomies as normal findings
are widely used in clinical practice to disambiguate subtle abnormalities from
medical images. So far, inadequate research attention has been received on
effectively emulating this practice in CAD methods. In this work, we exploit
semantic anatomical symmetry or asymmetry analysis in a complex CAD scenario,
i.e., anterior pelvic fracture detection in trauma PXRs, where semantically
pathological (refer to as fracture) and non-pathological (e.g., pose)
asymmetries both occur. Visually subtle yet pathologically critical fracture
sites can be missed even by experienced clinicians, when limited diagnosis time
is permitted in emergency care. We propose a novel fracture detection framework
that builds upon a Siamese network enhanced with a spatial transformer layer to
holistically analyze symmetric image features. Image features are spatially
formatted to encode bilaterally symmetric anatomies. A new contrastive feature
learning component in our Siamese network is designed to optimize the deep
image features being more salient corresponding to the underlying semantic
asymmetries (caused by pelvic fracture occurrences). Our proposed method have
been extensively evaluated on 2,359 PXRs from unique patients (the largest
study to-date), and report an area under ROC curve score of 0.9771. This is the
highest among state-of-the-art fracture detection methods, with improved
clinical indications.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:33:24 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jul 2020 04:04:28 GMT""},{""version"":""v3"",""created"":""Thu, 23 Jul 2020 14:30:38 GMT""}]","2020-07-24"
"2007.01465","Ghasem Pasandi","Ghasem Pasandi and Mackenzie Peterson and Moises Herrera and Shahin
  Nazarian and Massoud Pedram","Deep-PowerX: A Deep Learning-Based Framework for Low-Power Approximate
  Logic Synthesis",,,"10.1145/3370748.3406555",,"cs.AR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper aims at integrating three powerful techniques namely Deep
Learning, Approximate Computing, and Low Power Design into a strategy to
optimize logic at the synthesis level. We utilize advances in deep learning to
guide an approximate logic synthesis engine to minimize the dynamic power
consumption of a given digital CMOS circuit, subject to a predetermined error
rate at the primary outputs. Our framework, Deep-PowerX, focuses on replacing
or removing gates on a technology-mapped network and uses a Deep Neural Network
(DNN) to predict error rates at primary outputs of the circuit when a specific
part of the netlist is approximated. The primary goal of Deep-PowerX is to
reduce the dynamic power whereas area reduction serves as a secondary
objective. Using the said DNN, Deep-PowerX is able to reduce the exponential
time complexity of standard approximate logic synthesis to linear time.
Experiments are done on numerous open source benchmark circuits. Results show
significant reduction in power and area by up to 1.47 times and 1.43 times
compared to exact solutions and by up to 22% and 27% compared to
state-of-the-art approximate logic synthesis tools while having orders of
magnitudes lower run-time.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:47:58 GMT""}]","2020-07-06"
"2007.01466","Meng Cao","Meng Cao, Haozhi Huang, Hao Wang, Xuan Wang, Li Shen, Sheng Wang,
  Linchao Bao, Zhifeng Li, Jiebo Luo","Task-agnostic Temporally Consistent Facial Video Editing",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent research has witnessed the advances in facial image editing tasks. For
video editing, however, previous methods either simply apply transformations
frame by frame or utilize multiple frames in a concatenated or iterative
fashion, which leads to noticeable visual flickers. In addition, these methods
are confined to dealing with one specific task at a time without any
extensibility. In this paper, we propose a task-agnostic temporally consistent
facial video editing framework. Based on a 3D reconstruction model, our
framework is designed to handle several editing tasks in a more unified and
disentangled manner. The core design includes a dynamic training sample
selection mechanism and a novel 3D temporal loss constraint that fully exploits
both image and video datasets and enforces temporal consistency. Compared with
the state-of-the-art facial image editing methods, our framework generates
video portraits that are more photo-realistic and temporally smooth.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:49:20 GMT""}]","2020-07-06"
"2007.01467","Koichi Miyamoto","Kazuya Kaneko, Koichi Miyamoto, Naoyuki Takeda, Kazuyoshi Yoshino","Quantum Pricing with a Smile: Implementation of Local Volatility Model
  on Quantum Computer","29 pages, 13 Figures",,,,"quant-ph q-fin.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Applications of the quantum algorithm for Monte Carlo simulation to pricing
of financial derivatives have been discussed in previous papers. However, up to
now, the pricing model discussed in such papers is Black-Scholes model, which
is important but simple. Therefore, it is motivating to consider how to
implement more complex models used in practice in financial institutions. In
this paper, we then consider the local volatility (LV) model, in which the
volatility of the underlying asset price depends on the price and time. We
present two types of implementation. One is the register-per-RN way, which is
adopted in most of previous papers. In this way, each of random numbers (RNs)
required to generate a path of the asset price is generated on a separated
register, so the required qubit number increases in proportion to the number of
RNs. The other is the PRN-on-a-register way, which is proposed in the author's
previous work. In this way, a sequence of pseudo-random numbers (PRNs)
generated on a register is used to generate paths of the asset price, so the
required qubit number is reduced with a trade-off against circuit depth. We
present circuit diagrams for these two implementations in detail and estimate
required resources: qubit number and T-count.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:54:25 GMT""}]","2020-07-06"
"2007.01468","Zhijie Fan","Zhijie Fan","Weak type $(p,p)$ bounds for Schr\""odinger groups via generalized
  Gaussian estimates","17 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $L$ be a non-negative self-adjoint operator acting on $L^2(X)$, where $X$
is a space of homogeneous type with a dimension $n$. Suppose that the heat
operator $e^{-tL}$ satisfies the generalized Gaussian $(p_0, p'_0)$-estimates
of order $m$ for some $1\leq p_0 < 2$. It is known that the operator $(I+L)^{-s
} e^{itL}$ is bounded on $L^p(X)$ for $s\geq n|{1/ 2}-{1/p}| $ and $ p\in (p_0,
p_0')$ (see for example, \cite{Blunck2, BDN, CCO, CDLY, DN, Mi1}). In this
paper we study the endpoint case $p=p_0$ and show that for $s_0= n\big|{1\over
2}-{1\over p_0}\big|$, the operator $(I+L)^{-{s_0}}e^{itL} $ is of weak type
$(p_{0},p_{0})$, that is, there is a constant $C>0$, independent of $t$ and $f$
so that \begin{eqnarray*} \mu\left(\left\{x: \big|(I+L)^{-s_0}e^{itL}
f(x)\big|>\alpha \right\} \right)\leq C (1+|t|)^{n(1 - {p_0\over 2}) } \left(
{\|f\|_{p_0} \over \alpha} \right)^{p_0} , \ \ \ t\in{\mathbb R}
\end{eqnarray*} for $\alpha>0$ when $\mu(X)=\infty$, and
$\alpha>\big(\|f\|_{p_{0}}/\mu(X) \big)^{p_{0}}$ when $\mu(X)<\infty$. Our
results can be applied to Schr\""odinger operators with rough potentials and
%second order elliptic operators with rough lower order terms, or higher order
elliptic operators with bounded measurable coefficients although in general,
their semigroups fail to satisfy Gaussian upper bounds.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 02:55:54 GMT""}]","2020-07-06"
"2007.01469","Zhijie Fan","Peng Chen, Xuan Thinh Duong, Zhijie Fan, Ji Li, Lixin Yan","The Schr\""odinger equation in $L^p$ spaces for operators with heat
  kernel satisfying Poisson type bounds","Fix a gap in the previous version",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $L$ be a non-negative self-adjoint operator acting on $L^2(X)$ where $X$
is a space of homogeneous type with a dimension $n$. In this paper, we study
sharp endpoint $L^p$-Sobolev estimates for the solution of the initial value
problem for the Schr\""odinger equation, $i \partial_t u + L u=0 $ and show that
for all $f\in L^p(X), 1<p<\infty,$
  \begin{eqnarray*}
  \left\| e^{itL} (I+L)^{-{\sigma n}} f\right\|_{p} \leq C(1+|t|)^{\sigma n}
\|f\|_{p},
  \ \ \ t\in{\mathbb R}, \ \ \ \sigma\geq \big|{1\over 2}-{1\over p}\big|,
\end{eqnarray*} where the semigroup $e^{-tL}$ generated by $L$ satisfies a
Poisson type upper bound. This extends the previous result in \cite{CDLY1} in
which the semigroup $e^{-tL}$ generated by $L$ satisfies the exponential decay.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:01:13 GMT""},{""version"":""v2"",""created"":""Fri, 15 Apr 2022 14:11:05 GMT""}]","2022-04-18"
"2007.01470","Olivia Di Matteo","Olivia Di Matteo, John Gamble, Chris Granade, Kenneth Rudinger, Nathan
  Wiebe","Operational, gauge-free quantum tomography","27 pages, 11 figures. To appear in Quantum","Quantum 4, 364 (2020)","10.22331/q-2020-11-17-364",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  As increasingly impressive quantum information processors are realized in
laboratories around the world, robust and reliable characterization of these
devices is now more urgent than ever. These diagnostics can take many forms,
but one of the most popular categories is tomography, where an underlying
parameterized model is proposed for a device and inferred by experiments. Here,
we introduce and implement efficient operational tomography, which uses
experimental observables as these model parameters. This addresses a problem of
ambiguity in representation that arises in current tomographic approaches (the
gauge problem). Solving the gauge problem enables us to efficiently implement
operational tomography in a Bayesian framework computationally, and hence gives
us a natural way to include prior information and discuss uncertainty in fit
parameters. We demonstrate this new tomography in a variety of different
experimentally-relevant scenarios, including standard process tomography,
Ramsey interferometry, randomized benchmarking, and gate set tomography.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:02:34 GMT""},{""version"":""v2"",""created"":""Fri, 13 Nov 2020 14:05:40 GMT""}]","2020-11-18"
"2007.01471","Zhanjing Tao","Zhanjing Tao, Juntao Huang, Yuan Liu, Wei Guo, Yingda Cheng","An adaptive multiresolution ultra-weak discontinuous Galerkin method for
  nonlinear Schrodinger equations",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops a high order adaptive scheme for solving nonlinear
Schrodinger equations. The solutions to such equations often exhibit solitary
wave and local structures, which makes adaptivity essential in improving the
simulation efficiency. Our scheme uses the ultra-weak discontinuous Galerkin
(DG) formulation and belongs to the framework of adaptive multiresolution
schemes. Various numerical experiments are presented to demonstrate the
excellent capability of capturing the soliton waves and the blow-up phenomenon.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:02:50 GMT""}]","2020-07-06"
"2007.01472","Zhihui Shao","Zhihui Shao, and Jianyi Yang, and Shaolei Ren","Increasing Trustworthiness of Deep Neural Networks via Accuracy
  Monitoring","Accepted by the AISafety workshop co-located with IJCAI-PRICAI 2020",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Inference accuracy of deep neural networks (DNNs) is a crucial performance
metric, but can vary greatly in practice subject to actual test datasets and is
typically unknown due to the lack of ground truth labels. This has raised
significant concerns with trustworthiness of DNNs, especially in
safety-critical applications. In this paper, we address trustworthiness of DNNs
by using post-hoc processing to monitor the true inference accuracy on a user's
dataset. Concretely, we propose a neural network-based accuracy monitor model,
which only takes the deployed DNN's softmax probability output as its input and
directly predicts if the DNN's prediction result is correct or not, thus
leading to an estimate of the true inference accuracy. The accuracy monitor
model can be pre-trained on a dataset relevant to the target application of
interest, and only needs to actively label a small portion (1% in our
experiments) of the user's dataset for model transfer. For estimation
robustness, we further employ an ensemble of monitor models based on the
Monte-Carlo dropout method. We evaluate our approach on different deployed DNN
models for image classification and traffic sign detection over multiple
datasets (including adversarial samples). The result shows that our accuracy
monitor model provides a close-to-true accuracy estimation and outperforms the
existing baseline methods.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:09:36 GMT""}]","2020-07-06"
"2007.01473","Luca Rizzi","Luca Rizzi, Francesco Zucconi","Fujita decomposition and Massey product for fibered varieties","29 pages",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $f\colon X\to B$ be a semistable fibration where $X$ is a smooth variety
of dimension $n\geq 2$ and $B$ is a smooth curve. We give the structure theorem
for the local system of the relative $1$-forms and of the relative top forms.
This gives a neat interpretation of the second Fujita decomposition of
$f_*\omega_{X/B}$. We apply our interpretation to show the existence, up to
base change, of higher irrational pencils and on the finiteness of the
associated monodromy representations under natural Castelnuovo-type hypothesis
on local subsystems. Finally we give a criterion to have that $X$ is not of
Albanese general type if $B=\mathbb{P}^1$.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:10:09 GMT""}]","2020-07-06"
"2007.01474","Mansoor Ur Rehman","George Lazarides, Mansoor Ur Rehman, Qaisar Shafi and Fariha K. Vardag","Shifted $\mu$-hybrid inflation, gravitino dark matter, and observable
  gravity waves","14 pages, 9 figures; version published in Phys. Rev. D","Phys. Rev. D 103, 035033 (2021)","10.1103/PhysRevD.103.035033",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate supersymmetric hybrid inflation in a realistic model based on
the gauge symmetry $SU(4)_c \times SU(2)_L \times SU(2)_R$. The minimal
supersymmetric standard model (MSSM) $\mu$ term arises, following Dvali,
Lazarides, and Shafi, from the coupling of the MSSM electroweak doublets to a
gauge singlet superfield which plays an essential role in inflation. The
primordial monopoles are inflated away by arranging that the $SU(4)_c \times
SU(2)_L \times SU(2)_R$ symmetry is broken along the inflationary trajectory.
The interplay between the (above) $\mu$ coupling, the gravitino mass, and the
reheating following inflation is discussed in detail. We explore regions of the
parameter space that yield gravitino dark matter and observable gravity waves
with the tensor-to-scalar ratio $r \sim 10^{-4}-10^{-3}$.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:11:48 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 09:23:47 GMT""}]","2021-03-09"
"2007.01475","Xinjing Cheng","Xinjing Cheng, Peng Wang, Yanqi Zhou, Chenye Guan and Ruigang Yang","ODE-CNN: Omnidirectional Depth Extension Networks","Accepted by ICRA 2020, 7 pages, 5 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Omnidirectional 360{\deg} camera proliferates rapidly for autonomous robots
since it significantly enhances the perception ability by widening the field of
view(FoV). However, corresponding 360{\deg} depth sensors, which are also
critical for the perception system, are still difficult or expensive to have.
In this paper, we propose a low-cost 3D sensing system that combines an
omnidirectional camera with a calibrated projective depth camera, where the
depth from the limited FoV can be automatically extended to the rest of the
recorded omnidirectional image. To accurately recover the missing depths, we
design an omnidirectional depth extension convolutional neural
network(ODE-CNN), in which a spherical feature transform layer(SFTL) is
embedded at the end of feature encoding layers, and a deformable convolutional
spatial propagation network(D-CSPN) is appended at the end of feature decoding
layers. The former resamples the neighborhood of each pixel in the
omnidirectional coordination to the projective coordination, which reduces the
difficulty of feature learning, and the later automatically finds a proper
context to well align the structures in the estimated depths via CNN w.r.t. the
reference image, which significantly improves the visual quality. Finally, we
demonstrate the effectiveness of proposed ODE-CNN over the popular 360D dataset
and show that ODE-CNN significantly outperforms (relatively 33% reduction
in-depth error) other state-of-the-art (SoTA) methods.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:14:09 GMT""}]","2020-07-06"
"2007.01476","Shipeng Fu","Shipeng Fu, Zhen Li, Jun Xu, Ming-Ming Cheng, Zitao Liu, Xiaomin Yang","Interactive Knowledge Distillation","This work (IAKD) and BERT-of-Theseus (see arXiv:2002.02925) are
  concurrent works. IAKD was first submitted to CVPR2020 and now is accepted in
  Neurocomputing. Thank the authors in BERT-of-Theseus for pointing out this
  issue",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge distillation is a standard teacher-student learning framework to
train a light-weight student network under the guidance of a well-trained large
teacher network. As an effective teaching strategy, interactive teaching has
been widely employed at school to motivate students, in which teachers not only
provide knowledge but also give constructive feedback to students upon their
responses, to improve their learning performance. In this work, we propose an
InterActive Knowledge Distillation (IAKD) scheme to leverage the interactive
teaching strategy for efficient knowledge distillation. In the distillation
process, the interaction between teacher and student networks is implemented by
a swapping-in operation: randomly replacing the blocks in the student network
with the corresponding blocks in the teacher network. In the way, we directly
involve the teacher's powerful feature transformation ability to largely boost
the student's performance. Experiments with typical settings of teacher-student
networks demonstrate that the student networks trained by our IAKD achieve
better performance than those trained by conventional knowledge distillation
methods on diverse image classification datasets.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:22:04 GMT""},{""version"":""v2"",""created"":""Wed, 26 Aug 2020 07:30:36 GMT""},{""version"":""v3"",""created"":""Thu, 15 Apr 2021 07:21:43 GMT""}]","2021-04-16"
"2007.01477","Agustina Czenky","Agustina Czenky, Julia Plavnik","On odd-dimensional modular tensor categories","Some sections have been reorganized. Correction on Proposition 3.8",,,,"math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study odd-dimensional modular tensor categories and maximally non-self
dual (MNSD) modular tensor categories of low rank. We give lower bounds for the
ranks of modular tensor categories in terms of the rank of the adjoint
subcategory and the order of the group of invertible objects. As an application
of these results, we prove that MNSD modular tensor categories of ranks 13 and
15 are pointed. In addition, we show that MNSD tensor categories of ranks 17,
19, 21 and 23 are either pointed or perfect.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:27:08 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 19:47:32 GMT""},{""version"":""v3"",""created"":""Wed, 29 Dec 2021 16:34:04 GMT""},{""version"":""v4"",""created"":""Tue, 23 May 2023 22:25:59 GMT""}]","2023-05-25"
"2007.01478","Yongyi Guo","Yongyi Guo, Ziwei Zhu, Jianqing Fan","Best subset selection is robust against design dependence","47 pages, 3 figures, 6 tables",,,,"stat.ME math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Best subset selection (BSS) is widely known as the holy grail for
high-dimensional variable selection. Nevertheless, the notorious NP-hardness of
BSS substantially restricts its practical application and also discourages its
theoretical development to some extent, particularly in the current era of big
data. In this paper, we investigate the variable selection properties of BSS
when its target sparsity is greater than or equal to the true sparsity. Our
main message is that BSS is robust against design dependence in terms of
achieving model consistency and sure screening, and more importantly, that such
robustness can be propagated to the near best subsets that are computationally
tangible. Specifically, we introduce an identifiability margin condition that
is free of restricted eigenvalues and show that it is sufficient and nearly
necessary for BSS to exactly recover the true model. A relaxed version of this
condition is also sufficient for BSS to achieve the sure screening property.
Moreover, taking optimization error into account, we find that all the
established statistical properties for the exact best subset carry over to any
near best subset whose residual sum of squares is close enough to that of the
best one. In particular, a two-stage fully corrective iterative hard
thresholding (IHT) algorithm can provably find a sparse sure screening subset
within logarithmic steps; another round of exact BSS within this set can
recover the true model. The simulation studies and real data examples show that
IHT yields lower false discovery rates and higher true positive rates than the
competing approaches including LASSO, SCAD and Sure Independence Screening
(SIS), especially under highly correlated design.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:32:02 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 17:07:10 GMT""}]","2021-08-27"
"2007.01479","Yuchen Yue","Y. Yue, C. A. R. S\'a de Melo and I. B. Spielman","Enhanced transport of spin-orbit coupled Bose gases in disordered
  potentials","12 pages, 7 figures","Phys. Rev. A 102, 033325 (2020)","10.1103/PhysRevA.102.033325",,"cond-mat.quant-gas physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anderson localization is a single particle localization phenomena in
disordered media that is accompanied by an absence of diffusion. Spin-orbit
coupling (SOC) describes an interaction between a particle's spin and its
momentum that directly affects its energy dispersion, for example creating
dispersion relations with gaps and multiple local minima. We show theoretically
that combining one-dimensional spin-orbit coupling with a transverse Zeeman
field suppresses the effects of disorder, thereby increasing the localization
length and conductivity. This increase results from a suppression of back
scattering between states in the gap of the SOC dispersion relation. Here, we
focus specifically on the interplay of disorder from an optical speckle
potential and SOC generated by two-photon Raman processes in quasi-1D
Bose-Einstein condensates. We first describe back-scattering using a Fermi's
golden rule approach, and then numerically confirm this picture by solving the
time-dependent 1D Gross Pitaevskii equation for a weakly interacting
Bose-Einstein condensate with SOC and disorder. We find that on the 10's of
millisecond time scale of typical cold atom experiments moving in harmonic
traps, initial states with momentum in the zero-momentum SOC gap evolve with
negligible back-scattering, while without SOC these same states rapidly
localize.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:34:11 GMT""}]","2020-09-23"
"2007.01480","Chih-Hsing Ho","Chih-Hsing Ho, Shang-Ho (Lawrence) Tsai","RSAC: Regularized Subspace Approximation Classifier for Lightweight
  Continuous Learning",,,,,"cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous learning seeks to perform the learning on the data that arrives
from time to time. While prior works have demonstrated several possible
solutions, these approaches require excessive training time as well as memory
usage. This is impractical for applications where time and storage are
constrained, such as edge computing. In this work, a novel training algorithm,
regularized subspace approximation classifier (RSAC), is proposed to achieve
lightweight continuous learning. RSAC contains a feature reduction module and
classifier module with regularization. Extensive experiments show that RSAC is
more efficient than prior continuous learning works and outperforms these works
on various experimental settings.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:38:06 GMT""}]","2020-07-06"
"2007.01481","Mark J. Kilgard","Mark J. Kilgard","Ordinary Facet Angles of a Stroked Path Tessellated by Uniform Tangent
  Angle Steps Are Bounded by Twice the Step Angle","9 pages, supplemental paper for ""Polar Stroking: New Theory and
  Methods for Stroking Paths"" (SIGGRAPH 2020) arXiv:2007.00308",,,,"cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explain geometrically why ordinary facet angles of a stroked path
tessellated from uniform tangent angle steps are bounded by twice the step
angle. This fact means---excluding a small number of extraordinary facet angles
straddling offset cusps---our polar stroking method bounds the facet angle size
to less than $2 \theta$ where $\theta$ is the tangent step angle.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:38:24 GMT""}]","2020-07-06"
"2007.01482","Yang Liu","Yang Liu, Jun Zhao, Ming Li, Qingqing Wu","Intelligent Reflecting Surface Aided MISO Uplink Communication Network:
  Feasibility and Power Minimization for Perfect and Imperfect CSI","updated version",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the weighted sum-power minimization under
quality-of-service (QoS) constraints in the multi-user
multi-input-single-output (MISO) uplink wireless network assisted by
intelligent reflecting surface (IRS). We perform a comprehensive investigation
on various aspects of this problem. First, when users have sufficient transmit
powers, we present a new sufficient condition guaranteeing arbitrary
information rate constraints. This result strengthens the feasibility condition
in existing literature. Then, we design novel penalty dual decomposition (PDD)
based and nonlinear equality constrained alternative direction method of
multipliers (neADMM) based solutions to tackle the
IRS-dependent-QoS-constraints, which effectively solve the feasibility check
and power minimization problems. Besides, we further extend our proposals to
the cases where channel status information (CSI) is imperfect and develop an
online stochastic algorithm that satisfy QoS constraints stochastically without
requiring prior knowledge of CSI errors. Extensive numerical results are
presented to verify the effectiveness of our proposed algorithms.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:40:12 GMT""},{""version"":""v2"",""created"":""Sun, 27 Dec 2020 12:44:05 GMT""}]","2020-12-29"
"2007.01483","Lin Jiarong","Jiarong Lin, Xiyuan Liu and Fu Zhang","A decentralized framework for simultaneous calibration, localization and
  mapping with multiple LiDARs","Accepted by IROS2020",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  LiDAR is playing a more and more essential role in autonomous driving
vehicles for objection detection, self localization and mapping. A single LiDAR
frequently suffers from hardware failure (e.g., temporary loss of connection)
due to the harsh vehicle environment (e.g., temperature, vibration, etc.), or
performance degradation due to the lack of sufficient geometry features,
especially for solid-state LiDARs with small field of view (FoV). To improve
the system robustness and performance in self-localization and mapping, we
develop a decentralized framework for simultaneous calibration, localization
and mapping with multiple LiDARs. Our proposed framework is based on an
extended Kalman filter (EKF), but is specially formulated for decentralized
implementation. Such an implementation could potentially distribute the
intensive computation among smaller computing devices or resources dedicated
for each LiDAR and remove the single point of failure problem. Then this
decentralized formulation is implemented on an unmanned ground vehicle (UGV)
carrying 5 low-cost LiDARs and moving at $1.3m/s$ in urban environments.
Experiment results show that the proposed method can successfully and
simultaneously estimate the vehicle state (i.e., pose and velocity) and all
LiDAR extrinsic parameters. The localization accuracy is up to 0.2% on the two
datasets we collected. To share our findings and to make contributions to the
community, meanwhile enable the readers to verify our work, we will release all
our source codes and hardware design blueprint on our Github.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:42:26 GMT""}]","2020-07-06"
"2007.01484","Yanxun Xu","Yuliang Li, Yang Ni, Leah H. Rubin, Amanda B. Spence, Yanxun Xu","BAGEL: A Bayesian Graphical Model for Inferring Drug Effect
  Longitudinally on Depression in People with HIV",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Access and adherence to antiretroviral therapy (ART) has transformed the face
of HIV infection from a fatal to a chronic disease. However, ART is also known
for its side effects. Studies have reported that ART is associated with
depressive symptomatology. Large-scale HIV clinical databases with individuals'
longitudinal depression records, ART medications, and clinical characteristics
offer researchers unprecedented opportunities to study the effects of ART drugs
on depression over time. We develop BAGEL, a Bayesian graphical model to
investigate longitudinal effects of ART drugs on a range of depressive symptoms
while adjusting for participants' demographic, behavior, and clinical
characteristics, and taking into account the heterogeneous population through a
Bayesian nonparametric prior. We evaluate BAGEL through simulation studies.
Application to a dataset from the Women's Interagency HIV Study yields
interpretable and clinically useful results. BAGEL not only can improve our
understanding of ART drugs effects on disparate depression symptoms, but also
has clinical utility in guiding informed and effective treatment selection to
facilitate precision medicine in HIV.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:44:58 GMT""}]","2020-07-06"
"2007.01485","Jacob Priddle","Jacob W. Priddle, and Christopher Drovandi","Transformations in Semi-Parametric Bayesian Synthetic Likelihood",,,,,"stat.CO stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian synthetic likelihood (BSL) is a popular method for performing
approximate Bayesian inference when the likelihood function is intractable. In
synthetic likelihood methods, the likelihood function is approximated
parametrically via model simulations, and then standard likelihood-based
techniques are used to perform inference. The Gaussian synthetic likelihood
estimator has become ubiquitous in BSL literature, primarily for its simplicity
and ease of implementation. However, it is often too restrictive and may lead
to poor posterior approximations. Recently, a more flexible semi-parametric
Bayesian synthetic likelihood (semiBSL) estimator has been introduced, which is
significantly more robust to irregularly distributed summary statistics. In
this work, we propose a number of extensions to semiBSL. First, we consider
even more flexible estimators of the marginal distributions using
transformation kernel density estimation. Second, we propose whitening semiBSL
(wsemiBSL) -- a method to significantly improve the computational efficiency of
semiBSL. wsemiBSL uses an approximate whitening transformation to decorrelate
summary statistics at each algorithm iteration. The methods developed herein
significantly improve the versatility and efficiency of BSL algorithms.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 03:58:53 GMT""}]","2020-07-06"
"2007.01486","Shibo Shen","Shibo Shen, Rongpeng Li, Zhifeng Zhao, Honggang Zhang, Yugeng Zhou","Learning to Prune in Training via Dynamic Channel Propagation","accepted by ICPR-2020",,,,"cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel network training mechanism called ""dynamic
channel propagation"" to prune the neural networks during the training period.
In particular, we pick up a specific group of channels in each convolutional
layer to participate in the forward propagation in training time according to
the significance level of channel, which is defined as channel utility. The
utility values with respect to all selected channels are updated simultaneously
with the error back-propagation process and will adaptively change.
Furthermore, when the training ends, channels with high utility values are
retained whereas those with low utility values are discarded. Hence, our
proposed scheme trains and prunes neural networks simultaneously. We
empirically evaluate our novel training scheme on various representative
benchmark datasets and advanced convolutional neural network (CNN)
architectures, including VGGNet and ResNet. The experiment results verify the
superior performance and robust effectiveness of our approach.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:02:41 GMT""}]","2020-07-06"
"2007.01487","Armen Tokadjian","Armen Tokadjian, Anthony L. Piro","Impact of Tides on the Potential for Exoplanets to Host Exomoons","13 pages, 13 figures, updated with minor changes to match version
  accepted for publication in AJ",,"10.3847/1538-3881/abb29e",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exomoons may play an important role in determining the habitability of worlds
outside of our solar system. They can stabilize conditions, alter the climate
by breaking tidal locking with the parent star, drive tidal heating, and
perhaps even host life themselves. However, the ability of an exoplanet to
sustain an exomoon depends on complex tidal interactions. Motivated by this, we
make use of simplified tidal lag models to follow the evolution of the
separations and orbital and rotational periods in planet, star, and moon
systems. We apply these models to known exoplanet systems to assess the
potential for these exoplanets to host exomoons. We find that there are at
least 36 systems in which an exoplanet in the habitable zone may host an
exomoon for longer than one gigayear. This includes Kepler-1625b, an exoplanet
with an exomoon candidate, which we determine would be able to retain a
Neptune-sized moon for longer than a Hubble time. These results may help
provide potential targets for future observation. In many cases, there remains
considerable uncertainty in the composition of specific exoplanets. We show the
detection (or not) of an exomoon would provide an important constraint on the
planet structure due to differences in their tidal response.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:04:11 GMT""},{""version"":""v2"",""created"":""Wed, 26 Aug 2020 03:53:58 GMT""}]","2020-10-14"
"2007.01488","Jianing Li","Jianing Li, Yanyan Lan, Jiafeng Guo, Xueqi Cheng","On the Relation between Quality-Diversity Evaluation and
  Distribution-Fitting Goal in Text Generation","16 pages, 7 figures. ICML2020 Final Submission",,,,"cs.LG cs.CL stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of text generation models is to fit the underlying real probability
distribution of text. For performance evaluation, quality and diversity metrics
are usually applied. However, it is still not clear to what extend can the
quality-diversity evaluation reflect the distribution-fitting goal. In this
paper, we try to reveal such relation in a theoretical approach. We prove that
under certain conditions, a linear combination of quality and diversity
constitutes a divergence metric between the generated distribution and the real
distribution. We also show that the commonly used BLEU/Self-BLEU metric pair
fails to match any divergence metric, thus propose CR/NRR as a substitute for
quality/diversity metric pair.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:06:59 GMT""},{""version"":""v2"",""created"":""Wed, 19 Aug 2020 03:37:59 GMT""}]","2020-08-20"
"2007.01489","Atsuki Yoshinaga","Atsuki Yoshinaga","Ballistic propagation of a local impact in the one-dimensional $XY$
  model","29 pages, 9 figures; version 4: typos collected. Published in J.
  Stat. Mech","J. Stat. Mech. (2021) 013103","10.1088/1742-5468/abcd37",,"cond-mat.str-el cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Light-cone-like propagation of information is a universal phenomenon of
nonequilibrium dynamics of integrable spin systems. In this paper, we
investigate propagation of a local impact in the one-dimensional $XY$ model
with the anisotropy $\gamma$ in a magnetic field $h$ by calculating the
magnetization profile. Applying a local and instantaneous unitary operation to
the ground state, which we refer to as the local-impact protocol, we
numerically observe various types of light-cone-like propagation in the
parameter region $0\leq\gamma\leq1$ and $0\leq h \leq2$ of the model. By
combining numerical integration with an asymptotic analysis, we find the
following: (i) for $|h|\geq|1-\gamma^{2}|$ except for the case on the line
$h=1$ with $0<\gamma<\sqrt{3}/2$, a wave front propagates with the maximum
group velocity of quasiparticles, except for the case $\gamma=1$ and $0<h<1$,
in which there is no clear wave front; (ii) for $|h|<|1-\gamma^{2}|$ as well as
on the line $h=1$ with $0<\gamma<\sqrt{3}/2$, a second wave front appears owing
to multiple local extrema of the group velocity; (iii) for
$|h|=|1-\gamma^{2}|$, edges of the second wave front collapses at the origin,
and as a result, the magnetization profile exhibits a ridge at the impacted
site. Furthermore, we find by an asymptotic analysis that the height of the
wave front decays in a power law in time $t$ with various exponents depending
on the model parameters: the wave fronts exhibit a power-law decay $t^{-2/3}$
except for the line $h=1$, on which the decay can be given by either $\sim
t^{-3/5}$ or $\sim t^{-1}$; the ridge at the impacted site for
$|h|=|1-\gamma^{2}|$ shows the decay $t^{-1/2}$ as opposed to the decay
$t^{-1}$ in other cases.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:07:10 GMT""},{""version"":""v2"",""created"":""Sun, 4 Oct 2020 02:44:20 GMT""},{""version"":""v3"",""created"":""Sun, 8 Nov 2020 15:12:21 GMT""},{""version"":""v4"",""created"":""Sun, 24 Jan 2021 14:32:46 GMT""}]","2021-01-26"
"2007.01490","Shoji Yokura","Toshihiro Yamaguchi and Shoji Yokura","Poincar\'e polynomials of a map and a relative Hilali conjecture","any comments are welcome","Tbilisi Mathematical Journal, 13(4) (2020), pp. 33-47",,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we introduce homological and homotopical Poincar\'e polynomials
$P_f(t)$ and $P^{\pi}_f(t)$ of a continuous map $f:X \to Y$ such that if $f:X
\to Y$ is a constant map, or more generally, if $Y$ is contractible, then these
Poincar\'e polynomials are respectively equal to the usual homological and
homotopical Poincar\'e polynomials $P_X(t)$ and $P^{\pi}_X(t)$ of the source
space $X$. Our relative Hilali conjecture $P^{\pi}_f(1) \leqq P_f(1)$ is a map
version of the the well-known Hilali conjecture $P^{\pi}_X(1) \leqq P_X(1)$ of
a rationally elliptic space X. In this paper we show that under the condition
that $H_i(f;\mathbb Q):H_i(X;\mathbb Q) \to H_i(Y;\mathbb Q)$ is not injective
for some $i>0$, the relative Hilali conjecture of product of maps holds,
namely, there exists a positive integer $n_0$ such that for $\forall n \geqq
n_0$ the \emph{strict inequality $P^{\pi}_{f^n}(1) < P_{f^n}(1)$} holds, where
$f^n:X^n \to Y^n$. In the final section we pose a question whether a
""Hilali""-type inequality $HP^{\pi}_X(r_X) \leqq P_X(r_X)$ holds for a
rationally hyperbolic space $X$, provided the the homotopical Hilbert--Poincare
series $HP^{\pi}_X(r_X)$ converges at the radius $r_X$ of convergence.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:14:23 GMT""}]","2020-10-20"
"2007.01491","Chong Yu","Chong Yu, Jeff Pool","Self-Supervised GAN Compression","The appendix for this paper is in the following repository
  https://gitlab.com/dxxz/Self-Supervised-GAN-Compression-Appendix","NeurIPS 2020",,,"cs.LG cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning's success has led to larger and larger models to handle more
and more complex tasks; trained models can contain millions of parameters.
These large models are compute- and memory-intensive, which makes it a
challenge to deploy them with minimized latency, throughput, and storage
requirements. Some model compression methods have been successfully applied to
image classification and detection or language models, but there has been very
little work compressing generative adversarial networks (GANs) performing
complex tasks. In this paper, we show that a standard model compression
technique, weight pruning, cannot be applied to GANs using existing methods. We
then develop a self-supervised compression technique which uses the trained
discriminator to supervise the training of a compressed generator. We show that
this framework has a compelling performance to high degrees of sparsity, can be
easily applied to new tasks and models, and enables meaningful comparisons
between different pruning granularities.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:18:54 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jul 2020 16:43:57 GMT""}]","2023-05-19"
"2007.01492","Teruyuki Kitabayashi","Teruyuki Kitabayashi","Texture zeros flavor neutrino mass matrix and triplet Higgs models","10 pages, 4 figures. Accepted for publication in Physical Review D","Phys. Rev. D 102, 075027 (2020)","10.1103/PhysRevD.102.075027",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One- and two-zero textures for the flavor neutrino mass matrix have been
successful in explaining mixing in the neutrino sector. Conservatively, six
cases of one-zero textures and seven cases of two-zero textures are compatible
with observations. We show that one case may be the most natural in the one-
and two-zero textures schemes if tiny neutrino masses are generated by the
type-II seesaw mechanism in triplet Higgs models.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:20:56 GMT""},{""version"":""v2"",""created"":""Mon, 5 Oct 2020 06:41:56 GMT""},{""version"":""v3"",""created"":""Wed, 14 Oct 2020 02:22:18 GMT""}]","2020-10-28"
"2007.01493","Arthur Choi","Arthur Choi and Andy Shih and Anchal Goyanka and Adnan Darwiche","On Symbolically Encoding the Behavior of Random Forests","Presented at the 3rd Workshop on Formal Methods for ML-Enabled
  Autonomous Systems (FoMLAS), 2020",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work has shown that the input-output behavior of some machine learning
systems can be captured symbolically using Boolean expressions or tractable
Boolean circuits, which facilitates reasoning about the behavior of these
systems. While most of the focus has been on systems with Boolean inputs and
outputs, we address systems with discrete inputs and outputs, including ones
with discretized continuous variables as in systems based on decision trees. We
also focus on the suitability of encodings for computing prime implicants,
which have recently played a central role in explaining the decisions of
machine learning systems. We show some key distinctions with encodings for
satisfiability, and propose an encoding that is sound and complete for the
given task.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:21:47 GMT""}]","2020-07-06"
"2007.01494","Andi Han","Andi Han, Junbin Gao","Variance reduction for Riemannian non-convex optimization with batch
  size adaptation",,,,,"math.OC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variance reduction techniques are popular in accelerating gradient descent
and stochastic gradient descent for optimization problems defined on both
Euclidean space and Riemannian manifold. In this paper, we further improve on
existing variance reduction methods for non-convex Riemannian optimization,
including R-SVRG and R-SRG/R-SPIDER with batch size adaptation. We show that
this strategy can achieve lower total complexities for optimizing both general
non-convex and gradient dominated functions under both finite-sum and online
settings. As a result, we also provide simpler convergence analysis for R-SVRG
and improve complexity bounds for R-SRG under finite-sum setting. Specifically,
we prove that R-SRG achieves the same near-optimal complexity as R-SPIDER
without requiring a small step size. Empirical experiments on a variety of
tasks demonstrate effectiveness of proposed adaptive batch size scheme.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:34:39 GMT""}]","2020-07-06"
"2007.01495","Zhizhang Wang","Zhizhang Wang and Ling Xiao","Entire spacelike hypersurfaces with constant $\sigma_k$ curvature in
  Minkowski space",,,,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we prove the existence of smooth, entire, strictly convex,
spacelike, constant $\sigma_k$ curvature hypersurfaces with prescribed
lightlike directions in Minkowski space. This is equivalent to prove the
existence of smooth, entire, strictly convex, spacelike, constant $\sigma_k$
curvature hypersurfaces with prescribed Gauss map image. We also show that
there doesn't exist any entire, convex, strictly spacelike, constant $\sigma_k$
curvature hypersurfaces. Moreover, we generalize the result in \cite{RWX} and
construct strictly convex, spacelike, constant $\sigma_k$ curvature
hypersurface with bounded principal curvature, whose image of the Gauss map is
the unit ball.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:46:31 GMT""}]","2020-07-06"
"2007.01496","Shuo Lei","Shuo Lei, Xuchao Zhang, Jianfeng He, Fanglan Chen, Chang-Tien Lu","Few-Shot Semantic Segmentation Augmented with Image-Level Weak
  Annotations","Accpeted to ICME2021",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the great progress made by deep neural networks in the semantic
segmentation task, traditional neural-networkbased methods typically suffer
from a shortage of large amounts of pixel-level annotations. Recent progress in
fewshot semantic segmentation tackles the issue by only a few pixel-level
annotated examples. However, these few-shot approaches cannot easily be applied
to multi-way or weak annotation settings. In this paper, we advance the
few-shot segmentation paradigm towards a scenario where image-level annotations
are available to help the training process of a few pixel-level annotations.
Our key idea is to learn a better prototype representation of the class by
fusing the knowledge from the image-level labeled data. Specifically, we
propose a new framework, called PAIA, to learn the class prototype
representation in a metric space by integrating image-level annotations.
Furthermore, by considering the uncertainty of pseudo-masks, a distilled soft
masked average pooling strategy is designed to handle distractions in
image-level annotations. Extensive empirical results on two datasets show
superior performance of PAIA.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:58:20 GMT""},{""version"":""v2"",""created"":""Fri, 18 Jun 2021 17:55:54 GMT""}]","2021-06-21"
"2007.01497","Hao Chen","Jingru Zhang, Hao Chen, Xiao-Hua Zhou","A New Non-parametric Test for Multivariate Paired Data and Pair Matching",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In paired design studies, it is common to have multiple measurements taken
for the same set of subjects under different conditions. In observational
studies, it is many times of interest to conduct pair matching on multiple
covariates between a treatment group and a control group, and to test the
treatment effect represented by multiple response variables on well
pair-matched data. However, there is a lack of an effective test on
multivariate paired data. The multivariate paired Hotelling's $T^2$ test can
sometimes be used, but its power decreases fast as the dimension increases.
Existing methods for assessing the balance of multiple covariates in matched
observational studies usually ignore the paired structure and thus they do not
perform well under some settings. In this work, we propose a new non-parametric
test for paired data, which exhibits a substantial power improvement over
existing methods under a wide range of situations. We also derive the
asymptotic distribution of the new test and the approximate $p$-value is
reasonably accurate under finite samples through simulation studies even when
the dimension is larger than the sample size, making the new test an
easy-off-the-shelf tool for real applications. The proposed test is illustrated
through an analysis of a real data set on the Alzheimer's disease research.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:59:26 GMT""},{""version"":""v2"",""created"":""Sun, 19 Sep 2021 19:27:37 GMT""}]","2021-09-21"
"2007.01498","Yuqian Jiang","Yuqian Jiang, Sudarshanan Bharadwaj, Bo Wu, Rishi Shah, Ufuk Topcu,
  Peter Stone","Temporal-Logic-Based Reward Shaping for Continuing Reinforcement
  Learning Tasks",,,"10.1609/aaai.v35i9.16975",,"cs.AI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In continuing tasks, average-reward reinforcement learning may be a more
appropriate problem formulation than the more common discounted reward
formulation. As usual, learning an optimal policy in this setting typically
requires a large amount of training experiences. Reward shaping is a common
approach for incorporating domain knowledge into reinforcement learning in
order to speed up convergence to an optimal policy. However, to the best of our
knowledge, the theoretical properties of reward shaping have thus far only been
established in the discounted setting. This paper presents the first reward
shaping framework for average-reward learning and proves that, under standard
assumptions, the optimal policy under the original reward function can be
recovered. In order to avoid the need for manual construction of the shaping
function, we introduce a method for utilizing domain knowledge expressed as a
temporal logic formula. The formula is automatically translated to a shaping
function that provides additional reward throughout the learning process. We
evaluate the proposed method on three continuing tasks. In all cases, shaping
speeds up the average-reward learning rate without any reduction in the
performance of the learned policy compared to relevant baselines.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 05:06:57 GMT""},{""version"":""v2"",""created"":""Mon, 16 Jan 2023 21:37:25 GMT""}]","2023-01-18"
"2007.01499","Qing Li","Qing Li, Siyuan Huang, Yining Hong, Song-Chun Zhu","A Competence-aware Curriculum for Visual Concepts Learning via Question
  Answering","ECCV 2020 (Oral) Camera Ready. Project page:
  https://liqing-ustc.github.io/CL-mIRT/",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humans can progressively learn visual concepts from easy to hard questions.
To mimic this efficient learning ability, we propose a competence-aware
curriculum for visual concept learning in a question-answering manner.
Specifically, we design a neural-symbolic concept learner for learning the
visual concepts and a multi-dimensional Item Response Theory (mIRT) model for
guiding the learning process with an adaptive curriculum. The mIRT effectively
estimates the concept difficulty and the model competence at each learning step
from accumulated model responses. The estimated concept difficulty and model
competence are further utilized to select the most profitable training samples.
Experimental results on CLEVR show that with a competence-aware curriculum, the
proposed method achieves state-of-the-art performances with superior data
efficiency and convergence speed. Specifically, the proposed model only uses
40% of training data and converges three times faster compared with other
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 05:08:09 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jul 2020 21:57:39 GMT""}]","2020-07-29"
"2007.01500","Sapir Kaplan","Sapir Kaplan and Raja Giryes","Self-supervised Neural Architecture Search",,,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural Architecture Search (NAS) has been used recently to achieve improved
performance in various tasks and most prominently in image classification. Yet,
current search strategies rely on large labeled datasets, which limit their
usage in the case where only a smaller fraction of the data is annotated.
Self-supervised learning has shown great promise in training neural networks
using unlabeled data. In this work, we propose a self-supervised neural
architecture search (SSNAS) that allows finding novel network models without
the need for labeled data. We show that such a search leads to comparable
results to supervised training with a ""fully labeled"" NAS and that it can
improve the performance of self-supervised learning. Moreover, we demonstrate
the advantage of the proposed approach when the number of labels in the search
is relatively small.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 05:09:30 GMT""}]","2020-07-06"
"2007.01501","Seyed Peyman Zakeri","Zahra Rezaei, S. Peyman Zakeri","Singlet scalar dark matter in the non-commutative space-time: a viable
  hypothesis to explain the gamma-ray excess in the galactic center",,,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the non-commutative space-time to revive the idea that gamma-ray
excess in the galactic center can be the result of particle dark matter
annihilation. In the non-commutative theory, the photon spectrum is produced by
direct emission during this annihilation where a photon can be embed in the
final state together with other direct products in new vertices. In the various
configurations of dark matter phenomenology, we adopt the most common model
known as singlet scalar. Calculating the relevant aspects of the model, we can
obtain the photon flux in the galactic center. Comparing our numerical
achievements with experimental data reveals that non-commutative space-time can
be a reliable framework to explain the gamma-ray excess.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 05:22:44 GMT""}]","2020-07-06"
"2007.01502","Alejandro Mera","Alejandro Mera, Bo Feng, Long Lu, Engin Kirda","DICE: Automatic Emulation of DMA Input Channels for Dynamic Firmware
  Analysis",,"42nd IEEE Symposium on Security and Privacy, S&P 2021",,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Microcontroller-based embedded devices are at the core of Internet-of-Things
and Cyber-Physical Systems. The security of these devices is of paramount
importance. Among the approaches to securing embedded devices, dynamic firmware
analysis gained great attention lately, thanks to its offline nature and low
false-positive rates. However, regardless of the analysis and emulation
techniques used, existing dynamic firmware analyzers share a major limitation,
namely the inability to handle firmware using DMA. It severely limits the types
of devices supported and firmware code coverage. We present DICE, a drop-in
solution for firmware analyzers to emulate DMA input channels and generate or
manipulate DMA inputs. DICE is designed to be hardware-independent, and
compatible with common MCU firmware and embedded architectures. DICE identifies
DMA input channels as the firmware writes the source and destination DMA
transfer pointers into the DMA controller. Then DICE manipulates the input
transferred through DMA on behalf of the firmware analyzer. We integrated DICE
to the firmware analyzer P2IM (Cortex-M architecture) and a PIC32 emulator
(MIPS M4K/M-Class architecture). We evaluated it on 83 benchmarks and sample
firmware, representing 9 different DMA controllers from 5 different vendors.
DICE detected 33 out of 37 DMA input channels, with 0 false positives. It
correctly supplied DMA inputs to 21 out of 22 DMA buffers, which previous
firmware analyzers cannot achieve due to the lack of DMA emulation. DICE's
overhead is fairly low, it adds 3.4% on average to P2IM execution time. We also
fuzz-tested 7 real-world firmware using DICE and compared the results with the
original P2IM. DICE uncovered tremendously more execution paths (as much as
79X) and found 5 unique previously-unknown bugs that are unreachable without
DMA emulation. All our source code and dataset are publicly available.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 05:23:33 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 17:22:32 GMT""},{""version"":""v3"",""created"":""Fri, 15 Jan 2021 01:41:47 GMT""}]","2021-01-18"
"2007.01503","Yarema Boryshchak","Yarema Boryshchak","Mathematical Perspective of Machine Learning","9 pages 3 figures",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We take a closer look at some theoretical challenges of Machine Learning as a
function approximation, gradient descent as the default optimization algorithm,
limitations of fixed length and width networks and a different approach to RNNs
from a mathematical perspective.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 05:26:02 GMT""}]","2020-07-06"
"2007.01504","Mengxi Jia","Mengxi Jia, Yunpeng Zhai, Shijian Lu, Siwei Ma, Jian Zhang","A Similarity Inference Metric for RGB-Infrared Cross-Modality Person
  Re-identification","Accepted by IJCAI2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  RGB-Infrared (IR) cross-modality person re-identification (re-ID), which aims
to search an IR image in RGB gallery or vice versa, is a challenging task due
to the large discrepancy between IR and RGB modalities. Existing methods
address this challenge typically by aligning feature distributions or image
styles across modalities, whereas the very useful similarities among gallery
samples of the same modality (i.e. intra-modality sample similarities) is
largely neglected. This paper presents a novel similarity inference metric
(SIM) that exploits the intra-modality sample similarities to circumvent the
cross-modality discrepancy targeting optimal cross-modality image matching. SIM
works by successive similarity graph reasoning and mutual nearest-neighbor
reasoning that mine cross-modality sample similarities by leveraging
intra-modality sample similarities from two different perspectives. Extensive
experiments over two cross-modality re-ID datasets (SYSU-MM01 and RegDB) show
that SIM achieves significant accuracy improvement but with little extra
training as compared with the state-of-the-art.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 05:28:13 GMT""}]","2020-07-06"
"2007.01505","Manh-Huong Phan","Valery Ortiz Jimenez, Yen Thi Hai Pham, Mingzu Liu, Fu Zhang,
  Vijaysankar Kalappattil, Baleeswaraiah Muchharla, Tatiana Eggers, Dinh Loc
  Duong, Mauricio Terrones, and Manh-Huong Phan","Light-controlled room temperature ferromagnetism in vanadium-doped
  tungsten diselenide semiconducting monolayers",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Atomically thin transition metal dichalcogenide (TMD) semiconductors hold
enormous potential for modern optoelectronic devices and quantum computing
applications. By inducing long-range ferromagnetism (FM) in these
semiconductors through the introduction of small amounts of a magnetic dopant,
it is possible to extend their potential in emerging spintronic applications.
Here, we demonstrate light-mediated, room temperature (RT) FM, in V-doped WS2
(V-WS2) monolayers. We probe this effect using the principle of magnetic LC
resonance, which employs a soft ferromagnetic Co-based microwire coil driven
near its resonance in the radio frequency (RF) regime. The combination of LC
resonance with an extraordinary giant magneto-impedance effect, renders the
coil highly sensitive to changes in the magnetic flux through its core. We then
place the V-WS2 monolayer at the core of the coil where it is excited with a
laser while its change in magnetic permeability is measured. Notably, the
magnetic permeability of the monolayer is found to depend on the laser
intensity, thus confirming light control of RT magnetism in this
two-dimensional (2D) material. Guided by density functional calculations, we
attribute this phenomenon to the presence of excess holes in the conduction and
valence bands, as well as carriers trapped in the magnetic doping states, which
in turn mediates the magnetization of the V-WS2 monolayer. These findings
provide a unique route to exploit light-controlled ferromagnetism in low
powered 2D spintronic devices capable of operating at RT.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 05:32:02 GMT""}]","2020-07-06"
"2007.01506","Qianqian Zhang","Ying-Chang Liang, Qianqian Zhang, Erik G. Larsson, Geoffrey Ye Li","Symbiotic Radio: Cognitive Backscattering Communications for Future
  Wireless Networks",,,,,"eess.SP cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The heterogenous wireless services and exponentially growing traffic call for
novel spectrum- and energy-efficient wireless communication technologies. In
this paper, a new technique, called symbiotic radio (SR), is proposed to
exploit the benefits and address the drawbacks of cognitive radio (CR) and
ambient backscattering communications(AmBC), leading to mutualism spectrum
sharing and highly reliable backscattering communications. In particular, the
secondary transmitter (STx) in SR transmits messages to the secondary receiver
(SRx) over the RF signals originating from the primary transmitter (PTx) based
on cognitive backscattering communications, thus the secondary system shares
not only the radio spectrum, but also the power, and infrastructure with the
primary system. In return, the secondary transmission provides beneficial
multipath diversity to the primary system, therefore the two systems form
mutualism spectrum sharing. More importantly, joint decoding is exploited at
SRx to achieve highly reliable backscattering communications. To exploit the
full potential of SR, in this paper, we address three fundamental tasks in SR:
(1) enhancing the backscattering link via active load; (2) achieving highly
reliable communications through joint decoding; and (3) capturing PTx's RF
signals using reconfigurable intelligent surfaces. Emerging applications,
design challenges and open research problems will also be discussed.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 05:49:45 GMT""}]","2020-07-06"
"2007.01507","Yuting Liang","Yuting Liang, Reza Samavi","Towards Robust Deep Learning with Ensemble Networks and Noisy Layers","Accepted into AAAI RSEML 2021 workshop",,,,"cs.LG cs.CR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we provide an approach for deep learning that protects against
adversarial examples in image classification-type networks. The approach relies
on two mechanisms:1) a mechanism that increases robustness at the expense of
accuracy, and, 2) a mechanism that improves accuracy but does not always
increase robustness. We show that an approach combining the two mechanisms can
provide protection against adversarial examples while retaining accuracy. We
formulate potential attacks on our approach with experimental results to
demonstrate its effectiveness. We also provide a robustness guarantee for our
approach along with an interpretation for the guarantee.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:04:02 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 18:05:57 GMT""}]","2021-01-07"
"2007.01508","Valerica Raicu","Justin Trujillo and Valerica Raicu","Method to monitor the evolution of an epidemic in real time","9 pages, 4 figures",,,,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The emergence of an epidemic evokes the need to monitor its spread and assess
and validate any mitigation measures enacted by governments and administrative
bodies in real time. We present here a method to observe and quantify this
spread and the response of affected populations and governing bodies and apply
it to COVID-19 as a case study. This method provides means to simultaneously
track in real time quantities such as the mortality and the recovery rates as
well as the number of new infections caused by an infected person. With
sufficient data, this method enables thorough monitoring and assessment of an
epidemic without assumptions regarding the evolution of the pandemic in the
future.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:08:04 GMT""}]","2020-07-06"
"2007.01509","Stefano Montaldo","Ali Fardoun, Stefano Montaldo, Andrea Ratto","On the stability of the equator map for higher order energy functionals","13 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $B^n\subset {\mathbb R}^{n}$ and ${\mathbb S}^n\subset {\mathbb R}^{n+1}$
denote the Euclidean $n$-dimensional unit ball and sphere respectively. The
\textit{extrinsic $k$-energy functional} is defined on the Sobolev space
$W^{k,2}\left (B^n,{\mathbb S}^n \right )$ as follows: $E_{k}^{{\rm
ext}}(u)=\int_{B^n}|\Delta^s u|^2\,dx$ when $k=2s$, and $E_{k}^{{\rm
ext}}(u)=\int_{B^n}|\nabla \Delta^s u|^2\,dx$ when $k=2s+1$. These energy
functionals are a natural higher order version of the classical extrinsic
bienergy, also called Hessian energy. The equator map $u^*: B^n \to {\mathbb
S}^n$, defined by $u^*(x)=(x/|x|,0)$, is a critical point of $E_{k}^{{\rm
ext}}(u)$ provided that $n \geq 2k+1$. The main aim of this paper is to
establish necessary and sufficient conditions on $k$ and $n$ under which $u^*:
B^n \to {\mathbb S}^n$ is minimizing or unstable for the extrinsic $k$-energy.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:21:00 GMT""}]","2020-07-06"
"2007.01510","Yusi Zhang","Yusi Zhang, Chuanjie Liu, Angen Luo, Hui Xue, Xuan Shan, Yuxiang Luo,
  Yiqian Xia, Yuanchi Yan, Haidong Wang","MIRA: Leveraging Multi-Intention Co-click Information in Web-scale
  Document Retrieval using Deep Neural Networks",,,,,"cs.IR cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of deep recall model in industrial web search, which is,
given a user query, retrieve hundreds of most relevance documents from billions
of candidates. The common framework is to train two encoding models based on
neural embedding which learn the distributed representations of queries and
documents separately and match them in the latent semantic space. However, all
the exiting encoding models only leverage the information of the document
itself, which is often not sufficient in practice when matching with query
terms, especially for the hard tail queries. In this work we aim to leverage
the additional information for each document from its co-click neighbour to
help document retrieval. The challenges include how to effectively extract
information and eliminate noise when involving co-click information in deep
model while meet the demands of billion-scale data size for real time online
inference.
  To handle the noise in co-click relations, we firstly propose a web-scale
Multi-Intention Co-click document Graph(MICG) which builds the co-click
connections between documents on click intention level but not on document
level. Then we present an encoding framework MIRA based on Bert and graph
attention networks which leverages a two-factor attention mechanism to
aggregate neighbours. To meet the online latency requirements, we only involve
neighbour information in document side, which can save the time-consuming query
neighbor search in real time serving. We conduct extensive offline experiments
on both public dataset and private web-scale dataset from two major commercial
search engines demonstrating the effectiveness and scalability of the proposed
method compared with several baselines. And a further case study reveals that
co-click relations mainly help improve web search quality from two aspects: key
concept enhancing and query term complementary.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:32:48 GMT""}]","2020-07-06"
"2007.01511","Hyong-Chol O","Hyong Chol O, Tae Song Kim","Analysis on the Pricing model for a Discrete Coupon Bond with Early
  redemption provision by the Structural Approach","30 pages, 16 figures",,,,"q-fin.PR q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, using the structural approach is derived a mathematical model
of the discrete coupon bond with the provision that allow the holder to demand
early redemption at any coupon dates prior to the maturity and based on this
model is provided some analysis including min-max and gradient estimates of the
bond price. Using these estimates the existence and uniqueness of the default
boundaries and some relationships between the design parameters of the discrete
coupon bond with early redemption provision are described. Then under some
assumptions the existence and uniqueness of the early redemption boundaries is
proved and the analytic formula of the bond price is provided using higher
binary options. Finally for our bond is provided the analysis on the duration
and credit spread, which are used widely in financial reality. Our works
provide a design guide of the discrete coupon bond with the early redemption
provision
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:33:28 GMT""}]","2020-07-06"
"2007.01512","Angelo Rosello","Arnaud Debussche (IRMAR), Angelo Rosello (IRMAR, MINGUS)","Existence of martingale solutions for stochastic flocking models with
  local alignment",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish the existence of martingale solutions to a class of stochastic
conservation equations. The underlying models correspond to random
perturbations of kinetic models for collective motion such as the Cucker-Smale
and Motsch-Tadmor models. By regularizing the coefficients, we first construct
approximate solutions obtained as the mean-field limit of the corresponding
particle systems. We then establish the compactness in law of this family of
solutions by relying on a stochastic averaging lemma. This extends the results
obtained by Karper, Mellet and Trivisa in the deterministic case.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:33:53 GMT""}]","2020-07-06"
"2007.01513","Xihan Chen","Jiayu Zhang, Min Li, Shihao Yan, Chunshan Liu, Xihan Chen, Minjian
  Zhao, Philip Whiting","Joint Beam Training and Data Transmission Design for Covert
  Millimeter-Wave Communication","Submitted for possible journal publication",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Covert communication prevents legitimate transmission from being detected by
a warden while maintaining certain covert rate at the intended user. Prior
works have considered the design of covert communication over conventional
low-frequency bands, but few works so far have explored the higher-frequency
millimeter-wave (mmWave) spectrum. The directional nature of mmWave
communication makes it attractive for covert transmission. However, how to
establish such directional link in a covert manner in the first place remains
as a significant challenge. In this paper, we consider a covert mmWave
communication system, where legitimate parties Alice and Bob adopt beam
training approach for directional link establishment. Accounting for the
training overhead, we develop a new design framework that jointly optimizes
beam training duration, training power and data transmission power to maximize
the effective throughput of Alice-Bob link while ensuring the covertness
constraint at warden Willie is met. We further propose a dual-decomposition
successive convex approximation algorithm to solve the problem efficiently.
Numerical studies demonstrate interesting tradeoff among the key design
parameters considered and also the necessity of joint design of beam training
and data transmission for covert mmWave communication.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:35:29 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jul 2020 03:55:59 GMT""}]","2020-07-14"
"2007.01514","Shinya Matsubara","Shinya Matsubara, Akihiko Honda, Yonghoon Ji, Kazunori Umeda","Three-dimensional Human Tracking of a Mobile Robot by Fusion of Tracking
  Results of Two Cameras","4 pages, 11 figures",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a process that uses two cameras to obtain
three-dimensional (3D) information of a target object for human tracking.
Results of human detection and tracking from two cameras are integrated to
obtain the 3D information. OpenPose is used for human detection. In the case of
a general processing a stereo camera, a range image of the entire scene is
acquired as precisely as possible, and then the range image is processed.
However, there are problems such as incorrect matching and computational cost
for the calibration process. A new stereo vision framework is proposed to cope
with the problems. The effectiveness of the proposed framework and the method
is verified through target-tracking experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:46:49 GMT""}]","2020-07-06"
"2007.01515","Evis Ieronymou","Evis Ieronymou","Evaluation of Brauer elements over local fields","corrected minor mistakes, added details to some proofs",,,,"math.AG math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the evaluation maps given by elements of the Brauer group of
varieties over local fields. We show constancy of the aforementioned maps in
several interesting cases.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:47:31 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 18:39:19 GMT""},{""version"":""v3"",""created"":""Wed, 8 Jul 2020 09:22:17 GMT""},{""version"":""v4"",""created"":""Tue, 10 Aug 2021 13:59:13 GMT""}]","2021-08-11"
"2007.01516","Deepak Sharma","Deepak Sharma, Audrey Durand, Marc-Andr\'e Legault, Louis-Philippe
  Lemieux Perreault, Audrey Lema\c{c}on, Marie-Pierre Dub\'e, Joelle Pineau","Deep interpretability for GWAS","Accepted at ICML 2020 workshop on ML Interpretability for Scientific
  Discovery",,,,"cs.LG q-bio.GN stat.AP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Genome-Wide Association Studies are typically conducted using linear models
to find genetic variants associated with common diseases. In these studies,
association testing is done on a variant-by-variant basis, possibly missing out
on non-linear interaction effects between variants. Deep networks can be used
to model these interactions, but they are difficult to train and interpret on
large genetic datasets. We propose a method that uses the gradient based deep
interpretability technique named DeepLIFT to show that known diabetes genetic
risk factors can be identified using deep models along with possibly novel
associations.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:49:31 GMT""}]","2020-07-06"
"2007.01517","Xuding Zhu","Eun-Kyung Cho and Ilkyoo Choi and Ringi Kim and Boram Park and
  Tingting Shan and Xuding Zhu","Decomposing planar graphs into graphs with degree restrictions","16 pages, 5 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a graph $G$, a decomposition of $G$ is a partition of its edges. A
graph is $(d, h)$-decomposable if its edge set can be partitioned into a
$d$-degenerate graph and a graph with maximum degree at most $h$. For $d \le
4$, we are interested in the minimum integer $h_d$ such that every planar graph
is $(d,h_d)$-decomposable. It was known that $h_3 \le 4$, $h_2\le 8$, and $h_1
= \infty$. This paper proves that $h_4=1, h_3=2$, and $4 \le h_2 \le 6$.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:53:12 GMT""}]","2020-07-06"
"2007.01518","Alexis Lavail","Alexis Lavail (1), Oleg Kochukhov (1), Gaitee Hussain (2), Costanza
  Argiroffi (3 and 4), Evelyne Alecian (5), Julien Morin (6), the BinaMIcS
  collaboration ((1) Uppsala University, (2) European Southern Observatory, (3)
  University of Palermo, (4) INAF - Osservatorio Astronomico di Palermo, (5)
  Universit\'e Grenoble Alpes, CNRS, IPAG, (6) LUPM, Universit\'e de
  Montpellier)","The large-scale magnetic field of the eccentric pre-main-sequence binary
  system V1878 Ori","13 pages, 9 figures, accepted for publication in MNRAS",,"10.1093/mnras/staa1993",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report time-resolved, high-resolution optical spectropolarimetric
observations of the young double-lined spectroscopic binary V1878 Ori. Our
observations were collected with the ESPaDOnS spectropolarimeter at the
Canada-France-Hawaii Telescope through the BinaMIcS large programme. V1878 Ori
A and B are partially convective intermediate mass weak-line T Tauri stars on
an eccentric and asynchronous orbit. We also acquired X-ray observations at
periastron and outside periastron.
  Using the least-squares deconvolution technique (LSD) to combine information
from many spectral lines, we clearly detected circular polarization signals in
both components throughout the orbit. We refined the orbital solution for the
system and obtained disentangled spectra for the primary and secondary
components. The disentangled spectra were then employed to determine
atmospheric parameters of the two components using spectrum synthesis.
  Applying our Zeeman Doppler imaging code to composite Stokes $IV$ LSD
profiles, we reconstructed brightness maps and the global magnetic field
topologies of the two components. We find that V1878 Ori A and B have
strikingly different global magnetic field topologies and mean field strengths.
The global magnetic field of the primary is predominantly poloidal and
non-axisymmetric (with a mean field strength of 180 G). while the secondary has
a mostly toroidal and axisymmetric global field (mean strength of 310 G). These
findings confirm that stars with very similar parameters can exhibit radically
different global magnetic field characteristics. The analysis of the X-ray data
shows no sign of enhanced activity at periastron, suggesting the lack of strong
magnetospheric interaction at this epoch.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 06:56:12 GMT""}]","2020-07-15"
"2007.01519","Jianxiong Guo","Jianxiong Guo, Yapu Zhang, Weili Wu","Overall Evaluations on Benefits of Influence When Disturbed by Rivals",,"IEEE Transactions on Big Data, 2021","10.1109/TBDATA.2021.3084468",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Influence maximization (IM) is a representative and classic problem that has
been studied extensively before. The most important application derived from
the IM problem is viral marketing. Take us as a promoter, we want to get
benefits from the influence diffusion in a given social network, where each
influenced (activated) user is associated with a benefit. However, there is
often competing information initiated by our rivals diffusing in the same
social network at the same time. Consider such a scenario, a user is influenced
by both my information and my rivals' information. Here, the benefit from this
user should be weakened to certain degree. How to quantify the degree of
weakening? Based on that, we propose an overall evaluations on benefits of
influence (OEBI) problem. We prove the objective function of the OEBI problem
is not monotone, not submodular, and not supermodular. Fortunately, we can
decompose this objective function into the difference of two submodular
functions and adopt a modular-modular procedure to approximate it with a
data-dependent approximation guarantee. Because of the difficulty to compute
the exact objective value, we design a group of unbiased estimators by
exploiting the idea of reverse influence sampling, which can improve time
efficiency significantly without losing its approximation ratio. Finally,
numerical experiments on real datasets verified the effectiveness of our
approaches regardless of performance and efficiency.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:01:30 GMT""}]","2021-05-31"
"2007.01520","Alexander Mitchell Mr","Alexander L. Mitchell, Martin Engelcke, Oiwi Parker Jones, David
  Surovik, Siddhant Gangapurwala, Oliwier Melon, Ioannis Havoutis, and Ingmar
  Posner","First Steps: Latent-Space Control with Semantic Constraints for
  Quadruped Locomotion","8 pages, 7 figures, accepted at IROS 2020",,,,"cs.RO cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional approaches to quadruped control frequently employ simplified,
hand-derived models. This significantly reduces the capability of the robot
since its effective kinematic range is curtailed. In addition, kinodynamic
constraints are often non-differentiable and difficult to implement in an
optimisation approach. In this work, these challenges are addressed by framing
quadruped control as optimisation in a structured latent space. A deep
generative model captures a statistical representation of feasible joint
configurations, whilst complex dynamic and terminal constraints are expressed
via high-level, semantic indicators and represented by learned classifiers
operating upon the latent space. As a consequence, complex constraints are
rendered differentiable and evaluated an order of magnitude faster than
analytical approaches. We validate the feasibility of locomotion trajectories
optimised using our approach both in simulation and on a real-world ANYmal
quadruped. Our results demonstrate that this approach is capable of generating
smooth and realisable trajectories. To the best of our knowledge, this is the
first time latent space control has been successfully applied to a complex,
real robot platform.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:04:18 GMT""},{""version"":""v2"",""created"":""Fri, 20 Nov 2020 16:31:46 GMT""}]","2020-11-23"
"2007.01521","Martina Juhnke-Kubitzke","Martina Juhnke-Kubitzke and Uwe Nagel","Balanced squeezed Complexes","22 pages",,,,"math.CO math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given any order ideal $U$ consisting of color-squarefree monomials involving
variables with $d$ colors, we associate to it a balanced $(d-1)$-dimensional
simplicial complex $\Delta_{\mathrm{bal}}(U)$ that we call a balanced squeezed
complex. In fact, these complexes have properties similar to squeezed balls as
introduced by Kalai and the more general squeezed complexes, introduced by the
authors. We show that any balanced squeezed complex is vertex-decomposable and
that its flag $h$-vector can be read off from the underlying order ideal.
Moreover, we describe explicitly its Stanley-Reisner ideal
$I_{\Delta_{\mathrm{bal}}(U)}$. If $U$ is also shifted, we determine the
multigraded generic initial ideal of $I_{\Delta_{\mathrm{bal}}(U)}$ and
establish that the balanced squeezed complex $\Delta_{\mathrm{bal}}(U)$ has the
same graded Betti numbers as the complex obtained from color-shifting it. We
also introduce a class of color-squarefree monomial ideals that may be viewed
as a generalization of the classical squarefree stable monomial ideals and show
that their graded Betti numbers can be read off from their minimal generators.
Moreover, we develop some tools for computing graded Betti numbers.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:09:14 GMT""}]","2020-07-06"
"2007.01522","Yasmeen George","Yasmeen M. George, Suman Sedai, Bhavna J. Antony, Hiroshi Ishikawa,
  Gadi Wollstein, Joel S. Schuman and Rahil Garnavi","Dueling Deep Q-Network for Unsupervised Inter-frame Eye Movement
  Correction in Optical Coherence Tomography Volumes",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In optical coherence tomography (OCT) volumes of retina, the sequential
acquisition of the individual slices makes this modality prone to motion
artifacts, misalignments between adjacent slices being the most noticeable. Any
distortion in OCT volumes can bias structural analysis and influence the
outcome of longitudinal studies. On the other hand, presence of speckle noise
that is characteristic of this imaging modality, leads to inaccuracies when
traditional registration techniques are employed. Also, the lack of a
well-defined ground truth makes supervised deep-learning techniques ill-posed
to tackle the problem. In this paper, we tackle these issues by using deep
reinforcement learning to correct inter-frame movements in an unsupervised
manner. Specifically, we use dueling deep Q-network to train an artificial
agent to find the optimal policy, i.e. a sequence of actions, that best
improves the alignment by maximizing the sum of reward signals. Instead of
relying on the ground-truth of transformation parameters to guide the rewarding
system, for the first time, we use a combination of intensity based image
similarity metrics. Further, to avoid the agent bias towards speckle noise, we
ensure the agent can see retinal layers as part of the interacting environment.
For quantitative evaluation, we simulate the eye movement artifacts by applying
2D rigid transformations on individual B-scans. The proposed model achieves an
average of 0.985 and 0.914 for normalized mutual information and correlation
coefficient, respectively. We also compare our model with elastix intensity
based medical image registration approach, where significant improvement is
achieved by our model for both noisy and denoised volumes.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:14:30 GMT""}]","2020-07-06"
"2007.01523","Kadir Utku Can","K. U. Can, A. Hannaford-Gunn, R. Horsley, Y. Nakamura, H. Perlt, P. E.
  L. Rakow, G. Schierholz, K. Y. Somfleth, H. St\""uben, R. D. Young, J. M.
  Zanotti","Lattice QCD evaluation of the Compton amplitude employing the
  Feynman-Hellmann theorem","18 pages, 8 figures. Title has been changed due to the Editor's
  request. Version to appear in PRD","Phys. Rev. D 102, 114505 (2020)","10.1103/PhysRevD.102.114505","ADP-20-16/T1126, DESY 20-111, Liverpool LTH 1238","hep-lat hep-ph hep-th nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The forward Compton amplitude describes the process of virtual photon
scattering from a hadron and provides an essential ingredient for the
understanding of hadron structure. As a physical amplitude, the Compton tensor
naturally includes all target mass corrections and higher twist effects at a
fixed virtuality, $Q^2$. By making use of the second-order Feynman-Hellmann
theorem, the nucleon Compton tensor is calculated in lattice QCD at an
unphysical quark mass across a range of photon momenta $3 \lesssim Q^2 \lesssim
7$ GeV$^2$. This allows for the $Q^2$ dependence of the low moments of the
nucleon structure functions to be studied in a lattice calculation for the
first time. The results demonstrate that a systematic investigation of power
corrections and the approach to parton asymptotics is now within reach.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:15:47 GMT""},{""version"":""v2"",""created"":""Thu, 19 Nov 2020 10:54:17 GMT""}]","2020-12-11"
"2007.01524","Youngeun Kim","Youngeun Kim, Donghyeon Cho, Kyeongtak Han, Priyadarshini Panda,
  Sungeun Hong","Domain Adaptation without Source Data","13 pages",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Domain adaptation assumes that samples from source and target domains are
freely accessible during a training phase. However, such an assumption is
rarely plausible in the real-world and possibly causes data-privacy issues,
especially when the label of the source domain can be a sensitive attribute as
an identifier. To avoid accessing source data that may contain sensitive
information, we introduce Source data-Free Domain Adaptation (SFDA). Our key
idea is to leverage a pre-trained model from the source domain and
progressively update the target model in a self-learning manner. We observe
that target samples with lower self-entropy measured by the pre-trained source
model are more likely to be classified correctly. From this, we select the
reliable samples with the self-entropy criterion and define these as class
prototypes. We then assign pseudo labels for every target sample based on the
similarity score with class prototypes. Furthermore, to reduce the uncertainty
from the pseudo labeling process, we propose set-to-set distance-based
filtering which does not require any tunable hyperparameters. Finally, we train
the target model with the filtered pseudo labels with regularization from the
pre-trained source model. Surprisingly, without direct usage of labeled source
samples, our PrDA outperforms conventional domain adaptation methods on
benchmark datasets. Our code is publicly available at
https://github.com/youngryan1993/SFDA-SourceFreeDA
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:21:30 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jul 2020 02:00:51 GMT""},{""version"":""v3"",""created"":""Mon, 14 Dec 2020 15:57:52 GMT""},{""version"":""v4"",""created"":""Mon, 30 Aug 2021 06:29:13 GMT""}]","2021-08-31"
"2007.01525","Leon Sering","Hoang Minh Pham and Leon Sering","Dynamic Equilibria in Time-Varying Networks",,,,,"math.OC cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Predicting selfish behavior in public environments by considering Nash
equilibria is a central concept of game theory. For the dynamic traffic
assignment problem modeled by a flow over time game, in which every particle
tries to reach its destination as fast as possible, the dynamic equilibria are
called Nash flows over time. So far, this model has only been considered for
networks in which each arc is equipped with a constant capacity, limiting the
outflow rate, and with a transit time, determining the time it takes for a
particle to traverse the arc. However, real-world traffic networks can be
affected by temporal changes, for example, caused by construction works or
special speed zones during some time period. To model these traffic scenarios
appropriately, we extend the flow over time model by time-dependent capacities
and time-dependent transit times. Our first main result is the characterization
of the structure of Nash flows over time. Similar to the static-network model,
the strategies of the particles in dynamic equilibria can be characterized by
specific static flows, called thin flows with resetting. The second main result
is the existence of Nash flows over time, which we show in a constructive
manner by extending a flow over time step by step by these thin flows.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:22:34 GMT""}]","2020-07-06"
"2007.01526","Ilaria Maccari","Ilaria Maccari, Nicol\`o Defenu, Lara Benfatto, Claudio Castellani and
  Tilman Enss","Interplay of spin waves and vortices in the 2D XY model at small
  vortex-core energy",,"Phys. Rev. B 102, 104505 (2020)","10.1103/PhysRevB.102.104505",,"cond-mat.str-el cond-mat.stat-mech cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Berezinskii-Kosterlitz-Thouless (BKT) mechanism describes universal
vortex unbinding in many two-dimensional systems, including the paradigmatic XY
model. However, most of these systems present a complex interplay between
excitations at different length scales that complicates theoretical
calculations of nonuniversal thermodynamic quantities. These difficulties may
be overcome by suitably modifying the initial conditions of the BKT flow
equations to account for noncritical fluctuations at small length scales. In
this work, we perform a systematic study of the validity and limits of this
two-step approach by constructing optimised initial conditions for the BKT
flow. We find that the two-step approach can accurately reproduce the results
of Monte-Carlo simulations of the traditional XY model. In order to
systematically study the interplay between vortices and spin-wave excitations,
we introduce a modified XY model with increased vortex fugacity. We present
large-scale Monte-Carlo simulations of the spin stiffness and vortex density
for this modified XY model and show that even at large vortex fugacity, vortex
unbinding is accurately described by the nonperturbative functional
renormalisation group.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:29:13 GMT""},{""version"":""v2"",""created"":""Thu, 17 Sep 2020 22:50:56 GMT""}]","2020-09-21"
"2007.01527","Andreas Boukas","Andreas Boukas and Philip Feinsilver","Spectral Theorem approach to the Characteristic Function of Quantum
  Observables",,"Commun. Stoch. Anal. 13 (2019), no. 2, Article 3, 27 pp. MR4011326","10.31390/cosa.13.2.03.",,"math-ph math.FA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the spectral theorem we compute the Quantum Fourier Transform (or
Vacuum Characteristic Function) $\langle \Phi, e^{itH}\Phi\rangle$ of an
observable $H$ defined as a self-adjoint sum of the generators of a
finite-dimensional Lie algebra, where $\Phi$ is a unit vector in a Hilbert
space $\mathcal{H}$. We show how Stone's formula for computing the spectral
resolution of a Hilbert space self-adjoint operator, can serve as an
alternative to the traditional reliance on splitting (or disentanglement)
formulas for the operator exponential.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:30:30 GMT""}]","2020-07-06"
"2007.01528","Hai Wang","Hai Wang, David McAllester","On-The-Fly Information Retrieval Augmentation for Language Models","ACL 2020 NUSE Workshop",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here we experiment with the use of information retrieval as an augmentation
for pre-trained language models. The text corpus used in information retrieval
can be viewed as form of episodic memory which grows over time. By augmenting
GPT 2.0 with information retrieval we achieve a zero shot 15% relative
reduction in perplexity on Gigaword corpus without any re-training. We also
validate our IR augmentation on an event co-reference task.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:31:14 GMT""}]","2020-07-06"
"2007.01529","Yuriy Mokrousov","J. Kipp, K. Samanta, F. R. Lux, M. Merte, J.-P. Hanke, M. Redies, F.
  Freimuth, S. Bl\""ugel, M. Le\v{z}ai\'c, Y. Mokrousov","The chiral Hall effect in canted ferromagnets and antiferromagnets","To appear in Communications Physics (2021)","Communications Physics 4, 99 (2021)","10.1038/s42005-021-00587-3",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The anomalous Hall effect has been indispensable in our understanding of
numerous magnetic phenomena. This concerns both ferromagnetic materials, as
well as diverse classes of antiferromagnets, where in addition to the anomalous
and crystal Hall effects, the topological Hall effect in non-coplanar
antiferromagnets has been a subject of intensive research in the past decades.
Here, we uncover a new flavour of the anomalous Hall effect in canted spin
systems. Using advanced theoretical tools we demonstrate that upon canting, the
anomalous Hall effect acquires a contribution which is sensitive to the sense
of imprinted vector chirality among spins. We explore the origins and basic
properties of corresponding chiral Hall effect, and closely tie it to the
symmetry properties of the system. Our findings suggest that the chiral Hall
effect and corresponding chiral magneto-optical effects emerge as novel
versatile tools in characterizing an interplay of structure and chirality in
complex magnets, as well as in tracking their chiral dynamics and fluctuations.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:35:09 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 08:35:18 GMT""}]","2021-09-08"
"2007.01530","Stefan Mach","Stefan Mach, Fabian Schuiki, Florian Zaruba, Luca Benini","FPnew: An Open-Source Multi-Format Floating-Point Unit Architecture for
  Energy-Proportional Transprecision Computing",,,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The slowdown of Moore's law and the power wall necessitates a shift towards
finely tunable precision (a.k.a. transprecision) computing to reduce energy
footprint. Hence, we need circuits capable of performing floating-point
operations on a wide range of precisions with high energy-proportionality. We
present FPnew, a highly configurable open-source transprecision floating-point
unit (TP-FPU) capable of supporting a wide range of standard and custom FP
formats. To demonstrate the flexibility and efficiency of FPnew in
general-purpose processor architectures, we extend the RISC-V ISA with
operations on half-precision, bfloat16, and an 8bit FP format, as well as SIMD
vectors and multi-format operations. Integrated into a 32-bit RISC-V core, our
TP-FPU can speed up execution of mixed-precision applications by 1.67x w.r.t.
an FP32 baseline, while maintaining end-to-end precision and reducing system
energy by 37%. We also integrate FPnew into a 64-bit RISC-V core, supporting
five FP formats on scalars or 2, 4, or 8-way SIMD vectors. For this core, we
measured the silicon manufactured in Globalfoundries 22FDX technology across a
wide voltage range from 0.45V to 1.2V. The unit achieves leading-edge measured
energy efficiencies between 178 Gflop/sW (on FP64) and 2.95 Tflop/sW (on 8-bit
mini-floats), and a performance between 3.2 Gflop/s and 25.3 Gflop/s.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:38:00 GMT""}]","2020-07-06"
"2007.01531","Seho Yi","Seho Yi, Chongze Wang, Hyunsoo Jeon, and Jun-Hyung Cho","Stabilization mechanism of clathrate H cages in a room-temperature
  superconductor LaH$_{10}$","8 pages, 9 figures","Phys. Rev. Materials 5, 024801 (2021)","10.1103/PhysRevMaterials.5.024801",,"cond-mat.supr-con cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lanthanum hydride LaH$_{10}$ with a sodalitelike clathrate structure was
experimentally realized to exhibit a room-temperature superconductivity under
megabar pressures. Based on first-principles calculations, we reveal that the
metal framework of La atoms has the excess electrons at interstitial regions.
Such anionic electrons are easily captured to form a stable clathrate structure
of H cages. We thus propose that the charge transfer from La to H atoms is
mostly driven by the electride property of the La framework. Further, the
interaction between La atoms and H cages induces a delocalization of La-5$p$
semicore states to hybridize with H-1$s$ state. Consequently, the bonding
nature between La atoms and H cages is characterized as a mixture of ionic and
covalent. Our findings demonstrate that anionic and semicore electrons play
important roles in stabilizing clathrate H cages in LaH$_{10}$, which can be
broadly applicable to other high-pressure rare-earth hydrides with clathrate
structures.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:38:12 GMT""}]","2021-02-17"
"2007.01532","Dongmin Gang","Gil Young Cho, Dongmin Gang and Hee-Cheol Kim","M-theoretic Genesis of Topological Phases","29 pages, 1 figure",,"10.1007/JHEP11(2020)115",,"hep-th cond-mat.str-el math.GT","http://creativecommons.org/publicdomain/zero/1.0/","  We present a novel M-theoretic approach of constructing and classifying
anyonic topological phases of matter, by establishing a correspondence between
(2+1)d topological field theories and non-hyperbolic 3-manifolds. In this
construction, the topological phases emerge as macroscopic world-volume
theories of M5-branes wrapped around certain types of non-hyperbolic
3-manifolds. We devise a systematic algorithm for identifying the emergent
topological phases from topological data of the internal wrapped 3-manifolds.
As a benchmark of our approach, we reproduce all the known unitary bosonic
topological orders up to rank 4. Remarkably, our construction is not restricted
to an unitary bosonic theory but it can also generate fermionic and/or
non-unitary topological phases in an equivalent fashion. Hence, we pave a new
route toward the classification of topological phases of matter.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:46:48 GMT""}]","2020-12-30"
"2007.01533","Atsushi Miyauchi","Francesco Bonchi, David Garc\'ia-Soriano, Atsushi Miyauchi,
  Charalampos E. Tsourakakis","Finding Densest $k$-Connected Subgraphs",,"Discrete Applied Mathematics 305, 34-47, 2021","10.1016/j.dam.2021.08.032",,"cs.DS cs.DM cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dense subgraph discovery is an important graph-mining primitive with a
variety of real-world applications. One of the most well-studied optimization
problems for dense subgraph discovery is the densest subgraph problem, where
given an edge-weighted undirected graph $G=(V,E,w)$, we are asked to find
$S\subseteq V$ that maximizes the density $d(S)$, i.e., half the weighted
average degree of the induced subgraph $G[S]$. This problem can be solved
exactly in polynomial time and well-approximately in almost linear time.
However, a densest subgraph has a structural drawback, namely, the subgraph may
not be robust to vertex/edge failure. Indeed, a densest subgraph may not be
well-connected, which implies that the subgraph may be disconnected by removing
only a few vertices/edges within it. In this paper, we provide an algorithmic
framework to find a dense subgraph that is well-connected in terms of
vertex/edge connectivity. Specifically, we introduce the following problems:
given a graph $G=(V,E,w)$ and a positive integer/real $k$, we are asked to find
$S\subseteq V$ that maximizes the density $d(S)$ under the constraint that
$G[S]$ is $k$-vertex/edge-connected. For both problems, we propose
polynomial-time (bicriteria and ordinary) approximation algorithms, using
classic Mader's theorem in graph theory and its extensions.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:50:43 GMT""}]","2021-10-26"
"2007.01534","Ido Cohen","Ido Cohen, Omri Azencot, Pavel Lifshitz, Guy Gilboa","Modes of Homogeneous Gradient Flows","For further details https://idoc.webgr.technion.ac.il/
  https://www.vision-and-sensing.com/",,,,"math.DS cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding latent structures in data is drawing increasing attention in diverse
fields such as image and signal processing, fluid dynamics, and machine
learning. In this work we examine the problem of finding the main modes of
gradient flows. Gradient descent is a fundamental process in optimization where
its stochastic version is prominent in training of neural networks. Here our
aim is to establish a consistent theory for gradient flows $\psi_t = P(\psi)$,
where $P$ is a nonlinear homogeneous operator. Our proposed framework stems
from analytic solutions of homogeneous flows, previously formalized by
Cohen-Gilboa, where the initial condition $\psi_0$ admits the nonlinear
eigenvalue problem $P(\psi_0)=\lambda \psi_0 $. We first present an analytic
solution for \ac{DMD} in such cases. We show an inherent flaw of \ac{DMD},
which is unable to recover the essential dynamics of the flow. It is evident
that \ac{DMD} is best suited for homogeneous flows of degree one. We propose an
adaptive time sampling scheme and show its dynamics are analogue to homogeneous
flows of degree one with a fixed step size. Moreover, we adapt \ac{DMD} to
yield a real spectrum, using symmetric matrices. Our analytic solution of the
proposed scheme recovers the dynamics perfectly and yields zero error. We then
proceed to show that in the general case the orthogonal modes $\{ \phi_i \}$
are approximately nonlinear eigenfunctions $P(\phi_i) \approx\lambda_i \phi_i
$. We formulate Orthogonal Nonlinear Spectral decomposition (\emph{OrthoNS}),
which recovers the essential latent structures of the gradient descent process.
Definitions for spectrum and filtering are given, and a Parseval-type identity
is shown.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:51:34 GMT""},{""version"":""v2"",""created"":""Thu, 8 Oct 2020 17:49:38 GMT""},{""version"":""v3"",""created"":""Mon, 28 Dec 2020 18:15:38 GMT""}]","2020-12-29"
"2007.01535","Wei Liu","Qingdong Yang, Weijin Chen, Yuntian Chen, and Wei Liu","Scattering invariance for arbitrary polarizations protected by joint
  spatial-duality symmetries","6 pages and 4 figures; Comments to welcome","Phys. Rev. B 102, 155427 (2020)","10.1103/PhysRevB.102.155427",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We reveal how to exploit joint spatial-electromagnetic duality symmetries to
obtain invariant scattering properties (including extinction, scattering,
absorption) of self-dual scattering systems for incident waves of arbitrary
polarizations. The electromagnetic duality ensures the helicity preservation
along all scattering directions, and thus intrinsically eliminates the
interferences between the two scattering channels originating from the
circularly polarized components of incident waves. This absence of interference
directly secures invariant scattering properties for all polarizations located
on the same latitude circle of the Poincar\'{e} sphere, which are characterized
by polarization ellipses of the same eccentricity and handedness. Further
incorporations of mirror and/or inversion symmetries would lead to such
invariance throughout the whole Poincar\'{e} sphere, guaranteeing invariant
scattering properties for all polarizations. Simultaneous exploitations of
composite symmetries of different natures render an extra dimension of freedom
for scattering manipulations, offering new insights for both fundamental
explorations and optical device engineering related to symmetry dictated
light-matter interactions.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:54:17 GMT""}]","2020-11-04"
"2007.01536","Binbin Liao","Binbin Liao, Guangxing Zhang, Qinghua Wu, Zhenyu Li and Gaogang Xie","Cross-layer Path Selection in Multi-path Transport Protocol for Mobile
  Devices","ICNP under review",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MPTCP is a new transport protocol that enables mobile devices to use multiple
physical paths simultaneously through several network interfaces, such as WiFi
and Cellular. However, wireless path capacities change frequently in the mobile
environments, causing challenges for path selection. For example, WiFi
associated paths often become poor as devices walk away, since WiFi has
intermittent connectivity caused by the short signal coverage and stochastic
interference. MPTCP's native decision based on hysteretic TCP-layer estimation
will miss the real switching point of wireless quality, which may cumulate
packets on the broken path and causes serious packets reinjection. Through
analyzing a unique dataset in the wild, we quantitatively study the impact of
MAC-layer factors on the aggregated performance of MPTCP. We then propose a
decision tree approach for cross-layer path selection that decides which path
to carry the incoming packets dynamically according to the prior learned
schemes. A prototype of the path selection system named SmartPS, which
proactively probes the wireless environments, is realized and deployed in Linux
and Android. Evaluation results demonstrate that our SmartPS can efficiently
utilize the faster path, with goodput improvements of up to 29%.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:56:35 GMT""}]","2020-07-06"
"2007.01537","Eran O. Ofek","Eran O. Ofek, Maayane Soumagnac, Guy Nir, Avishay Gal-Yam, Peter
  Nugent, Frank Masci, Shrinivas R. Kulkarni","A catalog of over ten million variable source candidates in ZTF data
  release 1","Submitted to MNRAS",,"10.1093/mnras/staa2814",,"astro-ph.SR astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variable sources probe a wide range of astrophysical phenomena. We present a
catalog of over ten million variable source candidates found in Data Release 1
(DR1) of the Zwicky Transient Facility (ZTF). We perform a periodicity search
up to a frequency of 160 day^-1, and we classify the light curves into erratic
and smooth variables. We also present variability indicators and the results of
a periodicity search, up to a frequency of 5 day^-1, for about 1 billion
sources in the ZTF-DR1 light curve database. We present several new
short-period (<90 min) candidates, and about 60 new dwarf nova candidates,
including two candidate eclipsing systems. Both the 10 million variables
catalog and ~1 billion source catalog are available online in catsHTM format.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:59:29 GMT""}]","2020-11-04"
"2007.01538","Javier Fernandez de Bobadilla","J. Fernandez de Bobadilla, S. Heinze, M. Pe Pereira","Moderately Discontinuous Homotopy",,,,,"math.AG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a metric homotopy theory, which we call Moderately Discontinuous
Homotopy, designed to capture Lipschitz properties of metric singular
subanalytic germs. It matches with the Moderately Discontinuous Homology theory
receantly developed by the authors and E. Sampaio. The $k$-th MD homotopy group
is a group $MDH^b_\bullet$ for any $b\in [1,\infty]$ together with
homomorphisms $MD\pi^b\to MD\pi^{b'}$ for any $b\geq b'$. We develop all its
basic properties including finite presentation of the groups, long homology
sequences of pairs, metric homotopy invariance, Seifert-van Kampen Theorem and
the Hurewicz isomorphism Theorem. We prove comparison theorems that allow to
relate the metric homotopy groups with topological homotopy groups of
associated spaces. For $b=1$ it recovers the homotopy groups of the tangent
cone for the outer metric and of the Gromov tangent cone for the inner one. In
general, for $b=\infty$ the $MD$-homotopy recovers the homotopy of the
punctured germ. Hence, our invariant can be seen as an algebraic invariant
interpolating the homotopy from the germ to its tangent cone. We end the paper
with a full computation of our invariant for any normal surface singularity for
the inner metric. We also provide a full computation of the MD-Homology in the
same case.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:59:31 GMT""}]","2020-07-06"
"2007.01539","Edgar Bueno","Edgar Bueno and Dan Hedlin","A method to find an efficient and robust sampling strategy under model
  uncertainty",,,,,"stat.ME stat.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of deciding on sampling strategy, in particular
sampling design. We propose a risk measure, whose minimizing value guides the
choice. The method makes use of a superpopulation model and takes into account
uncertainty about its parameters. The method is illustrated with a real
dataset, yielding satisfactory results. As a baseline, we use the strategy that
couples probability proportional-to-size sampling with the difference
estimator, as it is known to be optimal when the superpopulation model is fully
known. We show that, even under moderate misspecifications of the model, this
strategy is not robust and can be outperformed by some alternatives
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:01:23 GMT""}]","2020-07-06"
"2007.01540","Graham Benham DPhil","GP Benham, MJ Bickle, JA Neufeld","Upscaling multiphase flow through heterogeneous porous media",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Upscaling the effect of heterogeneities in porous media is crucial for
macroscopic flow predictions, with widespread applications in energy and
environmental settings. In this study, we derive expressions for the upscaled
flow properties of a porous medium with a vertical heterogeneity, using a
combination of asymptotic analysis and numerical simulations. Then, we use
these upscaled expressions to describe the dynamic flooding of an aquifer,
where the classic Buckley-Leverett formulation is modified to account for
heterogeneities. In particular, we show that heterogeneities can modify
flooding speeds significantly, and we discuss the implications of these results
in the case of carbon dioxide sequestration.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:01:34 GMT""}]","2020-07-06"
"2007.01541","Michael D. Multerer","Helmut Harbrecht and Michael Multerer","A fast direct solver for nonlocal operators in wavelet coordinates",,,"10.1016/j.jcp.2020.110056",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we consider fast direct solvers for nonlocal operators. The
pivotal idea is to combine a wavelet representation of the system matrix,
yielding a quasi-sparse matrix, with the nested dissection ordering scheme. The
latter drastically reduces the fill-in during the factorization of the system
matrix by means of a Cholesky decomposition or an LU decomposition,
respectively. This way, we end up with the exact inverse of the compressed
system matrix with only a moderate increase of the number of nonzero entries in
the matrix.
  To illustrate the efficacy of the approach, we conduct numerical experiments
for different highly relevant applications of nonlocal operators: We consider
(i) the direct solution of boundary integral equations in three spatial
dimensions, issuing from the polarizable continuum model, (ii) a parabolic
problem for the fractional Laplacian in integral form and (iii) the fast
simulation of Gaussian random fields.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:02:34 GMT""}]","2021-02-03"
"2007.01542","Jeppe Theiss Kristensen","Jeppe Theiss Kristensen, Paolo Burelli","Strategies for Using Proximal Policy Optimization in Mobile Puzzle Games","10 pages, 8 figures, to be published in 2020 Foundations of Digital
  Games conference",,"10.1145/3402942.3402944",,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While traditionally a labour intensive task, the testing of game content is
progressively becoming more automated. Among the many directions in which this
automation is taking shape, automatic play-testing is one of the most promising
thanks also to advancements of many supervised and reinforcement learning (RL)
algorithms. However these type of algorithms, while extremely powerful, often
suffer in production environments due to issues with reliability and
transparency in their training and usage.
  In this research work we are investigating and evaluating strategies to apply
the popular RL method Proximal Policy Optimization (PPO) in a casual mobile
puzzle game with a specific focus on improving its reliability in training and
generalization during game playing.
  We have implemented and tested a number of different strategies against a
real-world mobile puzzle game (Lily's Garden from Tactile Games). We isolated
the conditions that lead to a failure in either training or generalization
during testing and we identified a few strategies to ensure a more stable
behaviour of the algorithm in this game genre.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:03:45 GMT""}]","2021-07-09"
"2007.01543","Thomas Haubner","Thomas Haubner, Andreas Brendel and Walter Kellermann","Online Supervised Acoustic System Identification exploiting Prelearned
  Local Affine Subspace Models",,,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present a novel algorithm for improved block-online
supervised acoustic system identification in adverse noise scenarios by
exploiting prior knowledge about the space of Room Impulse Responses (RIRs).
The method is based on the assumption that the variability of the unknown RIRs
is controlled by only few physical parameters, describing, e.g., source
position movements, and thus is confined to a low-dimensional manifold which is
modelled by a union of affine subspaces. The offsets and bases of the affine
subspaces are learned in advance from training data by unsupervised clustering
followed by Principal Component Analysis. We suggest to denoise the parameter
update of any supervised adaptive filter by projecting it onto an optimal
affine subspace which is selected based on a novel computationally efficient
approximation of the associated evidence. The proposed method significantly
improves the system identification performance of state-of-the-art algorithms
in adverse noise scenarios.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:05:03 GMT""}]","2020-07-06"
"2007.01544","Francisco Cruz","Adam Bignold, Francisco Cruz, Matthew E. Taylor, Tim Brys, Richard
  Dazeley, Peter Vamplew, Cameron Foale","A Conceptual Framework for Externally-influenced Agents: An Assisted
  Reinforcement Learning Review","33 pages, 9 figures",,"10.1007/s12652-021-03489-y",,"cs.AI cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A long-term goal of reinforcement learning agents is to be able to perform
tasks in complex real-world scenarios. The use of external information is one
way of scaling agents to more complex problems. However, there is a general
lack of collaboration or interoperability between different approaches using
external information. In this work, while reviewing externally-influenced
methods, we propose a conceptual framework and taxonomy for assisted
reinforcement learning, aimed at fostering collaboration by classifying and
comparing various methods that use external information in the learning
process. The proposed taxonomy details the relationship between the external
information source and the learner agent, highlighting the process of
information decomposition, structure, retention, and how it can be used to
influence agent learning. As well as reviewing state-of-the-art methods, we
identify current streams of reinforcement learning that use external
information in order to improve the agent's performance and its decision-making
process. These include heuristic reinforcement learning, interactive
reinforcement learning, learning from demonstration, transfer learning, and
learning from multiple sources, among others. These streams of reinforcement
learning operate with the shared objective of scaffolding the learner agent.
Lastly, we discuss further possibilities for future work in the field of
assisted reinforcement learning systems.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:07:31 GMT""},{""version"":""v2"",""created"":""Mon, 20 Sep 2021 03:00:40 GMT""}]","2021-09-21"
"2007.01545","Duojie Jia","Duojie Jia, Ji-Hai Pan, and Cheng-Qun Pang","A Mixing Coupling Scheme for Spectra of Singly Heavy Baryons with Spin-1
  Diquarks in P-waves","28 pages, 3 figures in total, with one new figure (FIG. 3) and one
  new section (Section VI) added in this enlarged version(V3). Due to twice
  extensions (Section V and Section VI added) including two newly added
  figures(FIG. 2 and FIG. 3), we also changed the title correspondingly","Eur. Phys. J. C 81 (2021) 434","10.1140/epjc/s10052-021-09205-6",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  A new scheme of state classification is proposed and applied to analyze
masses of the heavy baryons $\Omega_{Q}$, $\Sigma_{Q}$ and $\Xi_{Q}^{\prime}$
in P-waves. The results confirm all excited $\Omega_{c}$ and $\Omega_{b}$
baryons reported recently by LHCb to be bound states of a P-wave $ss$-diquark
and a respective charm or bottom quark, and thereby predict Regge trajectories
for more excited $\Omega_{c}$ and $\Omega_{b}$ baryons. We suggest one excited
{$J^{P}=5/2^{-}$} $\Omega_{b}$ state to be unseen by LHCb around $6352$ MeV,
and predict P-wave masses of all spin-partners of the odd-parity baryons
$\Sigma_{c}(2800)/\Xi_{c}^{\prime}(2942)$ and
$\Sigma_{b}(6097)$/$\Xi_{b}^{\prime }(6227)$. A computation is further given in
a relativized potential quark models to explain matched values of spin
couplings of all considered baryons, by which a scaling law for these spin
couplings is discussed.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:08:20 GMT""},{""version"":""v2"",""created"":""Sun, 11 Oct 2020 14:07:42 GMT""},{""version"":""v3"",""created"":""Fri, 5 Feb 2021 11:32:16 GMT""}]","2021-12-10"
"2007.01546","Yunpeng Zhai","Yunpeng Zhai, Qixiang Ye, Shijian Lu, Mengxi Jia, Rongrong Ji and
  Yonghong Tian","Multiple Expert Brainstorming for Domain Adaptive Person
  Re-identification","Accepted by ECCV'20",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Often the best performing deep neural models are ensembles of multiple
base-level networks, nevertheless, ensemble learning with respect to domain
adaptive person re-ID remains unexplored. In this paper, we propose a multiple
expert brainstorming network (MEB-Net) for domain adaptive person re-ID,
opening up a promising direction about model ensemble problem under
unsupervised conditions. MEB-Net adopts a mutual learning strategy, where
multiple networks with different architectures are pre-trained within a source
domain as expert models equipped with specific features and knowledge, while
the adaptation is then accomplished through brainstorming (mutual learning)
among expert models. MEB-Net accommodates the heterogeneity of experts learned
with different architectures and enhances discrimination capability of the
adapted re-ID model, by introducing a regularization scheme about authority of
experts. Extensive experiments on large-scale datasets (Market-1501 and
DukeMTMC-reID) demonstrate the superior performance of MEB-Net over the
state-of-the-arts.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:16:19 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 13:42:38 GMT""},{""version"":""v3"",""created"":""Mon, 13 Jul 2020 13:11:44 GMT""}]","2020-07-14"
"2007.01547","Robin M. Schmidt","Robin M. Schmidt, Frank Schneider, Philipp Hennig","Descending through a Crowded Valley - Benchmarking Deep Learning
  Optimizers","Raw results: https://github.com/SirRob1997/Crowded-Valley---Results",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Choosing the optimizer is considered to be among the most crucial design
decisions in deep learning, and it is not an easy one. The growing literature
now lists hundreds of optimization methods. In the absence of clear theoretical
guidance and conclusive empirical evidence, the decision is often made based on
anecdotes. In this work, we aim to replace these anecdotes, if not with a
conclusive ranking, then at least with evidence-backed heuristics. To do so, we
perform an extensive, standardized benchmark of fifteen particularly popular
deep learning optimizers while giving a concise overview of the wide range of
possible choices. Analyzing more than $50,000$ individual runs, we contribute
the following three points: (i) Optimizer performance varies greatly across
tasks. (ii) We observe that evaluating multiple optimizers with default
parameters works approximately as well as tuning the hyperparameters of a
single, fixed optimizer. (iii) While we cannot discern an optimization method
clearly dominating across all tested tasks, we identify a significantly reduced
subset of specific optimizers and parameter choices that generally lead to
competitive results in our experiments: Adam remains a strong contender, with
newer methods failing to significantly and consistently outperform it. Our
open-sourced results are available as challenging and well-tuned baselines for
more meaningful evaluations of novel optimization methods without requiring any
further computational efforts.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:19:36 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 10:12:48 GMT""},{""version"":""v3"",""created"":""Thu, 1 Oct 2020 13:27:59 GMT""},{""version"":""v4"",""created"":""Mon, 5 Oct 2020 17:21:01 GMT""},{""version"":""v5"",""created"":""Thu, 11 Feb 2021 18:17:58 GMT""},{""version"":""v6"",""created"":""Tue, 10 Aug 2021 23:17:21 GMT""}]","2021-08-12"
"2007.01548","Ammar Kamoona","Ammar Mansoor Kamoona, Amirali Khodadadian Gosta, Alireza
  Bab-Hadiashar, Reza Hoseinnezhad","Multiple Instance-Based Video Anomaly Detection using Deep Temporal
  Encoding-Decoding","The paper is under review",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a weakly supervised deep temporal encoding-decoding
solution for anomaly detection in surveillance videos using multiple instance
learning. The proposed approach uses both abnormal and normal video clips
during the training phase which is developed in the multiple instance framework
where we treat video as a bag and video clips as instances in the bag. Our main
contribution lies in the proposed novel approach to consider temporal relations
between video instances. We deal with video instances (clips) as a sequential
visual data rather than independent instances. We employ a deep temporal and
encoder network that is designed to capture spatial-temporal evolution of video
instances over time. We also propose a new loss function that is smoother than
similar loss functions recently presented in the computer vision literature,
and therefore; enjoys faster convergence and improved tolerance to local minima
during the training phase. The proposed temporal encoding-decoding approach
with modified loss is benchmarked against the state-of-the-art in simulation
studies. The results show that the proposed method performs similar to or
better than the state-of-the-art solutions for anomaly detection in video
surveillance applications.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:22:42 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 05:53:21 GMT""}]","2021-01-06"
"2007.01549","Zhenbo Xu","Zhenbo Xu, Wei Zhang, Xiao Tan, Wei Yang, Xiangbo Su, Yuchen Yuan,
  Hongwu Zhang, Shilei Wen, Errui Ding, Liusheng Huang","PointTrack++ for Effective Online Multi-Object Tracking and Segmentation","CVPR2020 MOTS Challenge Winner. PointTrack++ ranks first on KITTI
  MOTS (http://www.cvlibs.net/datasets/kitti/eval_mots.php)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multiple-object tracking and segmentation (MOTS) is a novel computer vision
task that aims to jointly perform multiple object tracking (MOT) and instance
segmentation. In this work, we present PointTrack++, an effective on-line
framework for MOTS, which remarkably extends our recently proposed PointTrack
framework. To begin with, PointTrack adopts an efficient one-stage framework
for instance segmentation, and learns instance embeddings by converting compact
image representations to un-ordered 2D point cloud. Compared with PointTrack,
our proposed PointTrack++ offers three major improvements. Firstly, in the
instance segmentation stage, we adopt a semantic segmentation decoder trained
with focal loss to improve the instance selection quality. Secondly, to further
boost the segmentation performance, we propose a data augmentation strategy by
copy-and-paste instances into training images. Finally, we introduce a better
training strategy in the instance association stage to improve the
distinguishability of learned instance embeddings. The resulting framework
achieves the state-of-the-art performance on the 5th BMTT MOTChallenge.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:28:37 GMT""}]","2020-07-06"
"2007.01550","Zhenbo Xu","Zhenbo Xu, Wei Zhang, Xiao Tan, Wei Yang, Huan Huang, Shilei Wen,
  Errui Ding, Liusheng Huang","Segment as Points for Efficient Online Multi-Object Tracking and
  Segmentation","ECCV2020 ORAL (top 2%). Code already available at
  https://github.com/detectRecog/PointTrack. A highly effective method for
  learning features based on instance segments",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current multi-object tracking and segmentation (MOTS) methods follow the
tracking-by-detection paradigm and adopt convolutions for feature extraction.
However, as affected by the inherent receptive field, convolution based feature
extraction inevitably mixes up the foreground features and the background
features, resulting in ambiguities in the subsequent instance association. In
this paper, we propose a highly effective method for learning instance
embeddings based on segments by converting the compact image representation to
un-ordered 2D point cloud representation. Our method generates a new
tracking-by-points paradigm where discriminative instance embeddings are
learned from randomly selected points rather than images. Furthermore, multiple
informative data modalities are converted into point-wise representations to
enrich point-wise features. The resulting online MOTS framework, named
PointTrack, surpasses all the state-of-the-art methods including 3D tracking
methods by large margins (5.4% higher MOTSA and 18 times faster over
MOTSFusion) with the near real-time speed (22 FPS). Evaluations across three
datasets demonstrate both the effectiveness and efficiency of our method.
Moreover, based on the observation that current MOTS datasets lack crowded
scenes, we build a more challenging MOTS dataset named APOLLO MOTS with higher
instance density. Both APOLLO MOTS and our codes are publicly available at
https://github.com/detectRecog/PointTrack.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:29:35 GMT""}]","2020-07-06"
"2007.01551","Taegyu Kim","Taegyu Kim and Phillial Oh","A Vanishingly Small Vector Mass from Anisotropy of Higher Dimensional
  Spacetime","References are added",,"10.3938/jkps.77.463",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider five-dimensional massive vector-gravity theory which is based on
the foliation preserving diffeomorphism and anisotropic conformal invariance.
It does not have an intrinsic scale and the only relevant parameter is the
anisotropic factor $z$ which characterizes the degree of anisotropy between the
four-dimensional spacetime and the extra dimension. We assume that physical
scale $M_*$ emerges as a consequence of spontaneous conformal symmetry breaking
of vacuum solution. It is demonstrated that a very small mass for the vector
particle compared to $M_*$ can be achieved with a relatively mild adjustment of
the parameter $z$. At the same time, it is also observed that the motion along
the extra dimension can be highly suppressed and the five-dimensional theory
can be effectively reduced to four-dimensional spacetime.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:32:19 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jul 2020 04:56:35 GMT""}]","2020-10-28"
"2007.01552","Achille Basile","Achille Basile, Surekha Rao, and K.P.S. Bhaskara Rao","Anonymous, non-manipulable, binary social choice","JEL Code: D71",,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let V be a finite society whose members express weak orderings (hence also
indifference, possibly) about two alternatives. We show a simple representation
formula that is valid for all, and only, anonymous, non-manipulable, binary
social choice functions on V . The number of such functions is $2^{n+1}$ if V
contains $n$ agents.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:36:33 GMT""}]","2020-07-06"
"2007.01553","James Jackman","James A. G. Jackman, Peter J. Wheatley, Jack S. Acton, David R.
  Anderson, Claudia Belardi, Matthew R. Burleigh, Sarah L. Casewell, Philipp
  Eigm\""uller, Samuel Gill, Edward Gillen, Michael R. Goad, Andrew Grange,
  Simon T. Hodgkin, James S. Jenkins, James McCormac, Maximiliano Moyano,
  Didier Queloz, Liam Raynard, Rosanna H. Tilbrook, Christopher A. Watson,
  Richard G. West","NGTS clusters survey -- II. White-light flares from the youngest stars
  in Orion","10 pages, 5 figures, 5 tables. Accepted for publication in the
  Monthly Notices of the Royal Astronomical Society",,"10.1093/mnras/staa1971",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the detection of high energy white-light flares from pre-main
sequence stars associated with the Orion complex, observed as part of the Next
Generation Transit Survey (NGTS). With energies up to $5.2\times10^{35}$ erg
these flares are some of the most energetic white-light flare events seen to
date. We have used the NGTS observations of flaring and non-flaring stars to
measure the average flare occurrence rate for 4 Myr M0-M3 stars. We have also
combined our results with those from previous studies to predict average rates
for flares above $1\times10^{35}$ ergs for early M stars in nearby young
associations.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:42:26 GMT""}]","2020-07-15"
"2007.01554","The ATLAS Collaboration","ATLAS Collaboration","Measurement of single top-quark production in association with a $W$
  boson in the single-lepton channel at $\sqrt{s} = 8$ TeV with the ATLAS
  detector","42 pages in total, author list starting page 26, 8 figures, 3 tables,
  published in Eur. Phys. J C 81 (2021) 720. All figures including auxiliary
  figures are available at :
  http://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/TOPQ-2016-06","Eur. Phys. J. C 81 (2021) 720","10.1140/epjc/s10052-021-09371-7","CERN-EP-2019-221","hep-ex","http://creativecommons.org/licenses/by/4.0/","  The production cross-section of a top quark in association with a $W$ boson
is measured using proton-proton collisions at $\sqrt{s} = 8$ TeV. The dataset
corresponds to an integrated luminosity of 20.2 fb$^{-1}$, and was collected in
2012 by the ATLAS detector at the Large Hadron Collider at CERN. The analysis
is performed in the single-lepton channel. Events are selected by requiring one
isolated lepton (electron or muon) and at least three jets. A neural network is
trained to separate the $tW$ signal from the dominant $t\bar{t}$ background.
The cross-section is extracted from a binned profile maximum-likelihood fit to
a two-dimensional discriminant built from the neural-network output and the
invariant mass of the hadronically decaying $W$ boson. The measured
cross-section is $\sigma_{tW} = 26 \pm 7$ pb, in good agreement with the
Standard Model expectation.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:45:36 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 12:05:32 GMT""}]","2021-08-24"
"2007.01555","Carlos Segarra","Carlos Segarra, Ricard Delgado-Gonzalo, Valerio Schiavoni","MQT-TZ: Secure MQTT Broker for Biomedical Signal Processing on the Edge","The definitive version is published in the proceedings of the 2020
  Medical Informatics Europe Conference (MIE2020)","Volume 270: Digital Personalized Health and Medicine 2020 - Pages
  332 - 336","10.3233/SHTI200177",,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Physical health records belong to healthcare providers, but the information
contained within belongs to each patient. In an increasing manner, more
health-related data is being acquired by wearables and other IoT devices
following the ever-increasing trend of the ""Quantified Self"". Even though data
protection regulations (e.g., GDPR) encourage the usage of privacy-preserving
processing techniques, most of the current IoT infrastructure was not
originally conceived for such purposes. One of the most used communication
protocols, MQTT, is a lightweight publish-subscribe protocol commonly used in
the Edge and IoT applications. In MQTT, the broker must process data on clear
text, hence exposing a large attack surface for a malicious agent to
steal/tamper with this health-related data. In this paper, we introduce MQT-TZ,
a secure MQTT broker leveraging Arm TrustZone, a popular Trusted Execution
Environment (TEE). We define a mutual TLS-based handshake and a two-layer
encryption for end-to-end security using the TEE as a trusted proxy. We provide
quantitative evaluation of our open-source PoC on streaming ECGs in real time
and highlight the trade-offs.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:47:46 GMT""}]","2020-07-06"
"2007.01556","Bin Wang","Bin Wang, Bing Xue, Mengjie Zhang","Surrogate-assisted Particle Swarm Optimisation for Evolving
  Variable-length Transferable Blocks for Image Classification",,,,,"cs.CV cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep convolutional neural networks have demonstrated promising performance on
image classification tasks, but the manual design process becomes more and more
complex due to the fast depth growth and the increasingly complex topologies of
convolutional neural networks. As a result, neural architecture search has
emerged to automatically design convolutional neural networks that outperform
handcrafted counterparts. However, the computational cost is immense, e.g.
22,400 GPU-days and 2,000 GPU-days for two outstanding neural architecture
search works named NAS and NASNet, respectively, which motivates this work. A
new effective and efficient surrogate-assisted particle swarm optimisation
algorithm is proposed to automatically evolve convolutional neural networks.
This is achieved by proposing a novel surrogate model, a new method of creating
a surrogate dataset and a new encoding strategy to encode variable-length
blocks of convolutional neural networks, all of which are integrated into a
particle swarm optimisation algorithm to form the proposed method. The proposed
method shows its effectiveness by achieving competitive error rates of 3.49% on
the CIFAR-10 dataset, 18.49% on the CIFAR-100 dataset, and 1.82% on the SVHN
dataset. The convolutional neural network blocks are efficiently learned by the
proposed method from CIFAR-10 within 3 GPU-days due to the acceleration
achieved by the surrogate model and the surrogate dataset to avoid the training
of 80.1% of convolutional neural network blocks represented by the particles.
Without any further search, the evolved blocks from CIFAR-10 can be
successfully transferred to CIFAR-100 and SVHN, which exhibits the
transferability of the block learned by the proposed method.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:48:21 GMT""}]","2020-07-06"
"2007.01557","Yongpeng Zhang","Y.Y. Gan, M.Y. Guan, Y.P.Zhang, P. Zhang, C.G. Yang, Q. Zhao, Y.T.
  Wei, W.X. Xiong","Using $^{22}$Na and $^{83{\rm m}}$Kr to calibrate and study the
  properties of scintillation in xenon-doped liquid argon","17 pages, 16 figures",,"10.1088/1748-0221/15/12/P12007",,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have measured the properties of scintillation light in liquid argon doped
with xenon concentrations from 165 ppm to 10,010 ppm using a $^{22}$Na source.
The energy transfer processes in the xenon-doped liquid argon are discussed in
detail, and a new waveform model is established and used to fit the average
waveform. The time profile of the scintillation photon in the xenon-doped
liquid argon and of the TPB emission are presented. The quantities of
xenon-doped are controlled by a Mass Flow Controller which is calibrated via a
Redusial Gas Analyzer to ensure that the xenon concentration is accurate. In
addition, a successful test of $^{83{\rm m}}$Kr as a calibration source has
been implemented in the xenon-doped liquid argon detector for the first time.
By comparing the light yield of the $^{22}$Na and $^{83{\rm m}}$Kr, it can be
concluded that the scintillation efficiency is almost same over the range of
41.5 keV to 511 keV.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:49:14 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jul 2020 13:48:39 GMT""},{""version"":""v3"",""created"":""Mon, 26 Oct 2020 02:00:14 GMT""}]","2021-02-03"
"2007.01558","Alexander Solntsev S","Nils Bernhardt, Sejeong Kim, Johannes E. Froch, Simon White, Ngoc My
  Hanh Duong, Zhe He, Bo Chen, Jin Liu, Igor Aharonovich, Alexander S. Solntsev","Large few-layer hexagonal boron nitride flakes for nonlinear optics",,,"10.1364/OL.416564",,"physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hexagonal boron nitride (hBN) is a layered dielectric material with a wide
range of applications in optics and photonics. In this work, we demonstrate a
fabrication method for few-layer hBN flakes with areas up to 5000 $\rm \mu m$.
We show that hBN in this form can be integrated with photonic microstructures:
as an example, we use a circular Bragg grating (CBG). The layer quality of the
exfoliated hBN flake on a CBG is confirmed by second-harmonic generation (SHG)
microscopy. We show that the SHG signal is uniform across the hBN sample
outside the CBG and is amplified in the centre of the CBG.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:49:37 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jul 2020 06:21:56 GMT""}]","2021-02-24"
"2007.01559","Sara Tahery","Sara Tahery, Liping Zou and Xurong Chen","A comparison of condensate mass of QCD vacuum between Wilson line
  approach and Schwinger effect","14 pages, 3 figures","2021 Chinese Phys. C 45 043107","10.1088/1674-1137/abe03b",,"hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By duality approach, we study condensate mass of QCD vacuum via dilaton wall
background in presence of parameter $c$ which represents the gluon condensation
in holographic set up. First from Wilson line calculation we find $m^2_0$
(condensate parameter in mixed nonlocal condensation) whose behavior mimics
that of QCD. The value of $m^2_0$ that we find by this approach, is in
agreement with QCD data. In the second step we consider produced mass m via
Schwinger effect mechanism in presence of parameter $c$. We show that generally
gluon condensation contribute mass dominantly and produced mass via Schwinger
effect is suppressed by $m_0$ .
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:51:41 GMT""},{""version"":""v2"",""created"":""Sun, 30 Aug 2020 06:34:19 GMT""},{""version"":""v3"",""created"":""Tue, 6 Oct 2020 05:18:22 GMT""},{""version"":""v4"",""created"":""Thu, 7 Jan 2021 03:52:32 GMT""}]","2021-03-22"
"2007.01560","Alistair Stewart","Alistair Stewart and Eleftherios Kokoris-Kogia","GRANDPA: a Byzantine Finality Gadget",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classic Byzantine fault-tolerant consensus protocols forfeit liveness in the
face of asynchrony in order to preserve safety, whereas most deployed
blockchain protocols forfeit safety in order to remain live. In this work, we
achieve the best of both worlds by proposing a novel abstractions called the
finality gadget. A finality gadget allows for transactions to always
optimistically commit but informs the clients that these transactions might be
unsafe. As a result, a blockchain can execute transactions optimistically and
only commit them after they have been sufficiently and provably audited. In
this work, we formally model the finality gadget abstraction, prove that it is
impossible to solve it deterministically in full asynchrony (even though it is
stronger than consensus) and provide a partially synchronous protocol which is
currently securing a major blockchain. This way we show that the protocol
designer can decouple safety and liveness in order to speed up recovery from
failures. We believe that there can be other types of finality gadgets that
provide weaker safety (e.g., probabilistic) in order to gain more efficiency
and this can depend on the probability that the network is not in synchrony.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:05:40 GMT""}]","2020-07-06"
"2007.01561","Alberto Giaretta","Matthias Forstmann, Alberto Giaretta, and Jennifer Renoux","Users' Concern for Privacy in Context-Aware Reasoning Systems","8 pages, 4 figures",,,,"cs.CY cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context-aware reasoning systems allow drawing sophisticated inferences about
users' behaviour and physiological condition, by aggregating data from
seemingly unrelated sources. We conducted a general population online survey to
evaluate users' concern about the privacy of data gathered by these systems. We
found that people are more concerned about third parties accessing data
gathered by environmental sensors as compared to physiological sensors.
Participants also indicated greater concern about unfamiliar third parties
(e.g., private companies) as opposed to familiar third parties (e.g.,
relatives). We further found that these concerns are predicted and (to a lesser
degree) causally affected by people's beliefs about how much can be inferred
from these types of data, as well as by their background in computer science.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:13:57 GMT""}]","2020-07-06"
"2007.01562","Xu Chen","Shuai Yu and Xu Chen and Shuai Wang and Lingjun Pu and Di Wu","An Edge Computing-based Photo Crowdsourcing Framework for Real-time 3D
  Reconstruction","Accepted by IEEE Transactions on Mobile Computing",,,,"cs.NI cs.DC eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image-based three-dimensional (3D) reconstruction utilizes a set of photos to
build 3D model and can be widely used in many emerging applications such as
augmented reality (AR) and disaster recovery. Most of existing 3D
reconstruction methods require a mobile user to walk around the target area and
reconstruct objectives with a hand-held camera, which is inefficient and
time-consuming. To meet the requirements of delay intensive and resource hungry
applications in 5G, we propose an edge computing-based photo crowdsourcing
(EC-PCS) framework in this paper. The main objective is to collect a set of
representative photos from ubiquitous mobile and Internet of Things (IoT)
devices at the network edge for real-time 3D model reconstruction, with network
resource and monetary cost considerations. Specifically, we first propose a
photo pricing mechanism by jointly considering their freshness, resolution and
data size. Then, we design a novel photo selection scheme to dynamically select
a set of photos with the required target coverage and the minimum monetary
cost. We prove the NP-hardness of such problem, and develop an efficient
greedy-based approximation algorithm to obtain a near-optimal solution.
Moreover, an optimal network resource allocation scheme is presented, in order
to minimize the maximum uploading delay of the selected photos to the edge
server. Finally, a 3D reconstruction algorithm and a 3D model caching scheme
are performed by the edge server in real time. Extensive experimental results
based on real-world datasets demonstrate the superior performance of our EC-PCS
system over the existing mechanisms.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:16:07 GMT""}]","2020-07-06"
"2007.01563","Minghua Chen Professor","Jiankang Shi and Minghua Chen","Correction of BDFk for fractional Feynman-Kac equation with L\'{e}vy
  flight","20pages","Journal of Scientific Computing (2020)","10.1007/s10915-020-01331-9",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present the correction formulas of the $k$-step BDF
convolution quadrature at the starting $k-1$ steps for the fractional
Feynman-Kac equation with L\'{e}vy flight.
  The desired $k$th-order convergence rate can be achieved with nonsmooth data.
Based on the idea of [{\sc Jin, Li, and Zhou}, SIAM J. Sci. Comput., 39 (2017),
A3129--A3152], we provide a detailed convergence analysis for the correction
BDF$k$ scheme. The numerical experiments with spectral method are given to
illustrate the effectiveness of the presented method. To the best of our
knowledge, this is the first proof of the convergence analysis and numerical
verified the sapce fractional evolution equation with correction BDF$k$.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:17:22 GMT""}]","2020-10-20"
"2007.01564","Ioannis Kontogiannis","I. Kontogiannis, E. Dineva, A. Diercke, M. Verma, C. Kuckein, H.
  Balthasar, C. Denker","High-resolution spectroscopy of an erupting minifilament and its impact
  on the nearby chromosphere","15 pages, 8 Figures, submitted to ApJ",,"10.3847/1538-4357/aba117",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the evolution of a mini-filament eruption in a quiet region at the
center of the solar disk and its impact on the ambient atmosphere. We used
high-spectral resolution imaging spectroscopy in H$\alpha$ acquired by the
echelle spectrograph of the Vacuum Tower Telescope (VTT), Tenerife, Spain,
photospheric magnetic field observations from the Helioseismic and Magnetic
Imager (HMI), and UV/EUV imaging from the Atmospheric Imaging Assembly (AIA) of
the Solar Dynamics Observatory (SDO). The H$\alpha$ line profiles were
noise-stripped using Principal Component Analysis (PCA) and then inverted to
produce physical and cloud model parameter maps. The minifilament formed
between small-scale, opposite-polarity magnetic features through a series of
small reconnection events and it erupted within an hour after its appearance in
H$\alpha$. Its development and eruption exhibited similarities with large-scale
erupting filaments, indicating the action of common mechanisms. Its eruption
took place in two phases, namely a slow rise and a fast expansion, and it
produced a coronal dimming, before the minifilament disappeared. During its
eruption we detected a complicated velocity pattern, indicative of a twisted,
thread-like structure. Part of its material returned to the chromosphere
producing observable effects on nearby low-lying magnetic structures. Cloud
model analysis showed that the minifilament was initially similar to other
chromospheric fine structures, in terms of optical depth, source function and
Doppler width, but it resembled a large-scale filament on its course to
eruption. High spectral resolution observations of the chromosphere can provide
a wealth of information regarding the dynamics and properties of minifilaments
and their interactions with the surrounding atmosphere.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:20:17 GMT""}]","2020-08-12"
"2007.01565","Zahra Khatibi","Zahra Khatibi, Roya Ahemeh, Mehdi Kargarian","Excitonic insulator phase and dynamics of condensate in a topological
  one-dimensional model","12 pages, 8 figures","Phys. Rev. B 102, 245121 (2020)","10.1103/PhysRevB.102.245121",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We employ mean-field approximation to investigate the interplay between the
nontrivial band topology and the formation of excitonic insulator (EI) in a
one-dimensional chain of atomic $s-p$ orbitals in the presence of repulsive
inter-orbital Coulomb interaction. We find that our model, in a non-interacting
regime, admits topological and trivial insulator phases, whereas, in strong
Coulomb interaction limit, the chiral symmetry is broken and the system
undergoes a topological-excitonic insulator phase transition. The latter phase
transition stems from an orbital pseudomagnetization and band inversion around
$k=0$. Our findings show that contrary to the topological insulator phase,
electron-hole bound states do not form exciton condensate in the trivial band
insulator phase due to lack of band inversion. Interestingly, the EI phase in
low $s-p$ hybridization limit hosts a Bardeen-Cooper-Schrieffer
(BCS)/Bose-Einstein condensation (BEC) crossover. Irradiated by a pump pulse,
our findings reveal that the oscillations of exciton states strongly depend on
the frequency of the laser pulse. We further explore the signatures of dynamics
of the exciton condensate in optical measurements.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:22:46 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 05:53:37 GMT""},{""version"":""v3"",""created"":""Thu, 5 Nov 2020 22:16:59 GMT""}]","2021-01-04"
"2007.01566","Bo Wu","Bo Wu, Meng Yu, Lianwu Chen, Yong Xu, Chao Weng, Dan Su, and Dong Yu","Distortionless Multi-Channel Target Speech Enhancement for Overlapped
  Speech Recognition",,,,,"eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Speech enhancement techniques based on deep learning have brought significant
improvement on speech quality and intelligibility. Nevertheless, a large gain
in speech quality measured by objective metrics, such as perceptual evaluation
of speech quality (PESQ), does not necessarily lead to improved speech
recognition performance due to speech distortion in the enhancement stage. In
this paper, a multi-channel dilated convolutional network based frequency
domain modeling is presented to enhance target speaker in the far-field, noisy
and multi-talker conditions. We study three approaches towards distortionless
waveforms for overlapped speech recognition: estimating complex ideal ratio
mask with an infinite range, incorporating the fbank loss in a multi-objective
learning and finetuning the enhancement model by an acoustic model.
Experimental results proved the effectiveness of all three approaches on
reducing speech distortions and improving recognition accuracy. Particularly,
the jointly tuned enhancement model works very well with other standalone
acoustic model on real test data.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:23:46 GMT""}]","2020-07-06"
"2007.01567","Eric Nardon","E. Nardon, A. Matsuyama, D. Hu, F. Wieschollek","Post-Thermal Quench Shattered Pellet Injection for small Runaway
  Electron seed depletion in ITER",,,,,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The possibility of using Shattered Pellet Injection(s) after the Thermal
Quench phase of an ITER disruption in order to deplete Runaway Electron (RE)
seeds before they can substantially avalanche is studied. Analytical and
numerical estimates of the required injection rate for shards to penetrate into
the forming RE beam and stop REs are given. How much material could be
assimilated before the Current Quench (CQ) becomes too short is also estimated.
It appears that, if Hydrogen pellets were used, the required number of pellets
to be injected during the CQ would be prohibitive, at least considering the
present design of the ITER Disruption Mitigation System (DMS). For Neon or
Argon, the required number of pellets, although large, might be within reach of
the ITER DMS, but the assimilated fraction would have to be very small. Other
materials may be better suited but would require a modification of the ITER
DMS.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:26:49 GMT""}]","2020-07-06"
"2007.01568","Yikun Li","Yikun Li, Mohamed Soliman, Paris Avgeriou","Identification and Remediation of Self-Admitted Technical Debt in Issue
  Trackers","The 46th Euromicro Conference on Software Engineering and Advanced
  Applications (SEAA)",,"10.1109/SEAA51224.2020.00083",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Technical debt refers to taking shortcuts to achieve short-term goals, which
might negatively influence software maintenance in the long-term. There is
increasing attention on technical debt that is admitted by developers in source
code comments (termed as self-admitted technical debt or SATD). But SATD in
issue trackers is relatively unexplored. We performed a case study, where we
manually examined 500 issues from two open source projects (i.e. Hadoop and
Camel), which contained 152 SATD items. We found that: 1) eight types of
technical debt are identified in issues, namely architecture, build, code,
defect, design, documentation, requirement, and test debt; 2) developers
identify technical debt in issues in three different points in time, and a
small part is identified by its creators; 3) the majority of technical debt is
paid off, 4) mostly by those who identified it or created it; 5) the median
time and average time to repay technical debt are 872.3 and 25.0 hours
respectively.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:29:52 GMT""},{""version"":""v2"",""created"":""Thu, 27 Aug 2020 10:57:25 GMT""},{""version"":""v3"",""created"":""Sat, 29 Aug 2020 21:41:37 GMT""}]","2022-02-07"
"2007.01569","Nikolaos Chalmoukis","Nikolaos Chalmoukis, Michael Hartz","Totally null sets and capacity in Dirichlet type spaces","20 pages",,"10.1112/jlms.12617",,"math.FA math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of Dirichlet type spaces on the unit ball of $\mathbb{C}^d$,
also known as Hardy-Sobolev or Besov-Sobolev spaces, we compare two notions of
smallness for compact subsets of the unit sphere. We show that the functional
analytic notion of being totally null agrees with the potential theoretic
notion of having capacity zero. In particular, this applies to the classical
Dirichlet space on the unit disc and logarithmic capacity. In combination with
a peak interpolation result of Davidson and the second named author, we obtain
strengthenings of boundary interpolation theorems of Peller and Khrushch\""{e}v
and of Cohn and Verbitsky.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:29:56 GMT""},{""version"":""v2"",""created"":""Mon, 24 Oct 2022 14:37:18 GMT""}]","2023-05-05"
"2007.01570","Johannes Gasteiger","Aleksandar Bojchevski, Johannes Gasteiger, Bryan Perozzi, Amol Kapoor,
  Martin Blais, Benedek R\'ozemberczki, Michal Lukasik, Stephan G\""unnemann","Scaling Graph Neural Networks with Approximate PageRank","Published as a Conference Paper at ACM SIGKDD 2020. Author name
  changed from Johannes Klicpera to Johannes Gasteiger",,"10.1145/3394486.3403296",,"cs.LG cs.SI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph neural networks (GNNs) have emerged as a powerful approach for solving
many network mining tasks. However, learning on large graphs remains a
challenge - many recently proposed scalable GNN approaches rely on an expensive
message-passing procedure to propagate information through the graph. We
present the PPRGo model which utilizes an efficient approximation of
information diffusion in GNNs resulting in significant speed gains while
maintaining state-of-the-art prediction performance. In addition to being
faster, PPRGo is inherently scalable, and can be trivially parallelized for
large datasets like those found in industry settings. We demonstrate that PPRGo
outperforms baselines in both distributed and single-machine training
environments on a number of commonly used academic graphs. To better analyze
the scalability of large-scale graph learning methods, we introduce a novel
benchmark graph with 12.4 million nodes, 173 million edges, and 2.8 million
node features. We show that training PPRGo from scratch and predicting labels
for all nodes in this graph takes under 2 minutes on a single machine, far
outpacing other baselines on the same graph. We discuss the practical
application of PPRGo to solve large-scale node classification problems at
Google.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:30:07 GMT""},{""version"":""v2"",""created"":""Tue, 5 Apr 2022 12:41:35 GMT""}]","2022-04-06"
"2007.01571","Zhenwei He","Zhenwei He and Lei Zhang","Domain Adaptive Object Detection via Asymmetric Tri-way Faster-RCNN","The paper is accepted in ECCV2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventional object detection models inevitably encounter a performance drop
as the domain disparity exists. Unsupervised domain adaptive object detection
is proposed recently to reduce the disparity between domains, where the source
domain is label-rich while the target domain is label-agnostic. The existing
models follow a parameter shared siamese structure for adversarial domain
alignment, which, however, easily leads to the collapse and out-of-control risk
of the source domain and brings negative impact to feature adaption. The main
reason is that the labeling unfairness (asymmetry) between source and target
makes the parameter sharing mechanism unable to adapt. Therefore, in order to
avoid the source domain collapse risk caused by parameter sharing, we propose
an asymmetric tri-way Faster-RCNN (ATF) for domain adaptive object detection.
Our ATF model has two distinct merits: 1) A ancillary net supervised by source
label is deployed to learn ancillary target features and simultaneously
preserve the discrimination of source domain, which enhances the structural
discrimination (object classification vs. bounding box regression) of domain
alignment. 2) The asymmetric structure consisting of a chief net and an
independent ancillary net essentially overcomes the parameter sharing aroused
source risk collapse. The adaption safety of the proposed ATF detector is
guaranteed. Extensive experiments on a number of datasets, including
Cityscapes, Foggy-cityscapes, KITTI, Sim10k, Pascal VOC, Clipart and
Watercolor, demonstrate the SOTA performance of our method.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:30:18 GMT""}]","2020-07-06"
"2007.01572","Andrey Mazanik","I. V. Bobkova, A. M. Bobkov, I. R. Rahmonov, A. A. Mazanik, K.
  Sengupta, and Yu. M. Shukrinov","Magnetization reversal in S/F/S Josephson junctions on a 3D topological
  insulator","8 pages, 6 figures","Phys. Rev. B 102, 134505 (2020)","10.1103/PhysRevB.102.134505",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a magnetization reversal by an electric current pulse in a
superconductor/insulating ferromagnet/superconductor Josephson junction placed
on top of a 3D topological insulator. It is demonstrated that such a system is
perspective for low-dissipative spintronics because of the strong spin-momentum
locking in the TI surface states. This property provides an ideally strong
coupling between the orbital and spin degrees of freedom thus giving a
possibility of efficient reversal of the magnetic moment by current pulse with
amplitude lower than the critical current, that results in strongly reduced
energy dissipation. The underlying physical mechanism of the reversal is
discussed. The influence of the magnetic anisotropy on the controllability of
the reversal by the pulse duration is investigated. In addition, a way of a
simultaneous electrical detection of the reversal is proposed.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:30:47 GMT""}]","2020-10-21"
"2007.01573","Julien Bremont","Julien Br\'emont (LAMA)","Planar random walk in a stratified quasi-periodic environment",,,,,"math.DS math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the recurrence of inhomogeneous Markov chains in the plane, when the
environment is horizontally stratified and the heterogeneity of quasi-periodic
type.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:31:27 GMT""},{""version"":""v2"",""created"":""Fri, 11 Dec 2020 10:54:23 GMT""}]","2020-12-14"
"2007.01574","Zhenjie Li","Song He, Zhenjie Li","A Note on Letters of Yangian Invariants","15 pages, 6 figures; v3: minor updates to match the published version
  in JHEP",,"10.1007/JHEP02(2021)155",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by reformulating Yangian invariants in planar ${\cal N}=4$ SYM
directly as $d\log$ forms on momentum-twistor space, we propose a purely
algebraic problem of determining the arguments of the $d\log$'s, which we call
""letters"", for any Yangian invariant. These are functions of momentum twistors
$Z$'s, given by the positive coordinates $\alpha$'s of parametrizations of the
matrix $C(\alpha)$, evaluated on the support of polynomial equations $C(\alpha)
\cdot Z=0$. We provide evidence that the letters of Yangian invariants are
related to the cluster algebra of Grassmannian $G(4,n)$, which is relevant for
the symbol alphabet of $n$-point scattering amplitudes. For $n=6,7$, the
collection of letters for all Yangian invariants contains the cluster ${\cal
A}$ coordinates of $G(4,n)$. We determine algebraic letters of Yangian
invariant associated with any ""four-mass"" box, which for $n=8$ reproduce the
$18$ multiplicative-independent, algebraic symbol letters discovered recently
for two-loop amplitudes.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:38:00 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 15:18:21 GMT""},{""version"":""v3"",""created"":""Wed, 24 Feb 2021 11:25:06 GMT""}]","2021-03-17"
"2007.01575","S\""oren Dittmer","S\""oren Dittmer, Carola-Bibiane Sch\""onlieb, Peter Maass","Ground Truth Free Denoising by Optimal Transport",,,,,"cs.CV cs.NE math.FA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a learned unsupervised denoising method for arbitrary types of
data, which we explore on images and one-dimensional signals. The training is
solely based on samples of noisy data and examples of noise, which --
critically -- do not need to come in pairs. We only need the assumption that
the noise is independent and additive (although we describe how this can be
extended). The method rests on a Wasserstein Generative Adversarial Network
setting, which utilizes two critics and one generator.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:39:25 GMT""}]","2020-07-06"
"2007.01576","Boris Kolev","Boris Desmorat (DALEMBERT), Marc Olive (LMT), Nicolas Auffray (MSME),
  Rodrigue Desmorat (LMT), Boris Kolev (LMT)","Computation of minimal covariants bases for 2D coupled constitutive laws",,,,,"math.RT physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We produce minimal integrity bases for both isotropic and hemitropic
invariant algebras (and more generally covariant algebras) of most common
bidimensional constitutive tensors and -- possibly coupled -- laws, including
piezoelectricity law, photoelasticity, Eshelby and elasticity tensors, complex
viscoelasticity tensor, Hill elasto-plasticity, and (totally symmetric) fabric
tensors up to twelfth-order. The concept of covariant, which extends that of
invariant is explained and motivated. It appears to be much more useful for
applications. All the tools required to obtain these results are explained in
detail and a cleaning algorithm is formulated to achieve minimality in the
isotropic case. The invariants and covariants are first expressed in complex
forms and then in tensorial forms, thanks to explicit translation formulas
which are provided. The proposed approach also applies to any $n$-uplet of
bidimensional constitutive tensors.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:42:51 GMT""}]","2020-07-06"
"2007.01577","Xavier Friederich","Xavier Friederich (IRMA)","Non dispersive solutions of the generalized KdV equations are typically
  multi-solitons",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider solutions of the generalized Korteweg-de Vries equations (gKdV)
which are non dispersive in some sense (in the spirit of [18]) and which remain
close to multi-solitons. We show that these solutions are necessarily pure
multi-solitons. For the Korteweg-de Vries equation (KdV) and the modified
Korteweg-de Vries equation (mKdV) in particular, we obtain a characterization
of multi-solitons and multi-breathers in terms of non-dispersion.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:45:40 GMT""}]","2020-07-06"
"2007.01578","Apostolos Chalkis","Apostolos Chalkis, Vissarion Fisikopoulos","Volesti: Volume Approximation and Sampling for Convex Polytopes in R","19 pages, 8 figures, 3 tables","The R Journal 13:2 (2021) 561-577","10.32614/RJ-2021-077",,"stat.CO cs.CG cs.MS","http://creativecommons.org/licenses/by/4.0/","  Sampling from high dimensional distributions and volume approximation of
convex bodies are fundamental operations that appear in optimization, finance,
engineering, artificial intelligence and machine learning. In this paper we
present volesti, an R package that provides efficient, scalable algorithms for
volume estimation, uniform and Gaussian sampling from convex polytopes. volesti
scales to hundreds of dimensions, handles efficiently three different types of
polyhedra and provides non existing sampling routines to R. We demonstrate the
power of volesti by solving several challenging problems using the R language.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:47:14 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 08:19:28 GMT""},{""version"":""v3"",""created"":""Sat, 4 Sep 2021 10:05:01 GMT""}]","2022-02-17"
"2007.01579","Thomas Haubner","Thomas Haubner, Andreas Brendel, Mohamed Elminshawi and Walter
  Kellermann","Noise-Robust Adaptation Control for Supervised Acoustic System
  Identification Exploiting A Noise Dictionary",,,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a noise-robust adaptation control strategy for block-online
supervised acoustic system identification by exploiting a noise dictionary. The
proposed algorithm takes advantage of the pronounced spectral structure which
characterizes many types of interfering noise signals. We model the noisy
observations by a linear Gaussian Discrete Fourier Transform-domain state space
model whose parameters are estimated by an online generalized
Expectation-Maximization algorithm. Unlike all other state-of-the-art
approaches we suggest to model the covariance matrix of the observation
probability density function by a dictionary model. We propose to learn the
noise dictionary from training data, which can be gathered either offline or
online whenever the system is not excited, while we infer the activations
continuously. The proposed algorithm represents a novel machine-learning based
approach to noise-robust adaptation control which allows for faster convergence
in applications characterized by high-level and non-stationary interfering
noise signals and abrupt system changes.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:47:35 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 07:39:42 GMT""},{""version"":""v3"",""created"":""Wed, 3 Feb 2021 09:56:58 GMT""}]","2021-02-04"
"2007.01580","Amnon Geifman","Amnon Geifman, Abhay Yadav, Yoni Kasten, Meirav Galun, David Jacobs,
  Ronen Basri","On the Similarity between the Laplace and Neural Tangent Kernels",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent theoretical work has shown that massively overparameterized neural
networks are equivalent to kernel regressors that use Neural Tangent
Kernels(NTK). Experiments show that these kernel methods perform similarly to
real neural networks. Here we show that NTK for fully connected networks is
closely related to the standard Laplace kernel. We show theoretically that for
normalized data on the hypersphere both kernels have the same eigenfunctions
and their eigenvalues decay polynomially at the same rate, implying that their
Reproducing Kernel Hilbert Spaces (RKHS) include the same sets of functions.
This means that both kernels give rise to classes of functions with the same
smoothness properties. The two kernels differ for data off the hypersphere, but
experiments indicate that when data is properly normalized these differences
are not significant. Finally, we provide experiments on real data comparing NTK
and the Laplace kernel, along with a larger class of{\gamma}-exponential
kernels. We show that these perform almost identically. Our results suggest
that much insight about neural networks can be obtained from analysis of the
well-known Laplace kernel, which has a simple closed-form.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:48:23 GMT""},{""version"":""v2"",""created"":""Sat, 14 Nov 2020 10:45:23 GMT""}]","2020-11-17"
"2007.01581","Arno F\""orster","Arno F\""orster and Lucas Visscher","Low-order Scaling $G_0W_0$ by Pair Atomic Density Fitting","final version as accepted by JCTC
  https://pubs.acs.org/doi/10.1021/acs.jctc.0c00693",,"10.1021/acs.jctc.0c00693",,"physics.chem-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive a low-scaling $G_0W_0$ algorithm for molecules, using pair atomic
density fitting (PADF) and an imaginary time representation of the Green's
function and describe its implementation in the Slater type orbital (STO) based
Amsterdam density functional (ADF) electronic structure code. We demonstrate
the scalability of our algorithm on a series of water clusters with up to 432
atoms and 7776 basis functions and observe asymptotic quadratic scaling with
realistic threshold qualities controlling distance effects and basis sets of
triple-$\zeta$ (TZ) plus double polarization quality. Also owing to a very
small prefactor, with these settings a $G_0W_0$ calculation for the largest of
these clusters takes only 240 CPU hours. With errors of 0.24 eV for HOMO
energies in the GW100 database on the quadruple-$\zeta$ level, our
implementation is less accurate than canonical all-electron implementations
using the larger def2-QZVP GTO-tpye basis set. Apart from basis set errors,
this is related to the well-known shortcomings of the GW space-time method
using analytical continuation techniques as well as to numerical issues of the
PADF-approach of accurately representing diffuse AO-products. We speculate,
that these difficulties might be overcome by using optimized auxiliary fit sets
with more diffuse functions of higher angular momenta. Despite these
shortcomings, for subsets of medium and large molecules from the GW5000
database, the error of our approach using basis sets of TZ and augmented DZ
quality is decreasing with system size. On the augmented DZ level we reproduce
canonical, complete basis set limit extrapolated reference values with an
accuracy of 80 meV on average for a set of 20 large organic molecules. We
anticipate our algorithm, in its current form, to be very useful in the study
of single-particle properties of large organic systems such as chromophores and
acceptor molecules.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:49:41 GMT""},{""version"":""v2"",""created"":""Wed, 16 Sep 2020 09:14:03 GMT""},{""version"":""v3"",""created"":""Thu, 12 Nov 2020 09:47:50 GMT""}]","2020-11-13"
"2007.01582","Sebastian Zanker","Nicolas Vogt, Sebastian Zanker, Jan-Michael Reiner, Thomas Eckl, Anika
  Marusczyk, Michael Marthaler","Preparing symmetry broken ground states with variational quantum
  algorithms",,,,,"quant-ph cond-mat.str-el physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most promising applications for near term quantum computers is the
simulation of physical quantum systems, particularly many-electron systems in
chemistry and condensed matter physics. In solid state physics, finding the
correct symmetry broken ground state of an interacting electron system is one
of the central challenges. The Variational Hamiltonian Ansatz (VHA), a
variational hybrid quantum-classical algorithm especially suited for finding
the ground state of a solid state system, will in general not prepare a broken
symmetry state unless the initial state is chosen to exhibit the correct
symmetry. In this work, we discuss three variations of the VHA designed to find
the correct broken symmetry states close to a transition point between
different orders. As a test case we use the two-dimensional Hubbard model where
we break the symmetry explicitly by means of external fields coupling to the
Hamiltonian and calculate the response to these fields. For the calculation we
simulate a gate-based quantum computer and also consider the effects of
dephasing noise on the algorithms. We find that two of the three algorithms are
in good agreement with the exact solution for the considered parameter range.
The third algorithm agrees with the exact solution only for a part of the
parameter regime, but is more robust with respect to dephasing compared to the
other two algorithms.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:51:02 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 08:04:42 GMT""}]","2020-07-16"
"2007.01583","Frank Schlosser","Frank Schlosser, Benjamin F. Maier, Olivia Jack, David Hinrichs,
  Adrian Zachariae, Dirk Brockmann","COVID-19 lockdown induces disease-mitigating structural changes in
  mobility networks","20 pages, 8 figures",,"10.1073/pnas.2012326117",,"physics.soc-ph q-bio.PE","http://creativecommons.org/licenses/by-sa/4.0/","  In the wake of the COVID-19 pandemic many countries implemented containment
measures to reduce disease transmission. Studies using digital data sources
show that the mobility of individuals was effectively reduced in multiple
countries. However, it remains unclear whether these reductions caused deeper
structural changes in mobility networks, and how such changes may affect
dynamic processes on the network. Here we use movement data of mobile phone
users to show that mobility in Germany has not only been reduced considerably:
Lockdown measures caused substantial and long-lasting structural changes in the
mobility network. We find that long-distance travel was reduced
disproportionately strongly. The trimming of long-range network connectivity
leads to a more local, clustered network and a moderation of the ""small-world""
effect. We demonstrate that these structural changes have a considerable effect
on epidemic spreading processes by ""flattening"" the epidemic curve and delaying
the spread to geographically distant regions.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:54:10 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 14:38:45 GMT""},{""version"":""v3"",""created"":""Thu, 5 Nov 2020 15:21:10 GMT""},{""version"":""v4"",""created"":""Fri, 18 Dec 2020 16:26:27 GMT""}]","2020-12-21"
"2007.01584","Aron Cummings","Bruna Gabrielly de Moraes, Aron W. Cummings, and Stephan Roche","Emergence of Intra-Particle Entanglement and Time-Varying Violation of
  Bell's Inequality in Dirac Matter","6 pages, 3 figures","Phys. Rev. B 102, 041403 (2020)","10.1103/PhysRevB.102.041403",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the emergence and dynamics of intra-particle entanglement in
massless Dirac fermions. This entanglement, generated by spin-orbit coupling,
arises between the spin and sublattice pseudospin of electrons in graphene. The
entanglement is a complex dynamic quantity but is generally large, independent
of the initial state. Its time dependence implies a dynamical violation of a
Bell inequality, while its magnitude indicates that large intra-particle
entanglement is a general feature of graphene on a substrate. These features
are also expected to impact entanglement between pairs of particles, and may be
detectable in experiments that combine Cooper pair splitting with nonlocal
measurements of spin-spin correlation in mesoscopic devices based on Dirac
materials.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:55:09 GMT""},{""version"":""v2"",""created"":""Sat, 1 Aug 2020 15:21:58 GMT""}]","2020-08-05"
"2007.01585","Toshiki Oguma","Toshiki Oguma, Hisako Takigawa-Imamura, Takashi Miura","Mechanism underlying dynamic scaling properties observed in the contour
  of spreading epithelial monolayer","11 pages, 6 figures, and supplemental materials","Phys. Rev. E 102, 062408 (2020)","10.1103/PhysRevE.102.062408",,"q-bio.CB nlin.PS physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We found evidence of dynamic scaling in the spreading of MDCK monolayer,
which can be characterized by the Hurst exponent ${\alpha} = 0.86$ and the
growth exponent ${\beta} = 0.73$, and theoretically and experimentally
clarified the mechanism that governs the contour shape dynamics. During the
spreading of the monolayer, it is known that so-called ""leader cells"" generate
the driving force and lead the other cells. Our time-lapse observations of cell
behavior showed that these leader cells appeared at the early stage of the
spreading, and formed the monolayer protrusion. Informed by these observations,
we developed a simple mathematical model that included differences in cell
motility, cell-cell adhesion, and random cell movement. The model reproduced
the quantitative characteristics obtained from the experiment, such as the
spreading speed, the distribution of the increment, and the dynamic scaling
law. Analysis of the model equation revealed that the model could reproduce the
different scaling law from ${\alpha} = 0.5, {\beta} = 0.25$ to ${\alpha} = 0.9,
{\beta} = 0.75$, and the exponents ${\alpha}, {\beta}$ were determined by the
two indices: $\rho t$ and $c$. Based on the analytical result, parameter
estimation from the experimental results was achieved. The monolayer on the
collagen-coated dishes showed a different scaling law ${\alpha} = 0.74, {\beta}
= 0.68$, suggesting that cell motility increased by 9 folds. This result was
consistent with the assay of the single-cell motility. Our study demonstrated
that the dynamics of the contour of the monolayer were explained by the simple
model, and proposed a new mechanism that exhibits the dynamic scaling property.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:56:52 GMT""}]","2021-01-04"
"2007.01586","Carlo Michel Carloni Calame","C.M. Carloni Calame, M. Chiesa, Syed Mehedi Hasan, G. Montagna, O.
  Nicrosini and F. Piccinini","Towards muon-electron scattering at NNLO","25 pages, 12 figures. One figure added, minor corrections
  implemented. Main results unchanged. References added and updated. Version
  accepted for publication on JHEP",,"10.1007/JHEP11(2020)028","LAPTH-029/20","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recently proposed MUonE experiment at CERN aims at providing a novel
determination of the leading order hadronic contribution to the muon anomalous
magnetic moment through the study of elastic muon-electron scattering at
relatively small momentum transfer. The anticipated accuracy of the order of
10ppm demands for high-precision predictions, including all the relevant
radiative corrections. The theoretical formulation for the fixed-order NNLO
photonic radiative corrections is described and the impact of the numerical
results obtained with the corresponding Monte Carlo code is discussed for
typical event selections of the MUonE experiment. In particular, the
gauge-invariant subsets of corrections due to electron radiation as well as to
muon radiation are treated exactly. The two-loop contribution due to diagrams
where at least two virtual photons connect the electron and muon lines is
approximated taking inspiration from the classical Yennie-Frautschi-Suura
approach. The calculation and its Monte Carlo implementation pave the way
towards the realization of a simulation code incorporating the full set of NNLO
corrections matched to multiple photon radiation, that will be ultimately
needed for data analysis.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:56:58 GMT""},{""version"":""v2"",""created"":""Mon, 9 Nov 2020 10:03:19 GMT""}]","2020-12-02"
"2007.01587","Dashan Gao","Dashan Gao, Ben Tan, Ce Ju, Vincent W. Zheng and Qiang Yang","Privacy Threats Against Federated Matrix Factorization","6 pages, 2 figures, 1 table, Accepted for Workshop on Federated
  Learning for Data Privacy and Confidentiality in Conjunction with IJCAI 2020
  (FL-IJCAI'20)",,,,"cs.CR cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Matrix Factorization has been very successful in practical recommendation
applications and e-commerce. Due to data shortage and stringent regulations, it
can be hard to collect sufficient data to build performant recommender systems
for a single company. Federated learning provides the possibility to bridge the
data silos and build machine learning models without compromising privacy and
security. Participants sharing common users or items collaboratively build a
model over data from all the participants. There have been some works exploring
the application of federated learning to recommender systems and the privacy
issues in collaborative filtering systems. However, the privacy threats in
federated matrix factorization are not studied. In this paper, we categorize
federated matrix factorization into three types based on the partition of
feature space and analyze privacy threats against each type of federated matrix
factorization model. We also discuss privacy-preserving approaches. As far as
we are aware, this is the first study of privacy threats of the matrix
factorization method in the federated learning framework.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:58:52 GMT""}]","2020-07-06"
"2007.01588","Marcy Robertson","Luciana Basualdo Bonatto, Safia Chettih, Abigail Linton, Sophie
  Raynor, Marcy Robertson, and Nathalie Wahl","An infinity operad of normalized cacti","48 pages, many figures, comments welcome!","Topology Appl. 316 (2022),Paper No. 108107","10.1016/j.topol.2022.108107","CPH-GeoTop-DNRF151","math.AT math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that normalized cacti form an $\infty$-operad in the form of a
dendroidal space satisfying a weak Segal condition. To do this, we introduce a
new topological operad of bracketed trees and an enrichment of the dendroidal
category $\Omega$.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:04:54 GMT""}]","2023-03-09"
"2007.01589","Man Ho Chan","Man Ho Chan, Chak Man Lee","Constraining the spin-independent elastic scattering cross section of
  dark matter using the Moon as a detection target and the background neutrino
  data","Accepted for publication in Physical Review D","Phys. Rev. D 102, 023024 (2020)","10.1103/PhysRevD.102.023024",,"astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our Moon is a natural giant direct-detection target for constraining dark
matter. By considering the dark matter capture rate of the Moon, we obtain some
constraints of the spin-independent elastic scattering cross section of dark
matter particles on nucleons $\sigma_p^{\rm SI}$ using the background neutrino
data. The upper limits of $\sigma_p^{\rm SI}$ can be constrained to $\sim
10^{-38}-10^{-36}$ cm$^2$ for certain `resonance dark matter mass' ranges.
These stringent astrophysical constraints are complementary to the constraints
obtained by the direct-detection experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:07:33 GMT""}]","2020-07-22"
"2007.01590","Magdalena Kunert-Bajraszewska","Magdalena Kunert-Bajraszewska, Aleksandra Wolowska, Kunal Mooley,
  Preeti Kharb, Gregg Hallinan","Caltech-NRAO Stripe 82 Survey (CNSS). IV. The Birth of Radio-loud Quasar
  013815+00","14 pages, 5 figures, 1 table, accepted to ApJ",,"10.3847/1538-4357/ab9598",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is believed that the gas accretion onto the supermassive black holes
(SMBHs) is the main process of powering its luminous emission, which occurs in
optical, UV and X-ray regimes and less frequently in radio waves. The
observational fact that only a few percent of quasars are radio-loud is still
an unresolved issue concerning the understanding of the active galactic nucleus
(AGN) population. Here we present a detection of a rapid transition from the
radio-quiet to the radio-loud mode in quasar 013815+00 (z=0.94) which coincides
with changes of its UV-optical continuum and the low ionization MgII broadline.
We interpret this as an enhancement of accretion onto a central black hole of
mass about 10^9 solar masses. As a consequence a new radio-loud AGN was born.
Its spectral and morphological properties indicate that it went through the
short gigahertz-peaked spectrum (GPS) phase at the beginning of its activity
and has now stabilized its flux density at the level of a few mJy. The radio
morphology of 013815+00 is very compact and we predict that with such
short-term jet activity its development will be very slow. The observed
luminosity changes of the accretion disk are shorter than the lifetime of the
new radio phase in 013815+00.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:10:43 GMT""}]","2020-07-22"
"2007.01591","Abdulla Al Mamon","Abdulla Al Mamon","Study of Tsallis holographic dark energy model in the framework of
  Fractal cosmology","6 pages, 5 figures, Accepted for publication in MPLA",,"10.1142/S021773232050251X",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we study the evolution of a fractal universe composed of
Tsallis holographic dark energy (THDE) and a pressureless dark matter that
interact with each other through a mutual interaction. We then reconstruct the
interaction term of this model by considering the Hubble length as the IR
cut-off scale. We also study the behavior of different cosmological parameters
during the cosmic evolution from the early matter-dominated era until the
late-time acceleration. The present study shows that the universe undergoes a
smooth transition from a decelerated to an accelerated phase of expansion in
the recent past. Moreover, we also shown the evolution of the normalized Hubble
parameter for our model and compared that with the latest cosmic chronometer
data. Finally, we test the viability of the model by exploring its stability
against small perturbation by using the squared of the sound speed.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:11:35 GMT""}]","2020-10-28"
"2007.01592","Muhammad Osama","Muhammad Osama, Dave Zachariah, Petre Stoica","Prediction of Spatial Point Processes: Regularized Method with
  Out-of-Sample Guarantees",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A spatial point process can be characterized by an intensity function which
predicts the number of events that occur across space. In this paper, we
develop a method to infer predictive intensity intervals by learning a spatial
model using a regularized criterion. We prove that the proposed method exhibits
out-of-sample prediction performance guarantees which, unlike standard
estimators, are valid even when the spatial model is misspecified. The method
is demonstrated using synthetic as well as real spatial data.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:11:59 GMT""}]","2020-07-06"
"2007.01593","S\""oren Dittmer","S\""oren Dittmer, Tobias Kluth, Mads Thorstein Roar Henriksen and Peter
  Maass","Deep image prior for 3D magnetic particle imaging: A quantitative
  comparison of regularization techniques on Open MPI dataset",,,,,"eess.IV cs.CV cs.LG math.FA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic particle imaging (MPI) is an imaging modality exploiting the
nonlinear magnetization behavior of (super-)paramagnetic nanoparticles to
obtain a space- and often also time-dependent concentration of a tracer
consisting of these nanoparticles. MPI has a continuously increasing number of
potential medical applications. One prerequisite for successful performance in
these applications is a proper solution to the image reconstruction problem.
More classical methods from inverse problems theory, as well as novel
approaches from the field of machine learning, have the potential to deliver
high-quality reconstructions in MPI. We investigate a novel reconstruction
approach based on a deep image prior, which builds on representing the solution
by a deep neural network. Novel approaches, as well as variational and
iterative regularization techniques, are compared quantitatively in terms of
peak signal-to-noise ratios and structural similarity indices on the publicly
available Open MPI dataset.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:13:10 GMT""}]","2020-07-06"
"2007.01594","Ganqu Cui","Ganqu Cui, Jie Zhou, Cheng Yang, Zhiyuan Liu","Adaptive Graph Encoder for Attributed Graph Embedding","To appear in KDD 2020",,"10.1145/3394486.3403140",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Attributed graph embedding, which learns vector representations from graph
topology and node features, is a challenging task for graph analysis. Recently,
methods based on graph convolutional networks (GCNs) have made great progress
on this task. However,existing GCN-based methods have three major drawbacks.
Firstly,our experiments indicate that the entanglement of graph convolutional
filters and weight matrices will harm both the performance and robustness.
Secondly, we show that graph convolutional filters in these methods reveal to
be special cases of generalized Laplacian smoothing filters, but they do not
preserve optimal low-pass characteristics. Finally, the training objectives of
existing algorithms are usually recovering the adjacency matrix or feature
matrix, which are not always consistent with real-world applications. To
address these issues, we propose Adaptive Graph Encoder (AGE), a novel
attributed graph embedding framework. AGE consists of two modules: (1) To
better alleviate the high-frequency noises in the node features, AGE first
applies a carefully-designed Laplacian smoothing filter. (2) AGE employs an
adaptive encoder that iteratively strengthens the filtered features for better
node embeddings. We conduct experiments using four public benchmark datasets to
validate AGE on node clustering and link prediction tasks. Experimental results
show that AGE consistently outperforms state-of-the-art graph embedding methods
considerably on these tasks.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:20:34 GMT""}]","2020-07-06"
"2007.01595","David Rozenberszki","David Rozenberszki, Andras Majdik","LOL: Lidar-Only Odometry and Localization in 3D Point Cloud Maps","Accepted paper for ICRA 2020, Github repository for implementation
  at: https://github.com/RozDavid/LOL",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we deal with the problem of odometry and localization for
Lidar-equipped vehicles driving in urban environments, where a premade target
map exists to localize against. In our problem formulation, to correct the
accumulated drift of the Lidar-only odometry we apply a place recognition
method to detect geometrically similar locations between the online 3D point
cloud and the a priori offline map. In the proposed system, we integrate a
state-of-the-art Lidar-only odometry algorithm with a recently proposed 3D
point segment matching method by complementing their advantages. Also, we
propose additional enhancements in order to reduce the number of false matches
between the online point cloud and the target map, and to refine the position
estimation error whenever a good match is detected. We demonstrate the utility
of the proposed LOL system on several Kitti datasets of different lengths and
environments, where the relocalization accuracy and the precision of the
vehicle's trajectory were significantly improved in every case, while still
being able to maintain real-time performance.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:20:53 GMT""}]","2020-07-06"
"2007.01596","Cristina Sanz-Fernandez","Cristina Sanz-Fern\'andez and Van Tuong Pham and Edurne Sagasta and
  Luis E. Hueso and Ilya V. Tokatly and F\`elix Casanova and F. Sebasti\'an
  Bergeret","Quantification of interfacial spin-charge conversion in metal/insulator
  hybrid structures by generalized boundary conditions",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present and verify experimentally a universal theoretical framework for
the description of spin-charge interconversion in non-magnetic metal/insulator
structures with interfacial spin-orbit coupling (ISOC). Our formulation is
based on drift-diffusion equations supplemented with generalized boundary
conditions. The latter encode the effects of ISOC and relate the electronic
transport in such systems to spin loss and spin-charge interconversion at the
interface, which are parameterized, respectively, by $G_{\parallel/\perp}$ and
$\sigma_{\rm{sc/cs}}$. We demonstrate that the conversion efficiency depends
solely on these interfacial parameters. We apply our formalism to two typical
spintronic devices that exploit ISOC: a lateral spin valve and a multilayer
Hall bar, for which we calculate the non-local resistance and the spin Hall
magnetoresistance, respectively. Finally, we perform measurements on these two
devices with a BiO$_x$/Cu interface and verify that transport properties
related to the ISOC are quantified by the same set of interfacial parameters.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:24:05 GMT""}]","2020-07-06"
"2007.01597","Frank Wolter","Jean Christoph Jung and Frank Wolter","Living without Beth and Craig: Definitions and Interpolants in the
  Guarded and Two-Variable Fragments","This is an updated version that also investigates the two-variable
  fragment of FO. The paper will appear in the proceedings of LICS 2021",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  In logics with the Craig interpolation property (CIP) the existence of an
interpolant for an implication follows from the validity of the implication. In
logics with the projective Beth definability property (PBDP), the existence of
an explicit definition of a relation follows from the validity of a formula
expressing its implicit definability. The two-variable fragment, FO2, and the
guarded fragment, GF, of first-order logic both fail to have the CIP and the
PBDP. We show that nevertheless in both fragments the existence of interpolants
and explicit definitions is decidable. In GF, both problems are
3ExpTime-complete in general, and 2ExpTime-complete if the arity of relation
symbols is bounded by a constant c not smaller than 3. In FO2, we prove a
coN2ExpTime upper bound and a 2ExpTime lower bound for both problems. Thus,
both for GF and FO2 existence of interpolants and explicit definitions are
decidable but harder than validity (in case of FO2 under standard complexity
assumptions).
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:30:24 GMT""},{""version"":""v2"",""created"":""Sun, 18 Apr 2021 09:33:10 GMT""}]","2021-04-20"
"2007.01598","Xinpeng Ding","Xinpeng Ding, Nannan Wang, Xinbo Gao, Jie Li, Xiaoyu Wang and
  Tongliang Liu","Weakly Supervised Temporal Action Localization with Segment-Level Labels","18 pages,7 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Temporal action localization presents a trade-off between test performance
and annotation-time cost. Fully supervised methods achieve good performance
with time-consuming boundary annotations. Weakly supervised methods with
cheaper video-level category label annotations result in worse performance. In
this paper, we introduce a new segment-level supervision setting: segments are
labeled when annotators observe actions happening here. We incorporate this
segment-level supervision along with a novel localization module in the
training. Specifically, we devise a partial segment loss regarded as a loss
sampling to learn integral action parts from labeled segments. Since the
labeled segments are only parts of actions, the model tends to overfit along
with the training process. To tackle this problem, we first obtain a similarity
matrix from discriminative features guided by a sphere loss. Then, a
propagation loss is devised based on the matrix to act as a regularization
term, allowing implicit unlabeled segments propagation during training.
Experiments validate that our method can outperform the video-level supervision
methods with almost same the annotation time.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:32:19 GMT""}]","2020-07-06"
"2007.01599","Joris Mollinga","Joris Mollinga, Herke van Hoof","An Autonomous Free Airspace En-route Controller using Deep Reinforcement
  Learning Techniques","Published at ICRAT2020",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Air traffic control is becoming a more and more complex task due to the
increasing number of aircraft. Current air traffic control methods are not
suitable for managing this increased traffic. Autonomous air traffic control is
deemed a promising alternative. In this paper an air traffic control model is
presented that guides an arbitrary number of aircraft across a
three-dimensional, unstructured airspace while avoiding conflicts and
collisions. This is done utilizing the power of graph based deep learning
approaches. These approaches offer significant advantages over current
approaches to this task, such as invariance to the input ordering of aircraft
and the ability to easily cope with a varying number of aircraft. Results
acquired using these approaches show that the air traffic control model
performs well on realistic traffic densities; it is capable of managing the
airspace by avoiding 100% of potential collisions and preventing 89.8% of
potential conflicts.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:37:25 GMT""}]","2020-07-06"
"2007.01600","Luis \'Angel Calder\'on P\'erez","Jos\'e Luis Bravo Trinidad, Luis \'Angel Calder\'on P\'erez, Manuel
  Fern\'andez Garc\'ia-Hierro","Upper bounds of limit cycles in Abel differential equations with
  invariant curves","16 pages, 4 figures",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  New criteria are established for upper bounds on the number of limit cycles
of periodic Abel differential equations having two periodic invariant curves,
one of them bounded. The criteria are applied to obtain upper bounds of either
zero or one limit cycle for planar differential systems.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:39:59 GMT""}]","2020-07-06"
"2007.01601","Alexandre Poulain","Alexandre Poulain","Scalar auxiliary variable finite element scheme for the
  parabolic-parabolic Keller-Segel model",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe and analyze a finite element numerical scheme for the
parabolic-parabolic Keller-Segel model. The scalar auxiliary variable method is
used to retrieve the monotonic decay of the energy associated with the system
at the discrete level. This method relies on the interpretation of the
Keller-Segel model as a gradient flow. The resulting numerical scheme is
efficient and easy to implement. We show the existence of a unique non-negative
solution and that a modified discrete energy is obtained due to the use of the
SAV method. We also prove the convergence of the discrete solutions to the ones
of the weak form of the continuous Keller-Segel model.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:40:05 GMT""}]","2020-07-06"
"2007.01602","Li Xia","Li Xia, Xianping Guo, Xi-Ren Cao","On the existence of optimal stationary policies for average Markov
  decision processes with countable states","25 pages",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a Markov decision process with countably infinite states, the optimal
value may not be achievable in the set of stationary policies. In this paper,
we study the existence conditions of an optimal stationary policy in a
countable-state Markov decision process under the long-run average criterion.
With a properly defined metric on the policy space of ergodic MDPs, the
existence of an optimal stationary policy can be guaranteed by the compactness
of the space and the continuity of the long-run average cost with respect to
the metric. We further extend this condition by some assumptions which can be
easily verified in control problems of specific systems, such as queueing
systems. Our results make a complementary contribution to the literature in the
sense that our method is capable to handle the cost function unbounded from
both below and above, only at the condition of continuity and ergodicity.
Several examples are provided to illustrate the application of our main
results.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:40:12 GMT""}]","2020-07-06"
"2007.01603","Enrique Perez","Francisco Prada, Robert Content, Ariel Goobar, Luca Izzo, Enrique
  P\'erez, Adriano Agnello, Carlos del Burgo, Vik Dhillon, Jos\'e M. Diego,
  Lluis Galbany, Jorge Garc\'ia-Rojas, David Jones, Jon Lawrence, Eduardo
  Mart\'in, Evencio Mediavilla, M. \'Angeles P\'erez Garc\'ia, Jorge S\'anchez
  Almeida, Jos\'e A. Acosta Pulido, Angel R. L\'opez-S\'anchez, Santiago
  Arribas, Francisco J. Carrera, Amalia Corral, Inmaculada Dom\'inguez, Silvia
  Mateos, Silvia Mart\'inez Nu\~nez, Eva Villaver, Mar\'ia Rosa Zapatero
  Osorio, Conrado Albertus, Fabrizio Arrigoni Battaia, David Barrado, V\'ictor
  J. S. Bejar, Henri M. J. Boffin, Herve Bouy, Adam Burgasser, Cesar Esteban,
  Nicolas Lodieu, Mar\'ia Morales Calder\'on, Antonio P\'erez Garrido, Pablo
  Rodr\'iguez Gil, Ana Sagu\'es Carracedo, Miguel Santander Garc\'ia, Enrique
  Solano, Manuel A. P. Torres, Roger Wesson","White Paper on MAAT@GTC","49 pages, 36 figures",,,,"astro-ph.IM astro-ph.CO astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MAAT is proposed as a visitor mirror-slicer optical system that will allow
the OSIRIS spectrograph on the 10.4-m Gran telescopio CANARIAS (GTC) the
capability to perform Integral Field Spectroscopy (IFS) over a seeing-limited
FoV 14.20''x10'' with a slice width of 0.303''. MAAT@GTC will enhance the
resolution power of OSIRIS by 1.6 times as compared to its 0.6'' wide
long-slit. All the eleven OSIRIS grisms and volume-phase holographic gratings
will be available to provide broad spectral coverage with moderate resolution
(R=600 up to 4100) in the 3600 - 10000 {\AA} wavelength range. MAAT unique
observing capabilities will broaden its use to the needs of the GTC community
to unveil the nature of most striking phenomena in the universe well beyond
time-domain astronomy. The GTC equipped with OSIRIS+MAAT will also play a
fundamental role in synergy with other facilities, some of them operating on
the northern ORM at La Palma. This White Paper presents the different aspects
of MAAT@GTC - including scientific and technical specifications, outstanding
science cases, and an outline of the instrument concept.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:41:22 GMT""},{""version"":""v2"",""created"":""Sun, 19 Jul 2020 12:01:20 GMT""}]","2020-07-21"
"2007.01604","Noemie Combe","N. C. Combe","Cech cover of the complement of the discriminant variety. Part II:
  Deformations of Gauss-skizze",,,,,"math.AG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The configuration space of $n$ marked points on the complex plane is
considered. We investigate a decomposition of this space by so-called
Gauss-skizze i.e. a class of graphs being forests, introduced by Gauss. It is
proved that this decomposition is a semi-algebraic topological stratification.
It also forms a cell decomposition of the configuration space of $n$ marked
points. Moreover, we prove that classical tools from deformation theory, ruled
by a Maurer--Cartan equation, can be used only locally for Gauss-skizze. We
prove that the deformation of the Gauss-skizze is governed by a
Hamilton--Jacobi differential equation. This gives developments concerning
Saito's Frobenius manifold. Finally, a Gauss-skizze operad is introduced. It is
an enriched Fulton--MacPherson operad, topologically equivalent to the little
2-disc operad.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:43:34 GMT""}]","2020-07-06"
"2007.01605","Ricky Lamberty","Ricky Lamberty, Alexander Poddey","Regulation conform DLT-operable payment adapter based on trustless -
  justified trust combined generalized state channels",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Open technologies, decentralized computation and intelligent applications
enable the third-generation web, Web 3.0, thereby digitizing whole industries.
The emerging Economy of Things (EoT) will be based on software agents running
on peer-to-peer trustless networks that require a programmable, regulation
conform means of payment. We give an overview of current solutions that differ
in their fundamental values and technological possibilities, like e.g.
private-issued stablecoins, DLT-issued electronic money and genuine
cryptocurrencies. Based on this analysis, we present the concept of justified
trust and propose to combine the strengths of the crypto based, decentralized
trustless elements with established and well regulated means of payment, based
on this concept, via a secure external re-balancing interface.
  Combining the advantages, e.g. lightweight, trustless, efficient high
frequency micro state transfers on the one hand, and ease of use, widely
spread, accepted alignment to a multitude of regulative requirements, on the
other hand, while neither leading into a lock-in in any of the proposed
solutions, nor undermining the basic principles of the crypto-movement or
unnecessarily reinforcing the banking system provides a synergy and the
necessary flexibility for further evolution alongside the regulative framework.
This offers a regulation conform transitional solution that can be implemented
in the short term, which enables companies to place their decentralized
business operations in a regulated environment.
  The contribution of our work is twofold: First, we illustrate and discuss
different DLT-operable means of payment. Second, our research proposes a novel
hybrid payment solution by interfacing trustless with justified trust combined
generalized state channels.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:45:55 GMT""}]","2020-07-06"
"2007.01606","Antonis Hadjipittas","Antonis Hadjipittas, H. I. B. Banks, B. Bergues, Agapi Emmanouilidou","Sequential single-photon and direct two-photon absorption processes for
  Xe interacting with attosecond XUV pulses","8 pages, 4 figures","Phys. Rev. A 102, 043108 (2020)","10.1103/PhysRevA.102.043108",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the interaction of Xe with isolated attosecond XUV pulses.
Specifically, we calculate the ion yields and determine the pathways leading to
the formation of ionic charged states up to Xe$^{5+}$. To do so, in our
formulation we account for single-photon absorption, sequential multi-photon
absorption, direct two-photon absorption, single and double Auger decays, and
shake-off. We compare our results for the ion yields and for ion yield ratios
with recent experimental results obtained for 93 eV and 115 eV attosecond XUV
pulses. In particular, we investigate the role that a sequence of two
single-photon ionization processes plays in the formation of Xe$^{4+}$. We find
that each one of these two processes ionizes a core electron and thus leads to
the formation of a double core-hole state. Remarkably, we find that the
formation of Xe$^{5+}$ involves a direct two-photon absorption process and the
absorption of a total of three photons.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:50:30 GMT""}]","2020-10-28"
"2007.01607","Peter Yuditskii","B. Eichinger, P. Yuditskii","Pointwise Remez inequality",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The standard well-known Remez inequality gives an upper estimate of the
values of polynomials on $[-1,1]$ if they are bounded by $1$ on a subset of
$[-1,1]$ of fixed Lebesgue measure. The extremal solution is given by the
rescaled Chebyshev polynomials for one interval. Andrievskii asked about the
maximal value of polynomials at a fixed point, if they are again bounded $1$ on
a set of fixed size. We show that the extremal polynomials are either Chebyshev
(one interval) or Akhiezer polynomials (two intervals) and prove Totik-Widom
bounds for the extremal value, thereby providing a complete asymptotic solution
to the Andrievskii problem.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:51:11 GMT""}]","2020-07-06"
"2007.01608","Sigbj{\o}rn L{\o}land Bore","Sigbj{\o}rn L{\o}land Bore and Michele Cascella","Hamiltonian and Alias-Free Hybrid Particle-Field Molecular Dynamics",,,,,"physics.comp-ph cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hybrid particle-field molecular dynamics combines standard molecular
potentials with density-field models into a computationally efficient
methodology that is well-adapted for the study of mesoscale soft matter
systems. Here, we introduce a new formulation based on filtered densities and a
particle-mesh formalism that allows for Hamiltonian dynamics and alias-free
force computation. This is achieved by introducing a length scale for the
particle-field interactions independent of the numerical grid used to represent
the density fields, enabling systematic convergence of the forces upon grid
refinement. Our scheme generalises the original particle-field molecular
dynamics implementations presented in the literature, finding them as limit
conditions. The accuracy of this new formulation is benchmarked by considering
simple monoatomic systems described by the standard hybrid particle-field
potentials. We find that by controlling the time step and grid size,
conservation of energy and momenta, as well as disappearance of alias, is
obtained. Increasing the particle-field interaction length scale permits the
use of larger time steps and coarser grids. This promotes the use of multiple
time step strategies over the quasi-instantaneous approximation, which is found
to not conserve energy and momenta equally well. Finally, our investigations of
the structural and dynamic properties of simple monoatomic systems show a
consistent behavior between the present formulation and Gaussian Core models.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:53:40 GMT""}]","2020-07-06"
"2007.01609","Corrado Zanella","Giovanni Longobardi, Corrado Zanella","Linear sets and MRD-codes arising from a class of scattered linearized
  polynomials",,"J. of Algebraic Combin. (2021)","10.1007/s10801-020-01011-9",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A class of scattered linearized polynomials covering infinitely many field
extensions is exhibited. More precisely, the $q$-polynomial over $\mathbb
F_{q^6}$, $q \equiv 1\pmod 4$ described in arXiv:1906.05611, arXiv:1910.02278
is generalized for any even $n\ge6$ to an $\mathbb F_q$-linear automorphism
$\psi(x)$ of $\mathbb F_q^n$ of order $n$. Such $\psi(x)$ and some functional
powers of it are proved to be scattered. In particular this provides new
maximum scattered linear sets of the projective line $\mathrm{PG}(1,q^n)$ for
$n=8,10$. The polynomials described in this paper lead to a new infinite family
of MRD-codes in $\mathbb F_q^{n\times n}$ with minimum distance $n-1$ for any
odd $q$ if $n\equiv0\pmod4$ and any $q\equiv1\pmod4$ if $n\equiv2\pmod4$.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:59:50 GMT""},{""version"":""v2"",""created"":""Wed, 30 Dec 2020 10:34:37 GMT""}]","2021-01-26"
"2007.01610","Jean Christoph Jung","Jean Christoph Jung, Carsten Lutz, Hadrien Pulcini, Frank Wolter","Logical Separability of Labeled Data Examples under Ontologies","Full Version of KR'20 paper",,,,"cs.LO cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding a logical formula that separates positive and negative examples given
in the form of labeled data items is fundamental in applications such as
concept learning, reverse engineering of database queries, generating referring
expressions, and entity comparison in knowledge graphs. In this paper, we
investigate the existence of a separating formula for data in the presence of
an ontology. Both for the ontology language and the separation language, we
concentrate on first-order logic and the following important fragments thereof:
the description logic $\mathcal{ALCI}$, the guarded fragment, the two-variable
fragment, and the guarded negation fragment. For separation, we also consider
(unions of) conjunctive queries. We consider several forms of separability that
differ in the treatment of negative examples and in whether or not they admit
the use of additional helper symbols to achieve separation. Our main results
are model-theoretic characterizations of (all variants of) separability, the
comparison of the separating power of different languages, and the
investigation of the computational complexity of deciding separability.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:00:47 GMT""},{""version"":""v2"",""created"":""Wed, 17 Aug 2022 12:29:41 GMT""}]","2022-08-18"
"2007.01611","Shubhankar Das Dr.","Shubhankar Das, Ariel Zaig, Moty Schultz, Susana Cardoso, Diana C
  Leitao, and Lior Klein","A four-state magnetic tunnel junction switchable with spin-orbit torques","4 pages, 3 figures, This article may be downloaded for personal use
  only. Any other use requires prior permission of the author and AIP
  Publishing. This article appeared in (Appl. Phys. Lett. 117, 072404 (2020))
  and may be found at (https://aip.scitation.org/doi/10.1063/5.0014771)","Appl. Phys. Lett. 117, 072404 (2020)","10.1063/5.0014771",,"physics.app-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a magnetic tunnel junction (MTJ) where its two ferromagnetic
layers are in the form of a single ellipse (SE) and two-crossing ellipses
(TCE). The MTJ exhibits four distinct resistance states corresponding to the
four remanent states of the TCE structure. Flowing current in an underlying Ta
layer generates in the adjacent TCE structure spin-orbit torques which induce
field-free switching of the four-state MTJ between all its resistance states.
The demonstrated four-state MTJ is an important step towards fabricating
multi-level MTJs with numerous resistance states which could be important in
various spintronics applications, such as multi-level magnetic random access or
neuromorphic memory.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:05:32 GMT""},{""version"":""v2"",""created"":""Thu, 20 Aug 2020 12:32:52 GMT""}]","2020-08-21"
"2007.01612","Julia Olkhovskaya","Gergely Neu and Julia Olkhovskaya","Online learning in MDPs with linear function approximation and bandit
  feedback",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider an online learning problem where the learner interacts with a
Markov decision process in a sequence of episodes, where the reward function is
allowed to change between episodes in an adversarial manner and the learner
only gets to observe the rewards associated with its actions. We allow the
state space to be arbitrarily large, but we assume that all action-value
functions can be represented as linear functions in terms of a known
low-dimensional feature map, and that the learner has access to a simulator of
the environment that allows generating trajectories from the true MDP dynamics.
Our main contribution is developing a computationally efficient algorithm that
we call MDP-LinExp3, and prove that its regret is bounded by
$\widetilde{\mathcal{O}}\big(H^2 T^{2/3} (dK)^{1/3}\big)$, where $T$ is the
number of episodes, $H$ is the number of steps in each episode, $K$ is the
number of actions, and $d$ is the dimension of the feature map. We also show
that the regret can be improved to $\widetilde{\mathcal{O}}\big(H^2
\sqrt{TdK}\big)$ under much stronger assumptions on the MDP dynamics. To our
knowledge, MDP-LinExp3 is the first provably efficient algorithm for this
problem setting.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:06:38 GMT""},{""version"":""v2"",""created"":""Sat, 12 Jun 2021 19:28:35 GMT""}]","2021-06-15"
"2007.01613","Razvan Mosincat","Razvan Mosincat, Didier Pilod, Jean-Claude Saut","Global well-posedness and scattering for the Dysthe equation in
  $L^2(\mathbb R^2)$","We added several references and clarified the derivation of the
  models in the introduction. 21 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on the Dysthe equation which is a higher order
approximation of the water waves system in the modulation (Schr\""{o}dinger)
regime and in the infinite depth case. We first review the derivation of the
Dysthe and related equations. Then we study the initial-value problem. We prove
a small data global well-posedness and scattering result in the critical space
$L^2(\mathbb R^2)$. This result is sharp in view of the fact that the flow map
cannot be $C^3$ continuous below $L^2(\mathbb R^2)$. Our analysis relies on
linear and bilinear Strichartz estimates in the context of the Fourier
restriction norm method. Moreover, since we are at a critical level, we need to
work in the framework of the atomic space $U^2_S$ and its dual $V^2_S $ of
square bounded variation functions. We also prove that the initial-value
problem is locally well-posed in $H^s(\mathbb R^2)$, $s>0$. Our results extend
to the finite depth version of the Dysthe equation.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:15:56 GMT""},{""version"":""v2"",""created"":""Wed, 19 Aug 2020 10:56:28 GMT""}]","2020-08-20"
"2007.01614","Konstantinos Kourtzanidis Dr","Konstantinos Kourtzanidis, Guillaume Dufour and Fran\c{c}ois Rogier","The ElectroHydroDynamic force distribution in surface AC Dielectric
  Barrier Discharge actuators: do streamers dictate the ionic wind profiles?","12 pages, 7 figures; references added, title changed, structure
  modified and text enriched, figures updated (and added) for improved
  visualization/comprehension, abstract enriched; all results remain unchanged","J. Phys. D: Appl. Phys. 54 26LT01 2021","10.1088/1361-6463/abf53e",,"physics.app-ph physics.comp-ph physics.flu-dyn physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the spatio-temporal ElectroHydroDynamic (EHD) force production
in surface AC-Dielectric Barrier Discharge (AC-DBD) actuators is strongly
influenced by both the streamer regime during the positive phase and the
micro-discharge regime during the negative phase. Focusing on the spatial EHD
force profiles, we demonstrate that the ionic wind spatial distribution can
only be explained by the positive contribution of the streamer regime. The
location of maximum ionic wind is found to be directly linked with the maximum
elongation of the streamers at several millimeters from the exposed electrode.
In both positive and negative phases of the AC-DBD operation, residual
volumetric and surface charges once again linked to the streamer formation and
afterburn, result to a variety of positive EHD force zones which, when
time-averaged in one AC period, contribute to the generation of the
experimentally observed induced thin wall jet. Through a thorough elaboration
of our numerical results, we provide an illustrative explanation of the EHD
force spatio-temporal evolution, showcase the importance of streamers and
retrieve a correct representation of the ionic wind spatial profiles when
compared to experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:17:13 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 17:49:42 GMT""}]","2021-04-20"
"2007.01615","Debraj Das","Debraj Das and Priyam Das","On Second order correctness of Bootstrap in Logistic Regression","38 pages",,,,"math.ST stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the fields of clinical trials, biomedical surveys, marketing, banking,
with dichotomous response variable, the logistic regression is considered as an
alternative convenient approach to linear regression. In this paper, we develop
a novel bootstrap technique based on perturbation resampling method for
approximating the distribution of the maximum likelihood estimator (MLE) of the
regression parameter vector. We establish second order correctness of the
proposed bootstrap method after proper studentization and smoothing. It is
shown that inferences drawn based on the proposed bootstrap method are more
accurate compared to that based on asymptotic normality. The main challenge in
establishing second order correctness remains in the fact that the response
variable being binary, the resulting MLE has a lattice structure. We show the
direct bootstrapping approach fails even after studentization. We adopt
smoothing technique developed in Lahiri (1993) to ensure that the smoothed
studentized version of the MLE has a density. Similar smoothing strategy is
employed to the bootstrap version also to achieve second order correct
approximation.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:18:20 GMT""},{""version"":""v2"",""created"":""Fri, 18 Sep 2020 14:58:05 GMT""}]","2020-09-21"
"2007.01616","Denis Sob'yanin","Denis Nikolaevich Sob'yanin (Lebedev Physical Institute)","Periodic fast radio bursts from forcedly precessing neutron stars,
  anomalous torque, and internal magnetic field for FRB 180916.J0158+65 and FRB
  121102","8 pages, 2 figures, MNRAS accepted","Mon. Not. R. Astron. Soc. 497, 1001 (2020)","10.1093/mnras/staa1976",,"astro-ph.HE astro-ph.SR physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A recent discovery of the periodic activity of the repeating fast radio burst
source FRB 180916.J0158+65 in the Canadian Hydrogen Intensity Mapping
Experiment (CHIME) hints at possible origin of the FRB from a freely precessing
neutron star with a magnetar magnetic field of about $10^{16}$ G. However, the
absence of simultaneously detected high-energy emission in the Swift and AGILE
observations imposes stringent constraints on the field magnitude and questions
the possibility of such a progenitor. We show that consideration of forced
precession of a neutron star does not encounter the difficulty. This kind of
precession takes place even if the neutron star is not deformed and is brought
about by the anomalous moment of electromagnetic forces induced by stellar
rotation and determined by non-corotational currents. Contrary to what is
expected for the currents of corotation, the anomalous torque calculated by the
direct method appears to be non-zero. If the observed 16.35-day period
corresponds to the period of stellar precession, the inferred internal magnetic
field appears to be about $6\times10^{14}$ G for rotational period 1 s. For
another possibly periodic FRB 121102 with 157-day period the magnetic field is
even lower, $2\times10^{14}$ G, thereby justifying earlier considerations and
not ruling out the hypothesis of FRB origin from precessing neutron stars.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:20:07 GMT""}]","2020-08-04"
"2007.01617","Carlo Cossu","Carlo Cossu","Replacing wakes with streaks in wind turbine arrays","revised version",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wind turbine wakes negatively impact downwind turbines in wind farms reducing
their global efficiency. The reduction of wake-turbine interactions by
actuating control on yaw angles and induction factors is an active area of
research. In this study, the capability of spanwise-periodic wind turbine
arrays with tilted rotors to reduce negative turbine-wakes interaction is
investigated by means of large-eddy simulations. It is shown that by means of
rotor tilt it is possible to replace turbine far wakes with high-speed streaks
where the streamwise velocity exceeds the freestream velocity at hub height.
Considering three aligned arrays of wind turbines, it is found that the global
power extracted from the wind can be increased by tilting rotors of upwind
turbine arrays similarly to what already known for the case of a single row of
aligned turbines. It is further shown that global tilt-induced power gains can
be significantly increased by operating the tilted turbines at higher induction
rates. Power gains can be further increased by increasing the ratio of the
rotor diameters and turbine spacing to the boundary layer thickness. All these
findings are consistent with those of previous studies where streamwise streaks
were artificially forced by means of arrays of wall-mounted roughness elements
in order to control canonical boundary layers for drag-reduction purposes.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:23:50 GMT""},{""version"":""v2"",""created"":""Thu, 13 Aug 2020 10:26:14 GMT""}]","2020-08-14"
"2007.01618","Fei-Fei Huang","Feifei Huang, Jie Li and Xuelin Zhu","Balanced Symmetric Cross Entropy for Large Scale Imbalanced and Noisy
  Data",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep convolution neural network has attracted many attentions in large-scale
visual classification task, and achieves significant performance improvement
compared to traditional visual analysis methods. In this paper, we explore many
kinds of deep convolution neural network architectures for large-scale product
recognition task, which is heavily class-imbalanced and noisy labeled data,
making it more challenged. Extensive experiments show that PNASNet achieves
best performance among a variety of convolutional architectures. Together with
ensemble technology and negative learning loss for noisy labeled data, we
further improve the model performance on online test data. Finally, our
proposed method achieves 0.1515 mean top-1 error on online test data.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:24:43 GMT""}]","2020-07-06"
"2007.01619","Lei Zhao","Rafael Ortega and Lei Zhao","Generalized periodic orbits in some restricted three-body problems","10 pages",,"10.1007/s00033-021-01470-5",,"math.DS math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We treat the circular and elliptic restricted three-body problems in inertial
frames as periodically forced Kepler problems with additional singularities and
explain that in this setting the main result of [4] is applicable. This
guarantees the existence of an arbitrary large number of generalized periodic
orbits (periodic orbits with possible double collisions regularized) provided
the mass ratio of the primaries is small enough.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:26:42 GMT""}]","2021-02-24"
"2007.01620","Immanuel Bayer","Immanuel Bayer and Anastasios Zouzias","Team voyTECH: User Activity Modeling with Boosting Trees",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describes our winning solution for the ECML-PKDD ChAT Discovery
Challenge 2020. We show that whether or not a Twitch user has subscribed to a
channel can be well predicted by modeling user activity with boosting trees. We
introduce the connection between target-encodings and boosting trees in the
context of high cardinality categoricals and find that modeling user activity
is more powerful then direct modeling of content when encoded properly and
combined with a suitable optimization approach.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:29:58 GMT""},{""version"":""v2"",""created"":""Thu, 6 Aug 2020 14:54:24 GMT""}]","2020-08-07"
"2007.01621","C\'edric Bernardin","C\'edric Bernardin, Pedro Cardoso, Patricia Gon\c{c}alves, Stefano
  Scotta","Hydrodynamic limit for a boundary driven super-diffusive symmetric
  exclusion",,,,,"math.PR","http://creativecommons.org/publicdomain/zero/1.0/","  We study the hydrodynamic limit for a model of symmetric exclusion processes
with heavy-tailed long jumps and in contact with infinitely extended
reservoirs. We show how the corresponding hydrodynamic equations are affected
by the parameters defining the model. The hydrodynamic equations are
characterized by a class of super-diffusive operators that are given by the
regional fractional Laplacian with some additional reaction terms and various
boundary conditions. This work solves some questions left open in \cite{BJGO2}
about the same model.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:32:58 GMT""},{""version"":""v2"",""created"":""Fri, 18 Jun 2021 08:27:51 GMT""},{""version"":""v3"",""created"":""Fri, 24 Jun 2022 14:41:34 GMT""}]","2022-06-27"
"2007.01622","Ant\'on Baleato Lizancos","Ant\'on Baleato Lizancos, Anthony Challinor and Julien Carron","Impact of internal-delensing biases on searches for primordial B-modes
  of CMB polarisation","22 pages + appendices & references. 15 figures. Matches version
  published in JCAP","JCAP 03(2021)016","10.1088/1475-7516/2021/03/016",,"astro-ph.CO","http://creativecommons.org/licenses/by-sa/4.0/","  Searches for the imprint of primordial gravitational waves in degree-scale
CMB $B$-mode polarisation data must account for significant contamination from
gravitational lensing. Fortunately, the lensing effects can be partially
removed by combining high-resolution $E$-mode measurements with an estimate of
the projected matter distribution. In the near future, experimental
characteristics will be such that the latter can be reconstructed internally
with high fidelity from the observed CMB, with the $EB$ quadratic estimator
providing a large fraction of the signal-to-noise. It is a well-known
phenomenon in this context that any overlap in modes between the $B$-field to
be delensed and the $B$-field from which the reconstruction is derived leads to
a suppression of delensed power going beyond that which can be attributed to a
mitigation of the lensing effects. More importantly, the variance associated
with this spectrum is also reduced, posing the question of whether the
additional power suppression could help better constrain the tensor-to-scalar
ratio, $r$. In this paper, we show this is not the case, as suggested but not
quantified in previous work. We develop an analytic model for the biased
delensed $B$-mode angular power spectrum, which suggests a simple
renormalisation prescription to avoid bias on the inferred tensor-to-scalar
ratio. With this approach, we learn that the bias necessarily leads to a
degradation of the signal-to-noise on a primordial component compared to
""unbiased delensing"". Next, we assess the impact of removing from the lensing
reconstruction any overlapping $B$-modes on our ability to constrain $r$,
showing that it is in general advantageous to do this rather than modeling or
renormalising the bias. Finally, we verify these results within a
maximum-likelihood inference framework applied to simulations.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:33:02 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 14:12:12 GMT""}]","2021-03-12"
"2007.01623","Oleg Szehr","Loris Cannelli, Giuseppe Nuti, Marzio Sala, Oleg Szehr","Hedging using reinforcement learning: Contextual $k$-Armed Bandit versus
  $Q$-learning","30 pages, 11 figures",,,,"cs.LG q-fin.CP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The construction of replication strategies for contingent claims in the
presence of risk and market friction is a key problem of financial engineering.
In real markets, continuous replication, such as in the model of Black, Scholes
and Merton (BSM), is not only unrealistic but it is also undesirable due to
high transaction costs. A variety of methods have been proposed to balance
between effective replication and losses in the incomplete market setting. With
the rise of Artificial Intelligence (AI), AI-based hedgers have attracted
considerable interest, where particular attention was given to Recurrent Neural
Network systems and variations of the $Q$-learning algorithm. From a practical
point of view, sufficient samples for training such an AI can only be obtained
from a simulator of the market environment. Yet if an agent was trained solely
on simulated data, the run-time performance will primarily reflect the accuracy
of the simulation, which leads to the classical problem of model choice and
calibration. In this article, the hedging problem is viewed as an instance of a
risk-averse contextual $k$-armed bandit problem, which is motivated by the
simplicity and sample-efficiency of the architecture. This allows for realistic
online model updates from real-world data. We find that the $k$-armed bandit
model naturally fits to the Profit and Loss formulation of hedging, providing
for a more accurate and sample efficient approach than $Q$-learning and
reducing to the Black-Scholes model in the absence of transaction costs and
risks.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:34:10 GMT""},{""version"":""v2"",""created"":""Sun, 6 Feb 2022 18:49:39 GMT""}]","2022-02-08"
"2007.01624","Medet Nursultanov","Robert Fulsche and Medet Nursultanov","Spectral Theory for Sturm-Liouville operators with measure potentials
  through Otelbaev's function","26 pages, 2 figures",,,,"math.FA math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the spectral properties of Sturm-Liouville operators with
measure potentials. We obtain two-sided estimates for the spectral distribution
function of the eigenvalues. As a corollary, we derive a criterion for the
discreteness of the spectrum and a criterion for the membership of the
resolvents to Schatten classes. We give two side estimates for the lower bound
of the essential spectrum. Our main tool in achieving this is Otelbaev's
function.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:41:13 GMT""},{""version"":""v2"",""created"":""Sun, 13 Jun 2021 01:38:55 GMT""}]","2021-06-15"
"2007.01625","Fabricio Breve","Jefferson Antonio Ribeiro Passerini and Fabricio Aparecido Breve","Complex Network Construction for Interactive Image Segmentation using
  Particle Competition and Cooperation: A New Approach","The 20th International Conference on Computational Science and its
  Applications (ICCSA2020)",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the interactive image segmentation task, the Particle Competition and
Cooperation (PCC) model is fed with a complex network, which is built from the
input image. In the network construction phase, a weight vector is needed to
define the importance of each element in the feature set, which consists of
color and location information of the corresponding pixels, thus demanding a
specialist's intervention. The present paper proposes the elimination of the
weight vector through modifications in the network construction phase. The
proposed model and the reference model, without the use of a weight vector,
were compared using 151 images extracted from the Grabcut dataset, the PASCAL
VOC dataset and the Alpha matting dataset. Each model was applied 30 times to
each image to obtain an error average. These simulations resulted in an error
rate of only 0.49\% when classifying pixels with the proposed model while the
reference model had an error rate of 3.14\%. The proposed method also presented
less error variation in the diversity of the evaluated images, when compared to
the reference model.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:42:07 GMT""}]","2020-07-06"
"2007.01626","Charles Cox","Charles Garnet Cox","Invariable generation and the Houghton groups","11 pages, 1 figure",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Houghton groups $H_1, H_2, \ldots$ are a family of infinite groups. In
1975 Wiegold showed that $H_3$ was invariably generated (IG) but $H_1\le H_3$
was not. A natural question is then whether the groups $H_2, H_3, \ldots$ are
all IG. Wiegold also ends by saying that, in the examples he had found of an IG
group with a subgroup that is not IG, the subgroup was never of finite index.
Another natural question is then whether there is a subgroup of finite index in
$H_3$ that is not IG. In this note we prove, for each $n\in \{2, 3, \ldots\}$,
that $H_n$ and all of its finite index subgroups are IG.
  The independent work of Minasyan and Goffer-Lazarovich in June 2020 frames
this note quite nicely: they showed that an IG group can have a finite index
subgroup that is not IG.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:42:18 GMT""}]","2020-07-06"
"2007.01627","Thomas Moreau","Marine Le Morvan (PARIETAL, IJCLab), Julie Josse (CMAP, XPOP), Thomas
  Moreau (PARIETAL), Erwan Scornet (CMAP), Ga\""el Varoquaux (PARIETAL, MILA)","NeuMiss networks: differentiable programming for supervised learning
  with missing values",,"Advances in Neural Information Processing Systems 33, Dec 2020,
  Vancouver, Canada",,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The presence of missing values makes supervised learning much more
challenging. Indeed, previous work has shown that even when the response is a
linear function of the complete data, the optimal predictor is a complex
function of the observed entries and the missingness indicator. As a result,
the computational or sample complexities of consistent approaches depend on the
number of missing patterns, which can be exponential in the number of
dimensions. In this work, we derive the analytical form of the optimal
predictor under a linearity assumption and various missing data mechanisms
including Missing at Random (MAR) and self-masking (Missing Not At Random).
Based on a Neumann-series approximation of the optimal predictor, we propose a
new principled architecture, named NeuMiss networks. Their originality and
strength come from the use of a new type of non-linearity: the multiplication
by the missingness indicator. We provide an upper bound on the Bayes risk of
NeuMiss networks, and show that they have good predictive accuracy with both a
number of parameters and a computational complexity independent of the number
of missing data patterns. As a result they scale well to problems with many
features, and remain statistically efficient for medium-sized samples.
Moreover, we show that, contrary to procedures using EM or imputation, they are
robust to the missing data mechanism, including difficult MNAR settings such as
self-masking.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:42:25 GMT""},{""version"":""v2"",""created"":""Mon, 12 Oct 2020 12:29:36 GMT""},{""version"":""v3"",""created"":""Tue, 13 Oct 2020 14:47:18 GMT""},{""version"":""v4"",""created"":""Wed, 4 Nov 2020 15:39:04 GMT""}]","2020-11-05"
"2007.01628","Wenxi Liu","Yuzhen Niu, Jianbin Wu, Wenxi Liu, Wenzhong Guo, Rynson W.H. Lau","HDR-GAN: HDR Image Reconstruction from Multi-Exposed LDR Images with
  Large Motions",,,"10.1109/TIP.2021.3064433",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Synthesizing high dynamic range (HDR) images from multiple low-dynamic range
(LDR) exposures in dynamic scenes is challenging. There are two major problems
caused by the large motions of foreground objects. One is the severe
misalignment among the LDR images. The other is the missing content due to the
over-/under-saturated regions caused by the moving objects, which may not be
easily compensated for by the multiple LDR exposures. Thus, it requires the HDR
generation model to be able to properly fuse the LDR images and restore the
missing details without introducing artifacts. To address these two problems,
we propose in this paper a novel GAN-based model, HDR-GAN, for synthesizing HDR
images from multi-exposed LDR images. To our best knowledge, this work is the
first GAN-based approach for fusing multi-exposed LDR images for HDR
reconstruction. By incorporating adversarial learning, our method is able to
produce faithful information in the regions with missing content. In addition,
we also propose a novel generator network, with a reference-based residual
merging block for aligning large object motions in the feature domain, and a
deep HDR supervision scheme for eliminating artifacts of the reconstructed HDR
images. Experimental results demonstrate that our model achieves
state-of-the-art reconstruction performance over the prior HDR methods on
diverse scenes.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:42:35 GMT""}]","2021-04-07"
"2007.01629","Daniel Preu{\ss}","Daniel Preu{\ss}, Tino Weinkauf, and Jens Kr\""uger","A Discrete Probabilistic Approach to Dense Flow Visualization",,,,,"cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dense flow visualization is a popular visualization paradigm. Traditionally,
the various models and methods in this area use a continuous formulation,
resting upon the solid foundation of functional analysis. In this work, we
examine a discrete formulation of dense flow visualization. From probability
theory, we derive a similarity matrix that measures the similarity between
different points in the flow domain, leading to the discovery of a whole new
class of visualization models. Using this matrix, we propose a novel
visualization approach consisting of the computation of spectral embeddings,
i.e., characteristic domain maps, defined by particle mixture probabilities.
These embeddings are scalar fields that give insight into the mixing processes
of the flow on different scales. The approach of spectral embeddings is already
well studied in image segmentation, and we see that spectral embeddings are
connected to Fourier expansions and frequencies. We showcase the utility of our
method using different 2D and 3D flows.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:45:51 GMT""}]","2020-07-06"
"2007.01630","Takuya Kawasaki","Takuya Kawasaki, Naoki Kita, Koji Nagano, Shotaro Wada, Yuya Kuwahara,
  Masaki Ando, Yuta Michimura","Optical trapping of the transversal motion for an optically levitated
  mirror","8 pages, 7 figures","Phys. Rev. A 102, 053520 (2020)","10.1103/PhysRevA.102.053520",,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optomechanical systems are suitable for elucidating quantum phenomena at the
macroscopic scale in the sense of the mass scale. The systems should be
well-isolated from the environment to avoid classical noises, which conceal
quantum signals. Optical levitation is a promising way to isolate
optomechanical systems from the environment. To realize optical levitation, all
degrees of freedom need to be trapped. Until now, longitudinal trapping and
rotational trapping of a mirror with optical radiation pressure have been
studied in detail and validated with various experiments. However, less
attention has been paid to the transversal trapping of a mirror. Herein, we
report a pioneering result where we experimentally confirmed transversal
trapping of a mirror of a Fabry-P\'erot cavity using a torsional pendulum.
Through this demonstration, we experimentally proved that optical levitation is
realizable with only two Fabry-P\'erot cavities that are aligned vertically.
This work paves the way toward optical levitation and realizing a macroscopic
quantum system.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:50:38 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 06:47:43 GMT""}]","2020-12-22"
"2007.01631","Kamila {\L}yczek","Piotr Gwiazda and Sander C. Hille and Kamila {\L}yczek","Existence and differentiability in parameter of the measure solution to
  a perturbed non-linear transport equation",,,,,"math.AP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a perturbation in the non-linear transport equation on measures
i.e. both initial condition $\mu_0$ and the solution $\mu_t^h$ are bounded
Radon measures $\mathcal{M}(\mathbb{R}^d)$. The perturbations occur in the
velocity field and also in the right-hand side scalar function. It is shown
that the solution is differentiable with respect to the perturbation parameter
$h$ i.e. that derivative is an element of a proper Banach space. This result
extends our previous result which considered the linear transport equation. The
proof exploits approximation of the non-linear problem which is based on the
study of the linear equation.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:52:17 GMT""}]","2020-07-06"
"2007.01632","Juuso \""Osterman","Juuso \""Osterman","On Finite Representation of Dimensionally Regularized One-loop Integrals","19 pages; references added",,,,"math-ph hep-th math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dimensional regularization of Euclidean momentum space integrals is a highly
successful technique in renormalization of quantum field theories. While it
yields a straightforward algorithmic method, with which to evaluate diagrams
beyond tree level, the actual integrals can be highly divergent, at least in a
traditional sense. In particular, standard one-loop integrals can be expressed
in terms of an explicit formula, which associates both ultraviolet and infrared
divergent parameter values to analytically continued special function
expressions. We aim to discuss the formulation of finite integral expressions
corresponding to the analytically continued structures. Effectively, we wish to
establish conditions which form an equivalence class for this analytical
continuation, or rather form a proper set/conditions of regularization
techniques leading to it. This is further demonstrated by considering both
partially and fully successful strategies side-by-side, with major emphasis on
the two simplest functioning schemes: Gaussian and cut-off regularization. By
explicit computations we aim to associate these generalisations of the initial
integrals with the results from dimensional regularization, considering both
multiple mass (or momentum) scales as well as scaleless cases. We achieve the
finiteness of the sought-after integrals by applying one of these suitable
schemes along with an additional scheme related scale. This enables us to
devise a proper representation of the dimensionally regularized expressions (or
a local description) through an operator removing all excess terms with the
additional scale(s).
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:57:35 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 09:27:28 GMT""},{""version"":""v3"",""created"":""Wed, 2 Sep 2020 10:58:43 GMT""}]","2020-09-03"
"2007.01633","Gediminas Simutis","G. Simutis, T. Takayama, Q. Barth\'elemy, F. Bert, H. Takagi and P.
  Mendels","Magnetic correlations in the semimetallic hyper-kagome iridate Na3Ir3O8",,"Phys. Rev. B 103, 100404 (2021)","10.1103/PhysRevB.103.L100404",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a microscopic study of a doped quantum spin liquid candidate, the
hyperkagome Na$_3$Ir$_3$O$_8$ compound by using $^{23}$Na NMR. We determine the
intrinsic behavior of the uniform \textbf{q} $ = 0$ susceptibility via shift
measurements and the dynamical response by probing the spin-lattice relaxation
rate. Throughout the studied temperature range, the susceptibility is
consistent with a semimetal behavior, though with electronic bands
substantially modified by correlations. Remarkably, the antiferromagnetic
fluctuations present in the insulating parent compound Na$_4$Ir$_3$O$_8$
survive in the studied compound. The spin dynamics are consistent with 120$^o$
excitations modes displaying short-range correlations.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:08:59 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 21:41:27 GMT""}]","2021-03-17"
"2007.01634","Christina Maria Mayr","Christina Maria Mayr, Gerta K\""oster","Social distancing with the Optimal Steps Model","9 pages, 8 figures, 4 tables",,,,"cs.MA physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the Covid-19 pandemic an urgent need to simulate social distancing
arises. The Optimal Steps Model (OSM) is a pedestrian locomotion model that
operationalizes an individual's need for personal space. We present new
parameter values for personal space in the Optimal Steps Model to simulate
social distancing in the pedestrian dynamics simulator Vadere. Our approach is
pragmatic. We consider two use cases: in the first we demand that a set social
distance must never be violated. In the second the social distance must be kept
only on average. For each use case we conduct simulation studies in a typical
bottleneck scenario and measure contact times, that is, violations of the
social distance rule. We derive rules of thumb for suitable parameter choices
in dependency of the desired social distance. We test the rules of thumb for
the social distances 1.5m and 2.0m and observe that the new parameter values
indeed lead to the desired social distancing. Thus, the rules of thumb will
quickly enable Vadere users to conduct their own studies without understanding
the intricacies of the OSM implementation and without extensive parameter
adjustment.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:10:40 GMT""},{""version"":""v2"",""created"":""Tue, 1 Mar 2022 08:44:24 GMT""}]","2022-03-02"
"2007.01635","Philipp Wacker","Philipp Wacker","Pointwise defined version of conditional expectation with respect to a
  random variable",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is often of interest to condition on a singular event given by a random
variable, e.g. $\{Y=y\}$ for a continuous random variable $Y$. Conditional
measures with respect to this event are usually derived as a special case of
the conditional expectation with respect to the random variables generating
sigma algebra. The existence of the latter is usually proven via a
non-constructive measure-theoretic argument which yields an only
almost-everywhere defined quantity. In particular, the quantity $\mathbb
E[f|Y]$ is initially only defined almost everywhere and conditioning on $Y=y$
corresponds to evaluating $\mathbb E[f|Y=y] = \mathbb E[f|Y]{Y=y}$, which is
not meaningful because of $\mathbb E[f|Y]$ not being well-defined on such
singular sets. This problem is not addressed by the introduction of regular
conditional distributions, either. On the other hand it can be shown that the
naively computed conditional density $f_{Z|Y=y}(z)$ (which is given by the
ratio of joint and marginal densities) is a version of the conditional
distribution, i.e. $\mathbb E[\{Z\in B\}|Y=y] = \int_B f_{Z|Y=y}(z) dz$ and
this density can indeed be evaluated pointwise in $y$. This mismatch between
mathematical theory (which generates an object which cannot produce what we
need from it) and practical computation via the conditional density is an
unfortunate fact. Furthermore, the classical approach does not allow a
pointwise definition of conditional expectations of the form $\mathbb
E[f|Y=y]$, only of conditional distributions $\mathbb E[\{Z\in B\}|Y=y]$. We
propose a (as far as the author is aware) little known approach to obtaining a
pointwise defined version of conditional expectation by use of the
Lebesgue-Besicovich lemma without the need of additional topological arguments
which are necessary in the usual derivation.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:11:42 GMT""}]","2020-07-06"
"2007.01636","Marinus Lagerwerf","Marinus J. Lagerwerf, Allard A. Hendriksen, Jan-Willem Buurlage and K.
  Joost Batenburg","Noise2Filter: fast, self-supervised learning and real-time
  reconstruction for 3D Computed Tomography",,,,,"eess.IV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  At X-ray beamlines of synchrotron light sources, the achievable
time-resolution for 3D tomographic imaging of the interior of an object has
been reduced to a fraction of a second, enabling rapidly changing structures to
be examined. The associated data acquisition rates require sizable
computational resources for reconstruction. Therefore, full 3D reconstruction
of the object is usually performed after the scan has completed. Quasi-3D
reconstruction -- where several interactive 2D slices are computed instead of a
3D volume -- has been shown to be significantly more efficient, and can enable
the real-time reconstruction and visualization of the interior. However,
quasi-3D reconstruction relies on filtered backprojection type algorithms,
which are typically sensitive to measurement noise. To overcome this issue, we
propose Noise2Filter, a learned filter method that can be trained using only
the measured data, and does not require any additional training data. This
method combines quasi-3D reconstruction, learned filters, and self-supervised
learning to derive a tomographic reconstruction method that can be trained in
under a minute and evaluated in real-time. We show limited loss of accuracy
compared to training with additional training data, and improved accuracy
compared to standard filter-based methods.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:12:10 GMT""}]","2020-07-06"
"2007.01637","L\'eo Henry","L\'eo Henry, Nicolas Markey, Thierry J\'eron","Active learning of timed automata with unobservable resets","Long version of the FORMATS2020 paper of same name",,,,"cs.LO cs.FL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active learning of timed languages is concerned with the inference of timed
automata from observed timed words. The agent can query for the membership of
words in the target language, or propose a candidate model and verify its
equivalence to the target. The major difficulty of this framework is the
inference of clock resets, central to the dynamics of timed automata, but not
directly observable. Interesting first steps have already been made by
restricting to the subclass of event-recording automata, where clock resets are
tied to observations. In order to advance towards learning of general timed
automata, we generalize this method to a new class, called reset-free
event-recording automata, where some transitions may reset no clocks. This
offers the same challenges as generic timed automata while keeping the simpler
framework of event-recording automata for the sake of readability. Central to
our contribution is the notion of invalidity, and the algorithm and data
structures to deal with it, allowing on-the-fly detection and pruning of reset
hypotheses that contradict observations, a key to any efficient active-learning
procedure for generic timed automata.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:13:42 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 07:30:20 GMT""}]","2020-07-09"
"2007.01638","Li-Sheng Geng","Qian-Qian Bai, Chun-Xuan Wang, Yang Xiao, and Li-Sheng Geng","Pion-mass dependence of the nucleon-nucleon interaction","7 pages, 5 figures, uncertainties generated by cutoff variations are
  added, and matched to the published version",,"10.1016/j.physletb.2020.135745",,"nucl-th hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nucleon-nucleon interactions, both bare and effective, play an important role
in our understanding of the non-perturbative strong interaction, as well as
nuclear structure and reactions. In recent years, tremendous efforts have been
seen in the lattice QCD community to derive nucleon-nucleon interactions from
first principles. Because of the daunting computing resources needed, most of
such simulations were still performed with larger than physical light quark
masses. In the present work, employing the recently proposed covariant chiral
effective field theory (ChEFT), we study the light quark mass dependence of the
nucleon-nucleon interaction extracted by the HALQCD group. It is shown that the
pion-full version of the ChEFT can describe the lattice QCD data with
$m_\pi=469$ MeV and their experimental counterpart reasonably well, while the
pion-less version can describe the lattice QCD data with $m_\pi=672, 837, 1015,
1171$ MeV, for both the $^1S_0$ and $^3S_1$-$^3D_1$ channels. The slightly
better description of the single channel than the triplet channel indicates
that higher order studies are necessary for the latter. Our results confirmed
previous studies that the nucleon-nucleon interaction becomes more attractive
for both the singlet and triplet channels as the pion mass decreases towards
its physical value. It is shown that the virtual bound state in the $^1S_0$
channel remains virtual down to the chiral limit, while the deuteron only
appears for a pion mass smaller than about 400 MeV. It seems that proper chiral
extrapolations of nucleon-nucleon interaction are possible for pion masses
smaller than 500 MeV, similar to the mesonic and one-baryon sectors.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:15:18 GMT""},{""version"":""v2"",""created"":""Tue, 29 Sep 2020 07:26:55 GMT""}]","2020-09-30"
"2007.01639","Yue Zhang","Yue Zhang, Yanbo Shen, Xiangao Xia, Guangyu Shi","Validation of GFS day-ahead solar irradiance forecasts in China","42 pages, 4 figures, 13 tables",,,,"physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper provides a benchmark to evaluate operational day-ahead solar
irradiance forecasts of Global Forecast System (GFS) for solar energy
applications in China. First, GFS day-ahead solar irradiance forecasts are
validated quantitatively with hourly observations at 17 first-class national
solar monitoring stations and 1 Baseline Surface Radiation Network (BSRN)
station all over China. Second, a hybrid forecast method based on Gradient
Boosting (GB) and GFS product is proposed to improve forecasts accuracy. Both
GFS forecasts and GB-based forecasts are compared with persistence forecasts.
The results demonstrate persistence model is more accurate than GFS forecasts,
and the hybrid method has the best performance. Besides, parameter optimization
of direct-diffuse separation fails to reduce the errors of direct normal
irradiance (DNI) forecasts.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:16:27 GMT""}]","2020-07-06"
"2007.01640","Marta Le\'sniak","Marta Le\'sniak, B{\l}a\.zej Szepietowski","Generating the mapping class group of a nonorientable surface by three
  torsions","17 pages, 11 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the mapping class group $\mathcal{M}(N_g)$ of a closed
nonorientable surface of genus $g$ different than 4 is generated by three
torsion elements. Moreover, for every even integer $k\ge 12$ and $g$ of the
form $g=pk+2q(k-1)$ or $g=pk+2q(k-1)+1$, where $p,q$ are non-negative integers
and $p$ is odd, $\mathcal{M}(N_g)$ is generated by three conjugate elements of
order $k$. Analogous results are proved for the subgroup of $\mathcal{M}(N_g)$
generated by Dehn twists.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:16:45 GMT""}]","2020-07-06"
"2007.01641","Karl Grosse-Erdmann","Antonio Bonilla and Karl-G. Grosse-Erdmann","Zero-one law of orbital limit points for weighted shifts",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chan and Seceleanu have shown that if a weighted shift on
$\ell^p(\mathbb{Z})$ admits an orbit with a non-zero limit point then it is
hypercyclic. We present a new proof of this result that allows to extend it to
very general sequence spaces. Under a stronger assumption on the orbit we also
obtain that the weighted shift is chaotic.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:20:19 GMT""}]","2020-07-06"
"2007.01642","Alistair Savage","Jonathan Brundan, Alistair Savage, Ben Webster","Foundations of Frobenius Heisenberg categories","50 pages; v2: minor corrections, published version","Journal of Algebra 578 (2021), 115-185","10.1016/j.jalgebra.2021.02.025",,"math.RT math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe bases for the morphism spaces of the Frobenius Heisenberg
categories associated to a symmetric graded Frobenius algebra, proving several
open conjectures. Our proof uses a categorical comultiplication and generalized
cyclotomic quotients of the category. We use our basis theorem to prove that
the Grothendieck ring of the Karoubi envelope of the Frobenius Heisenberg
category recovers the lattice Heisenberg algebra associated to the Frobenius
algebra.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:21:04 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 19:12:05 GMT""}]","2021-11-12"
"2007.01643","David Krejcirik","David Krejcirik and Pedro. R. S. Antunes","Bound states in semi-Dirac semi-metals","5 pages, 4 figures","Phys. Lett. A 386 (2021) 126991","10.1016/j.physleta.2020.126991",,"math-ph cond-mat.mes-hall math.MP math.SP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  New insights into transport properties of nanostructures with a linear
dispersion along one direction and a quadratic dispersion along another are
obtained by analysing their spectral stability properties under small
perturbations. Physically relevant sufficient and necessary conditions to
guarantee the existence of discrete eigenvalues are derived under rather
general assumptions on external fields. One of the most interesting features of
the analysis is the evident spectral instability of the systems in the weakly
coupled regime. The rigorous theoretical results are illustrated by numerical
experiments and predictions for physical experiments are made.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:22:19 GMT""}]","2022-08-22"
"2007.01644","Johannes M. Fink","M. Peruzzo, A. Trioni, F. Hassani, M. Zemlicka, J. M. Fink","Surpassing the resistance quantum with a geometric superinductor","8 pages, 5 figures, 1 table","Phys. Rev. Applied 14, 044055 (2020)","10.1103/PhysRevApplied.14.044055",,"cond-mat.mes-hall cond-mat.supr-con quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The superconducting circuit community has recently discovered the promising
potential of superinductors. These circuit elements have a characteristic
impedance exceeding the resistance quantum $R_\text{Q} \approx
6.45~\text{k}\Omega$ which leads to a suppression of ground state charge
fluctuations. Applications include the realization of hardware protected qubits
for fault tolerant quantum computing, improved coupling to small dipole moment
objects and defining a new quantum metrology standard for the ampere. In this
work we refute the widespread notion that superinductors can only be
implemented based on kinetic inductance, i.e. using disordered superconductors
or Josephson junction arrays. We present modeling, fabrication and
characterization of 104 planar aluminum coil resonators with a characteristic
impedance up to 30.9 $\text{k}\Omega$ at 5.6 GHz and a capacitance down to
$\leq1$ fF, with low-loss and a power handling reaching $10^8$ intra-cavity
photons. Geometric superinductors are free of uncontrolled tunneling events and
offer high reproducibility, linearity and the ability to couple magnetically -
properties that significantly broaden the scope of future quantum circuits.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:22:44 GMT""}]","2020-11-04"
"2007.01645","Henri H\""anninen","G. Beuf, H. H\""anninen, T. Lappi and H. M\""antysaari","Color Glass Condensate at next-to-leading order meets HERA data","20 pages, 9 figures. v2: matches published version. Fit results
  available at https://doi.org/10.5281/zenodo.4229269","Phys. Rev. D 102, 074028 (2020)","10.1103/PhysRevD.102.074028",,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform the first dipole picture fit to HERA inclusive cross section data
using the full next-to-leading order (NLO) impact factor combined with an
improved Balitsky-Kovchegov evolution including the dominant effects beyond
leading logarithmic accuracy at low $x$. We find that three different
formulations of the evolution equation that have been proposed in the recent
literature result in a very similar description of HERA data, and robust
predictions for future deep inelastic scattering experiments. We find evidence
pointing towards a significant nonperturbative contribution to the structure
function for light quarks, which stresses the need to extend the NLO impact
factor calculation to massive quarks.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:28:27 GMT""},{""version"":""v2"",""created"":""Tue, 3 Nov 2020 13:33:31 GMT""}]","2020-11-04"
"2007.01646","Haiping Wu","Yan Qian, Erjun Kan, Kaiming Deng, Haiping Wu","Transition between half-metal and ferromagnetic semiconductor induced by
  silicon vacancy in epitaxial silicene",,,"10.1088/1361-6463/abd356",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since the inevitability in experimental synthesis, defects show great
importance to many materials. They will deeply regulate the properties of the
materials, and then affect the further applications. Thus, exploring the
effects of defects on the properties of materials is desired. Here, by using
first-principles calculations, we systematically studied the effect of silicon
vacancy defects on the properties of silicene generated on Nterminated cubic
boron nitride (111) surface. It is found that the introduction of silicon
vacancy would trigger transition between half-metal and ferromagnetic
semiconductor. With small vacancy ratios of 1/36 and 1/24, the ground-state of
the samples would behave as ferromagnetic semiconductors, and the band gaps are
about 1.25 and 0.95 eV, respectively. When the vacancy ratio is increased up to
1/6, the sample would turn into a ferromagnetic half-metal with a half-metallic
gap of around 0.15 eV. The change of the electronic structure of the samples is
driven by the different electron transfer between silicon layer and substrate,
i.e., there will be different amount of electrons transferred from the silicon
layer to the substrate when the vacancy ratio is altered. This work would open
a new way to regulate the properties of materials and extend applications in
nanoelectronic field.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:29:10 GMT""}]","2021-02-03"
"2007.01647","Martin Stetter Ph.D.","Martin Stetter and Elmar W. Lang","Learning intuitive physics and one-shot imitation using
  state-action-prediction self-organizing maps","27 pages, 5 figures",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human learning and intelligence work differently from the supervised pattern
recognition approach adopted in most deep learning architectures. Humans seem
to learn rich representations by exploration and imitation, build causal models
of the world, and use both to flexibly solve new tasks. We suggest a simple but
effective unsupervised model which develops such characteristics. The agent
learns to represent the dynamical physical properties of its environment by
intrinsically motivated exploration, and performs inference on this
representation to reach goals. For this, a set of self-organizing maps which
represent state-action pairs is combined with a causal model for sequence
prediction. The proposed system is evaluated in the cartpole environment. After
an initial phase of playful exploration, the agent can execute kinematic
simulations of the environment's future, and use those for action planning. We
demonstrate its performance on a set of several related, but different one-shot
imitation tasks, which the agent flexibly solves in an active inference style.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:29:11 GMT""},{""version"":""v2"",""created"":""Fri, 8 Jan 2021 10:10:53 GMT""},{""version"":""v3"",""created"":""Wed, 27 Oct 2021 09:33:07 GMT""}]","2021-10-28"
"2007.01648","Michel Kinsy","Rashmi Agrawal, Lake Bu, Alan Ehret and Michel A. Kinsy","Fast Arithmetic Hardware Library For RLWE-Based Homomorphic Encryption",,,,"Report ascs-r06","cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we propose an open-source, first-of-its-kind, arithmetic
hardware library with a focus on accelerating the arithmetic operations
involved in Ring Learning with Error (RLWE)-based somewhat homomorphic
encryption (SHE). We design and implement a hardware accelerator consisting of
submodules like Residue Number System (RNS), Chinese Remainder Theorem (CRT),
NTT-based polynomial multiplication, modulo inverse, modulo reduction, and all
the other polynomial and scalar operations involved in SHE. For all of these
operations, wherever possible, we include a hardware-cost efficient serial and
a fast parallel implementation in the library. A modular and parameterized
design approach helps in easy customization and also provides flexibility to
extend these operations for use in most homomorphic encryption applications
that fit well into emerging FPGA-equipped cloud architectures. Using the
submodules from the library, we prototype a hardware accelerator on FPGA. The
evaluation of this hardware accelerator shows a speed up of approximately 4200x
and 2950x to evaluate a homomorphic multiplication and addition respectively
when compared to an existing software implementation.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:30:32 GMT""}]","2020-07-06"
"2007.01649","Huseyin Alpaslan Yildiz","Huseyin Alpaslan Yildiz, Leyla Goren-Sumer","Stabilizing of a Class of Underactuated Euler Lagrange System Using an
  Approximate Model","14 pages, 7 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The energy shaping method, Controlled Lagrangian, is a well-known approach to
stabilize the under-actuated Euler Lagrange (EL) systems. In this approach, to
construct a control rule, some nonlinear, nonhomogeneous partial differential
equations (PDEs), which are called matching conditions, must be solved. In this
paper, a method is proposed to obtain an approximate solution of these matching
conditions for a class of under-actuated EL systems. To develop the method, the
potential energy matching condition is transformed to a set of linear PDEs
using an approximation of inertia matrices. So the assignable potential energy
function and the controlled inertia matrix, both are constructed as a common
solution of these PDEs. Afterwards, the gyroscopic and dissipative forces are
found as the solution of the kinetic energy matching condition. Finally, the
control rule is constructed by adding energy shaping rule and additional
dissipation injection to provide asymptotic stability. The stability analysis
of the closed loop system which used the control rule derived with the proposed
method is also given. To demonstrate the success of the proposed method, the
stability problem of the inverted pendulum on a cart is considered.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:36:51 GMT""}]","2020-07-06"
"2007.01650","Massimiliano Lattanzi","Massimiliano Lattanzi, Martina Gerbino, Katherine Freese, Gordon Kane
  and Jos\'e W. F. Valle","Cornering (quasi) degenerate neutrinos with cosmology","19 pages, 6 figures, 1 table","JHEP 10 (2020) 213","10.1007/JHEP10(2020)213","IFIC/20-XXX","astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In light of the improved sensitivities of cosmological observations, we
examine the status of quasi-degenerate neutrino mass scenarios. Within the
simplest extension of the standard cosmological model with massive neutrinos,
we find that quasi-degenerate neutrinos are severely constrained by present
cosmological data and neutrino oscillation experiments. % % We find that Planck
2018 observations of cosmic microwave background (CMB) anisotropies disfavour
quasi-degenerate neutrino masses at $2.4$ Gaussian $\sigma$'s, while adding
Baryon acoustic oscillations (BAO) data brings the rejection to 5.9$\sigma$'s.
% The highest statistical significance with which one would be able to rule out
quasi-degeneracy would arise if the sum of neutrino masses is $\Sigma m_\nu =
60$ \meV (the minimum allowed by neutrino oscillation experiments); % indeed a
sensitivity of 15 meV, as expected from a combination of future cosmological
probes, would further improve the rejection level up to 17$\sigma$. % We
discuss the robustness of these projections with respect to assumptions on the
underlying cosmological model, and also compare them with bounds from $\beta$
decay endpoint and neutrinoless double beta decay studies.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:42:00 GMT""}]","2021-03-30"
"2007.01651","Chunhai Lyu","Chunhai Lyu, Stefano M. Cavaletto, Christoph H. Keitel and Zolt\'an
  Harman","Interrogating the temporal coherence of EUV frequency combs with highly
  charged ions","6 pages, 3 figures and 1 table","Phys. Rev. Lett. 125, 093201 (2020)","10.1103/PhysRevLett.125.093201",,"physics.atom-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A scheme to infer the temporal coherence of EUV frequency combs generated
from intra-cavity high-order harmonic generation is put forward. The excitation
dynamics of highly charged Mg-like ions, interacting with EUV pulse trains
featuring different carrier-envelope-phase fluctuations, are simulated. While
demonstrating the microscopic origin of the macroscopic equivalence between
excitations induced by pulse trains and continuous-wave lasers, we show that
the coherence time of the pulse train can be determined from the spectrum of
the excitations. The scheme will provide a verification of the comb temporal
coherence at time scales several orders of magnitude longer than current state
of the art, and at the same time will enable high-precision spectroscopy of EUV
transitions with a relative accuracy up to $\delta\omega/\omega\sim10^{-17}$.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:43:41 GMT""}]","2020-09-02"
"2007.01652","Heng-Da Xu","Heng-Da Xu, Xian-Ling Mao, Zewen Chi, Jing-Jing Zhu, Fanshu Sun, Heyan
  Huang","Generating Informative Dialogue Responses with Keywords-Guided Networks",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, open-domain dialogue systems have attracted growing attention. Most
of them use the sequence-to-sequence (Seq2Seq) architecture to generate
responses. However, traditional Seq2Seq-based open-domain dialogue models tend
to generate generic and safe responses, which are less informative, unlike
human responses. In this paper, we propose a simple but effective
keywords-guided Sequence-to-Sequence model (KW-Seq2Seq) which uses keywords
information as guidance to generate open-domain dialogue responses.
Specifically, KW-Seq2Seq first uses a keywords decoder to predict some topic
keywords, and then generates the final response under the guidance of them.
Extensive experiments demonstrate that the KW-Seq2Seq model produces more
informative, coherent and fluent responses, yielding substantive gain in both
automatic and human evaluation metrics.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:47:13 GMT""}]","2020-07-06"
"2007.01653","Randhir Singh","Randhir Singh","Analytic solution of system of singular nonlinear differential equations
  with Neumann-Robin boundary conditions arising in astrophysics",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a new approach for the approximate analytic
solution of system of Lane-Emden-Fowler type equations with Neumann-Robin
boundary conditions. The algorithm is based on Green's function and the
homotopy analysis method. This approach depends on constructing Green's
function before establishing the recursive scheme for the approximate analytic
solution of the equivalent system of integral equations. Unlike Adomian
decomposition method (ADM) \cite{singh2020solving}, the present method contains
adjustable parameters to control the convergence of the approximate series
solution. Convergence and error estimation of the present is provided under
quite general conditions. Several examples are considered to demonstrate the
accuracy of the current algorithm. Computational results reveal that the
proposed approach produces better results as compared to some existing
iterative methods.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:47:40 GMT""}]","2020-07-06"
"2007.01654","Yannick Ulrich","P. Banerjee, T. Engel, A. Signer, Y. Ulrich","QED at NNLO with McMule","35 pages, 12 figures, minor changes, published version","SciPost Phys. 9, 027 (2020)","10.21468/SciPostPhys.9.2.027","PSI-PR-20-09, ZU-TH 23/20","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  McMule is a framework for fully differential higher-order QED calculations of
scattering and decay processes involving leptons. It keeps finite lepton
masses, which regularises collinear singularities. Soft singularities are
treated with dimensional regularisation and using FKS$^\ell$ subtraction. We
describe the implementation of the framework in Fortran 95, list the processes
that are currently implemented, and give instructions on how to run the code.
In addition, we present new phenomenological results for muon-electron
scattering and lepton-proton scattering, including the dominant NNLO
corrections. While the applications presented focus on MUonE, MUSE, and P2, the
code can be used for a large number of planned and running experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:47:53 GMT""},{""version"":""v2"",""created"":""Mon, 31 Aug 2020 12:30:37 GMT""}]","2020-09-01"
"2007.01655","Kushagra Upadhyay","Kushagra Upadhyay, Bhuwan Joshi, Prabir K. Mitra, Ramit Bhattacharyya,
  Divya Oberoi, Christian Monstein","Solar Radio Observation Using CALLISTO at the USO/PRL, Udaipur","Published in IEEE. https://ieeexplore.ieee.org/document/9118669","2019 IEEE MTT-S International Microwave and RF Conference (IMARC),
  Electronic ISBN: 978-1-7281-4040-7, Print on Demand(PoD) ISBN:
  978-1-7281-4041-4","10.1109/IMaRC45935.2019.9118669",,"astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a detailed description of various subsystems of CALLISTO
solar radio spectrograph installed at the USO/PRL. In the front-end system, a
log periodic dipole antenna (LPDA) is designed for the frequency range of
40-900 MHz. In this paper LPDA design, its modifications, and simulation
results are presented. We also present some initial observations taken by
CALLISTO at Udaipur.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:49:11 GMT""}]","2020-07-06"
"2007.01656","Niklas Fehn","Niklas Fehn and Martin Kronbichler and Peter Munch and Wolfgang A Wall","Numerical evidence of anomalous energy dissipation in incompressible
  Euler flows: Towards grid-converged results for the inviscid Taylor-Green
  problem",,,,,"physics.flu-dyn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Providing evidence of finite-time singularities of the incompressible Euler
equations in three space dimensions is still an unsolved problem. Likewise, the
zeroth law of turbulence has not been proven to date by numerical experiments.
We address this issue by high-resolution numerical simulations of the inviscid
three-dimensional Taylor-Green vortex problem using a novel high-order
discontinuous Galerkin discretization approach. Our main finding is that the
kinetic energy evolution does not tend towards exact energy conservation for
increasing spatial resolution of the numerical scheme, but instead converges to
a solution with nonzero kinetic energy dissipation rate. This implies an energy
dissipation anomaly in the absense of viscous dissipation according to
Onsager's conjecture, and serves as an indication of finite-time singularities
in incompressible inviscid flows. We demonstrate convergence to a dissipative
solution for the three-dimensional inviscid Taylor-Green problem with a
measured relative $L_2$-error of $0.27 \%$ for the temporal evolution of the
kinetic energy and $3.52 \%$ for the kinetic energy dissipation rate.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:50:05 GMT""}]","2020-07-06"
"2007.01657","Paul-Andi Nagy","Paul-Andi Nagy, Uwe Semmelmann","Deformations of nearly $G_2$-structures","Improved presentation,added full details on rigidity of Aloff-Wallach
  space $N(1,1)$. 18 pages","J.London Math.Soc. (2) 104 (2021) 1795-1811",,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the second order obstruction to deformation for nearly $G_2$
structures on compact manifolds. Building on work of B.Alexandrov and
U.Semmelmann this allows proving rigidity under deformation for the proper
nearly $G_2$ structure on the Aloff-Wallach space $N(1,1)$.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:53:03 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jul 2020 12:54:48 GMT""}]","2021-11-23"
"2007.01658","Martin Malmsten","Martin Malmsten, Love B\""orjeson and Chris Haffenden","Playing with Words at the National Library of Sweden -- Making a Swedish
  BERT",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  This paper introduces the Swedish BERT (""KB-BERT"") developed by the KBLab for
data-driven research at the National Library of Sweden (KB). Building on recent
efforts to create transformer-based BERT models for languages other than
English, we explain how we used KB's collections to create and train a new
language-specific BERT model for Swedish. We also present the results of our
model in comparison with existing models - chiefly that produced by the Swedish
Public Employment Service, Arbetsf\""ormedlingen, and Google's multilingual
M-BERT - where we demonstrate that KB-BERT outperforms these in a range of NLP
tasks from named entity recognition (NER) to part-of-speech tagging (POS). Our
discussion highlights the difficulties that continue to exist given the lack of
training data and testbeds for smaller languages like Swedish. We release our
model for further exploration and research here:
https://github.com/Kungbib/swedish-bert-models .
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:53:39 GMT""}]","2020-07-06"
"2007.01659","Takahiro Mimori","Takahiro Mimori, Keiko Sasada, Hirotaka Matsui, Issei Sato","Diagnostic Uncertainty Calibration: Towards Reliable Machine Predictions
  in Medical Domain","31 pages, 6 figures",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an evaluation framework for class probability estimates (CPEs) in
the presence of label uncertainty, which is commonly observed as diagnosis
disagreement between experts in the medical domain. We also formalize
evaluation metrics for higher-order statistics, including inter-rater
disagreement, to assess predictions on label uncertainty. Moreover, we propose
a novel post-hoc method called $alpha$-calibration, that equips neural network
classifiers with calibrated distributions over CPEs. Using synthetic
experiments and a large-scale medical imaging application, we show that our
approach significantly enhances the reliability of uncertainty estimates:
disagreement probabilities and posterior CPEs.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:54:08 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 02:07:20 GMT""},{""version"":""v3"",""created"":""Mon, 25 Jan 2021 04:40:25 GMT""},{""version"":""v4"",""created"":""Mon, 22 Mar 2021 06:23:53 GMT""}]","2021-03-23"
"2007.01661","Pierre Arthuis","P. Arthuis, A. Tichai, J. Ripoche, T. Duguet","ADG: Automated generation and evaluation of many-body diagrams II.
  Particle-number projected Bogoliubov many-body perturbation theory","24 pages, 14 figures and one table. Associated code available on
  https://github.com/adgproject/adg/",,"10.1016/j.cpc.2020.107677",,"nucl-th cond-mat.str-el physics.atom-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the second version (v2.0.0) of the code ADG that automatically
(1) generates all valid off-diagonal Bogoliubov many-body perturbation theory
diagrams at play in particle-number projected Bogoliubov many-body perturbation
theory (PNP-BMBPT) and (2) evaluates their algebraic expression to be
implemented for numerical applications. This is achieved at any perturbative
order $p$ for a Hamiltonian containing both two-body (four-legs) and three-body
(six-legs) interactions (vertices). All valid off-diagonal BMBPT diagrams of
order $p$ are systematically generated from the set of diagonal, i.e.,
unprojected, BMBPT diagrams. The production of the latter were described at
length in https://doi.org/10.1016/j.cpc.2018.11.023 dealing with the first
version of ADG. The automated evaluation of off-diagonal BMBPT diagrams relies
both on the application of algebraic Feynman's rules and on the identification
of a powerful diagrammatic rule providing the result of the remaining $p$-tuple
time integral. The new diagrammatic rule generalizes the one already identified
in https://doi.org/10.1016/j.cpc.2018.11.023 to evaluate diagonal BMBPT
diagrams independently of their perturbative order and topology. The code ADG
is written in Python3 and uses the graph manipulation package NetworkX. The
code is kept flexible enough to be further expanded throughout the years to
tackle the diagrammatics at play in various many-body formalisms that already
exist or are yet to be formulated.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:59:34 GMT""}]","2021-03-17"
"2007.01662","Maarten Van Es","Maarten H. van Es (1), Benoit A.J. Quesson (2), Abbas Mohtashami (1),
  Daniele Piras (1), Kodai Hatakeyama (1), Laurent Fillinger (2), Paul L.M.J.
  van Neer (2) ((1) Optomechatronics, TNO, Delft, The Netherlands, (2)
  Acoustics and Sonar, TNO, The Hague, The Netherlands)","Scattering contrast in GHz frequency ultrasound subsurface atomic force
  microscopy for detection of deeply buried features","18 pages, 5 figures",,,,"physics.app-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While Atomic Force Microscopy is mostly used to investigate surface
properties, people have almost since its invention sought to apply its high
resolution capability to image also structures buried within samples. One of
the earliest techniques for this was based on using ultrasound excitations to
visualize local differences in effective tip-sample stiffness caused by the
presence of buried structures with different visco-elasticity from their
surroundings. While the use of ultrasound has often triggered discussions on
the contribution of diffraction or scattering of acoustic waves in visualizing
buried structures, no conclusive papers on this topic have been published. Here
we demonstrate and discuss how such acoustical effects can be unambiguously
recognized and can be used with Atomic Force Microscopy to visualize deeply
buried structures.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:02:19 GMT""}]","2020-07-06"
"2007.01663","So Chigusa","So Chigusa, Motoi Endo, Kazunori Kohri","Constraints on electron-scattering interpretation of XENON1T excess","20 pages, 3 figures","JCAP10(2020)035","10.1088/1475-7516/2020/10/035","KEK-TH-2236, KEK-Cosmo-258","hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the XENON1T experiment has observed an excess in the electronic
recoil data in the recoil energy range of $1$-$7$ keV. One of the most favored
new physics interpretations is electron scattering with a boosted particle with
a velocity of $\sim 0.1$ and a mass of $\gtrsim 0.1\,\mathrm{MeV}$. If such a
particle has a strong interaction with electrons, it may affect the standard
scenario of cosmology or be observed at low-threshold direct detection
experiments. We study various constraints, mainly focusing on those from the
big-bang nucleosynthesis, supernova cooling, and direct detection experiments.
We discuss the implication of these constraints on electron-scattering
interpretation of the XENON1T excess.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:05:18 GMT""},{""version"":""v2"",""created"":""Tue, 13 Oct 2020 18:48:49 GMT""}]","2020-10-15"
"2007.01664","Nicolas Chamel","Nicolas Chamel, Anthea Francesca Fantina, Julian-Leszek Zdunik, Pawel
  Haensel","Experimental constraints on shallow heating in accreting neutron-star
  crusts","18 pages, 2 figures. Accepted for publication in Phys. Rev. C",,"10.1103/PhysRevC.102.015804",,"astro-ph.HE nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The observed thermal relaxation of transiently accreting neutron stars during
quiescence periods in low-mass X-ray binaries suggests the existence of unknown
heat sources in the shallow layers of neutron-star crust. Making use of
existing experimental nuclear data, we estimate the maximum possible amount of
heat that can be deposited in the outer crust of an accreting neutron star due
to electron captures and pycnonuclear fusion reactions triggered by the burial
of X-ray burst ashes.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:07:27 GMT""}]","2020-08-05"
"2007.01665","Miroslav Radomirov","A. Golubtsova, H. Dimov, I. Iliev, M. Radomirov, R. C. Rashkov, T.
  Vetsov","Pulsating strings in $Schr_5 \times T^{1,1}$ background","Minor corrections, 18 pages, no figures, no tables",,"10.1088/1751-8121/abc7e9",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quest for extension of holographic correspondence to non-relativistic
sectors naturally includes Schr\""odinger backgrounds and their field theory
duals. In this paper we study the holography by probing the correspondence with
pulsating strings. The case we consider is pulsating strings in
five-dimensional Schr\""odinger space times five-torus $T^{1,1}$, which has as
field theory dual a dipole CFT. First we find particular pulsating string
solutions and then semi-classically quantize the theory. We obtain the wave
function of the problem and thoroughly study the corrections to the energy,
which by duality are supposed to give anomalous dimensions of certain operators
in the dipole CFT.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:08:26 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jul 2020 12:51:27 GMT""}]","2021-02-03"
"2007.01666","Christopher Bl\""ocker","Christopher Bl\""ocker and Martin Rosvall","Mapping Flows on Bipartite Networks",,"Phys. Rev. E 102, 052305 (2020)","10.1103/PhysRevE.102.052305",,"cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mapping network flows provides insight into the organization of networks, but
even though many real-networks are bipartite, no method for mapping flows takes
advantage of the bipartite structure. What do we miss by discarding this
information and how can we use it to understand the structure of bipartite
networks better? The map equation models network flows with a random walk and
exploits the information-theoretic duality between compression and finding
regularities to detect communities in networks. However, it does not use the
fact that random walks in bipartite networks alternate between node types,
information worth 1 bit. To make some or all of this information available to
the map equation, we developed a coding scheme that remembers node types at
different rates. We explored the community landscape of bipartite real-world
networks from no node-type information to full node-type information and found
that using node types at a higher rate generally leads to deeper community
hierarchies and a higher resolution. The corresponding compression of network
flows exceeds the amount of extra information provided. Consequently, taking
advantage of the bipartite structure increases the resolution and reveals more
network regularities.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:08:41 GMT""},{""version"":""v2"",""created"":""Fri, 9 Oct 2020 13:49:49 GMT""}]","2020-11-18"
"2007.01667","Milan Straka","Kate\v{r}ina Mackov\'a, Milan Straka","Reading Comprehension in Czech via Machine Translation and Cross-lingual
  Transfer","Accepted at TSD 2020, 23rd International Conference on Text, Speech
  and Dialogue",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reading comprehension is a well studied task, with huge training datasets in
English. This work focuses on building reading comprehension systems for Czech,
without requiring any manually annotated Czech training data. First of all, we
automatically translated SQuAD 1.1 and SQuAD 2.0 datasets to Czech to create
training and development data, which we release at
http://hdl.handle.net/11234/1-3249. We then trained and evaluated several BERT
and XLM-RoBERTa baseline models. However, our main focus lies in cross-lingual
transfer models. We report that a XLM-RoBERTa model trained on English data and
evaluated on Czech achieves very competitive performance, only approximately 2
percent points worse than a~model trained on the translated Czech data. This
result is extremely good, considering the fact that the model has not seen any
Czech data during training. The cross-lingual transfer approach is very
flexible and provides a reading comprehension in any language, for which we
have enough monolingual raw texts.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:09:37 GMT""}]","2020-07-06"
"2007.01668","Atul Mantri","Christian Badertscher, Alexandru Cojocaru, L\'eo Colisson, Elham
  Kashefi, Dominik Leichtle, Atul Mantri, Petros Wallden","Security Limitations of Classical-Client Delegated Quantum Computing","40 pages, 12 figures","ASIACRYPT 2020 In: Moriai S., Wang H. (eds) Advances in Cryptology
  - ASIACRYPT 2020. Lecture Notes in Computer Science, vol 12492. Springer,
  Cham","10.1007/978-3-030-64834-3_23",,"quant-ph cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Secure delegated quantum computing allows a computationally weak client to
outsource an arbitrary quantum computation to an untrusted quantum server in a
privacy-preserving manner. One of the promising candidates to achieve classical
delegation of quantum computation is classical-client remote state preparation
($RSP_{CC}$), where a client remotely prepares a quantum state using a
classical channel. However, the privacy loss incurred by employing $RSP_{CC}$
as a sub-module is unclear.
  In this work, we investigate this question using the Constructive
Cryptography framework by Maurer and Renner (ICS'11). We first identify the
goal of $RSP_{CC}$ as the construction of ideal RSP resources from classical
channels and then reveal the security limitations of using $RSP_{CC}$. First,
we uncover a fundamental relationship between constructing ideal RSP resources
(from classical channels) and the task of cloning quantum states. Any
classically constructed ideal RSP resource must leak to the server the full
classical description (possibly in an encoded form) of the generated quantum
state, even if we target computational security only. As a consequence, we find
that the realization of common RSP resources, without weakening their
guarantees drastically, is impossible due to the no-cloning theorem. Second,
the above result does not rule out that a specific $RSP_{CC}$ protocol can
replace the quantum channel at least in some contexts, such as the Universal
Blind Quantum Computing (UBQC) protocol of Broadbent et al. (FOCS '09).
However, we show that the resulting UBQC protocol cannot maintain its proven
composable security as soon as $RSP_{CC}$ is used as a subroutine. Third, we
show that replacing the quantum channel of the above UBQC protocol by the
$RSP_{CC}$ protocol QFactory of Cojocaru et al. (Asiacrypt '19), preserves the
weaker, game-based, security of UBQC.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:15:13 GMT""}]","2021-01-29"
"2007.01669","Yuya Yoshikawa","Yuya Yoshikawa, Tomoharu Iwata","Gaussian Process Regression with Local Explanation",,,"10.1109/TNNLS.2021.3131234",,"cs.LG stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gaussian process regression (GPR) is a fundamental model used in machine
learning. Owing to its accurate prediction with uncertainty and versatility in
handling various data structures via kernels, GPR has been successfully used in
various applications. However, in GPR, how the features of an input contribute
to its prediction cannot be interpreted. Herein, we propose GPR with local
explanation, which reveals the feature contributions to the prediction of each
sample, while maintaining the predictive performance of GPR. In the proposed
model, both the prediction and explanation for each sample are performed using
an easy-to-interpret locally linear model. The weight vector of the locally
linear model is assumed to be generated from multivariate Gaussian process
priors. The hyperparameters of the proposed models are estimated by maximizing
the marginal likelihood. For a new test sample, the proposed model can predict
the values of its target variable and weight vector, as well as their
uncertainties, in a closed form. Experimental results on various benchmark
datasets verify that the proposed model can achieve predictive performance
comparable to those of GPR and superior to that of existing interpretable
models, and can achieve higher interpretability than them, both quantitatively
and qualitatively.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:22:24 GMT""},{""version"":""v2"",""created"":""Wed, 25 Nov 2020 13:23:07 GMT""},{""version"":""v3"",""created"":""Wed, 2 Dec 2020 10:13:54 GMT""}]","2021-12-16"
"2007.01672","Sotirios Sabanis","Sotirios Sabanis, Ying Zhang","A fully data-driven approach to minimizing CVaR for portfolio of assets
  via SGLD with discontinuous updating","arXiv admin note: text overlap with arXiv:1910.02008",,,,"q-fin.PM math.OC math.PR math.ST q-fin.MF stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new approach in stochastic optimization via the use of stochastic gradient
Langevin dynamics (SGLD) algorithms, which is a variant of stochastic gradient
decent (SGD) methods, allows us to efficiently approximate global minimizers of
possibly complicated, high-dimensional landscapes. With this in mind, we extend
here the non-asymptotic analysis of SGLD to the case of discontinuous
stochastic gradients. We are thus able to provide theoretical guarantees for
the algorithm's convergence in (standard) Wasserstein distances for both convex
and non-convex objective functions. We also provide explicit upper estimates of
the expected excess risk associated with the approximation of global minimizers
of these objective functions. All these findings allow us to devise and present
a fully data-driven approach for the optimal allocation of weights for the
minimization of CVaR of portfolio of assets with complete theoretical
guarantees for its performance. Numerical results illustrate our main findings.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 17:11:57 GMT""}]","2020-07-06"
"2007.01673","Cl\'ement Dallard","Valentin Bartier, Nicolas Bousquet, Cl\'ement Dallard, Kyle Lomer,
  Amer E. Mouawad","On girth and the parameterized complexity of token sliding and token
  jumping",,,,,"cs.CC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the Token Jumping problem we are given a graph $G = (V,E)$ and two
independent sets $S$ and $T$ of $G$, each of size $k \geq 1$. The goal is to
determine whether there exists a sequence of $k$-sized independent sets in $G$,
$\langle S_0, S_1, \ldots, S_\ell \rangle$, such that for every $i$, $|S_i| =
k$, $S_i$ is an independent set, $S = S_0$, $S_\ell = T$, and $|S_i \Delta
S_{i+1}| = 2$. In other words, if we view each independent set as a collection
of tokens placed on a subset of the vertices of $G$, then the problem asks for
a sequence of independent sets which transforms $S$ to $T$ by individual token
jumps which maintain the independence of the sets. This problem is known to be
PSPACE-complete on very restricted graph classes, e.g., planar bounded degree
graphs and graphs of bounded bandwidth. A closely related problem is the Token
Sliding problem, where instead of allowing a token to jump to any vertex of the
graph we instead require that a token slides along an edge of the graph. Token
Sliding is also known to be PSPACE-complete on the aforementioned graph
classes. We investigate the parameterized complexity of both problems on
several graph classes, focusing on the effect of excluding certain cycles from
the input graph. In particular, we show that both Token Sliding and Token
Jumping are fixed-parameter tractable on $C_4$-free bipartite graphs when
parameterized by $k$. For Token Jumping, we in fact show that the problem
admits a polynomial kernel on $\{C_3,C_4\}$-free graphs. In the case of Token
Sliding, we also show that the problem admits a polynomial kernel on bipartite
graphs of bounded degree. We believe both of these results to be of independent
interest. We complement these positive results by showing that, for any
constant $p \geq 4$, both problems are W[1]-hard on $\{C_4, \dots, C_p\}$-free
graphs and Token Sliding remains W[1]-hard even on bipartite graphs.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:28:30 GMT""},{""version"":""v2"",""created"":""Tue, 17 Nov 2020 12:36:18 GMT""}]","2020-11-18"
"2007.01674","Mohamed Farhat","M. Farhat, P.Y. Chen, S. Guenneau, and Y. Wu","CPA-Lasing in Thin-Elastic Plates via Exceptional Points","6 pages, 3 figures","Phys. Rev. B 103, 134101 (2021)","10.1103/PhysRevB.103.134101",,"physics.class-ph physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present here how a coherent perfect absorber-laser (CPAL) enabled by
parity-time ($\mathcal{PT}$)-symmetry breaking may be exploited to build
monochromatic amplifying devices for flexural waves. The fourth order partial
differential equation governing the propagation of flexural waves leads to four
by four transfer matrices, and this results in physical properties of the
$\mathcal{PT}$-symmetry specific to elastic plate systems. We thus demonstrate
the possibility of using CPAL for such systems and we argue the possibility of
using this concept to detect extremely small-scale vibration perturbations with
important outcomes in surface science (imaging of nanometer vibration) and
geophysics (improving seismic sensors like velocimeters). The device can also
generate finite signals using very low exciting intensities. The system can
alternatively be used as a perfect absorber for flexural energy by tailoring
the left and right incident wave for energy harvesting applications.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:29:09 GMT""}]","2021-04-14"
"2007.01675","Michael Chappell","Michael A. Chappell, Martin S. Craig, Mark W. Woolrich","Stochastic Variational Bayesian Inference for a Nonlinear Forward Model",,,,,"eess.SP stat.AP stat.ML","http://creativecommons.org/licenses/by/4.0/","  Variational Bayes (VB) has been used to facilitate the calculation of the
posterior distribution in the context of Bayesian inference of the parameters
of nonlinear models from data. Previously an analytical formulation of VB has
been derived for nonlinear model inference on data with additive gaussian noise
as an alternative to nonlinear least squares. Here a stochastic solution is
derived that avoids some of the approximations required of the analytical
formulation, offering a solution that can be more flexibly deployed for
nonlinear model inference problems. The stochastic VB solution was used for
inference on a biexponential toy case and the algorithmic parameter space
explored, before being deployed on real data from a magnetic resonance imaging
study of perfusion. The new method was found to achieve comparable parameter
recovery to the analytic solution and be competitive in terms of computational
speed despite being reliant on sampling.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:30:50 GMT""}]","2020-07-06"
"2007.01676","Lola Lilensten","Lola Lilensten, Stoichko Antonov, Baptiste Gault, Sammy Tin,
  Paraskevas Kontis","Enhanced creep performance in a polycrystalline superalloy driven by
  atomic-scale phase transformation along planar faults",,,"10.1016/j.actamat.2020.10.062",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Predicting the mechanical failure of parts in service requires understanding
their deformation behavior, and associated dynamic microstructural evolution up
to the near-atomic scale. Solutes are known to interact with defects generated
by plastic deformation, thereby affecting their displacement throughout the
microstructure and hence the material mechanical response to solicitation. This
effect is studied here in a polycrystalline Ni-based superalloy with two
different Nb contents that lead to a significant change in their creep
lifetime. Creep testing at 750C and 600 MPa shows that the high-Nb alloy
performs better in terms of creep strain rate. Considering the similar initial
microstructures, the difference in mechanical behavior is attributed to a phase
transformation that occurs along planar faults, controlled by the different
types of stacking faults and alloy composition. Electron channeling contrast
imaging reveals the presence of stacking faults in both alloys. Microtwinning
is observed only in the low-Nb alloy, rationalizing in part the higher creep
strain rate. In the high-Nb alloy, atom probe tomography evidences two
different types of stacking faults based on their partitioning behavior.
Superlattice intrinsic stacking faults (SISF) were found enriched in Nb, Co, Cr
and Mo while only Nb and Co was segregated at superlattice extrinsic stacking
faults. Based on their composition, a local phase transformation occurring
along the faults is suggested, resulting in slower creep strain rate in the
high-Nb alloy. In comparison, mainly SISF enriched in Co, Cr, Nb and Mo were
found in the low-Nb alloy. Following the results presented here, and those
available in the literature, an atomic-scale driven alloy design approach that
controls and promotes local phase transformation along planar faults at 750C is
proposed, aiming to design superalloys with enhanced creep resistance.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:35:15 GMT""},{""version"":""v2"",""created"":""Thu, 5 Nov 2020 16:06:45 GMT""}]","2020-11-06"
"2007.01677","Fabio Bagarello Dr.","Fabio Bagarello","Susy for non-Hermitian Hamiltonians, with a view to coherent states","In press in Mathematical Physics, Analysis and Geometry",,"10.1007/s11040-020-09353-3",,"math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an extended version of supersymmetric quantum mechanics which can
be useful if the Hamiltonian of the physical system under investigation is not
Hermitian. The method is based on the use of two, in general different,
superpotentials. Bi-coherent states of the Gazeau-Klauder type are constructed
and their properties are analyzed. Some examples are also discussed, including
an application to the Black-Scholes equation, one of the most important
equations in Finance.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:37:31 GMT""}]","2020-08-26"
"2007.01678","Eric Poisson","Eric Poisson","Gravitomagnetic Love tensor of a slowly rotating body: post-Newtonian
  theory","20 pages, 3 figures, new appendix, matches published version","Phys. Rev. D 102, 064059 (2020)","10.1103/PhysRevD.102.064059",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The gravitomagnetic tidal Love number of a slowly rotating body was
calculated previously under the assumption that the velocity perturbation
created by the tidal field consists of an induction piece proportional to the
vector potential, and a rotational piece that scales with $\Omega$, the body's
angular velocity. The second part of this assumption is wrong: the rotational
piece of the velocity perturbation scales in fact like $\Omega^0 = 1$. The
previous calculations are therefore incorrect, and the purpose of this paper is
to repair the mistake. To keep the technical difficulties to a minimum, the
treatment here is restricted to a post-Newtonian expansion carried out to
leading order -- previous calculations of the gravitomagnetic Love number were
performed in full general relativity. On the other hand, the computation
presented here is not restricted to a stationary tidal field. I show that the
correct scaling of the velocity perturbation with $\Omega$ leads to the
promotion of the Love number to a Love tensor $k_{jk}^{\ \ pq}$, a four-index
object that relates the body's current quadrupole moment $S_{jk}$ to the
gravitomagnetic tidal moment ${\cal B}_{pq}$. The tensorial nature of this
quantity has to do with the fact that each $e^{im\phi}$ piece of the tidal
force gives rise to an $m$-specific velocity perturbation, and therefore to a
Love number that depends on $m$. The collection of these $m$-specific Love
numbers makes up the Love tensor $k_{jk}^{\ \ pq}$.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:37:36 GMT""},{""version"":""v2"",""created"":""Tue, 18 Aug 2020 14:43:17 GMT""}]","2020-09-30"
"2007.01679","Eiichiro Komatsu","Yi-Kuan Chiang, Ryu Makiya, Eiichiro Komatsu, Brice M\'enard","The thermal and gravitational energy densities in the large-scale
  structure of the Universe","11 pages + references, 4 figures, 2 tables. (v2) Expanded discussion
  on the modelling uncertainty. (v3) Fixed a minor typo in Eq.(22). Accepted
  for publication in the Astrophysical Journal. Julia codes to reproduce the
  figures and tables are available in
  https://github.com/komatsu5147/OmegaGrav.jl",,"10.3847/1538-4357/abe387",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As cosmic structures form, matter density fluctuations collapse
gravitationally and baryonic matter is shock-heated and thermalized. We
therefore expect a connection between the mean gravitational potential energy
density of collapsed halos, $\Omega_{W}^{\rm halo}$, and the mean thermal
energy density of baryons, $\Omega_{\rm th}$. These quantities can be obtained
using two fundamentally different estimates: we compute $\Omega_{W}^{\rm halo}$
using the theoretical framework of the halo model which is driven by dark
matter statistics, and measure $\Omega_{\rm th}$ using the Sunyaev-Zeldovich
(SZ) effect which probes the mean thermal pressure of baryons. First, we derive
that, at the present time, about 90% of $\Omega_{W}^{\rm halo}$ originates from
massive halos with $M>10^{13}\,M_\odot$. Then, using our measurements of the SZ
background, we find that $\Omega_{\rm th}$ accounts for about 80% of the
kinetic energy of the baryons available for pressure in halos at $z\lesssim
0.5$. This constrains the amount of non-thermal pressure, e.g., due to bulk and
turbulent gas motion sourced by mass accretion, to be about $\Omega_{\rm
non-th}\simeq 0.4\times 10^{-8}$ at $z=0$.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:38:22 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 08:10:12 GMT""},{""version"":""v3"",""created"":""Fri, 5 Mar 2021 08:16:25 GMT""}]","2021-03-31"
"2007.01680","Svetlana Cherlin Cherlin","Svetlana Cherlin and James M. S. Wason","Developing a predictive signature for two trial endpoints using the
  cross-validated risk scores method",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The existing cross-validated risk scores (CVRS) design has been proposed for
developing and testing the efficacy of a treatment in a high-efficacy patient
group (the sensitive group) using high-dimensional data (such as genetic data).
The design is based on computing a risk score for each patient and dividing
them into clusters using a non-parametric clustering procedure. In some
settings it is desirable to consider the trade-off between two outcomes, such
as efficacy and toxicity, or cost and effectiveness. With this motivation, we
extend the CVRS design (CVRS2) to consider two outcomes. The design employs
bivariate risk scores that are divided into clusters. We assess the properties
of the CVRS2 using simulated data and illustrate its application on a
randomised psychiatry trial. We show that CVRS2 is able to reliably identify
the sensitive group (the group for which the new treatment provides benefit on
both outcomes) in the simulated data. We apply the CVRS2 design to a psychology
clinical trial that had offender status and substance use status as two
outcomes and collected a large number of baseline covariates. The CVRS2 design
yields a significant treatment effect for both outcomes, while the CVRS
approach identified a significant effect for the offender status only after
pre-filtering the covariates.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:39:17 GMT""}]","2020-07-06"
"2007.01681","Subhamoy Maitra","Chandra Sekhar Mukherjee, Subhamoy Maitra, Vineet Gaurav and Dibyendu
  Roy","On Actual Preparation of Dicke State on a Quantum Computer","13 pages, 22 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exact number of CNOT and single qubit gates needed to implement a Quantum
Algorithm in a given architecture is one of the central problems of Quantum
Computation. In this work we study the importance of concise realizations of
Partially defined Unitary Transformations for better circuit construction using
the case study of Dicke State Preparation. The Dicke States $(\left|D^n_k
\right>)$ are an important class of entangled states with uses in many branches
of Quantum Information. In this regard we provide the most efficient
Deterministic Dicke State Preparation Circuit in terms of CNOT and single qubit
gate counts in comparison to existing literature. We further observe that our
improvements also reduce architectural constraints of the circuits. We
implement the circuit for preparing $\left| D^4_2 \right>$ on the ""ibmqx2""
machine of the IBM QX service and observe that the error induced due to noise
in the system is lesser in comparison to the existing circuit descriptions. We
conclude by describing the CNOT map of the generic $\left| D^n_k \right>$
preparation circuit and analyze different ways of distributing the CNOT gates
in the circuit and its affect on the induced error.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:40:32 GMT""},{""version"":""v2"",""created"":""Sun, 19 Jul 2020 16:14:56 GMT""}]","2020-07-21"
"2007.01682","Miao Tian","Miao Tian, Dongyan Guo, Ying Cui, Xiang Pan, Shengyong Chen","Improving auto-encoder novelty detection using channel attention and
  entropy minimization",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Novelty detection is a important research area which mainly solves the
classification problem of inliers which usually consists of normal samples and
outliers composed of abnormal samples. Auto-encoder is often used for novelty
detection. However, the generalization ability of the auto-encoder may cause
the undesirable reconstruction of abnormal elements and reduce the
identification ability of the model. To solve the problem, we focus on the
perspective of better reconstructing the normal samples as well as retaining
the unique information of normal samples to improve the performance of
auto-encoder for novelty detection. Firstly, we introduce attention mechanism
into the task. Under the action of attention mechanism, auto-encoder can pay
more attention to the representation of inlier samples through adversarial
training. Secondly, we apply the information entropy into the latent layer to
make it sparse and constrain the expression of diversity. Experimental results
on three public datasets show that the proposed method achieves comparable
performance compared with previous popular approaches.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:41:34 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 05:36:11 GMT""}]","2021-05-11"
"2007.01683","Henrique Araujo","Henrique Ara\'ujo","Revised performance parameters of the ZEPLIN-III dark matter experiment",,,,,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  This note presents revised detector parameters applicable to data from the
First Science Run of the ZEPLIN-III dark matter experiment; these datasets were
acquired in 2008 and reanalised in 2011. This run demonstrated electron recoil
discrimination in liquid xenon at the level of 1 part in 10,000 below 40 keV
nuclear recoil energy, at an electric field of 3.8 kV/cm; this remains the best
discrimination reported for this medium to date. Building on relevant
measurements published in recent years, the calibration of the scintillation
and ionisation responses for both electron and nuclear recoils, which had been
mapped linearly to Co-57 gamma-ray interactions, is converted here into optical
parameters which are better suited to relate the data to the emerging liquid
xenon response models. Additional information is given on the fitting of the
electron and nuclear recoil populations at low energy. The aim of this note is
to support the further development of these models with valuable data acquired
at high field.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:49:12 GMT""}]","2020-07-06"
"2007.01684","Dipendu Maity","Debashis Bhowmik, Dipendu Maity, Bhanu Pratap Yadav, Ashish Kumar
  Upadhyay","New Classes of Quantum Codes Associated with Surface Maps",,,,,"math.CO cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If the cyclic sequences of {face types} {at} all vertices in a map are the
same, then the map is said to be a semi-equivelar map. In particular, a
semi-equivelar map is equivelar if the faces are the same type. Homological
quantum codes represent a subclass of topological quantum codes. In this
article, we introduce {thirteen} new classes of quantum codes. These codes are
associated with the following: (i) equivelar maps of type $ [k^k]$, (ii)
equivelar maps on the double torus along with the covering of the maps, and
(iii) semi-equivelar maps on the surface of \Echar{-1}, along with {their}
covering maps. The encoding rate of the class of codes associated with the maps
in (i) is such that $ \frac{k}{n}\rightarrow 1 $ as $ n\rightarrow\infty $, and
for the remaining classes of codes, the encoding rate is $
\frac{k}{n}\rightarrow \alpha $ as $ n\rightarrow \infty $ with $ \alpha< 1 $.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:50:31 GMT""}]","2020-07-06"
"2007.01685","Ke Liu","Jonas Greitemann, Ke Liu, Lode Pollet","The view of TK-SVM on the phase hierarchy in the classical kagome
  Heisenberg antiferromagnet","13 pages, 10 figures, 3 tables; invited for JPCM Special Issue on
  machine learning; v2: added discussions on dipolar orders",,,,"cond-mat.str-el cond-mat.stat-mech physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We illustrate how the tensorial kernel support vector machine (TK-SVM) can
probe the hidden multipolar orders and emergent local constraint in the
classical kagome Heisenberg antiferromagnet. We show that TK-SVM learns the
finite-temperature phase diagram in an unsupervised way. Moreover, in virtue of
its strong interpretability, it identifies the tensorial quadrupolar and
octupolar orders, which define a biaxial $D_{3h}$ spin nematic, and the local
constraint that underlies the selection of coplanar states. We then discuss the
disorder hierarchy of the phases, which can be inferred from both the
analytical order parameters and a SVM bias parameter. For completeness we
mention that the machine also picks up the leading $\sqrt{3} \times \sqrt{3}$
correlations in the dipolar channel at very low temperature, which are however
weak compared to the quadrupolar and octupolar orders. Our work shows how
TK-SVM can facilitate and speed up the analysis of classical frustrated
magnets.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:53:23 GMT""},{""version"":""v2"",""created"":""Thu, 17 Sep 2020 15:10:44 GMT""}]","2020-09-18"
"2007.01686","Boris Zolotov","Elena Arseneva, John Iacono, Grigorios Koumoutsos, Stefan Langerman,
  Boris Zolotov","Sublinear Explicit Incremental Planar Voronoi Diagrams","14 pages, 10 figures. Presented ant JCDCGGG 2019",,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A data structure is presented that explicitly maintains the graph of a
Voronoi diagram of $N$ point sites in the plane or the dual graph of a convex
hull of points in three dimensions while allowing insertions of new
sites/points. Our structure supports insertions in $\tilde O (N^{3/4})$
expected amortized time, where $\tilde O$ suppresses polylogarithmic terms.
This is the first result to achieve sublinear time insertions; previously it
was shown by Allen et al. that $\Theta(\sqrt{N})$ amortized combinatorial
changes per insertion could occur in the Voronoi diagram but a sublinear-time
algorithm was only presented for the special case of points in convex position.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:54:55 GMT""}]","2020-07-06"
"2007.01687","Giacomo Gradenigo","Giacomo Gradenigo, Maria Chiara Angelini, Luca Leuzzi, Federico
  Ricci-Tersenghi","Solving the fully-connected spherical $p$-spin model with the cavity
  method: equivalence with the replica results","26 pages","J. Stat. Mech. 113302 (2020)","10.1088/1742-5468/abc4e3",,"cond-mat.stat-mech cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spherical $p$-spin is a fundamental model for glassy physics, thanks to
its analytic solution achievable via the replica method. Unfortunately the
replica method has some drawbacks: it is very hard to apply to diluted models
and the assumptions beyond it are not immediately clear. Both drawbacks can be
overcome by the use of the cavity method, which, however, needs to be applied
with care to spherical models. Here we show how to write the cavity equations
for spherical $p$-spin models on complete graphs, both in the Replica Symmetric
(RS) ansatz (corresponding to Belief Propagation) and in the 1-step Replica
Symmetry Breaking (1RSB) ansatz (corresponding to Survey Propagation). The
cavity equations can be solved by a Gaussian (RS) and multivariate Gaussian
(1RSB) ansatz for the distribution of the cavity fields. We compute the free
energy in both ansatzes and check that the results are identical to the replica
computation, predicting a phase transition to a 1RSB phase at low temperatures.
The advantages of solving the model with the cavity method are many. The
physical meaning of any ansatz for the cavity marginals is very clear. The
cavity method works directly with the distribution of local quantities, which
allows to generalize the method to dilute graphs. What we are presenting here
is the first step towards the solution of the diluted version of the spherical
$p$-spin model, which is a fundamental model in the theory of random lasers and
interesting $per~se$ as an easier-to-simulate version of the classical
fully-connected $p$-spin model.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:56:32 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 14:41:13 GMT""}]","2021-02-08"
"2007.01688","Louis Beziaud","Tristan Allard (DRUID), Louis B\'eziaud (LATECE Laboratory - UQAM
  Montreal, DRUID), S\'ebastien Gambs (LATECE Laboratory - UQAM Montreal)","Online publication of court records: circumventing the
  privacy-transparency trade-off",,,,,"cs.CR cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The open data movement is leading to the massive publishing of court records
online, increasing transparency and accessibility of justice, and to the design
of legal technologies building on the wealth of legal data available. However,
the sensitive nature of legal decisions also raises important privacy issues.
Current practices solve the resulting privacy versus transparency trade-off by
combining access control with (manual or semi-manual) text redaction. In this
work, we claim that current practices are insufficient for coping with massive
access to legal data (restrictive access control policies is detrimental to
openness and to utility while text redaction is unable to provide sound privacy
protection) and advocate for a in-tegrative approach that could benefit from
the latest developments of the privacy-preserving data publishing domain. We
present a thorough analysis of the problem and of the current approaches, and
propose a straw man multimodal architecture paving the way to a full-fledged
privacy-preserving legal data publishing system.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:58:01 GMT""}]","2020-07-06"
"2007.01689","Geoff Beck","Geoff Beck","Radio-Frequency Searches for Dark Matter in Dwarf Galaxies","14 pages, 3 figures",,,"HALO-SPECIAL_ISSUE/2020/04","astro-ph.HE astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dwarf spheroidal galaxies have long been discussed as optimal targets for
indirect dark matter searches. However, the majority of such studies have been
conducted with gamma-ray instruments. In this review, we discuss the very
recent progress that has been made in radio-based indirect dark matter
searches. We look at existing work on this topic and discuss the future
prospects that motivate continued work in this newly developing field that
promises to become, in the light of the up-coming Square Kilometre Array, a
prominent component of the hunt for dark matter.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 13:59:06 GMT""}]","2020-07-06"
"2007.01691","Shangding Gu","Chunhui Zhou, Shangding Gu, Yuanqiao Wen, Zhe Du, Changshi Xiao, Liang
  Huang and Man Zhu","The Review Unmanned Surface Vehicle Path Planning: Based on
  Multi-modality Constraint",,"Ocean Engineering,2020",,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The essence of the path planning problems is multi-modality constraint.
However, most of the current literature has not mentioned this issue. This
paper introduces the research progress of path planning based on the
multi-modality constraint. The path planning of multi-modality constraint
research can be classified into three stages in terms of its basic ingredients
(such as shape, kinematics and dynamics et al.): Route Planning, Trajectory
Planning and Motion Planning. It then reviews the research methods and
classical algorithms, especially those applied to the Unmanned Surface Vehicle
(USV) in every stage. Finally, the paper points out some existing problems in
every stage and suggestions for future research.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:01:56 GMT""}]","2020-07-06"
"2007.01692","Arelo O.A Tanoh","Arelo O.A Tanoh, Nicolas Gauriot, G\'eraud Delport, James Xiao, Raj
  Pandya, Joo Young Sung, Jesse Allardice, Zhaojun Li, Cyan A. Williams, Alan
  Baldwin, Samuel D. Stranks, Akshay Rao","Directed Energy Transfer from Monolayer $WS_{2}$ to NIR Emitting PbS-CdS
  Quantum Dots",,,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heterostructures of two-dimensional (2D) transition metal dichalcogenides
(TMDs) and inorganic semiconducting zero-dimensional (0D) quantum dots (QDs)
offer unique charge and energy transfer pathways which could form the basis of
novel optoelectronic devices. To date, most has focused on charge transfer and
energy transfer from QDs to TMDs, i.e. from 0D to 2D. Here, we present a study
of the energy transfer process from a 2D to 0D material, specifically exploring
energy transfer from monolayer tungsten disulphide ($WS_{2}$) to near infrared
(NIR) emitting lead sulphide-cadmium sulphide (PbS-CdS) QDs. The high
absorption cross section of $WS_{2}$ in the visible region combined with the
potentially high photoluminescence (PL) efficiency of PbS QD systems, make this
an interesting donor-acceptor system that can effectively use the WS2 as an
antenna and the QD as a tuneable emitter, in this case downshifting the
emission energy over hundreds of meV. We study the energy transfer process
using photoluminescence excitation (PLE) and PL microscopy, and show that 58%
of the QD PL arises due to energy transfer from the $WS_{2}$. Time resolved
photoluminescence (TRPL) microscopy studies show that the energy transfer
process is faster than the intrinsic PL quenching by trap states in the
$WS_{2}$, thus allowing for efficient energy transfer. Our results establish
that QDs could be used as tuneable and high PL efficiency emitters to modify
the emission properties of TMDs. Such TMD/QD heterostructures could have
applications in light emitting technologies, artificial light harvesting
systems or be used to read out the state of TMD devices optically in various
logic and computing applications
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:02:12 GMT""}]","2020-07-06"
"2007.01694","Carolin Willibald","Thiemo Theile, Denes Szabo, Carolin Willibald, Martin Schneebeli","Discrete element model for high strain rate deformations of snow","21 pages, 10 figures",,,,"physics.geo-ph cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  In engineering applications snow often undergoes large and fast deformations.
During these deformations the snow transforms from a sintered porous material
into a granular material. In order to capture the fundamental mechanical
behavior of this process a discrete element (DE) model is the physically most
appropriate. It explicitly includes all the relevant components: the snow
microstructure, consisting of bonded grains, the breaking of the bonds and the
following rearrangement and interaction of the loose grains. We developed and
calibrated a DE snow model based on the open source DE code liggghts. In the
model snow grains are represented by randomly distributed elastic spheres
connected by elastic-brittle bonds. This bonded structure corresponds to
sintered snow. After applying external forces, the stresses in the bonds might
exceed their strength, the bonds break, and we obtain loose particles,
corresponding to granular snow. Model parameters can be divided into
temperature dependent material parameters and snow type dependent
microstructure parameters. The model was calibrated by angle of repose
experiments and several high strain rate mechanical tests, performed in a cold
laboratory. We demonstrate the performance of the DE snow model by the
simulation of a combined compression and shear deformation of different snow
types with large strains. The model successfully reproduces the experiments.
Most characteristics of the mechanical snow behavior are captured by the model,
like the fracture behavior, the differences between low and high density snow,
the granular shear flow or the densification of low density snow. The model is
promising to simulate arbitrary high strain rate processes for a wide range of
snow types, and thus seems useful to be applied to different snow engineering
problems.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:03:17 GMT""}]","2020-07-06"
"2007.01697","Markus Holler","M. Holler, J.-P. Lenain, M. de Naurois, R. Rauth, D. A. Sanchez","A Run-Wise Simulation and Analysis Framework for Imaging Atmospheric
  Cherenkov Telescope Arrays","13 pages, 7 figures, 2 tables. Accepted for publication in
  Astroparticle Physics",,"10.1016/j.astropartphys.2020.102491",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new simulation and analysis paradigm for Imaging Atmospheric
Cherenkov Telescope (IACT) arrays, simulating the actual observation conditions
as well as individual telescope configuration for each observation unit.
Compared to existing frameworks, where simulations are usually generated using
pre-defined settings, this run-wise simulation approach implies more realistic
simulations and hence reduced systematic uncertainties. The computational
effort of this dedicated simulation concept is notably independent of the
amount of different observation configurations but just scales linearly with
observation time. This corresponds to a large advantage for increasingly
complex current and future IACT arrays where the size of the phase space makes
it computationally unfeasible to generate simulations that reach the
requirements regarding systematics using the classical simulation scheme.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:06:44 GMT""}]","2020-07-29"
"2007.01699","No\'e Lugaz","N. Lugaz, T. M. Salman, R. M. Winslow, N. Al-Haddad, C. J. Farrugia,
  B. Zhuang, A. B. Galvin","Inconsistencies Between Local and Global Measures of CME Radial
  Expansion as Revealed by Spacecraft Conjunctions","14 pages, accepted to ApJ",,"10.3847/1538-4357/aba26b",,"physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The radial expansion of coronal mass ejections (CMEs) is known to occur from
remote observations; from the variation of their properties with radial
distance; and from local in situ plasma measurements showing a decreasing speed
profile throughout the magnetic ejecta (ME). However, little is known on how
local measurements compare to global measurements of expansion. Here, we
present results from the analysis of 42 CMEs measured in the inner heliosphere
by two spacecraft in radial conjunction. The magnetic field decrease with
distance provides a measure of their global expansion. Near 1 au, the decrease
in their bulk speed provides a measure of their local expansion. We find that
these two measures have little relation with each other. We also investigate
the relation between characteristics of CME expansion and CME properties. We
find that the expansion depends on the initial magnetic field strength inside
the ME, but not significantly on the magnetic field inside the ME measured near
1 au. This is an indirect evidence that CME expansion in the innermost
heliosphere is driven by the high magnetic pressure inside the ME, while by the
time the MEs reach 1 au, they are expanding due to the decrease in the solar
wind dynamic pressure with distance. We also determine the evolution of the ME
tangential and normal magnetic field components with distance, revealing
significant deviations as compared to the expectations from force-free field
configurations as well as some evidence that the front half of MEs expand at a
faster rate than the back half.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:08:47 GMT""}]","2020-08-26"
"2007.01700","Jozef Strecka","Cesur Ekiz, Jozef Strecka","Unsaturated bipartite entanglement of a spin-1/2 Ising-Heisenberg model
  on a triangulated Husimi lattice","7 pages, 3 figures, presented at CSMAG'19 conference in Kosice,
  Slovakia","Acta Physica Polonica A 137 (2020) 592","10.12693/APhysPolA.137.592",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A bipartite entanglement between two nearest-neighbor Heisenberg spins of a
spin-1/2 Ising-Heisenberg model on a triangulated Husimi lattice is quantified
using a concurrence. It is shown that the concurrence equals zero in a
classical ferromagnetic and a quantum disordered phase, while it becomes
sizable though unsaturated in a quantum ferromagnetic phase. A
thermally-assisted reentrance of the concurrence is found above a classical
ferromagnetic phase, whereas a quantum ferromagnetic phase displays a striking
cusp of the concurrence at a critical temperature.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:09:38 GMT""}]","2020-07-06"
"2007.01706","Tomas Manzaneque","Tom\'as Manzaneque, Peter G. Steeneken, Farbod Alijani and Murali K.
  Ghatkesar","Method to Determine the Closed-Loop Precision of Resonant Sensors from
  Open-Loop Measurements","Accepted version of publication in IEEE Sensors Journal",,"10.1109/JSEN.2020.3008557",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Resonant sensors determine a sensed parameter by measuring the resonance
frequency of a resonator. For fast continuous sensing, it is desirable to
operate resonant sensors in a closed-loop configuration, where a feedback loop
ensures that the resonator is always actuated near its resonance frequency, so
that the precision is maximized even in the presence of drifts or fluctuations
of the resonance frequency. However, in a closed-loop configuration, the
precision is not only determined by the resonator itself, but also by the
feedback loop, even if the feedback circuit is noiseless. Therefore, to
characterize the intrinsic precision of resonant sensors, the open-loop
configuration is often employed. To link these measurements to the actual
closed-loop performance of the resonator, it is desirable to have a relation
that determines the closed-loop precision of the resonator from open-loop
characterisation data. In this work, we present a methodology to estimate the
closed-loop resonant sensor precision by relying only on an open-loop
characterization of the resonator. The procedure is beneficial for fast
performance estimation and benchmarking of resonant sensors, because it does
not require actual closed-loop sensor operation, thus being independent on the
particular implementation of the feedback loop. We validate the methodology
experimentally by determining the closed-loop precision of a mechanical
resonator from an open-loop measurement and comparing this to an actual
closed-loop measurement.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:18:49 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 14:42:35 GMT""},{""version"":""v3"",""created"":""Wed, 5 Aug 2020 09:58:24 GMT""}]","2020-08-07"
"2007.01707","Zdzislaw Musielak","Z.E. Musielak and T.B. Watson","Gauge Functions and Galilean Invariance of Lagrangians","7 pages","Physics Letters A 384, 126642 (2020)","10.1016/j.physleta.2020.126642",,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A novel method to make Lagrangians Galilean invariant is developed. The
method, based on null Lagrangians and their gauge functions, is used to
demonstrate the Galilean invariance of the Lagrangian for Newton's law of
inertia. It is suggested that this new solution of an old physics problem may
have implications and potential applications to all gauge-based theories of
physics.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:20:58 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jul 2020 21:37:29 GMT""}]","2020-07-22"
"2007.01708","Yichao Liu","Yichao Liu and Riccardo Ferrari and Ping Wu and Xiaoli Jiang and
  Sunwei Li and Jan-Willem van Wingerden","Fault Diagnosis of the 10MW Floating Offshore Wind Turbine Benchmark: a
  Mixed Model and Signal-based Approach",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Floating Offshore Wind Turbines (FOWTs) operate in the harsh marine
environment with limited accessibility and maintainability. Not only failures
are more likely to occur than in land-based turbines, but also corrective
maintenance is more expensive. In the present study, a mixed model and
signal-based Fault Diagnosis (FD) architecture is developed to detect and
isolate critical faults in FOWTs. More specifically, a model-based scheme is
developed to detect and isolate the faults associated with the turbine system.
It is based on a fault detection and approximation estimator and fault
isolation estimators, with time-varying adaptive thresholds to guarantee
against false-alarms. In addition, a signal-based scheme is established, within
the proposed architecture, for detecting and isolating two representative
mooring lines faults. For the purpose of verification, a 10MW FOWT benchmark is
developed and its operating conditions, which contains predefined faults, are
simulated by extending the high-fidelity simulator. Based on it, the
effectiveness of the proposed architecture is illustrated. In addition, the
advantages and limitations are discussed by comparing its fault detection to
the results delivered by other approaches. Results show that the proposed
architecture has the best performance in detecting and isolating the critical
faults in FOWTs under diverse operating conditions.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:23:01 GMT""}]","2020-07-06"
"2007.01711","Yue Wang","Yue Wang, Yuke Li, James H. Elder, Huchuan Lu, Runmin Wu, Lu Zhang","Synergistic saliency and depth prediction for RGB-D saliency detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Depth information available from an RGB-D camera can be useful in segmenting
salient objects when figure/ground cues from RGB channels are weak. This has
motivated the development of several RGB-D saliency datasets and algorithms
that use all four channels of the RGB-D data for both training and inference.
Unfortunately, existing RGB-D saliency datasets are small, which may lead to
overfitting and limited generalization for diverse scenarios. Here we propose a
semi-supervised system for RGB-D saliency detection that can be trained on
smaller RGB-D saliency datasets without saliency ground truth, while also make
effective joint use of a large RGB saliency dataset with saliency ground truth
together. To generalize our method on RGB-D saliency datasets, a novel
prediction-guided cross-refinement module which jointly estimates both saliency
and depth by mutual refinement between two respective tasks, and an adversarial
learning approach are employed. Critically, our system does not require
saliency ground-truth for the RGB-D datasets, which saves the massive human
labor for hand labeling, and does not require the depth data for inference,
allowing the method to be used for the much broader range of applications where
only RGB data are available. Evaluation on seven RGB-D datasets demonstrates
that even without saliency ground truth for RGB-D datasets and using only the
RGB data of RGB-D datasets at inference, our semi-supervised system performs
favorable against state-of-the-art fully-supervised RGB-D saliency detection
methods that use saliency ground truth for RGB-D datasets at training and depth
data at inference on two largest testing datasets. Our approach also achieves
comparable results on other popular RGB-D saliency benchmarks.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:24:41 GMT""},{""version"":""v2"",""created"":""Mon, 26 Oct 2020 06:23:18 GMT""}]","2020-10-27"
"2007.01713","Bruno Costa","Bruno Costa, Paulo F. Pires, Flavia C. Delicato","Towards the Adoption of OMG Standards in the Development of SOA-Based
  IoT Systems","To be published in the Journal of Systems and Software (JSS)",,,,"cs.SE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A common feature of the Internet of Things (IoT) is the high heterogeneity,
regarding network protocols, data formats, hardware and software platforms.
Aiming to deal with such a degree of heterogeneity, several frameworks have
applied the Model-Driven Development (MDD) to build IoT applications. On the
software architecture viewpoint, the literature has shown that the
Service-Oriented Architecture (SOA) is a promising style to address the
interoperability of entities composing these solutions. Some features of IoT
make it challenging to analyze the impact of design decisions on the SOA-based
IoT applications behavior. Thus, it is a key requirement to simulate the model
to verify whether the system performs as expected before its implementation.
Although the literature has identified that the SOA style is suitable for
addressing the interoperability, existing modelling languages do not consider
SOA elements as first-class citizens when designing IoT applications.
Furthermore, although existing MDD frameworks provide modeling languages
comprising well-defined syntax, they lack execution semantics, thus, are not
suitable for model execution and analysis. This work aims at addressing these
issues by introducing IoTDraw. The framework provides a fully OMG-compliant
executable modeling language for SOA-based IoT systems; thus, its
specifications can be implemented by any tool implementing OMG standards.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:25:22 GMT""}]","2020-07-06"
"2007.01714","Emil Vi\~nas Bostr\""om","Emil Vi\~nas Bostr\""om and Martin Claassen and James W. McIver and
  Gregor Jotzu and Angel Rubio and Michael A. Sentef","Light-induced topological magnons in two-dimensional van der Waals
  magnets","21 pages, 4 figures","SciPost Phys. 9, 061 (2020)","10.21468/SciPostPhys.9.4.061",,"cond-mat.str-el cond-mat.mtrl-sci cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Driving a two-dimensional Mott insulator with circularly polarized light
breaks time-reversal and inversion symmetry, which induces an optically-tunable
synthetic scalar spin chirality interaction in the effective low-energy spin
Hamiltonian. Here, we show that this mechanism can stabilize topological magnon
excitations in honeycomb ferromagnets and in optical lattices. We find that the
irradiated quantum magnet is described by a Haldane model for magnons that
hosts topologically-protected edge modes. We study the evolution of the magnon
spectrum in the Floquet regime and via time propagation of the magnon
Hamiltonian for a slowly varying pulse envelope. Compared to similar but
conceptually distinct driving schemes based on the Aharanov-Casher effect, the
dimensionless light-matter coupling parameter $\lambda = eEa/\hbar\omega$ at
fixed electric field strength is enhanced by a factor $\sim 10^5$. This
increase of the coupling parameter allows to induce a topological gap of the
order of $\Delta \approx 2$ meV with realistic laser pulses, bringing an
experimental realization of light-induced topological magnon edge states within
reach.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:28:02 GMT""},{""version"":""v2"",""created"":""Mon, 17 Aug 2020 10:20:15 GMT""},{""version"":""v3"",""created"":""Wed, 9 Sep 2020 08:20:58 GMT""},{""version"":""v4"",""created"":""Thu, 22 Oct 2020 13:26:02 GMT""}]","2020-11-04"
"2007.01715","Savvas Malikis","Savvas Malikis, Denis Kurlov, Vladimir Gritsev","Quasi-conserved quantities in the perturbed XXX spin chain","7 pages, 4 figures",,,,"cond-mat.stat-mech cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the isotropic spin-1/2 Heisenberg spin chain weakly perturbed by
a local translationally- and SU(2)-invariant perturbation. Starting from the
local integrals of motion of the unperturbed model, we modify them in order to
obtain quasi-conserved integrals of motion (charges) for the perturbed model.
Such quasi-conserved quantities are believed to be responsible for the
existence of the prethermalization phase at intermediate timescales. We find
that for a sufficiently local perturbation only the first few integrals of
motion can be promoted to the quasi-conserved charges, whereas higher-order
integrals of motion do not survive.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:28:19 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 11:13:07 GMT""}]","2020-12-10"
"2007.01718","Kaye Silva","Gaetano Siciliano and Kaye Silva","On the structure of the Nehari set associated to a Schr\""odinger-Poisson
  system with prescribed mass: old and new results",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we apply the fibering method of Pohozaev to a
Schr\""odinger-Poisson system, with prescribed $L^{2}$ norm of the unknown, in
the whole $\mathbb R^{3}$. The method makes clear the role played by the
exponents $p=3, p=8/3, p=10/3$.
  Beside to show as old results can be obtained in a unified way, we exhibit
also new ones.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:34:21 GMT""}]","2020-07-06"
"2007.01719","Halcyon Carvalho","Halcyon D. P. Carvalho, Mar\'ilia N. C. A. Lima, Wylliams B. Santos
  and Roberta A. de A.Fagunde","Ensemble Regression Models for Software Development Effort Estimation: A
  Comparative Study",,"International Journal of Software Engineering & Applications
  (IJSEA), Vol.11, No.3, May 2020","10.5121/ijsea.2020.11305",,"cs.SE cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As demand for computer software continually increases, software scope and
complexity become higher than ever. The software industry is in real need of
accurate estimates of the project under development. Software development
effort estimation is one of the main processes in software project management.
However, overestimation and underestimation may cause the software industry
loses. This study determines which technique has better effort prediction
accuracy and propose combined techniques that could provide better estimates.
Eight different ensemble models to estimate effort with Ensemble Models were
compared with each other base on the predictive accuracy on the Mean Absolute
Residual (MAR) criterion and statistical tests. The results have indicated that
the proposed ensemble models, besides delivering high efficiency in contrast to
its counterparts, and produces the best responses for software project effort
estimation. Therefore, the proposed ensemble models in this study will help the
project managers working with development quality software.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:40:41 GMT""}]","2020-07-06"
"2007.01720","Ronald Seoh","Ronald Seoh","Qualitative Analysis of Monte Carlo Dropout",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this report, we present qualitative analysis of Monte Carlo (MC) dropout
method for measuring model uncertainty in neural network (NN) models. We first
consider the sources of uncertainty in NNs, and briefly review Bayesian Neural
Networks (BNN), the group of Bayesian approaches to tackle uncertainties in
NNs. After presenting mathematical formulation of MC dropout, we proceed to
suggesting potential benefits and associated costs for using MC dropout in
typical NN models, with the results from our experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:40:56 GMT""}]","2020-07-06"
"2007.01721","Soteris Demetriou","Hsiao-Ying Huang, Soteris Demetriou, Rini Banerjee, G\""uliz Seray
  Tuncay, Carl A. Gunter, Masooda Bashir","Smartphone Security Behavioral Scale: A New Psychometric Measurement for
  Smartphone Security",,,,,"cs.CR cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite widespread use of smartphones, there is no measurement standard
targeted at smartphone security behaviors. In this paper we translate a
well-known cybersecurity behavioral scale into the smartphone domain and show
that we can improve on this translation by following an established
psychometrics approach surveying 1011 participants. We design a new 14-item
Smartphone Security Behavioral Scale (SSBS) exhibiting high reliability and
good fit to a two-component behavioural model based on technical versus social
protection strategies. We then demonstrate how SSBS can be applied to measure
the influence of mental health issues on smartphone security behavior
intentions. We found significant correlations that predict SSBS profiles from
three types of MHIs. Conversely, we are able to predict presence of MHIs using
SSBS profiles.We obtain prediction AUCs of 72.1% for Internet addiction,75.8%
for depression and 66.2% for insomnia.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:43:50 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 17:54:15 GMT""}]","2020-07-07"
"2007.01722","Tao Lin","Hu Fu, Tao Lin","Learning Utilities and Equilibria in Non-Truthful Auctions","A previous version of this paper has been accepted to NeurIPS 2020.
  This version fixes errors and updates references",,,,"cs.GT cs.LG econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In non-truthful auctions, agents' utility for a strategy depends on the
strategies of the opponents and also the prior distribution over their private
types; the set of Bayes Nash equilibria generally has an intricate dependence
on the prior. Using the First Price Auction as our main demonstrating example,
we show that $\tilde O(n / \epsilon^2)$ samples from the prior with $n$ agents
suffice for an algorithm to learn the interim utilities for all monotone
bidding strategies. As a consequence, this number of samples suffice for
learning all approximate equilibria. We give almost matching (up to polylog
factors) lower bound on the sample complexity for learning utilities. We also
consider a setting where agents must pay a search cost to discover their own
types. Drawing on a connection between this setting and the first price
auction, discovered recently by Kleinberg et al. (2016), we show that $\tilde
O(n / \epsilon^2)$ samples suffice for utilities and equilibria to be estimated
in a near welfare-optimal descending auction in this setting. En route, we
improve the sample complexity bound, recently obtained by Guo et al. (2021),
for the Pandora's Box problem, which is a classical model for sequential
consumer search.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:44:33 GMT""},{""version"":""v2"",""created"":""Wed, 28 Oct 2020 17:06:30 GMT""},{""version"":""v3"",""created"":""Mon, 31 Oct 2022 18:04:25 GMT""}]","2022-11-02"
"2007.01723","Min-Jae Kim","Min-Jae Kim, Armin Schulz, Tomohiro Takayama, Masahiko Isobe, Hidenori
  Takagi, Stefan Kaiser","Phononic soft mode and strong electronic background behavior across the
  structural phase transition in the excitonic insulator Ta$_2$NiSe$_5$ (with
  Erratum)","Merged version with Erratum (1 page) in the original manuscript (21
  pages, 8 figures). After publication of [Phys. Rev. Research 2, 042039
  (2020), arXiv:2007.01723v2] [1] we got notified on an instrumental artifact
  in the low frequency part of the Raman spectrum of Ta$_2$NiSe$_5$. This
  erroneously led to a description of a soft phonon mode and a strong
  electronic background. Properly taking into account a low frequency
  electronic signal correctly explains the observed soft mode as Fano coupled
  phonon where a critical softening of an excitonic collective mode takes place
  as described by P.A. Volkov et al. in arXiv:2007.07344 [2] and M. Ye et al.
  in arXiv:2102.07912 [3]","Phys. Rev. Research 2, 042039 (2020)","10.1103/PhysRevResearch.2.042039",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ta$_2$NiSe$_5$ became one of the most investigated candidate materials for
hosting an excitonic insulator ground state. Many studies describe the
corresponding phase transition as a condensation of excitons breaking a
continuous symmetry. This view got challenged recently pointing out the
importance of the loss of two mirror symmetries at a structural phase
transition that occurs together with the semiconductor-excitonic insulator
transition. For such a scenario an unstable optical zone-center phonon at low
energy is proposed to drive the transition. Here we report on the experimental
observation of such a soft mode behavior using Raman spectroscopy. In addition
we find a novel spectral feature, likely of electronic or joint electronic and
phononic origin, that is clearly distinct from the lattice dynamics and that
becomes dominant at Tc. This suggests a picture of joint structural and
electronic order driving the phase transition.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:45:18 GMT""},{""version"":""v2"",""created"":""Thu, 15 Oct 2020 13:06:47 GMT""},{""version"":""v3"",""created"":""Wed, 3 Mar 2021 10:46:58 GMT""}]","2021-03-04"
"2007.01724","Paritosh Mittal","Paritosh Mittal, Shankar M Venkatesan, Viswanath Veera, Aloknath De","Deep Fence Estimation using Stereo Guidance and Adversarial Learning","It was previously submitted to IEEE ICIP 2020. A previous version was
  also submitted to BMVC 2019",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  People capture memorable images of events and exhibits that are often
occluded by a wire mesh loosely termed as fence. Recent works in removing fence
have limited performance due to the difficulty in initial fence segmentation.
This work aims to accurately segment fence using a novel fence guidance mask
(FM) generated from stereo image pair. This binary guidance mask contains
deterministic cues about the structure of fence and is given as additional
input to the deep fence estimation model. We also introduce a directional
connectivity loss (DCL), which is used alongside adversarial loss to precisely
detect thin wires. Experimental results obtained on real world scenarios
demonstrate the superiority of proposed method over state-of-the-art
techniques.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:46:30 GMT""}]","2020-07-06"
"2007.01725","Jonas M\""uller","P. Basler, M. Muhlleitner, J. M\""uller","BSMPT v2 A Tool for the Electroweak Phase Transition and the Baryon
  Asymmetry of the Universe in Extended Higgs Sectors",,,"10.1016/j.cpc.2021.108124",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the C++ code BSMPT v2 which is an extension of the previous code
BSMPT for the calculation of the strength of the electroweak phase transition
in extended Higgs sectors. The new version BSMPT v2 includes the features of
BSMPT and extends the already implemented models (the 2-Higgs-Doublet model
(2HDM) in its CP-conserving and CP-violating versions and the Next-to-2HDM) by
the Complex Singlet Extension of the Standard Model (CxSM). The major upgrade
is the implementation of the computation of the baryon asymmetry of the
Universe (at present for the C2HDM) in two different approximation, called the
FH and the VIA approach. Furthermore, the possibility of varying the
renormalisation scale in the loop-corrected effective potential has been added.
These changes and further smaller modifications are described in this manual.
Additionally, a detailed explanation of the procedure for the implementation of
new models is given, which has also changed with respect to the previous
version.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:46:40 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 13:04:41 GMT""}]","2021-08-20"
"2007.01726","Jinniu Hu","Chencan Wang, Jinniu Hu, Ying Zhang and Hong Shen","Properties of nuclear matter in relativistic Brueckner-Hartree-Fock
  model with high-precision charge-dependent potentials","32 pages, 11 figures, 5 tables, accepted by J. Phys. G",,"10.1088/1361-6471/aba423",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Properties of nuclear matter are investigated in the framework of
relativistic Brueckner-Hartree-Fock model with the latest high-precision
charge-dependent Bonn (pvCD-Bonn) potentials, where the coupling between pion
and nucleon is adopted as pseudovector form. These realistic pvCD-Bonn
potentials are renormalized to effective nucleon-nucleon ($NN$) interactions,
$G$ matrices. They are obtained by solving the Blankenbecler-Sugar (BbS)
equation in nuclear medium. Then, the saturation properties of symmetric
nuclear matter are calculated with pvCD-Bonn A, B, C potentials. The energies
per nucleon are around $-10.72$ MeV to $-16.83$ MeV at saturation densities,
$0.139$ fm$^{-3}$ to $0.192$ fm$^{-3}$ with these three potentials,
respectively. It clearly demonstrates that the pseudovector coupling between
pion and nucleon can generate reasonable saturation properties comparing with
pseudoscalar coupling. Furthermore, these saturation properties have strong
correlations with the tensor components of $NN$ potentials, i.e., the $D$-state
probabilities of deuteron, $P_D$ to form a relativistic Coester band. In
addition, the charge symmetry breaking (CSB) and charge independence breaking
(CIB) effects are also discussed in nuclear matter from the partial wave
contributions with these high-precision charge-dependent potentials. In
general, the magnitudes of CSB from the differences between $nn$ and $pp$
potentials are about $0.05$ MeV, while those of CIB are around $0.35$ MeV from
the differences between $np$ and $pp$ potentials. Finally, the equations of
state of asymmetric nuclear matter are also calculated with different asymmetry
parameters. It is found that the effective neutron mass is larger than the
proton one in neutron-rich matter.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:48:28 GMT""}]","2020-10-28"
"2007.01727","Khaled H. A. Al-Ghaithi","Khaled H. A. Al-Ghaithi, Oliver G. Harlen, Nikil Kapur, Mark C. T.
  Wilson","Morphologies and dynamics of micro-droplet impact onto an idealised
  scratch",,"Journal of Fluid Mechanics, 2021, 925, A23","10.1017/jfm.2021.638",,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  As inkjet technology develops to produce smaller droplets, substrate features
such as accidental scratches or manufacturing defects can potentially affect
the outcome of printing, particularly for printed electronics where continuous
tracks are required. Here, the deposition of micro-droplets onto a scratch of
commensurate size is studied. The scratch is considered as a groove of
rectangular cross-section, with rectangular side ridges representing material
displaced from the substrate, and seven equilibrium morphologies are identified
as a result of inertial spreading, contact-line pinning, imbibition into the
scratch and capillary flow. A regime map is constructed in terms of scratch
depth and width, and theoretical estimates of the regime boundaries are
developed by adapting droplet spreading laws for flat surfaces to account for
liquid entering the scratches. Good agreement is seen with numerical results
obtained using a GPU-accelerated three-dimensional multiphase lattice Boltzmann
model validated against published experiments, and the influences of Reynolds
number, Weber number and advancing and receding contact angles are explored.
Negative and positive implications of the results for printing applications are
discussed and illustrated via multiple-droplet simulations of printing across
and along scratches.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:49:08 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 11:53:08 GMT""}]","2021-09-15"
"2007.01728","Luiz Antonio Ribeiro Junior","M. L. Pereira Junior, J. M. De Sousa, W. H. S. Brand\~ao, A. L.
  Aguiar, R. A. Biz\~ao, L. A. Ribeiro Junior, and D. S. Galv\~ao","On the Elastic Properties of Single-Walled Phagraphene Nanotubes","11 pages and 04 pages","Chemical Physics Letters, 2020, 756, 137830","10.1016/j.cplett.2020.137830",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phagraphene (PhaG) is a quasi-planar 2D structure composed of $5-6-7$ ring
sequence. We have investigated the structural and mechanical properties of
phagraphene nanotubes (PhaNTs) through fully atomistic reactive molecular
dynamics (MD) simulations. For comparison purposes, the results were also
contrasted to similar carbon nanotubes (CNTs). Results showed that PhaNTs and
CNTs present similar brittle fracture mechanisms. The Young's modulus values
obtained for PhaNTs were smaller than the corresponding ones for CNTs. Both,
PhaNTs and CNTs, present equivalent fracture strains ranging between 15\%-20\%.
For the ultimate strength values, CNTs present values about 30\% higher than
the corresponding ones for PhaNTs.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:50:04 GMT""},{""version"":""v2"",""created"":""Wed, 30 Sep 2020 14:46:29 GMT""}]","2020-10-01"
"2007.01729","Timofey Mukha","Timofey Mukha, Silje Kreken Almeland, Rickard E. Bensow","LES of a classical hydraulic jump: Influence of modelling parameters on
  the predictive accuracy",,,,,"physics.flu-dyn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Results from large-eddy simulations of a classical hydraulic jump at inlet
Froude number 2 are reported. The computations are performed using the
general-purpose finite-volume based code OpenFOAM, and the primary goal is to
evaluate the influence of modelling parameters on the predictive accuracy, as
well as establish associated best-practice guidelines. A benchmark simulation
on a dense computational mesh is conducted, and good agreement with existing
reference data is found. The remaining simulations cover different selections
of modelling parameters: geometric vs algebraic interface capturing, three mesh
resolution levels, four choices of the convective flux interpolation scheme.
Geometric interface capturing leads to better accuracy but deteriorated
numerical stability and increased simulation times. Interestingly, numerical
dissipation is shown to systematically improve the results, both in terms of
accuracy and stability. The densest of the three grids, which is twice as
coarse as the grid used in the benchmark simulation, was found to be sufficient
for faithfully reproducing all the considered quantities of interest. The
recommendation is therefore to use this grid, geometric interface capturing,
and a second-order upwind scheme for the convective fluxes.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:51:31 GMT""}]","2020-07-06"
"2007.01730","Frank Phillipson","Frank Phillipson and Irina Chiscop","Multimodal Container Planning: a QUBO Formulation and Implementation on
  a Quantum Annealer","15 pages",,,,"quant-ph math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum computing is developing fast. Real world applications are within
reach in the coming years. One of the most promising areas is combinatorial
optimisation, where the Quadratic Unconstrained Binary Optimisation (QUBO)
problem formulation is used to get good approximate solutions. Both the
universal quantum computer as the quantum annealer can handle this kind of
problems well. In this paper, we present an application on multimodal container
planning. We show how to map this problem to a QUBO problem formulation and how
the practical implementation can be done on the quantum annealer produced by
D-Wave Systems.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:51:41 GMT""}]","2020-07-06"
"2007.01731","Shan Ma","Shan Ma and Shibei Xue and Yu Guo and Chuan-Cun Shu","Numerical detection of Gaussian entanglement and its application to the
  identification of bound entangled Gaussian states","14 pages","Quantum Information Processing (2020) 19:225","10.1007/s11128-020-02726-1",,"quant-ph math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a numerical method for solving the separability problem of
Gaussian quantum states in continuous-variable quantum systems. We show that
the separability problem can be cast as an equivalent problem of determining
the feasibility of a set of linear matrix inequalities. Thus, it can be
efficiently solved using existent numerical solvers. We apply this method to
the identification of bound entangled Gaussian states. We show that the
proposed method can be used to identify bound entangled Gaussian states that
could be simple enough to be producible in quantum optics.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:53:58 GMT""}]","2020-07-06"
"2007.01732","Leonardo Campanelli","Leonardo Campanelli","Creation of Universes from the Third-Quantized Vacuum","12 pages, 7 figures, accepted for publication in Physical Review D","Phys. Rev. D 102, 043514 (2020)","10.1103/PhysRevD.102.043514",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate the average numbers of closed, flat, and open universes
spontaneously created from nothing in third quantization. The creation of
universes is exponentially suppressed for large values of the kinetic energy of
the inflaton, while for small kinetic energies it is exponentially favoured for
closed universes over flat and open ones: For a scale of inflation less than
about $2 \times 10^{16}$GeV, the ratio of the number of closed universes to
either the number of flat or open universes is \begin{equation}
\frac{n_{closed}}{n_{flat,open}} \gtrsim 10^{10^{10}} . \nonumber
\end{equation}
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:54:30 GMT""}]","2020-08-19"
"2007.01733","Gianluca Curzi","Gianluca Curzi and Luca Roversi","Probabilistic Soft Type Assignment","33 pages",,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We model randomized complexity classes in the style of Implicit Computational
Complexity. We introduce PSTA, a probabilistic version of STA, the
type-theoretical counterpart of Soft Linear Logic. PSTA is a type assignment
for an extension of Simpson's Linear Lambda Calculus and its surface reduction,
where Linear additives express random choice. Linear additives are weaker than
the usual ones; they allow for duplications harmlessly affecting the
computational cost of normalization. PSTA is sound and complete w.r.t.
probabilistic polynomial time functions and characterizes the probabilistic
complexity classes PP and BPP, the latter slightly less implicitly than PP.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:54:45 GMT""}]","2020-07-06"
"2007.01734","Christopher Lewis-Brown","Christopher Lewis-Brown, Sanjaye Ramgoolam","Quarter-BPS states, multi-symmetric functions and set partitions",,,"10.1007/JHEP03(2021)153",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a construction of general holomorphic quarter BPS operators in $
\mathcal{N}=4$ SYM at weak coupling with $U(N)$ gauge group at finite $N$. The
construction employs the M\""obius inversion formula for set partitions, applied
to multi-symmetric functions, alongside computations in the group algebras of
symmetric groups. We present a computational algorithm which produces an
orthogonal basis for the physical inner product on the space of holomorphic
operators. The basis is labelled by a $U(2)$ Young diagram, a $U(N)$ Young
diagram and an additional plethystic multiplicity label. We describe precision
counting results of quarter BPS states which are expected to be reproducible
from dual computations with giant gravitons in the bulk, including a symmetry
relating sphere and AdS giants within the quarter BPS sector. In the case $n
\leq N$ ($n$ being the dimension of the composite operator) the construction is
analytic, using multi-symmetric functions and $U(2)$ Clebsch-Gordan
coefficients. Counting and correlators of the BPS operators can be encoded in a
two-dimensional topological field theory based on permutation algebras and
equipped with appropriate defects.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:55:38 GMT""}]","2021-03-31"
"2007.01735","Frank Gounelas","Xi Chen and Frank Gounelas","Curves of maximal moduli on K3 surfaces","Minor changes, final version","Forum Math. Sigma 10 (2022), Paper No. e36, 21 pp","10.1017/fms.2022.24",,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that if $X$ is a complex projective K3 surface and $g>0$, then there
exist infinitely many families of curves of geometric genus $g$ on $X$ with
maximal, i.e., $g$-dimensional, variation in moduli. In particular every K3
surface contains a curve of geometric genus 1 which moves in a non-isotrivial
family. This implies a conjecture of Huybrechts on constant cycle curves and
gives an algebro-geometric proof of a theorem of Kobayashi that a K3 surface
has no global symmetric differential forms.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:56:02 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 10:49:29 GMT""},{""version"":""v3"",""created"":""Sat, 5 Nov 2022 12:37:13 GMT""}]","2022-11-08"
"2007.01736","Thi-Thao-Phuong Hoang","Thi-Thao-Phuong Hoang and Hyesuk Lee","A global-in-time domain decomposition method for the coupled nonlinear
  Stokes and Darcy flows","22 pages",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a decoupling iterative algorithm based on domain decomposition for
the time-dependent nonlinear Stokes-Darcy model, in which different time steps
can be used in the flow region and in the porous medium. The coupled system is
formulated as a space-time interface problem based on the interface condition
for mass conservation. The nonlinear interface problem is then solved by a
nested iteration approach which involves, at each Newton iteration, the
solution of a linearized interface problem and, at each Krylov iteration,
parallel solution of time-dependent linearized Stokes and Darcy problems.
Consequently, local discretizations in time (and in space) can be used to
efficiently handle multiphysics systems of coupled equations evolving at
different temporal scales. Numerical results with nonconforming time grids are
presented to illustrate the performance of the proposed method.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:56:14 GMT""}]","2020-07-06"
"2007.01737","Hee Sok Chung","Hee Sok Chung","${\overline{\rm MS}}$ renormalization of $S$-wave quarkonium
  wavefunctions at the origin","62 pages, 9 figures, 2 tables, typos corrected, version published in
  JHEP","JHEP12(2020)065","10.1007/JHEP12(2020)065","TUM-EFT 135/20","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute $S$-wave quarkonium wavefunctions at the origin in the
$\overline{\rm MS}$ scheme based on nonrelativistic effective field theories.
We include the effects of nonperturbative long-distance behaviors of the
potentials, while we determine the short-distance behaviors of the potentials
in perturbative QCD. We obtain $\overline{\rm MS}$-renormalized quarkonium
wavefunctions at the origin that have the correct scale dependences that are
expected from perturbative QCD, so that the scale dependences cancel in
physical quantities. Based on the calculation of the wavefunctions at the
origin, we make model-independent predictions of decay constants and
electromagnetic decay rates of $S$-wave charmonia and bottomonia, and compare
them with measurements. We find that the poor convergence of perturbative QCD
corrections are substantially improved when we include corrections to the
wavefunctions at the origin in the calculation of decay constants and decay
rates.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:57:14 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 12:57:31 GMT""},{""version"":""v3"",""created"":""Thu, 10 Dec 2020 20:50:33 GMT""}]","2020-12-14"
"2007.01738","Jingwei Xu","Jingwei Xu, Huazhe Xu, Bingbing Ni, Xiaokang Yang, Trevor Darrell","Video Prediction via Example Guidance","Project Page: https://sites.google.com/view/vpeg-supp/home","ICML 2020",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In video prediction tasks, one major challenge is to capture the multi-modal
nature of future contents and dynamics. In this work, we propose a simple yet
effective framework that can efficiently predict plausible future states. The
key insight is that the potential distribution of a sequence could be
approximated with analogous ones in a repertoire of training pool, namely,
expert examples. By further incorporating a novel optimization scheme into the
training procedure, plausible predictions can be sampled efficiently from
distribution constructed from the retrieved examples. Meanwhile, our method
could be seamlessly integrated with existing stochastic predictive models;
significant enhancement is observed with comprehensive experiments in both
quantitative and qualitative aspects. We also demonstrate the generalization
ability to predict the motion of unseen class, i.e., without access to
corresponding data during training phase.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:57:24 GMT""}]","2020-07-06"
"2007.01739","Colin Adams","Colin Adams and William H. Meeks III and \'Alvaro K. Ramos","Modifications Preserving Hyperbolicity of Link Complements","Added author addresses and reference ArXiv number",,,,"math.GT math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a link in a 3-manifold such that the complement is hyperbolic, we
provide two modifications to the link, called the chain move and the switch
move, that preserve hyperbolicity of the complement, with only a relatively
small number of manifold-link pair exceptions, which are also classified. These
modifications provide a substantial increase in the number of known hyperbolic
links in the 3-sphere and other 3-manifolds.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:58:16 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 17:55:39 GMT""}]","2020-07-10"
"2007.01740","Karol Kozlowski Kajetan","K.K. Kozlowski","On convergence of form factor expansions in the infinite volume quantum
  Sinh-Gordon model in 1+1 dimensions","81 pages 5 figures, V2, minor misprints corrected, V3 proof given
  more detail, missprints corrected",,,,"math-ph hep-th math.MP nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops a technique allowing one to prove the convergence of a
class of series of multiple integrals which corresponds to the form factor
expansion of two-point functions in the 1+1 dimensional massive integrable
Sinh-Gordon quantum field theory.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:58:51 GMT""},{""version"":""v2"",""created"":""Thu, 19 Nov 2020 08:39:22 GMT""},{""version"":""v3"",""created"":""Tue, 13 Dec 2022 19:27:27 GMT""}]","2022-12-15"
"2007.01741","Davide L. Ferrario","D.L. Ferrario","Fixed points and the inverse problem for central configurations",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Central configurations play an important role in the dynamics of the $n$-body
problem: they occur as relative equilibria and as asymptotic configurations in
colliding trajectories. We illustrate how they can be found as projective fixed
points of self-maps defined on the shape space, and some results on the inverse
problem in dimension $1$, i.e. finding (positive or real) masses which make a
given collinear configuration central. This survey article introduces readers
to the recent results of the author, also unpublished, showing an application
of the fixed point theory.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:00:45 GMT""}]","2020-07-06"
"2007.01742","Jean Van Schaftingen","Jean Van Schaftingen","Reverse superposition estimates in Sobolev spaces","7 pages, minor corrections","Pure Appl. Funct. Anal. 7 (2022), n. 2, 805-811",,,"math.AP math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study when and how the norm of a function $u$ in the homogeneous Sobolev
spaces $\dot{W}^{s, p} (\mathbb{R}^n, \mathbb{R}^m)$, with $p \ge 1$ and either
$s = 1$ or $s > 1/p$, is controlled by the norm of composite function $f \circ
u$ in the same space.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:03:06 GMT""},{""version"":""v2"",""created"":""Thu, 26 Nov 2020 12:35:30 GMT""}]","2022-08-09"
"2007.01743","Paolo Pani","Massimo Bianchi, Dario Consoli, Alfredo Grillo, Jos\`e Francisco
  Morales, Paolo Pani, Guilherme Raposo","Distinguishing fuzzballs from black holes through their multipolar
  structure","v3: 5 pages, 1 figure. Fixes grammatical typos. Matches version to
  appear in PRL",,"10.1103/PhysRevLett.125.221601",,"hep-th astro-ph.HE gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within General Relativity, the unique stationary solution of an isolated
black hole is the Kerr spacetime, which has a peculiar multipolar structure
depending only on its mass and spin. We develop a general method to extract the
multipole moments of arbitrary stationary spacetimes and apply it to a large
family of horizonless microstate geometries. The latter can break the axial and
equatorial symmetry of the Kerr metric and have a much richer multipolar
structure, which provides a portal to constrain fuzzball models
phenomenologically. We find numerical evidence that all multipole moments are
typically larger (in absolute value) than those of a Kerr black hole with the
same mass and spin. Current measurements of the quadrupole moment of black-hole
candidates could place only mild constraints on fuzzballs, while future
gravitational-wave detections of extreme mass-ratio inspirals with the space
mission LISA will improve these bounds by orders of magnitude.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:04:09 GMT""},{""version"":""v2"",""created"":""Wed, 5 Aug 2020 07:07:20 GMT""},{""version"":""v3"",""created"":""Wed, 28 Oct 2020 13:29:15 GMT""}]","2020-12-30"
"2007.01744","Michele Kotiuga","Michele Kotiuga, Karin M. Rabe","""Fraternal-twin"" ferroelectricity: competing polar states in
  hydrogen-doped samarium nickelate from first principles","9 pages, 10 figures",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reversible intercalation of hydrogen into samarium nickelate, SmNiO$_3$
(SNO), has been of recent interest. Upon entering SNO, the hydrogen
dissociates: the H$^+$ binds to an oxygen and the valence electron localizes on
a nearby NiO$_6$ octahedron, resulting in a local dipole moment. In this work,
we use first-principles calculations to explore the polar states of
hydrogen-doped SNO at a concentration of 1/4 hydrogen per Ni. The inherent tilt
pattern of SNO and the presence of the interstitial hydrogen present an
insurmountable energy barrier to switch these polar states to their
symmetry-related states under inversion. We find a sufficiently low barrier to
move the localized electron to a neighboring NiO$_6$ octahedron, a state
unrelated by symmetry but equal in energy under epitaxial strain, resulting in
a large change in polarization. We term this unconventional ferroelectric a
""fraternal-twin"" ferroelectric.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:05:02 GMT""}]","2020-07-06"
"2007.01745","Svitlana Mayboroda","Guy David and Svitlana Mayboroda","Good elliptic operators on Cantor sets",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that a purely unrectifiable set cannot support a harmonic
measure which is absolutely continuous with respect to the Hausdorff measure of
this set. We show that nonetheless there exist elliptic operators on (purely
unrectifiable) Cantor sets in ${\mathbb{R}}^2$ whose elliptic measure is
absolutely continuous, and in fact, essentially proportional to the Hausdorff
measure.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:06:14 GMT""}]","2020-07-06"
"2007.01746","Ra\'ul Bomb\'in","Ra\'ul Bomb\'in, Ferran Mazzanti and Jordi Boronat","Reply to the Comment on ""Berezinskii-Kosterlitz-Thouless Transition in
  Two-Dimensional Dipolar Stripes""",,"Phys. Rev. A 102, 047302 (2020)","10.1103/PhysRevA.102.047302",,"cond-mat.quant-gas cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is a Reply to the Comment from F. Cinti and M. Boninsegni on our recent
work on the Berezinskii-Kosterlitz-Thouless (BKT) phase transition in a
two-dimensional dipolar system [R.Bomb\'in, F. Mazzanti and J. Boronat,
Physical Review A 100, 063614 (2019)]. The main criticism about our work,
expressed in that Comment, is that we did not explicitly report the two spatial
contributions to the total superfluid fraction. Here, we analyze our results
for a point of the phase diagram corresponding to the stripe phase, close to
the gas to stripe transition line, and for a temperature below the BKT critical
temperature. The scaling with the system size of the contribution to the
superfluid fraction, coming from the direction in which spatial order appears,
shows that it remains finite in the thermodynamic limit, as we already stated
in our original work. This allow us to state that the stripe phase is
superfluid at low temperatures. Furthermore, we offer some comments that help
to understand where the differences between the results of Cinti and Boninsegni
and ours comes from.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:08:07 GMT""},{""version"":""v2"",""created"":""Tue, 20 Oct 2020 08:22:19 GMT""}]","2020-10-21"
"2007.01747","Michele Doro Prof.","Miguel Angel Sanchez Conde, Michele Doro","Overlay of the Special Issue 'The Role of Halo Substructure in Gamma-Ray
  Dark Matter Searches'","Special Issue in the Galaxies Journal","Galaxies (ISSN 2075-4434)",,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An important open question today is the understanding of the relevance that
dark matter (DM) halo substructure may have for DM searches. In the standard
cosmological framework, subhalos are predicted to be largely abundant inside
larger halos, i.e., galaxies like ours, and are thought to form first and later
merge to form larger structures. Dwarf satellite galaxies -- the most massive
exponents of halo substructure in our own galaxy -- are already known to be
excellent targets and, indeed, they are constantly scrutinized by current
gamma-ray experiments in their search for DM annihilation signals. Lighter
subhalos not massive enough to have a visible baryonic counterpart may be good
targets as well given their typical number densities and distances. In
addition, the clumpy distribution of subhalos residing in larger halos may
boost the DM signals considerably. In an era in which gamma-ray experiments
possess, for the first time, the exciting potential of reaching the most
relevant regions of the DM parameter space, a profound knowledge of the DM
targets and scenarios being tested at present is mandatory if we aim for
accurate predictions of DM-induced fluxes, for investing significant telescope
observing time to selected targets, and for deriving robust conclusions from
our DM search efforts. In this regard, a precise characterization of the
statistical and structural properties of subhalos becomes critical. With the
Special Issue ""The Role of Halo Substructure in Gamma-Ray Dark Matter Searches""
[https://www.mdpi.com/journal/galaxies/special_issues/Gamma-RayDMS], we aimed
to summarize where we stand today on our knowledge of the different aspects of
the DM halo substructure; to identify what are the remaining big questions, how
we could address these and, by doing so, to find new avenues for research.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:11:55 GMT""}]","2020-07-06"
"2007.01748","Richard Berkovits","Richard Berkovits","On super-Poissonian behavior of the Rosenzweig-Porter model in the
  non-ergodic extended regime","5 pages, 4 figures; Supplemental material: 2 pages, 2 figures","Phys. Rev. B 102, 165140 (2020)","10.1103/PhysRevB.102.165140",,"cond-mat.dis-nn cond-mat.mes-hall quant-ph","http://creativecommons.org/licenses/by/4.0/","  The Rosenzweig-Porter model has seen a resurgence in interest as it exhibits
a non-ergodic extended phase between the ergodic extended metallic phase and
the localized phase. Such a phase is relevant to many physical models from the
Sachdev-Ye-Kitaev model in high-energy physics and quantum gravity, to the
interacting many-body localization in condensed matter physics and quantum
computing. This phase is characterized by fractal behavior of the
wavefunctions, and a postulated correlated mini-band structure of the energy
spectrum. Here we will seek evidence for the latter in the spectrum. Since this
behavior is expected on intermediate energy scales spectral rigidity is a
natural way to tease it out. Nevertheless, due to the Thouless energy and
ambiguities in the unfolding procedure, the results are inconclusive. On the
other hand, by using the singular value decomposition method, clear evidence
for a super-Poissonian behavior in this regime emerges, consistent with a
picture of correlated mini-bands.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:11:56 GMT""}]","2020-10-28"
"2007.01749","Celine Maistret","Alex J. Best, L. Alexander Betts, Matthew Bisatt, Raymond van Bommel,
  Vladimir Dokchitser, Omri Faraggi, Sabrina Kunzweiler, C\'eline Maistret,
  Adam Morgan, Simone Muselli, Sarah Nowell","A user's guide to the local arithmetic of hyperelliptic curves","Minor changes. To appear in the Bulletin of the London Mathematical
  Society",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new approach has been recently developed to study the arithmetic of
hyperelliptic curves $y^2=f(x)$ over local fields of odd residue characteristic
via combinatorial data associated to the roots of $f$. Since its introduction,
numerous papers have used this machinery of ""cluster pictures"" to compute a
plethora of arithmetic invariants associated to these curves. The purpose of
this user's guide is to summarise and centralise all of these results in a
self-contained fashion, complemented by an abundance of examples.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:14:17 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 11:44:49 GMT""},{""version"":""v3"",""created"":""Tue, 1 Jun 2021 10:43:27 GMT""}]","2021-06-02"
"2007.01750","Kfir Blum","Francesca Bellini, Kfir Blum, Alexander Phillip Kalweit, Maximiliano
  Puccio","On coalescence as the origin of nuclei in hadronic collisions","24 pages, 10 figures","Phys. Rev. C 103, 014907 (2021)","10.1103/PhysRevC.103.014907",,"nucl-th hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The origin of weakly-bound nuclear clusters in hadronic collisions is a key
question to be addressed by heavy-ion collision (HIC) experiments. The measured
yields of clusters are approximately consistent with expectations from
phenomenological statistical hadronisation models (SHMs), but a theoretical
understanding of the dynamics of cluster formation prior to kinetic freeze out
is lacking. The competing model is nuclear coalescence, which attributes
cluster formation to the effect of final state interactions (FSI) during the
propagation of the nuclei from kinetic freeze out to the observer. This
phenomenon is closely related to the effect of FSI in imprinting femtoscopic
correlations between continuum pairs of particles at small relative momentum
difference. We give a concise theoretical derivation of the
coalescence--correlation relation, predicting nuclear cluster spectra from
femtoscopic measurements. We review the fact that coalescence derives from a
relativistic Bethe-Salpeter equation, and recall how effective quantum
mechanics controls the dynamics of cluster particles that are nonrelativistic
in the cluster centre of mass frame. We demonstrate that the
coalescence--correlation relation is roughly consistent with the observed
cluster spectra in systems ranging from PbPb to pPb and pp collisions. Paying
special attention to nuclear wave functions, we derive the coalescence
prediction for hypertriton and show that it, too, is roughly consistent with
the data. Our work motivates a combined experimental programme addressing
femtoscopy and cluster production under a unified framework. Upcoming pp, pPb
and peripheral PbPb data analysed within such a programme could stringently
test coalescence as the origin of clusters.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:14:23 GMT""}]","2021-02-03"
"2007.01751","Bilge Yigit Ozkan","Bilge Yigit Ozkan and Marco Spruit","Assessing and Improving Cybersecurity Maturity for SMEs: Standardization
  aspects","8 pages, https://www.raid2018.org/smesecworkshop.html",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  SMEs constitute a very large part of the economy in every country and they
play an important role in economic growth and social development. SMEs are
frequent targets of cybersecurity attacks similar to large enterprises.
However, unlike large enterprises, SMEs mostly have limited capabilities
regarding cybersecurity practices. Given the increasing cybersecurity risks and
the large impact that the risks may bring to the SMEs, assessing and improving
the cybersecurity capabilities is crucial for SMEs for sustainability. This
research aims to provide an approach for SMEs for assessing and improving their
cybersecurity capabilities by integrating key elements from existing industry
standards.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:18:02 GMT""}]","2020-07-06"
"2007.01752","Patrick Brosnan","Patrick Brosnan and Najmuddin Fakhruddin","Fixed points, local monodromy, and incompressibility of congruence
  covers","Added references and typo corrections in v2",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a fixed point theorem for the action of certain local monodromy
groups on \'etale covers and use it to deduce lower bounds in essential
dimension. In particular, we give more geometric proofs of many (but not all)
of the results of the preprint of Farb, Kisin and Wolfson, which uses
arithmetic methods to prove incompressibility results for Shimura varieties and
moduli spaces of curves. Our method allows us to prove results for exceptional
groups, and also for the reduction modulo good primes of Shimura varieties and
moduli spaces of curves.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:18:15 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jul 2020 18:56:44 GMT""}]","2020-07-21"
"2007.01753","Boris Zolotov","Elena Arseneva, Stefan Langerman, Boris Zolotov","A Complete List of All Convex Polyhedra Made by Gluing Regular Pentagons","16 pages, 15 figures. Presented at EGC 2019",,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a complete description of all convex polyhedra whose surface can be
constructed from several congruent regular pentagons by folding and gluing them
edge to edge. Our method of determining the graph structure of the polyhedra
from a gluing is of independent interest and can be used in other similar
settings.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:18:50 GMT""}]","2020-07-06"
"2007.01754","S\'ebastien Lachapelle","Philippe Brouillard, S\'ebastien Lachapelle, Alexandre Lacoste, Simon
  Lacoste-Julien, Alexandre Drouin","Differentiable Causal Discovery from Interventional Data","Appears in: Advances in Neural Information Processing Systems 34
  (NeurIPS 2020). 46 pages",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning a causal directed acyclic graph from data is a challenging task that
involves solving a combinatorial problem for which the solution is not always
identifiable. A new line of work reformulates this problem as a continuous
constrained optimization one, which is solved via the augmented Lagrangian
method. However, most methods based on this idea do not make use of
interventional data, which can significantly alleviate identifiability issues.
This work constitutes a new step in this direction by proposing a
theoretically-grounded method based on neural networks that can leverage
interventional data. We illustrate the flexibility of the
continuous-constrained framework by taking advantage of expressive neural
architectures such as normalizing flows. We show that our approach compares
favorably to the state of the art in a variety of settings, including perfect
and imperfect interventions for which the targeted nodes may even be unknown.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:19:17 GMT""},{""version"":""v2"",""created"":""Tue, 3 Nov 2020 20:43:10 GMT""}]","2020-11-05"
"2007.01755","Bin-Bin Gao","Bin-Bin Gao, Hong-Yu Zhou","Learning to Discover Multi-Class Attentional Regions for Multi-Label
  Image Recognition","13 pages, Accepted by IEEE TIP (5-Jun-2021)",,"10.1109/TIP.2021.3088605",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-label image recognition is a practical and challenging task compared to
single-label image classification. However, previous works may be suboptimal
because of a great number of object proposals or complex attentional region
generation modules. In this paper, we propose a simple but efficient two-stream
framework to recognize multi-category objects from global image to local
regions, similar to how human beings perceive objects. To bridge the gap
between global and local streams, we propose a multi-class attentional region
module which aims to make the number of attentional regions as small as
possible and keep the diversity of these regions as high as possible. Our
method can efficiently and effectively recognize multi-class objects with an
affordable computation cost and a parameter-free region localization module.
Over three benchmarks on multi-label image classification, we create new
state-of-the-art results with a single model only using image semantics without
label dependency. In addition, the effectiveness of the proposed method is
extensively demonstrated under different factors such as global pooling
strategy, input size and network architecture. Code has been made available
at~\url{https://github.com/gaobb/MCAR}.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:22:46 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 16:43:01 GMT""},{""version"":""v3"",""created"":""Wed, 9 Jun 2021 08:27:59 GMT""}]","2021-07-21"
"2007.01756","Elvire De Beck","E. De Beck and H. Olofsson","The surprisingly carbon-rich environment of the S-type star W Aql","12 pages, 8 figures (+26 pages appendix) Accepted for publication in
  Astronomy & Astrophysics","A&A 642, A20 (2020)","10.1051/0004-6361/202038335",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  W Aql is an asymptotic giant branch (AGB) star with an atmospheric elemental
abundance ratio C/O$\approx$0.98 and reported circumstellar molecular
abundances intermediate between those of M-type (C/O$<$1) and C-type (C/O$>$1)
AGB stars. This intermediate status is considered typical for S-type stars,
although our understanding of the chemical content of their circumstellar
envelopes (CSEs) is currently rather limited. We performed observations in the
frequency range 159-268 GHz with the APEX telescope and make abundance
estimates through comparison to available spectra towards some well-studied AGB
stars and based on rotational diagram analysis in the case of SiC2. We conclude
that W Aql's CSE appears considerably closer to that of a C-type AGB star than
to that of an M-type AGB star. In particular, we detect emission from C2H,
SiC2, SiN, and HC3N, molecules previously only detected towards the CSEs of
C-type stars. This conclusion, based on the chemistry of the gaseous component
of the CSE, is further supported by reports in the literature on the presence
of atmospheric molecular bands and spectral features of dust species typical
for C-type AGB stars. Although our observations mainly trace species in the
outer regions of the CSE, our conclusion matches closely that based on recent
chemical equilibrium models for the inner wind of S-type stars: the atmospheric
and circumstellar chemistry of S-type stars likely resembles that of C-type AGB
stars much more closely than that of M-type AGB stars. Further observational
investigation of the gaseous circumstellar chemistry of S-type stars is
required to characterise its dependence on the atmospheric C/O. Non-equilibrium
chemical models of the CSEs of AGB stars need to address the particular class
of S-type stars and the chemical variety that is induced by the range in
atmospheric C/O.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:23:45 GMT""}]","2020-09-30"
"2007.01757","Iosif Pinelis","Iosif Pinelis","Monotonicity preservation properties of kernel regression estimators","A shorter version, without pictures, to appear in Statistics and
  Probability Letters",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three common classes of kernel regression estimators are considered: the
Nadaraya--Watson (NW) estimator, the Priestley--Chao (PC) estimator, and the
Gasser--M\""uller (GM) estimator. It is shown that (i) the GM estimator has a
certain monotonicity preservation property for any kernel $K$, (ii) the NW
estimator has this property if and only the kernel $K$ is log concave, and
(iii) the PC estimator does not have this property for any kernel $K$. Other
related properties of these regression estimators are discussed.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:26:00 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 13:15:42 GMT""}]","2021-05-13"
"2007.01758","Guan Shanyan","Shanyan Guan, Ying Tai, Bingbing Ni, Feida Zhu, Feiyue Huang, Xiaokang
  Yang","Collaborative Learning for Faster StyleGAN Embedding","10 pages, 11 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The latent code of the recent popular model StyleGAN has learned disentangled
representations thanks to the multi-layer style-based generator. Embedding a
given image back to the latent space of StyleGAN enables wide interesting
semantic image editing applications. Although previous works are able to yield
impressive inversion results based on an optimization framework, which however
suffers from the efficiency issue. In this work, we propose a novel
collaborative learning framework that consists of an efficient embedding
network and an optimization-based iterator. On one hand, with the progress of
training, the embedding network gives a reasonable latent code initialization
for the iterator. On the other hand, the updated latent code from the iterator
in turn supervises the embedding network. In the end, high-quality latent code
can be obtained efficiently with a single forward pass through our embedding
network. Extensive experiments demonstrate the effectiveness and efficiency of
our work.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:27:37 GMT""}]","2020-07-06"
"2007.01759","Lukas Christian H{\o}gh{\o}j","Lukas Christan H{\o}gh{\o}j (1), Daniel Ruberg N{\o}rhave (1), Joe
  Alexandersen (2), Ole Sigmund (1), Casper Schousboe Andreasen (1) ((1)
  Department of Mechanical Engineering, Section for Solid Mechanics, Technical
  University of Denmark, Kgs. Lyngby, Denmark, (2) Department of Technology and
  Innovation, University of Southern Denmark, Odense, Denmark)","Topology Optimization of Two Fluid Heat Exchangers",,"International Journal of Heat and Mass Transfer (2020)","10.1016/j.ijheatmasstransfer.2020.120543",,"physics.flu-dyn cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A method for density-based topology optimization of heat exchangers with two
fluids is proposed. The goal of the optimization process is to maximize the
heat transfer from one fluid to the other, under maximum pressure drop
constraints for each of the fluid flows. A single design variable is used to
describe the physical fields. The solid interface and the fluid domains are
generated using an erosion-dilation based identification technique, which
guarantees well-separated fluids, as well as a minimum wall thickness between
them. Under the assumption of laminar steady flow, the two fluids are modelled
separately, but in the entire computational domain using the Brinkman
penalization technique for ensuring negligible velocities outside of the
respective fluid subdomains. The heat transfer is modelled using the
convection-diffusion equation, where the convection is driven by both fluid
flows. A stabilized finite element discretization is used to solve the
governing equations. Results are presented for two different problems: a
two-dimensional example illustrating and verifying the methodology; and a
three-dimensional example inspired by shell-and-tube heat exchangers. The
optimized designs for both cases show an improved heat transfer compared to the
baseline designs. For the shell-and-tube case, the full freedom topology
optimization approach is shown to yield performance improvements of up to 113%
under the same pressure drop.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:28:45 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 07:43:28 GMT""}]","2021-10-07"
"2007.01760","Philipp Liznerski","Philipp Liznerski, Lukas Ruff, Robert A. Vandermeulen, Billy Joe
  Franks, Marius Kloft, and Klaus-Robert M\""uller","Explainable Deep One-Class Classification","25 pages, published as a conference paper at ICLR 2021",,,,"cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep one-class classification variants for anomaly detection learn a mapping
that concentrates nominal samples in feature space causing anomalies to be
mapped away. Because this transformation is highly non-linear, finding
interpretations poses a significant challenge. In this paper we present an
explainable deep one-class classification method, Fully Convolutional Data
Description (FCDD), where the mapped samples are themselves also an explanation
heatmap. FCDD yields competitive detection performance and provides reasonable
explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet.
On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps,
FCDD sets a new state of the art in the unsupervised setting. Our method can
incorporate ground-truth anomaly maps during training and using even a few of
these (~5) improves performance significantly. Finally, using FCDD's
explanations we demonstrate the vulnerability of deep one-class classification
models to spurious image features such as image watermarks.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:29:06 GMT""},{""version"":""v2"",""created"":""Mon, 12 Oct 2020 16:11:43 GMT""},{""version"":""v3"",""created"":""Thu, 18 Mar 2021 10:35:33 GMT""}]","2021-03-19"
"2007.01761","Colin Werner","Colin Werner, Ze Shi Li, Neil Ernst, Daniela Damian","The Lack of Shared Understanding of Non-Functional Requirements in
  Continuous Software Engineering: Accidental or Essential?","12 pages, 1 figure, to be published in 28th IEEE International
  Requirements Engineering Conference (RE'20)",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Building shared understanding of requirements is key to ensuring downstream
software activities are efficient and effective. However, in continuous
software engineering (CSE) some lack of shared understanding is an expected,
and essential, part of a rapid feedback learning cycle. At the same time, there
is a key trade-off with avoidable costs, such as rework, that come from
accidental gaps in shared understanding. This trade-off is even more
challenging for non-functional requirements (NFRs), which have significant
implications for product success. Comprehending and managing NFRs is especially
difficult in small, agile organizations. How such organizations manage shared
understanding of NFRs in CSE is understudied. We conducted a case study of
three small organizations scaling up CSE to further understand and identify
factors that contribute to lack of shared understanding of NFRs, and its
relationship to rework. Our in-depth analysis identified 41 NFR-related
software tasks as rework due to a lack of shared understanding of NFRs. Of
these 41 tasks 78% were due to avoidable (accidental) lack of shared
understanding of NFRs. Using a mixed-methods approach we identify factors that
contribute to lack of shared understanding of NFRs, such as the lack of domain
knowledge, rapid pace of change, and cross-organizational communication
problems. We also identify recommended strategies to mitigate lack of shared
understanding through more effective management of requirements knowledge in
such organizations. We conclude by discussing the complex relationship between
shared understanding of requirements, rework and, CSE.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:32:08 GMT""}]","2020-07-06"
"2007.01762","Jacob Blackmore","Jacob A. Blackmore, Rahul Sawant, Philip D. Gregory, Sarah L. Bromley,
  Jes\'us Aldegunde, Jeremy M. Hutson and Simon L. Cornish","Controlling the ac Stark effect of RbCs with dc electric and magnetic
  fields",,"Phys. Rev. A 102, 053316 (2020)","10.1103/PhysRevA.102.053316",,"physics.atom-ph cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the effects of static electric and magnetic fields on the
differential ac Stark shifts for microwave transitions in ultracold bosonic
$^{87}$Rb$^{133}$Cs molecules, for light of wavelength $\lambda =
1064~\mathrm{nm}$. Near this wavelength we observe unexpected two-photon
transitions that may cause trap loss. We measure the ac Stark effect in
external magnetic and electric fields, using microwave spectroscopy of the
first rotational transition. We quantify the isotropic and anisotropic parts of
the molecular polarizability at this wavelength. We demonstrate that a modest
electric field can decouple the nuclear spins from the rotational angular
momentum, greatly simplifying the ac Stark effect. We use this simplification
to control the ac Stark shift using the polarization angle of the trapping
laser.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:34:18 GMT""}]","2020-11-25"
"2007.01763","Igor Abritta Costa","E. Baracchini and L. Benussi and S. Bianco and C. Capoccia and M.
  Caponero and G. Cavoto and A. Cortez and I. A. Costa and E. Di Marco and G.
  D'Imperio and G. Dho and F. Iacoangeli and G. Maccarrone and M. Marafini and
  G. Mazzitelli and A. Messina and R. A. Nobrega and A. Orlandi and E. Paoletti
  and L. Passamonti and F. Petrucci and D. Piccolo and D. Pierluigi and D.
  Pinci and F. Renga and F. Rosatelli and A. Russo and G. Saviano and S.
  Tomassini","A density-based clustering algorithm for the CYGNO data analysis",,"JINST 15 (2020) no.12, T12003","10.1088/1748-0221/15/12/T12003",,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time Projection Chambers (TPCs) working in combination with Gas Electron
Multipliers (GEMs) produce a very sensitive detector capable of observing low
energy events. This is achieved by capturing photons generated during the GEM
electron multiplication process by means of a high-resolution camera. The CYGNO
experiment has recently developed a TPC Triple GEM detector coupled to a low
noise and high spatial resolution CMOS sensor. For the image analysis, an
algorithm based on an adapted version of the well-known DBSCAN was implemented,
called iDBSCAN. In this paper a description of the iDBSCAN algorithm is given,
including test and validation of its parameters, and a comparison with DBSCAN
itself and a widely used algorithm known as Nearest Neighbor Clustering (NNC).
The results show that the adapted version of DBSCAN is capable of providing
full signal detection efficiency and very good energy resolution while
improving the detector background rejection.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:34:46 GMT""},{""version"":""v2"",""created"":""Fri, 18 Sep 2020 17:51:25 GMT""},{""version"":""v3"",""created"":""Mon, 28 Sep 2020 17:52:16 GMT""}]","2020-12-08"
"2007.01764","Xiang Wang","Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, Tat-Seng Chua","Disentangled Graph Collaborative Filtering","SIGIR 2020",,"10.1145/3397271.3401137",,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning informative representations of users and items from the interaction
data is of crucial importance to collaborative filtering (CF). Present
embedding functions exploit user-item relationships to enrich the
representations, evolving from a single user-item instance to the holistic
interaction graph. Nevertheless, they largely model the relationships in a
uniform manner, while neglecting the diversity of user intents on adopting the
items, which could be to pass time, for interest, or shopping for others like
families. Such uniform approach to model user interests easily results in
suboptimal representations, failing to model diverse relationships and
disentangle user intents in representations.
  In this work, we pay special attention to user-item relationships at the
finer granularity of user intents. We hence devise a new model, Disentangled
Graph Collaborative Filtering (DGCF), to disentangle these factors and yield
disentangled representations. Specifically, by modeling a distribution over
intents for each user-item interaction, we iteratively refine the intent-aware
interaction graphs and representations. Meanwhile, we encourage independence of
different intents. This leads to disentangled representations, effectively
distilling information pertinent to each intent. We conduct extensive
experiments on three benchmark datasets, and DGCF achieves significant
improvements over several state-of-the-art models like NGCF, DisenGCN, and
MacridVAE. Further analyses offer insights into the advantages of DGCF on the
disentanglement of user intents and interpretability of representations. Our
codes are available in
https://github.com/xiangwang1223/disentangled_graph_collaborative_filtering.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:37:25 GMT""}]","2020-07-06"
"2007.01765","Dimitrios K. Papoulias","O. G. Miranda, D. K. Papoulias, M. T\'ortola, J. W. F. Valle","XENON1T signal from transition neutrino magnetic moments","10 pages, 3 figures, 1 table. V2: Fig.1 updated, references added,
  matches published version","Phys.Lett. B 808 (2020) 135685","10.1016/j.physletb.2020.135685",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent puzzling results of the XENON1T collaboration at few keV
electronic recoils could be due to the scattering of solar neutrinos endowed
with finite Majorana transition magnetic moments (TMMs). Within such general
formalism, we find that the observed excess in the XENON1T data agrees well
with this interpretation. The required TMM strengths lie within the limits set
by current experiments, such as Borexino, specially when one takes into account
a possible tritium contamination.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:41:28 GMT""},{""version"":""v2"",""created"":""Fri, 14 Aug 2020 21:15:49 GMT""}]","2020-08-18"
"2007.01766","Kirtiman Ghosh","Avnish and Kirtiman Ghosh","Multi-charged TeV scale scalars and fermions in the framework of a
  radiative seesaw model","54 pages, 21 figures and 6 tables",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Explaining the tiny neutrino masses and non-zero mixings have been one of the
key motivations for going beyond the framework of the Standard Model (SM). We
discuss a collider testable model for generating neutrino masses and mixings
via radiative seesaw mechanism. That the model does not require any additional
symmetry to forbid tree-level seesaws makes its collider phenomenology
interesting. The model includes multi-charged fermions/scalars at the TeV scale
to realize the Weinberg operator at 1-loop level. After deriving the
constraints on the model parameters resulting from the neutrino oscillation
data as well as from the upper bound on the absolute neutrino mass scale, we
discuss the production, decay and resulting collider signatures of these TeV
scale fermions/scalars at the Large Hadron Collider (LHC). We consider both
Drell-Yan and photoproduction. The bounds from the neutrino data indicate the
possible presence of a long-lived multi-charged particle (MCP) in this model.
We obtain bounds on these long-lived MCP masses from the ATLAS search for
abnormally large ionization signature. When the TeV scale fermions/scalars
undergo prompt decay, we focus on the 4-lepton final states and obtain bounds
from different ATLAS 4-lepton searches. We also propose a 4-lepton event
selection criteria designed to enhance the signal to background ratio in the
context of this model.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:41:57 GMT""}]","2020-07-06"
"2007.01767","Yi-Chao Li","Yichao Li, Mario G. Santos, Keith Grainge, Stuart Harper, Jingying
  Wang","HI intensity mapping with MeerKAT: 1/f noise analysis","14 pages, 12 figures",,"10.1093/mnras/staa3856",,"astro-ph.CO astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nature of the time correlated noise component (the 1/f noise) of single
dish radio telescopes is critical to the detectability of the HI signal in
intensity mapping experiments. In this paper, we present the 1/f noise
properties of the MeerKAT receiver system using South Celestial Pole (SCP)
tracking data. We estimate both the temporal power spectrum density and the 2D
power spectrum density for each of the antennas and polarizations. We apply
Singular Value Decomposition (SVD) to the dataset and show that, by removing
the strongest components, the 1/f noise can be drastically reduced, indicating
that it is highly correlated in frequency. Without SVD mode subtraction, the
knee frequency over a $20\,$MHz integration is higher than $0.1\,\rm Hz$; with
just $2$~mode subtraction, the knee frequency is reduced to $\sim 3\times
10^{-3}\,{\rm Hz}$, indicating that the system induced 1/f-type variations are
well under the thermal noise fluctuations over a few hundred seconds time
scales. The 2D power spectrum shows that the 1/f-type variations are restricted
to a small region in the time-frequency space, either with long wavelength
correlations in frequency or in time. This gives a wide range of cosmological
scales where the 21cm signal can be measured without further need to calibrate
the gain time fluctuations. Finally, we demonstrate that a simple power
spectrum parameterization is sufficient to describe the data and provide
fitting parameters for both the 1D and 2D power spectrum.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:42:52 GMT""}]","2020-12-23"
"2007.01768","Qiang Yuan","Qiang Yuan (PMO), Bing-Qiang Qiao (PMO, IHEP), Yi-Qing Guo (IHEP),
  Yi-Zhong Fan (PMO), Xiao-Jun Bi (IHEP)","Nearby source interpretation of differences among light and medium
  composition spectra in cosmic rays","6 pages, 3 figures; accepted for publication in Frontiers of Physics","Front. Phys. 16 (2021) 24501","10.1007/s11467-020-0990-4",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently the AMS-02 reported the precise measurements of the energy spectra
of medium-mass compositions (Neon, Magnesium, Silicon) of primary cosmic rays,
which reveal different properties from those of light compositions (Helium,
Carbon, Oxygen). Here we propose a nearby source scenario, together with the
background source contribution, to explain the newly measured spectra of cosmic
ray Ne, Mg, Si, and particularly their differences from that of He, C, O. Their
differences at high energies can be naturally accounted for by the element
abundance of the nearby source. Specifically, the abundance ratio of the nearby
source to the background of the Ne, Mg, Si elements is lower by a factor of
$\sim1.7$ than that of the He, C, O elements. Such a difference could be due to
the abundance difference of the stellar evolution of the progenitor star or the
acceleration process/environment, of the nearby source. This scenario can
simultaneously explain the high-energy spectral softening features of cosmic
ray spectra revealed recently by CREAM/NUCLEON/DAMPE, as well as the
energy-dependent behaviors of the large-scale anisotropies. It is predicted
that the dipole anisotropy amplitudes below PeV energies of the Ne, Mg, Si
group are smaller than that of the He, C, O group, which can be tested with
future measurements.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:44:33 GMT""},{""version"":""v2"",""created"":""Tue, 25 Aug 2020 11:45:15 GMT""}]","2021-07-08"
"2007.01769","Thomas Eboli","Thomas Eboli, Jian Sun, Jean Ponce","End-to-end Interpretable Learning of Non-blind Image Deblurring","Accepted at ECCV2020 (poster)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-blind image deblurring is typically formulated as a linear least-squares
problem regularized by natural priors on the corresponding sharp picture's
gradients, which can be solved, for example, using a half-quadratic splitting
method with Richardson fixed-point iterations for its least-squares updates and
a proximal operator for the auxiliary variable updates. We propose to
precondition the Richardson solver using approximate inverse filters of the
(known) blur and natural image prior kernels. Using convolutions instead of a
generic linear preconditioner allows extremely efficient parameter sharing
across the image, and leads to significant gains in accuracy and/or speed
compared to classical FFT and conjugate-gradient methods. More importantly, the
proposed architecture is easily adapted to learning both the preconditioner and
the proximal operator using CNN embeddings. This yields a simple and efficient
algorithm for non-blind image deblurring which is fully interpretable, can be
learned end to end, and whose accuracy matches or exceeds the state of the art,
quite significantly, in the non-uniform case.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:45:01 GMT""},{""version"":""v2"",""created"":""Tue, 15 Sep 2020 14:44:59 GMT""}]","2020-09-16"
"2007.01770","Igor F. Justo","M. A. L. Capri, I. F. Justo, L. F. Palhares, G. Peruzzo, S. P. Sorella","Study of the renormalization of BRST invariant local composite operators
  in the $U(1)$ Higgs model","36 pages, 6 figures","Phys. Rev. D 102, 033003 (2020)","10.1103/PhysRevD.102.033003",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The renormalization properties of two local BRST invariant composite
operators, $(O,V_\mu)$, corresponding respectively to the gauge invariant
description of the Higgs particle and of the massive gauge vector boson, are
scrutinized in the $U(1)$ Higgs model by means of the algebraic renormalization
setup. Their renormalization $Z$'s factors are explicitly evaluated at one-loop
order in the $\overline{\text{MS}}$ scheme by taking into due account the
mixing with other gauge invariant operators. In particular, it turns out that
the operator $V_\mu$ mixes with the gauge invariant quantity $\partial_\nu
F_{\mu\nu}$, which has the same quantum numbers, giving rise to a $2 \times 2$
mixing matrix. Moreover, two additional powerful Ward identities exist which
enable us to determine the whole set of $Z$'s factors entering the $2 \times 2$
mixing matrix as well as the $Z$ factor of the operator $O$ in a purely
algebraic way. An explicit check of these Ward identities is provided. The
final setup obtained allows for computing perturbatively the full renormalized
result for any $n$-point correlation function of the scalar and vector
composite operators.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:45:23 GMT""}]","2020-08-26"
"2007.01771","Bin-Bin Gao","Bin-Bin Gao, Xin-Xin Liu, Hong-Yu Zhou, Jianxin Wu, Xin Geng","Learning Expectation of Label Distribution for Facial Age and
  Attractiveness Estimation","submitted to Pattern Recognition",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Facial attributes (\eg, age and attractiveness) estimation performance has
been greatly improved by using convolutional neural networks. However, existing
methods have an inconsistency between the training objectives and the
evaluation metric, so they may be suboptimal. In addition, these methods always
adopt image classification or face recognition models with a large amount of
parameters, which carry expensive computation cost and storage overhead. In
this paper, we firstly analyze the essential relationship between two
state-of-the-art methods (Ranking-CNN and DLDL) and show that the Ranking
method is in fact learning label distribution implicitly. This result thus
firstly unifies two existing popular state-of-the-art methods into the DLDL
framework. Second, in order to alleviate the inconsistency and reduce resource
consumption, we design a lightweight network architecture and propose a unified
framework which can jointly learn facial attribute distribution and regress
attribute value. The effectiveness of our approach has been demonstrated on
both facial age and attractiveness estimation tasks. Our method achieves new
state-of-the-art results using the single model with 36$\times$ fewer
parameters and 3$\times$ faster inference speed on facial age/attractiveness
estimation. Moreover, our method can achieve comparable results as the
state-of-the-art even though the number of parameters is further reduced to
0.9M (3.8MB disk storage).
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:46:53 GMT""},{""version"":""v2"",""created"":""Fri, 31 Dec 2021 11:00:57 GMT""}]","2022-01-03"
"2007.01772","Carlos Zapata-Carratal\'a","Carlos Zapata-Carratala","Jacobi Geometry and Hamiltonian Mechanics: the Unit-Free Approach",,,"10.1142/S0219887820300056",,"math.DG math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We present a systematic treatment of line bundle geometry and Jacobi
manifolds with an application to geometric mechanics that has not been noted in
the literature. We precisely identify categories that generalise the ordinary
categories of smooth manifolds and vector bundles to account for a lack of
choice of a preferred unit, which in standard differential geometry is always
given by the global constant function $1$. This is what we call the `unit-free'
approach. After giving a characterisation of local Lie brackets via their
symbol maps we apply our novel categorical language to review Jacobi manifolds
and related notions such as Lichnerowicz brackets and Jacobi algebroids. The
main advantage of our approach is that Jacobi geometry is recovered as the
direct unit-free generalisation of Poisson geometry, with all the familiar
notions translating in a straightforward manner. We then apply this formalism
to the question of whether there is a unit-free generalisation of Hamiltonian
mechanics. We identify the basic categorical structure of ordinary Hamiltonian
mechanics to argue that it is indeed possible to find a unit-free analogue.
This work serves as a prelude to the investigation of dimensioned structures,
an attempt at a general mathematical framework for the formal treatment of
physical quantities and dimensional analysis.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:49:15 GMT""}]","2020-12-02"
"2007.01773","Anne-Kathrin Schmuck","Rupak Majumdar and Anne-Kathrin Schmuck","Supervisory Controller Synthesis for Non-terminating Processes is an
  Obliging Game",,,,,"cs.LO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new algorithm to solve the supervisory control problem over
non-terminating processes modeled as $\omega$-regular automata. A solution to
this problem was obtained by Thistle in 1995 which uses complex manipulations
of automata. We show a new solution to the problem through a reduction to
obliging games, which, in turn, can be reduced to $\omega$-regular reactive
synthesis. Therefore, our reduction results in a symbolic algorithm based on
manipulating sets of states using tools from reactive synthesis.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:49:22 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jan 2021 08:05:55 GMT""},{""version"":""v3"",""created"":""Thu, 26 Aug 2021 07:44:57 GMT""}]","2021-08-27"
"2007.01774","Benjamin Tan","Benjamin Tan, Marc-Antoine Lemonde, Supanut Thanasilp, Jirawat
  Tangpanitanon, Dimitris G. Angelakis","Qubit-efficient encoding schemes for binary optimisation problems","9 pages of main text + 6 figures. Comments are welcome","Quantum 5, 454 (2021)","10.22331/q-2021-05-04-454",,"quant-ph cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  We propose and analyze a set of variational quantum algorithms for solving
quadratic unconstrained binary optimization problems where a problem consisting
of $n_c$ classical variables can be implemented on $\mathcal O(\log n_c)$
number of qubits. The underlying encoding scheme allows for a systematic
increase in correlations among the classical variables captured by a
variational quantum state by progressively increasing the number of qubits
involved. We first examine the simplest limit where all correlations are
neglected, i.e. when the quantum state can only describe statistically
independent classical variables. We apply this minimal encoding to find
approximate solutions of a general problem instance comprised of 64 classical
variables using 7 qubits. Next, we show how two-body correlations between the
classical variables can be incorporated in the variational quantum state and
how it can improve the quality of the approximate solutions. We give an example
by solving a 42-variable Max-Cut problem using only 8 qubits where we exploit
the specific topology of the problem. We analyze whether these cases can be
optimized efficiently given the limited resources available in state-of-the-art
quantum platforms. Lastly, we present the general framework for extending the
expressibility of the probability distribution to any multi-body correlations.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:52:24 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 05:22:39 GMT""}]","2021-05-05"
"2007.01775","Benoit Loiseau","B. Loiseau and S. Wycech","Extraction of baryonia from the lightest anti-protonic atoms","19 pages, 2 figures, 12 tables; added 2 tables giving informations on
  antiproton interaction; added discussion on charge-exchange contributions;
  typo corrected; published in PRC","Phys. Rev. C 102, 034006 (2020)","10.1103/PhysRevC.102.034006",,"nucl-th hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anti-protonic hydrogen and helium atoms are analyzed. Level shifts and width
are expressed in terms of $\bar{p}$-nucleon sub-threshold scattering lengths
and volumes. Experimental data are compared to results obtained from the 2009
version of the Paris $N\bar{N}$ interaction potential. Comparison with 1999
version is also made. Effects of $N\bar{N}$ quasi-bound states are discussed.
Atomic 2P hyperfine structure is calculated for antiprotonic deuterium and the
significance of new measurements is indicated.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:53:44 GMT""},{""version"":""v2"",""created"":""Tue, 13 Oct 2020 16:43:18 GMT""}]","2020-10-14"
"2007.01776","Konrad Wenz","Konrad Wenz, Ivan Kozyryev, Rees L. McNally, Leland Aldridge, Tanya
  Zelevinsky","Large molasses-like cooling forces for molecules using polychromatic
  optical fields: A theoretical description",,"Phys. Rev. Research 2, 043377 (2020)","10.1103/PhysRevResearch.2.043377",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent theoretical investigations have indicated that rapid optical cycling
should be feasible in complex polyatomic molecules with diverse constituents,
geometries and symmetries. However, as a composite molecular mass grows, so
does the required number of photon scattering events necessary to decelerate
and confine molecular beams using laser light. Utilizing coherent momentum
exchange between light fields and molecules can suppress spontaneous emission
and significantly reduce experimental complexity for slowing and trapping.
Working with BaH as a test species, we have identified a robust, experimentally
viable configuration to achieve large molasses-like cooling forces for
molecules using polychromatic optical fields addressing both $X-A$ and $X-B$
electronic transitions, simultaneously. Using numerical solutions of the
time-dependent density matrix as well as Monte Carlo simulations, we
demonstrate that creation of Suppressed Emission Rate (SupER) molasses with
large capture velocities ($\sim 40$ m/s) is generically feasible for polyatomic
molecules of increasing complexity that have an optical cycling center.
Proposed SupER molasses are anticipated to not only extend quantum control to
novel molecular species with abundant vibrational decay channels, but also
significantly increase trapped densities for previously laser-cooled diatomic
and triatomic species.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:56:50 GMT""},{""version"":""v2"",""created"":""Mon, 12 Oct 2020 22:46:51 GMT""}]","2020-12-18"
"2007.01856","Ritesh Kumar Mishra","Ritesh Kumar Mishra","$^{26}$Al-$^{26}$Mg isotopic, mineralogy, petrography of a
  Hibonite-Pyroxene Spherule in Allan Hills 77307 (CO3.03): Implications for
  the origin and evolution of these objects","arXiv admin note: substantial text overlap with arXiv:1712.00603",,,,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  10 Hibonite-pyroxene/glass spherules discovered hitherto are a rare suite of
refractory inclusions that show the largest range of exotic isotopic properties
(anomalies in neutron rich isotopes (e.g., $^{48}$Ca, $^{50}$Ti), abundance of
$^{26}$Al) despite their defining simple spherical morphology and mineralogy
consisting predominantly of few hibonites nestled within/with glassy or
crystallised calcium, aluminium-rich pyroxene. $^{26}$Al-$^{26}$Mg
chronological studies along with petrography and mineralogy of a relatively
large (~120 micron diameter), found in Allan Hills 77307 (CO3.03) has been
performed. Uniquely, both hibonite and pyroxene show discordant abundance of
short-lived now-extinct radionuclide $^{26}$Al that suggest disparate and
distinct regions of origin of hibonite and pyroxene. The pristine petrography
and mineralogy of this inclusion allow discernment of their genesis and trend
of alteration in hibonite-pyroxene/glass spherules.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:18:27 GMT""}]","2020-07-07"
"2007.01857","Dalcimar Casanova","Muriel Mazzetto and Marcelo Teixeira and \'Erick Oliveira Rodrigues
  and Dalcimar Casanova","Deep Learning Models for Visual Inspection on Automotive Assembling Line","arXiv admin note: text overlap with arXiv:1802.08717,
  arXiv:1703.05921 by other authors","International Journal of Advanced Engineering Research and Science
  7(4) (2020) 473-494","10.22161/ijaers.74.56",,"cs.CV eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Automotive manufacturing assembly tasks are built upon visual inspections
such as scratch identification on machined surfaces, part identification and
selection, etc, which guarantee product and process quality. These tasks can be
related to more than one type of vehicle that is produced within the same
manufacturing line. Visual inspection was essentially human-led but has
recently been supplemented by the artificial perception provided by computer
vision systems (CVSs). Despite their relevance, the accuracy of CVSs varies
accordingly to environmental settings such as lighting, enclosure and quality
of image acquisition. These issues entail costly solutions and override part of
the benefits introduced by computer vision systems, mainly when it interferes
with the operating cycle time of the factory. In this sense, this paper
proposes the use of deep learning-based methodologies to assist in visual
inspection tasks while leaving very little footprints in the manufacturing
environment and exploring it as an end-to-end tool to ease CVSs setup. The
proposed approach is illustrated by four proofs of concept in a real automotive
assembly line based on models for object detection, semantic segmentation, and
anomaly detection.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 20:00:45 GMT""}]","2020-07-07"
"2007.01858","Pawe{\l} Pietrzycki Dr","Pawe{\l} Pietrzycki","On Cauchy dual operator and duality for Banach spaces of analytic
  functions",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, two related types of dualities are investigated. The first is
the duality between left-invertible operators and the second is the duality
between Banach spaces of vector-valued analytic functions. We will examine a
pair ($\mathcal{B},\Psi)$ consisting of a reflexive Banach spaces $\mathcal{B}$
of vector-valued analytic functions on which a left-invertible multiplication
operator acts and an operator-valued holomorphic function $\Psi$. We prove that
there exist a dual pair ($\mathcal{B}^\prime,\Psi^\prime)$ such that the space
$\mathcal{B}^\prime$ is unitarily equivalent to the space $\mathcal{B}^*$ and
the following intertwining relations hold
  \begin{equation*}
  \mathscr{L} \mathcal{U} = \mathcal{U}\mathscr{M}_z^* \quad\text{and}\quad
  \mathscr{M}_z\mathcal{U} = \mathcal{U} \mathscr{L}^*,
  \end{equation*} where $\mathcal{U}$ is the unitary operator between
$\mathcal{B}^\prime$ and $\mathcal{B}^*$. In addition we show that $\Psi$ and
$\Psi^\prime$ are connected through the relation\begin{equation*}
  \langle(\Psi^\prime( \bar{z}) e_1) (\lambda),e_2\rangle= \langle e_1,(\Psi(
\bar{ \lambda}) e_2)(z)\rangle \end{equation*} for every $e_1,e_2\in E$, $z\in
\varOmega$, $\lambda\in \varOmega^\prime$.
  If a left-invertible operator $T$ satisfies certain conditions, then both $T$
and the Cauchy dual operator $T^\prime$ can be modelled as a multiplication
operator on reproducing kernel Hilbert spaces of vector-valued analytic
functions $\mathscr{H}$ and $\mathscr{H}^\prime$, respectively. We prove that
Hilbert space of the dual pair of $(\mathscr{H},\Psi)$ coincide with
$\mathscr{H}^\prime$, where $\Psi$ is a certain operator-valued holomorphic
function. Moreover, we characterize when the duality between spaces
$\mathscr{H}$ and $\mathscr{H}^\prime$ obtained by identifying them with
$\mathcal{H}$ is the same as the duality obtained from the Cauchy pairing.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:45:19 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 11:51:05 GMT""},{""version"":""v3"",""created"":""Sat, 10 Apr 2021 16:09:07 GMT""},{""version"":""v4"",""created"":""Thu, 22 Jul 2021 13:04:56 GMT""}]","2021-07-23"
"2007.01859","Mamoru Doi","Mamoru Doi","Improved flat-back 3D gadgets in origami extrusions completely downward
  compatible with the conventional pyramid-supported 3D gadgets","33 pages, 19 figures. arXiv admin note: text overlap with
  arXiv:1908.07342",,,,"cs.CG math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An origami extrusion is a folding of a 3D object in the middle of a flat
piece of paper, using 3D gadgets which create faces with solid angles. In this
paper we focus on 3D gadgets which create a top face parallel to the ambient
paper and two side faces sharing a ridge, with two outgoing simple pleats,
where a simple pleat is a pair of a mountain fold and a valley fold. There are
two such types of 3D gadgets. One is the conventional type of 3D gadgets with a
triangular pyramid supporting the two side faces from inside. The other is the
newer type of 3D gadgets presented in our previous paper, which improve the
conventional ones in several respects: They have flat back sides above the
ambient paper and no gap between the side faces; they are less interfering with
adjacent gadgets so that we can make the extrusion higher at one time; they are
downward compatible with conventional ones if constructible; they have a
modified flat-back gadget used for repetition which does not interfere with
adjacent gadgets; the angles of their outgoing pleats can be changed under
certain conditions. However, there are cases where we can apply the
conventional gadgets while we cannot our previous ones. The purpose of this
paper is to improve our previous 3D gadgets to be completely downward
compatible with the conventional ones, in the sense that any conventional
gadget can be replaced by our improved one with the same outgoing pleats, but
the converse is not always possible. To be more precise, we prove that for any
given conventional 3D gadget there are an infinite number of improved 3D
gadgets which are compatible with it, and the conventional 3D gadget can be
replaced with any of these 3D gadgets without affecting any other conventional
3D gadget. Also, we see that our improved 3D gadget keep all of the above
advantages over the conventional ones.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:04:27 GMT""}]","2020-07-07"
"2007.01860","Adam Larios","Adam Larios, Elizabeth Carlson","Sensitivity Analysis for the 2D Navier-Stokes Equations with
  Applications to Continuous Data Assimilation","arXiv admin note: substantial text overlap with arXiv:1812.07646",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We rigorously prove the well-posedness of the formal sensitivity equations
with respect to the Reynolds number corresponding to the 2D incompressible
Navier-Stokes equations. Moreover, we do so by showing a sequence of difference
quotients converges to the unique solution of the sensitivity equations for
both the 2D Navier-Stokes equations and the related data assimilation
equations, which utilize the continuous data assimilation algorithm proposed by
Azouani, Olson, and Titi. As a result, this method of proof provides uniform
bounds on difference quotients, demonstrating parameter recovery algorithms
that change parameters as the system evolves will not blow-up. We also note
that this appears to be the first such rigorous proof of global existence and
uniqueness to strong or weak solutions to the sensitivity equations for the 2D
Navier-Stokes equations (in the natural case of zero initial data), and that
they can be obtained as a limit of difference quotients with respect to the
Reynolds number.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:14:26 GMT""}]","2020-07-07"
"2007.01861","Shaolin Liao Dr.","Shaolin Liao and Lu Ou","IPO: Iterative Physical Optics Image Approximation","9 pages, 7 figures, more results added to the preprint of a paper
  submitted to the PIER Letters (http://www.jpier.org/PIERL/), July 2020",,,,"physics.class-ph physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An improved Iterative Physical Optics (IPO) image approximation method has
been presented to dramatically increase the accuracy of the approximation and
extend its applicability to PEC surfaces with smaller radii or larger
curvatures. Starting from the first-order conventional PO image approximation,
the IPO image approximation method iteratively correct the surface current to
compensate the deviation of the electric field boundary condition on the PEC
surfaces, making use of the local plane wave approximation. Numerical
validations with two popular PEC surfaces, i.e., the parabolic dish antennas
and the PEC spheres, are carried out and the results show that the IPO
approximation method increases the surface current accuracy by more than two
orders of magnitude, compared to the conventional PO image approximation
method.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:51:10 GMT""}]","2020-07-07"
"2007.01862","HMN Dilum Bandara","M. Shazmin Marikar and H.M.N. Dilum Bandara","An Analysis of Data Driven, Decision-Making Capabilities of Managers in
  Banks","19 pages, 8 figues, 5 tables",,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Organizations are adopting data analytics and Business Intelligence (BI)
tools to gain insights from the past data, forecast future events, and to get
timely and reliable information for decision making. While the tools are
becoming mature, affordable, and more comfortable to use, it is also essential
to understand whether the contemporary managers and leaders are ready for
Data-Driven Decision Making (DDDM). We explore the extent the Decision Makers
(DMs) utilize data and tools, as well as their ability to interpret various
forms of outputs from tools and to apply those insights to gain competitive
advantage. Our methodology was based on a qualitative survey, where we
interviewed 12 DMs of six commercial banks in Sri Lanka at the branch,
regional, and CTO, CIO, and Head of IT levels. We identified that on many
occasions, DMs' intuition overrules the DDDM due to uncertainty, lack of trust,
knowledge, and risk-taking. Moreover, it was identified that the quality of
visualizations has a significant impact on the use of intuition by overruling
DDDM. We further provide a set of recommendations on the adoption of BI tools
and how to overcome the struggles faced while performing DDDM.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:14:56 GMT""}]","2020-07-07"
"2007.01863","Elvira Zappale","Ana Cristina Barroso and Elvira Zappale","An optimal design problem with non-standard growth and no concentration
  effects","arXiv admin note: text overlap with arXiv:1712.03657",,,,"math.AP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain an integral representation for certain functionals arising in the
context of optimal design and damage evolution problems under non-standard
growth conditions and perimeter penalisation. Under our hypotheses, the
integral representation includes a term which is absolutely continuous with
respect to the Lebesgue measure and a perimeter term, but no additional
singular term.
  We also study some dimension reduction problems providing results for the
optimal design of thin films.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:21:48 GMT""},{""version"":""v2"",""created"":""Sun, 11 Apr 2021 17:01:04 GMT""}]","2021-04-13"
"2007.01864","Di Yuan","Di Yuan, Xiu Shu, Nana Fan, Xiaojun Chang, Qiao Liu and Zhenyu He","Accurate Bounding-box Regression with Distance-IoU Loss for Visual
  Tracking",,,"10.1016/j.jvcir.2021.103428",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most existing trackers are based on using a classifier and multi-scale
estimation to estimate the target state. Consequently, and as expected,
trackers have become more stable while tracking accuracy has stagnated. While
trackers adopt a maximum overlap method based on an intersection-over-union
(IoU) loss to mitigate this problem, there are defects in the IoU loss itself,
that make it impossible to continue to optimize the objective function when a
given bounding box is completely contained within/without another bounding box;
this makes it very challenging to accurately estimate the target state.
Accordingly, in this paper, we address the above-mentioned problem by proposing
a novel tracking method based on a distance-IoU (DIoU) loss, such that the
proposed tracker consists of target estimation and target classification. The
target estimation part is trained to predict the DIoU score between the target
ground-truth bounding-box and the estimated bounding-box. The DIoU loss can
maintain the advantage provided by the IoU loss while minimizing the distance
between the center points of two bounding boxes, thereby making the target
estimation more accurate. Moreover, we introduce a classification part that is
trained online and optimized with a Conjugate-Gradient-based strategy to
guarantee real-time tracking speed. Comprehensive experimental results
demonstrate that the proposed method achieves competitive tracking accuracy
when compared to state-of-the-art trackers while with a real-time tracking
speed.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:57:54 GMT""},{""version"":""v2"",""created"":""Tue, 11 Aug 2020 07:51:48 GMT""},{""version"":""v3"",""created"":""Sun, 10 Jan 2021 04:04:45 GMT""},{""version"":""v4"",""created"":""Thu, 20 Jan 2022 02:43:52 GMT""}]","2022-01-21"
"2007.01866","Rui Aguiar","Rui Aguiar, Jon Braatz","Selecting Regions of Interest in Large Multi-Scale Images for Cancer
  Pathology","9 pages",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent breakthroughs in object detection and image classification using
Convolutional Neural Networks (CNNs) are revolutionizing the state of the art
in medical imaging, and microscopy in particular presents abundant
opportunities for computer vision algorithms to assist medical professionals in
diagnosis of diseases ranging from malaria to cancer. High resolution scans of
microscopy slides called Whole Slide Images (WSIs) offer enough information for
a cancer pathologist to come to a conclusion regarding cancer presence,
subtype, and severity based on measurements of features within the slide image
at multiple scales and resolutions. WSIs' extremely high resolutions and
feature scales ranging from gross anatomical structures down to cell nuclei
preclude the use of standard CNN models for object detection and
classification, which have typically been designed for images with dimensions
in the hundreds of pixels and with objects on the order of the size of the
image itself. We explore parallel approaches based on Reinforcement Learning
and Beam Search to learn to progressively zoom into the WSI to detect Regions
of Interest (ROIs) in liver pathology slides containing one of two types of
liver cancer, namely Hepatocellular Carcinoma (HCC) and Cholangiocarcinoma
(CC). These ROIs can then be presented directly to the pathologist to aid in
measurement and diagnosis or be used for automated classification of tumor
subtype.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:27:41 GMT""}]","2020-07-07"
"2007.02673","Daniel \v{S}tifani\'c","Daniel \v{S}tifani\'c, Jelena Musulin, Adrijana Mio\v{c}evi\'c, Sandi
  Baressi \v{S}egota, Roman \v{S}ubi\'c, Zlatan Car","Impact of COVID-19 on Forecasting Stock Prices: An Integration of
  Stationary Wavelet Transform and Bidirectional Long Short-Term Memory","26 pages, 9 figures",,,,"q-fin.ST stat.ML","http://creativecommons.org/licenses/by/4.0/","  COVID-19 is an infectious disease that mostly affects the respiratory system.
At the time of this research being performed, there were more than 1.4 million
cases of COVID-19, and one of the biggest anxieties is not just our health, but
our livelihoods, too. In this research, authors investigate the impact of
COVID-19 on the global economy, more specifically, the impact of COVID-19 on
financial movement of Crude Oil price and three U.S. stock indexes: DJI, S&P
500 and NASDAQ Composite. The proposed system for predicting commodity and
stock prices integrates the Stationary Wavelet Transform (SWT) and
Bidirectional Long Short-Term Memory (BDLSTM) networks. Firstly, SWT is used to
decompose the data into approximation and detail coefficients. After
decomposition, data of Crude Oil price and stock market indexes along with
COVID-19 confirmed cases were used as input variables for future price movement
forecasting. As a result, the proposed system BDLSTM+WT-ADA achieved
satisfactory results in terms of five-day Crude Oil price forecast.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:03:39 GMT""}]","2020-07-07"
"2007.02674","Thomas Johnson","Thomas Johnson, Eiman Kanjo, Kieran Woodward","Sensor Data and the City: Urban Visualisation and Aggregation of
  Well-Being Data","4 pages, 5 figures",,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  The growth of mobile sensor technologies have made it possible for city
councils to understand peoples' behaviour in urban spaces which could help to
reduce stress around the city. We present a quantitative approach to convey a
collective sense of urban places. The data was collected at a high level of
granularity, navigating the space around a highly popular urban environment. We
capture people's behaviour by leveraging continuous multi-model sensor data
from environmental and physiological sensors. The data is also tagged with
self-report, location coordinates as well as the duration in different
environments. The approach leverages an exploratory data visualisation along
with geometrical and spatial data analysis algorithms, allowing spatial and
temporal comparisons of data clusters in relation to people's behaviour.
Deriving and quantifying such meaning allows us to observe how mobile sensing
unveils the emotional characteristics of places from such crowd-contributed
content.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:44:52 GMT""}]","2020-07-07"
"2007.02682","Siddhant Singh","Siddhant Singh","A switching approach for perfect state transfer over a scalable and
  routing enabled network architecture with superconducting qubits","Master Thesis for undergraduate integrated BS-MS course in Physics.
  arXiv admin note: substantial text overlap with arXiv:1102.2338,
  arXiv:quant-ph/0411020, arXiv:quant-ph/0212041 by other authors; text overlap
  with arXiv:1908.10018, arXiv:1803.09813, arXiv:quant-ph/0312126 by other
  authors",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a hypercube switching architecture for the perfect state transfer
(PST) where we prove that it is always possible to find an induced hypercube in
any given hypercube of any dimension such that PST can be performed between any
two given vertices of the original hypercube. We then generalise this switching
scheme over arbitrary number of qubits where also this routing feature of PST
between any two vertices is possible. It is shown that this is optimal and
scalable architecture for quantum computing with the feature of routing. This
allows for a scalable and growing network of qubits. We demonstrate this
switching scheme to be experimentally realizable using superconducting transmon
qubits with tunable couplings. We also propose a PST assisted quantum computing
model where we show the computational advantage of using PST against the
conventional resource expensive quantum swap gates. In addition, we present the
numerical study of signed graphs under Corona product of graphs and show few
examples where PST is established, in contrast to pre-existing results in the
literature for disproof of PST under Corona product. We also report an error in
pre-existing research for qudit state transfer over Bosonic Hamiltonian where
unitarity is violated.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:20:02 GMT""}]","2020-07-07"
"2007.02709","Mark Hagmann","Mark J. Hagmann and Logan D. Gibb","Consistent analytical solution for the response of a nanoscale circuit
  to a mode-locked laser","15 pages. arXiv admin note: substantial text overlap with
  arXiv:2006.04956",,,,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is now common practice to solve the Schr\""odinger equation to estimate the
tunneling current between two electrodes at specified potentials, or the
transmission through a potential barrier by assuming that there is an incident,
reflected, and transmitted wave. However, these two approaches may not be
appropriate for applications with nanoscale circuits. A new approach is
required because the electron man-free path may be as long as 68.2 nm in metals
so it is possible that the wavefunction may be coherent throughout a nanoscale
circuit. We define several algorithms for determining the eigenvalues with
different sets of the circuit parameters, thus demonstrating the existence of
consistent solutions for nanoscale circuits. We also present another algorithm
that is being applied to determine the full solution for nanoscale circuits.
All of this is done using only analytical solutions of the Schr\""odinger
equation.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:57:09 GMT""}]","2020-07-07"
"2007.02710","Sergio Barbero","Sergio Barbero and Mar\'ia del Mar Gonz\'alez","Admissible surfaces in progressive addition lenses",,,"10.1364/OL.401927",,"math.DG physics.med-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Progressive addition lenses contain a surface of spatially-varying curvature,
which provides variable optical power for different viewing areas over the
lens. We derive complete compatibility equations that provide the exact
magnitude of cylinder along lines of curvatures on any arbitrary PAL smooth
surface. These equations reveal that, contrary to current knowledge, cylinder,
and its derivative, does not only depend on principal curvature and its
derivatives along the principal line but also on the geodesic curvature and its
derivatives along the line orthogonal to the principal line. We quantify the
relevance of the geodesic curvature through numerical computations. We also
derive an extended and exact Minkwitz theorem only restricted to be applied
along lines of curvatures, but excluding umbilical points.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:59:47 GMT""}]","2020-10-28"
"2007.02711","Li-Heng Chen","Li-Heng Chen and Christos G. Bampis and Zhi Li and Andrey Norkin and
  Alan C. Bovik","Perceptually Optimizing Deep Image Compression","7 pages, 6 figures. arXiv admin note: substantial text overlap with
  arXiv:1910.08845",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mean squared error (MSE) and $\ell_p$ norms have largely dominated the
measurement of loss in neural networks due to their simplicity and analytical
properties. However, when used to assess visual information loss, these simple
norms are not highly consistent with human perception. Here, we propose a
different proxy approach to optimize image analysis networks against
quantitative perceptual models. Specifically, we construct a proxy network,
which mimics the perceptual model while serving as a loss layer of the
network.We experimentally demonstrate how this optimization framework can be
applied to train an end-to-end optimized image compression network. By building
on top of a modern deep image compression models, we are able to demonstrate an
averaged bitrate reduction of $28.7\%$ over MSE optimization, given a specified
perceptual quality (VMAF) level.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:33:28 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 15:04:06 GMT""}]","2020-07-13"
"2007.02720","Gregor Cerar","Gregor Cerar, Halil Yetgin, Mihael Mohor\v{c}i\v{c}, Carolina Fortuna","On Designing a Machine Learning Based Wireless Link Quality Classifier","accepted in PIMRC 2020. arXiv admin note: text overlap with
  arXiv:1812.08856","PIMRC 2020","10.1109/PIMRC48278.2020.9217171",,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ensuring a reliable communication in wireless networks strictly depends on
the effective estimation of the link quality, which is particularly challenging
when propagation environment for radio signals significantly varies. In such
environments, intelligent algorithms that can provide robust, resilient and
adaptive links are being investigated to complement traditional algorithms in
maintaining a reliable communication. In this respect, the data-driven link
quality estimation (LQE) using machine learning (ML) algorithms is one of the
most promising approaches. In this paper, we provide a quantitative evaluation
of design decisions taken at each step involved in developing a ML based
wireless LQE on a selected, publicly available dataset. Our study shows that,
re-sampling to achieve training class balance and feature engineering have a
larger impact on the final performance of the LQE than the selection of the ML
method on the selected data.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 14:31:14 GMT""}]","2021-04-19"
"2007.02723","Diyora Salimova","Aritz Bercher, Lukas Gonon, Arnulf Jentzen, Diyora Salimova","Weak error analysis for stochastic gradient descent optimization
  algorithms","123 pages",,,,"math.NA cs.LG cs.NA math.OC math.PR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic gradient descent (SGD) type optimization schemes are fundamental
ingredients in a large number of machine learning based algorithms. In
particular, SGD type optimization schemes are frequently employed in
applications involving natural language processing, object and face
recognition, fraud detection, computational advertisement, and numerical
approximations of partial differential equations. In mathematical convergence
results for SGD type optimization schemes there are usually two types of error
criteria studied in the scientific literature, that is, the error in the strong
sense and the error with respect to the objective function. In applications one
is often not only interested in the size of the error with respect to the
objective function but also in the size of the error with respect to a test
function which is possibly different from the objective function. The analysis
of the size of this error is the subject of this article. In particular, the
main result of this article proves under suitable assumptions that the size of
this error decays at the same speed as in the special case where the test
function coincides with the objective function.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:38:16 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jul 2020 12:07:12 GMT""}]","2020-07-22"
"2007.02724","Armenuhi Ghazaryan G","A.G. Ghazaryan, H.H. Matevosyan, Kh.V. Sedrakian","Second and third harmonics generation by coherent sub-THz radiation at
  induced Lifshitz transitions in gapped bilayer graphene","15 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:1905.08016; text overlap with arXiv:1508.02922 by other authors",,"10.1134/S1063776121050034",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the microscopic nonlinear quantum theory of interaction of strong
coherent electromagnetic radiation with a gapped bilayer graphene is developed
for high harmonic generation at low-energy photon excitation-induced Lifshitz
transitions. The Liouville-von Neumann equation for the density matrix is
solved numerically at the nonadiabatic multiphoton excitation regime. By
numerical solutions, we examine the rates of the second and third harmonics
generation at the particle-hole annihilation in induced Lifshitz transitions by
the two linearly polarized coherent electromagnetic waves propagating in
opposite directions. The obtained results show that the gapped bilayer graphene
can serve as an effective medium for generation of even and odd high harmonics
in the sub-THz domain of frequencies.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:59:05 GMT""}]","2021-07-14"
"2007.02725","Michael Chappell","Michael A. Chappell and Mark W. Woolrich","The FMRIB Variational Bayesian Inference Tutorial II: Stochastic
  Variational Bayes","Example code and exercises associated with this tutorial can be found
  here: https://vb-tutorial.readthedocs.io",,,,"stat.ME cs.LG","http://creativecommons.org/licenses/by/4.0/","  Bayesian methods have proved powerful in many applications for the inference
of model parameters from data. These methods are based on Bayes' theorem, which
itself is deceptively simple. However, in practice the computations required
are intractable even for simple cases. Hence methods for Bayesian inference
have historically either been significantly approximate, e.g., the Laplace
approximation, or achieve samples from the exact solution at significant
computational expense, e.g., Markov Chain Monte Carlo methods. Since around the
year 2000 so-called Variational approaches to Bayesian inference have been
increasingly deployed. In its most general form Variational Bayes (VB) involves
approximating the true posterior probability distribution via another more
'manageable' distribution, the aim being to achieve as good an approximation as
possible. In the original FMRIB Variational Bayes tutorial we documented an
approach to VB based that took a 'mean field' approach to forming the
approximate posterior, required the conjugacy of prior and likelihood, and
exploited the Calculus of Variations, to derive an iterative series of update
equations, akin to Expectation Maximisation. In this tutorial we revisit VB,
but now take a stochastic approach to the problem that potentially circumvents
some of the limitations imposed by the earlier methodology. This new approach
bears a lot of similarity to, and has benefited from, computational methods
applied to machine learning algorithms. Although, what we document here is
still recognisably Bayesian inference in the classic sense, and not an attempt
to use machine learning as a black-box to solve the inference problem.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 11:31:52 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 10:30:42 GMT""}]","2020-07-10"
"2007.02726","Yasin Simsek","Cem Cakmakli and Yasin Simsek","Bridging the COVID-19 Data and the Epidemiological Model using Time
  Varying Parameter SIRD Model",,,,,"q-bio.PE econ.EM stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper extends the canonical model of epidemiology, SIRD model, to allow
for time varying parameters for real-time measurement of the stance of the
COVID-19 pandemic. Time variation in model parameters is captured using the
generalized autoregressive score modelling structure designed for the typically
daily count data related to pandemic. The resulting specification permits a
flexible yet parsimonious model structure with a very low computational cost.
This is especially crucial at the onset of the pandemic when the data is scarce
and the uncertainty is abundant. Full sample results show that countries
including US, Brazil and Russia are still not able to contain the pandemic with
the US having the worst performance. Furthermore, Iran and South Korea are
likely to experience the second wave of the pandemic. A real-time exercise show
that the proposed structure delivers timely and precise information on the
current stance of the pandemic ahead of the competitors that use rolling
window. This, in turn, transforms into accurate short-term predictions of the
active cases. We further modify the model to allow for unreported cases.
Results suggest that the effects of the presence of these cases on the
estimation results diminish towards the end of sample with the increasing
number of testing.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:31:55 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 10:21:36 GMT""}]","2021-02-11"
"2007.02727","Julien Mathiaud","Y Dauvois (CEA), J. Mathiaud (CEA-CESTA, CELIA), Luc Mieussens (IMB)","An ES-BGK model for vibrational polyatomic gases",,,,,"cond-mat.stat-mech math-ph math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an extension of the Ellipsoidal-Statistical BGK model to account
for discrete levels of vibrational energy in a rarefied polyatomic gas. This
model satisfies an H-theorem and contains parameters that allow to fit almost
arbitrary values for the Prandtl number and the relaxation times of rotational
and vibrational energies. With the reduced distribution technique , this model
can be reduced to a three distribution system that could be used to simulate
polyatomic gases with rotational and vibrational energy for a computational
cost close to that of a simple monoatomic gas.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:34:24 GMT""}]","2020-07-07"
"2007.02728","HMN Dilum Bandara","Sandareka Wickramanayake, H.M.N Dilum Bandara, Nishal A. Samarasekara","Real-Time Monitoring and Driver Feedback to Promote Fuel Efficient
  Driving","17 pages, 9 figures, and 3 tables",,,,"cs.HC cs.AI","http://creativecommons.org/licenses/by/4.0/","  Improving the fuel efficiency of vehicles is imperative to reduce costs and
protect the environment. While the efficient engine and vehicle designs, as
well as intelligent route planning, are well-known solutions to enhance the
fuel efficiency, research has also demonstrated that the adoption of
fuel-efficient driving behaviors could lead to further savings. In this work,
we propose a novel framework to promote fuel-efficient driving behaviors
through real-time automatic monitoring and driver feedback. In this framework,
a random-forest based classification model developed using historical data to
identifies fuel-inefficient driving behaviors. The classifier considers
driver-dependent parameters such as speed and acceleration/deceleration
pattern, as well as environmental parameters such as traffic, road topography,
and weather to evaluate the fuel efficiency of one-minute driving events. When
an inefficient driving action is detected, a fuzzy logic inference system is
used to determine what the driver should do to maintain fuel-efficient driving
behavior. The decided action is then conveyed to the driver via a smartphone in
a non-intrusive manner. Using a dataset from a long-distance bus, we
demonstrate that the proposed classification model yields an accuracy of 85.2%
while increasing the fuel efficiency up to 16.4%.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 09:23:53 GMT""}]","2020-07-07"
"2007.02847","Guandong Xu","Hamad Zogan, Imran Razzak, Xianzhi Wang, Shoaib Jameel, Guandong Xu","Explainable Depression Detection with Multi-Modalities Using a Hybrid
  Deep Learning Model on Social Media","23 Pages",,,,"cs.IR cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model interpretability has become important to engenders appropriate user
trust by providing the insight into the model prediction. However, most of the
existing machine learning methods provide no interpretability for depression
prediction, hence their predictions are obscure to human. In this work, we
propose interpretive Multi-Modal Depression Detection with Hierarchical
Attention Network MDHAN, for detection depressed users on social media and
explain the model prediction. We have considered user posts along with
Twitter-based multi-modal features, specifically, we encode user posts using
two levels of attention mechanisms applied at the tweet-level and word-level,
calculate each tweet and words' importance, and capture semantic sequence
features from the user timelines (posts). Our experiments show that MDHAN
outperforms several popular and robust baseline methods, demonstrating the
effectiveness of combining deep learning with multi-modal features. We also
show that our model helps improve predictive performance when detecting
depression in users who are posting messages publicly on social media. MDHAN
achieves excellent performance and ensures adequate evidence to explain the
prediction.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 12:11:22 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 09:33:07 GMT""}]","2021-04-29"
"2007.03069","Kirk Bansak","Kirk Bansak, Elisabeth Paulson","Outcome-Driven Dynamic Refugee Assignment with Allocation Balancing",,,,,"math.OC cs.GT cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study proposes two new dynamic assignment algorithms to match refugees
and asylum seekers to geographic localities within a host country. The first,
currently implemented in a multi-year pilot in Switzerland, seeks to maximize
the average predicted employment level (or any measured outcome of interest) of
refugees through a minimum-discord online assignment algorithm. Although the
proposed algorithm achieves near-optimal expected employment compared to the
hindsight-optimal solution (and improves upon the status quo procedure by about
40%), it results in a periodically imbalanced allocation to the localities over
time. This leads to undesirable workload inefficiencies for resettlement
resources and agents. To address this problem, the second algorithm balances
the goal of improving refugee outcomes with the desire for an even allocation
over time. The performance of the proposed methods is illustrated using real
refugee resettlement data from a large resettlement agency in the United
States. On this dataset, we find that the allocation balancing algorithm can
achieve near-perfect balance over time with only a small loss in expected
employment compared to the pure employment-maximizing algorithm. In addition,
the allocation balancing algorithm offers a number of ancillary benefits
compared to pure outcome-maximization, including robustness to unknown arrival
flows and greater exploration.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:28:15 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 00:01:14 GMT""},{""version"":""v3"",""created"":""Fri, 10 Dec 2021 20:13:33 GMT""},{""version"":""v4"",""created"":""Thu, 13 Jan 2022 00:31:34 GMT""}]","2022-01-14"
"2007.03428","Gabriel R. Bengochea","Gabriel R. Bengochea","On the quantum description of the early universe","9 pages","Rev. Mex. Fis. E 17 (2) 263-271 (2020)","10.31349/RevMexFisE.17.263",,"physics.gen-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Why is it interesting to try to understand the origin of the universe?
Everything we observe today, including our existence, arose from that event.
Although we still do not have a theory that allows us to describe the origin
itself, the study of the very early era of the universe involves the ideal
terrain to analyze the interface between two of today's most successful
physical theories, General Relativity and Quantum physics. But it is also an
area in which we have a large number of observational data to test our
theoretical ideas. Two of the fathers of Quantum physics, Niels Bohr and Werner
Heisenberg, shared some thoughts that could be described with these words:
""Quantum physics tells us that there is a line between the observed and the
observer, and therefore science should be limited to what is observed. We must
give up a complete, objective and realistic theory of the world"". This article
will orbit around these ideas and summarizes how it is that today, from recent
works, we are in a position to try to challenge them (at least in part) through
cosmology, seeking the quantum description of the early universe.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 23:38:52 GMT""}]","2020-07-08"
"2007.03744","Maryam Rahbaralam Ph.D.","Maryam Rahbaralam, David Modesto, Jaume Card\'us, Amir Abdollahi, and
  Fernando M Cucchietti","Predictive Analytics for Water Asset Management: Machine Learning and
  Survival Analysis","19 pages, 7 figures",,,,"eess.SP cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding performance and prioritizing resources for the maintenance of
the drinking-water pipe network throughout its life-cycle is a key part of
water asset management. Renovation of this vital network is generally hindered
by the difficulty or impossibility to gain physical access to the pipes. We
study a statistical and machine learning framework for the prediction of water
pipe failures. We employ classical and modern classifiers for a short-term
prediction and survival analysis to provide a broader perspective and long-term
forecast, usually needed for the economic analysis of the renovation. To enrich
these models, we introduce new predictors based on water distribution domain
knowledge and employ a modern oversampling technique to remedy the high
imbalance coming from the few failures observed each year. For our case study,
we use a dataset containing the failure records of all pipes within the water
distribution network in Barcelona, Spain. The results shed light on the effect
of important risk factors, such as pipe geometry, age, material, and soil
cover, among others, and can help utility managers conduct more informed
predictive maintenance tasks.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 19:08:36 GMT""}]","2020-07-09"
"2007.03758","Quercus Hern\'andez Lain","Quercus Hernandez, Alberto Badias, David Gonzalez, Francisco Chinesta,
  Elias Cueto","Deep learning of thermodynamics-aware reduced-order models from data","17 pages, 7 figures",,"10.1016/j.cma.2021.113763",,"cs.CE cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an algorithm to learn the relevant latent variables of a
large-scale discretized physical system and predict its time evolution using
thermodynamically-consistent deep neural networks. Our method relies on sparse
autoencoders, which reduce the dimensionality of the full order model to a set
of sparse latent variables with no prior knowledge of the coded space
dimensionality. Then, a second neural network is trained to learn the
metriplectic structure of those reduced physical variables and predict its time
evolution with a so-called structure-preserving neural network. This data-based
integrator is guaranteed to conserve the total energy of the system and the
entropy inequality, and can be applied to both conservative and dissipative
systems. The integrated paths can then be decoded to the original
full-dimensional manifold and be compared to the ground truth solution. This
method is tested with two examples applied to fluid and solid mechanics.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 08:49:01 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 17:51:00 GMT""}]","2021-03-25"
"2007.03761","Takuro Ideguchi","Akira Kawai, Takahiro Kageyama, Ryoichi Horisaki, and Takuro Ideguchi","Compressive dual-comb spectroscopy",,,,,"eess.SP physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Broadband, high resolution and rapid measurement of dual-comb spectroscopy
(DCS) generates a large amount of data stream. We numerically demonstrate
significant data compression of DCS spectra by using a compressive sensing
technique. Our numerical simulation shows a compression rate of more than 100
with 3% error in mole fraction estimation of mid-infrared (MIR) DCS of two
molecular species in a broadband (~30 THz) and high resolution (~115 MHz)
condition. We also numerically demonstrate a massively parallel MIR DCS
spectrum of 10 different molecular species can be reconstructed with a
compression rate of 10.5 with a transmittance error of 0.003 from the original
spectrum.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 00:29:15 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 00:16:35 GMT""}]","2021-02-16"
"2007.03763","Mahmoud Pourmehrab","Mahmoud Pourmehrab, Lily Elefteriadou, Sanjay Ranka","Real-time Intersection Optimization for Signal Phasing, Timing, and
  Automated Vehicles' Trajectories",,,,,"eess.SP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study aims to develop a real-time intersection optimization (RIO)
control algorithm to efficiently serve traffic of Connected and Automated
Vehicles (CAVs) and conventional vehicles (CNVs). This paper extends previous
work to consider demand over capacity conditions and trajectory deviations by
re-optimizing decisions. To jointly optimize Signal Phase and Timing (SPaT) and
departure time of CAVs, we formulated a joint optimization model which is
reduced to and solved as a Minimum Cost Flow (MCF) problem. The MCF-based
optimization models is embedded into the RIO algorithm to operate the signal
controller and to plan the movement of CAVs. Simulation experiments showed
18-22% travel time decrease and up to 12% capacity improvement compared to the
base scenario.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 01:14:13 GMT""}]","2020-07-09"
"2007.04765","Omar El Housni","Omar El Housni, Mika Sumida, Paat Rusmevichientong, Huseyin Topaloglu,
  Serhan Ziya","Future Evolution of COVID-19 Pandemic in North Carolina: Can We Flatten
  the Curve?","arXiv admin note: substantial text overlap with arXiv:2005.14700",,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On June 24th, Governor Cooper announced that North Carolina will not be
moving into Phase 3 of its reopening process at least until July 17th. Given
the recent increases in daily positive cases and hospitalizations, this
decision was not surprising. However, given the political and economic
pressures which are forcing the state to reopen, it is not clear what actions
will help North Carolina to avoid the worst. We use a compartmentalized model
to study the effects of social distancing measures and testing capacity
combined with contact tracing on the evolution of the pandemic in North
Carolina until the end of the year. We find that going back to restrictions
that were in place during Phase 1 will slow down the spread but if the state
wants to continue to reopen or at least remain in Phase 2 or Phase 3 it needs
to significantly expand its testing and contact tracing capacity. Even under
our best-case scenario of high contact tracing effectiveness, the number of
contact tracers the state currently employs is inadequate.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:53:34 GMT""}]","2020-07-10"
"2007.04830","Tim Palmer","Tim Palmer","A Vision for Numerical Weather Prediction in 2030","For World Meteorological Organisation White Paper on Future of NWP",,,,"physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this essay, I outline a personal vision of how I think Numerical Weather
Prediction (NWP) should evolve in the years leading up to 2030 and hence what
it should look like in 2030. By NWP I mean initial-value predictions from
timescales of hours to seasons ahead. Here I want to focus on how NWP can
better help save lives from increasingly extreme weather in those parts of the
world where society is most vulnerable. Whilst we can rightly be proud of many
parts of our NWP heritage, its evolution has been influenced by national or
institutional politics as well as by underpinning scientific principles.
Sometimes these conflict with each other. It is important to be able to
separate these issues when discussing how best meteorological science can serve
society in 2030; otherwise any disruptive change - no matter how compelling the
scientific case for it - becomes impossibly difficult.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 07:41:26 GMT""},{""version"":""v2"",""created"":""Tue, 19 Apr 2022 09:21:44 GMT""}]","2022-04-20"
"2007.06498","Mian Zhang","Kevin Luke, Prashanta Kharel, Christian Reimer, Lingyan He, Marko
  Loncar, Mian Zhang","Wafer-scale low-loss lithium niobate photonic integrated circuits","5 pages, 4 figures",,"10.1364/OE.401959",,"physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thin-film lithium niobate (LN) photonic integrated circuits (PICs) could
enable ultrahigh performance in electro-optic and nonlinear optical devices. To
date, realizations have been limited to chip-scale proof-of-concepts. Here we
demonstrate monolithic LN PICs fabricated on 4- and 6-inch wafers with deep
ultraviolet lithography and show smooth and uniform etching, achieving 0.27
dB/cm optical propagation loss on wafer-scale. Our results show that LN PICs
are fundamentally scalable and can be highly cost-effective.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 04:19:27 GMT""}]","2020-08-26"
"2007.06500","Armen M. Gulian","Iris Dorn and Armen Gulian","Phonon Feedback Effects on Dynamics of Phase Slip Centers in Finite Gap
  Superconductors",,,,,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The results on the behavior of phase-slip centers in thin superconducting
wires based on finite-element modeling and time-dependent Ginzburg-Landau
(TDGL) equations are discussed. For closer relationship with experiments, we
used finite-gap formulation of the TDGL system. Both the dynamic equation for
the Cooper-pair condensate wave-function and the expression for the electric
current are more complex than in the gapless case. On this basis, the influence
of nonequilibrium phonons is explored. These phonons can essentially change the
location of geometrical points in which the phase slippage takes place. They
also affect the frequency of phase-slip oscillations. The reported effects are
experimentally detectable and can be used in practical devices.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 22:57:48 GMT""}]","2020-07-14"
"2007.06501","Sarit Agami","Sarit Agami","Impact of COVID-19 on Air Quality in Israel",,,,,"physics.soc-ph physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The COVID-19 pandemic has caused, in general, a sharp reduction in traffic
and industrial activities. This in turn leaded to a reduction in air pollution
around the world. It is important to quantity the amount of that reduction in
order to estimate the influence weight of traffic and industrial activities
over the total variation of air quality. The aim of this paper is to evaluate
the impact of the COVID-19 outbreak on air pollution in Israel, which is
considered one of the countries with a higher air pollution than other Western
countries. The results reveal two main findings: 1. During the COVID-19
outbreak, relative to its earlier closest period, the pollution from transport,
based on Nitrogen oxides, had reduced by 40$\%$ on average, whereas the
pollution from industrial, based on Grand-level ozone, had increased by 34$\%$
on average. Relative to 2019, the COVID-19 outbreak caused a reduction in air
pollution from transport and industrial as well. 2. The explanation percent of
the time period of COVID-19 is at most 22$\%$ over the total variation of each
pollutant amount.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 15:59:46 GMT""}]","2020-07-14"
"2007.06509","Armen M. Gulian","Yurii Aleshchenko, Boris Gorshunov, Elena Zhukova, Andrey Muratov,
  Alexander Dudka, Rajendra Dulal, Serafim Teknowijoyo, Sara Chahid, Vahan
  Nikoghosyan, and Armen Gulian","Terahertz spectroscopy evidence of possible 40 K superconductivity in
  rhenium-doped strontium ruthenates",,"Phys. Rev. Research 2, 042020 (2020)","10.1103/PhysRevResearch.2.042020",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Strontium ruthenates have many similarities with copper oxide superconductors
and are of particular interest for the investigation of the mechanisms and
conditions which lead to high-temperature superconductivity. We report here on
multiple experimental indications of superconductivity with onset at 40 K in
strontium ruthenate doped by rhenium and selenium with chlorine used as the
flux. The main experimental evidence arises from terahertz spectroscopy of this
material followed by AC and DC magnetization, as well as measurements of its
heat capacity and magnetoresistance. Structural and morphological studies
revealed the heterophase nature of this polycrystalline material as well as the
changes of lattice parameters relative to the original phases. Experimental
data show a higher critical temperature on the surface compared to that of the
bulk of the sample.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 21:52:26 GMT""}]","2020-11-04"
"2007.06633","Darrick Lee","Darrick Lee, Robert Ghrist","Path Signatures on Lie Groups","64 pages, 11 figures",,,,"cs.CV cs.LG math.DG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Path signatures are powerful nonparametric tools for time series analysis,
shown to form a universal and characteristic feature map for Euclidean valued
time series data. We lift the theory of path signatures to the setting of Lie
group valued time series, adapting these tools for time series with underlying
geometric constraints. We prove that this generalized path signature is
universal and characteristic. To demonstrate universality, we analyze the human
action recognition problem in computer vision, using $SO(3)$ representations
for the time series, providing comparable performance to other shallow learning
approaches, while offering an easily interpretable feature set. We also provide
a two-sample hypothesis test for Lie group-valued random walks to illustrate
its characteristic property. Finally we provide algorithms and a Julia
implementation of these methods.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:38:49 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 17:29:03 GMT""}]","2020-07-16"
"2007.06706","Boyang Lyu","Boyang Lyu, Thao Pham, Giles Blaney, Zachary Haga, Angelo Sassaroli,
  Sergio Fantini, Shuchin Aeron","Domain Adaptation for Robust Workload Level Alignment Between Sessions
  and Subjects using fNIRS",,,"10.1117/1.JBO.26.2.022908",,"cs.CV cs.LG q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Significance: We demonstrated the potential of using domain adaptation on
functional Near-Infrared Spectroscopy (fNIRS) data to classify different levels
of n-back tasks that involve working memory. Aim: Domain shift in fNIRS data is
a challenge in the workload level alignment across different experiment
sessions and subjects. In order to address this problem, two domain adaptation
approaches -- Gromov-Wasserstein (G-W) and Fused Gromov-Wasserstein (FG-W) were
used. Approach: Specifically, we used labeled data from one session or one
subject to classify trials in another session (within the same subject) or
another subject. We applied G-W for session-by-session alignment and FG-W for
subject-by-subject alignment to fNIRS data acquired during different n-back
task levels. We compared these approaches with three supervised methods:
multi-class Support Vector Machine (SVM), Convolutional Neural Network (CNN),
and Recurrent Neural Network (RNN). Results: In a sample of six subjects, G-W
resulted in an alignment accuracy of 68 $\pm$ 4 % (weighted mean $\pm$ standard
error) for session-by-session alignment, FG-W resulted in an alignment accuracy
of 55 $\pm$ 2 % for subject-by-subject alignment. In each of these cases, 25 %
accuracy represents chance. Alignment accuracy results from both G-W and FG-W
are significantly greater than those from SVM, CNN and RNN. We also showed that
removal of motion artifacts from the fNIRS data plays an important role in
improving alignment performance. Conclusions: Domain adaptation has potential
for session-by-session and subject-by-subject alignment of mental workload by
using fNIRS data.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:03:50 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 01:52:13 GMT""}]","2023-04-03"
"2007.10090","Amirhoshang Hoseinpour Dehkordi","Amirhoshang Hoseinpour Dehkordi, Majid Alizadeh, Ali Movaghar","Meet MASKS: A novel Multi-Classifier's verification approach","34 pages, 12 figures, 1 table",,,,"cs.AI cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, a new ensemble approach for classifiers is introduced. A
verification method for better error elimination is developed through the
integration of multiple classifiers. A multi-agent system comprised of multiple
classifiers is designed to verify the satisfaction of the safety property. In
order to examine the reasoning concerning the aggregation of the distributed
knowledge, a logical model has been proposed. To verify predefined properties,
a Multi-Agent Systems' Knowledge-Sharing algorithm (MASKS) has been formulated
and developed. As a rigorous evaluation, we applied this model to the
Fashion-MNIST, MNIST, and Fruit-360 datasets, where it reduced the error rate
to approximately one-tenth of the individual classifiers.
","[{""version"":""v1"",""created"":""Fri, 3 Jul 2020 10:47:40 GMT""},{""version"":""v2"",""created"":""Fri, 11 Dec 2020 11:48:44 GMT""},{""version"":""v3"",""created"":""Thu, 2 Jun 2022 15:26:24 GMT""}]","2022-06-03"
"2007.12596","Hailiang Liu","Wenli Cai and Hailiang Liu","Dynamics of many species through competition for resources",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with a mathematical model of competition for resource
where species consume noninteracting resources. This system of differential
equations is formally obtained by renormalizing the MacArthur's competition
model at equilibrium, and agrees with the trait-continuous model studied by
Mirrahimi S, Perthame B, Wakano JY [J. Math. Biol. 64(7): 1189-1223, 2012]. As
a dynamical system, self-organized generation of distinct species occurs. The
necessary conditions for survival are given. We prove the existence of the
evolutionary stable distribution (ESD) through an optimization problem and
present an independent algorithm to compute the ESD directly. Under certain
structural conditions, solutions of the system are shown to approach the
discrete ESD as time evolves. The time discretization of the system is proven
to satisfy two desired properties: positivity and energy dissipation. Numerical
examples are given to illustrate certain interesting biological phenomena.
","[{""version"":""v1"",""created"":""Thu, 2 Jul 2020 18:57:57 GMT""}]","2020-07-27"
