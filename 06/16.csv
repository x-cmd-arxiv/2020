"2006.08502","Thomas G. Rizzo","Thomas G. Rizzo","Dark Initial State Radiation and the Kinetic Mixing Portal","19 pages, 7 figs; Reference added, minor text changes",,"10.1007/JHEP01(2021)079","SLAC-PUB-17528","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data from Planck measurements of the cosmic microwave background (CMB) place
important constraints on models with light dark matter (DM) and light mediators
especially when both lie in the mass range below $\sim 1 $ GeV. In models
involving kinetic mixing where the dark photon acts as the mediator, these
constraints are easily satisfied and the appropriate DM relic density
achievable if the DM is, e.g., a complex scalar, where $p$-wave annihilation
occurs, or is the lighter component of a split pseudo-Dirac state where
co-annihilation dominates. In both of these cases, although higher order in the
dark gauge coupling, $g_D$, the corresponding annihilation processes including
dark photon initial state radiation (ISR) will be dominantly $s$-wave with
essentially temperature independent cross sections. The rates for these dark
ISR associated processes, though not yielding cross sections large enough to
contribute to the relic density, can still run into possible conflicts with the
bounds arising from the CMB. In this paper we perform a preliminary study of
the present and potential future constraints that the CMB imposes on the
parameter spaces for both of these scenarios due to the existence of this dark
ISR. Further analyses of the effects of dark ISR in DM annihilation is clearly
warranted.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:01:11 GMT""},{""version"":""v2"",""created"":""Thu, 10 Sep 2020 15:41:06 GMT""},{""version"":""v3"",""created"":""Tue, 6 Oct 2020 16:31:03 GMT""},{""version"":""v4"",""created"":""Tue, 20 Oct 2020 15:18:19 GMT""}]","2021-02-03"
"2006.08503","Andr\'es Chirre","Andr\'es Chirre and Emily Quesada-Herrera","The second moment of $S_n(t)$ on the Riemann hypothesis","To appear in Int. J. Number Theory",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $S(t) = \tfrac{1}{\pi} \arg \zeta \big({1/2} + it \big)$ be the argument
of the Riemann zeta-function at the point $\tfrac12 + it$. For $n \geq 1$ and
$t>0$ define its antiderivatives as \begin{equation*} S_n(t) = \int_0^t
S_{n-1}(\tau) \hspace{0.08cm} \rm d\tau + \delta_n, \end{equation*} where
$\delta_n$ is a specific constant depending on $n$ and $S_0(t) := S(t)$. In
1925, J. E. Littlewood proved, under the Riemann Hypothesis, that $$
\int_{0}^{T}|S_n(t)|^2 \hspace{0.06cm} \rm dt = O(T), $$ for $n\geq 1$. In
1946, Selberg unconditionally established the explicit asymptotic formulas for
the second moments of $S(t)$ and $S_1(t)$. This was extended by Fujii for
$S_n(t)$, when $n\geq 2$. Assuming the Riemann Hypothesis, we give the explicit
asymptotic formula for the second moment of $S_n(t)$ up to the second-order
term, for $n\geq 1$. Our result conditionally refines Selberg's and Fujii's
formulas and extends previous work by Goldston in 1987, where the case $n=0$
was considered.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:01:46 GMT""},{""version"":""v2"",""created"":""Wed, 6 Oct 2021 12:49:06 GMT""}]","2023-02-17"
"2006.08504","Emanuele Crisostomi","Serife Yilmaz, Ekaterina Dudkina, Michelangelo Bin, Emanuele
  Crisostomi, Pietro Ferraro, Roderick Murray-Smith, Thomas Parisini, Lewi
  Stone, Robert Shorten","Kemeny-based testing for COVID-19",,,"10.1371/journal.pone.0242401",,"physics.soc-ph q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Testing, tracking and tracing abilities have been identified as pivotal in
helping countries to safely reopen activities after the first wave of the
COVID-19 virus. Contact tracing apps give the unprecedented possibility to
reconstruct graphs of daily contacts, so the question is who should be tested?
As human contact networks are known to exhibit community structure, in this
paper we show that the Kemeny constant of a graph can be used to identify and
analyze bridges between communities in a graph. Our ""Kemeny indicator"" is the
change in Kemeny constant when a node or edge is removed from the graph. We
show that testing individuals who are associated with large values of the
Kemeny indicator can help in efficiently intercepting new virus outbreaks, when
they are still in their early stage. Extensive simulations provide promising
results in early identification and in blocking possible ""super-spreaders""
links that transmit disease between different communities.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:03:53 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 18:52:57 GMT""},{""version"":""v3"",""created"":""Thu, 25 Jun 2020 12:08:16 GMT""},{""version"":""v4"",""created"":""Fri, 24 Jul 2020 12:45:05 GMT""}]","2021-01-27"
"2006.08505","Thomas Pierrot","Thomas Pierrot, Valentin Mac\'e, F\'elix Chalumeau, Arthur Flajolet,
  Geoffrey Cideron, Karim Beguir, Antoine Cully, Olivier Sigaud and Nicolas
  Perrin-Gilbert","Diversity Policy Gradient for Sample Efficient Quality-Diversity
  Optimization","Add several baselines (Policy Gradient assisted MAP Elites, DIAYN,
  AGAC) Change writing to take the point of view of the evo community Change
  style, writing, explanation, figures",,"10.1145/3512290.3528845",,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A fascinating aspect of nature lies in its ability to produce a large and
diverse collection of organisms that are all high-performing in their niche. By
contrast, most AI algorithms focus on finding a single efficient solution to a
given problem. Aiming for diversity in addition to performance is a convenient
way to deal with the exploration-exploitation trade-off that plays a central
role in learning. It also allows for increased robustness when the returned
collection contains several working solutions to the considered problem, making
it well-suited for real applications such as robotics. Quality-Diversity (QD)
methods are evolutionary algorithms designed for this purpose. This paper
proposes a novel algorithm, QDPG, which combines the strength of Policy
Gradient algorithms and Quality Diversity approaches to produce a collection of
diverse and high-performing neural policies in continuous control environments.
The main contribution of this work is the introduction of a Diversity Policy
Gradient (DPG) that exploits information at the time-step level to drive
policies towards more diversity in a sample-efficient manner. Specifically,
QDPG selects neural controllers from a MAP-Elites grid and uses two
gradient-based mutation operators to improve both quality and diversity. Our
results demonstrate that QDPG is significantly more sample-efficient than its
evolutionary competitors.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:04:06 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 12:15:55 GMT""},{""version"":""v3"",""created"":""Thu, 25 Nov 2021 13:18:38 GMT""},{""version"":""v4"",""created"":""Thu, 3 Feb 2022 23:14:08 GMT""},{""version"":""v5"",""created"":""Tue, 31 May 2022 08:57:21 GMT""}]","2022-06-01"
"2006.08506","Tobias Watzel","Tobias Watzel, Ludwig K\""urzinger, Lujun Li, Gerhard Rigoll","Regularized Forward-Backward Decoder for Attention Models",,,,,"eess.AS cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays, attention models are one of the popular candidates for speech
recognition. So far, many studies mainly focus on the encoder structure or the
attention module to enhance the performance of these models. However, mostly
ignore the decoder. In this paper, we propose a novel regularization technique
incorporating a second decoder during the training phase. This decoder is
optimized on time-reversed target labels beforehand and supports the standard
decoder during training by adding knowledge from future context. Since it is
only added during training, we are not changing the basic structure of the
network or adding complexity during decoding. We evaluate our approach on the
smaller TEDLIUMv2 and the larger LibriSpeech dataset, achieving consistent
improvements on both of them.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:04:16 GMT""},{""version"":""v2"",""created"":""Wed, 28 Oct 2020 14:00:52 GMT""}]","2020-10-29"
"2006.08507","Maria-Jose Guzman","Alexey Golovnev, Maria-Jose Guzman","Bianchi identities in f(T) gravity: paving the way to confrontation with
  astrophysics","7 pages, no figures, comments welcome; minor changes, references
  added, matches the published version","Phys. Lett. B810, 135806 (2020)","10.1016/j.physletb.2020.135806",,"gr-qc hep-th","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Theories of $f(T)$ gravity are being actively confronted with cosmological
observations, and are being studied for their potential to solve famous
problems of cosmology. A necessary step is to extend these studies to
astrophysical settings. However, to this end one must understand the structure
of spherically symmetric solutions. We show that two different known approaches
to these solutions are actually fully equivalent from the point of view of
Lorentz-covariant formalism. Moreover, we explain Bianchi identities in $f(T)$
gravity and apply them to show that the corresponding equations are always
compatible. It puts these efforts on much firmer grounds than before.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:04:33 GMT""},{""version"":""v2"",""created"":""Sun, 4 Oct 2020 01:20:15 GMT""}]","2020-10-06"
"2006.08508","Tiago Peixoto","Sebastian Morel-Balbi, Tiago P. Peixoto","Null models for multi-optimized large-scale network structures","11 pages, 10 figures","Phys. Rev. E 102, 032306 (2020)","10.1103/PhysRevE.102.032306",,"physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech nlin.AO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study the emerging large-scale structures in networks subject to selective
pressures that simultaneously drive towards higher modularity and robustness
against random failures. We construct maximum-entropy null models that isolate
the effects of the joint optimization on the network structure from any kind of
evolutionary dynamics. Our analysis reveals a rich phase diagram of optimized
structures, composed of many combinations of modular, core-periphery and
bipartite patterns. Furthermore, we observe parameter regions where the
simultaneous optimization can be either synergistic or antagonistic, with the
improvement of one criterion directly aiding or hindering the other,
respectively. Our results show how interactions between different selective
pressures can be pivotal in determining the emerging network structure, and
that these interactions can be captured by simple network models.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:09:15 GMT""}]","2020-09-30"
"2006.08509","Tianzhe Wang","Tianzhe Wang, Kuan Wang, Han Cai, Ji Lin, Zhijian Liu, Song Han","APQ: Joint Search for Network Architecture, Pruning and Quantization
  Policy","Accepted by CVPR 2020",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present APQ for efficient deep learning inference on resource-constrained
hardware. Unlike previous methods that separately search the neural
architecture, pruning policy, and quantization policy, we optimize them in a
joint manner. To deal with the larger design space it brings, a promising
approach is to train a quantization-aware accuracy predictor to quickly get the
accuracy of the quantized model and feed it to the search engine to select the
best fit. However, training this quantization-aware accuracy predictor requires
collecting a large number of quantized <model, accuracy> pairs, which involves
quantization-aware finetuning and thus is highly time-consuming. To tackle this
challenge, we propose to transfer the knowledge from a full-precision (i.e.,
fp32) accuracy predictor to the quantization-aware (i.e., int8) accuracy
predictor, which greatly improves the sample efficiency. Besides, collecting
the dataset for the fp32 accuracy predictor only requires to evaluate neural
networks without any training cost by sampling from a pretrained once-for-all
network, which is highly efficient. Extensive experiments on ImageNet
demonstrate the benefits of our joint optimization approach. With the same
accuracy, APQ reduces the latency/energy by 2x/1.3x over MobileNetV2+HAQ.
Compared to the separate optimization approach (ProxylessNAS+AMC+HAQ), APQ
achieves 2.3% higher ImageNet accuracy while reducing orders of magnitude GPU
hours and CO2 emission, pushing the frontier for green AI that is
environmental-friendly. The code and video are publicly available.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:09:17 GMT""}]","2020-06-16"
"2006.08510","Ingo Martin Deppner","Ingo Deppner, Norbert Herrmann","The FAIR Phase 0 program of the CBM TOF","8 pages, 7 figures, Prepared for submission to JINST",,"10.1088/1748-0221/15/10/C10030",,"physics.ins-det nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to provide particle identification (PID) of charged hadrons at the
future high-rate Compressed Baryonic Matter (CBM) experiment the TOF group has
developed a large-area Time-of-Flight (ToF) wall equipped with Multi-gap
Resistive Plate Chambers (MRPC) capable to operate at incident particle fluxes
of up to 30 kHz/cm$^2$. Prior to its destined operation at the Facility for
Antiproton and Ion Research (FAIR) - starting in 2025 - this high-rate timing
MRPC technology will be used for physics research at two scientific pillars of
the FAIR Phase-0 program: the end-cap TOF upgrade of the STAR experiment at
RHIC and the mTOF wall of the mCBM experiment at SIS18. At STAR, the
fixed-target program of the Beam Energy Scan II (BES-II) will rely on 108 CBM
MRPC detectors for forward PID at trigger rates of up to 2 kHz. At mCBM,
high-performance benchmark runs of Lambda-baryon production at top SIS18
energies and CBM design interaction rates of 10 MHz will become feasible with a
PID backbone consisting of 25 CBM MRPC detectors. Apart from the physics
perspective, these pre-FAIR involvements will help gathering experience in
operating the final CBM TOF wall comprising about 1500 MRPC detectors and
110,000 readout channels. The status of the FAIR phase 0 program will be
discussed.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:11:03 GMT""},{""version"":""v2"",""created"":""Fri, 31 Jul 2020 10:42:18 GMT""}]","2020-12-30"
"2006.08511","Clebson Cruz","Wanisson S. Santana, Clebson Cruz, Elisama Lima and Frederico V.
  Prudente","Evaluating Bohm's quantum force in the scattering process by a classical
  potential",,"Eur. J. Phys. 42 025406 (2021)","10.1088/1361-6404/abc094",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we show an application of the de Broglie-Bohm Quantum Theory of
Motion (QTM) as a powerful tool for evaluating Bohm's quantum force in the
scattering process of a Gaussian wavepacket by a classical Eckart potential.
Our results show that in the absence of a classical potential, the system
experiences quantum effects arising from an effective force, intrinsically
related to the existence of the wavepacket itself. In contrast, in the
scattering by the classical potential, it experiences a quantum force effect
even in the absence of any classical force, reinforcing the fact that
potentials can act without classical force fields. Thus, this application could
be useful to introduce QTM, through the discussion of the concept of Bohm's
quantum force, as a classroom working tool instead of merely an alternative
interpretation of the quantum theory.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:12:39 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 20:47:57 GMT""},{""version"":""v3"",""created"":""Tue, 25 Aug 2020 18:15:02 GMT""}]","2021-02-10"
"2006.08512","Giancarlo Rinaldo","Giancarlo Rinaldo, Francesco Romeo","Hilbert Series of simple thin polyominoes",,,,,"math.AC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let P be a simple thin polyomino, roughly speaking a polyomino that has no
holes and does not contain a square tetromino as a subpolyomino. In this paper,
we determine the reduced Hilbert series $h(t)/(1-t)^d$ of K[P] by proving that
$h(t)$ is the rook polynomial of P. As an application, we characterize the
Gorenstein simple thin polyominoes.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:13:11 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 17:34:58 GMT""}]","2020-06-23"
"2006.08513","Jona Harris","Jona Harris and Aviv Zohar","Flood & Loot: A Systemic Attack On The Lightning Network",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Lightning Network promises to alleviate Bitcoin's known scalability
problems. The operation of such second layer approaches relies on the ability
of participants to turn to the blockchain to claim funds at any time, which is
assumed to happen rarely. One of the risks that was identified early on is that
of a wide systemic attack on the protocol, in which an attacker triggers the
closure of many Lightning channels at once. The resulting high volume of
transactions in the blockchain will not allow for the proper settlement of all
debts, and attackers may get away with stealing some funds. This paper explores
the details of such an attack and evaluates its cost and overall impact on
Bitcoin and the Lightning Network. Specifically, we show that an attacker is
able to simultaneously cause victim nodes to overload the Bitcoin blockchain
with requests and to steal funds that were locked in channels. We go on to
examine the interaction of Lightning nodes with the fee estimation mechanism
and show that the attacker can continuously lower the fee of transactions that
will later be used by the victim in its attempts to recover funds - eventually
reaching a state in which only low fractions of the block are available for
lightning transactions. Our attack is made easier even further as the Lightning
protocol allows the attacker to increase the fee offered by his own
transactions. We continue to empirically show that the vast majority of nodes
agree to channel opening requests from unknown sources and are therefore
susceptible to this attack. We highlight differences between various
implementations of the Lightning Network protocol and review the susceptibility
of each one to the attack. Finally, we propose mitigation strategies to lower
the systemic attack risk of the network.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:16:03 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 15:59:57 GMT""},{""version"":""v3"",""created"":""Mon, 10 Aug 2020 17:01:15 GMT""},{""version"":""v4"",""created"":""Thu, 27 Aug 2020 15:36:03 GMT""}]","2020-08-28"
"2006.08514","Keavin Moore","Keavin Moore, Nicolas B. Cowan","Keeping M-Earths Habitable in the Face of Atmospheric Loss by
  Sequestering Water in the Mantle","10 pages, 4 figures, accepted for publication in MNRAS",,"10.1093/mnras/staa1796",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Water cycling between Earth's mantle and surface has previously been modelled
and extrapolated to rocky exoplanets, but these studies neglected the host
star. M-dwarf stars are more common than Sun-like stars and at least as likely
to host temperate rocky planets (M-Earths). However, M dwarfs are active
throughout their lifetimes; specifically, X-ray and extreme ultraviolet (XUV)
radiation during their early evolution can cause rapid atmospheric loss on
orbiting planets. The increasing bolometric flux reaching M-Earths leads to
warmer, moister upper atmospheres, while XUV radiation can photodissociate
water molecules and drive hydrogen and oxygen escape to space. Here, we present
a coupled model of deep-water cycling and water loss to space on M-Earths to
explore whether these planets can remain habitable despite their volatile
evolution. We use a cycling parameterization accounting for the dependence of
mantle degassing on seafloor pressure, the dependence of regassing on mantle
temperature, and the effect of water on mantle viscosity and thermal evolution.
We assume the M dwarf's XUV radiation decreases exponentially with time, and
energy-limited water loss with 30% efficiency. We explore the effects of
cycling and loss to space on planetary water inventories and water
partitioning. Planet surfaces desiccated by loss can be rehydrated, provided
there is sufficient water sequestered in the mantle to degas once loss rates
diminish at later times. For a given water loss rate, the key parameter is the
mantle overturn timescale at early times: if the mantle overturn timescale is
longer than the loss timescale, then the planet is likely to keep some of its
water.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:16:03 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 18:12:45 GMT""}]","2020-07-01"
"2006.08515","Phillip Durdaut","Phillip Durdaut, Henrik Wolframm, Michael H\""oft","Low-Frequency Magnetic Noise in Statically-Driven Solenoid for Biasing
  Magnetic Field Sensors",,,,,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the generation of static magnetic fields solenoids are frequently used
for the purpose of research and development of magnetic field sensors. When
such a sensor is to be analyzed with regard to its inherent noise the influence
of other noise sources of the measurement system needs to be minimized. This
article reports on the low-frequency magnetic noise within such a coil system.
On the one hand, the impact of the intrinsic noise of the coil itself and on
the other hand the impact of additional current noise of various commercially
available current sources, which accordingly also leads to magnetic noise
within the coil, are investigated. With low-frequency values in the range of a
few tens of $\mathrm{fT}/\sqrt{\mathrm{Hz}}$, the coil's inherent noise is
mostly neglectable. However, frequently utilized current sources for the
generation of a static magnetic bias field lead to significant low-frequency
magnetic flux noise typically in the $\mathrm{nT}/\sqrt{\mathrm{Hz}}$ regime.
It is found that this noise cannot be decreased by increasing the coil's
magnetic sensitivity, i.e. the magnetic flux density as a function of the
static current. Instead, current sources with very high
current-to-current-noise ratios are required.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:16:19 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 10:56:34 GMT""}]","2021-11-01"
"2006.08516","Maurits Silvis","L. B. Streher, M. H. Silvis, P. Cifani, R. W. C. P. Verstappen","Mixed modeling for large-eddy simulation: The single-layer and two-layer
  minimum-dissipation-Bardina models","29 pages, 14 figures, 3 tables; revised, accepted manuscript","AIP Advances 11, 015002 (2021)","10.1063/5.0015293",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Predicting the behavior of turbulent flows using large-eddy simulation
requires modeling of the subgrid-scale stress tensor. This tensor can be
approximated using mixed models, which combine the dissipative nature of
functional models with the capability of structural models to approximate
out-of-equilibrium effects. We propose a mathematical basis to mix (functional)
eddy-viscosity models with the (structural) Bardina model. By taking an
anisotropic minimum-dissipation (AMD) model for the eddy viscosity, we obtain
the (single-layer) AMD-Bardina model. In order to also obtain a
physics-conforming model for wall-bounded flows, we further develop this mixed
model into a two-layer approach: the near-wall region is parameterized with the
AMD-Bardina model, whereas the outer region is computed with the Bardina model.
The single-layer and two-layer AMD-Bardina models are tested in turbulent
channel flows at various Reynolds numbers, and improved predictions are
obtained when the mixed models are applied in comparison to the computations
with the AMD and Bardina models alone. The results obtained with the two-layer
AMD-Bardina model are particularly remarkable: both first- and second-order
statistics are extremely well predicted and even the inflection of the mean
velocity in the channel center is captured. Hence, a very promising model is
obtained for large-eddy simulations of wall-bounded turbulent flows at moderate
and high Reynolds numbers.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:16:23 GMT""},{""version"":""v2"",""created"":""Thu, 7 Jan 2021 21:19:52 GMT""}]","2021-01-11"
"2006.08517","Yang You","Yang You and Yuhui Wang and Huan Zhang and Zhao Zhang and James Demmel
  and Cho-Jui Hsieh","The Limit of the Batch Size",,,,,"cs.LG cs.CV cs.DC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-batch training is an efficient approach for current distributed deep
learning systems. It has enabled researchers to reduce the ImageNet/ResNet-50
training from 29 hours to around 1 minute. In this paper, we focus on studying
the limit of the batch size. We think it may provide a guidance to AI
supercomputer and algorithm designers. We provide detailed numerical
optimization instructions for step-by-step comparison. Moreover, it is
important to understand the generalization and optimization performance of huge
batch training. Hoffer et al. introduced ""ultra-slow diffusion"" theory to
large-batch training. However, our experiments show contradictory results with
the conclusion of Hoffer et al. We provide comprehensive experimental results
and detailed analysis to study the limitations of batch size scaling and
""ultra-slow diffusion"" theory. For the first time we scale the batch size on
ImageNet to at least a magnitude larger than all previous work, and provide
detailed studies on the performance of many state-of-the-art optimization
schemes under this setting. We propose an optimization recipe that is able to
improve the top-1 test accuracy by 18% compared to the baseline.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:18:05 GMT""}]","2020-06-16"
"2006.08518","Nikita Doikov","Nikita Doikov, Yurii Nesterov","Convex optimization based on global lower second-order models",,"Advances in Neural Information Processing Systems 33, 2020",,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present new second-order algorithms for composite convex
optimization, called Contracting-domain Newton methods. These algorithms are
affine-invariant and based on global second-order lower approximation for the
smooth component of the objective. Our approach has an interpretation both as a
second-order generalization of the conditional gradient method, or as a variant
of trust-region scheme. Under the assumption, that the problem domain is
bounded, we prove $\mathcal{O}(1/k^{2})$ global rate of convergence in
functional residual, where $k$ is the iteration counter, minimizing convex
functions with Lipschitz continuous Hessian. This significantly improves the
previously known bound $\mathcal{O}(1/k)$ for this type of algorithms.
Additionally, we propose a stochastic extension of our method, and present
computational results for solving empirical risk minimization problem.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:19:42 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 21:33:34 GMT""}]","2020-12-23"
"2006.08519","Raphael F. Ribeiro","Raphael F. Ribeiro, Jorge A. Campos-Gonzalez-Angulo, Noel C. Giebink,
  Wei Xiong, Joel Yuen-Zhou","Enhanced optical nonlinearities under strong light-matter coupling",,"Phys. Rev. A 103, 063111 (2021)","10.1103/PhysRevA.103.063111",,"physics.chem-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optical microcavities and metallic nanostructures have been shown to
significantly modulate the dynamics and spectroscopic response of molecular
systems. We present a study of the nonlinear optics of a model consisting of
$N$ anharmonic multilevel systems (e.g., Morse oscillators) undergoing
collective strong coupling with a resonant infrared microcavity. We find that,
under experimentally accessible conditions, molecular systems in microcavities
may have nonlinear phenomena significantly intensified due to the high quality
of polariton resonances and the enhanced microcavity electromagnetic energy
density relative to free space. Particularly large enhancement of multiphoton
absorption happens when multipolariton states are resonant with bare molecule
multiphoton transitions. In particular, our model predicts two-photon
absorption cross section enhancements by several orders of magnitude relative
to free space when the Rabi splitting $\Omega_R$ is approximately equal to the
molecular anharmonic shift $2\Delta$. Our results provide rough upper bounds to
resonant nonlinear response enhancement factors as relaxation to dark states is
treated phenomenologically. Notably, ensembles of two-level systems undergoing
strong coupling with a cavity (described by the Tavis-Cummings model) show no
such optical nonlinearity enhancements, highlighting the rich phenomenology
afforded by multilevel anharmonic systems. Similar conclusions are expected to
hold for excitonic systems that share features with our model (e.g., molecular
dyes with accessible S_0 -> S_1 -> S_2 transitions) and strongly interact with
a UV-visible cavity.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:21:58 GMT""}]","2021-06-23"
"2006.08520","Kunyang Li","Kunyang Li, Tamara Bogdanovic, David R. Ballantyne","Pairing of Massive Black Holes in Merger Galaxies Driven by Dynamical
  Friction","Accepted to ApJ, 16 pages, 11 figures","Kunyang Li et al 2020 ApJ 896 113","10.3847/1538-4357/ab93c6",,"astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Motivated by observational searches for massive black hole (MBH) pairs at
kiloparsec separations we develop a semi-analytic model to describe their
orbital evolution under the influence of stellar and gaseous dynamical friction
(DF). The goal of this study is to determine how the properties of the merger
remnant galaxy and the MBHs affect the likelihood and timescale for formation
of a close MBH pair with separation of < 1 pc. We compute approximately 40,000
configurations that cover a wide range of host galaxy properties and
investigate their impact on the orbital evolution of unequal mass MBH pairs. We
find that the percentage for MBH pairing within a Hubble time is larger than
80% in remnant galaxies with a gas fraction < 20% and in galaxies hosting MBH
pairs with total mass > 10^6 solar mass and mass ratios > 1/4. Among these, the
remnant galaxies characterized by the fastest formation of close,
gravitationally bound MBHs have one or more of the following properties: (1)
large stellar bulge, (2) comparable mass MBHs and (3) a galactic gas disk
rotating close to the circular speed. In such galaxies, the MBHs with the
shortest inspiral times, which are likely progenitors of coalescing MBHs, are
either on circular prograde orbits or on very eccentric retrograde orbits. Our
model also indicates that remnant galaxies with opposite properties, that host
slowly evolving MBH pairs, are the most likely hosts of dual AGNs at kiloparsec
separations.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:27:04 GMT""}]","2021-08-05"
"2006.08521","Lukas Stappen","Lukas Stappen, Xinchen Du, Vincent Karas, Stefan M\""uller, Bj\""orn W.
  Schuller","Domain Adaptation with Joint Learning for Generic, Optical Car Part
  Recognition and Detection Systems (Go-CaRD)","Demonstration and instructions to obtain data and models:
  https://github.com/lstappen/GoCarD",,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Systems for the automatic recognition and detection of automotive parts are
crucial in several emerging research areas in the development of intelligent
vehicles. They enable, for example, the detection and modelling of interactions
between human and the vehicle. In this paper, we quantitatively and
qualitatively explore the efficacy of deep learning architectures for the
classification and localisation of 29 interior and exterior vehicle regions on
three novel datasets. Furthermore, we experiment with joint and transfer
learning approaches across datasets and point out potential applications of our
systems. Our best network architecture achieves an F1 score of 93.67 % for
recognition, while our best localisation approach utilising state-of-the-art
backbone networks achieve a mAP of 63.01 % for detection. The MuSe-CAR-Part
dataset, which is based on a large variety of human-car interactions in videos,
the weights of the best models, and the code is publicly available to academic
parties for benchmarking and future research.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:28:53 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 21:23:49 GMT""}]","2021-02-17"
"2006.08522","Ruobin Gong","Ruobin Gong","Transparent Privacy is Principled Privacy",,"Harvard Data Science Review, Special Issue 2, 2022","10.1162/99608f92.b5d3faaa",,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  In a technical treatment, this article establishes the necessity of
transparent privacy for drawing unbiased statistical inference for a wide range
of scientific questions. Transparency is a distinct feature enjoyed by
differential privacy: the probabilistic mechanism with which the data are
privatized can be made public without sabotaging the privacy guarantee.
Uncertainty due to transparent privacy may be conceived as a dynamic and
controllable component from the total survey error perspective. As the 2020
U.S. Decennial Census adopts differential privacy, constraints imposed on the
privatized data products through optimization constitute a threat to
transparency and result in limited statistical usability. Transparent privacy
presents a viable path toward principled inference from privatized data
releases, and shows great promise toward improved reproducibility,
accountability, and public trust in modern data curation.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:30:29 GMT""},{""version"":""v2"",""created"":""Tue, 26 Apr 2022 16:59:44 GMT""},{""version"":""v3"",""created"":""Sun, 18 Sep 2022 18:02:14 GMT""}]","2022-09-20"
"2006.08524","Peter Mell","Peter Mell and Assane Gueye","A Suite of Metrics for Calculating the Most Significant Security
  Relevant Software Flaw Types","6 pages",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Common Weakness Enumeration (CWE) is a prominent list of software
weakness types. This list is used by vulnerability databases to describe the
underlying security flaws within analyzed vulnerabilities. This linkage opens
the possibility of using the analysis of software vulnerabilities to identify
the most significant weaknesses that enable those vulnerabilities. We
accomplish this through creating mashup views combining CWE weakness taxonomies
with vulnerability analysis data. The resulting graphs have CWEs as nodes,
edges derived from multiple CWE taxonomies, and nodes adorned with
vulnerability analysis information (propagated from children to parents). Using
these graphs, we develop a suite of metrics to identify the most significant
weakness types (using the perspectives of frequency, impact, exploitability,
and overall severity).
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:34:05 GMT""}]","2020-06-16"
"2006.08525","Vadim Ohanyan","V. Ohanyan","Influence of $XY$ anisotropy on a magnetoelectric effect in spin-1/2
  $XY$ chain in a transverse magnetic field","11 pages, 6 figures","Condens. Matter Phys., 2020, vol. 23, No. 4, 43704","10.5488/CMP.23.43704",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  A magnetoelectric effect according to Katsura-Nagaosa-Balatsky mechanism in
spin-1/2 $XY$ chain in transverse magnetic field is considered. A spatial
orientation of the electric field is chosen to provide an exact solution of the
model in terms of free spinless fermions. The simplest model of quantum spin
chain demonstrating a magnetoelectric effect, a zero temperature case of the
spin-1/2 $XX$ chain in a transverse magnetic field with
Katsura-Nagaosa-Balatsky mechanism, is considered. The model has the simplest
possible form of the magnetization, polarization and susceptibility functions,
depending on electric and magnetic fields in a most simple form. For the case
of arbitrary $XY$ anisotropy, a non-monotonous dependence of magnetization on
the $XY$ anisotropy parameter is figured out. This non-uniform behaviour is
governed by the critical point which is connected with the possibility to drive
the system gapless or gapped by the electric field. Singularities of the
magnetoelectric susceptibility at the critical value of system parameters are
shown.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:34:33 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jul 2020 20:07:05 GMT""},{""version"":""v3"",""created"":""Mon, 18 Jan 2021 13:11:30 GMT""}]","2021-01-19"
"2006.08526","Zoe Gonzalez Izquierdo","Zoe Gonzalez Izquierdo, Shon Grabbe, Stuart Hadfield, Jeffrey
  Marshall, Zhihui Wang, Eleanor Rieffel","Ferromagnetically shifting the power of pausing","22 pages, 14 figures","Phys. Rev. Applied 15, 044013 (2021)","10.1103/PhysRevApplied.15.044013",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the interplay between quantum annealing parameters in embedded
problems, providing both deeper insights into the physics of these devices and
pragmatic recommendations to improve performance on optimization problems. We
choose as our test case the class of degree-bounded minimum spanning tree
problems. Through runs on a D-Wave quantum annealer, we demonstrate that
pausing in a specific time window in the anneal provides improvement in the
probability of success and in the time-to-solution for these problems. The time
window is consistent across problem instances, and its location is within the
region suggested by prior theory and seen in previous results on native
problems. An approach to enable gauge transformations for problems with the
qubit coupling strength $J$ in an asymmetric range is presented and shown to
significantly improve performance. We also confirm that the optimal pause
location exhibits a shift with the magnitude of the ferromagnetic coupling,
$|J_F|$, between physical qubits representing the same logical one. We extend
the theoretical picture for pausing and thermalization in quantum annealing to
the embedded case. This picture, along with perturbation theory analysis, and
exact numerical results on small problems, confirms that the effective pause
region moves earlier in the anneal as $|J_F|$ increases. It also suggests why
pausing, while still providing significant benefit, has a less pronounced
effect on embedded problems.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:34:34 GMT""}]","2021-04-14"
"2006.08527","Thayer Alshaabi","Thayer Alshaabi, David Rushing Dewhurst, James P. Bagrow, Peter
  Sheridan Dodds, Christopher M. Danforth","The sociospatial factors of death: Analyzing effects of
  geospatially-distributed variables in a Bayesian mortality model for Hong
  Kong","26 pages (15 main, 11 appendix), 22 figures (6 main, 11 appendix), 2
  tables",,"10.1371/journal.pone.0247795",,"physics.soc-ph cs.SI stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human mortality is in part a function of multiple socioeconomic factors that
differ both spatially and temporally. Adjusting for other covariates, the human
lifespan is positively associated with household wealth. However, the extent to
which mortality in a geographical region is a function of socioeconomic factors
in both that region and its neighbors is unclear. There is also little
information on the temporal components of this relationship. Using the
districts of Hong Kong over multiple census years as a case study, we
demonstrate that there are differences in how wealth indicator variables are
associated with longevity in (a) areas that are affluent but neighbored by
socially deprived districts versus (b) wealthy areas surrounded by similarly
wealthy districts. We also show that the inclusion of spatially-distributed
variables reduces uncertainty in mortality rate predictions in each census year
when compared with a baseline model. Our results suggest that geographic
mortality models should incorporate nonlocal information (e.g., spatial
neighbors) to lower the variance of their mortality estimates, and point to a
more in-depth analysis of sociospatial spillover effects on mortality rates.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:35:23 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 13:55:13 GMT""},{""version"":""v3"",""created"":""Mon, 26 Oct 2020 16:23:47 GMT""},{""version"":""v4"",""created"":""Mon, 25 Jan 2021 22:43:59 GMT""}]","2021-02-22"
"2006.08528","Fernando Luis","Fernando Luis (1 and 2), Pablo J. Alonso (1 and 2), Olivier Roubeau (1
  and 2), Ver\'onica Velasco (3), David Zueco (1 and 2 and 4), David Aguila
  (3), Leon\'i A. Barrios (3) and Guillem Arom\'i (3) ((1) Instituto de Ciencia
  de Materiales de Arag\'on (ICMA), CSIC-Universidad de Zaragoza, Zaragoza,
  Spain, (2) Dpto. de F\'isica de la Materia Condensada, Universidad de
  Zaragoza, Zaragoza, Spain, (3) Departament de Qu\'imica Inorganica and IN2UB,
  Universitat de Barcelona, Barcelona, Spain, (4) Fundaci\'on ARAID, Zaragoza,
  Spain)","A dissymmetric [Gd$_{2}$] coordination molecular dimer hosting six
  addressable spin qubits","25 pages, 9 figures, supporting material",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial magnetic molecules are suitable hosts to one or several spin
qubits, which could then implement small-scale algorithms. In order to become
of practical use, such molecular spin processors need to increase the dimension
$d$ of the available computational space and fulfill the highly demanding
conditions that warrant universal operations. Here, we design, synthesize and
fully characterize dissymetric molecular dimers hosting either one or two
Gd(III) ions. The strong sensitivity of Gd(III) magnetic anisotropy to the
symmetry of its local coordination gives rise to different zero-field
splittings at each coordination site. As a result, the [LaGd] and [GdLu]
complexes provide realizations of distinct $d = 8$ spin qudits, whereas the
[Gd$_{2}$] dimer meets all requirements, including a complete set of
operations, to act as a $d = 64$ all-electron spin qudit (or, equivalenty, as
six addressable qubits). Electron paramagnetic resonance experiments show that
the relevant resonant transitions between different spin states can be
coherently controlled, with coherence times T$_{M}$ of the order of $1$ $\mu$s
limited by intramolecular hyperfine interactions. Coordination complexes with
embedded quantum functionalities are promising building blocks for quantum
computation and simulation hybrid platforms.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:35:31 GMT""}]","2020-06-16"
"2006.08529","Egor Illarionov","Egor Illarionov, Alexander Kosovichev, Andrey Tlatov","Machine-learning approach to identification of coronal holes in solar
  disk images and synoptic maps",,,"10.3847/1538-4357/abb94d",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identification of solar coronal holes (CHs) provides information both for
operational space weather forecasting and long-term investigation of solar
activity. Source data for the first problem are typically most recent solar
disk observations, while for the second problem it is convenient to consider
solar synoptic maps. Motivated by the idea that the concept of CHs should be
similar for both cases we investigate universal models that can learn a CHs
segmentation in disk images and reproduce the same segmentation in synoptic
maps. We demonstrate that Convolutional Neural Networks (CNN) trained on daily
disk images provide an accurate CHs segmentation in synoptic maps and their
pole-centric projections. Using this approach we construct a catalog of
synoptic maps for the period of 2010-20 based on SDO/AIA observations in the
193 Angstrom wavelength. The obtained CHs synoptic maps are compared with
magnetic synoptic maps in the time-latitude and time-longitude diagrams. The
initial results demonstrate that while in some cases the CHs are associated
with magnetic flux transport events there are other mechanisms contributing to
the CHs formation and evolution. To stimulate further investigations the
catalog of synoptic maps is published in open access.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:37:20 GMT""},{""version"":""v2"",""created"":""Tue, 22 Sep 2020 14:37:53 GMT""}]","2020-11-18"
"2006.08530","Florent Forest","Alex Mourer, Florent Forest, Mustapha Lebbah, Hanane Azzag and
  J\'er\^ome Lacaille","Selecting the Number of Clusters $K$ with a Stability Trade-off: an
  Internal Validation Criterion","Accepted at PAKDD 2023",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model selection is a major challenge in non-parametric clustering. There is
no universally admitted way to evaluate clustering results for the obvious
reason that no ground truth is available. The difficulty to find a universal
evaluation criterion is a consequence of the ill-defined objective of
clustering. In this perspective, clustering stability has emerged as a natural
and model-agnostic principle: an algorithm should find stable structures in the
data. If data sets are repeatedly sampled from the same underlying
distribution, an algorithm should find similar partitions. However, stability
alone is not well-suited to determine the number of clusters. For instance, it
is unable to detect if the number of clusters is too small. We propose a new
principle: a good clustering should be stable, and within each cluster, there
should exist no stable partition. This principle leads to a novel clustering
validation criterion based on between-cluster and within-cluster stability,
overcoming limitations of previous stability-based methods. We empirically
demonstrate the effectiveness of our criterion to select the number of clusters
and compare it with existing methods. Code is available at
https://github.com/FlorentF9/skstab.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:38:48 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 14:40:46 GMT""},{""version"":""v3"",""created"":""Tue, 16 May 2023 20:28:01 GMT""}]","2023-05-18"
"2006.08531","Kookjin Lee","Kookjin Lee, Howard C. Elman, Catherine E. Powell, Dongeun Lee","Alternating Energy Minimization Methods for Multi-term Matrix Equations",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop computational methods for approximating the solution of a linear
multi-term matrix equation in low rank. We follow an alternating minimization
framework, where the solution is represented as a product of two matrices, and
approximations to each matrix are sought by solving certain minimization
problems repeatedly. The solution methods we present are based on a
rank-adaptive variant of alternating energy minimization methods that builds an
approximation iteratively by successively computing a rank-one solution
component at each step. We also develop efficient procedures to improve the
accuracy of the low-rank approximate solutions computed using these successive
rank-one update techniques. We explore the use of the methods with linear
multi-term matrix equations that arise from stochastic Galerkin finite element
discretizations of parameterized linear elliptic PDEs, and demonstrate their
effectiveness with numerical studies.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:39:04 GMT""}]","2020-06-16"
"2006.08532","Karren Yang","Karren Yang, Samuel Goldman, Wengong Jin, Alex Lu, Regina Barzilay,
  Tommi Jaakkola, Caroline Uhler","Improved Conditional Flow Models for Molecule to Image Synthesis",,,,,"q-bio.BM cs.CV cs.LG eess.IV q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we aim to synthesize cell microscopy images under different
molecular interventions, motivated by practical applications to drug
development. Building on the recent success of graph neural networks for
learning molecular embeddings and flow-based models for image generation, we
propose Mol2Image: a flow-based generative model for molecule to cell image
synthesis. To generate cell features at different resolutions and scale to
high-resolution images, we develop a novel multi-scale flow architecture based
on a Haar wavelet image pyramid. To maximize the mutual information between the
generated images and the molecular interventions, we devise a training strategy
based on contrastive learning. To evaluate our model, we propose a new set of
metrics for biological image generation that are robust, interpretable, and
relevant to practitioners. We show quantitatively that our method learns a
meaningful embedding of the molecular intervention, which is translated into an
image representation reflecting the biological effects of the intervention.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:39:50 GMT""}]","2020-06-16"
"2006.08533","Armin Mehrabian","Armin Mehrabian, Volker J. Sorger, Tarek El-Ghazawi","A Design Methodology for Post-Moore's Law Accelerators: The Case of a
  Photonic Neuromorphic Processor","4 pages, 4 figures",,,,"cs.ET eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the past decade alternative technologies have gained momentum as
conventional digital electronics continue to approach their limitations, due to
the end of Moore's Law and Dennard Scaling. At the same time, we are facing new
application challenges such as those due to the enormous increase in data. The
attention, has therefore, shifted from homogeneous computing to specialized
heterogeneous solutions. As an example, brain-inspired computing has re-emerged
as a viable solution for many applications. Such new processors, however, have
widened the abstraction gamut from device level to applications. Therefore,
efficient abstractions that can provide vertical design-flow tools for such
technologies became critical. Photonics in general, and neuromorphic photonics
in particular, are among the promising alternatives to electronics. While the
arsenal of device level toolbox for photonics, and high-level neural network
platforms are rapidly expanding, there has not been much work to bridge this
gap. Here, we present a design methodology to mitigate this problem by
extending high-level hardware-agnostic neural network design tools with
functional and performance models of photonic components. In this paper we
detail this tool and methodology by using design examples and associated
results. We show that adopting this approach enables designers to efficiently
navigate the design space and devise hardware-aware systems with alternative
technologies.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:39:52 GMT""}]","2020-06-16"
"2006.08534","Bingying Pan","B. Y. Pan, H. C. Xu, Y. Liu, R. Sutarto, F. He, Y. Shen, Y. Q. Hao, J.
  Zhao, Leland Harriger and D. L. Feng","Anomalous helimagnetic domain shrinkage due to the weakening of
  Dzyaloshinskii-Moriya interaction in CrAs",,"Phys. Rev. B 102, 104432 (2020)","10.1103/PhysRevB.102.104432",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  CrAs is a well-known helimagnet with the double-helix structure originating
from the competition between the Dzyaloshinskii-Moriya interaction (DMI) and
antiferromagnetic exchange interaction $J$. By resonant soft X-ray scattering
(RSXS), we observe the magnetic peak (0~0~$q_m$) that emerges at the helical
transition with $T_S$ $\approx$ 267.5 K. Intriguingly, the helimagnetic domains
significantly shrink on cooling below $\sim$255 K, opposite to the conventional
thermal effect. The weakening of DMI on cooling is found to play a critical
role here. It causes the helical wave vector to vary, ordered spins to rotate,
and extra helimagnetic domain boundaries to form at local defects, thus leading
to the anomalous shrinkage of helimagnetic domains. Our results indicate that
the size of magnetic helical domains can be controlled by tuning DMI in certain
helimagnets.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:40:16 GMT""}]","2020-09-30"
"2006.08535","George Lusztig","G. Lusztig","Open problems on Iwahori-Hecke algebras","3 pages; to appear in the European Math.Soc. Newsletter",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We state four open problems on Iwahori-Hecke algebras. The first one states a
relation between some algebras appearing in Solleveld's work and some explicit
Hecke algebras appearing in the study of unipotent representations. The second
one is a boundedness conjecture. The third one is a conjecture of
well-definedness of an asymptotic Hecke algebra. The fourth one concerns
positive conjugacy classes in a Weyl group.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:40:31 GMT""}]","2020-06-16"
"2006.08536","Burak Gerislioglu","Arash Ahmadivand, Burak Gerislioglu, Zeinab Ramezani, Ajeet Kaushik,
  Pandiaraj Manickam, S. Amir Ghoreishi","Femtomolar-level detection of SARS-CoV-2 spike proteins using toroidal
  plasmonic metasensors","21 pages, 5 figures, 1 table",,,,"physics.optics physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Effective and efficient management of human betacoronavirus severe acute
respiratory syndrome (SARS)-CoV-2 infection i.e., COVID-19 pandemic, required
sensitive sensors with short sample-to-result durations for performing
diagnostics. In this direction, one of appropriate alternative approach to
detect SARS-CoV-2 at low level (fmol) is exploring plasmonic metasensor
technology for COVID-19 diagnostics, which offers exquisite opportunities in
advanced healthcare programs, and modern clinical diagnostics. The intrinsic
merits of plasmonic metasensors stem from their capability to squeeze
electromagnetic fields, simultaneously in frequency, time, and space. However,
the detection of low-molecular weight biomolecules at low densities is a
typical drawback of conventional metasensors that has recently been addressed
using toroidal metasurface technology. This research reports fabrication of a
miniaturized plasmonic immunosensor based on toroidal electrodynamics concept
that can sustain robustly confined plasmonic modes with ultranarrow lineshapes
in the terahertz (THz) frequencies. By exciting toroidal dipole mode using our
quasi-infinite metasurface and a judiciously optimized protocol based on
functionalized gold nanoparticles (NPs) conjugated with the specific monoclonal
antibody of SARS-CoV-2 onto the metasurface, the resonance shifts for diverse
concentrations of the spike protein is monitored. Possessing molecular weight
around ~76 kDa allowed us to detect the presence of spike protein with
significantly low LoD ~4.2 fmol.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:41:46 GMT""}]","2020-06-16"
"2006.08537","Pau Vilimelis Aceituno","Pau Vilimelis Aceituno","Resonances induced by Spiking Time Dependent Plasticity","10 pages, 4 figures",,,,"q-bio.NC physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural populations exposed to a certain stimulus learn to represent it
better. However, the process that leads local, self-organized rules to do so is
unclear. We address the question of how can a neural periodic input be learned
and use the Differential Hebbian Learning framework, coupled with a homeostatic
mechanism to derive two self-consistency equations that lead to increased
responses to the same stimulus. Although all our simulations are done with
simple Leaky-Integrate and Fire neurons and standard Spiking Time Dependent
Plasticity learning rules, our results can be easily interpreted in terms of
rates and population codes.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:41:51 GMT""}]","2020-06-16"
"2006.08538","Yan Feng","Yan Feng, Baoyuan Wu, Yanbo Fan, Li Liu, Zhifeng Li, Shutao Xia","Boosting Black-Box Attack with Partially Transferred Conditional
  Adversarial Distribution",,,,,"cs.CR cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work studies black-box adversarial attacks against deep neural networks
(DNNs), where the attacker can only access the query feedback returned by the
attacked DNN model, while other information such as model parameters or the
training datasets are unknown. One promising approach to improve attack
performance is utilizing the adversarial transferability between some white-box
surrogate models and the target model (i.e., the attacked model). However, due
to the possible differences on model architectures and training datasets
between surrogate and target models, dubbed ""surrogate biases"", the
contribution of adversarial transferability to improving the attack performance
may be weakened. To tackle this issue, we innovatively propose a black-box
attack method by developing a novel mechanism of adversarial transferability,
which is robust to the surrogate biases. The general idea is transferring
partial parameters of the conditional adversarial distribution (CAD) of
surrogate models, while learning the untransferred parameters based on queries
to the target model, to keep the flexibility to adjust the CAD of the target
model on any new benign sample. Extensive experiments on benchmark datasets and
attacking against real-world API demonstrate the superior attack performance of
the proposed method.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:45:27 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jul 2020 02:26:36 GMT""},{""version"":""v3"",""created"":""Wed, 18 Nov 2020 06:28:19 GMT""},{""version"":""v4"",""created"":""Thu, 18 Mar 2021 08:56:09 GMT""}]","2021-03-19"
"2006.08539","Chieh T Wu","Chieh Wu, Aria Masoomi, Arthur Gretton, Jennifer Dy","Deep Layer-wise Networks Have Closed-Form Weights","This version will be published in AIStats 2022",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is currently a debate within the neuroscience community over the
likelihood of the brain performing backpropagation (BP). To better mimic the
brain, training a network $\textit{one layer at a time}$ with only a ""single
forward pass"" has been proposed as an alternative to bypass BP; we refer to
these networks as ""layer-wise"" networks. We continue the work on layer-wise
networks by answering two outstanding questions. First, $\textit{do they have a
closed-form solution?}$ Second, $\textit{how do we know when to stop adding
more layers?}$ This work proves that the kernel Mean Embedding is the
closed-form weight that achieves the network global optimum while driving these
networks to converge towards a highly desirable kernel for classification; we
call it the $\textit{Neural Indicator Kernel}$.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:48:03 GMT""},{""version"":""v2"",""created"":""Wed, 4 Nov 2020 18:40:56 GMT""},{""version"":""v3"",""created"":""Wed, 2 Dec 2020 16:38:13 GMT""},{""version"":""v4"",""created"":""Thu, 3 Dec 2020 14:57:29 GMT""},{""version"":""v5"",""created"":""Mon, 7 Feb 2022 17:13:16 GMT""},{""version"":""v6"",""created"":""Wed, 9 Feb 2022 17:42:52 GMT""}]","2022-02-10"
"2006.08540","Nan Li","Nan Li, Christoph Becker, and Simon Dye","The impact of line-of-sight structures on measuring $H_0$ with strong
  lensing time-delays","12 pages, 8 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab984",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measurements of The Hubble-Lemaitre constant from early- and local-universe
observations show a significant discrepancy. In an attempt to understand the
origin of this mismatch, independent techniques to measure H0 are required. One
such technique, strong lensing time delays, is set to become a leading
contender amongst the myriad methods due to forthcoming large strong lens
samples. It is therefore critical to understand the systematic effects inherent
in this method. In this paper, we quantify the influence of additional
structures along the line-of-sight by adopting realistic light cones derived
from the CosmoDC2 semi-analytical extra-galactic catalogue. Using multiple lens
plane ray-tracing to create a set of simulated strong lensing systems, we have
investigated the impact of line-of-sight structures on time-delay measurements
and in turn, on the inferred value of H0. We have also tested the reliability
of existing procedures for correcting for line-of-sight effects. We find that
if the integrated contribution of the line-of-sight structures is close to a
uniform mass sheet, the bias in H0 can be adequately corrected by including a
constant external convergence $\kappa_{ext}$ in the lens model. However, for
realistic line-of-sight structures comprising many galaxies at different
redshifts, this simple correction overestimates the bias by an amount that
depends linearly on the median external convergence. We, therefore, conclude
that lens modelling must incorporate multiple lens planes to account for
line-of-sight structures for accurate and precise inference of H0.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:49:01 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 14:19:06 GMT""},{""version"":""v3"",""created"":""Mon, 12 Apr 2021 02:34:23 GMT""}]","2021-04-21"
"2006.08541","Jonathan Novak","Colin McSwiggen and Jonathan Novak","Majorization and Spherical Functions","16 pages, no figures",,,,"math.RT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Majorization is a partial order on real vectors which plays an important role
in a variety of subjects, ranging from algebra and combinatorics to probability
and statistics. In this paper, we consider a generalized notion of majorization
associated to an arbitrary root system $\Phi,$ and show that it admits a
natural characterization in terms of the values of spherical functions on any
Riemannian symmetric space with restricted root system $\Phi.$
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:52:12 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 02:30:03 GMT""},{""version"":""v3"",""created"":""Wed, 16 Dec 2020 23:47:04 GMT""}]","2020-12-18"
"2006.08542","Jilali Assim J. Assim","Jilali Assim and Saad El Boukhari","On the existence of special elements in odd $K$-theory groups","27 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $k$ be an imaginary quadratic number field, and $F/k$ a finite abelian
extension of Galois group $G$. We investigate the relationship between the
conjectural special elements introduced in \cite{Burns-DeJeu-Gangl} and ETNC in
the semi-simple case. This provides a partial proof of the conjecture for $F/k$
under certain conditions.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:53:55 GMT""}]","2020-06-16"
"2006.08543","Douglas Leith","Douglas J. Leith, Stephen Farrell","Measurement-Based Evaluation Of Google/Apple Exposure Notification API
  For Proximity Detection in a Commuter Bus",,,"10.1371/journal.pone.0239943",,"cs.NI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the results of a measurement study carried out on a commuter bus
in Dublin, Ireland using the Google/Apple Exposure Notification (GAEN) API.
This API is likely to be widely used by Covid-19 contact tracing apps.
Measurements were collected between 60 pairs of handset locations and are
publicly available. We find that the attenuation level reported by the GAEN API
need not increase with distance between handsets, consistent with there being a
complex radio environment inside a bus caused by the metal-rich environment.
Changing the people holding a pair of handsets, with the location of the
handsets otherwise remaining unchanged, can cause variations of +/-10dB in the
attenuation level reported by the GAEN API. Applying the rule used by the Swiss
Covid-19 contact tracing app to trigger an exposure notification to our bus
measurements we find that no exposure notifications would have been triggered
despite the fact that all pairs of handsets were within 2m of one another for
at least 15 mins. Applying an alternative threshold-based exposure notification
rule can somewhat improve performance to a detection rate of 5% when an
exposure duration threshold of 15 minutes is used, increasing to 8% when the
exposure duration threshold is reduced to 10 mins. Stratifying the data by
distance between pairs of handsets indicates that there is only a weak
dependence of detection rate on distance.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:54:33 GMT""}]","2021-01-27"
"2006.08544","Pablo Santos","Pablo Santos-Peral, Alejandra Recio-Blanco, Patrick de Laverny, Emma
  Fern\'andez-Alvar, Christophe Ordenovic","The AMBRE Project: Spectrum normalisation influence on Mg abundances in
  the metal-rich Galactic disc","Accepted for publication in A&A","A&A 639, A140 (2020)","10.1051/0004-6361/202037522",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The abundance of {\alpha}-elements provides an important fossil signature in
Galactic archaeology to trace the chemical evolution of the different disc
populations. High-precision chemical abundances are crucial to improving our
understanding of the chemodynamical properties present in the Galaxy. However,
deriving precise abundance estimations in the metal-rich disc ([M/H] > 0 dex)
is still challenging. The aim of this paper is to analyse different error
sources affecting magnesium abundance estimations from optical spectra of
metal-rich stars. We derived Mg abundances for 87522 high-resolution spectra of
2210 solar neighbourhood stars from the AMBRE Project. For this purpose, the
GAUGUIN automated abundance estimation procedure was employed. The
normalisation procedure has a strong impact on the derived abundances, with a
clear dependence on the stellar type and the line intensity. For non-saturated
lines, the optimal wavelength domain for the local continuum placement should
be evaluated using a goodness-of-fit criterion, allowing mask-size dependence
with the spectral type. Moreover, for strong saturated lines, applying a narrow
normalisation window reduces the parameter-dependent biases of the abundance
estimate, increasing the line-to-line abundance precision. In addition, working
at large spectral resolutions always leads to better results than at lower
ones. The resulting improvement in the abundance precision makes it possible to
observe both a clear thin-thick disc chemical distinction and a decreasing
trend in the magnesium abundance even at supersolar metallicities. In the era
of precise kinematical and dynamical data, optimising the normalisation
procedures implemented for large spectroscopic stellar surveys would provide a
significant improvement to our understanding of the chemodynamical patterns of
Galactic populations.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:59:50 GMT""}]","2020-07-29"
"2006.08545","Andrew Wilson","Polina Kirichenko, Pavel Izmailov, Andrew Gordon Wilson","Why Normalizing Flows Fail to Detect Out-of-Distribution Data","Code is available at https://github.com/PolinaKirichenko/flows_ood",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detecting out-of-distribution (OOD) data is crucial for robust machine
learning systems. Normalizing flows are flexible deep generative models that
often surprisingly fail to distinguish between in- and out-of-distribution
data: a flow trained on pictures of clothing assigns higher likelihood to
handwritten digits. We investigate why normalizing flows perform poorly for OOD
detection. We demonstrate that flows learn local pixel correlations and generic
image-to-latent-space transformations which are not specific to the target
image dataset. We show that by modifying the architecture of flow coupling
layers we can bias the flow towards learning the semantic structure of the
target data, improving OOD detection. Our investigation reveals that properties
that enable flows to generate high-fidelity images can have a detrimental
effect on OOD detection.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:00:01 GMT""}]","2020-06-16"
"2006.08546","Jose Manuel S\'anchez Vel\'azquez","Daniel E. Borrajo Guti\'errez, Jose A. R. Cembranos, Luis J. Garay and
  Jose M. S\'anchez Vel\'azquez","Derivative couplings in gravitational production in the early universe","24 pages, 6 figures",,,,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gravitational particle production in the early universe is due to the
coupling of matter fields to curvature. This coupling may include derivative
terms that modify the kinetic term. The most general first order action
contains derivative couplings to the curvature scalar and to the traceless
Ricci tensor, which can be dominant in the case of (pseudo-)Nambu-Goldstone
bosons or disformal scalars, such as branons. In the presence of these
derivative couplings, the density of produced particles for the adiabatic
regime in the de Sitter phase (which mimics inflation) is constant in time and
decays with the inverse effective mass (which in turn depends on the coupling
to the curvature scalar). In the reheating phase following inflation, the
presence of derivative couplings to the background curvature modifies in a
nontrivial way the gravitational production even in the perturbative regime. We
also show that the two couplings -- to the curvature scalar and to the
traceless Ricci tensor -- are drastically different, specially for large
masses. In this regime, the production becomes highly sensitive to the former
coupling while it becomes independent of the latter.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:03:00 GMT""}]","2020-06-16"
"2006.08547","Nils G\""ahlert","Nils G\""ahlert, Niklas Hanselmann, Uwe Franke, Joachim Denzler","Visibility Guided NMS: Efficient Boosting of Amodal Object Detection in
  Crowded Traffic Scenes","Machine Learning for Autonomous Driving Workshop at the 33rd
  Conference on Neural Information Processing Systems (NeurIPS 2019),
  Vancouver, Canada",,,,"cs.CV cs.LG cs.RO eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Object detection is an important task in environment perception for
autonomous driving. Modern 2D object detection frameworks such as Yolo, SSD or
Faster R-CNN predict multiple bounding boxes per object that are refined using
Non-Maximum-Suppression (NMS) to suppress all but one bounding box. While
object detection itself is fully end-to-end learnable and does not require any
manual parameter selection, standard NMS is parametrized by an overlap
threshold that has to be chosen by hand. In practice, this often leads to an
inability of standard NMS strategies to distinguish different objects in
crowded scenes in the presence of high mutual occlusion, e.g. for parked cars
or crowds of pedestrians. Our novel Visibility Guided NMS (vg-NMS) leverages
both pixel-based as well as amodal object detection paradigms and improves the
detection performance especially for highly occluded objects with little
computational overhead. We evaluate vg-NMS using KITTI, VIPER as well as the
Synscapes dataset and show that it outperforms current state-of-the-art NMS.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:03:23 GMT""}]","2020-06-16"
"2006.08548","Jingjing Bu","Jingjing Bu and Mehran Mesbahi","A Note on Nesterov's Accelerated Method in Nonconvex Optimization: a
  Weak Estimate Sequence Approach",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a variant of accelerated gradient descent algorithms, adapted from
Nesterov's optimal first-order methods, for weakly-quasi-convex and
weakly-quasi-strongly-convex functions. We show that by tweaking the so-called
estimate sequence method, the derived algorithm achieves optimal convergence
rate for weakly-quasi-convex and weakly-quasi-strongly-convex in terms of
oracle complexity. In particular, for a weakly-quasi-convex function with
Lipschitz continuous gradient, we require $O(\frac{1}{\sqrt{\varepsilon}})$
iterations to acquire an $\varepsilon$-solution; for
weakly-quasi-strongly-convex functions, the iteration complexity is $O\left(
\ln\left(\frac{1}{\varepsilon}\right) \right)$. Furthermore, we discuss the
implications of these algorithms for linear quadratic optimal control problem.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:05:08 GMT""}]","2020-06-16"
"2006.08549","Jianhua Pan","Jianhua Pan, Yu-Yen Chen, Liang-Shih Fan","Second Order Unconditional Positive Preserving Schemes for
  Non-equilibrium Reactive Flows with Mass and Mole Balance",,,"10.1016/j.jcp.2021.110477",,"physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, a family of second order process based modified Patankar
Runge-Kutta schemes is proposed with both the mass and mole maintained in
balance while preserving the positivity of density and pressure with the time
step determined by convection terms. The accuracy analysis is conducted to
derive the sufficient and necessary conditions for the Runge-Kutta and Patankar
coefficients. Coupling with the finite volume method, the proposed schemes are
extended to Euler equations with non-equilibrium reacting source terms.
Benchmark tests are given to prove the prior order of accuracy and validate the
positive-preserving property for both density and pressure.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:05:17 GMT""}]","2021-07-07"
"2006.08550","Kenta Oono","Kenta Oono, Taiji Suzuki","Optimization and Generalization Analysis of Transduction through
  Gradient Boosting and Application to Multi-scale Graph Neural Networks","9 pages, Reference 6 pages, Supplemental material 18 pages. Accepted
  at Neural Information Processing Systems (NeurIPS) 2020",,,,"cs.LG math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that the current graph neural networks (GNNs) are difficult to
make themselves deep due to the problem known as over-smoothing. Multi-scale
GNNs are a promising approach for mitigating the over-smoothing problem.
However, there is little explanation of why it works empirically from the
viewpoint of learning theory. In this study, we derive the optimization and
generalization guarantees of transductive learning algorithms that include
multi-scale GNNs. Using the boosting theory, we prove the convergence of the
training error under weak learning-type conditions. By combining it with
generalization gap bounds in terms of transductive Rademacher complexity, we
show that a test error bound of a specific type of multi-scale GNNs that
decreases corresponding to the number of node aggregations under some
conditions. Our results offer theoretical explanations for the effectiveness of
the multi-scale structure against the over-smoothing problem. We apply boosting
algorithms to the training of multi-scale GNNs for real-world node prediction
tasks. We confirm that its performance is comparable to existing GNNs, and the
practical behaviors are consistent with theoretical observations. Code is
available at https://github.com/delta2323/GB-GNN.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:06:17 GMT""},{""version"":""v2"",""created"":""Tue, 20 Oct 2020 06:18:49 GMT""},{""version"":""v3"",""created"":""Wed, 6 Jan 2021 14:17:46 GMT""}]","2021-01-07"
"2006.08551","Ian Heywood","I. Heywood, C. L. Hale, M. J. Jarvis, S. Makhathini, J. A. Peters, M.
  L. L. Sebokolodi and O. M. Smirnov","VLA imaging of the XMM-LSS / VIDEO deep field at 1-2 GHz","13 pages, 8 figures, 3 tables, accepted for publication in MNRAS",,"10.1093/mnras/staa1770",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern radio telescopes are routinely reaching depths where normal
starforming galaxies are the dominant observed population. Realising the
potential of radio as a tracer of star formation and black hole activity over
cosmic time involves achieving such depths over representative volumes, with
radio forming part of a larger multiwavelength campaign. In pursuit of this we
used the Karl G. Jansky Very Large Array (VLA) to image $\sim$5 deg$^{2}$ of
the VIDEO/XMM-LSS extragalactic deep field at 1--2 GHz. We achieve a median
depth of 16 $\mu$Jy beam$^{-1}$ with an angular resolution of 4.5\arcsec.
Comparisons with existing radio observations of XMM-LSS showcase the improved
survey speed of the upgraded VLA: we cover 2.5 times the area and increase the
depth by $\sim$20\% in 40\% of the time. Direction-dependent calibration and
wide-field imaging were required to suppress the error patterns from off-axis
sources of even modest brightness. We derive a catalogue containing 5,762
sources from the final mosaic. Sub-band imaging provides in-band spectral
indices for 3,458 (60\%) sources, with the average spectrum becoming flatter
than the canonical synchrotron slope below 1 mJy. Positional and flux-density
accuracy of the observations, and the differential source counts are in
excellent agreement with those of existing measurements. A public release of
the images and catalogue accompanies this article.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:15:59 GMT""}]","2020-07-01"
"2006.08552","Xuhan Guo","Jinlong Xiang, Zhiyuan Tao, Xuhan Guo, Yong Zhang, Yaotian Zhao, and
  Yikai Su","Universal programmable on-chip metasurface building blocks for arbitrary
  high-order mode manipulation",,,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On-chip mode-division multiplexing (MDM) has been emerging as a promising
technology to further enhance the link capacity and bandwidth of data
communications with multiple mode channels. Both mode converters and mode
exchangers are indispensable fundamental components for flexible mode
operations. While several configurations have been developed previously, it is
still very challenging to efficiently manipulate arbitrary high-order modes in
a versatile way to reduce the R&D and prototyping costs. Here we initiate a
breakthrough with a simple yet universal generic mode operator building block
concept utilizing metasurface structures. The programmable arbitrary high-order
mode operators can realize mode conversion and exchange simultaneously with
competitive and uniform performance, high stability and compact footprints,
offering a quintessential step change for on-chip multimode optical
interconnections.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:16:29 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 15:05:28 GMT""},{""version"":""v3"",""created"":""Fri, 19 Jun 2020 01:05:53 GMT""},{""version"":""v4"",""created"":""Wed, 15 Jul 2020 02:56:42 GMT""}]","2020-07-16"
"2006.08553","Chi Zhang","Chi Zhang, Jennifer Ahern, Mark J. van der Laan, Oleg Sofrygin","tmleCommunity: A R Package Implementing Target Maximum Likelihood
  Estimation for Community-level Data","42 pages",,,,"stat.AP stat.CO","http://creativecommons.org/licenses/by/4.0/","  Over the past years, many applications aim to assess the causal effect of
treatments assigned at the community level, while data are still collected at
the individual level among individuals of the community. In many cases, one
wants to evaluate the effect of a stochastic intervention on the community,
where all communities in the target population receive probabilistically
assigned treatments based on a known specified mechanism (e.g., implementing a
community-level intervention policy that target stochastic changes in the
behavior of a target population of communities). The tmleCommunity package is
recently developed to implement targeted minimum loss-based estimation (TMLE)
of the effect of community-level intervention(s) at a single time point on an
individual-based outcome of interest, including the average causal effect.
Implementations of the inverse-probability-of-treatment-weighting (IPTW) and
the G-computation formula (GCOMP) are also available. The package supports
multivariate arbitrary (i.e., static, dynamic or stochastic) interventions with
a binary or continuous outcome. Besides, it allows user-specified data-adaptive
machine learning algorithms through SuperLearner, sl3 and h2oEnsemble packages.
The usage of the tmleCommunity package, along with a few examples, will be
described in this paper.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:16:40 GMT""}]","2020-06-16"
"2006.08554","Aditya Rajagopal","Aditya Rajagopal, Christos-Savvas Bouganis","Now that I can see, I can improve: Enabling data-driven finetuning of
  CNNs on the edge","Accepted for publication at CVPR2020 workshop - Efficient Deep
  Learning for Computer Vision",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In today's world, a vast amount of data is being generated by edge devices
that can be used as valuable training data to improve the performance of
machine learning algorithms in terms of the achieved accuracy or to reduce the
compute requirements of the model. However, due to user data privacy concerns
as well as storage and communication bandwidth limitations, this data cannot be
moved from the device to the data centre for further improvement of the model
and subsequent deployment. As such there is a need for increased edge
intelligence, where the deployed models can be fine-tuned on the edge, leading
to improved accuracy and/or reducing the model's workload as well as its memory
and power footprint. In the case of Convolutional Neural Networks (CNNs), both
the weights of the network as well as its topology can be tuned to adapt to the
data that it processes. This paper provides a first step towards enabling CNN
finetuning on an edge device based on structured pruning. It explores the
performance gains and costs of doing so and presents an extensible open-source
framework that allows the deployment of such approaches on a wide range of
network architectures and devices. The results show that on average, data-aware
pruning with retraining can provide 10.2pp increased accuracy over a wide range
of subsets, networks and pruning levels with a maximum improvement of 42.0pp
over pruning and retraining in a manner agnostic to the data being processed by
the network.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:16:45 GMT""}]","2020-06-18"
"2006.08555","Stephen McAleer","Stephen McAleer, John Lanier, Roy Fox, Pierre Baldi","Pipeline PSRO: A Scalable Approach for Finding Approximate Nash
  Equilibria in Large Games","SM and JL contributed equally",,,,"cs.GT cs.AI cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding approximate Nash equilibria in zero-sum imperfect-information games
is challenging when the number of information states is large. Policy Space
Response Oracles (PSRO) is a deep reinforcement learning algorithm grounded in
game theory that is guaranteed to converge to an approximate Nash equilibrium.
However, PSRO requires training a reinforcement learning policy at each
iteration, making it too slow for large games. We show through counterexamples
and experiments that DCH and Rectified PSRO, two existing approaches to scaling
up PSRO, fail to converge even in small games. We introduce Pipeline PSRO
(P2SRO), the first scalable general method for finding approximate Nash
equilibria in large zero-sum imperfect-information games. P2SRO is able to
parallelize PSRO with convergence guarantees by maintaining a hierarchical
pipeline of reinforcement learning workers, each training against the policies
generated by lower levels in the hierarchy. We show that unlike existing
methods, P2SRO converges to an approximate Nash equilibrium, and does so faster
as the number of parallel workers increases, across a variety of imperfect
information games. We also introduce an open-source environment for Barrage
Stratego, a variant of Stratego with an approximate game tree complexity of
$10^{50}$. P2SRO is able to achieve state-of-the-art performance on Barrage
Stratego and beats all existing bots. Experiment code is available
athttps://github.com/JBLanier/pipeline-psro.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:17:17 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 19:26:01 GMT""}]","2021-02-22"
"2006.08556","Cl\'ement Dutreix","C. Dutreix, M. Bellec, P. Delplace, F. Mortessagne","Wavefront dislocations reveal the topology of quasi-1D photonic
  insulators",,"Nature Communications 12, 3571 (2021)","10.1038/s41467-021-23790-w",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phase singularities appear ubiquitously in wavefields, regardless of the wave
equation. Such topological defects can lead to wavefront dislocations, as
observed in a humongous number of classical wave experiments. Phase
singularities of wave functions are also at the heart of the topological
classification of the gapped phases of matter. Despite identical singular
features, topological insulators and topological defects in waves remain two
distinct fields. Realising 1D microwave insulators, we experimentally observe a
wavefront dislocation - a 2D phase singularity - in the local density of states
when the systems undergo a topological phase transition. We show theoretically
that the change in the number of interference fringes at the transition reveals
the topological index that characterises the band topology in the insulator.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:17:24 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 06:55:18 GMT""},{""version"":""v3"",""created"":""Tue, 27 Oct 2020 09:37:46 GMT""},{""version"":""v4"",""created"":""Mon, 14 Jun 2021 12:26:02 GMT""}]","2021-06-15"
"2006.08557","Haibin Hang","Haibin Hang, Washington Mio","Correspondence Modules and Persistence Sheaves: A Unifying Perspective
  on One-Parameter Persistent Homology",,,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a unifying framework for the treatment of various persistent
homology architectures using the notion of correspondence modules. In this
formulation, morphisms between vector spaces are given by partial linear
relations, as opposed to linear mappings. In the one-dimensional case, among
other things, this allows us to: (i) treat persistence modules and zigzag
modules as algebraic objects of the same type; (ii) give a categorical
formulation of zigzag structures over a continuous parameter; and (iii)
construct barcodes associated with spaces and mappings that are richer in
geometric information. A structural analysis of one-parameter persistence is
carried out at the level of sections of correspondence modules that yield
sheaf-like structures, termed persistence sheaves. Under some tameness
hypotheses, we prove interval decomposition theorems for persistence sheaves
and correspondence modules, as well as an isometry theorem for persistence
diagrams obtained from interval decompositions. Applications include: (a) a
Mayer-Vietoris sequence that relates the persistent homology of sublevelset
filtrations and superlevelset filtrations to the levelset homology module of a
real-valued function and (b) the construction of slices of 2-parameter
persistence modules along negatively sloped lines.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:21:22 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 02:06:05 GMT""}]","2021-06-01"
"2006.08558","Yaodong Yu","Yaodong Yu, Kwan Ho Ryan Chan, Chong You, Chaobing Song, Yi Ma","Learning Diverse and Discriminative Representations via the Principle of
  Maximal Coding Rate Reduction",,,,,"cs.LG cs.CV cs.IT math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To learn intrinsic low-dimensional structures from high-dimensional data that
most discriminate between classes, we propose the principle of Maximal Coding
Rate Reduction ($\text{MCR}^2$), an information-theoretic measure that
maximizes the coding rate difference between the whole dataset and the sum of
each individual class. We clarify its relationships with most existing
frameworks such as cross-entropy, information bottleneck, information gain,
contractive and contrastive learning, and provide theoretical guarantees for
learning diverse and discriminative features. The coding rate can be accurately
computed from finite samples of degenerate subspace-like distributions and can
learn intrinsic representations in supervised, self-supervised, and
unsupervised settings in a unified manner. Empirically, the representations
learned using this principle alone are significantly more robust to label
corruptions in classification than those using cross-entropy, and can lead to
state-of-the-art results in clustering mixed data from self-learned invariant
features.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:23:55 GMT""}]","2020-06-16"
"2006.08559","Meredith Durbin","M. J. Durbin, R. L. Beaton, J. J. Dalcanton, B. F. Williams, M. L.
  Boyer","MCR-TRGB: A Multiwavelength-Covariant, Robust Tip of the Red Giant
  Branch Measurement Method","32 pages, 21 figures, accepted to ApJ",,"10.3847/1538-4357/ab9cbb",,"astro-ph.GA astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new method to measure colors and magnitudes of the tip of the
red giant branch in multiple bandpasses simultaneously by fitting an
n-dimensional Gaussian to photometry of candidate tip stars. We demonstrate
that this method has several advantages over traditional edge detection,
particularly in regimes where the TRGB magnitude is strongly color-dependent,
as is the case in the near-infrared. We apply this method to a re-reduction of
a set of optical and near-IR HST data originally presented in Dalcanton et al.
(2012). The re-reduction takes advantage of the increased depth and accuracy in
the NIR photometry enabled by simultaneous reduction with higher resolution
optical data in crowded fields (Williams et al. 2014). We compare three
possible absolute calibrations of the resulting apparent TRGB measurements, one
adopting the same distance moduli as in Dalcanton et al. (2012), and two based
on predicted TRGB absolute magnitudes from two widely-used, modern sets of
model isochrones. We find systematic offsets among the model absolute
calibrations at the ~0.1 mag level, in line with previous investigations. The
models also have difficulty reproducing the optical-NIR color-magnitude
behavior of our measurements, making these observations a useful benchmark for
future improvements.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:25:00 GMT""}]","2020-07-29"
"2006.08560","Attila Szolnoki","Attila Szolnoki and Xiaojie Chen","Blocking defector invasion by focusing on the most successful partner","10 pages, 7 figures, accepted for publication in Applied Mathematics
  and Computation","Applied Mathematics and Computation 385(2020) 125430","10.1016/j.amc.2020.125430",,"physics.soc-ph cs.GT nlin.AO q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  According to the standard protocol of spatial public goods game, a cooperator
player invests not only into his own game but also into the games organized by
neighboring partners. In this work, we relax this assumption by allowing
cooperators to decide which neighboring group to prefer instead of supporting
them uniformly. In particular, we assume that they select their most successful
neighbor and focus external investments exclusively into the related group. We
show that this very simple alteration of the dynamical rule results in a
surprisingly positive evolutionary outcome -- cooperators prevail even in harsh
environment represented by small values of the synergy factor in the game. The
microscopic mechanism behind the reported success of the cooperator strategy
can be explained by a blocking mechanism which affects the propagations of
competing strategies in a biased way. Our results, which remain intact by using
different interaction topologies, reveal that it could be beneficial to
concentrate individual efforts to reach a higher global wellbeing.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:27:31 GMT""}]","2020-06-23"
"2006.08561","Sihao Cheng","Sihao Cheng, Yuan-Sen Ting, Brice M\'enard, Joan Bruna","A new approach to observational cosmology using the scattering transform","13 pages, 7 figures; accepted to MNRAS",,"10.1093/mnras/staa3165",,"astro-ph.CO astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parameter estimation with non-Gaussian stochastic fields is a common
challenge in astrophysics and cosmology. In this paper, we advocate performing
this task using the scattering transform, a statistical tool sharing ideas with
convolutional neural networks (CNNs) but requiring no training nor tuning. It
generates a compact set of coefficients, which can be used as robust summary
statistics for non-Gaussian information. It is especially suited for fields
presenting localized structures and hierarchical clustering, such as the
cosmological density field.
  To demonstrate its power, we apply this estimator to a cosmological parameter
inference problem in the context of weak lensing. On simulated convergence maps
with realistic noise, the scattering transform outperforms classic estimators
and is on a par with state-of-the-art CNN. It retains the advantages of
traditional statistical descriptors, has provable stability properties, allows
to check for systematics, and importantly, the scattering coefficients are
interpretable. It is a powerful and attractive estimator for observational
cosmology and the study of physical fields in general.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:28:05 GMT""},{""version"":""v2"",""created"":""Mon, 12 Oct 2020 21:34:08 GMT""}]","2020-10-21"
"2006.08562","Oliver Sch\""afer","Ties Behnke (1), Ralf Diener (1), Ulrich Einhaus (1 and 2), Uwe
  Kr\""amer (1 and 2), Paul Malek (1 and 2), Oliver Sch\""afer (1), Mengqing Wu
  (1) ((1) Deutsches Elektronen-Synchrotron DESY, (2) Universit\""at Hamburg)","Recent Performance Studies of the GEM-based TPC Readout (DESY Module)","15 pages, 12 figures, ""Talk presented at the International Workshop
  on Future Linear Colliders (LCWS2019), Sendai, Japan, 28 October-1 November,
  2019. C19-10-28.""",,,,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  For the International Large Detector (ILD) at the planned International
Linear Collider (ILC) a Time Projection Chamber (TPC) is foreseen as the main
tracking detector. To achieve the required point resolution, Micro-Pattern
Gaseous Detectors (MPGD) will be used in the amplification stage. A readout
module using a stack of three Gas Electron Multipliers (GEM) for gas
amplification was developed at DESY and tested at the DESY II Test Beam
Facility. After introducing the readout module and the infrastructure at the
test beam facility, the performance related to single point and double-hit
resolution of three of these modules is presented. This is followed by results
on the particle identification capabilities of the system, using the specific
energy loss dE/dx, and simulation studies, aimed to investigate and quantify
the impact of high granularity on dE/dx resolution. In addition, a new and
improved TPC field cage and the LYCORIS Large-Area Silicon-Strip Telescope for
the test beam are described. The LYCORIS beam telescope is foreseen to provide
a precise reference of the particle trajectory to validate the momentum
resolution measured with a large TPC prototype. For this purpose, it is being
installed and tested at the test beam facility within the so-called PCMAG
(Persistent Current Magnet).
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:30:24 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 20:07:13 GMT""}]","2020-06-26"
"2006.08563","Wade Hindes","Wade Hindes","Counting points of bounded height in monoid orbits","Main result strengthened to generic sets of rational functions. An
  appendix by Umberto Zannier is included",,,,"math.NT math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a set of endomorphisms on $\mathbb{P}^N$, we establish an upper bound
on the number of points of bounded height in the associated monoid orbits.
Moreover, we give a more refined estimate with an associated lower bound when
the monoid is free. Finally, we show that most sets of rational functions in
one variable satisfy these more refined bounds.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:30:52 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 00:03:03 GMT""}]","2020-07-07"
"2006.08564","Colin White","Yash Savani, Colin White, Naveen Sundar Govindarajulu","Intra-Processing Methods for Debiasing Neural Networks",,"Advances in Neural Information Processing Systems 2020",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As deep learning models become tasked with more and more decisions that
impact human lives, such as criminal recidivism, loan repayment, and face
recognition for law enforcement, bias is becoming a growing concern. Debiasing
algorithms are typically split into three paradigms: pre-processing,
in-processing, and post-processing. However, in computer vision or natural
language applications, it is common to start with a large generic model and
then fine-tune to a specific use-case. Pre- or in-processing methods would
require retraining the entire model from scratch, while post-processing methods
only have black-box access to the model, so they do not leverage the weights of
the trained model. Creating debiasing algorithms specifically for this
fine-tuning use-case has largely been neglected.
  In this work, we initiate the study of a new paradigm in debiasing research,
intra-processing, which sits between in-processing and post-processing methods.
Intra-processing methods are designed specifically to debias large models which
have been trained on a generic dataset and fine-tuned on a more specific task.
We show how to repurpose existing in-processing methods for this use-case, and
we also propose three baseline algorithms: random perturbation, layerwise
optimization, and adversarial fine-tuning. All of our techniques can be used
for all popular group fairness measures such as equalized odds or statistical
parity difference. We evaluate these methods across three popular datasets from
the AIF360 toolkit, as well as on the CelebA faces dataset. Our code is
available at https://github.com/abacusai/intraprocessing_debiasing.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:30:57 GMT""},{""version"":""v2"",""created"":""Mon, 7 Dec 2020 18:04:19 GMT""}]","2022-04-12"
"2006.08565","Kristina Monakhova","Kristina Monakhova, Kyrollos Yanny, Neerja Aggarwal, Laura Waller","Spectral DiffuserCam: lensless snapshot hyperspectral imaging with a
  spectral filter array","10 pages, 10 figures, Optica","Optica 7, 1298-1307 (2020)","10.1364/OPTICA.397214",,"eess.IV cs.CV physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hyperspectral imaging is useful for applications ranging from medical
diagnostics to agricultural crop monitoring; however, traditional scanning
hyperspectral imagers are prohibitively slow and expensive for widespread
adoption. Snapshot techniques exist but are often confined to bulky benchtop
setups or have low spatio-spectral resolution. In this paper, we propose a
novel, compact, and inexpensive computational camera for snapshot hyperspectral
imaging. Our system consists of a tiled spectral filter array placed directly
on the image sensor and a diffuser placed close to the sensor. Each point in
the world maps to a unique pseudorandom pattern on the spectral filter array,
which encodes multiplexed spatio-spectral information. By solving a
sparsity-constrained inverse problem, we recover the hyperspectral volume with
sub-super-pixel resolution. Our hyperspectral imaging framework is flexible and
can be designed with contiguous or non-contiguous spectral filters that can be
chosen for a given application. We provide theory for system design,
demonstrate a prototype device, and present experimental results with high
spatio-spectral resolution.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:31:17 GMT""},{""version"":""v2"",""created"":""Tue, 29 Sep 2020 03:21:47 GMT""}]","2020-09-30"
"2006.08566","Adriana Rodr\'iguez Kamenetzky","A. Rodr\'iguez-Kamenetzky, C. Carrasco-Gonz\'alez, J. M. Torrelles, W.
  H. T. Vlemmings, L. F. Rodr\'iguez, G. Surcis, J. F. G\'omez, J. Cant\'o, C.
  Goddi, J. S. Kim, S. -W. Kim, N. A\~nez-L\'opez, S. Curiel and H. J. van
  Langevelde","Characterizing the radio continuum nature of sources in the massive
  star-forming region W75N (B)","14 pages, 7 figures. Accepted for publication in MNRAS",,"10.1093/mnras/staa1742",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The massive star-forming region W75N~(B) is thought to host a cluster of
massive protostars (VLA~1, VLA~2, and VLA~3) undergoing different evolutionary
stages. In this work, we present radio continuum data with the highest
sensitivity and angular resolution obtained to date in this region, using the
VLA-A and covering a wide range of frequencies (4-48~GHz), which allowed us to
study the morphology and the nature of the emission of the different radio
continuum sources. We also performed complementary studies with multi-epoch VLA
data and ALMA archive data at 1.3 mm wavelength. We find that VLA~1 is driving
a thermal radio jet at scales of $\approx$0.1 arcsec ($\approx$130 au), but
also shows signs of an incipient hyper-compact HII region at scales of
$\lesssim$ 1 arcsec ($\lesssim$ 1300~au). VLA~3 is also driving a thermal radio
jet at scales of a few tenths of arcsec (few hundred of au). We conclude that
this jet is shock-exciting the radio continuum sources Bc and VLA~4 (obscured
HH objects), which show proper motions moving outward from VLA~3 at velocities
of $\approx$112--118~km/s. We have also detected three new weak radio continuum
sources, two of them associated with millimeter continuum cores observed with
ALMA, suggesting that these two sources are also embedded YSOs in this massive
star-forming region.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:31:25 GMT""}]","2020-07-01"
"2006.08567","Alexandre Danilenko","Alexandre I. Danilenko and Mariusz Lema\'nczyk","Ergodic cocycles of IDPFT systems and nonsingular Gaussian actions","Some new references are added",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is proved that each Gaussian cocycle over a mildly mixing Gaussian
transformation is either a Gaussian coboundary or sharply weak mixing. The
class of nonsingular infinite direct products $T$ of transformations $T_n$,
$n\in\Bbb N$, of finite type (IDPFT) is studied. It is shown that if $T_n$ is
mildly mixing, $n\in\Bbb N$, the sequence of the Radon-Nikodym derivatives of
$T_n$ is asymptotically translation quasi-invariant and $T$ is conservative
then the Maharam extension of $T$ is sharply weak mixing. This techniques
provides a new approach to the nonsingular Gaussian transformations studied
recently by Arano, Isono and Marrakchi.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:31:54 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 13:47:17 GMT""}]","2020-06-30"
"2006.08568","Ssu-Hsin Yu","Ssu-Hsin Yu","PrivyTRAC: Privacy and Security Preserving Contact Tracing System","11 pages, 5 figures; submitted to EmergencyComm 2020",,,,"cs.CY cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Smartphone location-based methods have been proposed and implemented as an
effective alternative to traditional labor intensive contact tracing methods.
However, there are serious privacy and security concerns that may impede
wide-spread adoption in many societies. Furthermore, these methods rely solely
on proximity to patients, based on Bluetooth or GPS signal for example,
ignoring lingering effects of virus, including COVID-19, present in the
environment. This results in inaccurate risk assessment and incomplete contact
tracing. A new system concept, called PrivyTRAC, preserves user privacy,
increases security and improves accuracy of smartphone contact tracing.
PrivyTRAC enhances users' and patients' privacy by letting users conduct
self-evaluation based on the risk maps download to their smartphones. No user
information is transmitted to external locations or devices, and no personally
identifiable patient information is embedded in the risk maps as they are
processed anonymized and aggregated locations of confirmed patients. The risk
maps consider both spatial proximity and temporal effects to improve the
accuracy of the infection risk estimation. Experiments conducted in the paper
illustrate improvement of PrivyTRAC over proximity based methods in terms of
true and false positives. An approach to further improve infection risk
estimation by incorporating both positive and negative local test results from
contacts of confirmed cases is also described.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:32:38 GMT""}]","2020-06-16"
"2006.08569","Meng Liu","Meng Liu and David F. Gleich","Strongly local p-norm-cut algorithms for semi-supervised learning and
  local graph clustering","23 pages. Code available at http://github.com/MengLiuPurdue/SLQ",,,,"cs.SI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph based semi-supervised learning is the problem of learning a labeling
function for the graph nodes given a few example nodes, often called seeds,
usually under the assumption that the graph's edges indicate similarity of
labels. This is closely related to the local graph clustering or community
detection problem of finding a cluster or community of nodes around a given
seed. For this problem, we propose a novel generalization of random walk,
diffusion, or smooth function methods in the literature to a convex p-norm cut
function. The need for our p-norm methods is that, in our study of existing
methods, we find those principled methods based on eigenvector, spectral,
random walk, or linear system often have difficulty capturing the correct
boundary of a target label or target cluster. In contrast, 1-norm or
maxflow-mincut based methods capture the boundary, but cannot grow from small
seed set; hybrid procedures that use both have many hard to set parameters. In
this paper, we propose a generalization of the objective function behind these
methods involving p-norms. To solve the p-norm cut problem we give a strongly
local algorithm -- one whose runtime depends on the size of the output rather
than the size of the graph. Our method can be thought as a nonlinear
generalization of the Anderson-Chung-Lang push procedure to approximate a
personalized PageRank vector efficiently. Our procedure is general and can
solve other types of nonlinear objective functions, such as p-norm variants of
Huber losses. We provide a theoretical analysis of finding planted target
clusters with our method and show that the p-norm cut functions improve on the
standard Cheeger inequalities for random walk and spectral methods. Finally, we
demonstrate the speed and accuracy of our new method in synthetic and real
world datasets. Our code is available at http://github.com/MengLiuPurdue/SLQ.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:33:53 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 20:28:38 GMT""}]","2020-10-27"
"2006.08570","Tommaso Di Fonzo","Tommaso Di Fonzo, Daniele Girolimetto","Cross-temporal forecast reconciliation: Optimal combination method and
  heuristic alternatives","Main text: 49 pages, 10 figures, 2 tables. Appendix: 68 pages, 29
  figures, 17 tables",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Forecast reconciliation is a post-forecasting process aimed to improve the
quality of the base forecasts for a system of hierarchical/grouped time series
(Hyndman et al., 2011). Contemporaneous (cross-sectional) and temporal
hierarchies have been considered in the literature, but - except for Kourentzes
and Athanasopoulos (2019) - generally these two features have not been fully
considered together. Adopting a notation able to simultaneously deal with both
forecast reconciliation dimensions, the paper shows two new results: (i) an
iterative cross-temporal forecast reconciliation procedure which extends, and
overcomes some weaknesses of, the two-step procedure by Kourentzes and
Athanasopoulos (2019), and (ii) the closed-form expression of the optimal (in
least squares sense) point forecasts which fulfill both contemporaneous and
temporal constraints. The feasibility of the proposed procedures, along with
first evaluations of their performance as compared to the most performing
`single dimension' (either cross-sectional or temporal) forecast reconciliation
procedures, is studied through a forecasting experiment on the 95 quarterly
time series of the Australian GDP from Income and Expenditure sides considered
by Athanasopoulos et al. (2019).
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:34:05 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 14:15:59 GMT""},{""version"":""v3"",""created"":""Mon, 19 Oct 2020 19:18:51 GMT""}]","2020-10-21"
"2006.08571","Tianlin Xu","Tianlin Xu, Li K. Wenliang, Michael Munn, Beatrice Acciaio","COT-GAN: Generating Sequential Data via Causal Optimal Transport",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce COT-GAN, an adversarial algorithm to train implicit generative
models optimized for producing sequential data. The loss function of this
algorithm is formulated using ideas from Causal Optimal Transport (COT), which
combines classic optimal transport methods with an additional temporal
causality constraint. Remarkably, we find that this causality condition
provides a natural framework to parameterize the cost function that is learned
by the discriminator as a robust (worst-case) distance, and an ideal mechanism
for learning time dependent data distributions. Following Genevay et al.\
(2018), we also include an entropic penalization term which allows for the use
of the Sinkhorn algorithm when computing the optimal transport cost. Our
experiments show effectiveness and stability of COT-GAN when generating both
low- and high-dimensional time series data. The success of the algorithm also
relies on a new, improved version of the Sinkhorn divergence which demonstrates
less bias in learning.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:37:15 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 19:19:38 GMT""}]","2020-10-23"
"2006.08572","Ondrej Bohdal","Ondrej Bohdal, Yongxin Yang, Timothy Hospedales","Flexible Dataset Distillation: Learn Labels Instead of Images","Presented at the 4th Workshop on Meta-Learning (MetaLearn) at NeurIPS
  2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of dataset distillation - creating a small set of
synthetic examples capable of training a good model. In particular, we study
the problem of label distillation - creating synthetic labels for a small set
of real images, and show it to be more effective than the prior image-based
approach to dataset distillation. Methodologically, we introduce a more robust
and flexible meta-learning algorithm for distillation, as well as an effective
first-order strategy based on convex optimization layers. Distilling labels
with our new algorithm leads to improved results over prior image-based
distillation. More importantly, it leads to clear improvements in flexibility
of the distilled dataset in terms of compatibility with off-the-shelf
optimizers and diverse neural architectures. Interestingly, label distillation
can also be applied across datasets, for example enabling learning Japanese
character recognition by training only on synthetically labeled English
letters.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:37:23 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 17:55:36 GMT""},{""version"":""v3"",""created"":""Sat, 12 Dec 2020 12:46:47 GMT""}]","2020-12-15"
"2006.08573","Sheheryar Zaidi","Sheheryar Zaidi, Arber Zela, Thomas Elsken, Chris Holmes, Frank
  Hutter, Yee Whye Teh","Neural Ensemble Search for Uncertainty Estimation and Dataset Shift","Accepted at NeurIPS 2021; earlier version of this work was accepted
  for oral presentation at ICML 2020 Workshop on Uncertainty & Robustness in
  Deep Learning",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ensembles of neural networks achieve superior performance compared to
stand-alone networks in terms of accuracy, uncertainty calibration and
robustness to dataset shift. \emph{Deep ensembles}, a state-of-the-art method
for uncertainty estimation, only ensemble random initializations of a
\emph{fixed} architecture. Instead, we propose two methods for automatically
constructing ensembles with \emph{varying} architectures, which implicitly
trade-off individual architectures' strengths against the ensemble's diversity
and exploit architectural variation as a source of diversity. On a variety of
classification tasks and modern architecture search spaces, we show that the
resulting ensembles outperform deep ensembles not only in terms of accuracy but
also uncertainty calibration and robustness to dataset shift. Our further
analysis and ablation studies provide evidence of higher ensemble diversity due
to architectural variation, resulting in ensembles that can outperform deep
ensembles, even when having weaker average base learners. To foster
reproducibility, our code is available: \url{https://github.com/automl/nes}
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:38:15 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 00:45:28 GMT""},{""version"":""v3"",""created"":""Mon, 21 Feb 2022 19:31:23 GMT""}]","2022-02-23"
"2006.08574","Yilin Wang","Eveliina Peltola, Yilin Wang","Large deviations of multichordal SLE$_{0+}$, real rational functions,
  and zeta-regularized determinants of Laplacians","67 pages, 4 figures. Final version to appear in JEMS",,,,"math-ph math.CV math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a strong large deviation principle (LDP) for multiple chordal
SLE$_{0+}$ curves with respect to the Hausdorff metric. In the single-chord
case, this result strengthens an earlier partial result by the second author.
We also introduce a Loewner potential, which in the smooth case has a simple
expression in terms of zeta-regularized determinants of Laplacians. This
potential differs from the LDP rate function by an additive constant depending
only on the boundary data, that satisfies PDEs arising as a semiclassical limit
of the Belavin-Polyakov-Zamolodchikov equations of level two in conformal field
theory with central charge $c \to -\infty$.
  Furthermore, we show that every multichord minimizing the potential in the
upper half-plane for given boundary data is the real locus of a rational
function and is unique, thus coinciding with the $\kappa \to 0+$ limit of the
multiple SLE$_\kappa$. As a by-product, we provide an analytic proof of the
Shapiro conjecture in real enumerative geometry, first proved by Eremenko and
Gabrielov: if all critical points of a rational function are real, then the
function is real up to post-composition by a M\""obius transformation.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:38:41 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 17:17:10 GMT""},{""version"":""v3"",""created"":""Mon, 20 Dec 2021 18:59:11 GMT""},{""version"":""v4"",""created"":""Sat, 18 Mar 2023 16:26:41 GMT""}]","2023-03-21"
"2006.08575","Nicholas Boffi","Nicholas M. Boffi, Stephen Tu, and Jean-Jacques E. Slotine","The role of optimization geometry in single neuron learning","AISTATS 2022. Minor cosmetic edits to camera-ready",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent numerical experiments have demonstrated that the choice of
optimization geometry used during training can impact generalization
performance when learning expressive nonlinear model classes such as deep
neural networks. These observations have important implications for modern deep
learning but remain poorly understood due to the difficulty of the associated
nonconvex optimization problem. Towards an understanding of this phenomenon, we
analyze a family of pseudogradient methods for learning generalized linear
models under the square loss - a simplified problem containing both
nonlinearity in the model parameters and nonconvexity of the optimization which
admits a single neuron as a special case. We prove non-asymptotic bounds on the
generalization error that sharply characterize how the interplay between the
optimization geometry and the feature space geometry sets the out-of-sample
performance of the learned model. Experimentally, selecting the optimization
geometry as suggested by our theory leads to improved performance in
generalized linear model estimation problems such as nonlinear and nonconvex
variants of sparse vector recovery and low-rank matrix sensing.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:39:44 GMT""},{""version"":""v2"",""created"":""Wed, 26 Aug 2020 17:18:18 GMT""},{""version"":""v3"",""created"":""Tue, 16 Feb 2021 18:03:36 GMT""},{""version"":""v4"",""created"":""Fri, 22 Apr 2022 00:53:38 GMT""}]","2022-04-25"
"2006.08576","Auriane Egal","A. Egal, P. G. Brown, J. Rendtel, M. Campbell-Brown and P. Wiegert","Activity of the Eta-Aquariid and Orionid meteor showers","Accepted for publication in Astronomy & Astrophysics (date of
  acceptance: 10/06/2020)","A&A 640, A58 (2020)","10.1051/0004-6361/202038115",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a multi-instrumental, multidecadal analysis of the activity of the
Eta-Aquariid and Orionid meteor showers for the purpose of constraining models
of 1P/Halley's meteoroid streams. The interannual variability of the showers'
peak activity and period of duration is investigated through the compilation of
published visual and radar observations prior to 1985 and more recent
measurements reported in the International Meteor Organization (IMO) Visual
Meteor DataBase, by the IMO Video Meteor Network and by the Canadian Meteor
Orbit Radar (CMOR). These techniques probe the range of meteoroid masses from
submilligrams to grams. The Eta-Aquariids and Orionids activity duration,
shape, maximum zenithal hourly rates (ZHR) values, and the solar longitude of
annual peaks since 1985 are analyzed. When available, annual activity profiles
recorded by each detection network were measured and are compared. Observations
from the three detection methods show generally good agreement in the showers'
shape, activity levels, and annual intensity variations. Both showers display
several activity peaks of variable location and strength with time. The
Eta-Aquariids are usually two to three times stronger than the Orionids, but
the two showers display occasional outbursts with peaks two to four times their
usual activity level. CMOR observations since 2002 seem to support the
existence of an ~12 year cycle in Orionids activity variations; however,
additional and longer term radar and optical observations of the shower are
required to confirm such periodicity.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:40:01 GMT""}]","2020-08-19"
"2006.08577","Frederik Skovbo M{\o}ller","Frederik M{\o}ller, Chen Li, Igor Mazets, Hans-Peter Stimming, Tianwei
  Zhou, Zijie Zhu, Xuzong Chen, J\""org Schmiedmayer","Extension of the Generalized Hydrodynamics to the Dimensional Crossover
  Regime","23 pages, 13 figures","Phys. Rev. Lett. 126, 090602 (2021)","10.1103/PhysRevLett.126.090602",,"cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  In an effort to address integrability breaking in cold gas experiments, we
extend the integrable hydrodynamics of the 1d Lieb-Liniger model with two
additional components representing the population of atoms in the first and
second transverse excited states, thus enabling a description of quasi-1d
condensates. Collisions between different components are accounted for through
the inclusion of a Boltzmann-type collision integral in the hydrodynamic
equation. Contrary to standard generalized hydrodynamics, our extended model
captures thermalization of the condensate at a rate consistent with
experimental observations from a quantum Newton's cradle setup.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:41:00 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 15:39:54 GMT""},{""version"":""v3"",""created"":""Fri, 19 Feb 2021 11:34:26 GMT""}]","2021-03-10"
"2006.08578","Christoph Aistleitner","Christoph Aistleitner and Bence Borda","Quantum invariants of hyperbolic knots and extreme values of
  trigonometric products","Version 1: 24 pages. Version 2: Improved error estimate in Theorem 1
  as a consequence of the new Theorem 4. Several other minor modifications. 30
  pages",,,,"math.NT math-ph math.GN math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the relation between the function $J_{4_1,0}$, which
arises from a quantum invariant of the figure-eight knot, and Sudler's
trigonometric product. We find $J_{4_1,0}$ up to a constant factor along
continued fraction convergents to a quadratic irrational, and we show that its
asymptotics deviates from the universal limiting behavior that has been found
by Bettin and Drappeau in the case of large partial quotients. We relate the
value of $J_{4_1,0}$ to that of Sudler's trigonometric product, and establish
asymptotic upper and lower bounds for such Sudler products in response to a
question of Lubinsky.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:42:01 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 11:08:00 GMT""}]","2021-07-05"
"2006.08579","Jorge G. Hirsch","A. Carranza M., S. Pittel, Jorge G. Hirsch","Influence of pairing and deformation on charge exchange transitions","Review article, 16 figures, 180 references. Comments are welcome
  (also missing references)",,,,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the importance of charge-exchange reactions, and in particular
Gamow-Teller transitions, in astrophysical processes and double beta decay, and
in understanding of nuclear structure. We first provide an overview of the
central role played by the isovector pairing and the quadrupole-quadrupole
channels in the description of energy spectra and in the manifestation of
collective modes, some associated with deformation of the nuclear shape. We
then turned our focus to Gamow-Teller (GT) transitions in relatively light
nuclei, especially in the 2p1f shell, where isoscalar pairing may be playing a
role in competition with the isovector pairing that dominates in heavier
regions. Following a summary of the progress made in recent years on this
subject, we report a systematic shell model study aimed at providing further
clarification as to how these pairing modes compete. In this study, we use a
schematic Hamiltonian that contains a quadrupole-quadrupole interaction as well
as both isoscalar and isovector pairing interactions. We first find an optimal
set of Hamiltonian parameters for the model, to provide a starting point from
which to vary the relevant pairing strengths and thus assess how this impacts
the behavior of GT transitions and the corresponding energy spectra and
rotational properties of the various nuclei involved in the decays. The
analysis includes as an important theme a comparison with experimental data.
The need to suppress the isoscalar pairing mode when treating nuclei with a
neutron excess to avoid producing spurious results for the ground state spin
and parity with the simplified Hamiltonian is highlighted. Varying the strength
parameters for the two pairing modes is found to exhibit different but
systematic effects on GT transition properties and on the corresponding energy
spectra, which are detailed. (abridged)
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:44:05 GMT""}]","2020-06-16"
"2006.08580","Changxiao Cai","Changxiao Cai, H. Vincent Poor, Yuxin Chen","Uncertainty quantification for nonconvex tensor completion: Confidence
  intervals, heteroscedasticity and optimality","Accepted in part to ICML 2020","IEEE Transactions on Information Theory, vol. 69, no. 1, pp.
  407-452, Jan. 2023",,,"stat.ML cs.IT cs.LG math.IT math.OC math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the distribution and uncertainty of nonconvex optimization for noisy
tensor completion -- the problem of estimating a low-rank tensor given
incomplete and corrupted observations of its entries. Focusing on a two-stage
estimation algorithm proposed by Cai et al. (2019), we characterize the
distribution of this nonconvex estimator down to fine scales. This
distributional theory in turn allows one to construct valid and short
confidence intervals for both the unseen tensor entries and the unknown tensor
factors. The proposed inferential procedure enjoys several important features:
(1) it is fully adaptive to noise heteroscedasticity, and (2) it is data-driven
and automatically adapts to unknown noise distributions. Furthermore, our
findings unveil the statistical optimality of nonconvex tensor completion: it
attains un-improvable $\ell_{2}$ accuracy -- including both the rates and the
pre-constants -- when estimating both the unknown tensor and the underlying
tensor factors.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:47:13 GMT""}]","2023-01-18"
"2006.08581","Yunhe Feng","Yunhe Feng and Wenjun Zhou","Is Working From Home The New Norm? An Observational Study Based on a
  Large Geo-tagged COVID-19 Twitter Dataset",,"Information processing & management 59.2 (2022): 102820","10.1016/j.ipm.2021.102820",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the COVID-19 pandemic swept over the world, people discussed facts,
expressed opinions, and shared sentiments on social media. Since the reaction
to COVID-19 in different locations may be tied to local cases, government
regulations, healthcare resources and socioeconomic factors, we curated a large
geo-tagged Twitter dataset and performed exploratory analysis by location.
Specifically, we collected 650,563 unique geo-tagged tweets across the United
States (50 states and Washington, D.C.) covering the date range from January 25
to May 10, 2020. Tweet locations enabled us to conduct region-specific studies
such as tweeting volumes and sentiment, sometimes in response to local
regulations and reported COVID-19 cases. During this period, many people
started working from home. The gap between workdays and weekends in hourly
tweet volumes inspired us to propose algorithms to estimate work engagement
during the COVID-19 crisis. This paper also summarizes themes and topics of
tweets in our dataset using both social media exclusive tools (i.e., #hashtags,
@mentions) and the latent Dirichlet allocation model. We welcome requests for
data sharing and conversations for more insights.
  Dataset link: http://covid19research.site/geo-tagged_twitter_datasets/
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:48:37 GMT""}]","2022-01-07"
"2006.08582","Anton Shchechkin","A. Shchechkin","Blowup relations on $\mathbb{C}^2/\mathbb{Z}_2$ from Nakajima-Yoshioka
  blowup relations","16 pages, 1 figure",,,,"math-ph hep-th math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain bilinear relations on Nekrasov partition functions, arising from
study of tau functions of quantum $q$-Painlev\'e equations, from
Nakajima-Yoshioka blowup relations by an elementary algebraic approach.
  Additionaly, using this approach, we prove certain relations on Nekrasov
partition functions, modified by Chern-Simons term.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:49:11 GMT""}]","2020-06-16"
"2006.08583","Fabrizio Di Giovanni","Fabrizio Di Giovanni, Saeed Fakhry, Nicolas Sanchis-Gual, Juan Carlos
  Degollado, Jos\'e A. Font","Dynamical formation and stability of fermion-boson stars","13 pages, 16 figures","Phys. Rev. D 102, 084063 (2020)","10.1103/PhysRevD.102.084063",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gravitationally bound structures composed by fermions and scalar particles
known as fermion-boson stars are regular and static configurations obtained by
solving the coupled Einstein-Klein-Gordon-Euler (EKGE) system. In this work, we
discuss one possible scenario through which these fermion-boson stars may form
by solving numerically the EKGE system under the simplifying assumption of
spherical symmetry. Our initial configurations assume an already existing
neutron star surrounded by an accreting cloud of a massive and complex scalar
field. The results of our simulations show that once part of the initial scalar
field is expelled via gravitational cooling the system gradually oscillates
around an equilibrium configuration that is asymptotically consistent with a
static solution of the system. The formation of fermion-boson stars for large
positive values of the coupling constant in the self-interaction term of the
scalar-field potential reveal the presence of a node in the scalar field. This
suggests that a fermionic core may help stabilize configurations with nodes in
the bosonic sector, as happens for purely boson stars in which the ground state
and the first excited state coexist.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:49:17 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 07:31:56 GMT""}]","2020-11-04"
"2006.08584","Tomasz Kowalczyk","Juliusz Banecki, Tomasz Kowalczyk","Sums of even powers of k-regulous functions","Final version, to appear in Indagationes Mathmaticae",,"10.1016/j.indag.2022.12.004",,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide an example of a nonnegative $k$-regulous function on
$\mathbb{R}^n$ for $k\geq 1$ and $n \geq 2$ which cannot be written as a sum of
squares of $k$-regulous functions. We then obtain lower bounds for Pythagoras
numbers $p_{2d}(\mathcal{R}^k(\mathbb{R}^n))$ of $k$-regulous functions on
$\mathbb{R}^n$ for $k\geq 1$ and $n\geq 2$. We also prove that the second
Pythagoras number of the ring of $0$-regulous functions $\mathcal{R}^0(X)$ on
an irreducible $0$-regulous affine variety $X$ is finite and bounded from above
by $2^{\dim X}$.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:51:14 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jul 2020 14:28:05 GMT""},{""version"":""v3"",""created"":""Sun, 7 Feb 2021 09:20:09 GMT""},{""version"":""v4"",""created"":""Sun, 16 Jan 2022 14:23:22 GMT""},{""version"":""v5"",""created"":""Thu, 7 Apr 2022 16:09:32 GMT""},{""version"":""v6"",""created"":""Thu, 15 Dec 2022 11:38:25 GMT""}]","2022-12-16"
"2006.08585","Wei-Chi Chiu","Wei-Chi Chiu, Bahadur Singh, Sougata Mardanya, Johannes Nokelainen,
  Amit Agarwal, Hsin Lin, Christopher Lane, Katariina Pussi, Bernardo
  Barbiellini and Arun Bansil","Topological Dirac Semimetal Phase in Bismuth Based Anode Materials for
  Sodium-Ion Batteries",,"Condens. Matter 2020, 5(2), 39","10.3390/condmat5020039",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bismuth has recently attracted interest in connection with Na-ion battery
anodes due to its high volumetric capacity. It reacts with Na to form Na$_3$Bi
which is a prototypical Dirac semimetal with a nontrivial electronic structure.
Density-functional-theory based first-principles calculations are playing a key
role in understanding the fascinating electronic structure of Na$_3$Bi and
other topological materials. In particular, the
strongly-constrained-and-appropriately-normed (SCAN)
meta-generalized-gradient-approximation (meta-GGA) has shown significant
improvement over the widely used generalized-gradient-approximation (GGA)
scheme in capturing energetic, structural, and electronic properties of many
classes of materials. Here, we discuss the electronic structure of Na$_3$Bi
within the SCAN framework and show that the resulting Fermi velocities and {\it
s}-band shift around the $\Gamma$ point are in better agreement with
experiments than the corresponding GGA predictions. SCAN yields a purely
spin-orbit-coupling (SOC) driven Dirac semimetal state in Na$_3$Bi in contrast
with the earlier GGA results. Our analysis reveals the presence of a
topological phase transition from the Dirac semimetal to a trivial band
insulator phase in Na$_{3}$Bi$_{x}$Sb$_{1-x}$ alloys as the strength of the SOC
varies with Sb content, and gives insight into the role of the SOC in
modulating conduction properties of Na$_3$Bi.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:51:33 GMT""}]","2020-06-16"
"2006.08586","Wen Jiang","Wen Jiang, Nikos Kolotouros, Georgios Pavlakos, Xiaowei Zhou, Kostas
  Daniilidis","Coherent Reconstruction of Multiple Humans from a Single Image","CVPR 2020. Project Page: https://jiangwenpl.github.io/multiperson/",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we address the problem of multi-person 3D pose estimation from
a single image. A typical regression approach in the top-down setting of this
problem would first detect all humans and then reconstruct each one of them
independently. However, this type of prediction suffers from incoherent
results, e.g., interpenetration and inconsistent depth ordering between the
people in the scene. Our goal is to train a single network that learns to avoid
these problems and generate a coherent 3D reconstruction of all the humans in
the scene. To this end, a key design choice is the incorporation of the SMPL
parametric body model in our top-down framework, which enables the use of two
novel losses. First, a distance field-based collision loss penalizes
interpenetration among the reconstructed people. Second, a depth ordering-aware
loss reasons about occlusions and promotes a depth ordering of people that
leads to a rendering which is consistent with the annotated instance
segmentation. This provides depth supervision signals to the network, even if
the image has no explicit 3D annotations. The experiments show that our
approach outperforms previous methods on standard 3D pose benchmarks, while our
proposed losses enable more coherent reconstruction in natural images. The
project website with videos, results, and code can be found at:
https://jiangwenpl.github.io/multiperson
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:51:45 GMT""}]","2020-06-16"
"2006.08587","Ebru Toprak Dr.","Michael K.-H. Kiessling, A. Shadi Tahvildar-Zadeh, Ebru Toprak","On general-relativistic hydrogen and hydrogenic ions","corrected version, to appear in J. Math. Phys","J. Math. Phys. vol.61, art.092303, 22pp (2020)","10.1063/5.0018569",,"math-ph gr-qc math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies how the static non-linear electromagnetic-vacuum spacetime
of a point nucleus with negative bare mass affects the self-adjointness of the
general-relativistic Dirac Hamiltonian for a test electron, without and with an
anomalous magnetic moment.
  The study interpolates between the previously studied extreme cases of a test
electron in (a) the Reissner--Weyl--Nordstr\""om spacetime (Maxwell's
electromagnetic vacuum), which supports a very strong curvature singularity
with negative infinite bare mass, and (b) the Hoffmann spacetime (Born or
Born--Infeld's electromagnetic vacuum) with vanishing bare mass, which features
the mildest possible curvature singularity.
  The main conclusion reached is: {on electrostatic spacetimes of a point
nucleus with a strictly negative bare mass} (which may be $-\infty$) essential
self-adjointness fails unless the radial electric field diverges sufficiently
fast at the nucleus and the anomalous magnetic moment of the electron is taken
into account.
  Thus on the Hoffmann spacetime with (strictly) negative bare mass the Dirac
Hamiltonian of a test electron, with or without anomalous magnetic moment, is
not essentially self-adjoint.
  All these operators have self-adjoint extensions, though, with the usual
essential spectrum $(-\infty,-\mEL c^2]\cup[\mEL c^2,\infty)$ and an infinite
discrete spectrum located in the gap $(-\mEL c^2,\mEL c^2)$
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:51:59 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 16:10:33 GMT""},{""version"":""v3"",""created"":""Sat, 29 Aug 2020 21:56:49 GMT""}]","2020-12-02"
"2006.08588","Kevin OMeara","John Holbrook and Kevin C. O'Meara","A computing strategy and programs to resolve the Gerstenhaber Problem
  for commuting triples of matrices",,,,,"math.AC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a MATLAB program that could produce a negative answer to the
Gerstenhaber Problem by the construction of three commuting $n \times n$
matrices $A,B,C$ over a field $F$ such that the subalgebra $F[A,B,C]$ they
generate has dimension greater than $n$. This problem has remained open for
nearly 60 years, following Gerstenhaber's surprising result (Annals Math.) that
$\dim F[A,B] \le n$ for any two commuting matrices $A,B$. The property fails
for four or more commuting matrices. We also make the MATLAB files freely
available.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:53:21 GMT""}]","2020-06-16"
"2006.08589","Jeremy Leipzig","Jeremy Leipzig, Daniel N\""ust, Charles Tapley Hoyt, Stian
  Soiland-Reyes, Karthik Ram, Jane Greenberg","The role of metadata in reproducible computational research","53 pages, 18 figures, 2 tables, 216 references",,,,"cs.DL cs.SE","http://creativecommons.org/licenses/by/4.0/","  Reproducible computational research (RCR) is the keystone of the scientific
method for in silico analyses, packaging the transformation of raw data to
published results. In addition to its role in research integrity, RCR has the
capacity to significantly accelerate evaluation and reuse. This potential and
wide-support for the FAIR principles have motivated interest in metadata
standards supporting RCR. Metadata provides context and provenance to raw data
and methods and is essential to both discovery and validation. Despite this
shared connection with scientific data, few studies have explicitly described
the relationship between metadata and RCR. This article employs a functional
content analysis to identify metadata standards that support RCR functions
across an analytic stack consisting of input data, tools, notebooks, pipelines,
and publications. Our article provides background context, explores gaps, and
discovers component trends of embeddedness and methodology weight from which we
derive recommendations for future work.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:53:21 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 12:37:25 GMT""}]","2021-04-20"
"2006.08590","Thomas Davison Mr","Thomas A. Davison, Mark A. Norris, Joel L. Pfeffer, Jonathan J.
  Davies, Robert A. Crain","An EAGLE's View of Ex-situ Galaxy Growth","16 pages, 11 figures. Accepted for publication in MNRAS",,"10.1093/mnras/staa1816",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern observational and analytic techniques now enable the direct
measurement of star formation histories and the inference of galaxy assembly
histories. However, current theoretical predictions of assembly are not ideally
suited for direct comparison with such observational data. We therefore extend
the work of prior examinations of the contribution of ex-situ stars to the
stellar mass budget of simulated galaxies. Our predictions are specifically
tailored for direct testing with a new generation of observational techniques
by calculating ex-situ fractions as functions of galaxy mass and morphological
type, for a range of surface brightnesses. These enable comparison with results
from large FoV IFU spectrographs, and increasingly accurate spectral fitting,
providing a look-up method for the estimated accreted fraction. We furthermore
provide predictions of ex-situ mass fractions as functions of galaxy mass,
galactocentric radius and environment. Using $z=0$ snapshots from the
100cMpc$^3$ and 25cMpc$^3$ EAGLE simulations we corroborate the findings of
prior studies, finding that ex-situ fraction increases with stellar mass for
central and satellite galaxies in a stellar mass range of 2$\times$10$^{7}$ -
1.9$\times$10$^{12}$ M$_{\odot}$. For those galaxies of mass
M$_*$>5$\times$10$^{8}$M$_{\odot}$, we find that the total ex-situ mass
fraction is greater for more extended galaxies at fixed mass. When categorising
satellite galaxies by their parent group/cluster halo mass we find that the
ex-situ fraction decreases with increasing parent halo mass at fixed galaxy
mass. This apparently counter-intuitive result may be the result of high
passing velocities within large cluster halos inhibiting efficient accretion
onto individual galaxies.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:54:32 GMT""}]","2020-07-01"
"2006.08591","Ezra Winston","Ezra Winston, J. Zico Kolter","Monotone operator equilibrium networks","NeurIPS 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Implicit-depth models such as Deep Equilibrium Networks have recently been
shown to match or exceed the performance of traditional deep networks while
being much more memory efficient. However, these models suffer from unstable
convergence to a solution and lack guarantees that a solution exists. On the
other hand, Neural ODEs, another class of implicit-depth models, do guarantee
existence of a unique solution but perform poorly compared with traditional
networks. In this paper, we develop a new class of implicit-depth model based
on the theory of monotone operators, the Monotone Operator Equilibrium Network
(monDEQ). We show the close connection between finding the equilibrium point of
an implicit network and solving a form of monotone operator splitting problem,
which admits efficient solvers with guaranteed, stable convergence. We then
develop a parameterization of the network which ensures that all operators
remain monotone, which guarantees the existence of a unique equilibrium point.
Finally, we show how to instantiate several versions of these models, and
implement the resulting iterative solvers, for structured linear operators such
as multi-scale convolutions. The resulting models vastly outperform the Neural
ODE-based models while also being more computationally efficient. Code is
available at http://github.com/locuslab/monotone_op_net.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:57:31 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 22:39:35 GMT""}]","2021-05-05"
"2006.08592","Alexandros Gezerlis","Alexandros Gezerlis, Martin Williams","Six textbook mistakes in computational physics","14 pages, 5 figures; v2 corresponds to published version","Am. J. Phys. 89, 51 (2021)","10.1119/10.0001945",,"physics.ed-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article discusses several erroneous claims which appear in textbooks on
numerical methods and computational physics. These are not typos or mistakes an
individual author has made, but widespread misconceptions. In an attempt to
stop these issues from further propagating, we discuss them here, along with
some background comments. In each case, we also provide a correction, which is
aimed at summarizing material that is known to experts but is frequently
mishandled in the introductory literature. To make the mistakes and corrections
easy to understand, we bring up specific examples drawn from elementary physics
and math. We also take this opportunity to provide pointers to the specialist
literature for readers who wish to delve into a given topic in more detail.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:58:14 GMT""},{""version"":""v2"",""created"":""Wed, 23 Dec 2020 20:59:18 GMT""}]","2020-12-25"
"2006.08593","Alexander Muraviev","A. Muraviev, A. Bashinov, E. Efimenko, V. Volokitin, I. Meyerov and A.
  Gonoskov","Strategies for particle resampling in PIC simulations",,,"10.1016/j.cpc.2021.107826",,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In particle-in-cell simulations, excessive or even unfeasible computational
demands can be caused by the growth of the number of particles in the course of
prolific ionization or cascaded pair production due to the effects of quantum
electrodynamics. Here we discuss how one can organize a dynamic rearrangement
of the ensemble to reduce the number of macroparticles, while maintaining
acceptable sampling of an arbitrary particle distribution. The approaches of
merging and thinning as well as their variants are discussed and the aspects of
use are considered.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:58:29 GMT""},{""version"":""v2"",""created"":""Fri, 18 Dec 2020 16:07:57 GMT""}]","2021-01-25"
"2006.08594","James Cline","Richard P. Feynman, James M. Cline","Feynman Lectures on the Strong Interactions","98 pages, 117 figures; Feynman's personal course notes and audio
  files for lectures 15, 17, 18 available at
  http://www.physics.mcgill.ca/~jcline/Feynman/ . arXiv admin note: This
  version withdrawn by arXiv administrators because the author did not have the
  right to agree to our license at the time of submission",,,,"hep-ph hep-th physics.hist-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  These twenty-two lectures, with exercises, comprise the extent of what was
meant to be a full-year graduate-level course on the strong interactions and
QCD, given at Caltech in 1987-88. The course was cut short by the illness that
led to Feynman's death. Several of the lectures were finalized in collaboration
with Feynman for an anticipated monograph based on the course. The others,
while retaining Feynman's idiosyncrasies, are revised similarly to those he was
able to check. His distinctive approach and manner of presentation are manifest
throughout. Near the end he suggests a novel, nonperturbative formulation of
quantum field theory in $D$ dimensions. Supplementary material is provided in
appendices and ancillary files, including verbatim transcriptions of three
lectures and the corresponding audiotaped recordings.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:59:55 GMT""}]","2021-06-17"
"2006.08595","Johan Olofsson","J. Olofsson, J. Milli, A. Bayo, Th. Henning, N. Engler","The challenge of measuring the phase function of debris disks.
  Application to HR\,4796","Accepted for publication in A&A, 13 pages, 11 Figures","A&A 640, A12 (2020)","10.1051/0004-6361/202038237",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Abridged: Debris disks are valuable systems to study dust properties. Because
they are optically thin at all wavelengths, we have direct access to the
properties of dust grains. One very promising technique to study them is to
measure their phase function. Disks that are highly inclined are promising
targets as a wider range of scattering angles can be probed. The phase function
is usually either inferred by comparing the observations to synthetic disk
models assuming a parametrized phase function, or estimating it from the
surface brightness of the disk. We argue here that the latter approach can be
biased due to projection effects leading to an increase in column density along
the major axis of a non flat disk. We present a novel approach to account for
those column density effects. The method remains model dependent, as one still
requires a disk model to estimate the density variations as a function of the
scattering angle. This method allows us however to estimate the shape of the
phase function without having to invoke any parametrized form. We apply our
method to SPHERE/ZIMPOL observations of HR\,4796 and highlight the differences
with previous measurements. Our modelling results suggest that the disk is not
vertically flat at optical wavelengths. We discuss some of the caveats of the
approach, mostly that our method remains blind to real local increase of the
dust density, and that it cannot yet be readily applied to angular differential
imaging observations. Similarly to previous studies on HR\,4796, we still
cannot reconcile the full picture using a given scattering theory to explain
the shape of the phase function, a long lasting problem for debris disks.
Nonetheless, we argue that similar effects as the ones highlighted in this
study can also bias the determination of the phase function in total intensity.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:59:58 GMT""}]","2020-08-05"
"2006.08596","Jes\'us Vega-Ferrero","J. Vega-Ferrero, J. M. Dana, J. M. Diego, G. Yepes, W. Cui and M.
  Meneghetti","Constraining the cross-section of dark matter with giant radial arcs in
  galaxy clusters","12 pages, 4 figures and 2 tables",,"10.1093/mnras/staa3235",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compare the statistics and morphology of giant arcs in galaxy clusters
using N-body and non-radiative SPH simulations within the standard cold dark
matter model and simulations where dark matter has a non-negligible probability
of interaction (parametrized by its cross-section), i.e self-interacting dark
matter (SIDM). We use a ray-tracing technique to produce a statistically large
number of arcs around six simulated galaxy clusters at different redshifts.
Since dark matter is more likely to interact in colliding clusters than in
relaxed clusters, and this probability of interaction is largest in denser
regions, we focus our analysis on radial arcs (which trace the lensing
potential in the central region better than tangential arcs) in galaxy clusters
which underwent (or are undergoing) a major merger. We find that
self-interacting dark matter produces fewer radial arcs than standard cold dark
matter but they are on average more magnified. We also appreciate differences
in the arc morphology that could be used to statistically favor one model
versus the other.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:59:59 GMT""},{""version"":""v2"",""created"":""Wed, 14 Oct 2020 21:18:02 GMT""}]","2020-10-28"
"2006.08598","Lun Wang","Lun Wang and Qi Pang and Dawn Song","Towards practical differentially private causal graph discovery",,,,,"cs.CR cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Causal graph discovery refers to the process of discovering causal relation
graphs from purely observational data. Like other statistical data, a causal
graph might leak sensitive information about participants in the dataset. In
this paper, we present a differentially private causal graph discovery
algorithm, Priv-PC, which improves both utility and running time compared to
the state-of-the-art. The design of Priv-PC follows a novel paradigm called
sieve-and-examine which uses a small amount of privacy budget to filter out
""insignificant"" queries, and leverages the remaining budget to obtain highly
accurate answers for the ""significant"" queries. We also conducted the first
sensitivity analysis for conditional independence tests including conditional
Kendall's tau and conditional Spearman's rho. We evaluated Priv-PC on 4 public
datasets and compared with the state-of-the-art. The results show that Priv-PC
achieves 10.61 to 32.85 times speedup and better utility.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:30:41 GMT""}]","2020-06-17"
"2006.08600","Changhee Lee","Changhee Lee and Mihaela van der Schaar","Temporal Phenotyping using Deep Predictive Clustering of Disease
  Progression",,,,,"physics.med-ph cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the wider availability of modern electronic health records, patient
care data is often being stored in the form of time-series. Clustering such
time-series data is crucial for patient phenotyping, anticipating patients'
prognoses by identifying ""similar"" patients, and designing treatment guidelines
that are tailored to homogeneous patient subgroups. In this paper, we develop a
deep learning approach for clustering time-series data, where each cluster
comprises patients who share similar future outcomes of interest (e.g., adverse
events, the onset of comorbidities). To encourage each cluster to have
homogeneous future outcomes, the clustering is carried out by learning discrete
representations that best describe the future outcome distribution based on
novel loss functions. Experiments on two real-world datasets show that our
model achieves superior clustering performance over state-of-the-art benchmarks
and identifies meaningful clusters that can be translated into actionable
information for clinical decision-making.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:48:43 GMT""}]","2020-06-17"
"2006.08614","Sahil Suneja","Sahil Suneja, Yunhui Zheng, Yufan Zhuang, Jim Laredo, Alessandro
  Morari","Learning to map source code to software vulnerability using
  code-as-a-graph",,,,,"cs.SE cs.CR cs.LG cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the applicability of Graph Neural Networks in learning the nuances
of source code from a security perspective. Specifically, whether signatures of
vulnerabilities in source code can be learned from its graph representation, in
terms of relationships between nodes and edges. We create a pipeline we call
AI4VA, which first encodes a sample source code into a Code Property Graph. The
extracted graph is then vectorized in a manner which preserves its semantic
information. A Gated Graph Neural Network is then trained using several such
graphs to automatically extract templates differentiating the graph of a
vulnerable sample from a healthy one. Our model outperforms static analyzers,
classic machine learning, as well as CNN and RNN-based deep learning models on
two of the three datasets we experiment with. We thus show that a code-as-graph
encoding is more meaningful for vulnerability detection than existing
code-as-photo and linear sequence encoding approaches. (Submitted Oct 2019,
Paper #28, ICST)
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:05:27 GMT""}]","2020-06-17"
"2006.08615","James Schombert","James Schombert, Stacy McGaugh, Federico Lelli","Using The Baryonic Tully-Fisher Relation to Measure $H_o$","21 pages, 3 figures, accepted by AJ",,"10.3847/1538-3881/ab9d88",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the use of the baryonic Tully-Fisher relation (bTFR) as a new
distance indicator. Advances in near-IR imaging and stellar population models,
plus precise rotation curves, have reduced the scatter in the bTFR such that
distance is the dominant source of uncertainty. Using 50 galaxies with accurate
distances from Cepheids or tip magnitude of the red giant branch, we calibrate
the bTFR on a scale independent of $H_o$. We then apply this calibrated bTFR to
95 independent galaxies from the SPARC sample, using CosmicFlows-3 velocities,
to deduce the local value of $H_o$. We find $H_o$ = 75.1 +/- 2.3 (stat) +/- 1.5
(sys) km s$^{-1}$ Mpc$^{-1}$.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:43:58 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 20:31:28 GMT""}]","2020-07-29"
"2006.08616","Peihong Gu","Pei-Hong Gu","Weinberg dimension-5 operator by vector-like lepton doublets","5 pages, 6 figures",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that a Weinberg dimension-5 operator for small neutrino
masses can be realized at tree level in three types of renormalizable models:
(i) the type-I seesaw mediated by fermion singlets, (ii) the type-II seesaw
mediated by Higgs triplets, (iii) the type-III seesaw mediated by fermion
triplets. We here point out such operator can be also induced at tree level by
vector-like lepton doublets in association with unusual fermion singlets, Higgs
triplets or fermion triplets. If these unusual fermion singlets, Higgs triplets
or fermion triplets are heavy enough, their decays can generate a lepton
asymmetry to explain the cosmic baryon asymmetry, meanwhile, the vector-like
lepton doublets can lead to a novel inverse or linear seesaw with rich
observable phenomena. We further specify our scenario can be naturally embedded
into a grand unification theory without the conventional type-I, type-II or
type-III seesaw.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:01:58 GMT""}]","2020-06-17"
"2006.08617","Matthew Temple","Matthew J. Temple, Gary J. Ferland, Amy L. Rankine, Paul C. Hewett, N.
  R. Badnell, C. P. Ballance, G. Del Zanna, and R. P. Dufresne","Fe III emission in quasars: evidence for a dense turbulent medium","12 pages, 11 figures, plus appendices","MNRAS 496, 2565 (2020)","10.1093/mnras/staa1717",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent improvements to atomic energy-level data allow, for the first time,
accurate predictions to be made for the Fe III line emission strengths in the
spectra of luminous, $L_\text{bol}=10^{46}-10^{48}$ erg/s, Active Galactic
Nuclei. The Fe III emitting gas must be primarily photoionized, consistent with
observations of line reverberation. We use CLOUDY models exploring a wide range
of parameter space, together with 26,500 rest-frame ultraviolet spectra from
the Sloan Digital Sky Survey, to constrain the physical conditions of the line
emitting gas. The observed Fe III emission is best accounted for by dense
($n_H=10^{14}$ cm$^{-3}$) gas which is microturbulent, leading to smaller line
optical depths and fluorescent excitation. Such high density gas appears to be
present in the central regions of the majority of luminous quasars. Using our
favoured model, we present theoretical predictions for the relative strengths
of the Fe III UV34 $\lambda\lambda$1895,1914,1926 multiplet. This multiplet is
blended with the Si III] $\lambda$1892 and C III] $\lambda$1909 emission lines
and an accurate subtraction of UV34 is essential when using these lines to
infer information about the physics of the broad line region in quasars.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 13:26:04 GMT""}]","2020-07-01"
"2006.08618","Adam Jermyn","Adam S. Jermyn and Matteo Cantiello","The Origin of the Bimodal Distribution of Magnetic Fields in Early-type
  Stars","Submitted to ApJ. 16 pages, 14 figures",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In early-type stars a fossil magnetic field may be generated during the star
formation process or be the result of a stellar merger event. Surface magnetic
fields are thought to be erased by (sub)surface convection layers, which
typically leave behind weak disordered fields. However, if the fossil field is
strong enough it can prevent the onset of (sub)surface convection and so be
preserved onto the main sequence. We calculate the critical field strength at
which this occurs, and find that it corresponds well with the lower limit
amplitude of observed fields in strongly magnetised Ap/Bp stars ($\approx$ 300
G). The critical field strength is predicted to increase slightly during the
main sequence evolution, which could also explain the observed decline in the
fraction of magnetic stars. This supports the conclusion that the bimodal
distribution of observed magnetic fields in early-type stars reflects two
different field origin stories: strongly magnetic fields are fossils fields
inherited from star formation or a merger event, and weak fields are the
product of on-going dynamo action.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:00 GMT""}]","2020-06-17"
"2006.08619","Xuheng Ding","X. Ding, T. Treu, S. Birrer, G. C.-F. Chen, J. Coles, P. Denzel, M.
  Frigo A. Galan, P. J. Marshall, M. Millon, A. More, A. J. Shajib, D. Sluse,
  H. Tak, D. Xu, M. W. Auger, V. Bonvin, H. Chand, F. Courbin, G. Despali, C.
  D. Fassnacht, D. Gilman, S. Hilbert, S. R. Kumar, Y.-Y. Lin, J. W. Park, P.
  Saha, S. Vegetti, L. Van de Vyvere, L. L.R. Williams","Time Delay Lens Modelling Challenge","23 pages, 12 figures, 6 tables, MNRAS accepted","MNRAS, (2021), 503, 1096","10.1093/mnras/stab484",,"astro-ph.CO astro-ph.GA astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, breakthroughs in methods and data have enabled gravitational
time delays to emerge as a very powerful tool to measure the Hubble constant
$H_0$. However, published state-of-the-art analyses require of order 1 year of
expert investigator time and up to a million hours of computing time per
system. Furthermore, as precision improves, it is crucial to identify and
mitigate systematic uncertainties. With this time delay lens modelling
challenge we aim to assess the level of precision and accuracy of the modelling
techniques that are currently fast enough to handle of order 50 lenses, via the
blind analysis of simulated datasets. The results in Rung 1 and Rung 2 show
that methods that use only the point source positions tend to have lower
precision ($10 - 20\%$) while remaining accurate. In Rung 2, the methods that
exploit the full information of the imaging and kinematic datasets can recover
$H_0$ within the target accuracy ($ |A| < 2\%$) and precision ($< 6\%$ per
system), even in the presence of poorly known point spread function and complex
source morphology. A post-unblinding analysis of Rung 3 showed the numerical
precision of the ray-traced cosmological simulations to be insufficient to test
lens modelling methodology at the percent level, making the results difficult
to interpret. A new challenge with improved simulations is needed to make
further progress in the investigation of systematic uncertainties. For
completeness, we present the Rung 3 results in an appendix, and use them to
discuss various approaches to mitigating against similar subtle data generation
effects in future blind challenges.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 12:20:08 GMT""}]","2021-06-11"
"2006.08620","Bruno Le Floch","Bruno Le Floch, Philippe G. LeFloch, Gabriele Veneziano","Universal scattering laws for quiescent bouncing cosmology","6 pages; updated presentation of the three laws","Phys. Rev. D 103, 083531 (2021)","10.1103/PhysRevD.103.083531","CERN-TH-2020-101","gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cosmological bounces occur in many gravity theories. We define singularity
scattering maps relating large scale geometries before and after the bounce
(assuming no BKL oscillations) and encoding microscopic details of the theory.
By classifying all suitably local maps we uncover three universal laws: scaling
of Kasner exponents, canonical transformation of matter, directional metric
scaling. These are indeed obeyed by Bianchi I bounces in string theory, loop
quantum cosmology and modified matter models; our classification then
determines how inhomogeneities and anisotropies traverse bounces, and precisely
extracts model-dependent degrees of freedom.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Sat, 15 Aug 2020 14:12:41 GMT""},{""version"":""v3"",""created"":""Mon, 15 Mar 2021 23:16:54 GMT""}]","2021-05-05"
"2006.08621","Emily Cunningham","Emily C. Cunningham, Nicolas Garavito-Camargo, Alis J. Deason, Kathryn
  V. Johnston, Denis Erkal, Chervin F. P. Laporte, Gurtina Besla, Rodrigo
  Luger, Robyn E. Sanderson","Quantifying the Stellar Halo's Response to the LMC's Infall with
  Spherical Harmonics","25 pages, 13 figures. Accepted for publication in ApJ",,"10.3847/1538-4357/ab9b88",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The vast majority of the mass in the Milky Way (MW) is in dark matter (DM);
we therefore cannot directly observe the MW mass distribution, and have to use
tracer populations in order to infer properties of the MW DM halo. However, MW
halo tracers do not only feel the gravitational influence of the MW itself.
Tracers can also be affected by MW satellites; Garavito-Camargo et al. (2019)
(hereafter GC19) demonstrate that the Large Magellanic Cloud (LMC) induces a
density wake in the MW DM, resulting in large scale kinematic patterns in the
MW stellar halo. In this work, we use spherical harmonic expansion (SHE) of the
velocity fields of simulated stellar halos in an effort to disentangle
perturbations on large scales (e.g., due to the LMC itself as well as the
LMC-induced DM wake) and small scales (due to substructure). Using the GC19
simulations, we demonstrate how the different terms in the SHE of the stellar
velocity field reflect the different wake components, and show that these
signatures are a strong function of the LMC mass. An exploration of model halos
built from accreted dwarfs Bullock & Johnston (2005) suggests that stellar
debris from massive, recent accretion events can produce much more power in the
velocity angular power spectra than the perturbation from the LMC-induced wake.
We therefore consider two models for the Sagittarius (Sgr) stream -- the most
recent, massive accretion event in the MW apart from the LMC -- and find that
the angular power on large scales is generally dominated by the LMC-induced
wake, even when Sgr is included. We conclude that SHE of the MW stellar halo
velocity field may therefore be a useful tool in quantifying the response of
the MW DM halo to the LMC's infall.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:00 GMT""}]","2020-07-22"
"2006.08622","Michael Kuhn","Michael A. Kuhn (1), Lynne A. Hillenbrand (1), John M. Carpenter (2),
  Angel Rodrigo Avelar Menendez (1) ((1) California Institute of Technology,
  (2) Joint ALMA Observatory)","The Formation of a Stellar Association in the NGC 7000/IC 5070 Complex:
  Results from Kinematic Analysis of Stars and Gas","ApJ (in press). 22 figures and 7 tables. Full versions of Tables 2
  and 7 and the extra panels for Figures 12, 16, and 17 are available at
  https://drive.google.com/drive/folders/1BflnyZKyCDN5r7Xw0J2INIubjDqWQYaB?usp=sharing",,"10.3847/1538-4357/aba19a",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the clustering and kinematics of young stellar objects (YSOs) in
the North America/Pelican Nebulae, as revealed by Gaia astrometry, in relation
to the structure and motions of the molecular gas, as indicated in molecular
line maps. The Gaia parallaxes and proper motions allow us to significantly
refine previously published lists of YSOs, demonstrating that many of the
objects previously thought to form a distributed population turn out to be
non-members. The members are subdivided into at least 6 spatio-kinematic
groups, each of which is associated with its own molecular cloud component or
components. Three of the groups are expanding, with velocity gradients of
0.3-0.5 km/s/pc, up to maximum velocities of ~8 km/s away from the groups'
centers. The two known O-type stars associated with the region, 2MASS
J20555125+4352246 and HD 199579, are rapidly escaping one of these groups,
following the same position-velocity relation as the low-mass stars. We
calculate that a combination of gas expulsion and tidal forces from the clumpy
distribution of molecular gas could impart the observed velocity gradients
within the groups. However, on a global scale, the relative motions of the
groups do not appear either divergent or convergent. The velocity dispersion of
the whole system is consistent with the kinetic energy gained due to
gravitational collapse of the complex. Most of the stellar population has ages
similar to the free-fall timescales for the natal clouds. Thus, we suggest the
nearly free-fall collapse of a turbulent molecular cloud as the most likely
scenario for star formation in this complex.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 18:00:00 GMT""}]","2020-08-26"
"2006.08623","Laura Lopez","Laura A. Lopez, Smita Mathur, Dustin D. Nguyen, Todd A. Thompson,
  Grace M. Olivier","Temperature and Metallicity Gradients in the Hot Gas Outflows of M82","15 pages, 8 figures, ApJ in press",,"10.3847/1538-4357/abc010",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We utilize deep Chandra X-ray Observatory imaging and spectra of M82, the
prototype of a starbursting galaxy with a multiphase wind, to map the hot
plasma properties along the minor axis of the galaxy. We extract spectra from
11 regions up to 2.5 kpc from the starbursting midplane and model the data as a
multi-temperature, optically thin thermal plasma with contributions from a
non-thermal (power-law) component and from charge exchange (CX). We examine the
gradients in best-fit parameters, including the intrinsic column density,
plasma temperature, metal abundances, and number density of the hot gas as a
function of distance from the M82 nucleus. We find that the temperatures and
number densities of the warm-hot and hot plasma peak at the starbursting ridge
and decreases along the minor axis. The temperature and density profiles are
inconsistent with spherical adiabatic expansion of a super-heated wind and
suggest mass loading and mixing of the hot phase with colder material.
Non-thermal emission is detected in all of the regions considered, and CX
comprises 8-25% of the total absorption-corrected, broad-band (0.5-7 keV) X-ray
flux. We show that the abundances of O, Ne, Mg, and Fe are roughly constant
across the regions considered, while Si and S peak within 500 pc of the central
starburst. These findings support a direct connection between the M82 superwind
and the warm-hot, metal-rich circumgalactic medium (CGM).
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Sat, 10 Oct 2020 22:37:14 GMT""}]","2020-12-09"
"2006.08624","Ivan Esteban","Pilar Coloma, Ivan Esteban, M.C. Gonzalez-Garcia, Javier Menendez","Determining the nuclear neutron distribution from Coherent Elastic
  neutrino-Nucleus Scattering: current results and future prospects","16 pages, 4 figures. Minor text changes and references added. Matches
  version accepted by JHEP",,"10.1007/JHEP08(2020)030","YITP-SB-2020-14, IFT-UAM/CSIC-20-087, IFIC-20-31","hep-ph hep-ex nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coherent elastic neutrino-nucleus scattering (CE$\nu$NS), a process recently
measured for the first time at ORNL's Spallation Neutron Source, is directly
sensitive to the weak form factor of the nucleus. The European Spallation
Source (ESS), presently under construction, will generate the most intense
pulsed neutrino flux suitable for the detection of CE$\nu$NS. In this paper we
quantify its potential to determine the root mean square radius of the
point-neutron distribution, for a variety of target nuclei and a suite of
detectors. To put our results in context we also derive, for the first time, a
constraint on this parameter from the analysis of the energy and timing data of
the CsI detector at the COHERENT experiment.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 18:00:58 GMT""}]","2020-08-26"
"2006.08625","Rohan Naidu","Rohan P. Naidu, Charlie Conroy, Ana Bonaca, Benjamin D. Johnson,
  Yuan-Sen Ting, Nelson Caldwell, Dennis Zaritsky, Phillip A. Cargile","Evidence from the H3 Survey that the Stellar Halo is Entirely Comprised
  of Substructure","Submitted to ApJ. Key results in Figures 18-21. Summary of individual
  structures in Sec. 3.3 and Table 1. Comments very welcome!",,"10.3847/1538-4357/abaef4",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the $\Lambda$CDM paradigm the Galactic stellar halo is predicted to harbor
the accreted debris of smaller systems. To identify these systems, the H3
Spectroscopic Survey, combined with $Gaia$, is gathering 6D phase-space and
chemical information in the distant Galaxy. Here we present a comprehensive
inventory of structure within 50 kpc from the Galactic center using a sample of
5684 giants at $|b|>40^{\circ}$ and $|Z|>2$ kpc. We identify known structures
including the high-$\alpha$ disk, the in-situ halo (disk stars heated to
eccentric orbits), Sagittarius (Sgr), $Gaia$-Sausage-Enceladus (GSE), the Helmi
Streams, Sequoia, and Thamnos. Additionally, we identify the following new
structures: (i) Aleph ([Fe/H]$=-0.5$), a low eccentricity structure that rises
a surprising 10 kpc off the plane, (ii, iii) Arjuna ([Fe/H]$=-1.2$) and I'itoi
([Fe/H]$<-2$), which comprise the high-energy retrograde halo along with
Sequoia, and (iv) Wukong ([Fe/H]$=-1.6$), a prograde phase-space overdensity
chemically distinct from GSE. For each structure we provide [Fe/H],
[$\alpha$/Fe], and orbital parameters. Stars born within the Galaxy are a major
component at $|Z|\sim$2 kpc ($\approx$60$\%$), but their relative fraction
declines sharply to $\lesssim$5$\%$ past 15 kpc. Beyond 15 kpc, $>$80$\%$ of
the halo is built by two massive ($M_{\star}\sim10^{8}-10^{9}M_{\odot}$)
accreted dwarfs: GSE ([Fe/H]$=-1.2$) within 25 kpc, and Sgr ([Fe/H]$=-1.0$)
beyond 25 kpc. This explains the relatively high overall metallicity of the
halo ([Fe/H]$\approx-1.2$). We attribute $\gtrsim$95$\%$ of the sample to one
of the listed structures, pointing to a halo built entirely from accreted
dwarfs and heating of the disk.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:01 GMT""}]","2020-09-30"
"2006.08626","Jose Manuel Alarc\'on","Jose Manuel Alarc\'on (U. Complutense de Madrid & IPARCOS), Franziska
  Hagelstein (AEC Bern), Vadim Lensky, Vladimir Pascalutsa (JGU Mainz)","Forward doubly-virtual Compton scattering off the nucleon in chiral
  perturbation theory: II. Spin polarizabilities and moments of polarized
  structure functions","47 pages, 11 figures, 2 tables. Includes Mathematica notebook with
  the spin polarizabilities and moments of polarized structure functions as
  supplemental material. Replaced to match the published version","Phys. Rev. D 102, 114026 (2020)","10.1103/PhysRevD.102.114026","MITP/20-033","hep-ph hep-lat nucl-ex nucl-th physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the polarized doubly-virtual Compton scattering (VVCS) off the
nucleon using chiral perturbation theory ($\chi$PT). The polarized VVCS
contains a wealth of information on the spin structure of the nucleon which is
relevant to the calculation of the two-photon-exchange effects in atomic
spectroscopy and electron scattering. We report on a complete
next-to-leading-order (NLO) calculation of the polarized VVCS amplitudes
$S_1(\nu, Q^2)$ and $S_2(\nu, Q^2)$, and the corresponding polarized spin
structure functions $g_1(x, Q^2)$ and $g_2(x,Q^2)$. Our results for the moments
of polarized structure functions, partially related to different spin
polarizabilities, are compared to other theoretical predictions and
""data-driven"" evaluations, as well as to the recent Jefferson Lab measurements.
By expanding the results in powers of the inverse nucleon mass, we reproduce
the known ""heavy-baryon"" expressions. This serves as a check of our
calculation, as well as demonstrates the differences between the manifestly
Lorentz-invariant baryon $\chi$PT (B$\chi$PT) and heavy-baryon (HB$\chi$PT)
frameworks.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 12:22:57 GMT""}]","2021-03-30"
"2006.08627","Alessandro Paggi","A. Paggi, M. Bonato, C. M. Raiteri, M. Villata, G. De Zotti, M. I.
  Carnerero","A New Multi-Wavelength Census of Blazars","53 pages, 32 figures, 6 tables. Accepted for publication on A&A","A&A 641, A62 (2020)","10.1051/0004-6361/202038430",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context:Blazars are the rarest and most powerful active galactic nuclei,
playing a crucial and growing role in today multi-frequency and multi-messenger
astrophysics. Current blazar catalogs, however, are incomplete and particularly
depleted at low Galactic latitudes. Aims: We aim at augmenting the current
blazar census to build a catalog of blazar candidates with homogeneous sky
coverage that can provide candidate counterparts to unassociated gamma-ray
sources, sources of high-energy neutrino emission, and ultra-high energy cosmic
rays. Methods: Starting from the ALMA Calibrator Catalog we built a catalog of
1580 blazar candidates (ALMA Blazar Candidates, ABC) for which we collect
multi-wavelength information. We also compared ABC sources with existing blazar
catalogs. Results: The ABC catalogue fills the lack of low Galactic latitude
sources in current blazar catalogues. ABC sources are significantly dimmer than
known blazars in Gaia g band, and they appear bluer in SDSS and WISE colors.
The majority of ABC sources (~ 90%) have optical spectra that classify them as
QSO, while the remaining sources resulted galactic objects. ABC sources are
similar in X-rays to known blazar, while in gamma-rays they are on average
dimmer and softer, indicating a significant contribution of FSRQ sources.
Making use of WISE colours, we classified 715 ABC sources as candidate
gamma-ray blazar of different classes. Conclusions: We built a new catalogue of
1580 candidate blazars with a rich multi-wavelength data-set, filling the lack
of low Galactic latitude sources in current blazar catalogues. This will be
particularly important to identify the source population of high energy
neutrinos or ultra-high energy cosmic rays. The data collected by the upcoming
LSST surveys will provide a key tool to investigate the possible blazar nature
of these sources.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:02 GMT""}]","2020-09-16"
"2006.08628","Mathieu Remazeilles","Mathieu Remazeilles, Aditya Rotti, Jens Chluba","Peeling off foregrounds with the constrained moment ILC method to unveil
  primordial CMB $B$-modes","21 pages, 11 figures, added appendix, updated to match version
  accepted by MNRAS",,"10.1093/mnras/stab648",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galactic foregrounds are the main obstacle to observations of the cosmic
microwave background (CMB) $B$-mode polarization. In addition to obscuring the
inflationary $B$-mode signal by several orders of magnitude, Galactic
foregrounds have non-trivial spectral signatures that are partially unknown and
distorted by averaging effects along the line-of-sight, within the pixel/beam
window, and by various analysis choices (e.g., spherical harmonic transforms
and filters). Statistical moment expansion methods provide a powerful tool for
modeling the effective Galactic foreground emission resulting from these
averaging effects in CMB observations, while blind component separation
treatments can handle unknown foregrounds. In this work, we combine these two
approaches to develop a new semi-blind component separation method at the
intersection of parametric and blind methods, called constrained moment ILC
(cMILC). This method adds several constraints to the standard ILC method to
de-project the main statistical moments of the Galactic foreground emission.
Applications to maps are performed in needlet space and when compared to the
NILC method, this helps significantly reducing residual foreground
contamination (bias, variance, and skewness) in the reconstructed CMB $B$-mode
map, power spectrum, and tensor-to-scalar ratio. We consider sky-simulations
for experimental settings similar to those of LiteBIRD and PICO, illustrating
which trade-offs between residual foreground biases and degradation of the
constraint on $r$ can be expected within the new cMILC framework. We also
outline several directions that require more work in preparation for the coming
analysis challenges.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 19:28:38 GMT""}]","2021-03-17"
"2006.08629","Seyed Morteza Hosseini","Seyed Morteza Hosseini, Kiril Hristov, Yuji Tachikawa, Alberto
  Zaffaroni","Anomalies, Black strings and the charged Cardy formula","42 pages, 1 figure; v2: crucial references added; v3: typos corrected","JHEP09(2020)167","10.1007/JHEP09(2020)167",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive the general anomaly polynomial for a class of two-dimensional CFTs
arising as twisted compactifications of a higher-dimensional theory on compact
manifolds $\mathcal{M}_d$, including the contribution of the isometries of
$\mathcal{M}_d$. We then use the result to perform a counting of microstates
for electrically charged and rotating supersymmetric black strings in
AdS$_5\times S^5$ and AdS$_7\times S^4$ with horizon topology BTZ$ \ltimes S^2$
and BTZ$ \ltimes S^2 \times \Sigma_\mathfrak{g}$, respectively, where
$\Sigma_\mathfrak{g}$ is a Riemann surface. We explicitly construct the latter
class of solutions by uplifting a class of four-dimensional rotating black
holes. We provide a microscopic explanation of the entropy of such black holes
by using a charged version of the Cardy formula.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 15:48:11 GMT""},{""version"":""v3"",""created"":""Sat, 22 May 2021 16:11:04 GMT""}]","2021-05-25"
"2006.08630","Kara Farnsworth","Gilly Elor, Kara Farnsworth, Michael L. Graesser, and Gabriel Herczeg","The Newman-Penrose Map and the Classical Double Copy","37 pages, 2 figures, v2: 39 pages, 2 figures, typos fixed, references
  added",,"10.1007/JHEP12(2020)121","LA-UR-20-23506","hep-th gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gauge-gravity duality is arguably our best hope for understanding quantum
gravity. Considerable progress has been made in relating scattering amplitudes
in certain gravity theories to those in gauge theories---a correspondence
dubbed the ""double copy"". Recently, double copies have also been realized in a
classical setting, as maps between exact solutions of gauge theories and
gravity. We present here a novel map between a certain class of real, exact
solutions of Einstein's equations and self-dual solutions of the flat-space
vacuum Maxwell equations. This map, which we call the ""Newman-Penrose map"", is
well-defined even for non-vacuum, non-stationary spacetimes, providing a
systematic framework for exploring gravity solutions in the context of the
double copy that have not been previously studied in this setting. To
illustrate this, we present here the Newman-Penrose map for the Schwarzschild
and Kerr black holes, and Kinnersley's photon rocket.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jul 2020 18:06:08 GMT""}]","2021-02-03"
"2006.08631","Dario Cilluffo","Dario Cilluffo, Angelo Carollo, Salvatore Lorenzo, Jonathan A. Gross,
  G. Massimo Palma, Francesco Ciccarello","Collisional picture of quantum optics with giant emitters","21 pages, 7 figures","Phys. Rev. Research 2, 043070 (2020)","10.1103/PhysRevResearch.2.043070",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The effective description of the weak interaction between an emitter and a
bosonic field as a sequence of two-body collisions provides a simple intuitive
picture compared to traditional quantum optics methods as well as an effective
calculation tool of the joint emitter-field dynamics. Here, this collisional
approach is extended to many emitters (atoms or resonators), each generally
interacting with the field at many coupling points (""giant"" emitter). In the
regime of negligible delays, the unitary describing each collision in
particular features a contribution of a chiral origin resulting in an effective
Hamiltonian. The picture is applied to derive a Lindblad master equation (ME)
of a set of giant atoms coupled to a (generally chiral) waveguide field in an
arbitrary white-noise Gaussian state, which condenses into a single equation
and extends a variety of quantum optics and waveguide-QED MEs. The effective
Hamiltonian and jump operators corresponding to a selected photodetection
scheme are also worked out.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:04 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 18:00:02 GMT""}]","2020-10-26"
"2006.08632","Charles J. Lada","C.J. Lada and T.M. Dame","The Mass-Size Relation and the Constancy of GMC Surface Densities in the
  Milky Way","27 pages, 7 figures, accepted for publication in the ApJ, corrected
  typos in earlier version",,"10.3847/1538-4357/ab9bfb",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use two existing molecular cloud catalogs derived from the same CO survey
and two catalogs derived from local dust extinction surveys to investigate the
nature of the GMC mass-size relation in the Galaxy. We find that the four
surveys are well described by $M_{GMC} \sim R^2$ implying a constant mean
surface density, $\Sigma_{GMC}$, for the cataloged clouds. However, the scaling
coefficients and scatter differ significantly between the CO and extinction
derived relations. We find that the additional scatter seen in the CO relations
is due to a systematic variation in $\Sigma_{GMC}$ with Galactic radius that is
unobservable in the local extinction data. We decompose this radial variation
of $\Sigma_{GMC}$ into two components, a linear negative gradient with Galactic
radius and a broad peak coincident with the molecular ring and superposed on
the linear gradient. We show that the former may be due to a radial dependence
of X$_{CO}$ on metallicity while the latter likely results from a combination
of increased surface densities of individual GMCs and a systematic upward bias
in the measurements of $\Sigma_{GMC}$ due to cloud blending in the molecular
ring. We attribute the difference in scaling coefficients between the CO and
extinction data to an underestimate of X$_{CO}$. We recalibrate the CO
observations of nearby GMCs using extinction measurements to find that locally
X$_{CO}$ $=$ 3.6$\pm$0.3 $\times$ 10$^{20}$ cm$^{-2}$ (K-km/s)$^{-1}$. We
conclude that outside the molecular ring the GMC population of the Galaxy can
be described to relatively good precision by a constant $\Sigma_{GMC}$ of 35
M$_\odot$ pc$^{-2}$.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:04 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 01:56:25 GMT""}]","2020-07-22"
"2006.08633","Carlo Alberto Cremonini","Carlo Alberto Cremonini, Pietro Antonio Grassi, Silvia Penati","Surface Operators in Superspace","47 pages, added references, adjusted notation in App A",,"10.1007/JHEP11(2020)050",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We generalize the geometrical formulation of Wilson loops recently introduced
in arXiv:2003.01729v2 to the description of Wilson Surfaces. For N=(2,0) theory
in six dimensions, we provide an explicit derivation of BPS Wilson Surfaces
with non-trivial coupling to scalars, together with their manifestly
supersymmetric version. We derive explicit conditions which allow to classify
these operators in terms of the number of preserved supercharges. We also
discuss kappa-symmetry and prove that BPS conditions in six dimensions arise
from kappa-symmetry invariance in eleven dimensions. Finally, we discuss
super-Wilson Surfaces - and higher dimensional operators - as objects charged
under global $p$-form (super)symmetries generated by tensorial supercurrents.
To this end, the construction of conserved supercurrents in supermanifolds and
of the corresponding conserved charges is developed in details.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:04 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 16:02:09 GMT""}]","2020-12-02"
"2006.08634","Haojie Xu","Ping Zhao, Haojie Xu, Antonios Katsianis, Xiaohu Yang","The intrinsic SFRF and sSFRF of galaxies: comparing SDSS observation
  with IllustrisTNG simulation","19 pages, 10 figures, accepted for publication in RAA","RAA-2020-0141","10.1088/1674-4527/20/12/195",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The star formation rate function (SFRF) and specific star formation rate
function (sSFRF) from the observation are impacted by the Eddington bias, due
to the uncertainties on the estimated SFR. We develop a novel method to correct
the Eddington bias and obtained the intrinsic SFRF and sSFRF from the Sloan
Digital Sky Survey Data Release 7. The intrinsic SFRF is in good agreement with
measurements from previous data in the literature that relied on UV SFRs but
its high star-forming end is slightly lower than those IR and radio tracers. We
demonstrate that the intrinsic sSFRF from SDSS has a bi-modal form with the one
peak found at ${\rm sSFR \sim 10^{-9.7} yr^{-1}}$ representing the star-forming
objects while the other peak is found at ${\rm sSFR \sim 10^{-12} yr^{-1}}$
representing the quenched population. Furthermore, we compare our observations
with the predictions from the IllustrisTNG and Illustris simulations and show
that the ``TNG'' model performs much better than its predecessor. However, we
show that the simulated SFRF and cosmic star formation density (CSFRD) of TNG
simulations are highly dependent on resolution, reflecting the limitations of
the model and today state-of-the-art simulations. We demonstrate that the
bi-modal, two peaked sSFRF implied by the SDSS observations does not appear in
TNG regardless of the adopted box-size or resolution. This tension reflects the
need for inclusion of an additional efficient quenching mechanism to the TNG
model.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:04 GMT""}]","2021-01-13"
"2006.08635","Shyeh Tjing Loi","Shyeh Tjing Loi","Effect of a strong magnetic field on gravity-mode period spacings in red
  giant stars","14 pages, 11 figures, accepted for publication in MNRAS",,"10.1093/mnras/staa1823",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When a star evolves into a red giant, the enhanced coupling between
core-based gravity modes and envelope-based pressure modes forms mixed modes,
allowing its deep interior to be probed by asteroseismology. The ability to
obtain information about stellar interiors is important for constraining
theories of stellar structure and evolution, for which the origin of various
discrepancies between prediction and observation are still under debate.
Ongoing speculation surrounds the possibility that some red giant stars may
harbour strong (dynamically significant) magnetic fields in their cores, but
interpretation of the observational data remains controversial. In part, this
is tied to shortfalls in our understanding of the effects of strong fields on
the seismic properties of gravity modes, which lies beyond the regime of
standard perturbative methods. Here we seek to investigate the effect of a
strong magnetic field on the asymptotic period spacings of gravity modes. We
use a Hamiltonian ray approach to measure the volume of phase space occupied by
mode-forming rays, this being roughly proportional to the average density of
modes (number of modes per unit frequency interval). A strong field appears to
systematically increase this by about 10%, which predicts a ~10% smaller period
spacing. Evidence of near integrability in the ray dynamics hints that the
gravity-mode spectrum may still exhibit pseudo-regularities under a strong
field.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:05 GMT""}]","2020-07-08"
"2006.08636","Fredrick Olness","Martha Constantinou, Aurore Courtoy, Markus A. Ebert, Michael
  Engelhardt, Tommaso Giani, Tim Hobbs, Tie-Jiun Hou, Aleksander Kusina,
  Krzysztof Kutak, Jian Liang, Huey-Wen Lin, Keh-Fei Liu, Simonetta Liuti,
  C\'edric Mezrag, Pavel Nadolsky, Emanuele R. Nocera, Fred Olness, Jian-Wei
  Qiu, Marco Radici, Anatoly Radyushkin, Abha Rajan, Ted Rogers, Juan Rojo,
  Gerrit Schierholz, C.-P. Yuan, Jian-Hui Zhang, Rui Zhang","Parton distributions and lattice QCD calculations: toward 3D structure","2020 PDFLattice Report, 64 pages, 34 figures",,"10.1016/j.ppnp.2021.103908","Nikhef 2020-018; MIT-CTP/5213; MSUHEP-20-012; IFJPAN-IV-2020-3;
  SMU-HEP-20-03","hep-ph hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The strong force which binds hadrons is described by the theory of Quantum
Chromodynamics (QCD). Determining the character and manifestations of QCD is
one of the most important and challenging outstanding issues necessary for a
comprehensive understanding of the structure of hadrons. Within the context of
the QCD parton picture, the Parton Distribution Functions (PDFs) have been
remarkably successful in describing a wide variety of processes. However, these
PDFs have generally been confined to the description of collinear partons
within the hadron. New experiments and facilities provide the opportunity to
additionally explore the transverse structure of hadrons which is described by
Generalized Parton Distributions (GPDs) and Transverse Momentum Dependent
Parton Distribution Functions (TMD PDFs). In our previous review, we compared
and contrasted the two main approaches used to determine the collinear PDFs:
the first based on perturbative QCD factorization theorems, and the second
based on lattice QCD calculations. In the present report, we provide an update
of recent progress on the collinear PDFs, and also expand the scope to
encompass the generalized PDFs (GPDs and TMD PDFs). We review the current state
of the various calculations, and consider what new data might be available in
the near future. We also examine how a shared effort can foster dialog between
the PDF and Lattice QCD communities, and yield improvements for these
generalized PDFs.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:06 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 17:46:24 GMT""}]","2021-10-04"
"2006.08637","David Ellis","David Ellis, David J. E. Marsh, Christoph Behrens","Axion Miniclusters Made Easy",,"Phys. Rev. D 103, 083525 (2021)","10.1103/PhysRevD.103.083525",,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use a modified version of the Peak Patch excursion set formalism to
compute the mass and size distribution of QCD axion miniclusters from a fully
non-Gaussian initial density field obtained from numerical simulations of axion
string decay. We find strong agreement with N-Body simulations at a
significantly lower computational cost. We employ a spherical collapse model
and provide fitting functions for the modified barrier in the radiation era.
The halo mass function at $z=629$ has a power-law distribution $M^{-0.6}$ for
masses within the range $10^{-15}\lesssim M\lesssim 10^{-10}M_{\odot}$, with
all masses scaling as $(m_a/50\mu\mathrm{eV})^{-0.5}$. We construct merger
trees to estimate the collapse redshift and concentration mass relation,
$C(M)$, which is well described using analytical results from the initial power
spectrum and linear growth. Using the calibrated analytic results to
extrapolate to $z=0$, our method predicts a mean concentration $C\sim
\mathcal{O}(\text{few})\times10^4$. The low computational cost of our method
makes future investigation of the statistics of rare, dense miniclusters easy
to achieve.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:06 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 13:11:31 GMT""}]","2021-05-12"
"2006.08638","Peter M. Weilbacher","Peter M. Weilbacher (1), Ralf Palsa (2), Ole Streicher (1), Roland
  Bacon (3), Tanya Urrutia (1), Lutz Wisotzki (1), Simon Conseil (3,4), Bernd
  Husemann (5), Aur\'elien Jarno (3), Andreas Kelz (1), Arlette
  P\'econtal-Rousset (3), Johan Richard (3), Martin M. Roth (1), Fernando
  Selman (6) and Jo\""el Vernet (2) ((1) Leibniz-Institut f\""ur Astrophysik
  Potsdam (AIP), (2) ESO Garching (3) CRAL, (4) Gemini, (5) MPIA, (6) ESO
  Santiago)","The Data Processing Pipeline for the MUSE Instrument","31 pages, 19 figures, includes the short appendix. Paper accepted by
  A&A. Software available from ESO
  (https://www.eso.org/sci/software/pipelines/muse/muse-pipe-recipes.html) and
  AIP (https://data.aip.de/projects/musepipeline.html)","A&A 641, A28 (2020)","10.1051/0004-6361/202037855",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Processing of raw data from modern astronomical instruments is nowadays often
carried out using dedicated software, so-called ""pipelines"" which are largely
run in automated operation. In this paper we describe the data reduction
pipeline of the Multi Unit Spectroscopic Explorer (MUSE) integral field
spectrograph operated at ESO's Paranal observatory. This spectrograph is a
complex machine: it records data of 1152 separate spatial elements on detectors
in its 24 integral field units. Efficiently handling such data requires
sophisticated software, a high degree of automation and parallelization. We
describe the algorithms of all processing steps that operate on calibrations
and science data in detail, and explain how the raw science data gets
transformed into calibrated datacubes. We finally check the quality of selected
procedures and output data products, and demonstrate that the pipeline provides
datacubes ready for scientific analysis.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:06 GMT""}]","2020-09-02"
"2006.08639","Elias Bernreuther","Elias Bernreuther, Thorben Finke, Felix Kahlhoefer, Michael Kr\""amer,
  Alexander M\""uck","Casting a graph net to catch dark showers","16 pages + appendices, 10 figures","SciPost Phys. 10, 046 (2021)","10.21468/SciPostPhys.10.2.046","TTK-20-17, P3H-20-025","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Strongly interacting dark sectors predict novel LHC signatures such as
semi-visible jets resulting from dark showers that contain both stable and
unstable dark mesons. Distinguishing such semi-visible jets from large QCD
backgrounds is difficult and constitutes an exciting challenge for jet
classification. In this article we explore the potential of supervised deep
neural networks to identify semi-visible jets. We show that dynamic graph
convolutional neural networks operating on so-called particle clouds outperform
convolutional neural networks analysing jet images as well as other neural
networks based on Lorentz vectors. We investigate how the performance depends
on the properties of the dark shower and discuss training on mixed samples as a
strategy to reduce model dependence. By modifying an existing mono-jet analysis
we show that LHC sensitivity to dark sectors can be enhanced by more than an
order of magnitude by using the dynamic graph network as a dark shower tagger.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:07 GMT""},{""version"":""v2"",""created"":""Mon, 26 Oct 2020 09:44:10 GMT""},{""version"":""v3"",""created"":""Thu, 7 Jan 2021 18:15:46 GMT""}]","2021-02-24"
"2006.08640","Nathan Sandford","Nathan R. Sandford, Daniel R. Weisz, Yuan-Sen Ting","Forecasting Chemical Abundance Precision for Extragalactic Stellar
  Archaeology","60 pages, 24 figures, accepted for publication in ApJS",,"10.3847/1538-4365/ab9cb0",,"astro-ph.SR astro-ph.GA astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Increasingly powerful and multiplexed spectroscopic facilities promise
detailed chemical abundance patterns for millions of resolved stars in galaxies
beyond the Milky Way (MW). Here, we employ the Cram\'er-Rao Lower Bound (CRLB)
to forecast the precision to which stellar abundances for metal-poor, low-mass
stars outside the MW can be measured for 41 current (e.g., Keck, MMT, VLT,
DESI) and planned (e.g., MSE, JWST, ELTs) spectrograph configurations. We show
that moderate resolution ($R\lesssim5000$) spectroscopy at blue-optical
wavelengths ($\lambda\lesssim4500$ \AA) (i) enables the recovery of 2-4 times
as many elements as red-optical spectroscopy
($5000\lesssim\lambda\lesssim10000$ \AA) at similar or higher resolutions
($R\sim 10000$) and (ii) can constrain the abundances of several neutron
capture elements to $\lesssim$0.3 dex. We further show that high-resolution
($R\gtrsim 20000$), low S/N ($\sim$10 pixel$^{-1}$) spectra contain rich
abundance information when modeled with full spectral fitting techniques. We
demonstrate that JWST/NIRSpec and ELTs can recover (i) $\sim$10 and 30
elements, respectively, for metal-poor red giants throughout the Local Group
and (ii) [Fe/H] and [$\alpha$/Fe] for resolved stars in galaxies out to several
Mpc with modest integration times. We show that select literature abundances
are within a factor of $\sim$2 (or better) of our CRLBs. We suggest that, like
ETCs, CRLBs should be used when planning stellar spectroscopic observations. We
include an open source python package, \texttt{Chem-I-Calc}, that allows users
to compute CRLBs for spectrographs of their choosing.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:08 GMT""}]","2020-08-05"
"2006.08641","Anke Arentsen","Anke Arentsen, Else Starkenburg, Nicolas F. Martin, David S. Aguado,
  Daniel B. Zucker, Carlos Allende Prieto, Vanessa Hill, Kim. A. Venn, Raymond
  G. Carlberg, Jonay I. Gonz\'alez Hern\'andez, Lyudmila I. Mashonkina, Julio
  F. Navarro, Rub\'en S\'anchez-Janssen, Mathias Schultheis, Guillaume F.
  Thomas, Kris Youakim, Geraint F. Lewis, Jeffrey D. Simpson, Zhen Wan, Roger
  E. Cohen, Doug Geisler, Julia E. O'Connell","The Pristine Inner Galaxy Survey (PIGS) II: Uncovering the most
  metal-poor populations in the inner Milky Way","accepted for publication in MNRAS, 17 pages, 9 figures",,"10.1093/mnras/staa1661",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metal-poor stars are important tools for tracing the early history of the
Milky Way, and for learning about the first generations of stars. Simulations
suggest that the oldest metal-poor stars are to be found in the inner Galaxy.
Typical bulge surveys, however, lack low metallicity ([Fe/H] < -1.0) stars
because the inner Galaxy is predominantly metal-rich. The aim of the Pristine
Inner Galaxy Survey (PIGS) is to study the metal-poor and very metal-poor (VMP,
[Fe/H] < -2.0) stars in this region. In PIGS, metal-poor targets for
spectroscopic follow-up are selected from metallicity-sensitive CaHK photometry
from the CFHT. This work presents the ~250 deg^2 photometric survey as well as
intermediate-resolution spectroscopic follow-up observations for ~8000 stars
using AAOmega on the AAT. The spectra are analysed using two independent tools:
ULySS with an empirical spectral library, and FERRE with a library of synthetic
spectra. The comparison between the two methods enables a robust determination
of the stellar parameters and their uncertainties. We present a sample of 1300
VMP stars -- the largest sample of VMP stars in the inner Galaxy to date.
Additionally, our spectroscopic dataset includes ~1700 horizontal branch stars,
which are useful metal-poor standard candles. We furthermore show that PIGS
photometry selects VMP stars with unprecedented efficiency: 86%/80%
(lower/higher extinction) of the best candidates satisfy [Fe/H] < -2.0, as do
80%/63% of a larger, less strictly selected sample. We discuss future
applications of this unique dataset that will further our understanding of the
chemical and dynamical evolution of the innermost regions of our Galaxy.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:08 GMT""}]","2020-07-22"
"2006.08642","Ion Cosma Fulga","S. Thirupathaiah, Y. S. Kushnirenk, K. Koepernik, B. R. Piening, B.
  Buechner, S. Aswartham, J. van den Brink, S. V. Borisenko and I. C. Fulga","Sixfold fermion near the Fermi level in cubic PtBi2","15 pages, 6 figures; this is the final, published version","SciPost Phys. 10, 004 (2021)","10.21468/SciPostPhys.10.1.004",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the cubic compound PtBi2, is a topological semimetal hosting a
sixfold band touching point in close proximity to the Fermi level. Using
angle-resolved photoemission spectroscopy, we map the bandstructure of the
system, which is in good agreement with results from density functional theory.
Further, by employing a low energy effective Hamiltonian valid close to the
crossing point, we study the effect of a magnetic field on the sixfold fermion.
The latter splits into a total of twenty Weyl cones for a Zeeman field oriented
in the diagonal, [111] direction. Our results mark cubic PtBi2, as an ideal
candidate to study the transport properties of gapless topological systems
beyond Dirac and Weyl semimetals.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:09 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 14:15:37 GMT""}]","2021-02-09"
"2006.08643","Aitor Lewkowycz","Aitor Lewkowycz and Guy Gur-Ari","On the training dynamics of deep networks with $L_2$ regularization","10+12 pages, 5+10 figures. Updated to match NeurIPS version",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the role of $L_2$ regularization in deep learning, and uncover
simple relations between the performance of the model, the $L_2$ coefficient,
the learning rate, and the number of training steps. These empirical relations
hold when the network is overparameterized. They can be used to predict the
optimal regularization parameter of a given model. In addition, based on these
observations we propose a dynamical schedule for the regularization parameter
that improves performance and speeds up training. We test these proposals in
modern image classification settings. Finally, we show that these empirical
relations can be understood theoretically in the context of infinitely wide
networks. We derive the gradient flow dynamics of such networks, and compare
the role of $L_2$ regularization in this context with that of linear models.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:09 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jan 2021 17:15:12 GMT""}]","2021-01-05"
"2006.08644","Tanay Kibe","Tanay Kibe, Ayan Mukhopadhyay, Alexander Soloviev and Hareram Swain","$SL(2,R)$ lattices as information processors","23 pages, 13 figures; conclusions expanded with summary, more
  comments and references added","Phys. Rev. D 102, 086008 (2020)","10.1103/PhysRevD.102.086008",,"hep-th cond-mat.str-el gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Black holes past their Page times should act as efficient scramblers and
information mirrors. The information of the infalling bits are rapidly encoded
by the old black hole in the Hawking quanta, but it should take time that is
exponential in the Page time entropy to decode the interior. Motivated by the
features of fragmentation instability of near-extremal black holes, we
construct a simple phenomenological model of the black hole as a lattice of
interacting nearly $AdS_2$ throats with gravitational hair charges propagating
over the lattice. We study the microstate solutions and their response to
shocks. The energy of the shocks are almost wholly absorbed by the total ADM
mass of the $AdS_2$ throats, but the information of their locations and
time-ordering come out in the hair oscillations, which decouple from the final
microstate to which the full system quickly relaxes. We discuss the
Hayden-Preskill protocol of decoding infalling information. We also construct
generalizations of our model involving a lattice of $AdS_2$ throats networked
via wormholes and their analogues in the form of tensor networks of SYK
spin-states.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:11 GMT""},{""version"":""v2"",""created"":""Sun, 27 Sep 2020 05:53:57 GMT""}]","2020-10-14"
"2006.08645","Hengxiao Guo","Hengxiao Guo, Jiacheng Peng, Kaiwen Zhang, Colin J. Burke, Xin Liu,
  Mouyuan Sun, Shu Wang, Minzhi Kong, Zhenfeng Sheng, Tinggui Wang, Zhicheng
  He, and Minfeng Gu","High-redshift Extreme Variability Quasars from Sloan Digital Sky Survey
  Multi-Epoch Spectroscopy","25 pages, 15 figures, 6 tables, published in ApJ",,"10.3847/1538-4357/abc2ce",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a systematic search for high-redshift ($z >$ 1.5) extreme
variability quasars (EVQs) using repeat spectra from the Sixteenth Data Release
of Sloan Digital Sky Survey, which provides a baseline spanning up to $\sim$18
yrs in the observed frame. We compile a sample of 348 EVQs with a maximum
continuum variability at rest frame 1450 Angstrom of more than 100% (i.e.,
$\delta$V $\equiv$ (Max$-$Min)/Mean $>$1). The EVQs show a range of emission
line variability, including 23 where at least one line in our redshift range
disappears below detectability, which can then be seen as analogous to
low-redshift changing-look quasars (CLQs)"". Importantly, spurious CLQs caused
by SDSS problematic spectral flux calibration, e.g., fiber drop issue, have
been rejected. The similar properties (e.g., continuum/line,
difference-composite spectra and Eddington ratio) of normal EVQs and CLQs,
implies that they are basically the same physical population with analogous
intrinsic variability mechanisms, as a tail of a continuous distribution of
normal quasar properties. In addition, we find no reliable evidence ($\lesssim$
1$\sigma$) to support that the CLQs are a subset of EVQs with less efficient
accretion. Finally, we also confirm the anti-breathing of C IV (i.e., line
width increases as luminosity increases) in EVQs, and find that in addition to
$\sim$ 0.4 dex systematic uncertainty in single-epoch C IV virial black hole
mass estimates, an extra scatter of $\sim$ 0.3 dex will be introduced by
extreme variability.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:23 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 19:20:02 GMT""},{""version"":""v3"",""created"":""Mon, 21 Dec 2020 17:36:20 GMT""}]","2020-12-23"
"2006.08646","Norbert Schuch","Sven Jandura, Mohsin Iqbal, and Norbert Schuch","Quantum trimer models and topological SU(3) spin liquids on the kagome
  lattice",,"Phys. Rev. Research 2, 033382 (2020)","10.1103/PhysRevResearch.2.033382",,"cond-mat.str-el cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct and study quantum trimer models and resonating SU(3)-singlet
models on the kagome lattice, which generalize quantum dimer models and the
Resonating Valence Bond wavefunctions to a trimer and SU(3) setting. We
demonstrate that these models carry a Z_3 symmetry which originates in the
structure of trimers and the SU(3) representation theory, and which becomes the
only symmetry under renormalization. Based on this, we construct simple and
exact parent Hamiltonians for the model which exhibit a topological 9-fold
degenerate ground space. A combination of analytical reasoning and numerical
analysis reveals that the quantum order ultimately displayed by the model
depends on the relative weight assigned to different types of trimers -- it can
display either Z_3 topological order or form a symmetry-broken trimer crystal,
and in addition possesses a point with an enhanced U(1) symmetry and critical
behavior. Our results accordingly hold for the SU(3) model, where the two
natural choices for trimer weights give rise to either a topological spin
liquid or a system with symmetry-broken order, respectively. Our work thus
demonstrates the suitability of resonating trimer and SU(3)-singlet ansatzes to
model SU(3) topological spin liquids on the kagome lattice.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:25 GMT""}]","2020-09-14"
"2006.08647","Andres Escala","Andres Escala","Universal Relation for Life-span Energy Consumption in Living Organisms:
  Insights for the origin of ageing","Comments welcome aescala@das.uchile.cl",,,,"q-bio.OT physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metabolic energy consumption has long been thought to play a major role in
the aging process ({\it 1}). Across species, a gram of tissue on average
expends about the same amount of energy during life-span ({\it 2}). Energy
restriction has also been shown that increases maximum life-span ({\it 3}) and
retards age-associated changes ({\it 4}). However, there are significant
exceptions to a universal energy consumption during life-span, mainly coming
from the inter-class comparison ({\it 5, 6}). Here we present a unique relation
for life-span energy consumption, valid for $\sim$300 species representing all
classes of living organisms, from unicellular ones to the largest mammals. The
relation has an average scatter of only 0.3 dex, with 95\% ($\rm 2-\sigma$) of
the organisms having departures less than a factor of $\pi$ from the relation,
despite the $\sim$20 orders of magnitude difference in body mass, reducing any
possible inter-class variation in the relation to only a geometrical factor.
This result can be interpreted as supporting evidence for the existence of an
approximately constant total number $\rm N_r \sim 10^8$ of respiration cycles
per lifetime for all organisms, effectively predetermining the extension of
life by the basic energetics of respiration, being an incentive for future
studies that investigate the relation of such constant $\rm N_r$ cycles per
lifetime with the production rates of free radicals and oxidants, which may
give definite constraints on the origin of ageing.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:32 GMT""}]","2020-06-17"
"2006.08648","Jordan Cotler","Jordan Cotler, Kristan Jensen","AdS$_3$ gravity and random CFT","51+8 pages, 5 figures; v2: minor typos fixed; v3: published version,
  more typos fixed",,"10.1007/JHEP04(2021)033",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the path integral of three-dimensional gravity with negative
cosmological constant on spaces which are topologically a torus times an
interval. These are Euclidean wormholes, which smoothly interpolate between two
asymptotically Euclidean AdS$_3$ regions with torus boundary. From our results
we obtain the spectral correlations between BTZ black hole microstates near
threshold, as well as extract the spectral form factor at fixed momentum, which
has linear growth in time with small fluctuations around it. The low-energy
limit of these correlations is precisely that of a double-scaled random matrix
ensemble with Virasoro symmetry. Our findings suggest that if pure
three-dimensional gravity has a holographic dual, then the dual is an ensemble
which generalizes random matrix theory.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:50 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 23:40:42 GMT""},{""version"":""v3"",""created"":""Wed, 27 Jul 2022 13:34:10 GMT""}]","2022-07-28"
"2006.08649","David Berenstein","David Berenstein, Adolfo Holguin","Open giant magnons suspended between dual giant gravitons in ${\cal
  N}=4$ SYM","20 pages",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study classical solutions to the Nambu-Goto string on $AdS_2 \times S^1$
and $AdS_3 \times S^1$ corresponding to strings stretched between wrapped
branes extending in $AdS$. The solutions are obtained by analytic continuation
of giant magnon solutions, cut at the position of the branes.
  These solutions carry one or two $SO(2,4)$ charges and a single $SO(6)$
charge. We compute their energies and show their relation to $\frac{1}{2}$-BPS
geometries. Their relevance to the $SL(2)$ sector of $\mathcal{N}=4$ SYM is
also discussed.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:00:56 GMT""}]","2020-06-17"
"2006.08650","Abhishek Mohapatra","Eric Braaten, Li-Ping He, and Abhishek Mohapatra","Masses of Doubly Heavy Tetraquarks with Error Bars","28 pages, 7 tables, Minor revisions, published in Phys. Rev. D","Phys. Rev. D 103, 016001 (2021)","10.1103/PhysRevD.103.016001",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the heavy-quark limit, the two heavy quarks in a doubly heavy baryon or a
doubly heavy tetraquark are bound by their color-Coulomb potential into a
compact diquark. The doubly heavy hadrons are related by the approximate
heavy-quark--diquark symmetry of QCD to the heavy hadrons obtained by replacing
the heavy diquark by a heavy antiquark. Effective field theories can be used to
expand the masses of singly heavy hadrons and doubly heavy hadrons in inverse
powers of the heavy quark masses. The coefficients in the expansions for doubly
heavy tetraquarks can be determined from those for heavy mesons, heavy baryons,
and doubly heavy baryons using heavy-quark--diquark symmetry. We predict the
masses of the ground-state doubly heavy tetraquarks with error bars using as
inputs the masses of heavy mesons and heavy baryons measured in experiments and
the masses of doubly heavy baryons calculated using lattice QCD. The only
doubly heavy tetraquarks predicted to be stable with respect to strong decays
are $bb$ tetraquarks with light flavor $\bar u \bar d$, $\bar s \bar u$ and
$\bar s \bar d$.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:02:29 GMT""},{""version"":""v2"",""created"":""Fri, 8 Jan 2021 18:00:05 GMT""}]","2021-01-13"
"2006.08651","Elizabeth Gonzalez Dr.","Elizabeth J. Gonzalez, Martin Makler, Diego Garcia Lambas, Martin
  Chalela, Maria E. S. Pereira, Ludovic Van Waerbeke, HuanYuan Shan, Thomas
  Erben","Measuring the surface mass density ellipticity of redMaPPer galaxy
  clusters using weak-lensing","16 pages, 6 figures, submitted to MNRAS",,"10.1093/mnras/staa3570",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we study the shape of the projected surface mass density
distribution of galaxy clusters using weak-lensing stacking techniques. In
particular, we constrain the average aligned component of the projected
ellipticity, $\epsilon$, for a sample of redMaPPer clusters ($0.1 \leq z <
0.4$). We consider six different proxies for the cluster orientation and
measure $\epsilon$ for three ranges of projected distances from the cluster
centres. The mass distribution in the inner region (up to $700\,$kpc) is better
traced by the cluster galaxies with a higher membership probability, while the
outer region (from $700\,$kpc up to $5\,$Mpc) is better traced by the inclusion
of less probable galaxy cluster members. The fitted ellipticity in the inner
region is $\epsilon = 0.21 \pm 0.04$, in agreement with previous estimates. We
also study the relation between $\epsilon$ and the cluster mean redshift and
richness. By splitting the sample in two redshift ranges according to the
median redshift, we obtain larger $\epsilon$ values for clusters at higher
redshifts, consistent with the expectation from simulations. In addition, we
obtain higher ellipticity values in the outer region of clusters at low
redshifts. We discuss several systematic effects that might affect the measured
lensing ellipticities and their relation to the derived ellipticity of the mass
distribution.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:03:24 GMT""}]","2020-12-09"
"2006.08652","John Barrow","John D. Barrow","Multifractality in the general cosmological solution of Einstein's
  equations","5 pages, no figures, extra text and refs, accepted version","Phys. Rev. D 102, 041501 (2020)","10.1103/PhysRevD.102.041501",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the scale invariance of the vacuum Bianchi type IX equations
and use this to argue for the possibility of multifractal turbulence as a
realisation of the suggestion by Belinski that there will be a fragmentation of
local regions of inhomogeneous Mixmaster chaos on approach to an initial
inhomogeneous cosmological singularity. Differences between the gravitational
and hydrodynamical situations are outlined. Various potential obstacles to this
picture of gravitational turbulence are discussed.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:03:27 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jul 2020 15:19:46 GMT""}]","2020-08-12"
"2006.08653","Alexei Tsvelik","A. M. Tsvelik","Simulating exotic phases of matter with bond-directed interactions with
  arrays of Majorana-Cooper pair boxes","7 pages, 7 figures, typos removed, explanations added","Phys. Rev. Lett. 125, 197202 (2020)","10.1103/PhysRevLett.125.197202",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is suggested that networks of Majorana-Cooper pair boxes connected by
metallic nanowires can simulate various exotic states of matter. In this
simulations Majorana-Cooper boxes play the role of effective spins S=1/2 and
the metallic connections generate the Kondo screening and the
Ruderman-Kittel-Kasuya-Yosida (RKKY) interaction. Depending on what prevails -
whether it is the Kondo effect or the RKKY exchange, one will have either an
effective spin model or a Kondo lattice. The list of exotic stets includes the
famous hexagonal Kitaev model, a generalization of this model for a Kondo
lattice and various spin models with three-spin interactions. A special
emphasize is made on the discussion of the Kondo lattice scaenario.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:03:55 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 14:38:53 GMT""},{""version"":""v3"",""created"":""Fri, 18 Sep 2020 17:23:13 GMT""}]","2020-11-11"
"2006.08654","Pedro Garc\'ia-L\'opez","Pedro Garc\'ia-L\'opez, Aitor Arjona, Josep Sampe, Aleksander
  Slominski, Lionel Villard","Triggerflow: Trigger-based Orchestration of Serverless Workflows","The 14th ACM International Conference on Distributed and Event-based
  Systems (DEBS 2020)",,"10.1145/3401025.3401731",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As more applications are being moved to the Cloud thanks to serverless
computing, it is increasingly necessary to support native life cycle execution
of those applications in the data center. But existing systems either focus on
short-running workflows (like IBM Composer or Amazon Express Workflows) or
impose considerable overheads for synchronizing massively parallel jobs (Azure
Durable Functions, Amazon Step Functions, Google Cloud Composer). None of them
are open systems enabling extensible interception and optimization of custom
workflows. We present Triggerflow: an extensible Trigger-based Orchestration
architecture for serverless workflows built on top of Knative Eventing and
Kubernetes technologies. We demonstrate that Triggerflow is a novel serverless
building block capable of constructing different reactive schedulers (State
Machines, Directed Acyclic Graphs, Workflow as code). We also validate that it
can support high-volume event processing workloads, auto-scale on demand and
transparently optimize scientific workflows.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:04:33 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 14:18:34 GMT""}]","2020-06-18"
"2006.08655","Luigi Acerbi","Luigi Acerbi","Variational Bayesian Monte Carlo with Noisy Likelihoods","To appear in Advances in Neural Information Processing Systems 33
  (NeurIPS 2020). 26 pages, 11 figures",,,,"stat.ML cs.LG q-bio.NC q-bio.QM stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variational Bayesian Monte Carlo (VBMC) is a recently introduced framework
that uses Gaussian process surrogates to perform approximate Bayesian inference
in models with black-box, non-cheap likelihoods. In this work, we extend VBMC
to deal with noisy log-likelihood evaluations, such as those arising from
simulation-based models. We introduce new `global' acquisition functions, such
as expected information gain (EIG) and variational interquantile range (VIQR),
which are robust to noise and can be efficiently evaluated within the VBMC
setting. In a novel, challenging, noisy-inference benchmark comprising of a
variety of models with real datasets from computational and cognitive
neuroscience, VBMC+VIQR achieves state-of-the-art performance in recovering the
ground-truth posteriors and model evidence. In particular, our method vastly
outperforms `local' acquisition functions and other surrogate-based inference
methods while keeping a small algorithmic cost. Our benchmark corroborates VBMC
as a general-purpose technique for sample-efficient black-box Bayesian
inference also with noisy models.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:06:18 GMT""},{""version"":""v2"",""created"":""Fri, 2 Oct 2020 15:30:43 GMT""},{""version"":""v3"",""created"":""Mon, 19 Oct 2020 05:54:29 GMT""}]","2020-10-20"
"2006.08656","Shaojie Bai","Shaojie Bai and Vladlen Koltun and J. Zico Kolter","Multiscale Deep Equilibrium Models","NeurIPS 2020 Oral",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new class of implicit networks, the multiscale deep equilibrium
model (MDEQ), suited to large-scale and highly hierarchical pattern recognition
domains. An MDEQ directly solves for and backpropagates through the equilibrium
points of multiple feature resolutions simultaneously, using implicit
differentiation to avoid storing intermediate states (and thus requiring only
$O(1)$ memory consumption). These simultaneously-learned multi-resolution
features allow us to train a single model on a diverse set of tasks and loss
functions, such as using a single MDEQ to perform both image classification and
semantic segmentation. We illustrate the effectiveness of this approach on two
large-scale vision tasks: ImageNet classification and semantic segmentation on
high-resolution images from the Cityscapes dataset. In both settings, MDEQs are
able to match or exceed the performance of recent competitive computer vision
models: the first time such performance and scale have been achieved by an
implicit deep learning approach. The code and pre-trained models are at
https://github.com/locuslab/mdeq .
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:07:44 GMT""},{""version"":""v2"",""created"":""Tue, 24 Nov 2020 06:59:38 GMT""}]","2020-11-25"
"2006.08657","Yan-Fei Jiang","Yan-Fei Jiang, Omer Blaes","Opacity Driven Convection and Variability in Accretion Disks around
  Supermassive Black Holes","15 pages, 14 figures, resubmitted after including the referee's
  comments","ApJ, 900, 25, 2020","10.3847/1538-4357/aba4b7",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the structure of accretion disks around supermassive black holes in
the radial range $30\sim 100$ gravitational radii, using a three dimensional
radiation magneto-hydrodynamic simulation. For typical conditions in this
region of Active Galactic Nuclei (AGN), the Rosseland mean opacity is expected
to be larger than the electron scattering value. We show that the iron opacity
bump causes the disk to be convective unstable. Turbulence generated by
convection puffs up the disk due to additional turbulent pressure support and
enhances the local angular momentum transport. This also results in strong
fluctuations in surface density and heating of the disk. The opacity drops with
increasing temperature and convection is suppressed. The disk cools down and
the whole process repeats again. This causes strong oscillations of the disk
scale height and luminosity variations by more than a factor of $\approx 3-6$
over a few years' timescale. Since the iron opacity bump will move to different
locations of the disk for black holes with different masses and accretion
rates, we suggest that this is a physical mechanism that can explain the
variability of AGN with a wide range of amplitudes over a time scale of years
to decades.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:08:04 GMT""}]","2020-09-02"
"2006.08658","Antoine Saporta","Antoine Saporta, Tuan-Hung Vu, Matthieu Cord, Patrick P\'erez","ESL: Entropy-guided Self-supervised Learning for Domain Adaptation in
  Semantic Segmentation","Accepted at the CVPR 2020 Workshop on Scalability in Autonomous
  Driving",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While fully-supervised deep learning yields good models for urban scene
semantic segmentation, these models struggle to generalize to new environments
with different lighting or weather conditions for instance. In addition,
producing the extensive pixel-level annotations that the task requires comes at
a great cost. Unsupervised domain adaptation (UDA) is one approach that tries
to address these issues in order to make such systems more scalable. In
particular, self-supervised learning (SSL) has recently become an effective
strategy for UDA in semantic segmentation. At the core of such methods lies
`pseudo-labeling', that is, the practice of assigning high-confident class
predictions as pseudo-labels, subsequently used as true labels, for target
data. To collect pseudo-labels, previous works often rely on the highest
softmax score, which we here argue as an unfavorable confidence measurement.
  In this work, we propose Entropy-guided Self-supervised Learning (ESL),
leveraging entropy as the confidence indicator for producing more accurate
pseudo-labels. On different UDA benchmarks, ESL consistently outperforms strong
SSL baselines and achieves state-of-the-art results.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:10:09 GMT""}]","2020-06-17"
"2006.08659","James Goodman","James Goodman, Simon Lucas","Does it matter how well I know what you're thinking? Opponent Modelling
  in an RTS game","Preprint of paper accepted for IEEE World Congress on Computational
  Intelligence (IEEE WCCI) 2020",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Opponent Modelling tries to predict the future actions of opponents, and is
required to perform well in multi-player games. There is a deep literature on
learning an opponent model, but much less on how accurate such models must be
to be useful. We investigate the sensitivity of Monte Carlo Tree Search (MCTS)
and a Rolling Horizon Evolutionary Algorithm (RHEA) to the accuracy of their
modelling of the opponent in a simple Real-Time Strategy game. We find that in
this domain RHEA is much more sensitive to the accuracy of an opponent model
than MCTS. MCTS generally does better even with an inaccurate model, while this
will degrade RHEA's performance. We show that faced with an unknown opponent
and a low computational budget it is better not to use any explicit model with
RHEA, and to model the opponent's actions within the tree as part of the MCTS
algorithm.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:10:22 GMT""}]","2020-06-17"
"2006.08660","Claire Gu\'epin","Claire Gu\'epin","Signatures of secondary acceleration in neutrino flares","12 pages, 4 figues, submitted to A&A","A&A 641, A29 (2020)","10.1051/0004-6361/202037576",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-energy neutrino flares are interesting prospective counterparts to
photon flares, as their detection would guarantee the presence of accelerated
hadrons within a source, provide precious information about cosmic-ray
acceleration and interactions, and thus impact the subsequent modeling of
non-thermal emissions in explosive transients. In these sources, photomeson
production can be efficient, producing a large amount of secondary particles,
such as charged pions and muons, that decay and produce high-energy neutrinos.
Before their decay, secondary particles can experience energy losses and
acceleration, which can impact high-energy neutrino spectra and thus affect
their detectability. In this work, we focus on the impact of secondary
acceleration. We consider a one zone model, characterized mainly by a
variability timescale $t_{\rm var}$, a luminosity $L_{\rm bol}$, a bulk Lorentz
factor $\Gamma$. The mean magnetic field $B$ is deduced from these parameters.
The photon field is modeled by a broken power-law. This generic model allows to
evaluate systematically the maximum energy of high-energy neutrinos in the
parameter space of explosive transients, and shows that it could be strongly
affected by secondary acceleration for a large number of source categories. In
order to determine the impact of secondary acceleration on the high-energy
neutrino spectrum and in particular on its peak energy and flux, we complement
these estimates by several case studies. We show that secondary acceleration
can increase the maximum neutrino flux, and produce a secondary peak at the
maximum energy in the case of efficient acceleration. Secondary acceleration
could therefore enhance the detectability of very-high-energy neutrinos, that
will be the target of next generation neutrino detectors such as KM3NeT,
IceCube-Gen2, POEMMA or GRAND.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:10:25 GMT""}]","2020-09-02"
"2006.08661","Jihyeon Lee","Jihyeon Lee, Dylan Grosz, Burak Uzkent, Sicheng Zeng, Marshall Burke,
  David Lobell, Stefano Ermon","Predicting Livelihood Indicators from Community-Generated Street-Level
  Imagery","Accepted to AAAI 2021. Code:
  https://github.com/sustainlab-group/mapillarygcn",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Major decisions from governments and other large organizations rely on
measurements of the populace's well-being, but making such measurements at a
broad scale is expensive and thus infrequent in much of the developing world.
We propose an inexpensive, scalable, and interpretable approach to predict key
livelihood indicators from public crowd-sourced street-level imagery. Such
imagery can be cheaply collected and more frequently updated compared to
traditional surveying methods, while containing plausibly relevant information
for a range of livelihood indicators. We propose two approaches to learn from
the street-level imagery: (1) a method that creates multi-household cluster
representations by detecting informative objects and (2) a graph-based approach
that captures the relationships between images. By visualizing what features
are important to a model and how they are used, we can help end-user
organizations understand the models and offer an alternate approach for index
estimation that uses cheaply obtained roadway features. By comparing our
results against ground data collected in nationally-representative household
surveys, we demonstrate the performance of our approach in accurately
predicting indicators of poverty, population, and health and its scalability by
testing in two different countries, India and Kenya. Our code is available at
https://github.com/sustainlab-group/mapillarygcn.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:12:12 GMT""},{""version"":""v2"",""created"":""Sat, 27 Jun 2020 19:03:55 GMT""},{""version"":""v3"",""created"":""Sat, 5 Sep 2020 22:52:08 GMT""},{""version"":""v4"",""created"":""Thu, 3 Dec 2020 02:27:31 GMT""},{""version"":""v5"",""created"":""Sat, 5 Dec 2020 08:29:27 GMT""},{""version"":""v6"",""created"":""Fri, 26 Feb 2021 19:45:49 GMT""}]","2021-03-02"
"2006.08662","Manisha Caleb","M. Caleb, B. W. Stappers, T. D. Abbott, E. D. Barr, M. C.
  Bezuidenhout, S. J. Buchner, M. Burgay, W. Chen, I. Cognard, L. N. Driessen,
  R. Fender, G. H. Hilmarsson, J. Hoang, D. M. Horn, F. Jankowski, M. Kramer,
  D. R. Lorimer, M. Malenta, V. Morello, M. Pilia, E. Platts, A. Possenti, K.
  M. Rajwade, A. Ridolfi, L. Rhodes, S. Sanidas, M. Serylak, L. G. Spitler, L.
  J. Townsend, A. Weltman, P. A. Woudt, J. Wu","Simultaneous multi-telescope observations of FRB 121102","Accepted for publication in MNRAS",,"10.1093/mnras/staa1791",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present 11 detections of FRB 121102 in ~3 hours of observations during its
'active' period on the 10th of September 2019. The detections were made using
the newly deployed MeerTRAP system and single pulse detection pipeline at the
MeerKAT radio telescope in South Africa. Fortuitously, the Nancay radio
telescope observations on this day overlapped with the last hour of MeerKAT
observations and resulted in 4 simultaneous detections. The observations with
MeerKAT's wide band receiver, which extends down to relatively low frequencies
(900-1670 MHz usable L-band range), have allowed us to get a detailed look at
the complex frequency structure, intensity variations and frequency-dependent
sub-pulse drifting. The drift rates we measure for the full-band and sub-banded
data are consistent with those published between 600-6500 MHz with a slope of
-0.147 +/- 0.014 ms^-1. Two of the detected bursts exhibit fainter 'precursors'
separated from the brighter main pulse by ~28 ms and ~34 ms. A follow-up
multi-telescope campaign on the 6th and 8th October 2019 to better understand
these frequency drifts and structures over a wide and continuous band was
undertaken. No detections resulted, indicating that the source was 'inactive'
over a broad frequency range during this time.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:12:30 GMT""}]","2020-07-08"
"2006.08663","Baoyi Chen","Baoyi Chen, Feng-Li Lin, Bo Ning and Yanbei Chen","Constraints on low-energy effective theories from weak cosmic censorship","22 pages, 2 figures","Phys. Rev. Lett. 126 (2021) 031102","10.1103/PhysRevLett.126.031102",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the weak cosmic censorship conjecture (WCCC) for the extremal
charged black hole in possible generalizations of Einstein-Maxwell theory due
to the higher order corrections, up to fourth-derivative terms. Our derivation
is based on Wald's gedanken experiment to destroy an extremal black hole. We
find that, provided the null energy condition for the falling matter, the WCCC
is preserved for all possible generalizations. Thus, the WCCC cannot serve as a
constraint to the higher order effective theories. We also show that up to
first order variations of black hole mass and charge, WCCC is preserved for
non-rotating extremal black holes in all $n$-dimensional
diffeomorphism-covariant theories of gravity and $U(1)$ gauge field.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:12:34 GMT""},{""version"":""v2"",""created"":""Sun, 7 Mar 2021 19:28:43 GMT""}]","2021-03-09"
"2006.08664","Alexander Zhdanok","Alexander I. Zhdanok","Ergodicity conditions for general Markov chains in terms of invariant
  finitely additive measures","34 pages, in Russian",,,,"math.PR math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider general Markov chains with discrete time in an arbitrary
measurable (phase) space and homogeneous in time. Markov chains are defined by
the classical transition function which within the framework of the operator
treatment generates a conjugate pair of linear Markov operators in the Banach
space of measurable bounded functions and in the Banach space of bounded finite
additive measures. It is proved that the well-known Doeblin condition $ (D) $
of ergodicity (quasi\-compactness) of the Markov chain is equivalent to the
condition $ (*) $: all finitely additive invariant measures of the Markov
operator are countably additive i.e. there are no invariant purely finitely
additive measures. Under some assumptions, it is proved that the conditions $
(D) $ and $ (*) $ are also equivalent to the condition $ (**) $: the set of
invariant finitely additive measures of a Markov operator is
finite-dimensional. Ergodic theorems are given.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:13:34 GMT""}]","2020-06-17"
"2006.08665","Lucas Porth","Lucas Porth, Robert E. Smith, Patrick Simon, Laura Marian, Stefan
  Hilbert","Fast estimation of aperture-mass statistics I: aperture mass variance
  and an application to the CFHTLenS data","26 pages, 15 figures. Submitted to MNRAS, comments welcome. v2:
  updated MNRAS template",,"10.1093/mnras/staa2900",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore an alternative method to the usual shear correlation function
approach for the estimation of aperture mass statistics in weak lensing survey
data. Our approach builds on the direct estimator method of Schneider (1998).
In this paper, to test and validate the methodology, we focus on the aperture
mass dispersion. After computing the signal and noise for a weighted set of
measured ellipticites we show how the direct estimator can be made into a
linear order algorithm that enables a fast and efficient computation. We then
investigate the applicability of the direct estimator approach in the presence
of a real survey mask with holes and chip gaps. For this we use a large
ensemble of full ray-tracing mock simulations. By using various weighting
schemes for combining information from different apertures we find that inverse
variance weighting the individual aperture estimates with an aperture
completeness greater than 70 per cent coverage yields an answer that is in
close agreement with the standard correlation function approach. We then apply
this approach to the CFHTLenS as pilot scheme and find that our method recovers
to high accuracy the Kilbinger (2013) result for the variance of both the E and
B mode signal, after we correct the catalogue for the shear bias in the lensfit
algorithm for pairs closer than 9"". We then explore the cosmological
information content of the direct estimator using the Fisher information
approach. We show that there is a only modest loss in cosmological information
from the rejection of apertures that are of low completeness. This method
unlocks the door to fast and efficient methods for recovering higher order
aperture mass statistics in linear order operations.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:14:39 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 11:11:58 GMT""}]","2020-09-30"
"2006.08666","Shuvra Bhattacharyya","Adrian Sapio, Shuvra S. Bhattacharyya, Marilyn Wolf","Runtime Adaptation in Wireless Sensor Nodes Using Structured Learning",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Markov Decision Processes (MDPs) provide important capabilities for
facilitating the dynamic adaptation and self-optimization of cyber physical
systems at runtime. In recent years, this has primarily taken the form of
Reinforcement Learning (RL) techniques that eliminate some MDP components for
the purpose of reducing computational requirements. In this work, we show that
recent advancements in Compact MDP Models (CMMs) provide sufficient cause to
question this trend when designing wireless sensor network nodes. In this work,
a novel CMM-based approach to designing self-aware wireless sensor nodes is
presented and compared to Q-Learning, a popular RL technique. We show that a
certain class of CPS nodes is not well served by RL methods, and contrast RL
versus CMM methods in this context. Through both simulation and a prototype
implementation, we demonstrate that CMM methods can provide significantly
better runtime adaptation performance relative to Q-Learning, with comparable
resource requirements.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:14:52 GMT""}]","2020-06-17"
"2006.08667","Benjamin Grimmer","Benjamin Grimmer, Haihao Lu, Pratik Worah, Vahab Mirrokni","The Landscape of the Proximal Point Method for Nonconvex-Nonconcave
  Minimax Optimization","Notably updated version that connects our theory with that of Attouch
  and Wets from the 80s and notably expands on our first posting to apply to
  generic minimax problems (rather than requiring bilinear interaction)",,,,"math.OC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Minimax optimization has become a central tool in machine learning with
applications in robust optimization, reinforcement learning, GANs, etc. These
applications are often nonconvex-nonconcave, but the existing theory is unable
to identify and deal with the fundamental difficulties this poses. In this
paper, we study the classic proximal point method (PPM) applied to
nonconvex-nonconcave minimax problems. We find that a classic generalization of
the Moreau envelope by Attouch and Wets provides key insights. Critically, we
show this envelope not only smooths the objective but can convexify and
concavify it based on the level of interaction present between the minimizing
and maximizing variables. From this, we identify three distinct regions of
nonconvex-nonconcave problems. When interaction is sufficiently strong, we
derive global linear convergence guarantees. Conversely when the interaction is
fairly weak, we derive local linear convergence guarantees with a proper
initialization. Between these two settings, we show that PPM may diverge or
converge to a limit cycle.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:17:00 GMT""},{""version"":""v2"",""created"":""Mon, 28 Dec 2020 02:40:49 GMT""},{""version"":""v3"",""created"":""Thu, 1 Apr 2021 16:31:07 GMT""}]","2021-04-02"
"2006.08668","Hendrik Molter","Sebastian Bu{\ss}, Hendrik Molter, Rolf Niedermeier, Maciej Rymar","Algorithmic Aspects of Temporal Betweenness",,,,,"cs.DS cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The betweenness centrality of a graph vertex measures how often this vertex
is visited on shortest paths between other vertices of the graph. In the
analysis of many real-world graphs or networks, betweenness centrality of a
vertex is used as an indicator for its relative importance in the network. In
particular, it is among the most popular tools in social network analysis. In
recent years, a growing number of real-world networks is modeled as temporal
graphs, where we have a fixed set of vertices and there is a finite discrete
set of time steps and every edge might be present only at some time steps.
While shortest paths are straightforward to define in static graphs, temporal
paths can be considered ""optimal"" with respect to many different criteria,
including length, arrival time, and overall travel time (shortest, foremost,
and fastest paths). This leads to different concepts of temporal betweenness
centrality and we provide a systematic study of temporal betweenness variants
based on various concepts of optimal temporal paths. Computing the betweenness
centrality for vertices in a graph is closely related to counting the number of
optimal paths between vertex pairs. We show that counting foremost and fastest
paths is computationally intractable (#P-hard) and hence the computation of the
corresponding temporal betweenness values is intractable as well. For shortest
paths and two selected special cases of foremost paths, we devise
polynomial-time algorithms for temporal betweenness computation. Moreover, we
also explore the distinction between strict (ascending time labels) and
non-strict (non-descending time labels) time labels in temporal paths. In our
experiments with established real-world temporal networks, we demonstrate the
practical effectiveness of our algorithms, compare the various betweenness
concepts, and derive recommendations on their practical use.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:17:30 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 13:30:03 GMT""}]","2021-04-09"
"2006.08669","Reza Shokri","Hongyan Chang, Ta Duy Nguyen, Sasi Kumar Murakonda, Ehsan Kazemi, Reza
  Shokri","On Adversarial Bias and the Robustness of Fair Machine Learning",,,,,"stat.ML cs.CR cs.CY cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimizing prediction accuracy can come at the expense of fairness. Towards
minimizing discrimination against a group, fair machine learning algorithms
strive to equalize the behavior of a model across different groups, by imposing
a fairness constraint on models. However, we show that giving the same
importance to groups of different sizes and distributions, to counteract the
effect of bias in training data, can be in conflict with robustness. We analyze
data poisoning attacks against group-based fair machine learning, with the
focus on equalized odds. An adversary who can control sampling or labeling for
a fraction of training data, can reduce the test accuracy significantly beyond
what he can achieve on unconstrained models. Adversarial sampling and
adversarial labeling attacks can also worsen the model's fairness gap on test
data, even though the model satisfies the fairness constraint on training data.
We analyze the robustness of fair machine learning through an empirical
evaluation of attacks on multiple algorithms and benchmark datasets.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:17:44 GMT""}]","2020-06-17"
"2006.08670","Anna Pearson","A.N. Pearson, Y. Guryanova, P. Erker, E.A. Laird, G.A.D. Briggs, M.
  Huber and N. Ares","Measuring the thermodynamic cost of timekeeping",,"Phys. Rev. X 11, 021029 (2021)","10.1103/PhysRevX.11.021029",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  All clocks, in some form or another, use the evolution of nature towards
higher entropy states to quantify the passage of time. Due to the statistical
nature of the second law and corresponding entropy flows, fluctuations
fundamentally limit the performance of any clock. This suggests a deep relation
between the increase in entropy and the quality of clock ticks. Indeed, minimal
models for autonomous clocks in the quantum realm revealed that a linear
relation can be derived, where for a limited regime every bit of entropy
linearly increases the accuracy of quantum clocks. But can such a linear
relation persist as we move towards a more classical system? We answer this in
the affirmative by presenting the first experimental investigation of this
thermodynamic relation in a nanoscale clock. We stochastically drive a
nanometer-thick membrane and read out its displacement with a radio-frequency
cavity, allowing us to identify the ticks of a clock. We show theoretically
that the maximum possible accuracy for this classical clock is proportional to
the entropy created per tick, similar to the known limit for a weakly coupled
quantum clock but with a different proportionality constant. We measure both
the accuracy and the entropy. Once non-thermal noise is accounted for, we find
that there is a linear relation between accuracy and entropy and that the clock
operates within an order of magnitude of the theoretical bound.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:17:44 GMT""}]","2021-05-12"
"2006.08671","Sinong Wang","Sinong Wang, Madian Khabsa, Hao Ma","To Pretrain or Not to Pretrain: Examining the Benefits of Pretraining on
  Resource Rich Tasks","Accepted in ACL2020",,,,"cs.CL cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pretraining NLP models with variants of Masked Language Model (MLM)
objectives has recently led to a significant improvements on many tasks. This
paper examines the benefits of pretrained models as a function of the number of
training samples used in the downstream task. On several text classification
tasks, we show that as the number of training examples grow into the millions,
the accuracy gap between finetuning BERT-based model and training vanilla LSTM
from scratch narrows to within 1%. Our findings indicate that MLM-based models
might reach a diminishing return point as the supervised data size increases
significantly.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:18:59 GMT""}]","2020-06-17"
"2006.08672","Ingrid Nunes","Ingrid Nunes and Dietmar Jannach","A systematic review and taxonomy of explanations in decision support and
  recommender systems",,"User Modeling and User-Adapted Interaction, 27 (3-5), 393-444
  (2017)","10.1007/s11257-017-9195-0",,"cs.AI cs.IR","http://creativecommons.org/licenses/by/4.0/","  With the recent advances in the field of artificial intelligence, an
increasing number of decision-making tasks are delegated to software systems. A
key requirement for the success and adoption of such systems is that users must
trust system choices or even fully automated decisions. To achieve this,
explanation facilities have been widely investigated as a means of establishing
trust in these systems since the early years of expert systems. With today's
increasingly sophisticated machine learning algorithms, new challenges in the
context of explanations, accountability, and trust towards such systems
constantly arise. In this work, we systematically review the literature on
explanations in advice-giving systems. This is a family of systems that
includes recommender systems, which is one of the most successful classes of
advice-giving software in practice. We investigate the purposes of explanations
as well as how they are generated, presented to users, and evaluated. As a
result, we derive a novel comprehensive taxonomy of aspects to be considered
when designing explanation facilities for current and future decision support
systems. The taxonomy includes a variety of different facets, such as
explanation objective, responsiveness, content and presentation. Moreover, we
identified several challenges that remain unaddressed so far, for example
related to fine-grained issues associated with the presentation of explanations
and how explanation facilities are evaluated.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:19:20 GMT""}]","2020-06-17"
"2006.08673","Luke Causer","Luke Causer, Igor Lesanovsky, Mari Carmen Ba\~nuls, Juan P. Garrahan","Dynamics and large deviation transitions of the XOR-Fredrickson-Andersen
  kinetically constrained model","13+2 pages, 7+1 figures",,"10.1103/PhysRevE.102.052132",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a one-dimensional classical stochastic kinetically constrained model
(KCM) inspired by Rydberg atoms in their ""facilitated"" regime, where sites can
flip only if a single of their nearest neighbours is excited. We call this
model ""XOR-FA"" to distinguish it from the standard Fredrickson-Andersen (FA)
model. We describe the dynamics of the XOR-FA model, including its relation to
simple exclusion processes in its domain wall representation. The interesting
relaxation dynamics of the XOR-FA is related to the prominence of large
dynamical fluctuations that lead to phase transitions between active and
inactive dynamical phases as in other KCMs. By means of numerical tensor
network methods we study in detail such transitions in the dynamical large
deviation regime.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:20:25 GMT""},{""version"":""v2"",""created"":""Tue, 18 Aug 2020 08:33:19 GMT""},{""version"":""v3"",""created"":""Wed, 4 Nov 2020 16:21:58 GMT""}]","2020-11-26"
"2006.08674","Vasilios Zarikas","Vasilios Zarikas and Georgios Kofinas","Singularities and Phenomenological aspects of Asymptotic Safe Gravity",,"Journal of Physics: Conference Series, Volume 1051, XX
  International Meeting ""Physical Interpretations of Relativity Theory 2017""
  3-6 July 2017, Moscow, Russian Federation","10.1088/1742-6596/1051/1/012028",,"gr-qc astro-ph.CO hep-ph hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  Asymptotic Safety (AS) Program for quantum gravity keeps the same fields and
symmetries with General Relativity and studies the associated gravitational
action as a fundamental part of the complete theory at the nonperturbative
level with the help of functional renormalization group (RG) techniques. An
important phenomenological task that can test the new point of view of AS
approach is the discovery of RG improved cosmologies and black holes. In this
work, we analyze the properties of recently found non-singular spherically
symmetric and non-singular cosmological solutions. Furthermore, we derive a
novel consistent set of modified Einstein field equations, in the spirit of AS,
which respects the Bianchi identities. This new set of equations extend
previously published modified Einstein equations which arise by adding
appropriate covariant kinetic terms to the action.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:20:34 GMT""}]","2020-06-17"
"2006.08675","Chi Zhang","Chi Zhang, Jennifer Ahern, Mark J. van der Laan","Targeted Maximum Likelihood Estimation of Community-based Causal Effect
  of Community-Level Stochastic Interventions","20 pages. arXiv admin note: substantial text overlap with
  arXiv:2006.08553",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  Unlike the commonly used parametric regression models such as mixed models,
that can easily violate the required statistical assumptions and result in
invalid statistical inference, target maximum likelihood estimation allows more
realistic data-generative models and provides double-robust, semi-parametric
and efficient estimators. Target maximum likelihood estimators (TMLEs) for the
causal effect of a community-level static exposure were previously proposed by
Balzer et al. In this manuscript, we build on this work and present
identifiability results and develop two semi-parametric efficient TMLEs for the
estimation of the causal effect of the single time-point community-level
stochastic intervention whose assignment mechanism can depend on measured and
unmeasured environmental factors and its individual-level covariates. The first
community-level TMLE is developed under a general hierarchical non-parametric
structural equation model, which can incorporate pooled individual-level
regressions for estimating the outcome mechanism. The second individual-level
TMLE is developed under a restricted hierarchical model in which the additional
assumption of no covariate interference within communities holds. The proposed
TMLEs have several crucial advantages. First, both TMLEs can make use of
individual level data in the hierarchical setting, and potentially reduce
finite sample bias and improve estimator efficiency. Second, the stochastic
intervention framework provides a natural way for defining and estimating
casual effects where the exposure variables are continuous or discrete with
multiple levels, or even cannot be directly intervened on. Also, the positivity
assumption needed for our proposed causal parameters can be weaker than the
version of positivity required for other casual parameters.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:22:38 GMT""}]","2020-06-17"
"2006.08676","Astrid Ordell","Astrid Ordell, Roman Pasechnik and Hugo Ser\^odio","Anomaly-free 2HDMs with a gauged abelian symmetry and two generations of
  right-handed neutrinos","14 pages, 5 figures, 3 tables","Phys. Rev. D 102, 035016 (2020)","10.1103/PhysRevD.102.035016","LU-TP 20-28","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the popularity of two-Higgs-doublet models (2HDMs) with a gauged
abelian flavor symmetry, the allowed Yukawa textures have only been partly
explored so far. In this work, we classify and compare every anomaly-free
instance, in the case of having two generations of right-handed neutrinos and a
type-I seesaw mechanism. We found 16 valid implementations in total, out of
which 11 agree well with current experimental bounds. To our knowledge, neither
of these models have been considered previously.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:23:00 GMT""},{""version"":""v2"",""created"":""Tue, 18 Aug 2020 12:49:14 GMT""}]","2020-08-19"
"2006.08677","Nicol\'as Matte Bon","Adrien Le Boudec, Nicol\'as Matte Bon","A commutator lemma for confined subgroups and applications to groups
  acting on rooted trees","48 pages. v1->v2: minor revision",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A subgroup $H$ of a group $G$ is confined if the $G$-orbit of $H$ under
conjugation is bounded away from the trivial subgroup in the space
$\operatorname{Sub}(G)$ of subgroups of $G$. We prove a commutator lemma for
confined subgroups. For groups of homeomorphisms, this provides the exact
analogue for confined subgroups (hence in particular for URSs) of the classical
commutator lemma for normal subgroups: if $G$ is a group of homeomorphisms of a
Hausdorff space $X$ and $H$ is a confined subgroup of $G$, then $H$ contains
the derived subgroup of the rigid stabilizer of some open subset of $X$. We
apply this commutator lemma to the study of URSs and actions on compact spaces
of groups acting on rooted trees. We prove a theorem describing the structure
of URSs of weakly branch groups and of their non-topologically free minimal
actions. Among the applications of these results, we show: 1) if $G$ is a
finitely generated branch group, the $G$-action on $\partial T$ has the
smallest possible orbital growth among all faithful $G$-actions; 2) if $G$ is a
finitely generated branch group, then every embedding from $G$ into a group of
homeomorphisms of strongly bounded type (e.g. a bounded automaton group) must
be spatially realized; 3) if $G$ is a finitely generated weakly branch group,
then $G$ does not embed into the group IET of interval exchange
transformations.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:24:06 GMT""},{""version"":""v2"",""created"":""Tue, 8 Dec 2020 09:56:40 GMT""}]","2020-12-09"
"2006.08678","Alexandre Vazdekis","A. Vazdekis, P. Rodr\'iguez-Beltr\'an, M. Cervi\~no, M. Montes, I.
  Mart\'in-Navarro, M.B. Beasley","Surface Brightness Fluctuations for constraining the chemical enrichment
  of massive galaxies","Proceedings of the IAU Symposium No. 359: Galaxy evolution and
  feedback across different environments. Editors: T. Storchi-Bergmann, R.
  Overzier, W. Forman & R. Riffel",,"10.1017/S1743921320001702",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on very deep photometry, Surface Brightness Fluctuations (SBF) have
been traditionally used to determine galaxy distances. We have recently
computed SBF spectra of stellar populations at moderately high resolution,
which are fully based on empirical stars. We show that the SBF spectra provide
an unprecedented potential for stellar population studies that, so far, have
been tackled on the basis of the mean fluxes. We find that the SBFs are able to
unveil metal-poor stellar components at the one percent level, which are not
possible to disentangle with the standard analysis. As these metal-poor
components correspond to the first stages of the chemical enrichment, the SBF
analysis provides stringent constrains on the quenching epoch.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:28:00 GMT""}]","2021-04-07"
"2006.08679","Justin Shenk","Mats L. Richter and Justin Shenk and Wolf Byttner and Anders Arpteg
  and Mikael Huss","Feature Space Saturation during Training","45 pages, 41 figures; author order changed in v5 to reflect
  additional contribution; for code see http://github.com/MLRichter/phd-lab and
  http://github.com/delve-team/delve","British Machine Vision Conference (BMVC) 2021",,,"cs.LG cs.CV cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose layer saturation - a simple, online-computable method for
analyzing the information processing in neural networks. First, we show that a
layer's output can be restricted to the eigenspace of its variance matrix
without performance loss. We propose a computationally lightweight method for
approximating the variance matrix during training. From the dimension of its
lossless eigenspace we derive layer saturation - the ratio between the
eigenspace dimension and layer width. We show that saturation seems to indicate
which layers contribute to network performance. We demonstrate how to alter
layer saturation in a neural network by changing network depth, filter sizes
and input resolution. Furthermore, we show that well-chosen input resolution
increases network performance by distributing the inference process more evenly
across the network.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:28:21 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 15:07:19 GMT""},{""version"":""v3"",""created"":""Thu, 18 Jun 2020 09:24:39 GMT""},{""version"":""v4"",""created"":""Fri, 13 Nov 2020 19:17:39 GMT""},{""version"":""v5"",""created"":""Mon, 22 Nov 2021 14:11:35 GMT""}]","2021-11-23"
"2006.08680","Jeff Z. HaoChen","Jeff Z. HaoChen, Colin Wei, Jason D. Lee, Tengyu Ma","Shape Matters: Understanding the Implicit Bias of the Noise Covariance",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The noise in stochastic gradient descent (SGD) provides a crucial implicit
regularization effect for training overparameterized models. Prior theoretical
work largely focuses on spherical Gaussian noise, whereas empirical studies
demonstrate the phenomenon that parameter-dependent noise -- induced by
mini-batches or label perturbation -- is far more effective than Gaussian
noise. This paper theoretically characterizes this phenomenon on a
quadratically-parameterized model introduced by Vaskevicius et el. and
Woodworth et el. We show that in an over-parameterized setting, SGD with label
noise recovers the sparse ground-truth with an arbitrary initialization,
whereas SGD with Gaussian noise or gradient descent overfits to dense solutions
with large norms. Our analysis reveals that parameter-dependent noise
introduces a bias towards local minima with smaller noise variance, whereas
spherical Gaussian noise does not. Code for our project is publicly available.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:31:02 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 03:34:08 GMT""}]","2020-06-19"
"2006.08681","Laura Lopez","H\'ector Mart\'inez-Rodr\'iguez, Laura A. Lopez, Katie Auchettl,
  Carles Badenes, Tyler Holland-Ashford, Daniel J. Patnaude, Shiu-Hang Lee,
  Adam R. Foster, Patrick O. Slane","Evidence of a Type Ia Progenitor for Supernova Remnant 3C 397","9 pages, 4 figures, submitted to MNRAS",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The explosive origin of the young supernova remnant (SNR) 3C 397 (G41.1-0.3)
is debated. Its elongated morphology and proximity to a molecular cloud are
suggestive of a core-collapse (CC) SN origin, yet recent X-ray studies of heavy
metals show chemical yields and line centroid energies consistent with a Type
Ia SN. In this paper, we analyze the full X-ray spectrum from 0.7-10 keV of 3C
397 observed with Suzaku and compare the line centroid energies, fluxes, and
elemental abundances of intermediate-mass and heavy metals (Mg to Ni) to Type
Ia and CC hydrodynamical model predictions. Based on the results, we conclude
that 3C 397 likely arises from an energetic Type Ia explosion in a high-density
ambient medium, and we show that the progenitor was a near Chandrasekhar mass
white dwarf.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:32:12 GMT""}]","2020-06-17"
"2006.08682","David Byrd","David Byrd, Sruthi Palaparthi, Maria Hybinette, Tucker Hybinette Balch","The Importance of Low Latency to Order Book Imbalance Trading Strategies",,,,,"q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a pervasive assumption that low latency access to an exchange is a
key factor in the profitability of many high-frequency trading strategies. This
belief is evidenced by the ""arms race"" undertaken by certain financial firms to
co-locate with exchange servers. To the best of our knowledge, our study is the
first to validate and quantify this assumption in a continuous double auction
market with a single exchange similar to the New York Stock Exchange. It is not
feasible to conduct this exploration with historical data in which trader
identity and location are not reported. Accordingly, we investigate the
relationship between latency of access to order book information and
profitability of trading strategies exploiting that information with an
agent-based interactive discrete event simulation in which thousands of agents
pursue archetypal trading strategies. We introduce experimental traders
pursuing a low-latency order book imbalance (OBI) strategy in a controlled
manner across thousands of simulated trading days, and analyze OBI trader
profit while varying distance (latency) from the exchange. Our experiments
support that latency is inversely related to profit for the OBI traders, but
more interestingly show that latency rank, rather than absolute magnitude, is
the key factor in allocating returns among agents pursuing a similar strategy.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:34:04 GMT""}]","2020-06-17"
"2006.08683","Javad Shabani","Kasra Sardashti, Matthieu C. Dartiailh, Joseph Yuan, Sean Hart, Patryk
  Gumann, Javad Shabani","Voltage-tunable superconducting resonators: a platform for random access
  quantum memory",,"IEEE Transactions on Quantum Engineering, vol. 1, pp. 1-7, 2020,
  Art no. 5502107","10.1109/TQE.2020.3034553",,"quant-ph physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In quantum computing architectures, one important factor is the trade-off
between the need to couple qubits to each other and to an external drive and
the need to isolate them well enough in order to protect the information for an
extended period of time. In the case of superconducting circuits, one approach
is to utilize fixed frequency qubits coupled to coplanar waveguide resonators
such that the system can be kept in a configuration that is relatively
insensitive to noise. Here, we propose a scalable voltage-tunable quantum
memory (QuMem) design concept compatible with superconducting qubit platforms.
Our design builds on the recent progress in fabrication of Josephson field
effect transistors (JJ-FETs) which use InAs quantum wells. The JJ-FET is
incorporated into a tunable coupler between a transmission line and a
high-quality resonator in order to control the overall inductance of the
coupler. A full isolation of the high-quality resonator can be achieved by
turning off the JJ-FET. This could allow for long coherence times and
protection of the quantum information inside the storage cavity. The proposed
design would facilitate the implementation of random access memory for storage
of quantum information in between computational gate operations.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:34:42 GMT""}]","2021-01-29"
"2006.08684","Sebastian Curi","Sebastian Curi, Felix Berkenkamp, Andreas Krause","Efficient Model-Based Reinforcement Learning through Optimistic Policy
  Search and Planning",,,,,"cs.LG cs.RO cs.SY eess.SY stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model-based reinforcement learning algorithms with probabilistic dynamical
models are amongst the most data-efficient learning methods. This is often
attributed to their ability to distinguish between epistemic and aleatoric
uncertainty. However, while most algorithms distinguish these two uncertainties
for learning the model, they ignore it when optimizing the policy, which leads
to greedy and insufficient exploration. At the same time, there are no
practical solvers for optimistic exploration algorithms. In this paper, we
propose a practical optimistic exploration algorithm (H-UCRL). H-UCRL
reparameterizes the set of plausible models and hallucinates control directly
on the epistemic uncertainty. By augmenting the input space with the
hallucinated inputs, H-UCRL can be solved using standard greedy planners.
Furthermore, we analyze H-UCRL and construct a general regret bound for
well-calibrated models, which is provably sublinear in the case of Gaussian
Process models. Based on this theoretical foundation, we show how optimistic
exploration can be easily combined with state-of-the-art reinforcement learning
algorithms and different probabilistic models. Our experiments demonstrate that
optimistic exploration significantly speeds-up learning when there are
penalties on actions, a setting that is notoriously difficult for existing
model-based reinforcement learning algorithms.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:37:38 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 11:52:34 GMT""},{""version"":""v3"",""created"":""Tue, 1 Dec 2020 17:35:07 GMT""}]","2020-12-02"
"2006.08685","Rudrajit Banerjee","R. Banerjee and M. Niedermaier","Bonus Properties of States of Low Energy","57 pages, 1 figure","J. Math. Phys. 61 (2020) 103511","10.1063/5.0019311",,"math-ph gr-qc hep-th math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  States of Low Energy (SLE) are exact Hadamard states defined on arbitrary
Friedmann-Lema\^{i}tre spacetimes. They are constructed from a fiducial state
by minimizing the Hamiltonian's expectation value after averaging with a
temporal window function. We show the SLE to be expressible solely in terms of
the (state independent) commutator function. They also admit a convergent
series expansion in powers of the spatial momentum, both for massive and for
massless theories. In the massless case the leading infrared behavior is found
to be Minkowski-like for all scale factors. This provides a new cure for the
infrared divergences in Friedmann-Lema\^{i}tre spacetimes with accelerated
expansion. In consequence, massless SLE are viable candidates for
pre-inflationary vacua and in a soluble model are shown to entail a
qualitatively correct primordial power spectrum.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:38:52 GMT""},{""version"":""v2"",""created"":""Tue, 27 Oct 2020 17:10:43 GMT""}]","2020-10-28"
"2006.08686","Nicholas Trieu","Nicholas Trieu, Sebastian Goodman, Pradyumna Narayana, Kazoo Sone,
  Radu Soricut","Multi-Image Summarization: Textual Summary from a Set of Cohesive Images","9 pages, 5 figures",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-sentence summarization is a well studied problem in NLP, while
generating image descriptions for a single image is a well studied problem in
Computer Vision. However, for applications such as image cluster labeling or
web page summarization, summarizing a set of images is also a useful and
challenging task. This paper proposes the new task of multi-image
summarization, which aims to generate a concise and descriptive textual summary
given a coherent set of input images. We propose a model that extends the
image-captioning Transformer-based architecture for single image to
multi-image. A dense average image feature aggregation network allows the model
to focus on a coherent subset of attributes across the input images. We explore
various input representations to the Transformer network and empirically show
that aggregated image features are superior to individual image embeddings. We
additionally show that the performance of the model is further improved by
pretraining the model parameters on a single-image captioning task, which
appears to be particularly effective in eliminating hallucinations in the
output.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:45:35 GMT""}]","2020-06-17"
"2006.08687","Felix Sharipov","Felix Sharipov and Victor J. Benites","Transport coefficients of multi-component mixtures of noble gases based
  on ab initio potentials. Viscosity and thermal conductivity",,,"10.1063/5.0016261",,"physics.comp-ph physics.chem-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The viscosity and thermal conductivity of binary, ternary and quaternary
mixtures of helium, neon, argon, and krypton at low density are computed for
wide ranges of temperature and molar fractions, applying the Chapman-Enskog
method. Ab initio interatomic potentials are employed in order to calculate the
omega-integrals. The relative numerical errors of the viscosity and thermal
conductivity do not exceed 1.e-6 and 1.e-5, respectively. The relative
uncertainty related to the interatomic potential is about 0.1%. A comparison of
the present data with results reported in other papers available in the
literature shows a significant improvement of accuracy of the transport
coefficients considered here.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:50:21 GMT""}]","2020-07-24"
"2006.08688","Ke Yang","Ke Yang, Joshua R. Loftus, Julia Stoyanovich","Causal intersectionality for fair ranking",,,,,"cs.LG cs.AI stat.AP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose a causal modeling approach to intersectional
fairness, and a flexible, task-specific method for computing intersectionally
fair rankings. Rankings are used in many contexts, ranging from Web search
results to college admissions, but causal inference for fair rankings has
received limited attention. Additionally, the growing literature on causal
fairness has directed little attention to intersectionality. By bringing these
issues together in a formal causal framework we make the application of
intersectionality in fair machine learning explicit, connected to important
real world effects and domain knowledge, and transparent about technical
limitations. We experimentally evaluate our approach on real and synthetic
datasets, exploring its behaviour under different structural assumptions.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:57:46 GMT""}]","2020-06-17"
"2006.08689","Shengxue He Dr.","Shengxue He","Identify the Optimal Locations of Dedicated Bus Lanes to Improve the
  Stability of Bus Line",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bus bunching and unevenly dispersed buses along a bus line lead to a low
service level and deteriorate the operational stability of the bus line. Speed
adjustment as a control means has been proposed to solve the above problem. But
due to the difficulty of adjusting speed in the mixed traffic and the
discontinuously distributed dedicated bus lanes (DBLs) in a bus line, the
existing methods which coordinate or adjust bus speeds in all road segments
encounter serious obstacles in practice. To overcome the above problem, we
first take into account the influence of the deployment of the DBLs along a bus
line on the performance of the speed adjustment strategy. With the funding
limit and the maximally allowable influence on other road traffic as main
constraints, a nonlinear mixed integer stochastic mathematic model is
formulated aiming at improving the whole stability of the bus line operation.
The model can be effectively solved by a newly designed branch and bound
algorithm. The optimal regulating speed in a DBL is determined with a process
of looking multiple critical time point ahead. Numerical experiment verified
the effectiveness and efficiency of our new method. Three findings were
obtained as follows. To determine the optimal regulating speed, the number of
the critical time points to be looked ahead should not be too big. Increasing
the number of DBLs improves the stability of a bus line. The more evenly DBLs
are distributed along the bus line, the greater the stability of the bus line
will be.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:58:43 GMT""}]","2020-06-17"
"2006.08690","Chudi Zhong","Jimmy Lin, Chudi Zhong, Diane Hu, Cynthia Rudin, Margo Seltzer","Generalized and Scalable Optimal Sparse Decision Trees","This paper was published in ICML 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decision tree optimization is notoriously difficult from a computational
perspective but essential for the field of interpretable machine learning.
Despite efforts over the past 40 years, only recently have optimization
breakthroughs been made that have allowed practical algorithms to find optimal
decision trees. These new techniques have the potential to trigger a paradigm
shift where it is possible to construct sparse decision trees to efficiently
optimize a variety of objective functions without relying on greedy splitting
and pruning heuristics that often lead to suboptimal solutions. The
contribution in this work is to provide a general framework for decision tree
optimization that addresses the two significant open problems in the area:
treatment of imbalanced data and fully optimizing over continuous variables. We
present techniques that produce optimal decision trees over a variety of
objectives including F-score, AUC, and partial area under the ROC convex hull.
We also introduce a scalable algorithm that produces provably optimal results
in the presence of continuous variables and speeds up decision tree
construction by several orders of magnitude relative to the state-of-the art.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:00:11 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jul 2020 04:18:56 GMT""},{""version"":""v3"",""created"":""Tue, 11 Aug 2020 03:51:29 GMT""},{""version"":""v4"",""created"":""Tue, 22 Nov 2022 22:43:25 GMT""}]","2022-11-24"
"2006.08691","Elif K\""oksal Ers\""oz","Elif K\""oksal Ers\""oz, Julien Modolo, Fabrice Bartolomei, Fabrice
  Wendling","Neural mass modeling of slow-fast dynamics of seizure initiation and
  abortion",,,"10.1371/journal.pcbi.1008430",,"q-bio.NC math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Epilepsy is a dynamic and complex neurological disease affecting about 1% of
the worldwide population, among which 30% of the patients are drug-resistant.
Epilepsy is characterized by recurrent episodes of paroxysmal neural discharges
(the so-called seizures), which manifest themselves through a large-amplitude
rhythmic activity observed in depth-EEG recordings, in particular in local
field potentials (LFPs). The signature characterizing the transition to
seizures involves complex oscillatory patterns, which could serve as a marker
to prevent seizure initiation by triggering appropriate therapeutic
neurostimulation methods. To investigate such protocols, neurophysiological
lumped-parameter models at the mesoscopic scale, namely neural mass models, are
powerful tools that not only mimic the LFP signals but also give insights on
the neural mechanisms related to different stages of seizures. Here, we analyze
the multiple time-scale dynamics of a neural mass model and explain the
underlying structure of the complex oscillations observed before seizure
initiation. We investigate population-specific effects of the stimulation and
the dependence of stimulation parameters on synaptic timescales. In particular,
we show that intermediate stimulation frequencies (>20 Hz) can abort seizures
if the timescale difference is pronounced. Those results have the potential in
the design of therapeutic brain stimulation protocols based on the
neurophysiological properties of tissue.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:00:15 GMT""}]","2021-01-27"
"2006.08692","David Kimsey","David P. Kimsey","On a minimal solution for the indefinite truncated multidimensional
  moment problem",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We will consider the indefinite truncated multidimensional moment problem.
Necessary and sufficient conditions for a given truncated multisequence to have
a signed representing measure $\mu$ with ${\rm card}\,{\rm supp}\, \mu$ as
small as possible are given by the existence of a rank preserving extension of
a multivariate Hankel matrix (built from the given truncated multisequence)
such that the corresponding associated polynomial ideal is real radical. This
result is a special case of a more general characterisation of truncated
multisequences with a minimal complex representing measure whose support is
symmetric with respect to complex conjugation (which we will call {\it
quasi-complex}). One motivation for our results is the fact that positive
semidefinite truncated multisequence need not have a positive representing
measure. Thus, our main result gives the potential for computing a signed
representing measure $\mu = \mu_+ - \mu_-$, where ${\rm card} \,\mu_-$ is
small. We illustrate this point on concrete examples.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:00:38 GMT""}]","2020-06-17"
"2006.08693","Jorge Bellor\'in","Jorge Bellorin, Claudio Borquez and Byron Droguett","Curvature vs degrees of freedom: The case of the critical 2+1 Horava
  theory","We have included the results of this paper in another work with a
  different focusing",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the interesting case of the 2+1 nonprojectable Horava theory
formulated at the critical point, where it does not posses local degrees of
freedom. The critical point is defined by the value of a coupling constant of
the theory. We discuss how, in spite of the absence of degrees of freedom, the
theory admits solutions with nonflat or nonconstant curvature. We consider the
theory without cosmological constant and without terms of higher order
derivatives, hence this is an effect that can be seen at the same order of 2+1
general relativity. We present an exact nonflat solution that is not
asymptotically flat. The presence of solutions with nontrivial curvature seems
to be related to the relaxing of the asymptotically flat condition. We discuss
that there is no analogue of Newtonian potential in this theory, and a broad
class of asymptotically flat geometries leads to the restriction that the only
solutions that can be found among them are the flat ones.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:04:55 GMT""},{""version"":""v2"",""created"":""Fri, 28 Aug 2020 21:53:10 GMT""}]","2020-09-01"
"2006.08694","Gulcin Baykal","Gulcin Baykal, Gozde Unal","DeshuffleGAN: A Self-Supervised GAN to Improve Structure Learning","Accepted at ICIP 2020",,"10.1109/ICIP40778.2020.9190774",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative Adversarial Networks (GANs) triggered an increased interest in
problem of image generation due to their improved output image quality and
versatility for expansion towards new methods. Numerous GAN-based works attempt
to improve generation by architectural and loss-based extensions. We argue that
one of the crucial points to improve the GAN performance in terms of realism
and similarity to the original data distribution is to be able to provide the
model with a capability to learn the spatial structure in data. To that end, we
propose the DeshuffleGAN to enhance the learning of the discriminator and the
generator, via a self-supervision approach. Specifically, we introduce a
deshuffling task that solves a puzzle of randomly shuffled image tiles, which
in turn helps the DeshuffleGAN learn to increase its expressive capacity for
spatial structure and realistic appearance. We provide experimental evidence
for the performance improvement in generated images, compared to the baseline
methods, which is consistently observed over two different datasets.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:06:07 GMT""}]","2020-10-09"
"2006.08695","Ryan Lau","Ryan M. Lau, J.J. Eldridge, Matthew J. Hankins, Astrid Lamberts,
  Itsuki Sakon, Peredur M. Williams","Revisiting the Impact of Dust Production from Carbon-Rich Wolf-Rayet
  Binaries","34 pages, 12 figures, 7 tables, Accepted for publication in ApJ",,"10.3847/1538-4357/ab9cb5",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a dust spectral energy distribution (SED) and binary stellar
population analysis revisiting the dust production rates (DPRs) in the winds of
carbon-rich Wolf-Rayet (WC) binaries and their impact on galactic dust budgets.
DustEM SED models of 19 Galactic WC ``dustars"" reveal DPRs of
$\dot{M}_d\sim10^{-10}-10^{-6}$ M$_\odot$ yr$^{-1}$ and carbon dust
condensation fractions, $\chi_C$, between $0.002 - 40\%$. A large ($0.1 - 1.0$
$\mu$m) dust grain size composition is favored for efficient dustars where
$\chi_C\gtrsim1\%$. Results for dustars with known orbital periods verify a
power-law relation between $\chi_C$, orbital period, WC mass-loss rate, and
wind velocity consistent with predictions from theoretical models of dust
formation in colliding-wind binaries. We incorporated dust production into
Binary Population and Spectral Synthesis (BPASS) models to analyze dust
production rates from WC dustars, asymptotic giant branch stars (AGBs), red
supergiants (RSGs), and core-collapse supernovae (SNe). BPASS models assuming
constant star formation (SF) and a co-eval $10^6$ M$_\odot$ stellar population
were performed at low, Large Magellanic Cloud (LMC)-like, and solar
metallicities (Z = 0.001, 0.008, and 0.020). Both constant SF and co-eval
models show that SNe are net dust destroyers at all metallicities. Constant SF
models at LMC-like metallicities show that AGB stars slightly outproduce WC
binaries and RSGs by factors of $2-3$, whereas at solar metallicites WC
binaries are the dominant source of dust for $\sim60$ Myr until the onset of
AGBs, which match the dust input of WC binaries. Co-eval population models show
that for ""bursty"" SF, AGB stars dominate dust production at late times
($t\gtrsim 70$ Myr).
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:07:46 GMT""}]","2020-08-05"
"2006.08696","Prashant Pandey","Prashant Pandey, Aayush Kumar Tyagi, Sameer Ambekar, and Prathosh AP","Unsupervised Domain Adaptation for Semantic Segmentation of NIR Images
  through Generative Latent Search","ECCV 2020 [Spotlight]",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Segmentation of the pixels corresponding to human skin is an essential first
step in multiple applications ranging from surveillance to heart-rate
estimation from remote-photoplethysmography. However, the existing literature
considers the problem only in the visible-range of the EM-spectrum which limits
their utility in low or no light settings where the criticality of the
application is higher. To alleviate this problem, we consider the problem of
skin segmentation from the Near-infrared images. However, Deep learning based
state-of-the-art segmentation techniques demands large amounts of labelled data
that is unavailable for the current problem. Therefore we cast the skin
segmentation problem as that of target-independent Unsupervised Domain
Adaptation (UDA) where we use the data from the Red-channel of the
visible-range to develop skin segmentation algorithm on NIR images. We propose
a method for target-independent segmentation where the 'nearest-clone' of a
target image in the source domain is searched and used as a proxy in the
segmentation network trained only on the source domain. We prove the existence
of 'nearest-clone' and propose a method to find it through an optimization
algorithm over the latent space of a Deep generative model based on variational
inference. We demonstrate the efficacy of the proposed method for NIR skin
segmentation over the state-of-the-art UDA segmentation methods on the two
newly created skin segmentation datasets in NIR domain despite not having
access to the target NIR data. Additionally, we report state-of-the-art results
for adaption from Synthia to Cityscapes which is a popular setting in
Unsupervised Domain Adaptation for semantic segmentation. The code and datasets
are available at https://github.com/ambekarsameer96/GLSS.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:07:55 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jul 2020 12:07:42 GMT""}]","2020-07-20"
"2006.08697","Iacopo Poli","Am\'elie Chatelain, Elena Tommasone, Laurent Daudet, Iacopo Poli","Online Change Point Detection in Molecular Dynamics With Optical Random
  Features","15 pages, 12 figures",,,,"physics.comp-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Proteins are made of atoms constantly fluctuating, but can occasionally
undergo large-scale changes. Such transitions are of biological interest,
linking the structure of a protein to its function with a cell. Atomic-level
simulations, such as Molecular Dynamics (MD), are used to study these events.
However, molecular dynamics simulations produce time series with multiple
observables, while changes often only affect a few of them. Therefore,
detecting conformational changes has proven to be challenging for most
change-point detection algorithms. In this work, we focus on the identification
of such events given many noisy observables. In particular, we show that the
No-prior-Knowledge Exponential Weighted Moving Average (NEWMA) algorithm can be
used along optical hardware to successfully identify these changes in
real-time. Our method does not need to distinguish between the background of a
protein and the protein itself. For larger simulations, it is faster than using
traditional silicon hardware and has a lower memory footprint. This technique
may enhance the sampling of the conformational space of molecules. It may also
be used to detect change-points in other sequential data with a large number of
features.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:07:57 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 07:47:12 GMT""}]","2022-10-26"
"2006.08698","Duo Wang","Duo Wang, Mateja Jamnik, Pietro Lio","Extrapolatable Relational Reasoning With Comparators in Low-Dimensional
  Manifolds",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While modern deep neural architectures generalise well when test data is
sampled from the same distribution as training data, they fail badly for cases
when the test data distribution differs from the training distribution even
along a few dimensions. This lack of out-of-distribution generalisation is
increasingly manifested when the tasks become more abstract and complex, such
as in relational reasoning. In this paper we propose a neuroscience-inspired
inductive-biased module that can be readily amalgamated with current neural
network architectures to improve out-of-distribution (o.o.d) generalisation
performance on relational reasoning tasks. This module learns to project
high-dimensional object representations to low-dimensional manifolds for more
efficient and generalisable relational comparisons. We show that neural nets
with this inductive bias achieve considerably better o.o.d generalisation
performance for a range of relational reasoning tasks. We finally analyse the
proposed inductive bias module to understand the importance of lower dimension
projection, and propose an augmentation to the algorithmic alignment theory to
better measure algorithmic alignment with generalisation.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:09:13 GMT""},{""version"":""v2"",""created"":""Sat, 3 Oct 2020 16:00:19 GMT""}]","2020-10-06"
"2006.08699","Somnath Bhattacharya","Somnath Bhattacharya","Current relaxation in the Random Resistor cum Tunneling Network Model
  through First-Passage route : Regimes and Time-scales","10 pages, 12 figures","Physica A, v 575, pp 126039, (2021)",,,"cond-mat.dis-nn cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Numerically we study the bulk current relaxation in percolative Random
Resistor cum Tunneling Network (RRTN) model through a first-passage route. The
RRTN considers an extra semi-classical barrier-crossing process over a voltage
threshold within a framework of classical RRN bond percolation model. We
identify the different temporal regimes of relaxation and corresponding
phenomenological time-scales, which fix up the extents of different regimes.
These time-scales were previously identified in refs. \cite{relax-physicaA,
aksubh}. We investigate on the distributions of these time-scales and observe
that there exists a perfect correlation among them in the thermodynamic limit.
We conclude that there exists a single time-scale which controls the RRTN
dynamics. The variation of mean first-passage time .vs. system size seems to be
due to sub-diffusive motion of charge carrier through the network.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:09:17 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 15:23:26 GMT""}]","2021-05-21"
"2006.08700","Shengxue He Dr.","Shengxue He","A multi-stage looking-ahead holding strategy to stabilize a
  high-frequency bus line",,,,,"eess.SY cs.SY math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If a bus line becomes unstable, passengers waiting time will be lengthened
and buses capacities will be mismatched. To stabilize a high-frequency bus
line, many holding strategies have been proposed. Among these strategies, some
need to take oversimplified assumptions to simplify the formulation of a real
bus line; some may choose a myopic holding time because they take into account
only the local and currently available headway information. To overcome the
above shortcomings, we proposed an adaptive holding strategy which continuously
reduces the deviations of the instantaneous headways from the Dynamic Target
Headway -DTH. By using DTH, the new strategy can make use of the global headway
information to determine a proper holding time. To fully estimate the influence
of a holding time on the operation of a bus line in a relative long time
period, we introduced the multi-stage looking-ahead mechanism into our new
strategy. A detailed bus line simulation system was used to realize the above
mechanism and to describe all kinds of complex components of a bus line. The
numerical experiment demonstrated the effectiveness of our new strategy. Some
meaningful insights were uncovered as follow: a. The number of stages to be
looked ahead should not be too small or too big; b. The bigger the range of the
action set, the better the performance of our strategy; c. To obtain the
optimal performance, the interval between two neighbor holding times should not
be too small or too big; d. the bigger the number of the control points, the
better the performance of our strategy.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:09:47 GMT""}]","2020-06-17"
"2006.08701","Jake Rhodes","Jake S. Rhodes, Adele Cutler, Guy Wolf, Kevin R. Moon","Supervised Visualization for Data Exploration","21 pages, 9 figures",,,,"stat.ML cs.HC cs.LG stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dimensionality reduction is often used as an initial step in data
exploration, either as preprocessing for classification or regression or for
visualization. Most dimensionality reduction techniques to date are
unsupervised; they do not take class labels into account (e.g., PCA, MDS,
t-SNE, Isomap). Such methods require large amounts of data and are often
sensitive to noise that may obfuscate important patterns in the data. Various
attempts at supervised dimensionality reduction methods that take into account
auxiliary annotations (e.g., class labels) have been successfully implemented
with goals of increased classification accuracy or improved data visualization.
Many of these supervised techniques incorporate labels in the loss function in
the form of similarity or dissimilarity matrices, thereby creating
over-emphasized separation between class clusters, which does not realistically
represent the local and global relationships in the data. In addition, these
approaches are often sensitive to parameter tuning, which may be difficult to
configure without an explicit quantitative notion of visual superiority. In
this paper, we describe a novel supervised visualization technique based on
random forest proximities and diffusion-based dimensionality reduction. We
show, both qualitatively and quantitatively, the advantages of our approach in
retaining local and global structures in data, while emphasizing important
variables in the low-dimensional embedding. Importantly, our approach is robust
to noise and parameter tuning, thus making it simple to use while producing
reliable visualizations for data exploration.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:10:17 GMT""}]","2020-06-17"
"2006.08703","Ulisses Barres de Almeida","Ulisses Barres de Almeida, Alberto Krone-Martins, Marcos Diaz, Jos\'e
  Dias do Nascimento, Wagner V. L\'eo, Reinaldo R. Rosa and Roberto K. Saito","Information technology & astronomical data in Brazil: Perspectives and
  proposals","5 pages, 1 figure, 3 tables, Published in the Bulletin of the
  Brazilian Astronomical Society, vol. 32, n. 1, pp. 142-6 (2020).
  https://sab-astro.org.br/sab/publicacoes/boletim-da-sab-vol-32/","Proc. of XLIII Annual Meeting of the Brazilian Astronomical
  Society, Bull. of Brazil. Astron. Soc., vol. 32, n. 1, pp. 142-146 (2020)",,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Commission on Science and Information Technology (CTCI) of the Brazilian
Astronomical Society (SAB) is tasked with assisting the Society on issues of
astronomical data management, from its handling and the management of data
centres and networks, to technical aspects of the archiving, storage and
dissemination of data. In this paper we present a summary of the results of a
survey recently conducted by the Commission to diagnose the status of several
data-related issues within the Brazilian astronomical community, as well as
some proposals derived therefrom.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:12:03 GMT""}]","2020-06-17"
"2006.08704","Tyrone Ghaswala","Adam Clay and Tyrone Ghaswala","Circularly ordering direct products and the obstruction to
  left-orderability","Minor changes made to accommodate the referee's comments. To appear
  in the Pacific Journal of Mathematics","Pacific J. Math. 312 (2021) 401-419","10.2140/pjm.2021.312.401",,"math.GR math.DS math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the recent result that left-orderability of a group $G$ is
intimately connected to circular orderability of direct products $G \times
\mathbb{Z}/n\mathbb{Z}$, we provide necessary and sufficient cohomological
conditions that such a direct product be circularly orderable. As a consequence
of the main theorem, we arrive at a new characterization for the fundamental
group of a rational homology 3-sphere to be left-orderable. Our results imply
that for mapping class groups of once-punctured surfaces, and other groups
whose actions on $S^1$ are cohomologically rigid, the products $G \times
\mathbb{Z}/n\mathbb{Z}$ are seldom circularly orderable. We also address
circular orderability of direct products in general, dealing with the cases of
factor groups admitting a bi-invariant circular ordering, and iterated direct
products whose factor groups are amenable.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:13:28 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 13:32:13 GMT""}]","2021-09-01"
"2006.08705","Yuri Mishin","R. K. Koju and Y. Mishin","Direct atomistic modeling of solute drag by moving grain boundaries",,"Acta Materialia 198, 111-120 (2020)","10.1016/j.actamat.2020.07.052",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that molecular dynamics (MD) simulations are capable of reproducing
the drag of solute segregation atmospheres by moving grain boundaries (GBs).
Although lattice diffusion is frozen out on the MD timescale, the accelerated
GB diffusion provides enough atomic mobility to allow the segregated atoms to
follow the moving GB. This finding opens the possibility of studying the solute
drag effect with atomic precision using the MD approach. We demonstrate that a
moving GB activates diffusion and alters the short-range order in the lattice
regions swept during its motion. It is also shown that a moving GB drags an
atmosphere of non-equilibrium vacancies, which accelerate diffusion in
surrounding lattice regions.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:15:02 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2020 16:54:04 GMT""}]","2020-08-13"
"2006.08706","Shengxue He Dr.","Sheng-Xue He, Jian-Jia He, Shi-Dong Liang, June Qiong Dong, Peng-Cheng
  Yuan","A Dynamic Holding Approach to Stabilizing a Bus Line Based on the
  Q-learning Algorithm with Multistage Look-ahead",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unreliable service and the unstable operation of a high frequency bus
line are shown as bus bunching and the uneven distribution of headways along
the bus line. Although many control strategies, such as the static and dynamic
holding strategies, have been proposed to solve the above problems, many of
them take on some oversimplified assumptions about the real bus line operation.
So it is hard for them to continuously adapt to the evolving complex system. In
view of this dynamic setting, we present an adaptive holding method which
combines the classic approximate dynamic programming (ADP) with the multi-stage
look-ahead mechanism. The holding time, that is the only control means used in
this study, will be determined by estimating its impact on the operation
stability of the bus line system in the remained observation period. The
multi-stage look-ahead mechanism introduced into the classic Q-learning
algorithm of the ADP model makes the algorithm get through its earlier unstable
phase more quickly and easily. During the implementation of the new holding
approach, the past experiences of holding operations can be cumulated
effectively into an artificial neural network used to approximate the
unavailable Q-factor. The use of a detailed simulation system in the new
approach makes it possible to take into accounts most of the possible causes of
instability. The numerical experiments show that the new holding approach can
stabilize the system by producing evenly distributed headway and removing bus
bunching thoroughly. Comparing with the terminal station holding strategies,
the new method brings a more reliable bus line with shorter waiting times for
passengers.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:16:50 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 07:39:03 GMT""}]","2021-03-02"
"2006.08710","Przemys{\l}aw Spurek","Przemys{\l}aw Spurek, Maciej Zi\k{e}ba, Jacek Tabor, Tomasz
  Trzci\'nski","HyperFlow: Representing 3D Objects as Surfaces",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present HyperFlow - a novel generative model that leverages
hypernetworks to create continuous 3D object representations in a form of
lightweight surfaces (meshes), directly out of point clouds. Efficient object
representations are essential for many computer vision applications, including
robotic manipulation and autonomous driving. However, creating those
representations is often cumbersome, because it requires processing unordered
sets of point clouds. Therefore, it is either computationally expensive, due to
additional optimization constraints such as permutation invariance, or leads to
quantization losses introduced by binning point clouds into discrete voxels.
Inspired by mesh-based representations of objects used in computer graphics, we
postulate a fundamentally different approach and represent 3D objects as a
family of surfaces. To that end, we devise a generative model that uses a
hypernetwork to return the weights of a Continuous Normalizing Flows (CNF)
target network. The goal of this target network is to map points from a
probability distribution into a 3D mesh. To avoid numerical instability of the
CNF on compact support distributions, we propose a new Spherical Log-Normal
function which models density of 3D points around object surfaces mimicking
noise introduced by 3D capturing devices. As a result, we obtain continuous
mesh-based object representations that yield better qualitative results than
competing approaches, while reducing training time by over an order of
magnitude.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:18:02 GMT""}]","2020-06-17"
"2006.08712","Aleksander Vesel","Aleksander Vesel","Efficient proper embedding of a daisy cube",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a set $X$ of binary words of length $h$ the daisy cube $Q_h(X)$ is
defined as the subgraph of the hypercube $Q_h$ induced by the set of all
vertices on shortest paths that connect vertices of $X$ with the vertex $0 ^h$.
A vertex in the intersection of all of these paths is a minimal vertex of a
daisy cube. A graph $G$ isomorphic to a daisy cube admits several isometric
embeddings into a hypercube. We show that an isometric embedding is proper if
and only if the label $0 ^h$ is assigned to a minimal vertex of $G$. This
result allows us to devise an algorithm which finds a proper embedding of a
graph isomorphic to a daisy cube into a hypercube in linear time.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:20:28 GMT""}]","2020-06-17"
"2006.08713","Stephan Block","Matthias Wallert, Chuanxiong Nie, Parambath Anilkumar, Srinivas
  Abbina, Sumati Bhatia, Jayachandran N. Kizhakkedathu, Rainer Haag, Stephan
  Block","Mucin-inspired, high molecular weight virus binding inhibitors show
  biphasic binding behavior to influenza A viruses","30 pages, 5 figures, 2 tables",,,,"physics.bio-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multivalent virus binding inhibitors are a promising new class of antivirals,
preventing virus infection of cells by inhibiting the first step in the viral
infection cycle - binding of viruses to the cell surface. The design of
multivalent virus binding inhibitors is complex as many properties, such as
inhibitor size and functionalization with virus attachment factors, have a
strong impact on the inhibition efficiency. In this study, we synthesized virus
binding inhibitors, the design of which has been inspired by mucins, which are
naturally occurring glycosylated proteins with molecular weights in the MDa
range and which show high affinity in the interaction with various viruses.
Hyperbranched polyglycerols (hPG), serving as polymeric scaffolds, were
functionalized with sialic acids and sulfate groups at degrees of
functionalization as suggested from the structure of mucins. The molecular
weights of the hPG-based inhibitors ranged between 10 and 2600 kDa, thereby
hitting the size of mucins (MDa scale) and allowing for comparing the
inhibition efficiency of the largest, mucin-sized inhibitor (2600 kDa) with
related inhibitors of lower molecular weight. Inhibition efficiencies were
determined by various methods based on the inhibition of influenza A virus
(IAV) binding to lipid membranes, including an assay based on total internal
reflection fluorescence (TIRF) microscopy that allows for probing the
interaction of IAV with its native attachment factor, sialic acid. Potent
inhibition is observed in all assays already at pM concentrations for the
mucin-sized inhibitor, while decreasing the inhibitor's molecular weight also
decreased its inhibition efficiency. In addition, a biphasic binding behavior
of the inhibitors to IAV is observed, which is attributed to differences in the
binding affinity to two IAV envelope proteins, neuraminidase and hemagglutinin.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:21:18 GMT""}]","2020-06-17"
"2006.08714","Joey Hong","Joey Hong and Branislav Kveton and Manzil Zaheer and Yinlam Chow and
  Amr Ahmed and Craig Boutilier","Latent Bandits Revisited","16 pages, 2 figures",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A latent bandit problem is one in which the learning agent knows the arm
reward distributions conditioned on an unknown discrete latent state. The
primary goal of the agent is to identify the latent state, after which it can
act optimally. This setting is a natural midpoint between online and offline
learning---complex models can be learned offline with the agent identifying
latent state online---of practical relevance in, say, recommender systems. In
this work, we propose general algorithms for this setting, based on both upper
confidence bounds (UCBs) and Thompson sampling. Our methods are contextual and
aware of model uncertainty and misspecification. We provide a unified
theoretical analysis of our algorithms, which have lower regret than classic
bandit policies when the number of latent states is smaller than actions. A
comprehensive empirical study showcases the advantages of our approach.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:24:02 GMT""}]","2020-06-17"
"2006.08715","Shengfeng Cheng","Chengyuan Wen, Roy Odle, Shengfeng Cheng","Coarse-Grained Molecular Dynamics Modeling of A Branched Polyetherimide","19 pages, 11 figures, 4-page Supporting Information","Macromolecules 54, 143-160 (2021)","10.1021/acs.macromol.0c01440",,"cond-mat.mtrl-sci cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A coarse-grained model is developed to allow large-scale molecular dynamics
(MD) simulations of a branched polyetherimide derived from two backbone
monomers [4,4'-bisphenol A dianhydride (BPADA) and m-phenylenediamine (MPD)], a
chain terminator [phthalic anhydride (PA)], and a branching agent
[tris[4-(4-aminophenoxy)phenyl] ethane (TAPE)]. An atomistic model is first
built for the branched polyetherimide. A systematic protocol based on
chemistry-informed grouping of atoms, derivation of bond and angle interactions
by direct Boltzmann inversion, and parameterization of nonbonded interactions
by potential of mean force (PMF) calculations via gas-phase MD simulations of
atomic group pairs, is used to construct the coarse-grained model. A six-pair
geometry, with one atomic group at the center and six replicates of the other
atomic group placed surrounding the central group in a NaCl structure, has been
demonstrated to significantly speed up the PMF calculations and partially
capture the many-body aspect of the PMFs. Furthermore, we propose a correction
term to the PMFs that can make the resulting coarse-grained model transferable
temperature-wise, by enabling the model to capture the thermal expansion
property of the polymer. The coarse-grained model has been applied to explore
the mechanical, structural, and rheological properties of the branched
polyetherimide.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:26:47 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jan 2021 22:37:29 GMT""}]","2021-01-15"
"2006.08716","Phillip C. Stancil","R. C. Forrey, J. F. Babb, E. D. S. Courtney, R. McArdle, and P. C.
  Stancil","Revisiting the Formation of HeH$^+$ in the Planetary Nebula NGC 7027","etable of rate coefficients available",,"10.3847/1538-4357/ab9a50",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  From four independent calculations using three different theoretical
approaches, rate coefficients for the formation of HeH$^+$ via the radiative
association of He$^+$ and H were computed. Good agreement is found between our
new calculations and prior results obtained two decades ago for kinetic
temperatures between $\sim$800 and 20,000 K. This finding is inconsistent with
a recent claim in the literature of a wide variation in published values and
establishes the robustness of our knowledge of this process for the formation
of HeH$^+$. The implications of the current results to the first detection of
HeH$^+$ and its modeled abundance in the planetary nebula NGC 7027 are
discussed.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:28:08 GMT""}]","2020-08-05"
"2006.08717","Valerii Kozin","V. K. Kozin, V. A. Shabashov, A. V. Kavokin and I. A. Shelykh","Anomalous Exciton Hall Effect","6 pages, 2 figures, published in PRL","Phys. Rev. Lett. 126, 036801 (2021)","10.1103/PhysRevLett.126.036801",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that electrically neutral excitons can still be affected by
crossed electric and magnetic fields that make them move in a direction
perpendicular to both fields. We show that a similar effect appears in the
absence of external electric fields, in the case of scattering of an exciton
flow by charged impurities in the presence of the external magnetic field. As a
result, the exciton flow changes the direction of its propagation that may be
described in terms of the Hall conductivity for excitons. We develop a theory
of this effect, which we refer to as the anomalous exciton Hall effect, to
distinguish it from the exciton Hall effect that arises due to the valley
selective exciton transport in transition metal dichalcogenides. According to
our estimations, the effect is relatively weak for optically active or bright
excitons in conventional GaAs quantum wells, but it becomes significant for
optically inactive or dark excitons, because of the difference of the
lifetimes. This makes the proposed effect a convenient tool for spatial
separation of dark and bright excitons.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:31:43 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 21:51:19 GMT""},{""version"":""v3"",""created"":""Fri, 4 Sep 2020 14:36:50 GMT""},{""version"":""v4"",""created"":""Thu, 21 Jan 2021 15:28:58 GMT""}]","2021-01-22"
"2006.08718","Rika Antonova","Rika Antonova, Maksim Maydanskiy, Danica Kragic, Sam Devlin, Katja
  Hofmann","Analytic Manifold Learning: Unifying and Evaluating Representations for
  Continuous Control","Added Section 4: ""Imposing AML Relations During Transfer""; expanded
  description of experiments in Section 5: ""Evaluating AML and Latent Space
  Transfer""",,,,"cs.LG cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of learning reusable state representations from
streaming high-dimensional observations. This is important for areas like
Reinforcement Learning (RL), which yields non-stationary data distributions
during training. We make two key contributions. First, we propose an evaluation
suite that measures alignment between latent and true low-dimensional states.
We benchmark several widely used unsupervised learning approaches. This
uncovers the strengths and limitations of existing approaches that impose
additional constraints/objectives on the latent space. Our second contribution
is a unifying mathematical formulation for learning latent relations. We learn
analytic relations on source domains, then use these relations to help
structure the latent space when learning on target domains. This formulation
enables a more general, flexible and principled way of shaping the latent
space. It formalizes the notion of learning independent relations, without
imposing restrictive simplifying assumptions or requiring domain-specific
information. We present mathematical properties, concrete algorithms for
implementation and experimental validation of successful learning and transfer
of latent relations.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:33:47 GMT""},{""version"":""v2"",""created"":""Tue, 6 Oct 2020 19:43:50 GMT""}]","2020-10-08"
"2006.08720","Whitney Huang","Whitney K. Huang, Adam H. Monahan, Francis W. Zwiers","Estimating Concurrent Climate Extremes: A Conditional Approach","39 pages, 18 figures, 1 table",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simultaneous concurrence of extreme values across multiple climate variables
can result in large societal and environmental impacts. Therefore, there is
growing interest in understanding these concurrent extremes. In many
applications, not only the frequency but also the magnitude of concurrent
extremes are of interest. One way to approach this problem is to study the
distribution of one climate variable given that another is extreme. In this
work we develop a statistical framework for estimating bivariate concurrent
extremes via a conditional approach, where univariate extreme value modeling is
combined with dependence modeling of the conditional tail distribution using
techniques from quantile regression and extreme value analysis to quantify
concurrent extremes. We focus on the distribution of daily wind speed
conditioned on daily precipitation taking its seasonal maximum. The Canadian
Regional Climate Model large ensemble is used to assess the performance of the
proposed framework both via a simulation study with specified dependence
structure and via an analysis of the climate model-simulated dependence
structure.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:37:47 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 16:38:15 GMT""},{""version"":""v3"",""created"":""Fri, 12 Mar 2021 19:14:30 GMT""}]","2021-03-16"
"2006.08721","Tao Cai","Tao Cai","Upward Overshooting in Turbulent Compressible Convection. III. Calibrate
  Parameters for One-dimensional Reynolds Stress Model","published in ApJ",,"10.3847/1538-4357/ab7203",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we calibrate the coefficients for the one-dimensional Reynolds
stress model with the data generated from the three-dimensional numerical
simulations of upward overshooting in turbulent compressible convection. It has
been found that the calibrated convective and isotropic coefficients are almost
the same as those calibrated in the pure convection zone. However, the
calibrated diffusive coefficients differ significantly from those calibrated in
the pure convection zone. We suspect that the diffusive effect induced by the
boundary is stronger than by the adjacent stable zone. We have checked the
validity of the downgradient approximation. We find that the prediction of the
downgradient approximation on the third-order moments is unsatisfactory.
However, the prediction on their derivatives is much better. It explains why
the performance of the Reynolds stress model is reasonable in application to
the real stars. With the calibrated coefficients, we have solved the full set
of nonlocal turbulent equations on Reynolds stress model. We find that the
Reynolds stress model has successfully produced the thermal adjustment layer
and turbulent dissipation layer, which were identified in the three-dimensional
numerical simulations. We suggest to use the inflection point of the
auto-correlation of temperature perturbation and the P\'eclet number as the
indicators on measuring the extents of the thermal adjustment layer and
turbulent dissipation layer, respectively. This result may offer a practical
guidance on the application of the Reynolds stress model in 1D stellar
structure and evolution models.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:38:04 GMT""}]","2020-06-17"
"2006.08722","Sulaiman Alghunaim","Sulaiman A. Alghunaim, Ming Yan, Ali H. Sayed","A Multi-Agent Primal-Dual Strategy for Composite Optimization over
  Distributed Features","To appear in European Signal Processing Conference (EUSIPCO) 2020",,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work studies multi-agent sharing optimization problems with the
objective function being the sum of smooth local functions plus a convex
(possibly non-smooth) function coupling all agents. This scenario arises in
many machine learning and engineering applications, such as regression over
distributed features and resource allocation. We reformulate this problem into
an equivalent saddle-point problem, which is amenable to decentralized
solutions. We then propose a proximal primal-dual algorithm and establish its
linear convergence to the optimal solution when the local functions are
strongly-convex. To our knowledge, this is the first linearly convergent
decentralized algorithm for multi-agent sharing problems with a general convex
(possibly non-smooth) coupling function.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:40:24 GMT""}]","2020-06-17"
"2006.08724","Roman Sverdlov","Roman Sverdlov","Continuous measurement on a causal set with and without a boundary","27 pages, no figures",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this paper is two-fold. First, we would like to get rid of
common assumption that causal set is bounded and attempt to model its scalar
field action under the assumption that it isn't. Secondly, we would like to
propose continuous measurement model in this context.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:46:54 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 08:03:43 GMT""}]","2020-06-18"
"2006.08725","Pelin Guven Geredeli","Pelin G. Geredeli","Bounded Semigroup Wellposedness for a Linearized Compressible Flow
  Structure PDE Interaction with Material Derivative",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a compressible flow structure interaction (FSI) PDE system which
is linearized about some reference rest state. The deformable interface is
under the effect of an ambient field generated by the underlying and unbounded
material derivative term which further contributes to the non-dissipativity of
the FSI system, with respect to the standard energy inner product. In this work
we show that, on an appropriate subspace, only one dimension less than the
entire finite energy space, the FSI system is wellposed, and is moreover
associated with a continuous semigroup which is \emph{uniformly bounded} in
time. Our approach involves establishing maximal dissipativity with respect to
a special inner product which is equivalent to the standard inner product for
the given finite energy space. Among other technical features, the necesssary
PDE estimates require the invocation of a multiplier which is intrinsic to the
given compressible FSI system.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:47:08 GMT""}]","2020-06-17"
"2006.08727","Jeremy Wolcott","NOvA Collaboration: M. A. Acero (2), P. Adamson (12), G. Agam (19), L.
  Aliaga (12), T. Alion (39), V. Allakhverdian (26), N. Anfimov (26), A.
  Antoshkin (26), L. Asquith (39), A. Aurisano (6), A. Back (24), C. Backhouse
  (44), M. Baird (20 and 39 and 45), N. Balashov (26), P. Baldi (25), B. A.
  Bambah (17), S. Bashar (43), K. Bays (4 and 19), S. Bending (44), R.
  Bernstein (12), V. Bhatnagar (32), B. Bhuyan (14), J. Bian (25 and 30), J.
  Blair (16), A. C. Booth (39), P. Bour (9), R. Bowles (20), C. Bromberg (28),
  N. Buchanan (8), A. Butkevich (22), S. Calvez (8), T. J. Carroll (42 and 48),
  E. Catano-Mur (24 and 47), S. Childress (12), B. C. Choudhary (11), T. E.
  Coan (37), M. Colo (47), L. Corwin (36), L. Cremonesi (44), G. S. Davies (31
  and 20), P. F. Derwent (12), P. Ding (12), Z. Djurcic (1), D. Doyle (8), E.
  C. Dukes (45), P. Dung (42), H. Duyang (35), S. Edayath (7), R. Ehrlich (45),
  M. Elkins (24), G. J. Feldman (15), P. Filip (23), W. Flanagan (10), J. Franc
  (9), M. J. Frank (34, 45), H. R. Gallagher (43), R. Gandrajula (28), F. Gao
  (33), S. Germani (44), A. Giri (18), R. A. Gomes (13), M. C. Goodman (1), V.
  Grichine (27), M. Groh (20), R. Group (45), B. Guo (35), A. Habig (29), F.
  Hakl (21), J. Hartnell (39), R. Hatcher (12), A. Hatzikoutelis (41), K.
  Heller (30), V Hewes (6), A. Himmel (12), A. Holin (44), B. Howard (20), J.
  Huang (42), J. Hylen (12), F. Jediny (9), C. Johnson (8), M. Judah (8), I.
  Kakorin (26), D. Kalra (32), D. M. Kaplan (19), R. Keloth (7), O. Klimov
  (26), L. W. Koerner (16), L. Kolupaeva (26), S. Kotelnikov (27), Ch.
  Kullenberg (26), A. Kumar (32), C. D. Kuruppu (35), V. Kus (9), T. Lackey
  (20), K. Lang (42), L. Li (25), S. Lin (8), M. Lokajicek (23), S. Luchuk
  (22), K. Maan (32), S. Magill (1), W. A. Mann (43), M. L. Marshak (30), M.
  Martinez-Casales (24), V. Matveev (22), B. Mayes (39), D. P. M\'endez (39),
  M. D. Messier (20), H. Meyer (46), T. Miao (12), W. H. Miller (30), S. R.
  Mishra (35), A. Mislivec (30), R. Mohanta (17), A. Moren (29), A. Morozova
  (26), L. Mualem (4), M. Muether (46), S. Mufson (20), K. Mulder (44), R.
  Murphy (20), J. Musser (20), D. Naples (33), N. Nayak (25), J. K. Nelson
  (47), R. Nichol (44), G. Nikseresht (19), E. Niner (12), A. Norman (12), A.
  Norrick (12), T. Nosek (5), A. Olshevskiy (26), T. Olson (43), J. Paley (12),
  R. B. Patterson (4), G. Pawloski (30), O. Petrova (26), R. Petti (35), R. K.
  Plunkett (12), A. Rafique (1), F. Psihas (20 and 42), A. Radovic (47), V. Raj
  (4), B. Ramson (12), B. Rebel (12 and 48), P. Rojas (8), V. Ryabov (27), O.
  Samoylov (26), M. C. Sanchez (24), S. S\'anchez Falero (24), I. S. Seong
  (25), P. Shanahan (12), A. Sheshukov (26), P. Singh (11), V. Singh (3), E.
  Smith (20), J. Smolik (9), P. Snopok (19), N. Solomey (46), A. Sousa (6), K.
  Soustruznik (5), M. Strait (30), L. Suter (12), A. Sutton (45), C. Sweeney
  (44), R. L. Talaga (1), B. Tapia Oregui (42), P. Tas (5), R. B. Thayyullathil
  (7), J. Thomas (44 and 48), E. Tiras (24), D. Torbunov (30), J. Tripathi
  (32), Y. Torun (19), J. Urheim (20), P. Vahle (47), Z. Vallari (4), J. Vasel
  (20), P. Vokac (9), T. Vrba (9), M. Wallbank (6), T. K. Warburton (24), M.
  Wetstein (24), D. Whittington (40 and 20), S. G. Wojcicki (38), J. Wolcott
  (43), A. Yallappa Dombara (40), K. Yonehara (12), S. Yu (1 and 19), Y. Yu
  (19), S. Zadorozhnyy (22), J. Zalesak (23), Y. Zhang (39), R. Zwaska (12)
  ((1) Argonne National Laboratory, (2) Universidad del Atlantico, (3)
  Department of Physics, Institute of Science, Banaras Hindu University, (4)
  California Institute of Technology, (5) Charles University, Faculty of
  Mathematics and Physics, Institute of Particle and Nuclear Physics, (6)
  Department of Physics, University of Cincinnati, (7) Department of Physics,
  Cochin University of Science and Technology, (8) Department of Physics,
  Colorado State University, (9) Czech Technical University in Prague, (10)
  University of Dallas, (11) Department of Physics and Astrophysics, University
  of Delhi, (12) Fermi National Accelerator Laboratory, (13) Instituto de
  F\'isica, Universidade Federal de Goi\'as, (14) Department of Physics, IIT
  Guwahati, (15) Department of Physics, Harvard University, (16) Department of
  Physics, University of Houston, (17) School of Physics, University of
  Hyderabad, (18) Department of Physics, IIT Hyderabad, (19) Department of
  Physics, Illinois Institute of Technology, (20) Indiana University, (21)
  Institute of Computer Science, The Czech Academy of Sciences, (22) Inst. for
  Nuclear Research of Russia, (23) Institute of Physics, The Czech Academy of
  Sciences, (24) Department of Physics and Astronomy, Iowa State University,
  (25) Department of Physics and Astronomy, University of California at Irvine,
  (26) Joint Institute for Nuclear Research, (27) Nuclear Physics and
  Astrophysics Division, (28) Department of Physics and Astronomy, Michigan
  State University, (29) Department of Physics and Astronomy, University of
  Minnesota Duluth, (30) School of Physics and Astronomy, University of
  Minnesota Twin Cities, (31) University of Mississippi, (32) Department of
  Physics, Panjab University, (33) Department of Physics, University of
  Pittsburgh, (34) Department of Physics, University of South Alabama, (35)
  Department of Physics and Astronomy, University of South Carolina, (36) South
  Dakota School of Mines and Technology, (37) Department of Physics, Southern
  Methodist University, (38) Department of Physics, Stanford University, (39)
  Department of Physics and Astronomy, University of Sussex, (40) Department of
  Physics, Syracuse University, (41) Department of Physics and Astronomy,
  University of Tennessee, (42) Department of Physics, University of Texas at
  Austin, (43) Department of Physics and Astronomy, Tufts University, (44)
  Physics and Astronomy Dept., University College London, (45) Department of
  Physics, University of Virginia, (46) Department of Mathematics, Statistics,
  and Physics, Wichita State University, (47) Department of Physics, William
  and Mary, (48) Department of Physics, University of Wisconsin-Madison)","Adjusting Neutrino Interaction Models and Evaluating Uncertainties using
  NOvA Near Detector Data","Code implementing adjustments to GENIE 2.12.2 described in this paper
  is available at https://github.com/novaexperiment/NOvARwgt-public","Eur. Phys. J. C 80, 1119 (2020)","10.1140/epjc/s10052-020-08577-5","FERMILAB-PUB-20-243-ND","hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The two-detector design of the NOvA neutrino oscillation experiment, in which
two functionally identical detectors are exposed to an intense neutrino beam,
aids in canceling leading order effects of cross-section uncertainties.
However, limited knowledge of neutrino interaction cross sections still gives
rise to some of the largest systematic uncertainties in current oscillation
measurements. We show contemporary models of neutrino interactions to be
discrepant with data from NOvA, consistent with discrepancies seen in other
experiments. Adjustments to neutrino interaction models in GENIE that improve
agreement with our data are presented. We also describe systematic
uncertainties on these models, including uncertainties on multi-nucleon
interactions from a newly developed procedure using NOvA near detector data.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:51:38 GMT""},{""version"":""v2"",""created"":""Mon, 5 Oct 2020 16:10:15 GMT""},{""version"":""v3"",""created"":""Thu, 10 Dec 2020 19:20:03 GMT""}]","2023-02-18"
"2006.08728","Jacob Page","Jacob Page, Yves Dubief and Rich R. Kerswell","Exact travelling wave solutions in viscoelastic channel flow",,"Phys. Rev. Lett. 125, 154501 (2020)","10.1103/PhysRevLett.125.154501",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Elasto-inertial turbulence (EIT) is a new, two-dimensional chaotic flow state
observed in polymer solutions with possible connections to inertialess elastic
turbulence and drag-reduced Newtonian turbulence. In this Letter, we argue that
the origins of EIT are fundamentally different from Newtonian turbulence by
finding a dynamical connection between EIT and an elasto-inertial linear
instability recently found at high Weissenberg numbers (Garg et al. Phys. Rev.
Lett. 121, 024502, 2018). This link is established by isolating the first known
exact coherent structures in viscoelastic parallel flows - nonlinear
elasto-inertial travelling waves (TWs) - borne at the linear instability and
tracking them down to substantially lower Weissenberg numbers where EIT exists.
These TWs have a distinctive ``arrowhead'' structure in the polymer stretch
field and can be clearly recognised, albeit transiently, in EIT, as well as
being attractors for EIT dynamics if the Weissenberg number is sufficiently
large. Our findings suggest that the dynamical systems picture in which
Newtonian turbulence is built around the co-existence of many (unstable) simple
invariant solutions populating phase space carries over to EIT, though these
solutions rely on elasticity to exist.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:56:55 GMT""}]","2020-10-14"
"2006.08729","Sina Loriani","Sina Loriani, Christian Schubert, Dennis Schlippert, Wolfgang Ertmer,
  Franck Pereira Dos Santos, Ernst Maria Rasel, Naceur Gaaloul and Peter Wolf","Resolution of the Co-Location Problem in Satellite Quantum Tests of the
  Universality of Free Fall","12 pages, 3 figures","Phys. Rev. D 102, 124043 (2020)","10.1103/PhysRevD.102.124043",,"quant-ph gr-qc physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A major challenge common to all Galilean drop tests of the Universality of
Free Fall (UFF) is the required control over the initial kinematics of the two
test masses upon release due to coupling to gravity gradients and rotations. In
this work, we present a two-fold mitigation strategy to significantly alleviate
the source preparation requirements in space-borne quantum tests of the UFF,
using a compensation mechanism together with signal demodulation. To this end,
we propose a scheme to reduce the gravity-gradient-induced uncertainties in an
atom-interferometric experiment in a dedicated satellite mission and assess the
experimental feasibility. We find that with moderate parameters, the
requirements on the initial kinematics of the two masses can be relaxed by five
orders of magnitude. This does not only imply a significantly reduced mission
time but also allows to reduce the differential acceleration uncertainty caused
by co-location imperfections below the $10^{-18}$ level.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:57:21 GMT""}]","2021-01-06"
"2006.08730","Jorge Pullin","Rodolfo Gambini and Jorge Pullin","Fundamental bound for time measurements and minimum uncertainty clocks","6 pages, RevTex, one figure","J. Phys. Commun. 4 (2020) 065008","10.1088/2399-6528/ab9a07","LSU-REL-060320","quant-ph gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a simple argument leading to a fundamental minimum uncertainty in
the determination of times. It only relies in the uncertainty principle and
time dilation in a gravitational field. It implies any attempt to measure times
will have a fundamental level of uncertainty. Implications are briefly
outlined.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:01:38 GMT""}]","2020-06-17"
"2006.08731","Johannes Vass","Johannes Vass, Marie-Louise Lackner, Nysret Musliu","Exact and Metaheuristic Approaches for the Production Leveling Problem","Instance set is published under
  https://dbai.tuwien.ac.at/staff/jvass/production-leveling/",,,,"cs.AI cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we introduce a new problem in the field of production planning
which we call the Production Leveling Problem. The task is to assign orders to
production periods such that the load in each period and on each production
resource is balanced, capacity limits are not exceeded and the orders'
priorities are taken into account. Production Leveling is an important
intermediate step between long-term planning and the final scheduling of orders
within a production period, as it is responsible for selecting good subsets of
orders to be scheduled within each period.
  A formal model of the problem is proposed and NP-hardness is shown by
reduction from Bin Backing. As an exact method for solving moderately sized
instances we introduce a MIP formulation. For solving large problem instances,
metaheuristic local search is investigated. A greedy heuristic and two
neighborhood structures for local search are proposed, in order to apply them
using Variable Neighborhood Descent and Simulated Annealing. Regarding exact
techniques, the main question of research is, up to which size instances are
solvable within a fixed amount of time. For the metaheuristic approaches the
aim is to show that they produce near-optimal solutions for smaller instances,
but also scale well to very large instances.
  A set of realistic problem instances from an industrial partner is
contributed to the literature, as well as random instance generators. The
experimental evaluation conveys that the proposed MIP model works well for
instances with up to 250 orders. Out of the investigated metaheuristic
approaches, Simulated Annealing achieves the best results. It is shown to
produce solutions with less than 3% average optimality gap on small instances
and to scale well up to thousands of orders and dozens of periods and products.
The presented metaheuristic methods are already being used in the industry.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:04:59 GMT""}]","2020-06-17"
"2006.08732","Shuo Zhang","Shuo Zhang and Krisztian Balog","Evaluating Conversational Recommender Systems via User Simulation","Proceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery
  and Data Mining (KDD '20), 2020",,"10.1145/3394486.3403202",,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conversational information access is an emerging research area. Currently,
human evaluation is used for end-to-end system evaluation, which is both very
time and resource intensive at scale, and thus becomes a bottleneck of
progress. As an alternative, we propose automated evaluation by means of
simulating users. Our user simulator aims to generate responses that a real
human would give by considering both individual preferences and the general
flow of interaction with the system. We evaluate our simulation approach on an
item recommendation task by comparing three existing conversational recommender
systems. We show that preference modeling and task-specific interaction models
both contribute to more realistic simulations, and can help achieve high
correlation between automatic evaluation measures and manual human assessments.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:05:39 GMT""}]","2020-06-17"
"2006.08733","Zahra Ghodsi","Zahra Ghodsi, Akshaj Veldanda, Brandon Reagen, Siddharth Garg","CryptoNAS: Private Inference on a ReLU Budget",,,,,"cs.LG cs.CR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning as a service has given raise to privacy concerns surrounding
clients' data and providers' models and has catalyzed research in private
inference (PI): methods to process inferences without disclosing inputs.
Recently, researchers have adapted cryptographic techniques to show PI is
possible, however all solutions increase inference latency beyond practical
limits. This paper makes the observation that existing models are ill-suited
for PI and proposes a novel NAS method, named CryptoNAS, for finding and
tailoring models to the needs of PI. The key insight is that in PI operator
latency cost are non-linear operations (e.g., ReLU) dominate latency, while
linear layers become effectively free. We develop the idea of a ReLU budget as
a proxy for inference latency and use CryptoNAS to build models that maximize
accuracy within a given budget. CryptoNAS improves accuracy by 3.4% and latency
by 2.4x over the state-of-the-art.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:06:05 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 16:52:51 GMT""}]","2021-05-14"
"2006.08734","Michael Kinyon","Ale\v{s} Dr\'apal and Michael Kinyon","Normality, nuclear squares and Osborn identities","16 pages; v.2: typos fixed; bibliography entry fixed","Commentationes Mathematicae Universitatis Carolinae 61 (2020), no.
  4, 481-500","10.14712/1213-7243.2020.038",,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $Q$ be a loop. If $S\leq Q$ is such that $\varphi(S) \subseteq S$ for
each standard generator of $\mathrm{Inn}(Q)$, then $S$ does not have to be a
normal subloop. In an LC loop the left and middle nucleus coincide and form a
normal subloop. The identities of Osborn loops are obtained by applying the
idea of nuclear identification, and various connections of Osborn loops to
Moufang and CC loops are discussed. Every Osborn loop possesses a normal
nucleus, and this nucleus coincides with the left, the right and the middle
nucleus. Loops that are both Buchsteiner and Osborn are characterized as loops
in which each square is in the nucleus.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:08:52 GMT""},{""version"":""v2"",""created"":""Sat, 27 Jun 2020 16:45:48 GMT""}]","2022-10-14"
"2006.08735","Abhishek Deshpande","Yida Ding, Abhishek Deshpande, Gheorghe Craciun","Minimal invariant regions and minimal globally attracting regions for
  toric differential inclusions","29 pages, 15 figures",,,,"math.DS q-bio.MN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Toric differential inclusions occur as key dynamical systems in the context
of the Global Attractor Conjecture. We introduce the notions of minimal
invariant regions and minimal globally attracting regions for toric
differential inclusions. We describe a procedure for constructing explicitly
the minimal invariant and minimal globally attracting regions for
two-dimensional toric differential inclusions. In particular, we obtain
invariant regions and globally attracting regions for two-dimensional weakly
reversible or endotactic dynamical systems (even if they have time-dependent
parameters).
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:14:13 GMT""}]","2020-06-17"
"2006.08736","Peter G. Doyle","Peter G. Doyle","Conway's drum quilts","Version 1.0 dated 15 June 2020. Public domain",,,,"math.GT math.DG math.GR","http://creativecommons.org/publicdomain/zero/1.0/","  A `transplantable pair' is a pair of glueing diagrams that can be used to
create pairs of plane domains that are isospectral for the Laplace operator. We
present a host of transplantable pairs worked out by John Conway using his
theory of quilts
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:15:01 GMT""}]","2020-06-17"
"2006.08737","Raj Kumar Maity","Avishek Ghosh, Raj Kumar Maity and Arya Mazumdar","Distributed Newton Can Communicate Less and Resist Byzantine Workers",,,,,"cs.LG cs.DC math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a distributed second order optimization algorithm that is
communication-efficient as well as robust against Byzantine failures of the
worker machines. We propose COMRADE (COMunication-efficient and Robust
Approximate Distributed nEwton), an iterative second order algorithm, where the
worker machines communicate only once per iteration with the center machine.
This is in sharp contrast with the state-of-the-art distributed second order
algorithms like GIANT [34] and DINGO[7], where the worker machines send
(functions of) local gradient and Hessian sequentially; thus ending up
communicating twice with the center machine per iteration. Moreover, we show
that the worker machines can further compress the local information before
sending it to the center. In addition, we employ a simple norm based
thresholding rule to filter-out the Byzantine worker machines. We establish the
linear-quadratic rate of convergence of COMRADE and establish that the
communication savings and Byzantine resilience result in only a small
statistical error rate for arbitrary convex loss functions. To the best of our
knowledge, this is the first work that addresses the issue of Byzantine
resilience in second order distributed optimization. Furthermore, we validate
our theoretical results with extensive experiments on synthetic and benchmark
LIBSVM [5] data-sets and demonstrate convergence guarantees.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:16:15 GMT""}]","2021-03-19"
"2006.08738","Jeremy Brazas","Jeremy Brazas","The infinitary n-cube shuffle","13 pages, 2 figures","Topology and its Applications 287 (2020) 107446","10.1016/j.topol.2020.107446",,"math.AT math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we formalize the sense in which higher homotopy groups are
""infinitely commutative."" In particular, we both simplify and extend the highly
technical procedure, due to Eda and Kawamura, for constructing homotopies that
isotopically rearrange infinite configurations of disjoint $n$-cubes within the
unit $n$-cube.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:17:07 GMT""}]","2021-03-26"
"2006.08739","Navid Hashemi","Navid Hashemi, Justin Ruths","Generalized Outer Bounds on the Finite Geometric Sum of Ellipsoids",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  General results on convex bodies are reviewed and used to derive an exact
closed-form parametric formula for the boundary of the geometric (Minkowski)
sum of $k$ ellipsoids in $n$-dimensional Euclidean space. Previously this was
done through iterative algorithms in which each new ellipsoid was added to an
ellipsoid approximation of the sum of the previous ellipsoids. Here we provide
one shot formulas to add $k$ ellipsoids directly with no intermediate
approximations required. This allows us to observe a new degree of freedom in
the family of ellipsoidal bounds on the geometric sum. We demonstrate an
application of these tools to compute the reachable set of a discrete-time
dynamical system.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:17:50 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 19:43:25 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jul 2021 03:51:41 GMT""}]","2021-07-07"
"2006.08740","Michal Sustr","Michal \v{S}ustr, Martin Schmid, Matej Morav\v{c}\'ik, Neil Burch,
  Marc Lanctot, Michael Bowling","Sound Algorithms in Imperfect Information Games","Accepted to AAMAS2021 as extended abstract (Ref. numbers not
  available yet)",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Search has played a fundamental role in computer game research since the very
beginning. And while online search has been commonly used in perfect
information games such as Chess and Go, online search methods for imperfect
information games have only been introduced relatively recently. This paper
addresses the question of what is a sound online algorithm in an imperfect
information setting of two-player zero-sum games. We argue that
the~fixed-strategy~definitions of exploitability and $\epsilon$-Nash equilibria
are ill-suited to measure an online algorithm's worst-case performance. We thus
formalize $\epsilon$-soundness, a concept that connects the worst-case
performance of an online algorithm to the performance of an $\epsilon$-Nash
equilibrium. As $\epsilon$-soundness can be difficult to compute in general, we
introduce a consistency framework -- a hierarchy that connects an online
algorithm's behavior to a Nash equilibrium. These multiple levels of
consistency describe in what sense an online algorithm plays ""just like a fixed
Nash equilibrium"". These notions further illustrate the difference between
perfect and imperfect information settings, as the same consistency guarantees
have different worst-case online performance in perfect and imperfect
information games. The definitions of soundness and the consistency hierarchy
finally provide appropriate tools to analyze online algorithms in repeated
imperfect information games. We thus inspect some of the previous online
algorithms in a new light, bringing new insights into their worst-case
performance guarantees.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:18:57 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 17:26:46 GMT""}]","2021-03-03"
"2006.08741","Phebe Vayanos","Phebe Vayanos, Qing Jin, George Elissaios","ROC++: Robust Optimization in C++","45 pages, 1 figure, submitted for publication",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robust optimization is a very popular means to address decision-making
problems affected by uncertainty. Its success has been fueled by its attractive
robustness and scalability properties, by ease of modeling, and by the limited
assumptions it needs about the uncertain parameters to yield meaningful
solutions. Robust optimization techniques can address both single- and
multi-stage decision-making problems involving real-valued and/or binary
decisions, and exogenous and/or endogenous uncertain parameters. Many of these
techniques apply to problems with either robust (worst-case) or stochastic
(expectation) objectives and can thus be tailored to the risk preferences of
the decision-maker. Robust optimization techniques rely on duality theory
(potentially augmented with approximations) to transform a semi-infinite
optimization problem to a finite program of benign complexity (the ``robust
counterpart''). While writing down the model for a robust or stochastic
optimization problem is usually a simple task, obtaining the robust counterpart
requires expertise in robust optimization. To date, very few solutions are
available that can facilitate the modeling and solution of such problems. This
has been a major impediment to their being put to practical use. In this paper,
we propose ROC++, a C++ based platform for automatic robust optimization,
applicable to a wide array of single- and multi-stage stochastic and robust
problems with both exogenous and endogenous uncertain parameters. We also
propose the ROB file format that generalizes the LP file format to robust
optimization. Our platform can help streamline the modeling and solution of
stochastic and robust optimization problems for both researchers and
practitioners. It comes with detailed documentation to facilitate its use and
expansion. ROC++ is freely distributed for academic use.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:20:05 GMT""}]","2020-06-17"
"2006.08742","Michael Curry","Michael J. Curry, Ping-Yeh Chiang, Tom Goldstein, John Dickerson","Certifying Strategyproof Auction Networks",,,,,"cs.GT cs.AI cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimal auctions maximize a seller's expected revenue subject to individual
rationality and strategyproofness for the buyers. Myerson's seminal work in
1981 settled the case of auctioning a single item; however, subsequent decades
of work have yielded little progress moving beyond a single item, leaving the
design of revenue-maximizing auctions as a central open problem in the field of
mechanism design. A recent thread of work in ""differentiable economics"" has
used tools from modern deep learning to instead learn good mechanisms. We focus
on the RegretNet architecture, which can represent auctions with arbitrary
numbers of items and participants; it is trained to be empirically
strategyproof, but the property is never exactly verified leaving potential
loopholes for market participants to exploit. We propose ways to explicitly
verify strategyproofness under a particular valuation profile using techniques
from the neural network verification literature. Doing so requires making
several modifications to the RegretNet architecture in order to represent it
exactly in an integer program. We train our network and produce certificates in
several settings, including settings for which the optimal strategyproof
mechanism is not known.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:22:48 GMT""}]","2020-06-17"
"2006.08743","Manh Hong Duong","S. Kum, M. H. Duong, Y. Lim and S. Yun","A GPM-based algorithm for solving regularized Wasserstein barycenter
  problems in some spaces of probability measures","39 pages, significant revised from the previous version, results were
  strengthened, title changed",,,,"math.OC cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we focus on the analysis of the regularized Wasserstein
barycenter problem. We provide uniqueness and a characterization of the
barycenter for two important classes of probability measures: (i) Gaussian
distributions and (ii) $q$-Gaussian distributions; each regularized by a
particular entropy functional. We propose an algorithm based on gradient
projection method in the space of matrices in order to compute these
regularized barycenters. We also consider a general class of
$\varphi$-exponential measures, for which only the non-regularized barycenter
is studied. Finally, we numerically show the influence of parameters and
stability of the algorithm under small perturbation of data.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:25:03 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 09:25:25 GMT""},{""version"":""v3"",""created"":""Tue, 5 Oct 2021 10:59:50 GMT""},{""version"":""v4"",""created"":""Sat, 6 Aug 2022 07:17:50 GMT""}]","2022-08-09"
"2006.08744","Jacopo Ciambella","Jacopo Ciambella and Paola Nardinocchi","A structurally frame-indifferent model for anisotropic
  visco-hyperelastic materials","43 pages,, 9 figures",,"10.1016/j.jmps.2020.104247",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the main theoretical issues in developing a theory of anisotropic
viscoelastic media at finite strains lies in the proper definition of the
material symmetry group and its evolution with time. In this paper the matter
is discussed thoroughly and addressed by introducing a novel anisotropic
remodelling equation compatible with the principle of structural frame
indifference, a requirement that every inelastic theory based on the
multiplicative decomposition of the deformation gradient must obey to. The
evolution laws of the dissipative process are %obtained by introducing a novel
(remodelling) balance equation which is completely determined by two scalar
functions, the elastic strain energy and the dissipation densities. The proper
choice of the dissipation function allows us to reduce the proposed model to
the Ericksen anisotropic fluid, when deformation is sufficiently slow, or to
the anisotropic hyperelastic solid for fast deformations. Finally, a few
prototype examples are discussed to highlight the role of the relaxation times
in the constitutive response.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:35:25 GMT""},{""version"":""v2"",""created"":""Sun, 26 Jul 2020 07:47:16 GMT""}]","2021-02-03"
"2006.08745","Andrew Gelman","Jon Zelner, Julien Riou, Ruth Etzioni, and Andrew Gelman","Accounting for Uncertainty During a Pandemic","16 pages",,,,"stat.AP physics.soc-ph q-bio.PE q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss several issues of statistical design, data collection, analysis,
communication, and decision making that have arisen in recent and ongoing
coronavirus studies, focusing on tools for assessment and propagation of
uncertainty. This paper does not purport to be a comprehensive survey of the
research literature; rather, we use examples to illustrate statistical points
that we think are important.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:36:42 GMT""}]","2020-06-17"
"2006.08746","Paul Egr\'e","Paul Egr\'e, Lorenzo Rossi, Jan Sprenger","Gibbardian Collapse and Trivalent Conditionals",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper discusses the scope and significance of the so-called triviality
result stated by Allan Gibbard for indicative conditionals, showing that if a
conditional operator satisfies the Law of Import-Export, is supraclassical, and
is stronger than the material conditional, then it must collapse to the
material conditional. Gibbard's result is taken to pose a dilemma for a
truth-functional account of indicative conditionals: give up Import-Export, or
embrace the two-valued analysis. We show that this dilemma can be averted in
trivalent logics of the conditional based on Reichenbach and de Finetti's idea
that a conditional with a false antecedent is undefined. Import-Export and
truth-functionality hold without triviality in such logics. We unravel some
implicit assumptions in Gibbard's proof, and discuss a recent generalization of
Gibbard's result due to Branden Fitelson.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:37:43 GMT""}]","2020-06-17"
"2006.08747","Salvador El\'ias Venegas-Andraca","Fei Yan, Salvador E. Venegas-Andraca, Kaoru Hirota","A Critical and Moving-Forward View on Quantum Image Processing","16 pages, 4 figures. Under review",,,,"quant-ph cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physics and computer science have a long tradition of cross-fertilization.
One of the latest outcomes of this mutually beneficial relationship is quantum
information science, which comprises the study of information processing tasks
that can be accomplished using quantum mechanical systems. Quantum Image
Processing (QIMP) is an emergent field of quantum information science whose
main goal is to strengthen our capacity for storing, processing, and retrieving
visual information from images and video either by transitioning from digital
to quantum paradigms or by complementing digital imaging with quantum
techniques. The expectation is that harnessing the properties of quantum
mechanical systems in QIMP will result in the realization of advanced
technologies that will outperform, enhance or complement existing and upcoming
digital technologies for image and video processing tasks.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:38:25 GMT""}]","2020-06-17"
"2006.08748","Chris Hokamp","Chris Hokamp, Demian Gholipour Ghalandari, Nghia The Pham, John Glover","DynE: Dynamic Ensemble Decoding for Multi-Document Summarization",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequence-to-sequence (s2s) models are the basis for extensive work in natural
language processing. However, some applications, such as multi-document
summarization, multi-modal machine translation, and the automatic post-editing
of machine translation, require mapping a set of multiple distinct inputs into
a single output sequence. Recent work has introduced bespoke architectures for
these multi-input settings, and developed models which can handle increasingly
longer inputs; however, the performance of special model architectures is
limited by the available in-domain training data. In this work we propose a
simple decoding methodology which ensembles the output of multiple instances of
the same model on different inputs. Our proposed approach allows models trained
for vanilla s2s tasks to be directly used in multi-input settings. This works
particularly well when each of the inputs has significant overlap with the
others, as when compressing a cluster of news articles about the same event
into a single coherent summary, and we obtain state-of-the-art results on
several multi-document summarization datasets.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:40:06 GMT""}]","2020-06-17"
"2006.08749","Sean McKeown","Clemens Krueger, Sean McKeown","Using Amazon Alexa APIs as a Source of Digital Evidence",,,"10.1109/CyberSecurity49315.2020.9138849",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the release of Amazon Alexa and the first Amazon Echo device, the
company revolutionised the smart home. It allowed their users to communicate
with, and control, their smart home ecosystem purely using voice commands.
However, this also means that Amazon processes and stores a large amount of
personal data about their users, as these devices are always present and always
listening in peoples' private homes. That makes this data a valuable source of
evidence for investigators performing digital forensics. The Alexa Voice
Service uses a series of APIs for communication between clients and the Amazon
cloud. These APIs return a wide range of data related to the functionality of
the device used.
  The first goal of this research was to clarify exactly what kind of
information about the user is stored and accessible through these APIs. To do
this, a combination of literature review and exploratory analysis was used to
establish a list of all relevant APIs. Then, possible artefacts and conclusions
to be drawn from their responses were identified and presented. Lastly, the
perspective of the users was taken, and options for improving their privacy
were reviewed. Specifically, the history of interaction between the user and
Alexa is available through multiple APIs, and there are several options to
delete it. It was determined that these options have different behaviours and
that most of them do not remove all data related to user interaction.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:40:14 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jul 2020 10:03:39 GMT""}]","2020-07-28"
"2006.08750","Luis Garc\'ia Ramos","Luis Garc\'ia Ramos, Reinhard Nabben","A two-level shifted Laplace preconditioner for Helmholtz problems:
  Field-of-values analysis and wavenumber-independent convergence","24 pages, 5 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the main tools for solving linear systems arising from the
discretization of the Helmholtz equation is the shifted Laplace preconditioner,
which results from the discretization of a perturbed Helmholtz problem $-\Delta
u - (k^2 + i \varepsilon )u = f$ where $0 \neq \varepsilon \in \mathbb{R}$ is
an absorption parameter. In this work we revisit the idea of combining the
shifted Laplace preconditioner with two-level deflation and apply it to
Helmholtz problems discretized with linear finite elements. We use the
convergence theory of GMRES based on the field of values to prove that GMRES
applied to the two-level preconditioned system with a shift parameter
$\varepsilon \sim k^2$ converges in a number of iterations independent of the
wavenumber $k$,provided that the coarse mesh size $H$ satisfies a condition of
the form $Hk^{2} \leq C$ for some constant $C$ depending on the domain but
independent of the wavenumber $k$. This behaviour is sharply different to the
standalone shifted Laplacian, for which wavenumber-independent GMRES
convergence has been established only under the condition that $\varepsilon
\sim k$ by [M.J. Gander, I.G. Graham and E.A. Spence, Numer. Math., 131 (2015),
567-614]. Finally, we present numerical evidence that wavenumber-independent
convergence of GMRES also holds for pollution-free meshes, where the coarse
mesh size satisfies $Hk^{3/2} \leq C $, and inexact coarse grid solves.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:43:30 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 14:46:50 GMT""}]","2020-06-18"
"2006.08751","Ferenc Simon","B. G. M\'arkus}, P. Szirmai, K. F. Edelthalhammer, P. Eckerlein, A.
  Hirsch, F. Hauke, N. M. Nemes, Julio C. Chac\'on-Torres, B. N\'afr\'adi, L.
  Forr\'o, T. Pichler, and F. Simon","Ultralong spin lifetime in light alkali atom doped graphene","10 pages, 5 figures+ Supplementary Materials","ACS Nano 14, 7492 (2020)","10.1021/acsnano.0c03191",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Today's great challenges of energy and informational technologies are
addressed with a singular compound, the Li and Na doped few layer graphene. All
what is impossible for graphite (homogeneous and high level Na doping), and
unstable for single layer graphene, works very well for this structure. The
transformation of the Raman G line to a Fano lineshape and the emergence of
strong, metallic-like electron spin resonance (ESR) modes, attest the high
level of graphene doping in liquid ammonia for both kinds of alkali atoms. The
spin-relaxation time in our materials, deduced from the ESR line-width, is 6-8
ns, which is comparable to the longest values found in spin-transport
experiments on ultrahigh mobility graphene flakes. This could qualify our
material as promising candidate in spintronics devices. On the other hand, the
successful sodium doping, this being a highly abundant metal, could be an
encouraging alternative to lithium batteries.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:44:24 GMT""}]","2020-09-15"
"2006.08752","Mirko Mauri","Camilla Felisetti, Mirko Mauri","P=W conjectures for character varieties with symplectic resolution","49 pages. Final version to appear in Journal de l'\'Ecole
  polytechnique",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish P=W and PI=WI conjectures for character varieties with
structural group $\mathrm{GL}_n$ and $\mathrm{SL}_n$ which admit a symplectic
resolution, i.e. for genus 1 and arbitrary rank, and genus 2 and rank 2. We
formulate the P=W conjecture for resolution, and prove it for symplectic
resolutions. We exploit the topology of birational and quasi-\'{e}tale
modifications of Dolbeault moduli spaces of Higgs bundles. To this end, we
prove auxiliary results of independent interest, like the construction of a
relative compactification of the Hodge moduli space for reductive algebraic
groups, and the projectivity of the compactification of the de Rham moduli
space. In particular, we study in detail a Dolbeault moduli space which is
specialization of the singular irreducible holomorphic symplectic variety of
type O'Grady 6.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:44:42 GMT""},{""version"":""v2"",""created"":""Sat, 24 Oct 2020 09:14:01 GMT""},{""version"":""v3"",""created"":""Tue, 11 Jan 2022 19:48:21 GMT""},{""version"":""v4"",""created"":""Mon, 16 May 2022 21:27:32 GMT""}]","2022-05-18"
"2006.08753","Michael Cohen","Michael K. Cohen and Marcus Hutter","Pessimism About Unknown Unknowns Inspires Conservatism","12 pages, plus 16-page appendix; to be published in COLT 2020
  proceedings",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If we could define the set of all bad outcomes, we could hard-code an agent
which avoids them; however, in sufficiently complex environments, this is
infeasible. We do not know of any general-purpose approaches in the literature
to avoiding novel failure modes. Motivated by this, we define an idealized
Bayesian reinforcement learner which follows a policy that maximizes the
worst-case expected reward over a set of world-models. We call this agent
pessimistic, since it optimizes assuming the worst case. A scalar parameter
tunes the agent's pessimism by changing the size of the set of world-models
taken into account. Our first main contribution is: given an assumption about
the agent's model class, a sufficiently pessimistic agent does not cause
""unprecedented events"" with probability $1-\delta$, whether or not designers
know how to precisely specify those precedents they are concerned with. Since
pessimism discourages exploration, at each timestep, the agent may defer to a
mentor, who may be a human or some known-safe policy we would like to improve.
Our other main contribution is that the agent's policy's value approaches at
least that of the mentor, while the probability of deferring to the mentor goes
to 0. In high-stakes environments, we might like advanced artificial agents to
pursue goals cautiously, which is a non-trivial problem even if the agent were
allowed arbitrary computing power; we present a formal solution.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:46:33 GMT""}]","2020-06-17"
"2006.08754","Kwang-Sung Jun","Kwang-Sung Jun, Chicheng Zhang","Crush Optimism with Pessimism: Structured Bandits Beyond Asymptotic
  Optimality","accepted to NeurIPS'20; added the lower bound result",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study stochastic structured bandits for minimizing regret. The fact that
the popular optimistic algorithms do not achieve the asymptotic
instance-dependent regret optimality (asymptotic optimality for short) has
recently alluded researchers. On the other hand, it is known that one can
achieve bounded regret (i.e., does not grow indefinitely with $n$) in certain
instances. Unfortunately, existing asymptotically optimal algorithms rely on
forced sampling that introduces an $\omega(1)$ term w.r.t. the time horizon $n$
in their regret, failing to adapt to the ""easiness"" of the instance. In this
paper, we focus on the finite hypothesis case and ask if one can achieve the
asymptotic optimality while enjoying bounded regret whenever possible. We
provide a positive answer by introducing a new algorithm called CRush Optimism
with Pessimism (CROP) that eliminates optimistic hypotheses by pulling the
informative arms indicated by a pessimistic hypothesis. Our finite-time
analysis shows that CROP $(i)$ achieves a constant-factor asymptotic optimality
and, thanks to the forced-exploration-free design, $(ii)$ adapts to bounded
regret, and $(iii)$ its regret bound scales not with $K$ but with an effective
number of arms $K_\psi$ that we introduce. We also discuss a problem class
where CROP can be exponentially better than existing algorithms in
\textit{nonasymptotic} regimes. This problem class also reveals a surprising
fact that even a clairvoyant oracle who plays according to the asymptotically
optimal arm pull scheme may suffer a linear worst-case regret.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:46:52 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 01:51:16 GMT""}]","2020-10-26"
"2006.08755","Eduardo Bragan\c{c}a","K. E. L. de Farias, E. A. F. Bragan\c{c}a and H. F. Santana Mota","Scalar self-interaction in the spacetime of a cosmic dispiration","12 pages, 3 figures",,"10.1016/j.physletb.2021.136660",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper we investigate the classical self-interaction associated
with a charged scalar point particle placed at rest in the gravitational field
of a linear topological defect known in literature as cosmic dispiration, a
combination of a cosmic string with a screw dislocation. We found exact
expressions for the Green's function and, consequently, for the self-energy by
considering both massive and massless scalar point particles. We present
numerical graphs and analyze the nature of the self-interactions in the cosmic
dispiration spacetime itself and in the cases of pure screw dislocation and
cosmic string spacetimes.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:48:31 GMT""}]","2021-10-27"
"2006.08756","Daniel Fortunato","Daniel Fortunato, Nicholas Hale, and Alex Townsend","The ultraspherical spectral element method",,,"10.1016/j.jcp.2020.110087",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a novel spectral element method based on the ultraspherical
spectral method and the hierarchical Poincar\'{e}-Steklov scheme for solving
second-order linear partial differential equations on polygonal domains with
unstructured quadrilateral or triangular meshes. Properties of the
ultraspherical spectral method lead to almost banded linear systems, allowing
the element method to be competitive in the high-polynomial regime ($p > 5$).
The hierarchical Poincar\'{e}-Steklov scheme enables precomputed solution
operators to be reused, allowing for fast elliptic solves in implicit and
semi-implicit time-steppers. The resulting spectral element method achieves an
overall computational complexity of $\mathcal{O}(p^4/h^3)$ for mesh size $h$
and polynomial order $p$, enabling $hp$-adaptivity to be efficiently performed.
We develop an open-source software system, ultraSEM, for flexible,
user-friendly spectral element computations in MATLAB.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:49:07 GMT""},{""version"":""v2"",""created"":""Fri, 18 Dec 2020 20:12:52 GMT""}]","2021-05-19"
"2006.08757","Jordan Eagle","J. Eagle, S. Marchesi, M. Ajello, D. Castro, A. Vendrasco","Gamma-ray emission revealed at the western edge of SNR G344.7-0.1","9 pages, 7 figures, Submitted to ApJ June 15, 2020. Accepted for
  publication Oct 2, 2020",,"10.3847/1538-4357/abbe08",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the investigation of a very high energy (VHE), Galactic
gamma-ray source recently discovered at >50GeV using the Large Area Telescope
(LAT) on board the Fermi Gamma-Ray Space Telescope. This object, 2FHL
J1703.4-4145, displays a very hard >50GeV spectrum with a photon index ~1.2 in
the 2FHL catalog and, as such, is one of the most extreme sources in the 2FHL
sub-sample of Galactic objects. A detailed analysis of the available
multi-wavelength data shows that this source is located on the western edge of
the supernova remnant (SNR) G344.7--0.1, along with extended TeV source, HESS
J1702-420. The observations and the spectral energy distribution modeling
support a scenario where this gamma-ray source is the byproduct of the
interaction between the SNR shock and the dense surrounding medium, with
escaping cosmic rays (CRs) diffusing into the dense environment and interacting
with a large local cloud, generating the observed TeV emission. If confirmed,
an interaction between the SNR CRs and a nearby cloud would make 2FHL
J1703.4-4145 another promising candidate for efficient particle acceleration of
the 2FHL Galactic sample, following the first candidate from our previous
investigation of a likely shock-cloud interaction occurring on the West edge of
the Vela SNR.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:50:03 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 16:29:33 GMT""},{""version"":""v3"",""created"":""Mon, 5 Oct 2020 14:49:09 GMT""}]","2020-12-02"
"2006.08758","Kamel Khelifa-Kerfa","Kamel Khelifa-Kerfa, Yazid Delenda","Eikonal amplitudes for three-hard legs processes at finite-N$_c$","6 pages. Published version","Physics Letters B 809 (2020) 135768","10.1016/j.physletb.2020.135768",,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend our previous work on scattering amplitudes [1] to hadron
collisions. We provide a general formalism for the computation of eikonal
amplitudes squared for the radiation of soft and energy-ordered gluons off
three hard-legs at finite-N$_c$ to any order in the perturbative expansion.
Examples of three-hard legs processes include vector/Higgs boson production in
association with a single hard jet and dijet production in DIS. Explicit
expressions for the radiation of up to four gluons are provided as an
illustration of the formalism.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:50:32 GMT""},{""version"":""v2"",""created"":""Mon, 14 Sep 2020 11:23:15 GMT""}]","2020-09-15"
"2006.08759","Nazariy Shaydyuk","Nazariy K. Shaydyuk, Eugene B. John","Semi-Streaming Architecture: A New Design Paradigm for CNN
  Implementation on FPGAs","8 pages, 5 figures",,,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent research advances in deep learning have led to the development of
small and powerful Convolutional Neural Network (CNN) architectures. Meanwhile
Field Programmable Gate Arrays (FPGAs) has become a popular hardware target
choice for their deployment, splitting into two main implementation categories:
streaming hardware architectures and single computation engine design
approaches. The streaming hardware architectures generally require implementing
every layer as a discrete processing unit, and are suitable for smaller
software models that could fit in their unfolded versions into
resource-constrained targets. On the other hand, single computation engines can
be scaled to fit into a device to execute CNN models of different sizes and
complexities, however, the achievable performance of one-size-fits-all
implementations may vary across CNNs with different workload attributes leading
to inefficient utilization of hardware resources. By combing the advantages of
both of the above methods, this work proposes a new design paradigm called
semi-streaming architecture, where layerspecialized configurable engines are
used for network realization. As a proof of concept this paper presents a set
of five layerspecialized configurable processing engines for implementing 8-bit
quantized MobilenevV2 CNN model. The engines are chained to partially preserve
data streaming and tuned individually to efficiently process specific types of
layers: normalized addition of residuals, depthwise, pointwise (expansion and
projection), and standard 2D convolution layers capable of delivering 5.4GOp/s,
16GOp/s, 27.2GOp/s, 27.2GOp/s and 89.6GOp/s, respectively, with the overall
energy efficiency of 5.32GOp/s/W at a 100MHz system clock, requiring total
power of 6.2W on a XCZU7EV SoC FPGA.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:51:58 GMT""}]","2020-06-17"
"2006.08760","Ali Ahmad Malik","Ali Ahmad Malik, Alexander Brem","Man, machine and work in a digital twin setup: a case study",,"Robotics and Computer-Integrated Manufacturing, 68, 2021, 102092,
  ISSN 0736-5845","10.1016/j.rcim.2020.102092",,"cs.CY cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper explores the opportunities of using a digital twin to address the
complexities of collaborative production systems through an industrial case and
a demonstrator. A digital twin, as a virtual counterpart of a physical
human-robot assembly system, is built as a front-runner for validation and
control through design, build, and operation. The forms of digital twins along
the system life cycle, the building blocks, and potential advantages are
presented. Recommendations for future research and practice in the use of
digital twins in the field of collaborative robots are given.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:54:43 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 10:05:00 GMT""}]","2020-11-24"
"2006.08761","Sayeed Shafayet Chowdhury","Sayeed Shafayet Chowdhury, Chankyu Lee and Kaushik Roy","Towards Understanding the Effect of Leak in Spiking Neural Networks","Sayeed Shafayet Chowdhury and Chankyu Lee contributed equally",,,,"cs.NE cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spiking Neural Networks (SNNs) are being explored to emulate the astounding
capabilities of human brain that can learn and compute functions robustly and
efficiently with noisy spiking activities. A variety of spiking neuron models
have been proposed to resemble biological neuronal functionalities. With
varying levels of bio-fidelity, these models often contain a leak path in their
internal states, called membrane potentials. While the leaky models have been
argued as more bioplausible, a comparative analysis between models with and
without leak from a purely computational point of view demands attention. In
this paper, we investigate the questions regarding the justification of leak
and the pros and cons of using leaky behavior. Our experimental results reveal
that leaky neuron model provides improved robustness and better generalization
compared to models with no leak. However, leak decreases the sparsity of
computation contrary to the common notion. Through a frequency domain analysis,
we demonstrate the effect of leak in eliminating the high-frequency components
from the input, thus enabling SNNs to be more robust against noisy
spike-inputs.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:56:31 GMT""}]","2020-06-17"
"2006.08762","Nils Wandel","Nils Wandel, Michael Weinmann, Reinhard Klein","Learning Incompressible Fluid Dynamics from Scratch -- Towards Fast,
  Differentiable Fluid Models that Generalize","to be published at International Conference on Learning
  Representations (ICLR) 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fast and stable fluid simulations are an essential prerequisite for
applications ranging from computer-generated imagery to computer-aided design
in research and development. However, solving the partial differential
equations of incompressible fluids is a challenging task and traditional
numerical approximation schemes come at high computational costs. Recent deep
learning based approaches promise vast speed-ups but do not generalize to new
fluid domains, require fluid simulation data for training, or rely on complex
pipelines that outsource major parts of the fluid simulation to traditional
methods.
  In this work, we propose a novel physics-constrained training approach that
generalizes to new fluid domains, requires no fluid simulation data, and allows
convolutional neural networks to map a fluid state from time-point t to a
subsequent state at time t + dt in a single forward pass. This simplifies the
pipeline to train and evaluate neural fluid models. After training, the
framework yields models that are capable of fast fluid simulations and can
handle various fluid phenomena including the Magnus effect and Karman vortex
streets. We present an interactive real-time demo to show the speed and
generalization capabilities of our trained models. Moreover, the trained neural
networks are efficient differentiable fluid solvers as they offer a
differentiable update step to advance the fluid simulation in time. We exploit
this fact in a proof-of-concept optimal control experiment. Our models
significantly outperform a recent differentiable fluid solver in terms of
computational speed and accuracy.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:59:28 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 19:53:34 GMT""},{""version"":""v3"",""created"":""Tue, 2 Mar 2021 12:59:03 GMT""}]","2021-03-03"
"2006.08763","Louise Breuval Mrs","Louise Breuval, Pierre Kervella, Richard I. Anderson, Adam G. Riess,
  Fr\'ed\'eric Arenou, Boris Trahin, Antoine M\'erand, Alexandre Gallenne,
  Wolfgang Gieren, Jesper Storm, Giuseppe Bono, Grzegorz Pietrzy\'nski, Nicolas
  Nardetto, Behnam Javanmardi, Vincent Hocd\'e","The Milky Way Cepheid Leavitt law based on Gaia DR2 parallaxes of
  companion stars and host open cluster populations","15 pages, 20 figures. Accepted for publication in A&A","A&A 643, A115 (2020)","10.1051/0004-6361/202038633",,"astro-ph.SR astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classical Cepheids provide the foundation for the empirical extragalactic
distance ladder. Milky Way Cepheids are the only stars in this class accessible
to trigonometric parallax measurements. However, the parallaxes of Cepheids
from the second Gaia data release (GDR2) are affected by systematics because of
the absence of chromaticity correction, and occasionally by saturation. As a
proxy for the parallaxes of 36 Galactic Cepheids, we adopt either the GDR2
parallaxes of their spatially resolved companions or the GDR2 parallax of their
host open cluster. This novel approach allows us to bypass the systematics on
the GDR2 Cepheids parallaxes that is induced by saturation and variability. We
adopt a GDR2 parallax zero-point (ZP) of -0.046 mas with an uncertainty of
0.015 mas that covers most of the recent estimates. We present new Galactic
calibrations of the Leavitt law in the V, J, H, K_S , and Wesenheit W_H bands.
We compare our results with previous calibrations based on non-Gaia
measurements and compute a revised value for the Hubble constant anchored to
Milky Way Cepheids. From an initial Hubble constant of 76.18 +/- 2.37 km/s/Mpc
based on parallax measurements without Gaia, we derive a revised value by
adopting companion and average cluster parallaxes in place of direct Cepheid
parallaxes, and we find H_0 = 72.8 +/- 1.9 (statistical + systematics) +/- 1.9
(ZP) km/s/Mpc when all Cepheids are considered and H0 = 73.0 +/- 1.9
(statistical + systematics) +/- 1.9 (ZP) km/s/Mpc for fundamental mode
pulsators only.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:59:31 GMT""},{""version"":""v2"",""created"":""Sat, 19 Sep 2020 20:23:26 GMT""}]","2020-11-11"
"2006.08764","Thomas Donlon","Thomas Donlon II, Heidi Jo Newberg, Robyn Sanderson, Lawrence M.
  Widrow","The Milky Way's Shell Structure Reveals the Time of a Radial Collision",,,"10.3847/1538-4357/abb5f6",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We identify shell structures in the Milky Way for the first time. We find 2
shells in the Virgo Overdensity (VOD) region and 2 shells in the Hercules
Aquila Cloud (HAC) region using Sloan Digital Sky Survey, Gaia, and LAMOST
data. These shell stars are a subset of the substructure previously identified
as the Virgo Radial Merger (VRM). Timing arguments for these shells indicate
that their progenitor dwarf galaxy passed through the Galactic center 2.7 +/-
0.2 Gyr ago. Based on the time of collision, it is also possible that the VRM
is related to the phenomenon that created phase-space spirals in the vertical
motion of the disk and/or the Splash, and could have caused a burst of star
formation in the inner disk.
  We analyze phase mixing in a collection of radial merger N-body simulations,
and find that shell structure similar to that observed in Milky Way data
disappears by 5 Gyr after collision with the Galactic center. The method used
to calculate the merger time of the VRM was able to reliably recover the
correct merger times for these simulations.
  Previous work supports the idea that the VRM and the Gaia
Sausage/Gaia-Enceladus Merger are the same. However, the Gaia Sausage is widely
believed to be 8--11 Gyr old. The disparate ages could be reconciled if the
larger age is associated with an infall time when the progenitor crossed the
virial radius; we do not constrain the time at which the progenitor became
bound to the Milky Way. Alternatively, the Gaia Sausage could be younger than
previously thought.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:59:41 GMT""},{""version"":""v2"",""created"":""Fri, 21 Aug 2020 15:54:14 GMT""},{""version"":""v3"",""created"":""Wed, 9 Sep 2020 15:18:31 GMT""}]","2020-10-28"
"2006.08765","Junyi Gao","Junyi Gao, Cao Xiao, Lucas M. Glass, Jimeng Sun","COMPOSE: Cross-Modal Pseudo-Siamese Network for Patient Trial Matching","Accepted by KDD'20",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Clinical trials play important roles in drug development but often suffer
from expensive, inaccurate and insufficient patient recruitment. The
availability of massive electronic health records (EHR) data and trial
eligibility criteria (EC) bring a new opportunity to data driven patient
recruitment. One key task named patient-trial matching is to find qualified
patients for clinical trials given structured EHR and unstructured EC text
(both inclusion and exclusion criteria). How to match complex EC text with
longitudinal patient EHRs? How to embed many-to-many relationships between
patients and trials? How to explicitly handle the difference between inclusion
and exclusion criteria? In this paper, we proposed CrOss-Modal PseudO-SiamEse
network (COMPOSE) to address these challenges for patient-trial matching. One
path of the network encodes EC using convolutional highway network. The other
path processes EHR with multi-granularity memory network that encodes
structured patient records into multiple levels based on medical ontology.
Using the EC embedding as query, COMPOSE performs attentional record alignment
and thus enables dynamic patient-trial matching. COMPOSE also introduces a
composite loss term to maximize the similarity between patient records and
inclusion criteria while minimize the similarity to the exclusion criteria.
Experiment results show COMPOSE can reach 98.0% AUC on patient-criteria
matching and 83.7% accuracy on patient-trial matching, which leads 24.3%
improvement over the best baseline on real-world patient-trial matching tasks.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:01:33 GMT""}]","2020-06-17"
"2006.08766","Li Li","Li Li, Dianchao Lin, Saif Eddin Jabari","A User-Based Charge and Subsidy Scheme for Single O-D Network Mobility
  Management","6 pages, 3 figures, 2 tables, IEEE ITSC 2020","The 23rd IEEE International Conference on Intelligent
  Transportation Systems, 2020","10.1109/ITSC45102.2020.9294680","2020","eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a path guidance system with a user-based charge and subsidy (UBCS)
scheme for single O-D network mobility management. Users who are willing to
join the scheme (subscribers) can submit travel requests along with their VOTs
to the system before traveling. Those who are not willing to join (outsiders)
only need to submit travel requests to the system. Our system will give all
users path guidance from their origins to their destinations, and collect a
\emph{path payment} from the UBCS subscribers. Subscribers will be charged or
subsided in a way that renders the UBCS strategy-proof, revenue-neutral, and
Pareto-improving. A numerical example shows that the UBCS scheme is equitable
and progressive.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:02:30 GMT""}]","2021-01-01"
"2006.08769","Daniel Greb","Daniel Greb, Stefan Kebekus, Thomas Peternell","Projective flatness over klt spaces and uniformisation of varieties with
  nef anti-canonical divisor","v2: minor corrections as suggested by referee; accepted for
  publication by Journal of Algebraic Geometry","J. Algebraic Geom. 31 (2022), 467-496","10.1090/jag/785",,"math.AG math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a criterion for the projectivisation of a reflexive sheaf on a klt
space to be induced by a projective representation of the fundamental group of
the smooth locus. This criterion is then applied to give a characterisation of
finite quotients of projective spaces and Abelian varieties by
$\mathbb{Q}$-Chern class (in)equalities and a suitable stability condition.
This stability condition is formulated in terms of a naturally defined
extension of the tangent sheaf by the structure sheaf. We further examine cases
in which this stability condition is satisfied, comparing it to K-semistability
and related notions.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:06:56 GMT""},{""version"":""v2"",""created"":""Tue, 11 Jan 2022 20:43:09 GMT""}]","2022-07-25"
"2006.08770","Ademir Aguiar","Ademir Alves Aguiar, Orizon Pereira Ferreira, Leandro da Fonseca
  Prudente","Subgradient method with feasible inexact projections for constrained
  convex optimization problems",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a new inexact version of the projected subgradient
method to solve nondifferentiable constrained convex optimization problems. The
method combine $\epsilon$-subgradient method with a procedure to obtain a
feasible inexact projection onto the constraint set. Asymptotic convergence
results and iteration-complexity bounds for the sequence generated by the
method employing the well known exogenous stepsizes, Polyak's stepsizes, and
dynamic stepsizes are established.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:08:28 GMT""}]","2020-06-17"
"2006.08771","Philipp H\""ovel","Thomas Maertens, Eckehard Sch\""oll, Jorge Ruiz, Philipp H\""ovel","Multilayer network analysis of C. elegans: Looking into the locomotory
  circuitry","32 pages, 18 figures",,,,"nlin.AO q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate how locomotory behavior is generated in the brain focusing on
the paradigmatic connectome of nematode Caenorhabditis elegans (C. elegans) and
on neuronal activity patterns that control forward locomotion. We map the
neuronal network of the worm as a multilayer network that takes into account
various neurotransmitters and neuropeptides. Using logistic regression
analysis, we predict the neurons of the locomotory subnetwork. Combining
Hindmarsh-Rose equations for neuronal activity with a leaky integrator model
for muscular activity, we study the dynamics within this subnetwork and predict
the forward locomotion of the worm using a harmonic wave model. The application
of time-delayed feedback control reveals synchronization effects that
contribute to a coordinated locomotion of C. elegans. Analyzing the
synchronicity when the activity of certain neurons is silenced informs us about
their significance for a coordinated locomotory behavior. Since the information
processing is the same in humans and C. elegans, the study of the locomotory
circuitry provides new insights for understanding how the brain generates
motion behavior.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:09:00 GMT""}]","2020-06-17"
"2006.08772","Bento Rafael Siqueira","B. R. Siqueira, F. C. Ferrari, T. Vogel, R. De Lemos","Micro-controllers: Promoting Structurally Flexible Controllers in
  Self-Adaptive Software Systems","10 pages, 4 figures",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To promote structurally flexible controllers in self-adaptive software
systems, this paper proposes the use of micro-controllers. Instead of generic
monolithic controllers, like Rainbow, we advocate the use of service-specific
micro-controllers which can be based on microservices. Although traditional
generic controllers can be configured parametrically according to system needs,
their use and reuse are nevertheless restrictive because of the wide range of
services expected from the different stages of the feedback control loop.The
solution being advocated is to have structurally flexible controllers that can
be composed from micro-controllers. Controlling the architectural configuration
of these micro-controllers is a meta-controller that is able to configure the
controller according to the services required for controlling the target
system. The feasibility of the proposed approach of using micro-controllers at
the level of the controller is demonstrated in the context of the PhoneAdapter
case study in which micro-controllers are configured at run-time depending on
changes affecting the system or its environment.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:11:04 GMT""}]","2020-06-17"
"2006.08773","DianChao Lin","DianChao Lin and Saif Eddin Jabari","Comparative Analysis of Economic Instruments in Intersection Operation:
  A User-Based Perspective","6 pages, 8 figures, 6 tables, IEEE-ITSC2020","The 23rd IEEE International Conference on Intelligent
  Transportation Systems, 2020","10.1109/ITSC45102.2020.9294641","2020","cs.CY cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Focusing on different economic instruments implemented in intersection
operations under a connected environment, this paper analyzes their advantages
and disadvantages from the travelers' perspective. Travelers' concerns revolve
around whether a new instrument is easy to learn and operate, whether it can
save time or money, and whether it can reduce the rich-poor gap. After a
comparative analysis, we found that both credit and free-market schemes can
benefit users. Second-price auctions can only benefit high VOT vehicles. From
the perspective of technology deployment and adoption, a credit scheme is not
easy to learn and operate for travelers.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:11:26 GMT""}]","2021-01-01"
"2006.08774","Antonio De Domenico","Antonio De Domenico, Ya-Feng Liu, and Wei Yu","Optimal Virtual Network Function Deployment for 5G Network Slicing in a
  Hybrid Cloud Infrastructure","Under submission in IEEE Transactions on Wireless Communications",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network virtualization is a key enabler for 5G systems to support the
expected use cases of vertical markets. In this context, we study the joint
optimal deployment of Virtual Network Functions (VNFs) and allocation of
computational resources in a hybrid cloud infrastructure by taking the
requirements of the 5G services and the characteristics of the cloud
architecture into consideration. The resulting mixed-integer problem is
reformulated as an integer linear problem, which can be solved by using a
standard solver. Our results underline the advantages of a hybrid
infrastructure over a standard centralized radio access network consisting only
of a central cloud, and show that the proposed mechanism to deploy VNF chains
leads to high resource utilization efficiency and large gains in terms of the
number of supported VNF chains. To deal with the computational complexity of
optimizing a large number of clouds and VNF chains, we propose a simple
low-complexity heuristic that attempts to find a feasible VNF deployment
solution with a limited number of functional splits. Numerical results indicate
that the performance of the proposed heuristic is close to the optimal one when
the edge clouds are well dimensioned with respect to the computational
requirements of the 5G services.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:15:25 GMT""}]","2020-06-17"
"2006.08775","Louis DeBiasio","Louis DeBiasio and Robert A. Krueger","A note about monochromatic components in graphs of large minimum degree","11 pages, 3 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For all positive integers $r\geq 3$ and $n$ such that $r^2-r$ divides $n$ and
an affine plane of order $r$ exists, we construct an $r$-edge colored graph
with minimum degree $(1-\frac{r-2}{r^2-r})n-2$ such that the largest
monochromatic component has order less than $\frac{n}{r-1}$. This generalizes
an example of Guggiari and Scott and, independently, Rahimi for $r=3$ and thus
disproves a conjecture of Gy\'arf\'as and S\'ark\""ozy for all integers $r\geq
3$ such that an affine plane of order $r$ exists.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:17:48 GMT""}]","2020-06-17"
"2006.08776","Razvan-Dumitru Ceuca","Razvan-Dumitru Ceuca","Cubic microlattices embedded in nematic liquid crystals: a Landau
  de-Gennes study",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a Landau-de Gennes model for a connected cubic lattice scaffold
in a nematic host, in a dilute regime. We analyse the homogenised limit for
both cases in which the lattice of embedded particles presents or not cubic
symmetry and then we compute the free effective energy of the composite
material. In the cubic symmetry case, we impose different types of surface
anchoring energy densities, such as quartic, Rapini-Papoular or more general
versions, and, in this case, we show that we can tune any coefficient from the
corresponding bulk potential, especially the phase transition temperature. In
the case with loss of cubic symmetry, we prove similar results in which the
effective free energy functional has now an additional term, which describes a
change in the preferred alignment of the liquid crystal particles inside the
domain. Moreover, we compute the rate of convergence for how fast the surface
energies converge to the homogenised one and also for how fast the minimisers
of the free energies tend to the minimiser of the homogenised free energy.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:20:31 GMT""}]","2020-06-17"
"2006.08777","Artur Bekasov","Artur Bekasov, Iain Murray","Ordering Dimensions with Nested Dropout Normalizing Flows",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The latent space of normalizing flows must be of the same dimensionality as
their output space. This constraint presents a problem if we want to learn
low-dimensional, semantically meaningful representations. Recent work has
provided compact representations by fitting flows constrained to manifolds, but
hasn't defined a density off that manifold. In this work we consider flows with
full support in data space, but with ordered latent variables. Like in PCA, the
leading latent dimensions define a sequence of manifolds that lie close to the
data. We note a trade-off between the flow likelihood and the quality of the
ordering, depending on the parameterization of the flow.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:23:24 GMT""}]","2020-06-17"
"2006.08778","Hina Tabassum Prof.","Javad Sayehvand and Hina Tabassum","Interference and Coverage Analysis in Coexisting RF and Dense TeraHertz
  Wireless Networks",,,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops a stochastic geometry framework to characterize the
statistics of the downlink interference and coverage probability of a typical
user in a coexisting terahertz (THz) and radio frequency (RF) network. We first
characterize the exact Laplace Transform (LT) of the aggregate interference and
coverage probability of a user in a THz-only network. Then, for a coexisting
RF/THz network, we derive the coverage probability of a typical user
considering biased received signal power association (BRSP). The framework can
be customized to capture the performance of a typical user in various network
configurations such as THz-only, opportunistic RF/THz, and hybrid RF/THz. In
addition, asymptotic approximations are presented for scenarios where the
intensity of THz BSs becomes large or molecular absorption coefficient in THz
approaches to zero. Numerical results demonstrate the accuracy of the derived
expressions and extract insights related to the significance of the BRSP
association compared to the conventional reference signal received power (RSRP)
association in the coexisting network.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:25:49 GMT""}]","2023-04-06"
"2006.08779","Yaqing Wang","Yaqing Wang, Yifan Ethan Xu, Xian Li, Xin Luna Dong and Jing Gao","Automatic Validation of Textual Attribute Values in E-commerce Catalog
  by Learning with Limited Labeled Data","KDD 2020",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Product catalogs are valuable resources for eCommerce website. In the
catalog, a product is associated with multiple attributes whose values are
short texts, such as product name, brand, functionality and flavor. Usually
individual retailers self-report these key values, and thus the catalog
information unavoidably contains noisy facts. Although existing deep neural
network models have shown success in conducting cross-checking between two
pieces of texts, their success has to be dependent upon a large set of quality
labeled data, which are hard to obtain in this validation task: products span a
variety of categories. To address the aforementioned challenges, we propose a
novel meta-learning latent variable approach, called MetaBridge, which can
learn transferable knowledge from a subset of categories with limited labeled
data and capture the uncertainty of never-seen categories with unlabeled data.
More specifically, we make the following contributions. (1) We formalize the
problem of validating the textual attribute values of products from a variety
of categories as a natural language inference task in the few-shot learning
setting, and propose a meta-learning latent variable model to jointly process
the signals obtained from product profiles and textual attribute values. (2) We
propose to integrate meta learning and latent variable in a unified model to
effectively capture the uncertainty of various categories. (3) We propose a
novel objective function based on latent variable model in the few-shot
learning setting, which ensures distribution consistency between unlabeled and
labeled data and prevents overfitting by sampling from the learned
distribution. Extensive experiments on real eCommerce datasets from hundreds of
categories demonstrate the effectiveness of MetaBridge on textual attribute
validation and its outstanding performance compared with state-of-the-art
approaches.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:31:05 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 01:42:13 GMT""},{""version"":""v3"",""created"":""Tue, 23 Jun 2020 03:52:03 GMT""}]","2020-06-24"
"2006.08780","Theodore Pailas","T. Pailas","""Time""-covariant Schr\""odinger equation and the canonical quantization
  of the Reissner-Nordstr\""om black hole","4 figures",,"10.3390/quantum2030029",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A ""time""-covariant Schr\""{o}dinger equation is defined for the minisuperspace
model of the Reissner-Nordstr\""{o}m (RN) black hole, as a ""hybrid"" between the
""intrinsic time"" Schr\""{o}dinger and Wheeler-DeWitt(WDW) equations. To do so, a
reduced, regular and ""time(r)""-dependent Hamiltonian density was constructed,
without ""breaking"" the re-parametrization covariance $r\rightarrow
f(\tilde{r})$. As a result, evolution of states with respect to the parameter
$r$ and probabilistic interpretation of the resulting quantum description is
possible, while quantum schemes for different gauge choices are equivalent by
construction. The solutions are found for a Dirac's delta and a Gaussian
initial states. A geometrical interpretation of the wavefunctions is presented
via Bohm analysis. Alongside, a criterion is presented to adjudicate which,
between two singular spacetimes is ""more"" or ""less"" singular. Two ways to
adjudicate about the existence of singularities are compared (vanishing of the
probability density at the classical singularity and semi-classical spacetime
singularity). Finally, an equivalence of the reduced equations with these of a
3D electromagnetic pp-wave spacetime is revealed.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:31:42 GMT""},{""version"":""v2"",""created"":""Tue, 24 Nov 2020 23:17:10 GMT""}]","2020-11-26"
"2006.08781","Jeremiah Birrell","Jeremiah Birrell, Markos A. Katsoulakis, Yannis Pantazis","Optimizing Variational Representations of Divergences and Accelerating
  their Statistical Estimation","48 pages, 6 figures",,,,"cs.LG cs.IT math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variational representations of divergences and distances between
high-dimensional probability distributions offer significant theoretical
insights and practical advantages in numerous research areas. Recently, they
have gained popularity in machine learning as a tractable and scalable approach
for training probabilistic models and for statistically differentiating between
data distributions. Their advantages include: 1) They can be estimated from
data as statistical averages. 2) Such representations can leverage the ability
of neural networks to efficiently approximate optimal solutions in function
spaces. However, a systematic and practical approach to improving the tightness
of such variational formulas, and accordingly accelerate statistical learning
and estimation from data, is currently lacking. Here we develop such a
methodology for building new, tighter variational representations of
divergences. Our approach relies on improved objective functionals constructed
via an auxiliary optimization problem. Furthermore, the calculation of the
functional Hessian of objective functionals unveils the local curvature
differences around the common optimal variational solution; this quantifies and
orders the tightness gains between different variational representations.
Finally, numerical simulations utilizing neural network optimization
demonstrate that tighter representations can result in significantly faster
learning and more accurate estimation of divergences in both synthetic and real
datasets (of more than 1000 dimensions), often accelerated by nearly an order
of magnitude.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:32:21 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 23:11:14 GMT""},{""version"":""v3"",""created"":""Wed, 23 Mar 2022 18:32:59 GMT""}]","2022-03-25"
"2006.08782","Craig Roberts","Craig D. Roberts and Sebastian M. Schmidt","Reflections upon the Emergence of Hadronic Mass","13 pages, 9 figures. Invited contribution to EPJ ST Issue ""Strong
  Correlations in Dense Matter Physics""",,"10.1140/epjst/e2020-000064-6","NJU-INP 018/20","hep-ph hep-ex hep-lat nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With discovery of the Higgs boson, science has located the source for
$\lesssim 2$% of the mass of visible matter. The focus of attention can now
shift to the search for the origin of the remaining $\gtrsim 98$%. The
instruments at work here must be capable of simultaneously generating the 1 GeV
mass-scale associated with the nucleon and ensuring that this mass-scale is
completely hidden in the chiral-limit pion. This hunt for an understanding of
the emergence of hadronic mass (EHM) has actually been underway for many years.
What is changing are the impacts of QCD-related theory, through the elucidation
of clear signals for EHM in hadron observables, and the ability of modern and
planned experimental facilities to access these observables. These developments
are exemplified in a discussion of the evolving understanding of pion and kaon
parton distributions.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:34:54 GMT""}]","2021-02-03"
"2006.08783","Claire David","Claire David and Pierre Sagaut","Structural stability of Lattice Boltzmann schemes",,,,,"physics.comp-ph cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of this work is to determine classes of traveling solitary wave
solutions for Lattice Boltzmann schemes by means of an hyperbolic ansatz. It is
shown that spurious solitary waves can occur in finite-difference solutions of
nonlinear wave equation. The occurence of such a spurious solitary wave, which
exhibits a very long life time, results in a non-vanishing numerical error for
arbitrary time in unbounded numerical domain. Such a behavior is referred here
to have a structural instability of the scheme, since the space of solutions
spanned by the numerical scheme encompasses types of solutions (solitary waves
in the present case) that are not solutions of the original continuous
equations. This paper extends our previous work about classical schemes to
Lattice Boltzmann schemes.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:35:09 GMT""}]","2020-06-17"
"2006.08784","\'Oscar Carri\'on-Gonz\'alez","\'Oscar Carri\'on-Gonz\'alez, Antonio Garc\'ia Mu\~noz, Juan Cabrera,
  Szil\'ard Csizmadia, Nuno C. Santos, Heike Rauer","Directly imaged exoplanets in reflected starlight. The importance of
  knowing the planet radius","Accepted for publication in A&A. 22 pages, 6 Tables, 16 figures. The
  abstract has been shortened to meet arXiv requirements","A&A 640, A136 (2020)","10.1051/0004-6361/202038101",,"astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have investigated the information content in reflected-starlight spectra
of exoplanets. We specify our analysis to Barnard's Star b candidate
super-Earth, for which we assume a radius 0.6 times that of Neptune, an
atmosphere dominated by H$_2$-He, and a CH$_4$ volume mixing ratio of
5$\cdot$10$^{-3}$. The main conclusions of our study are however
planet-independent. We set up a model of the exoplanet described by seven
parameters including its radius, atmospheric methane abundance and basic
properties of a cloud layer. We generate synthetic spectra at zero phase (full
disk illumination) from 500 to 900 nm and spectral resolution R$\sim$125-225.
We simulate a measured spectrum with a simplified, wavelength-independent noise
model at Signal-to-Noise ratio S/N=10. With an MCMC-based retrieval
methodology, we analyse which planet/atmosphere parameters can be inferred from
the measured spectrum and the theoretical correlations amongst them. We
consider limiting cases in which the planet radius is either known or
completely unknown, and intermediate cases in which the planet radius is partly
constrained. If the planet radius is known, we can generally discriminate
between cloud-free and cloudy atmospheres, and constrain the methane abundance
to within two orders of magnitude. If the planet radius is unknown, new
correlations between model parameters occur and the accuracy of the retrievals
decreases. Without a radius determination, it is challenging to discern whether
the planet has clouds, and the estimates on methane abundance degrade. However,
we find the planet radius is constrained to within a factor of two for all the
cases explored. Having a priori information on the planet radius, even if
approximate, helps improve the retrievals. We urge exoplanet detection efforts
to extend the population of long-period planets with mass and radius
determinations.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:35:50 GMT""}]","2020-09-02"
"2006.08785","Anji Liu","Anji Liu and Yitao Liang and Ji Liu and Guy Van den Broeck and Jianshu
  Chen","On Effective Parallelization of Monte Carlo Tree Search",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite its groundbreaking success in Go and computer games, Monte Carlo Tree
Search (MCTS) is computationally expensive as it requires a substantial number
of rollouts to construct the search tree, which calls for effective
parallelization. However, how to design effective parallel MCTS algorithms has
not been systematically studied and remains poorly understood. In this paper,
we seek to lay its first theoretical foundation, by examining the potential
performance loss caused by parallelization when achieving a desired speedup. In
particular, we discover the necessary conditions of achieving a desirable
parallelization performance, and highlight two of their practical benefits.
First, by examining whether existing parallel MCTS algorithms satisfy these
conditions, we identify key design principles that should be inherited by
future algorithms, for example tracking the unobserved samples (used in WU-UCT
(Liu et al., 2020)). We theoretically establish this essential design
facilitates $\mathcal{O} ( \ln n + M / \sqrt{\ln n} )$ cumulative regret when
the maximum tree depth is 2, where $n$ is the number of rollouts and $M$ is the
number of workers. A regret of this form is highly desirable, as compared to
$\mathcal{O} ( \ln n )$ regret incurred by a sequential counterpart, its excess
part approaches zero as $n$ increases. Second, and more importantly, we
demonstrate how the proposed necessary conditions can be adopted to design more
effective parallel MCTS algorithms. To illustrate this, we propose a new
parallel MCTS algorithm, called BU-UCT, by following our theoretical
guidelines. The newly proposed algorithm, albeit preliminary, out-performs four
competitive baselines on 11 out of 15 Atari games. We hope our theoretical
results could inspire future work of more effective parallel MCTS.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:36:00 GMT""},{""version"":""v2"",""created"":""Sun, 4 Oct 2020 21:13:55 GMT""}]","2020-10-06"
"2006.08786","Robin Verstraten","Robin C. Verstraten, Rodrigo F. Ozela, Cristiane Morais Smith","Time Glass: A Fractional Calculus Approach","Main text: 6 pages, 3 figures. SM: 10 pages, 4 figures","Phys. Rev. B 103, L180301 (2021)","10.1103/PhysRevB.103.L180301",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Out of equilibrium states in glasses and crystals have been a major topic of
research in condensed-matter physics for many years, and the idea of time
crystals has triggered a flurry of new research. Here, we provide the first
description for the recently conjectured Time Glasses using fractional calculus
methods. An exactly solvable effective theory is introduced, with a continuous
parameter describing the transition from liquid through normal glass, Time
Glass, into the Gardner phase. The phenomenological description with a
fractional Langevin equation is connected to a microscopic model of a particle
in a sub-Ohmic bath in the framework of a generalized Caldeira-Leggett model.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:45:31 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 12:15:09 GMT""}]","2022-06-14"
"2006.08787","Mohamed Majdoub","Mohamed Majdoub, Ezzedine Mliki","Well-posedness for Hardy-H\'enon parabolic equations with fractional
  Brownian noise",,,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Hardy-H\'enon parabolic equations on $\mathbb{R}^{N}$ ($N=2, 3$)
under the effect of an additive fractional Brownian noise with Hurst parameter
$H>\max\left(1/2, N/4\right).$ We show local existence and uniqueness of a mid
$L^{q}$-solution under suitable assumptions on $q$.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:47:21 GMT""}]","2020-06-17"
"2006.08788","Xavier Gitiaux","Xavier Gitiaux, Huzefa Rangwala","Learning Smooth and Fair Representations",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Organizations that own data face increasing legal liability for its
discriminatory use against protected demographic groups, extending to
contractual transactions involving third parties access and use of the data.
This is problematic, since the original data owner cannot ex-ante anticipate
all its future uses by downstream users. This paper explores the upstream
ability to preemptively remove the correlations between features and sensitive
attributes by mapping features to a fair representation space. Our main result
shows that the fairness measured by the demographic parity of the
representation distribution can be certified from a finite sample if and only
if the chi-squared mutual information between features and representations is
finite. Empirically, we find that smoothing the representation distribution
provides generalization guarantees of fairness certificates, which improves
upon existing fair representation learning approaches. Moreover, we do not
observe that smoothing the representation distribution degrades the accuracy of
downstream tasks compared to state-of-the-art methods in fair representation
learning.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:51:50 GMT""}]","2020-06-17"
"2006.08789","Thomas Pock","Erich Kobler, Alexander Effland, Karl Kunisch, Thomas Pock","Total Deep Variation: A Stable Regularizer for Inverse Problems","30 pages, 12 figures. arXiv admin note: text overlap with
  arXiv:2001.05005",,,,"cs.CV cs.NA math.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Various problems in computer vision and medical imaging can be cast as
inverse problems. A frequent method for solving inverse problems is the
variational approach, which amounts to minimizing an energy composed of a data
fidelity term and a regularizer. Classically, handcrafted regularizers are
used, which are commonly outperformed by state-of-the-art deep learning
approaches. In this work, we combine the variational formulation of inverse
problems with deep learning by introducing the data-driven general-purpose
total deep variation regularizer. In its core, a convolutional neural network
extracts local features on multiple scales and in successive blocks. This
combination allows for a rigorous mathematical analysis including an optimal
control formulation of the training problem in a mean-field setting and a
stability analysis with respect to the initial values and the parameters of the
regularizer. In addition, we experimentally verify the robustness against
adversarial attacks and numerically derive upper bounds for the generalization
error. Finally, we achieve state-of-the-art results for numerous imaging tasks.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:54:15 GMT""}]","2020-06-17"
"2006.08790","Quentin Rebjock","Armin Askari, Quentin Rebjock, Alexandre d'Aspremont and Laurent El
  Ghaoui","FANOK: Knockoffs in Linear Time","For code see https://github.com/qrebjock/fanok",,,,"cs.LG stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a series of algorithms that efficiently implement Gaussian
model-X knockoffs to control the false discovery rate on large scale feature
selection problems. Identifying the knockoff distribution requires solving a
large scale semidefinite program for which we derive several efficient methods.
One handles generic covariance matrices, has a complexity scaling as $O(p^3)$
where $p$ is the ambient dimension, while another assumes a rank $k$ factor
model on the covariance matrix to reduce this complexity bound to $O(pk^2)$. We
also derive efficient procedures to both estimate factor models and sample
knockoff covariates with complexity linear in the dimension. We test our
methods on problems with $p$ as large as $500,000$.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:55:34 GMT""}]","2020-06-17"
"2006.08791","Kaifu Wang","Kaifu Wang, Qiang Ning, Dan Roth","Learnability with Indirect Supervision Signals",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning from indirect supervision signals is important in real-world AI
applications when, often, gold labels are missing or too costly. In this paper,
we develop a unified theoretical framework for multi-class classification when
the supervision is provided by a variable that contains nonzero mutual
information with the gold label. The nature of this problem is determined by
(i) the transition probability from the gold labels to the indirect supervision
variables and (ii) the learner's prior knowledge about the transition. Our
framework relaxes assumptions made in the literature, and supports learning
with unknown, non-invertible and instance-dependent transitions. Our theory
introduces a novel concept called \emph{separation}, which characterizes the
learnability and generalization bounds. We also demonstrate the application of
our framework via concrete novel results in a variety of learning scenarios
such as learning with superset annotations and joint supervision signals.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:57:11 GMT""},{""version"":""v2"",""created"":""Wed, 11 Nov 2020 10:12:53 GMT""}]","2020-11-12"
"2006.08792","Emiel Van Miltenburg","Emiel van Miltenburg","On the use of human reference data for evaluating automatic image
  descriptions","Originally presented as a (non-archival) poster at the VizWiz 2020
  workshop, collocated with CVPR 2020. See:
  https://vizwiz.org/workshops/2020-workshop/",,,,"cs.CL cs.CV cs.HC","http://creativecommons.org/licenses/by/4.0/","  Automatic image description systems are commonly trained and evaluated using
crowdsourced, human-generated image descriptions. The best-performing system is
then determined using some measure of similarity to the reference data (BLEU,
Meteor, CIDER, etc). Thus, both the quality of the systems as well as the
quality of the evaluation depends on the quality of the descriptions. As
Section 2 will show, the quality of current image description datasets is
insufficient. I argue that there is a need for more detailed guidelines that
take into account the needs of visually impaired users, but also the
feasibility of generating suitable descriptions. With high-quality data,
evaluation of image description systems could use reference descriptions, but
we should also look for alternatives.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:57:27 GMT""}]","2020-06-17"
"2006.08793","Stephanie Simmons","L. Bergeron, C. Chartrand, A. T. K. Kurkjian, K. J. Morse, H. Riemann,
  N. V. Abrosimov, P. Becker, H.-J. Pohl, M. L. W. Thewalt, and S. Simmons","A silicon-integrated telecom photon-spin interface","5 pages, 3 figures","PRX Quantum 1, 020301 (2020)","10.1103/PRXQuantum.1.020301",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Long-distance entanglement distribution is a vital capability for quantum
technologies. An outstanding practical milestone towards this aim is the
identification of a suitable matter-photon interface which possesses,
simultaneously, long coherence lifetimes and efficient telecommunications-band
optical access. In this work, alongside its sister publication, we report upon
the T center, a silicon defect with spin-selective optical transitions at 1326
nm in the telecommunications O-band. Here we show that the T center in
$^{28}$Si offers electron and nuclear spin lifetimes beyond a millisecond and
second respectively, as well as optical lifetimes of 0.94(1) $\mu$s and a
Debye-Waller factor of 0.23(1). This work represents a significant step towards
coherent photonic interconnects between long-lived silicon spins,
spin-entangled telecom single-photon emitters, and spin-dependent
silicon-integrated photonic nonlinearities for future global quantum
technologies.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:58:36 GMT""}]","2020-10-07"
"2006.08794","Stephanie Simmons","L. Bergeron, C. Chartrand, A. T. K. Kurkjian, K. J. Morse, H. Riemann,
  N. V. Abrosimov, P. Becker, H.-J. Pohl, M. L. W. Thewalt, and S. Simmons","Characterization of the T center in $^{28}$Si","13 pages, 10 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Silicon is host to two separate leading quantum technology platforms:
integrated silicon photonics as well as long-lived spin qubits. There is an
ongoing search for the ideal photon-spin interface able to hybridize these two
approaches into a single silicon platform offering substantially expanded
capabilities. A number of silicon defects are known to have spin-selective
optical transitions, although very few of these are known to be in the highly
desirable telecommunications bands, and those that do often do not couple
strongly to light. Here we characterize the T center in silicon, a highly
stable silicon defect which supports a short-lived bound exciton that upon
recombination emits light in the telecommunications O-band. In this first study
of T centers in $^{28}$Si, we present the temperature dependence of the zero
phonon line, report ensemble zero phonon linewidths as narrow as 33(2) MHz, and
elucidate the excited state spectrum of the bound exciton.
Magneto-photoluminescence, in conjunction with magnetic resonance, is used to
observe twelve distinct orientational subsets of the T center, which are
independently addressable due to the anisotropic g factor of the bound
exciton's hole spin. The T center is thus a promising contender for the
hybridization of silicon's two leading quantum technology platforms.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:58:42 GMT""}]","2020-06-17"
"2006.08795","Shorya Consul","Shorya Consul, Sinead A. Williamson","Balance is key: Private median splits yield high-utility random trees","17 pages",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Random forests are a popular method for classification and regression due to
their versatility. However, this flexibility can come at the cost of user
privacy, since training random forests requires multiple data queries, often on
small, identifiable subsets of the training data. Privatizing these queries
typically comes at a high utility cost, in large part because we are
privatizing queries on small subsets of the data, which are easily corrupted by
added noise. In this paper, we propose DiPriMe forests, a novel tree-based
ensemble method for differentially private regression and classification, which
is appropriate for real or categorical covariates. We generate splits using a
differentially private version of the median, which encourages balanced leaf
nodes. By avoiding low occupancy leaf nodes, we avoid high signal-to-noise
ratios when privatizing the leaf node sufficient statistics. We show
theoretically and empirically that the resulting algorithm exhibits high
utility, while ensuring differential privacy.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:59:30 GMT""},{""version"":""v2"",""created"":""Sat, 20 Feb 2021 01:18:15 GMT""}]","2021-02-23"
"2006.08796","Rakshith Sharma Srinivasa","Rakshith S Srinivasa, Cao Xiao, Lucas Glass, Justin Romberg, Jimeng
  Sun","Fast Graph Attention Networks Using Effective Resistance Based Graph
  Sparsification",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The attention mechanism has demonstrated superior performance for inference
over nodes in graph neural networks (GNNs), however, they result in a high
computational burden during both training and inference. We propose FastGAT, a
method to make attention based GNNs lightweight by using spectral
sparsification to generate an optimal pruning of the input graph. This results
in a per-epoch time that is almost linear in the number of graph nodes as
opposed to quadratic. We theoretically prove that spectral sparsification
preserves the features computed by the GAT model, thereby justifying our
algorithm. We experimentally evaluate FastGAT on several large real world graph
datasets for node classification tasks under both inductive and transductive
settings. FastGAT can dramatically reduce (up to \textbf{10x}) the
computational time and memory requirements, allowing the usage of attention
based GNNs on large graphs.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:07:54 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 14:14:32 GMT""},{""version"":""v3"",""created"":""Mon, 5 Oct 2020 15:26:10 GMT""}]","2020-10-06"
"2006.08797","Ahmed Akhtar","A. A. Akhtar and Yi-Zhuang You","Multi-Region Entanglement in Locally Scrambled Quantum Dynamics","23 pages, 15 figures; added & updated references","Phys. Rev. B 102, 134203 (2020)","10.1103/PhysRevB.102.134203",,"cond-mat.dis-nn cond-mat.stat-mech cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the evolution of multi-region bipartite entanglement entropy under
locally scrambled quantum dynamics. We show that the multi-region entanglement
can significantly modify the growth of single-region entanglement, whose effect
has been largely overlooked in the existing literature. We developed a novel
theoretical framework, called the entanglement feature formalism, to organize
all the multi-region entanglement systematically as a sign-free many-body
state. We further propose a two-parameter matrix product state (MPS) ansatz to
efficiently capture the exponentially many multi-region entanglement features.
Using these tools, we are able to study the multi-region entanglement dynamics
jointly and represent the evolution in the MPS parameter space. By comparing
the dynamical constraints on the motion of entanglement cuts, we are able to
identify different quantum dynamics models in a unifying entanglement feature
Hamiltonian. Depending on the quantum dynamics model, we find that multi-region
effects can dominate the single region entanglement growth and only vanish for
Haar random circuits. We calculate the operator-averaged out-of-time-order
correlator based on the entanglement feature Hamiltonian and extract the
butterfly velocity from the result. We show that the previously conjectured
bound between the entanglement velocity and the butterfly velocity holds true
even under the influence of multi-region entanglement. These developments could
enable more efficient numerical simulations and more systematic theoretical
understandings of the multi-region entanglement dynamics in quantum many-body
systems.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:09:10 GMT""},{""version"":""v2"",""created"":""Sat, 5 Sep 2020 18:30:42 GMT""}]","2020-10-07"
"2006.08798","Matilde Tristany Farinha Miss","Matilde Tristany Farinha, S\'ergio Pequito, Pedro A. Santos, M\'ario
  A. T. Figueiredo","Equilibrium Propagation for Complete Directed Neural Networks","6 pages, 6 images, accepted for ESANN 2020",,,,"cs.LG cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial neural networks, one of the most successful approaches to
supervised learning, were originally inspired by their biological counterparts.
However, the most successful learning algorithm for artificial neural networks,
backpropagation, is considered biologically implausible. We contribute to the
topic of biologically plausible neuronal learning by building upon and
extending the equilibrium propagation learning framework. Specifically, we
introduce: a new neuronal dynamics and learning rule for arbitrary network
architectures; a sparsity-inducing method able to prune irrelevant connections;
a dynamical-systems characterization of the models, using Lyapunov theory.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:12:30 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 10:23:51 GMT""}]","2020-06-18"
"2006.08799","Christian Lenz","Christian T. Lenz, Hubert Klahr, Tilman Birnstiel, Katherine Kretke,
  and Sebastian Stammler","Constraining the parameter space for the Solar Nebula","A&A accepted",,"10.1051/0004-6361/202037878",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If we want to understand planetesimal formation, the only data set we have is
our own Solar System. It is particularly interesting as it is so far the only
planetary system we know of that developed life. Understanding the conditions
under which the Solar Nebula evolved is crucial in order to understand the
different processes in the disk and the subsequent dynamical interaction
between (proto-)planets, once the gas disk is gone. Protoplanetary disks
provide a plethora of different parameters to explore. The question is whether
this parameter space can be constrained, allowing simulations to reproduce the
Solar System. Models and observations of planet formation provide constraints
on the initial planetesimal mass in certain regions of the Solar Nebula. By
making use of pebble flux-regulated planetesimal formation, we perform a
parameter study with nine different disk parameters like the initial disk mass,
initial disk size, initial dust-to-gas ratio, turbulence level, and more. We
find that the distribution of mass in planetesimals in the disk depends on the
planetesimal formation timescale and the pebbles' drift timescale. Multiple
disk parameters can influence pebble properties and thus planetesimal
formation. However, it is still possible to draw some conclusions on potential
parameter ranges. Pebble flux-regulated planetesimal formation seems to be very
robust, allowing simulations with a wide range of parameters to meet the
initial planetesimal constraints for the Solar Nebula. I.e., it does not
require a lot of fine tuning.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:14:10 GMT""}]","2022-11-23"
"2006.08800","David De La Cruz G\'omez","Alejandro Ayala, David de la Cruz, L. A. Hern\'andez, S.
  Hern\'andez-Ort\'iz and Jordi Salinas","Quark spin - thermal vorticity alignment and the Lambda, anti-Lambda
  polarization in heavy-ion collisions","9 pages, 5 figures. Proceedings of the 36th Winter Workshop on
  Nuclear Dynamics, Puerto Vallarta, Mexico 2020",,"10.1088/1742-6596/1602/1/012025",,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been proposed that the $\Lambda$ and $\overline{\Lambda}$
polarizations observed in heavy-ion collisions are due to the interaction
between quark spin and thermal vorticity. In this work we report on a
computation of the relaxation time required for this alignment to occur at
finite temperature and baryon chemical potential, considering quarks with a
finite mass. The calculation is performed after modelling the interaction by
means of an effective vertex which couples the thermal gluons and quarks within
the vortical medium. We show that the effect of the quark mass is to reduce the
relaxation time as compared to the massless quark case. An intrinsic global
polarization of quarks/antiquarks emerges which is shown to be linked with the
$\Lambda$/$\bar{\Lambda}$ polarization.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:17:26 GMT""}]","2020-09-23"
"2006.08801","Niall Bootland","Niall Bootland, Victorita Dolean, Alexandros Kyriakis, Jennifer
  Pestana","Analysis of parallel Schwarz algorithms for time-harmonic problems using
  block Toeplitz matrices",,"Electron. Trans. Numer. Anal., 55, 112-141 (2022)","10.1553/etna_vol55s112",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we study the convergence properties of the one-level parallel
Schwarz method with Robin transmission conditions applied to the
one-dimensional and two-dimensional Helmholtz and Maxwell's equations.
One-level methods are not scalable in general. However, it has recently been
proven that when impedance transmission conditions are used in the case of the
algorithm applied to the equations with absorption, under certain assumptions,
scalability can be achieved and no coarse space is required. We show here that
this result is also true for the iterative version of the method at the
continuous level for strip-wise decompositions into subdomains that can
typically be encountered when solving wave-guide problems. The convergence
proof relies on the particular block Toeplitz structure of the global iteration
matrix. Although non-Hermitian, we prove that its limiting spectrum has a near
identical form to that of a Hermitian matrix of the same structure. We
illustrate our results with numerical experiments.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:18:51 GMT""},{""version"":""v2"",""created"":""Sun, 28 Feb 2021 17:50:11 GMT""},{""version"":""v3"",""created"":""Tue, 31 Aug 2021 14:15:03 GMT""}]","2022-01-13"
"2006.08802","Bartosz Fornal","Bartosz Fornal","Gravitational Wave Signatures of Lepton Universality Violation","8 pages, 4 figures; v2: published version","Phys. Rev. D 103, 015018 (2021)","10.1103/PhysRevD.103.015018",,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We analyze the prospects for using gravitational waves produced in early
universe phase transitions as a complementary probe of the flavor anomalies in
B meson decays. We focus on the Left-Right SU(4) Model, for which the strength
of the observed lepton universality violation and consistency with other
experiments impose a vast hierarchy between the symmetry breaking scales. This
leads to a multipeaked gravitational wave signature within the reach of
upcoming gravitational wave detectors.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:20:16 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jan 2021 03:30:00 GMT""}]","2021-01-19"
"2006.08803","Nils Paar Dr.","A. Ravlic, E. Yuksel, Y. F. Niu, G. Colo, E. Khan, N. Paar","Stellar electron capture rates based on finite temperature relativistic
  quasiparticle random-phase approximation","16 pages, 11 figures, submitted to Physical Review C","Phys. Rev. C 102, 065804 (2020)","10.1103/PhysRevC.102.065804",,"nucl-th astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The electron capture process plays an important role in the evolution of the
core collapse of a massive star that precedes the supernova explosion. In this
study, the electron capture on nuclei in stellar environment is described in
the relativistic energy density functional framework, including both the finite
temperature and nuclear pairing effects. Relevant nuclear transitions $J^\pi =
0^\pm, 1^\pm, 2^\pm$ are calculated using the finite temperature proton-neutron
quasiparticle random phase approximation with the density-dependent
meson-exchange effective interaction DD-ME2. The pairing and temperature
effects are investigated in the Gamow-Teller transition strength as well as the
electron capture cross sections and rates for ${}^{44}$Ti and ${}^{56}$Fe in
stellar environment. It is found that the pairing correlations establish an
additional unblocking mechanism similar to the finite temperature effects, that
can allow otherwise blocked single-particle transitions. Inclusion of pairing
correlations at finite temperature can significantly alter the electron capture
cross sections, even up to a factor of two for ${}^{44}$Ti, while for the same
nucleus electron capture rates can increase by more than one order of
magnitude. We conclude that for the complete description of electron capture on
nuclei both pairing and temperature effects must be taken into account.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:22:41 GMT""}]","2021-01-04"
"2006.08804","Mingyuan Zhou","Hao Zhang, Bo Chen, Yulai Cong, Dandan Guo, Hongwei Liu, Mingyuan Zhou","Deep Autoencoding Topic Model with Scalable Hybrid Bayesian Inference","To appear in IEEE Transactions on Pattern Analysis and Machine
  Intelligence. arXiv admin note: text overlap with arXiv:1803.01328",,,,"cs.LG stat.AP stat.CO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To build a flexible and interpretable model for document analysis, we develop
deep autoencoding topic model (DATM) that uses a hierarchy of gamma
distributions to construct its multi-stochastic-layer generative network. In
order to provide scalable posterior inference for the parameters of the
generative network, we develop topic-layer-adaptive stochastic gradient
Riemannian MCMC that jointly learns simplex-constrained global parameters
across all layers and topics, with topic and layer specific learning rates.
Given a posterior sample of the global parameters, in order to efficiently
infer the local latent representations of a document under DATM across all
stochastic layers, we propose a Weibull upward-downward variational encoder
that deterministically propagates information upward via a deep neural network,
followed by a Weibull distribution based stochastic downward generative model.
To jointly model documents and their associated labels, we further propose
supervised DATM that enhances the discriminative power of its latent
representations. The efficacy and scalability of our models are demonstrated on
both unsupervised and supervised learning tasks on big corpora.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:22:56 GMT""}]","2020-06-17"
"2006.08805","Oznur Alkan","Oznur Alkan and Elizabeth Daly","User Profiling from Reviews for Accurate Time-Based Recommendations",,,,,"cs.IR cs.HC cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender systems are a valuable way to engage users in a system, increase
participation and show them resources they may not have found otherwise. One
significant challenge is that user interests may change over time and certain
items have an inherently temporal aspect. As a result, a recommender system
should try and take into account the time-dependant user-item relationships.
However, temporal aspects of a user profile may not always be explicitly
available and so we may need to infer this information from available
resources. Product reviews on sites, such as Amazon, represent a valuable data
source to understand why someone bought an item and potentially who the item is
for. This information can then be used to construct a dynamic user profile. In
this paper, we demonstrate utilising reviews to extract temporal information to
infer the \textit{age category preference} of users, and leverage this feature
to generate time-dependent recommendations. Given the predictable and yet
shifting nature of age and time, we show that, recommendations generated using
this dynamic aspect lead to higher accuracy compared with techniques from state
of art. Mining temporally related content in reviews can enable the recommender
to go beyond finding similar items or users to potentially predict a future
need of a user.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:23:17 GMT""}]","2020-06-17"
"2006.08806","Alexander Evans","Alex Evans","Liquidity Provider Returns in Geometric Mean Markets",,,,,"q-fin.MF q-fin.PR q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Geometric mean market makers (G3Ms), such as Uniswap and Balancer, comprise a
popular class of automated market makers (AMMs) defined by the following rule:
the reserves of the AMM before and after each trade must have the same
(weighted) geometric mean. This paper extends several results known for
constant-weight G3Ms to the general case of G3Ms with time-varying and
potentially stochastic weights. These results include the returns and
no-arbitrage prices of liquidity pool (LP) shares that investors receive for
supplying liquidity to G3Ms. Using these expressions, we show how to create
G3Ms whose LP shares replicate the payoffs of financial derivatives. The
resulting hedges are model-independent and exact for derivative contracts whose
payoff functions satisfy an elasticity constraint. These strategies allow LP
shares to replicate various trading strategies and financial contracts,
including standard options. G3Ms are thus shown to be capable of recreating a
variety of active trading strategies through passive positions in LP shares.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:24:40 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 22:20:08 GMT""},{""version"":""v3"",""created"":""Fri, 10 Jul 2020 15:59:44 GMT""},{""version"":""v4"",""created"":""Tue, 14 Jul 2020 22:58:00 GMT""}]","2020-07-16"
"2006.08807","Pingye Zhang","Pingye Zhang, Junshui Ma, Xinqun Chen, Yue Shentu","A Nonparametric Method for Value Function Guided Subgroup Identification
  via Gradient Tree Boosting for Censored Survival Data","33 pages, 3 figures, 4 tables. Revisions Submitted to Statistics in
  Medicine",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In randomized clinical trials with survival outcome, there has been an
increasing interest in subgroup identification based on baseline genomic,
proteomic markers or clinical characteristics. Some of the existing methods
identify subgroups that benefit substantially from the experimental treatment
by directly modeling outcomes or treatment effect. When the goal is to find an
optimal treatment for a given patient rather than finding the right patient for
a given treatment, methods under the individualized treatment regime framework
estimate an individualized treatment rule that would lead to the best expected
clinical outcome as measured by a value function. Connecting the concept of
value function to subgroup identification, we propose a nonparametric method
that searches for subgroup membership scores by maximizing a value function
that directly reflects the subgroup-treatment interaction effect based on
restricted mean survival time. A gradient tree boosting algorithm is proposed
to search for the individual subgroup membership scores. We conduct simulation
studies to evaluate the performance of the proposed method and an application
to an AIDS clinical trial is performed for illustration.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:26:58 GMT""}]","2020-06-17"
"2006.08808","Andrew Kent","Ferran Maci\`a and Andrew D. Kent","Magnetic Droplet Solitons","9 pages, 9 figures","Journal of Applied Physics 128, 100901 (2020)","10.1063/5.0018251",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic droplet solitons are dynamical magnetic textures that form due to an
attractive interaction between spin waves in thin films with perpendicular
magnetic anisotropy. Spin currents and the spin torques associated with these
currents enable their formation as they provide a means to excite
non-equilibrium spin wave populations and compensate their decay. Recent years
have seen rapid advances in experiments that realize and study magnetic
droplets. Important advances include the first direct x-ray images of droplets,
determination of their threshold and sustaining currents, measurement of their
generation and annihilation time and evidence for drift instabilities, which
can limit their lifetime in spin-transfer nanocontacts. This article reviews
these studies and contrasts these solitons to other types of spin-current
excitations such as spin-wave bullets, and static magnetic textures, including
magnetic vortices and skyrmions. Magnetic droplet solitons can also serve as
current controlled microwave frequency oscillators with potential applications
in neuromorphic chips as nonlinear oscillators with memory.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:31:59 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 15:37:15 GMT""}]","2020-09-10"
"2006.08809","Micha{\l} Okulewicz","Micha{\l} Okulewicz and Jacek Ma\'ndziuk","A Particle Swarm Optimization hyper-heuristic for the Dynamic Vehicle
  Routing Problem","14 pages, presented at BIOMA 2016 conference, Bled, Slovenia","Proceedings of Bioinspired Optimization Methods and their
  Applications, 215-227, Jozef Stefan Institute, 2016",,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a method for choosing a Particle Swarm Optimization based
optimizer for the Dynamic Vehicle Routing Problem on the basis of the initially
available data of a given problem instance. The optimization algorithm is
chosen on the basis of a prediction made by a linear model trained on that data
and the relative results obtained by the optimization algorithms. The achieved
results suggest that such a model can be used in a hyper-heuristic approach as
it improved the average results, obtained on the set of benchmark instances, by
choosing the appropriate algorithm in 82% of significant cases. Two leading
multi-swarm Particle Swarm Optimization based algorithms for solving the
Dynamic Vehicle Routing Problem are used as the basic optimization algorithms:
Khouadjia's et al. Multi-Environmental Multi-Swarm Optimizer and authors'
2--Phase Multiswarm Particle Swarm Optimization.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:34:17 GMT""}]","2020-06-17"
"2006.08810","Alfonso Ballon Bayona","Alfonso Ballon-Bayona, Henrique Boschi-Filho, Eduardo Folco Capossoli
  and Diego M. Rodrigues","Criticality from Einstein-Maxwell-dilaton holography at finite
  temperature and density","V4: 57 pages, 20 figures. Title updated. Published in Physical Review
  D",,"10.1103/PhysRevD.102.126003",,"hep-th hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate consistent charged black hole solutions to the
Einstein-Maxwell-Dilaton (EMD) equations that are asymptotically AdS. The
solutions are gravity duals to phases of a non-conformal plasma at finite
temperature and density. For the dilaton we take a quadratic ansatz leading to
linear confinement at zero temperature and density. We consider a grand
canonical ensemble, where the chemical potential is fixed, and find a rich
phase diagram involving the competition of small and large black holes. The
phase diagram contains a critical line and a critical point similar to the van
der Waals-Maxwell liquid-gas transition. As the critical point is approached,
we show that the trace anomaly in the plasma phases vanishes signifying the
restoration of conformal symmetry in the fluid. We find that the heat capacity
and charge susceptibility diverge as $C_V \propto (T-T^c)^{-\alpha}$ and $\chi
\propto (T-T^c)^{-\gamma}$ at the critical point with universal critical
exponents $\alpha=\gamma=2/3$. Our results suggest a description of the
thermodynamics near the critical point in terms of catastrophe theories. In the
limit $\mu \to 0$ we compare our results with lattice results for $SU(N_c)$
Yang-Mills theories.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:38:23 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 23:23:32 GMT""},{""version"":""v3"",""created"":""Tue, 3 Nov 2020 18:26:51 GMT""},{""version"":""v4"",""created"":""Fri, 4 Dec 2020 01:31:46 GMT""}]","2020-12-07"
"2006.08811","Charles Gon\c{c}alves","Charles F. Gon\c{c}alves, Daniel S. Menasch\'e, Alberto Avritzer, Nuno
  Antunes, Marco Vieira","A Model-Based Approach to Anomaly Detection Trading Detection Time and
  False Alarm Rate","2020 Mediterranean Communication and Computer Networking Conference
  (MedComNet)",,,,"cs.CR cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The complexity and ubiquity of modern computing systems is a fertile ground
for anomalies, including security and privacy breaches. In this paper, we
propose a new methodology that addresses the practical challenges to implement
anomaly detection approaches. Specifically, it is challenging to define normal
behavior comprehensively and to acquire data on anomalies in diverse cloud
environments. To tackle those challenges, we focus on anomaly detection
approaches based on system performance signatures. In particular, performance
signatures have the potential of detecting zero-day attacks, as those
approaches are based on detecting performance deviations and do not require
detailed knowledge of attack history. The proposed methodology leverages an
analytical performance model and experimentation and allows to control the rate
of false positives in a principled manner. The methodology is evaluated using
the TPCx-V workload, which was profiled during a set of executions using
resource exhaustion anomalies that emulate the effects of anomalies affecting
system performance. The proposed approach was able to successfully detect the
anomalies, with a low number of false positives (precision 90%-98%).
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 22:49:57 GMT""}]","2020-06-17"
"2006.08812","Xiongjie Chen","Xiongjie Chen, Yongxin Yang, Yunpeng Li","Augmented Sliced Wasserstein Distances","37 pages, 19 figures, published as a conference paper at ICLR 2022",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While theoretically appealing, the application of the Wasserstein distance to
large-scale machine learning problems has been hampered by its prohibitive
computational cost. The sliced Wasserstein distance and its variants improve
the computational efficiency through the random projection, yet they suffer
from low accuracy if the number of projections is not sufficiently large,
because the majority of projections result in trivially small values. In this
work, we propose a new family of distance metrics, called augmented sliced
Wasserstein distances (ASWDs), constructed by first mapping samples to
higher-dimensional hypersurfaces parameterized by neural networks. It is
derived from a key observation that (random) linear projections of samples
residing on these hypersurfaces would translate to much more flexible nonlinear
projections in the original sample space, so they can capture complex
structures of the data distribution. We show that the hypersurfaces can be
optimized by gradient ascent efficiently. We provide the condition under which
the ASWD is a valid metric and show that this can be obtained by an injective
neural network architecture. Numerical results demonstrate that the ASWD
significantly outperforms other Wasserstein variants for both synthetic and
real-world problems.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:00:08 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 21:40:23 GMT""},{""version"":""v3"",""created"":""Thu, 15 Oct 2020 21:41:02 GMT""},{""version"":""v4"",""created"":""Thu, 1 Jul 2021 14:19:11 GMT""},{""version"":""v5"",""created"":""Mon, 11 Oct 2021 21:00:54 GMT""},{""version"":""v6"",""created"":""Wed, 16 Mar 2022 13:23:45 GMT""},{""version"":""v7"",""created"":""Thu, 17 Mar 2022 12:14:25 GMT""}]","2022-03-18"
"2006.08813","Sahar Daraeizadeh","Sahar Daraeizadeh, Shavindra P. Premaratne, A. Y. Matsuura","Designing high-fidelity multi-qubit gates for semiconductor quantum dots
  through deep reinforcement learning",,,"10.1109/QCE49297.2020.00014",,"quant-ph cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a machine learning framework to design
high-fidelity multi-qubit gates for quantum processors based on quantum dots in
silicon, with qubits encoded in the spin of single electrons. In this hardware
architecture, the control landscape is vast and complex, so we use the deep
reinforcement learning method to design optimal control pulses to achieve high
fidelity multi-qubit gates. In our learning model, a simulator models the
physical system of quantum dots and performs the time evolution of the system,
and a deep neural network serves as the function approximator to learn the
control policy. We evolve the Hamiltonian in the full state-space of the
system, and enforce realistic constraints to ensure experimental feasibility.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:08:46 GMT""}]","2021-03-18"
"2006.08814","Mathieu Tanneau","Miguel F. Anjos, Andrea Lodi, Mathieu Tanneau","Design and implementation of a modular interior-point solver for linear
  optimization",,,"10.1007/s12532-020-00200-8",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces the algorithmic design and implementation of Tulip, an
open-source interior-point solver for linear optimization. It implements a
regularized homogeneous interior-point algorithm with multiple centrality
corrections, and therefore handles unbounded and infeasible problems. The
solver is written in Julia, thus allowing for a flexible and efficient
implementation: Tulip's algorithmic framework is fully disentangled from linear
algebra implementations and from a model's arithmetic. In particular, this
allows to seamlessly integrate specialized routines for structured problems.
Extensive computational results are reported. We find that Tulip is competitive
with open-source interior-point solvers on the H. Mittelmann's benchmark of
barrier linear programming solvers. Furthermore, we design specialized linear
algebra routines for structured master problems in the context of Dantzig-Wolfe
decomposition. These routines yield a tenfold speedup on large and dense
instances that arise in power systems operation and two-stage stochastic
programming, thereby outperforming state-of-the-art commercial interior point
method solvers. Finally, we illustrate Tulip's ability to use different levels
of arithmetic precision by solving problems in extended precision.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:10:03 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 17:50:02 GMT""}]","2022-04-04"
"2006.08815","Li Yan","Jean-Paul Blaizot and Li Yan","Analytical attractor for Bjorken expansion","Updates with new discussion on transasymptotic matching. Version
  accepted for publication in PLB",,"10.1016/j.physletb.2021.136478",,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an analytic solution of a simple set of equations that govern the
expansion of boost-invariant plasmas of massless particles. These equations
describe, approximately, the early time, collisionless regime, and the
transition to hydrodynamics at late time. Their mathematical structure
encompasses all versions of second order hydrodynamics when applied to Bjorken
flows. The analytic solution provides an explicit expression for the attractor
solution that connects the collisionless regime to hydrodynamics. It also
constitutes a neat example of an application of the theory of resurgence in
asymptotic series.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:14:03 GMT""},{""version"":""v2"",""created"":""Fri, 25 Jun 2021 04:54:02 GMT""}]","2021-06-30"
"2006.08816","Cheng Yang","Cheng Yang, Gene Cheung, Wei Hu","Signed Graph Metric Learning via Gershgorin Disc Perfect Alignment","code available: https://github.com/bobchengyang/SGML",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a convex and differentiable objective $Q(\M)$ for a real symmetric
matrix $\M$ in the positive definite (PD) cone -- used to compute Mahalanobis
distances -- we propose a fast general metric learning framework that is
entirely projection-free. We first assume that $\M$ resides in a space $\cS$ of
generalized graph Laplacian matrices corresponding to balanced signed graphs.
$\M \in \cS$ that is also PD is called a graph metric matrix. Unlike low-rank
metric matrices common in the literature, $\cS$ includes the important
diagonal-only matrices as a special case. The key theorem to circumvent full
eigen-decomposition and enable fast metric matrix optimization is Gershgorin
disc perfect alignment (GDPA): given $\M \in \cS$ and diagonal matrix $\S$,
where $S_{ii} = 1/v_i$ and $\v$ is $\M$'s first eigenvector, we prove that
Gershgorin disc left-ends of similarity transform $\B = \S \M \S^{-1}$ are
perfectly aligned at the smallest eigenvalue $\lambda_{\min}$. Using this
theorem, we replace the PD cone constraint in the metric learning problem with
tightest possible linear constraints per iteration, so that the alternating
optimization of the diagonal / off-diagonal terms in $\M$ can be solved
efficiently as linear programs via the Frank-Wolfe method. We update $\v$ using
Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) with warm
start as entries in $\M$ are optimized successively. Experiments show that our
graph metric optimization is significantly faster than cone-projection schemes,
and produces competitive binary classification performance.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:15:12 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 09:23:24 GMT""},{""version"":""v3"",""created"":""Fri, 19 Jun 2020 19:41:53 GMT""},{""version"":""v4"",""created"":""Mon, 6 Jul 2020 04:41:55 GMT""},{""version"":""v5"",""created"":""Sat, 10 Apr 2021 17:54:48 GMT""},{""version"":""v6"",""created"":""Fri, 11 Jun 2021 03:32:47 GMT""}]","2021-06-14"
"2006.08817","Yingyuan Yang","Yingyuan Yang, Xueli Huang, Jiangnan Li, and Jinyuan Sun","BubbleMap: Privilege Mapping for Behavior-based Implicit Authentication
  Systems","12 pages. arXiv admin note: substantial text overlap with
  arXiv:1808.00638",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Leveraging users' behavioral data sampled by various sensors during the
identification process, implicit authentication (IA) relieves users from
explicit actions such as remembering and entering passwords. Various IA schemes
have been proposed based on different behavioral and contextual features such
as gait, touch, and GPS. However, existing IA schemes suffer from false
positives, i.e., falsely accepting an adversary, and false negatives, i.e.,
falsely rejecting the legitimate user due to users' behavior change and noise.
To deal with this problem, we propose BubbleMap (BMap), a framework that can be
seamlessly incorporated into any existing IA system to balance between security
(reducing false positives) and usability (reducing false negatives) as well as
reducing the equal error rate (EER). To evaluate the proposed framework, we
implemented BMap on five state-of-the-art IA systems. We also conducted an
experiment in a real-world environment from 2016 to 2020. Most of the
experimental results show that BMap can greatly enhance the IA schemes'
performances in terms of the EER, security, and usability, with a small amount
of penalty on energy consumption.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:18:24 GMT""},{""version"":""v2"",""created"":""Sat, 12 Mar 2022 22:28:11 GMT""},{""version"":""v3"",""created"":""Wed, 13 Apr 2022 00:09:58 GMT""}]","2022-04-14"
"2006.08818","Ingrid Nunes","Ingrid Nunes, Phillip Taylor, Lina Barakat, Nathan Griffiths, Simon
  Miles","Explaining reputation assessments",,"International Journal of Human-Computer Studies, 123, 1-17 (2019)","10.1016/j.ijhcs.2018.10.007",,"cs.AI cs.HC","http://creativecommons.org/licenses/by/4.0/","  Reputation is crucial to enabling human or software agents to select among
alternative providers. Although several effective reputation assessment methods
exist, they typically distil reputation into a numerical representation, with
no accompanying explanation of the rationale behind the assessment. Such
explanations would allow users or clients to make a richer assessment of
providers, and tailor selection according to their preferences and current
context. In this paper, we propose an approach to explain the rationale behind
assessments from quantitative reputation models, by generating arguments that
are combined to form explanations. Our approach adapts, extends and combines
existing approaches for explaining decisions made using multi-attribute
decision models in the context of reputation. We present example argument
templates, and describe how to select their parameters using explanation
algorithms. Our proposal was evaluated by means of a user study, which followed
an existing protocol. Our results give evidence that although explanations
present a subset of the information of trust scores, they are sufficient to
equally evaluate providers recommended based on their trust score. Moreover,
when explanation arguments reveal implicit model information, they are less
persuasive than scores.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:19:35 GMT""}]","2020-06-17"
"2006.08819","Ioannis Ivrissimtzis","Xin Zhang and Ning Jia and Ioannis Ivrissimtzis","A study of the effect of the illumination model on the generation of
  synthetic training datasets","8 pages",,,,"cs.CV cs.GR cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of computer generated images to train Deep Neural Networks is a
viable alternative to real images when the latter are scarce or expensive. In
this paper, we study how the illumination model used by the rendering software
affects the quality of the generated images. We created eight training sets,
each one with a different illumination model, and tested them on three
different network architectures, ResNet, U-Net and a combined architecture
developed by us. The test set consisted of photos of 3D printed objects
produced from the same CAD models used to generate the training set. The effect
of the other parameters of the rendering process, such as textures and camera
position, was randomized.
  Our results show that the effect of the illumination model is important,
comparable in significance to the network architecture. We also show that both
light probes capturing natural environmental light, and modelled lighting
environments, can give good results. In the case of light probes, we identified
as two significant factors affecting performance the similarity between the
light probe and the test environment, as well as the light probe's resolution.
Regarding modelled lighting environment, similarity with the test environment
was again identified as a significant factor.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:22:24 GMT""}]","2020-06-17"
"2006.08820","Ingrid Nunes","Fernando Santos, Ingrid Nunes, Ana L. C. Bazzan","Quantitatively Assessing the Benefits of Model-driven Development in
  Agent-based Modeling and Simulation",,"Simulation Modelling Practice and Theory, v. 104, 1-19 (2020)","10.1016/j.simpat.2020.102126",,"cs.AI cs.SE","http://creativecommons.org/licenses/by/4.0/","  The agent-based modeling and simulation (ABMS) paradigm has been used to
analyze, reproduce, and predict phenomena related to many application areas.
Although there are many agent-based platforms that support simulation
development, they rely on programming languages that require extensive
programming knowledge. Model-driven development (MDD) has been explored to
facilitate simulation modeling, by means of high-level modeling languages that
provide reusable building blocks that hide computational complexity, and code
generation. However, there is still limited knowledge of how MDD approaches to
ABMS contribute to increasing development productivity and quality. We thus in
this paper present an empirical study that quantitatively compares the use of
MDD and ABMS platforms mainly in terms of effort and developer mistakes. Our
evaluation was performed using MDD4ABMS-an MDD approach with a core and
extensions to two application areas, one of which developed for this study-and
NetLogo, a widely used platform. The obtained results show that MDD4ABMS
requires less effort to develop simulations with similar (sometimes better)
design quality than NetLogo, giving evidence of the benefits that MDD can
provide to ABMS.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:29:04 GMT""}]","2020-06-17"
"2006.08821","Vismay Modi","Vismay Modi, Lawson Fulton, Shinjiro Sueda, Alec Jacobson, David I.W.
  Levin","EMU: Efficient Muscle Simulation In Deformation Space",,,,,"cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  EMU is an efficient and scalable model to simulate bulk musculoskeletal
motion with heterogenous materials. First, EMU requires no model reductions, or
geometric coarsening, thereby producing results visually accurate when compared
to an FEM simulation. Second, EMU is efficient and scales much better than
state-of-the-art FEM with the number of elements in the mesh, and is more
easily parallelizable. Third, EMU can handle heterogeneously stiff meshes with
an arbitrary constitutive model, thus allowing it to simulate soft muscles,
stiff tendons and even stiffer bones all within one unified system. These three
key characteristics of EMU enable us to efficiently orchestrate muscle
activated skeletal movements. We demonstrate the efficacy of our approach via a
number of examples with tendons, muscles, bones and joints.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:30:46 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 20:51:23 GMT""},{""version"":""v3"",""created"":""Tue, 29 Sep 2020 20:48:01 GMT""},{""version"":""v4"",""created"":""Thu, 19 Nov 2020 16:48:05 GMT""}]","2020-11-20"
"2006.08822","Bo Li","Xiao-Bin Liang, Bo Li, Liang Huang, Biao-Liang Ye, Shao-Ming Fei, and
  Shi-Xiang Huang","Optimal approximations of available states and a triple uncertainty
  relation","comments are welcome","Phys. Rev. A 101, 062106(2020)","10.1103/PhysRevA.101.062106",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the optimal convex approximation of the quantum state with
respect to a set of available states. By isometric transformation, we have
presented the general mathematical model and its solutions together with a
triple uncertainty equality relation. Meanwhile, we show a concise inequality
criterion for decomposing qubit mixed states. The new results include previous
ones as special cases. Our model and method may be applied to solve similar
problems in high-dimensional and multipartite scenarios
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:31:51 GMT""}]","2020-06-17"
"2006.08823","Edilson Crema","Edilson Crema","Not even the air of empty spaces is coronavirus free (Two meters is not
  a safe distance)",,,,,"physics.soc-ph q-bio.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A key safety measure encouraged by health authorities to avoid the SARS-CoV-2
spreading is the distance of one to two meters between people. This recommended
two-meters distance is mainly based on short-distance contagion, when infected
drops are expelled during a speech, coughing, or sneezing and directly hit
another person. The dangerous form of airway contamination caused by droplets
that remain suspended in the air for several hours has been almost ignored.
However, the theoretical calculations performed in this work, recent
experiments, and the accumulated knowledge in this and other epidemics indicate
that, because of the airborne transmission, there is no safe distance to the
coronavirus, either indoors or in open places. Recent investigations have
confirmed not only the presence of the coronavirus in droplets suspended in the
air but that these viruses remain active for several hours. Furthermore,
significant indirect evidence of this means of transmission is the great
difference in contagion between Brazilian regions in the current outbreak.
While the Amazonian states have a contamination rate greater than 20%, in the
southern states of the country this rate is less than 1%, despite high
temperatures in the Northern region. Notwithstanding the social and economic
differences between these regions, it seems that the extremely high humidity of
the forest air prolongs the survival of the viruses in the drops in the
external environment. Our theoretical calculations explain empirical
observations from recent epidemiological studies and strengthen the need to
use, not only a mask but also protective glasses throughout the population in
the same way that they are mandatory for health professionals. Besides, our
calculations show how air conditioning and heating systems can increase
contagion. Finally, we suggest measures that could reduce the spread of the
pandemic.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:35:02 GMT""}]","2020-06-17"
"2006.08824","Murat Sa\u{g}lam","Murat Sa\u{g}lam","Holomorphic curves in the symplectizations of lens spaces: an elementary
  approach","43 pages, 8 figures",,,,"math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an elementary computational scheme for the moduli spaces of
rational pseudo-holomorphic curves in the symplectizations of 3-dimensional
lens spaces, which are equipped with Morse-Bott contact forms induced by the
standard Morse-Bott contact form on $S^3$. As an application, we prove that for
$p$ prime and $1<q,q'<p-1$, if there is a contactomorphism between lens spaces
$L(p,q)$ and $L(p,q')$, where both spaces are equipped with their standard
contact structures, then $q\equiv (q')^{\pm 1}$ in$\mod p$. For the proof we
study the moduli spaces of pair of pants with two non-contractible ends in
detail and establish that the standard almost complex structure that is used is
regular. Then the existence of a contactomorphism enables us to follow a
neck-stretching process, by means of which we compare the homotopy relations
encoded at the non-contractible ends of the pair of pants in the
symplectizations of $L(p,q)$ and $L(p,q')$. Combining our proof with the result
of Honda on the classification of universally tight contact structures on lens
spaces, we provide a purely symplectic/contact topological proof of the
diffeomorphism classification of lens spaces in the class mentioned above
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:35:39 GMT""},{""version"":""v2"",""created"":""Tue, 25 Aug 2020 13:09:16 GMT""}]","2020-08-26"
"2006.08825","Nathan Painchaud","Nathan Painchaud, Youssef Skandarani, Thierry Judge, Olivier Bernard,
  Alain Lalande, Pierre-Marc Jodoin","Cardiac Segmentation with Strong Anatomical Guarantees","11 pages, accepted for publication in IEEE TMI",,"10.1109/TMI.2020.3003240",,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional neural networks (CNN) have had unprecedented success in medical
imaging and, in particular, in medical image segmentation. However, despite the
fact that segmentation results are closer than ever to the inter-expert
variability, CNNs are not immune to producing anatomically inaccurate
segmentations, even when built upon a shape prior. In this paper, we present a
framework for producing cardiac image segmentation maps that are guaranteed to
respect pre-defined anatomical criteria, while remaining within the
inter-expert variability. The idea behind our method is to use a well-trained
CNN, have it process cardiac images, identify the anatomically implausible
results and warp these results toward the closest anatomically valid cardiac
shape. This warping procedure is carried out with a constrained variational
autoencoder (cVAE) trained to learn a representation of valid cardiac shapes
through a smooth, yet constrained, latent space. With this cVAE, we can project
any implausible shape into the cardiac latent space and steer it toward the
closest correct shape. We tested our framework on short-axis MRI as well as
apical two and four-chamber view ultrasound images, two modalities for which
cardiac shapes are drastically different. With our method, CNNs can now produce
results that are both within the inter-expert variability and always
anatomically plausible without having to rely on a shape prior.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:38:31 GMT""}]","2020-06-17"
"2006.08826","Yize Chen","Yize Chen, Weiwei Yang, Baosen Zhang","Using Mobility for Electrical Load Forecasting During the COVID-19
  Pandemic","Data and code available at
  https://github.com/chennnnnyize/Load-Forecasting-During-COVID-19",,,,"eess.SP physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The novel coronavirus (COVID-19) pandemic has posed unprecedented challenges
for the utilities and grid operators around the world. In this work, we focus
on the problem of load forecasting. With strict social distancing restrictions,
power consumption profiles around the world have shifted both in magnitude and
daily patterns. These changes have caused significant difficulties in
short-term load forecasting. Typically algorithms use weather, timing
information and previous consumption levels as input variables, yet they cannot
capture large and sudden changes in socioeconomic behavior during the pandemic.
In this paper, we introduce mobility as a measure of economic activities to
complement existing building blocks of forecasting algorithms. Mobility data
acts as good proxies for the population-level behaviors during the
implementation and subsequent easing of social distancing measures. The major
challenge with such dataset is that only limited mobility records are
associated with the recent pandemic. To overcome this small data problem, we
design a transfer learning scheme that enables knowledge transfer between
several different geographical regions. This architecture leverages the
diversity across these regions and the resulting aggregated model can boost the
algorithm performance in each region's day-ahead forecast. Through simulations
for regions in the US and Europe, we show our proposed algorithm can outperform
conventional forecasting methods by more than three-folds. In addition, we
demonstrate how the proposed model can be used to project how electricity
consumption would recover based on different mobility scenarios.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:41:01 GMT""}]","2020-06-17"
"2006.08827","Davide Amato","Davide Amato, Renu Malhotra, Vladislav Sidorenko, Aaron J. Rosengren","Lunar close encounters compete with the circumterrestrial Lidov-Kozai
  effect","17 pages, 7 figures. Accepted for publication in Celestial Mechanics
  and Dynamical Astronomy, topical collection ""Toward the Moon and Beyond.""
  Parts of this work were presented at the 2018 John L. Junkins Dynamical
  Systems Symposium and at the 2019 Meeting of the AAS Division on Dynamical
  Astronomy (DDA)","Cel. Mech. Dyn. Astr. 135 (2020), 35","10.1007/s10569-020-09972-6",,"astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Luna 3 (or Lunik 3 in Russian sources) was the first spacecraft to perform a
flyby of the Moon. Launched in October 1959 on a translunar trajectory with
large semi-major axis and eccentricity, it collided with the Earth in late
March 1960. The short, 6-month dynamical lifetime has often been explained
through an increase in eccentricity due to the Lidov-Kozai effect. However, the
classical Lidov-Kozai solution is only valid in the limit of small semi-major
axis ratio, a condition that is satisfied only for solar (but not for lunar)
perturbations. We undertook a study of the dynamics of Luna 3 with the aim of
assessing the principal mechanisms affecting its evolution. We analyze the Luna
3 trajectory by generating accurate osculating solutions, and by comparing them
to integrations of singly- and doubly-averaged equations of motion in vectorial
form. Lunar close encounters, which cannot be reproduced in an averaging
approach, decisively affect the trajectory and break the doubly-averaged
dynamics. Solar perturbations induce oscillations of intermediate period that
affect the geometry of the close encounters and cause the singly-averaged and
osculating inclinations to change quadrants (the orbital plane ``flips''). We
find that the peculiar evolution of Luna 3 can only be explained by taking into
account lunar close encounters and intermediate-period terms; such terms are
averaged out in the Lidov-Kozai solution, which is not adequate to describe
translunar or cislunar trajectories. Understanding the limits of the
Lidov-Kozai solution is of particular significance for the motion of objects in
the Earth-Moon environment and of exoplanetary systems.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:43:46 GMT""}]","2020-07-21"
"2006.08828","Ayman Moawad","Ayman Moawad, Ehsan Islam, Namdoo Kim, Ram Vijayagopal, Aymeric
  Rousseau, and Wei Biao Wu","Explainable AI for a No-Teardown Vehicle Component Cost Estimation: A
  Top-Down Approach","17 pages, 18 figures","IEEE Transactions on Artificial Intelligence (Volume: 2, Issue: 2,
  April 2021, Page(s): 185 - 199)","10.1109/TAI.2021.3065011",,"cs.CY cs.AI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The broader ambition of this article is to popularize an approach for the
fair distribution of the quantity of a system's output to its subsystems, while
allowing for underlying complex subsystem level interactions. Particularly, we
present a data-driven approach to vehicle price modeling and its component
price estimation by leveraging a combination of concepts from machine learning
and game theory. We show an alternative to common teardown methodologies and
surveying approaches for component and vehicle price estimation at the
manufacturer's suggested retail price (MSRP) level that has the advantage of
bypassing the uncertainties involved in 1) the gathering of teardown data, 2)
the need to perform expensive and biased surveying, and 3) the need to perform
retail price equivalent (RPE) or indirect cost multiplier (ICM) adjustments to
mark up direct manufacturing costs to MSRP. This novel exercise not only
provides accurate pricing of the technologies at the customer level, but also
shows the, a priori known, large gaps in pricing strategies between
manufacturers, vehicle sizes, classes, market segments, and other factors.
There is also clear synergism or interaction between the price of certain
technologies and other specifications present in the same vehicle. Those
(unsurprising) results are indication that old methods of manufacturer-level
component costing, aggregation, and the application of a flat and rigid RPE or
ICM adjustment factor should be carefully examined. The findings are based on
an extensive database, developed by Argonne National Laboratory, that includes
more than 64,000 vehicles covering MY1990 to MY2020 over hundreds of vehicle
specs.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:47:19 GMT""}]","2021-10-22"
"2006.08829","Liping Bai","Liping Bai, Zhongqiang Pang","Multiagent Reinforcement Learning based Energy Beamforming Control","5 Pages, 3 Figures",,,,"eess.SP cs.SY eess.SY","http://creativecommons.org/publicdomain/zero/1.0/","  Ultra low power devices make far-field wireless power transfer a viable
option for energy delivery despite the exponential attenuation. Electromagnetic
beams are constructed from the stations such that wireless energy is
directionally concentrated around the ultra low power devices. Energy
beamforming faces different challenges compare to information beamforming due
to the lack of feedback on channel state. Various methods have been proposed
such as one-bit channel feedback to enhance energy beamforming capacity, yet it
still has considerable computation overhead and need to be computed centrally.
Valuable resources and time is wasted on transfering control information back
and forth. In this paper, we propose a novel multiagent reinforcement
learning(MARL) formulation for codebook based beamforming control. It takes
advantage of the inherienntly distributed structure in a wirelessly powered
network and lay the ground work for fully locally computed beam control
algorithms. Source code can be found at
https://github.com/BaiLiping/WirelessPowerTransfer.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:48:32 GMT""}]","2020-06-17"
"2006.08830","Hany Farid","Sophie Nightingale, Hany Farid","Examining the Global Spread of COVID-19 Misinformation",,,,,"cs.SI physics.soc-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The global COVID-19 pandemic has led to the online proliferation of health-,
political-, and conspiratorial-based misinformation. Understanding the reach
and belief in this misinformation is vital to managing this crisis, as well as
future crises. The results from our global survey finds a troubling reach of
and belief in COVID-related misinformation, as well as a correlation with those
that primarily consume news from social media, and, in the United States, a
strong correlation with political leaning.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:48:50 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 20:23:36 GMT""}]","2021-01-29"
"2006.08831","Chuizheng Meng","Sungyong Seo, Chuizheng Meng, Sirisha Rambhatla, Yan Liu","Physics-aware Spatiotemporal Modules with Auxiliary Tasks for
  Meta-Learning","To be published in the 30th International Joint Conference on
  Artificial Intelligence (IJCAI-21)",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Modeling the dynamics of real-world physical systems is critical for
spatiotemporal prediction tasks, but challenging when data is limited. The
scarcity of real-world data and the difficulty in reproducing the data
distribution hinder directly applying meta-learning techniques. Although the
knowledge of governing partial differential equations (PDE) of data can be
helpful for the fast adaptation to few observations, it is mostly infeasible to
exactly find the equation for observations in real-world physical systems. In
this work, we propose a framework, physics-aware meta-learning with auxiliary
tasks, whose spatial modules incorporate PDE-independent knowledge and temporal
modules utilize the generalized features from the spatial modules to be adapted
to the limited data, respectively. The framework is inspired by a local
conservation law expressed mathematically as a continuity equation and does not
require the exact form of governing equation to model the spatiotemporal
observations. The proposed method mitigates the need for a large number of
real-world tasks for meta-learning by leveraging spatial information in
simulated data to meta-initialize the spatial modules. We apply the proposed
framework to both synthetic and real-world spatiotemporal prediction tasks and
demonstrate its superior performance with limited observations.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:51:40 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 22:03:35 GMT""}]","2021-06-09"
"2006.08832","Kyle Brown","Kyle Brown and Katherine Driggs-Campbell and Mykel J. Kochenderfer","A Taxonomy and Review of Algorithms for Modeling and Predicting Human
  Driver Behavior",,,,,"eess.SY cs.AI cs.CY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a review and taxonomy of 200 models from the literature on driver
behavior modeling. We begin by introducing a mathematical framework for
describing the dynamics of interactive multi-agent traffic. Based on the
partially observable stochastic game, this framework provides a basis for
discussing different driver modeling techniques. Our taxonomy is constructed
around the core modeling tasks of state estimation, intention estimation, trait
estimation, and motion prediction, and also discusses the auxiliary tasks of
risk estimation, anomaly detection, behavior imitation and microscopic traffic
simulation. Existing driver models are categorized based on the specific tasks
they address and key attributes of their approach.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:53:45 GMT""},{""version"":""v2"",""created"":""Mon, 3 Aug 2020 18:35:04 GMT""},{""version"":""v3"",""created"":""Sun, 29 Nov 2020 03:40:24 GMT""}]","2020-12-01"
"2006.08833","Andre Kovach","Andre Kovach, Arynn Gallegos, Jinghan He, Hyungwoo Choi, Andrea M.
  Armani","Cascaded Stokes and anti-Stokes laser based on an optical resonator with
  a self-assembled organic monolayer","5 pages, 5 figures",,"10.1364/OL.397861",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to their high circulating intensities, ultra-high quality factor
dielectric whispering-gallery mode resonators have enabled the development of
low threshold Raman microlasers. Subsequently, other Raman-related phenomena,
such as cascaded stimulated Raman scattering (CSRS) and stimulated anti-Stokes
Raman scattering (SARS), were observed. While low threshold frequency
conversion and generation have clear applications, CSRS and SARS have been
limited by the low Raman gain. In this work, the surface of a silica resonator
is modified with an organic monolayer, increasing the Raman gain. Up to four
orders of CSRS is observed with sub-mW input power, and the SARS efficiency is
improved by three orders of magnitude compared to previous studies with hybrid
resonators.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:06:43 GMT""}]","2020-08-26"
"2006.08834","Chris Nagele","Chris Nagele, Hideyuki Umeda, Koh Takahashi, Takashi Yoshida, Kohsuke
  Sumiyoshi","The Final Fate of Supermassive $M \sim 5 \times 10^4 \; M_\odot$ Pop III
  Stars: Explosion or Collapse?",,,"10.1093/mnras/staa1636",,"astro-ph.HE astro-ph.CO astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the possibility of a supernova in supermassive ($5 \times 10^4
\;M_\odot$) population III stars induced by a general relativistic instability
occurring in the helium burning phase. This explosion could occur via rapid
helium burning during an early contraction of the isentropic core. Such an
explosion would be visible to future telescopes and could disrupt the proposed
direct collapse formation channel for early universe supermassive black holes.
We simulate first the stellar evolution from hydrogen burning using a 1D
stellar evolution code with a post Newtonian approximation; at the point of
dynamical collapse, we switch to a 1D (general relativistic) hydrodynamics code
with the Misner-Sharpe metric. In opposition to a previous study, we do not
find an explosion in the non rotating case, although our model is close to
exploding for a similar mass to the explosion in the previous study. When we
include slow rotation, we find one exploding model, and we conclude that there
likely exist additional exploding models, though they may be rare.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:10:57 GMT""}]","2020-06-17"
"2006.08835","Juan Pablo Torres-Papaqui PhD","Hrant M. Tovmassian and Juan P. Torres-Papaqui","On the Alignment of Galaxies in Clusters","9 paginas,1 figure, and 7 tables. Accepted in Astrophysics. arXiv
  admin note: text overlap with arXiv:1909.07757",,"10.1007/s10511-020-09649-w",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the distribution of position angles (PA) of galaxies in clusters.
We selected for study the isolated clusters, since the distribution of the
galaxy orientation in clusters with close neighbors could be altered by
gravitational influence of the latter. We assume that galaxies are aligned, if
their number at one $90^o$ position angle interval is more than twice higher
than at the other $90^o$ interval. We study the galaxy PA distribution at the
outer regions of clusters with smaller space density, where the probability of
the PA variation in the result of interactions between galaxies is smaller than
at the dense central regions. We found that the alignment of galaxies is more
often observed in poor clusters and concluded that originally galaxies were
aligned, but in the result of accretion in time of field galaxies with
arbitrary orientations and also due to the mutual interactions the relative
number of aligned galaxies decreases.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:11:48 GMT""}]","2020-11-18"
"2006.08836","Yufei Zhao","Matthew Kwan, Lisa Sauermann, Yufei Zhao","Extension complexity of low-dimensional polytopes","32 pages, 5 figures",,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sometimes, it is possible to represent a complicated polytope as a projection
of a much simpler polytope. To quantify this phenomenon, the extension
complexity of a polytope $P$ is defined to be the minimum number of facets of a
(possibly higher-dimensional) polytope from which $P$ can be obtained as a
(linear) projection. This notion is motivated by its relevance to combinatorial
optimisation, and has been studied intensively for various specific polytopes
associated with important optimisation problems. In this paper we study
extension complexity as a parameter of general polytopes, more specifically
considering various families of low-dimensional polytopes.
  First, we prove that for a fixed dimension $d$, the extension complexity of a
random $d$-dimensional polytope (obtained as the convex hull of random points
in a ball or on a sphere) is typically on the order of the square root of its
number of vertices. Second, we prove that any cyclic $n$-vertex polygon (whose
vertices lie on a circle) has extension complexity at most $24\sqrt n$. This
bound is tight up to the constant factor $24$. Finally, we show that there
exists an $n^{o(1)}$-dimensional polytope with at most $n$ vertices and
extension complexity $n^{1-o(1)}$. Our theorems are proved with a range of
different techniques, which we hope will be of further interest.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:12:50 GMT""},{""version"":""v2"",""created"":""Sat, 12 Jun 2021 00:12:59 GMT""},{""version"":""v3"",""created"":""Wed, 23 Mar 2022 01:16:54 GMT""}]","2022-03-24"
"2006.08837","Ronald Alberto Zuniga-Rojas","Peter B. Gothen and Ronald A. Z\'u\~niga-Rojas","Stratifications on the Nilpotent Cone of the moduli space of Hitchin
  pairs","10 pages","Revista Matem\'atica Complutense 35 (2022), 311-321","10.1007/s13163-021-00400-3",,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of finding the limit at infinity (corresponding to
the downward Morse flow) of a Higgs bundle in the nilpotent cone under the
natural $\mathbb{C}^*$-action on the moduli space. For general rank we provide
an answer for Higgs bundles with regular nilpotent Higgs field, while in rank
three we give the complete answer. Our results show that the limit can be
described in terms of data defined by the Higgs field, via a filtration of the
underlying vector bundle.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:14:35 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 19:15:16 GMT""}]","2022-11-07"
"2006.08838","Xuhua He","Ulrich G\""ortz, Xuhua He and Sian Nie","Basic loci of Coxeter type with arbitrary parahoric level","33 pages. A new section on the smoothness of closures of strata is
  added",,,,"math.AG math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the desire to understand the geometry of the basic loci in the
reduction of Shimura varieties, we study their ""group-theoretic models"" --
generalized affine Deligne-Lusztig varieties -- in cases where they have a
particularly nice description. Continuing the work of [GH] and [GHN] we single
out the class of cases of Coxeter type, give a characterization in terms of the
dimension, and obtain a complete classification. We also discuss known, new and
open cases from the point of view of Shimura varieties/Rapoport-Zink spaces.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:23:35 GMT""},{""version"":""v2"",""created"":""Fri, 18 Sep 2020 07:25:00 GMT""}]","2020-09-21"
"2006.08840","Davit Harutyunyan","Zhirayr Avetisyan, Davit Harutyunyan, and Narek Hovsepyan","Rigidity of a thin domain depends on the curvature, width, and boundary
  conditions","24 pages",,,,"math.AP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with the study of linear geometric rigidity of
shallow thin domains under zero Dirichlet boundary conditions on the
displacement field on the thin edge of the domain. A shallow thin domain is a
thin domain that has in-plane dimensions of order $O(1)$ and $\epsilon,$ where
$\epsilon\in (h,1)$ is a parameter (here $h$ is the thickness of the shell).
The problem has been solved in [8,10] for the case $\epsilon=1,$ with the
outcome of the optimal constant $C\sim h^{-3/2},$ $C\sim h^{-4/3},$ and $C\sim
h^{-1}$ for parabolic, hyperbolic and elliptic thin domains respectively. We
prove in the present work that in fact there are two distinctive scaling
regimes $\epsilon\in (h,\sqrt h]$ and $\epsilon\in (\sqrt h,1),$ such that in
each of which the thin domain rigidity is given by a certain formula in $h$ and
$\epsilon.$ An interesting new phenomenon is that in the first (small
parameter) regime $\epsilon\in (h,\sqrt h]$, the rigidity does not depend on
the curvature of the thin domain mid-surface.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:27:41 GMT""}]","2020-06-17"
"2006.08842","Hongzhi Wang","Shun Yao, Hongzhi Wang and Yu Yan","Index Selection for NoSQL Database with Deep Reinforcement Learning",,,,,"cs.DB cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new approach of NoSQL database index selection. For different
workloads, we select different indexes and their different parameters to
optimize the database performance. The approach builds a deep reinforcement
learning model to select an optimal index for a given fixed workload and adapts
to a changing workload. Experimental results show that, Deep Reinforcement
Learning Index Selection Approach (DRLISA) has improved performance to varying
degrees according to traditional single index structures.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:40:50 GMT""}]","2020-06-17"
"2006.08843","Adrian Bishop","Adrian N. Bishop and Pierre Del Moral","On the Mathematical Theory of Ensemble (Linear-Gaussian) Kalman-Bucy
  Filtering",,,,,"math.ST math.OC math.PR stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this review is to present a comprehensive overview of the
theory of ensemble Kalman-Bucy filtering for continuous-time, linear-Gaussian
signal and observation models. We present a system of equations that describe
the flow of individual particles and the flow of the sample covariance and the
sample mean in continuous-time ensemble filtering. We consider these equations
and their characteristics in a number of popular ensemble Kalman filtering
variants. Given these equations, we study their asymptotic convergence to the
optimal Bayesian filter. We also study in detail some non-asymptotic
time-uniform fluctuation, stability, and contraction results on the sample
covariance and sample mean (or sample error track). We focus on testable
signal/observation model conditions, and we accommodate fully unstable (latent)
signal models. We discuss the relevance and importance of these results in
characterising the filter's behaviour, e.g. it's signal tracking performance,
and we contrast these results with those in classical studies of stability in
Kalman-Bucy filtering. We also provide a novel (and negative) result proving
that the bootstrap particle filter cannot track even the most basic unstable
latent signal, in contrast with the ensemble Kalman filter (and the optimal
filter). We provide intuition for how the main results extend to nonlinear
signal models and comment on their consequence on some typical filter
behaviours seen in practice, e.g. catastrophic divergence.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:41:18 GMT""},{""version"":""v2"",""created"":""Sun, 15 Jan 2023 05:38:28 GMT""}]","2023-01-18"
"2006.08844","Xinghui Li Mr.","Xinghui Li, Kai Han, Shuda Li, Victor Adrian Prisacariu","Dual-Resolution Correspondence Networks","NeurIPS 2020, code at https://dualrcnet.active.vision/",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We tackle the problem of establishing dense pixel-wise correspondences
between a pair of images. In this work, we introduce Dual-Resolution
Correspondence Networks (DualRC-Net), to obtain pixel-wise correspondences in a
coarse-to-fine manner. DualRC-Net extracts both coarse- and fine- resolution
feature maps. The coarse maps are used to produce a full but coarse 4D
correlation tensor, which is then refined by a learnable neighbourhood
consensus module. The fine-resolution feature maps are used to obtain the final
dense correspondences guided by the refined coarse 4D correlation tensor. The
selected coarse-resolution matching scores allow the fine-resolution features
to focus only on a limited number of possible matches with high confidence. In
this way, DualRC-Net dramatically increases matching reliability and
localisation accuracy, while avoiding to apply the expensive 4D convolution
kernels on fine-resolution feature maps. We comprehensively evaluate our method
on large-scale public benchmarks including HPatches, InLoc, and Aachen
Day-Night. It achieves the state-of-the-art results on all of them.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:42:43 GMT""},{""version"":""v2"",""created"":""Wed, 28 Oct 2020 17:16:58 GMT""}]","2020-10-29"
"2006.08845","Kyle Jordan Brown","Kyle Brown, Oriana Peltzer, Martin A. Sehr, Mac Schwager, Mykel J.
  Kochenderfer","Optimal Sequential Task Assignment and Path Finding for Multi-Agent
  Robotic Assembly Planning","Presented at International Conference on Robotics and Automation
  (ICRA) 2020","International Conference on Robotics and Automation (ICRA) 2020",,,"cs.RO cs.AI cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of sequential task assignment and collision-free routing
for large teams of robots in applications with inter-task precedence
constraints (e.g., task $A$ and task $B$ must both be completed before task $C$
may begin). Such problems commonly occur in assembly planning for robotic
manufacturing applications, in which sub-assemblies must be completed before
they can be combined to form the final product. We propose a hierarchical
algorithm for computing makespan-optimal solutions to the problem. The
algorithm is evaluated on a set of randomly generated problem instances where
robots must transport objects between stations in a ""factory ""grid world
environment. In addition, we demonstrate in high-fidelity simulation that the
output of our algorithm can be used to generate collision-free trajectories for
non-holonomic differential-drive robots.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:45:07 GMT""}]","2020-06-17"
"2006.08846","Feng Hu","Feng Hu","Mining Personalized Climate Preferences for Assistant Driving",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Both assistant driving and self-driving have attracted a great amount of
attention in the last few years. However, the majority of research efforts
focus on safe driving; few research has been conducted on in-vehicle climate
control, or assistant driving based on travellers' personal habits or
preferences. In this paper, we propose a novel approach for climate control,
driver behavior recognition and driving recommendation for better fitting
drivers' preferences in their daily driving. The algorithm consists three
components: (1) A in-vehicle sensing and context feature enriching compnent
with a Internet of Things (IoT) platform for collecting related environment,
vehicle-running, and traffic parameters that affect drivers' behaviors. (2) A
non-intrusive intelligent driver behaviour and vehicle status detection
component, which can automatically label vehicle's status (open windows, turn
on air condition, etc.), based on results of applying further feature
extraction and machine learning algorithms. (3) A personalized driver habits
learning and preference recommendation component for more healthy and
comfortable experiences. A prototype using a client-server architecture with an
iOS app and an air-quality monitoring sensor has been developed for collecting
heterogeneous data and testing our algorithms. Real-world experiments on
driving data of 11,370 km (320 hours) by different drivers in multiple cities
worldwide have been conducted, which demonstrate the effective and accuracy of
our approach.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:45:08 GMT""}]","2020-06-17"
"2006.08847","Wei Cai","Sh. Akhondzadeh, Ryan B. Sills, Nicolas Bertin, Wei Cai","Dislocation Density-Based Plasticity Model from Massive Discrete
  Dislocation Dynamics Database",,,"10.1016/j.jmps.2020.104152",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a dislocation density-based strain hardening model for single
crystal copper through a systematic coarse-graining analysis of more than 200
discrete dislocation dynamics (DDD) simulations of plastic deformation under
uniaxial tension. The proposed constitutive model has two components: a
generalized Taylor relation connecting resolved shear stresses to dislocation
densities on individual slip systems, and a generalized Kocks-Mecking model for
dislocation multiplication. The DDD data strongly suggests a logarithmic
dependence of flow stress on the plastic shear strain rate on each slip system,
and, equivalently, an exponential dependence of the plastic shear strain rate
on the resolved shear stress. Hence the proposed generalized Taylor relation
subsumes the Orowan relation for plastic flow. The DDD data also calls for a
correction to the Kocks-Mecking model of dislocation multiplication to account
for the increase of dislocation density on slip systems with negligible plastic
shear strain rate. This is accomplished by allowing the multiplication rate on
each slip system to include contributions from the plastic strain rates of the
two coplanar slip systems. The resulting constitutive model successfully
captures the strain hardening rate dependence on the loading orientation as
predicted by the DDD simulations, which is also consistent with existing
experiments.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:55:16 GMT""}]","2020-10-28"
"2006.08848","The Canh Dinh","Canh T. Dinh, Nguyen H. Tran, Tuan Dung Nguyen","Personalized Federated Learning with Moreau Envelopes",,,,,"cs.LG cs.DC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning (FL) is a decentralized and privacy-preserving machine
learning technique in which a group of clients collaborate with a server to
learn a global model without sharing clients' data. One challenge associated
with FL is statistical diversity among clients, which restricts the global
model from delivering good performance on each client's task. To address this,
we propose an algorithm for personalized FL (pFedMe) using Moreau envelopes as
clients' regularized loss functions, which help decouple personalized model
optimization from the global model learning in a bi-level problem stylized for
personalized FL. Theoretically, we show that pFedMe's convergence rate is
state-of-the-art: achieving quadratic speedup for strongly convex and sublinear
speedup of order 2/3 for smooth nonconvex objectives. Experimentally, we verify
that pFedMe excels at empirical performance compared with the vanilla FedAvg
and Per-FedAvg, a meta-learning based personalized FL algorithm.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:55:23 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 03:07:46 GMT""},{""version"":""v3"",""created"":""Wed, 26 Jan 2022 01:05:36 GMT""}]","2022-01-27"
"2006.08849","Haoxing Lin","Haoxing Lin, Rufan Bai, Weijia Jia, Xinyu Yang, Yongjian You","Preserving Dynamic Attention for Long-Term Spatial-Temporal Prediction","11 pages, an ACM SIGKDD 2020 paper",,"10.1145/3394486.3403046",,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Effective long-term predictions have been increasingly demanded in urban-wise
data mining systems. Many practical applications, such as accident prevention
and resource pre-allocation, require an extended period for preparation.
However, challenges come as long-term prediction is highly error-sensitive,
which becomes more critical when predicting urban-wise phenomena with
complicated and dynamic spatial-temporal correlation. Specifically, since the
amount of valuable correlation is limited, enormous irrelevant features
introduce noises that trigger increased prediction errors. Besides, after each
time step, the errors can traverse through the correlations and reach the
spatial-temporal positions in every future prediction, leading to significant
error propagation. To address these issues, we propose a Dynamic
Switch-Attention Network (DSAN) with a novel Multi-Space Attention (MSA)
mechanism that measures the correlations between inputs and outputs explicitly.
To filter out irrelevant noises and alleviate the error propagation, DSAN
dynamically extracts valuable information by applying self-attention over the
noisy input and bridges each output directly to the purified inputs via
implementing a switch-attention mechanism. Through extensive experiments on two
spatial-temporal prediction tasks, we demonstrate the superior advantage of
DSAN in both short-term and long-term predictions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:56:43 GMT""}]","2020-06-17"
"2006.08850","Blake Mason","Blake Mason, Lalit Jain, Ardhendu Tripathy, and Robert Nowak","Finding All {\epsilon}-Good Arms in Stochastic Bandits","93 total pages (8 main pages + appendices), 12 figures, submitted to
  NeurIPS 2020",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The pure-exploration problem in stochastic multi-armed bandits aims to find
one or more arms with the largest (or near largest) means. Examples include
finding an {\epsilon}-good arm, best-arm identification, top-k arm
identification, and finding all arms with means above a specified threshold.
However, the problem of finding all {\epsilon}-good arms has been overlooked in
past work, although arguably this may be the most natural objective in many
applications. For example, a virologist may conduct preliminary laboratory
experiments on a large candidate set of treatments and move all {\epsilon}-good
treatments into more expensive clinical trials. Since the ultimate clinical
efficacy is uncertain, it is important to identify all {\epsilon}-good
candidates. Mathematically, the all-{\epsilon}-good arm identification problem
presents significant new challenges and surprises that do not arise in the
pure-exploration objectives studied in the past. We introduce two algorithms to
overcome these and demonstrate their great empirical performance on a
large-scale crowd-sourced dataset of 2.2M ratings collected by the New Yorker
Caption Contest as well as a dataset testing hundreds of possible cancer drugs.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 00:58:40 GMT""},{""version"":""v2"",""created"":""Fri, 11 Sep 2020 17:25:48 GMT""}]","2020-09-14"
"2006.08851","Stavroula Foteinopoulou","S. Foteinopoulou and J. P. Vigneron","Extended slow-light field enhancement in positive/negative-index
  heterostructures","28 pages, 10 figures","Physical Review B vol. 88, 195144 (2013)","10.1103/PhysRevB.88.195144",,"physics.optics cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a bi-waveguide paradigm composed of joined Positive-Index-Material
PIM)/Negative-Index-Material (NIM) slabs, demonstrating ultra-slow light
propagation stemming from the competing propagation disposition in the PIM and
NIM regions. We report for the first time a mesoscopic extended electromagnetic
(EM) enhancement covering regions of the order of the free space wavelength,
enabled by the slow-light mode in our system. Our dynamic numerical results are
consistent with our developed theoretical model, predicting an EM energy
accumulation reminiscent of a charging capacitor. Our analysis reveals that
spatial compression is not a requirement to EM enhancement in slow-light
systems and stresses on the merits of high coupling efficiency, strong temporal
compression, monomodality and modal index bandwidth, -all present in our
proposed paradigm. Furthermore, we show that the heterostructure waveguide mode
is an extra-ordinary entity with a unique energy velocity, that is opposite to
the Poynting vector in one of the participant waveguides. We believe these
results will inspire new slow-light platforms relevant to the collective
harvesting of strong light-matter interactions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:00:18 GMT""}]","2020-06-17"
"2006.08852","Aishwarya Sivaraman","Aishwarya Sivaraman, Golnoosh Farnadi, Todd Millstein, Guy Van den
  Broeck","Counterexample-Guided Learning of Monotonic Neural Networks",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The widespread adoption of deep learning is often attributed to its automatic
feature construction with minimal inductive bias. However, in many real-world
tasks, the learned function is intended to satisfy domain-specific constraints.
We focus on monotonicity constraints, which are common and require that the
function's output increases with increasing values of specific input features.
We develop a counterexample-guided technique to provably enforce monotonicity
constraints at prediction time. Additionally, we propose a technique to use
monotonicity as an inductive bias for deep learning. It works by iteratively
incorporating monotonicity counterexamples in the learning process. Contrary to
prior work in monotonic learning, we target general ReLU neural networks and do
not further restrict the hypothesis space. We have implemented these techniques
in a tool called COMET. Experiments on real-world datasets demonstrate that our
approach achieves state-of-the-art results compared to existing monotonic
learners, and can improve the model quality compared to those that were trained
without taking monotonicity constraints into account.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:04:26 GMT""}]","2020-06-17"
"2006.08853","Zhi-Xi Wang","Meng-Li Guo, Bo-Li, Zhi-Xi Wang and Shao-Ming Fei","Tighter constraints of multiqubit entanglement in terms of
  R\'{e}nyi-$\alpha$ entropy","10 pages, 2 figures","Chin. Phys. B Vol. 29, No. 7 (2020) 070304","10.1088/1674-1056/ab8e2e",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum entanglement plays essential roles in quantum information processing.
The monogamy and polygamy relations characterize the entanglement distributions
in the multipartite systems. We present a class of monogamy inequalities
related to the $\mu$th power of the entanglement measure based on
R\'{e}nyi-$\alpha$ entropy, as well as polygamy relations in terms of the
$\mu$th powered of R\'{e}nyi-$\alpha$ entanglement of assistance. These
monogamy and polygamy relations are shown to be tighter than the existing ones.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:05:21 GMT""}]","2020-06-17"
"2006.08854","Harley Eades PhD","Harley Eades III and Dominic Orchard","Grading Adjoint Logic","Extended abstract of a talk presented at LINEARITY/TLLA 2020",,,,"cs.LO cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new logic that combines Adjoint Logic with Graded Necessity
Modalities. This results in a very expressive system capable of controlling
when and how structural rules are used. We give a sequent calculus, natural
deduction, and term assignment for Graded Adjoint Logic.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:11:08 GMT""}]","2020-06-17"
"2006.08855","Ye Tian","Ye Tian and Yang Feng","RaSE: Random Subspace Ensemble Classification","93 pages, 13 figures","Journal of Machine Learning Research 22, no. 45 (2021): 1-93",,,"stat.ML cs.LG math.ST stat.CO stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a flexible ensemble classification framework, Random Subspace
Ensemble (RaSE), for sparse classification. In the RaSE algorithm, we aggregate
many weak learners, where each weak learner is a base classifier trained in a
subspace optimally selected from a collection of random subspaces. To conduct
subspace selection, we propose a new criterion, ratio information criterion
(RIC), based on weighted Kullback-Leibler divergence. The theoretical analysis
includes the risk and Monte-Carlo variance of the RaSE classifier, establishing
the screening consistency and weak consistency of RIC, and providing an upper
bound for the misclassification rate of the RaSE classifier. In addition, we
show that in a high-dimensional framework, the number of random subspaces needs
to be very large to guarantee that a subspace covering signals is selected.
Therefore, we propose an iterative version of the RaSE algorithm and prove that
under some specific conditions, a smaller number of generated random subspaces
are needed to find a desirable subspace through iteration. An array of
simulations under various models and real-data applications demonstrate the
effectiveness and robustness of the RaSE classifier and its iterative version
in terms of low misclassification rate and accurate feature ranking. The RaSE
algorithm is implemented in the R package RaSEn on CRAN.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:14:38 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 18:59:19 GMT""},{""version"":""v3"",""created"":""Sat, 29 May 2021 15:54:44 GMT""}]","2021-06-01"
"2006.08856","Nicolas Saintier","Juan Pablo Pinasco and Mauro Rodriguez Cartabia and Nicolas Saintier","Interacting particles systems with delay and random delay differential
  equations",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we study a kinetic model of active particles with delayed
dynamics, and its limit when the number of particles goes to infinity. This
limit turns out to be related to delayed differential equations with random
initial conditions. We analyze two different dynamics, one based on the full
knowledge of the individual trajectories of each particle, and another one
based only on the trace of the particle cloud, loosing track of the individual
trajectories. Notice that in the first dynamic the state of a particles is its
path, whereas it is simply a point in $\R^d$ in the second case. We analyse in
both cases the corresponding mean-field dynamic obtaining an equation for the
time evolution of the distribution of the particles states. Well-posedness of
the equation is proved by a fixed-point argument. We conclude the paper with
some possible future research directions and modelling applications.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:16:55 GMT""}]","2020-06-17"
"2006.08857","Chong You","Chong You, Zhihui Zhu, Qing Qu, Yi Ma","Robust Recovery via Implicit Bias of Discrepant Learning Rates for
  Double Over-parameterization",,,,,"cs.LG cs.CV math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances have shown that implicit bias of gradient descent on
over-parameterized models enables the recovery of low-rank matrices from linear
measurements, even with no prior knowledge on the intrinsic rank. In contrast,
for robust low-rank matrix recovery from grossly corrupted measurements,
over-parameterization leads to overfitting without prior knowledge on both the
intrinsic rank and sparsity of corruption. This paper shows that with a double
over-parameterization for both the low-rank matrix and sparse corruption,
gradient descent with discrepant learning rates provably recovers the
underlying matrix even without prior knowledge on neither rank of the matrix
nor sparsity of the corruption. We further extend our approach for the robust
recovery of natural images by over-parameterizing images with deep
convolutional networks. Experiments show that our method handles different test
images and varying corruption levels with a single learning pipeline where the
network width and termination conditions do not need to be adjusted on a
case-by-case basis. Underlying the success is again the implicit bias with
discrepant learning rates on different over-parameterized parameters, which may
bear on broader applications.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:21:22 GMT""}]","2020-06-17"
"2006.08858","Lin Zheng","Lin Zheng, Qinliang Su, Dinghan Shen and Changyou Chen","Generative Semantic Hashing Enhanced via Boltzmann Machines",,,,,"cs.LG cs.CL stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative semantic hashing is a promising technique for large-scale
information retrieval thanks to its fast retrieval speed and small memory
footprint. For the tractability of training, existing generative-hashing
methods mostly assume a factorized form for the posterior distribution,
enforcing independence among the bits of hash codes. From the perspectives of
both model representation and code space size, independence is always not the
best assumption. In this paper, to introduce correlations among the bits of
hash codes, we propose to employ the distribution of Boltzmann machine as the
variational posterior. To address the intractability issue of training, we
first develop an approximate method to reparameterize the distribution of a
Boltzmann machine by augmenting it as a hierarchical concatenation of a
Gaussian-like distribution and a Bernoulli distribution. Based on that, an
asymptotically-exact lower bound is further derived for the evidence lower
bound (ELBO). With these novel techniques, the entire model can be optimized
efficiently. Extensive experimental results demonstrate that by effectively
modeling correlations among different bits within a hash code, our model can
achieve significant performance gains.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:23:39 GMT""}]","2020-06-17"
"2006.08859","Sejun Park","Sejun Park, Chulhee Yun, Jaeho Lee, Jinwoo Shin","Minimum Width for Universal Approximation",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The universal approximation property of width-bounded networks has been
studied as a dual of classical universal approximation results on depth-bounded
networks. However, the critical width enabling the universal approximation has
not been exactly characterized in terms of the input dimension $d_x$ and the
output dimension $d_y$. In this work, we provide the first definitive result in
this direction for networks using the ReLU activation functions: The minimum
width required for the universal approximation of the $L^p$ functions is
exactly $\max\{d_x+1,d_y\}$. We also prove that the same conclusion does not
hold for the uniform approximation with ReLU, but does hold with an additional
threshold activation function. Our proof technique can be also used to derive a
tighter upper bound on the minimum width required for the universal
approximation using networks with general activation functions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:24:21 GMT""}]","2020-06-17"
"2006.08860","Minxin Huang","Min-xin Huang","Note on Quantum Periods and a TBA-like System","13 pages, no figure. v2: journal version",,"10.1016/j.physletb.2021.136102","USTC-ICTS/PCFT-20-16","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is an interesting relation between the quantum periods on a certain
limit of local $\mathbb{P}^1\times \mathbb{P}^1$ Calabi-Yau space and a TBA
(Thermodynamic Bethe Ansatz) system appeared in the studies of ABJM
(Aharony-Bergman-Jafferis-Maldacena) theory. We propose a one-parameter
generalization of the relation. Furthermore, we derive the differential
operators for quantum periods and the TBA-like equation in various limits of
the generalized relation.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:36:04 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 05:23:13 GMT""}]","2021-01-27"
"2006.08861","Feng Hu","Feng Hu","GPU-accelerated Hierarchical Panoramic Image Feature Retrieval for
  Indoor Localization",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Indoor localization has many applications, such as commercial Location Based
Services (LBS), robotic navigation, and assistive navigation for the blind.
This paper formulates the indoor localization problem into a multimedia
retrieving problem by modeling visual landmarks with a panoramic image feature,
and calculating a user's location via GPU- accelerated parallel retrieving
algorithm. To solve the scene similarity problem, we apply a multi-images based
retrieval strategy and a 2D aggregation method to estimate the final retrieval
location. Experiments on a campus building real data demonstrate real-time
responses (14fps) and robust localization.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:42:20 GMT""}]","2020-06-17"
"2006.08862","Yong Zhang","Bao-Zhi Lin, Yong Zhang","Can the Kappa-distributed electron energies account for the intensity
  ratios of O II lines in photoionized gaseous nebulae?","18 pages, 8 figures, Accepted for publication in ApJ",,"10.3847/1538-4357/ab9d7e",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A vexing puzzle in the study of planetary nebulae and \ion{H}{2} regions is
that the plasma diagnostic results based on collisionally excited lines
systematically differ from those based on recombination lines. A fairly
speculative interpretation is the presence of nonthermal electrons with the
so-called $\kappa$ energy distributions, yet there is little observational
evidence to verify or disprove this hypothesis. In this paper, we examine the
influence of $\kappa$-distributed electrons on the emissivities of \ion{O}{2}
recombination lines using an approximate method, where the rate coefficients
for a $\kappa$ distribution are computed by summing Maxwellian-Boltzmann rate
coefficients with appropriate weights. The results show that if invoking
$\kappa$-distributed electrons, the temperatures derived from the [\ion{O}{3}]
$(\lambda4959+\lambda5007)/\lambda4363$ ratios could coincide with those
estimated from the \ion{O}{2} $\lambda4649/\lambda4089$ ratios. However, the
estimated temperatures and $\kappa$ values are not in agreement with those
obtained through comparing the [\ion{O}{3}]
$(\lambda4959+\lambda5007)/\lambda4363$ ratios and the hydrogen recombination
spectra, suggesting that the electron energy is unlikely to follow the
$\kappa$-distributions over a global scale of the nebular regions.
Nevertheless, based on this observation alone, we cannot definitely rule out
the presence of $\kappa$-distributed electrons in some microstructures within
nebulae.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:46:14 GMT""}]","2020-08-19"
"2006.08863","Chiwei Yan","Francisco Castro, Peter Frazier, Hongyao Ma, Hamid Nazerzadeh, Chiwei
  Yan","Matching Queues, Flexibility and Incentives",,,,,"cs.GT math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated in part by online marketplaces such as ridesharing and freelancing
platforms, we study two-sided matching markets where agents are heterogeneous
in their compatibility with different types of jobs: flexible agents can
fulfill any job, whereas each specialized agent can only be matched to a
specific subset of jobs. When the set of jobs compatible with each agent is
known, the full-information first-best throughput (i.e. number of matches) can
be achieved by prioritizing dispatch of specialized agents as much as possible.
When agents are strategic, however, we show that such aggressive reservation of
flexible capacity incentivizes flexible agents to pretend to be specialized.
The resulting equilibrium throughput could be even lower than the outcome under
a baseline policy, which does not reserve flexible capacity, and simply
dispatches jobs to agents at random. To balance matching efficiency with
agents' strategic considerations, we introduce a novel robust capacity
reservation policy (RCR). The RCR policy retains a similar structure to the
first best policy, but offers additional and seemingly incompatible edges along
which jobs can be dispatched. We show a Braess' paradox-like result, that
offering these additional edges could sometimes lead to worse equilibrium
outcomes. Nevertheless, we prove that under any market conditions, and
regardless of agents' strategies, the proposed RCR policy always achieves
higher throughput than the baseline policy. Our work highlights the importance
of considering the interplay between strategic behavior and capacity allocation
policies in service systems.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:55:11 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 00:56:44 GMT""},{""version"":""v3"",""created"":""Fri, 26 Jun 2020 03:06:51 GMT""},{""version"":""v4"",""created"":""Wed, 10 Feb 2021 06:45:04 GMT""}]","2021-02-11"
"2006.08864","Hangjin Jiang","Hangjin Jiang","A Goodness-of-Fit Test for Statistical Models",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Statistical modeling plays a fundamental role in understanding the underlying
mechanism of massive data (statistical inference) and predicting the future
(statistical prediction). Although all models are wrong, researchers try their
best to make some of them be useful. The question here is how can we measure
the usefulness of a statistical model for the data in hand? This is key to
statistical prediction. The important statistical problem of testing whether
the observations follow the proposed statistical model has only attracted
relatively few attentions. In this paper, we proposed a new framework for this
problem through building its connection with two-sample distribution
comparison. The proposed method can be applied to evaluate a wide range of
models. Examples are given to show the performance of the proposed method.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:58:21 GMT""}]","2020-06-17"
"2006.08865","Shang Gao","Shang Gao, Daigorou Hirai, Hajime Sagayama, Hiroyuki Ohsumi, Zenji
  Hiroi, and Taka-hisa Arima","Antiferromagnetic long-range order in $5d^1$ double-perovskite
  Sr$_2$MgReO$_6$","6 pages, 5 figures","Phys. Rev. B 101, 220412(R) (2020)","10.1103/PhysRevB.101.220412",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The double-perovskite A$_2$BB'O$_6$ with heavy transition metal ions on the
ordered B' sites is an important family of compounds to study the interplay
between electron correlation and spin-orbit coupling (SOC). Here we prepared
high-quality Sr$_2$MgReO$_6$ powder and single-crystal samples and performed
non-resonant and resonant synchrotron x-ray diffraction experiments to
investigate its magnetic ground state. By combining the magnetic susceptibility
and heat capacity measurements, we conclude that Sr$_2$MgReO$_6$ exhibits a
layered antiferromagnetic (AF) order at temperatures below $\sim$ 55 K with a
propagation vector q = (001), which contrasts the previously suspected spin
glass state. Our works clarify the magnetic order in Sr$_2$MgReO$_6$ and
demonstrate it as a candidate system to look for magnetic octupolar orders and
exotic spin dynamics.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 01:58:39 GMT""}]","2020-07-01"
"2006.08866","Yasunori Akagi","Yasunori Akagi, Yusuke Tanaka, Tomoharu Iwata, Takeshi Kurashima,
  Hiroyuki Toda","Probabilistic Optimal Transport based on Collective Graphical Models",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimal Transport (OT) is being widely used in various fields such as machine
learning and computer vision, as it is a powerful tool for measuring the
similarity between probability distributions and histograms. In previous
studies, OT has been defined as the minimum cost to transport probability mass
from one probability distribution to another. In this study, we propose a new
framework in which OT is considered as a maximum a posteriori (MAP) solution of
a probabilistic generative model. With the proposed framework, we show that OT
with entropic regularization is equivalent to maximizing a posterior
probability of a probabilistic model called Collective Graphical Model (CGM),
which describes aggregated statistics of multiple samples generated from a
graphical model. Interpreting OT as a MAP solution of a CGM has the following
two advantages: (i) We can calculate the discrepancy between noisy histograms
by modeling noise distributions. Since various distributions can be used for
noise modeling, it is possible to select the noise distribution flexibly to
suit the situation. (ii) We can construct a new method for interpolation
between histograms, which is an important application of OT. The proposed
method allows for intuitive modeling based on the probabilistic
interpretations, and a simple and efficient estimation algorithm is available.
Experiments using synthetic and real-world spatio-temporal population datasets
show the effectiveness of the proposed interpolation method.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:03:34 GMT""}]","2020-06-17"
"2006.08867","Anna Heffernan","Annalisa Riccardi, Jessica Gemignani, Francisco Fern\'andez-Navarro,
  Anna Heffernan","Optimisation of non-pharmaceutical measures in COVID-19 growth via
  neural networks","This work has been accepted for publication by IEEE Transactions on
  Emerging Topics in Computational Intelligence. \copyright 2020 IEEE","IEEE Transactions on Emerging Topics in Computational
  Intelligence, vol. 5, no. 1, pp. 79-91, Feb. 2021","10.1109/TETCI.2020.3046012",,"q-bio.OT q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On 19th March, the World Health Organisation declared a pandemic. Through
this global spread, many nations have witnessed exponential growth of confirmed
cases brought under control by severe mass quarantine or lockdown measures.
However, some have, through a different timeline of actions, prevented this
exponential growth. Currently as some continue to tackle growth, others attempt
to safely lift restrictions whilst avoiding a resurgence. This study seeks to
quantify the impact of government actions in mitigating viral transmission of
SARS-CoV-2 by a novel soft computing approach that makes concurrent use of a
neural network model, to predict the daily slope increase of cumulative
infected, and an optimiser, with a parametrisation of the government
restriction time series, to understanding the best set of mitigating actions.
Data for two territories, Italy and Taiwan, have been gathered to model
government restrictions in traveling, testing and enforcement of social
distance measures as well as people connectivity and adherence to government
actions. It is found that a larger and earlier testing campaign with tighter
entry restrictions benefit both regions, resulting in significantly less
confirmed cases. Interestingly, this scenario couples with an earlier but
milder implementation of nationwide restrictions for Italy, thus supporting
Taiwan's lack of nationwide lockdown. The results, found with a purely
data-driven approach, are in line with the main findings of mathematical
epidemiological models, proving that the proposed approach has value and that
the data alone contains valuable knowledge to inform decision makers.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:04:40 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 21:04:03 GMT""},{""version"":""v3"",""created"":""Wed, 25 Nov 2020 20:54:07 GMT""},{""version"":""v4"",""created"":""Wed, 16 Dec 2020 00:29:43 GMT""}]","2022-09-28"
"2006.08868","Yutao Li","Yutao Li, Scott Dietrich, Carlos Forsythe, Takashi Taniguchi, Kenji
  Watanabe, Pilkyung Moon, Cory R. Dean","Anisotropic band flattening in graphene with 1D superlattices",,,"10.1038/s41565-021-00849-9",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Patterning graphene with a spatially-periodic potential provides a powerful
means to modify its electronic properties. Dramatic effects have been
demonstrated in twisted bilayers where coupling to the resulting
moir\'e-superlattice yields an isolated flat band that hosts correlated
many-body phases. However, both the symmetry and strength of the effective
moir\'e potential are constrained by the constituent crystals, limiting its
tunability. Here we exploit the technique of dielectric patterning to subject
graphene to a one-dimensional electrostatic superlattice (SL). We observe the
emergence of multiple Dirac cones and find evidence that with increasing SL
potential the main and satellite Dirac cones are sequentially flattened in the
direction parallel to the SL basis vector. Our results demonstrate the ability
to induce tunable transport anisotropy in high mobility two-dimensional
materials, a long-desired property for novel electronic and optical
applications, as well as a new approach to engineering flat energy bands where
electron-electron interactions can lead to emergent properties.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:05:14 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 14:47:41 GMT""}]","2021-06-09"
"2006.08869","Xuewen Liu","Xuewen Liu, Ying Li, Tianjun Li, Bin Zhu","The Light Sgoldstino Phenomenology: Explanations for the Muon $(g-2)$
  Deviation and KOTO Anomaly","17 pages, 4 figures, version accepted by JHEP","JHEP10(2020)197","10.1007/JHEP10(2020)197",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we study the long-standing experimental anomaly in muon $(g-2)$
and also recent anomalous excess in $K_L\to \pi^0+\nu\bar\nu$ at the J-PARC
KOTO experiment with sgoldstino. After supersymmetry breaking, the interactions
between quarks and sgoldstino ($s$) make the decays $K\to \pi+s$ sizable
through loop diagrams, which affects the measurements of decays $K\to
\pi+\mathrm{invisible}$. Furthermore, the couplings between photons and
sgoldstino contribute to $\Delta a_\mu$ as well as the bino-slepton
contribution. With satisfying all known experimental constraints such as from
NA62, E949, E137, Orsay, KTEV and CHARM experiments, these two anomalies can be
explained simultaneously. The mass of CP-even sgoldstino is close to the
neutral pion mass which does not violate the Grossman-Nir bound. The parameter
space can be further tested in future NA62, DUNE experiments, as well as
experiments in the LHC.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:06:05 GMT""},{""version"":""v2"",""created"":""Wed, 30 Sep 2020 00:12:45 GMT""}]","2020-10-30"
"2006.08870","Ahan M R","Ahan M. R., Shreyas Sunil Kulkarni","End-to-End Code Switching Language Models for Automatic Speech
  Recognition","5 pages, 2 figures, To appear in the proceedings of First Workshop on
  Speech Technologies for Code-switching in Multilingual Communities 2020",,,,"cs.CL cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we particularly work on the code-switched text, one of the
most common occurrences in the bilingual communities across the world. Due to
the discrepancies in the extraction of code-switched text from an Automated
Speech Recognition(ASR) module, and thereby extracting the monolingual text
from the code-switched text, we propose an approach for extracting monolingual
text using Deep Bi-directional Language Models(LM) such as BERT and other
Machine Translation models, and also explore different ways of extracting
code-switched text from the ASR model. We also explain the robustness of the
model by comparing the results of Perplexity and other different metrics like
WER, to the standard bi-lingual text output without any external information.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:11:18 GMT""}]","2020-06-17"
"2006.08871","Seiichi Kamada","Andrew Bartholomew, Roger Fenn, Naoko Kamada and Seiichi Kamada","Doodles and commutator identities",,,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A doodle is a collection of immersed circles without triple intersections in
the $2$-sphere. It was shown by the second author and P.~Tayler that doodles
induce commutator identities (identities amongst commutators) in a free group.
In this paper we observe this idea more closely by concentrating on doodles
with proper noose systems and elementary commutator identities. In particular
we show that there is a bijection between cobordism classes of colored doodles
and weak equivalence classes of elementary commutator identities.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:12:55 GMT""},{""version"":""v2"",""created"":""Wed, 24 Feb 2021 05:55:31 GMT""}]","2021-02-25"
"2006.08872","Piotr Przytycki","Piotr Przytycki and Marcin Sabok","Unicorn paths and hyperfiniteness for the mapping class group","14 pages, 2 figures","Forum of Mathematics, Sigma 9 (2021) e36","10.1017/fms.2021.34",,"math.GT math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let S be an orientable surface of finite type. Using Pho-On's infinite
unicorn paths, we prove the hyperfiniteness of orbit equivalence relations
induced by the actions of the mapping class group of S on the Gromov boundaries
of the arc graph and the curve graph of S. In the curve graph case, this
strengthens the results of Hamenst\""adt and Kida that this action is
universally amenable and that the mapping class group of S is exact.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:13:31 GMT""},{""version"":""v2"",""created"":""Fri, 9 Apr 2021 12:20:29 GMT""}]","2021-07-01"
"2006.08873","Yulai Cong","Yulai Cong, Miaoyun Zhao, Jianqiao Li, Junya Chen, Lawrence Carin","GO Hessian for Expectation-Based Objectives",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An unbiased low-variance gradient estimator, termed GO gradient, was proposed
recently for expectation-based objectives
$\mathbb{E}_{q_{\boldsymbol{\gamma}}(\boldsymbol{y})} [f(\boldsymbol{y})]$,
where the random variable (RV) $\boldsymbol{y}$ may be drawn from a stochastic
computation graph with continuous (non-reparameterizable) internal nodes and
continuous/discrete leaves. Upgrading the GO gradient, we present for
$\mathbb{E}_{q_{\boldsymbol{\boldsymbol{\gamma}}}(\boldsymbol{y})}
[f(\boldsymbol{y})]$ an unbiased low-variance Hessian estimator, named GO
Hessian. Considering practical implementation, we reveal that GO Hessian is
easy-to-use with auto-differentiation and Hessian-vector products, enabling
efficient cheap exploitation of curvature information over stochastic
computation graphs. As representative examples, we present the GO Hessian for
non-reparameterizable gamma and negative binomial RVs/nodes. Based on the GO
Hessian, we design a new second-order method for
$\mathbb{E}_{q_{\boldsymbol{\boldsymbol{\gamma}}}(\boldsymbol{y})}
[f(\boldsymbol{y})]$, with rigorous experiments conducted to verify its
effectiveness and efficiency.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:20:41 GMT""}]","2020-06-17"
"2006.08874","Yuan-Chuan Zou","Yuan-Chuan Zou","Conceptual remote distance measurement with a double-slit interference","Accepted for publication in Journal of Astronomical Instrumentation",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distance measurement is crucial to astronomy. Here we suggest a new
conceptual method to measure the distance by using a local instrument. By
engaging the double-slit interference and by considering the phase information
of the light, the position of the intensity maximum is related to the distance
of the source. Consequently, the precise measurement of the position can be
used to measure the distance of the remote source.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:21:19 GMT""}]","2020-06-17"
"2006.08875","Zichuan Lin","Zichuan Lin, Garrett Thomas, Guangwen Yang, Tengyu Ma","Model-based Adversarial Meta-Reinforcement Learning","Accepted by NeurIPS 2020. Code at https://github.com/LinZichuan/AdMRL",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Meta-reinforcement learning (meta-RL) aims to learn from multiple training
tasks the ability to adapt efficiently to unseen test tasks. Despite the
success, existing meta-RL algorithms are known to be sensitive to the task
distribution shift. When the test task distribution is different from the
training task distribution, the performance may degrade significantly. To
address this issue, this paper proposes Model-based Adversarial
Meta-Reinforcement Learning (AdMRL), where we aim to minimize the worst-case
sub-optimality gap -- the difference between the optimal return and the return
that the algorithm achieves after adaptation -- across all tasks in a family of
tasks, with a model-based approach. We propose a minimax objective and optimize
it by alternating between learning the dynamics model on a fixed task and
finding the adversarial task for the current model -- the task for which the
policy induced by the model is maximally suboptimal. Assuming the family of
tasks is parameterized, we derive a formula for the gradient of the
suboptimality with respect to the task parameters via the implicit function
theorem, and show how the gradient estimator can be efficiently implemented by
the conjugate gradient method and a novel use of the REINFORCE estimator. We
evaluate our approach on several continuous control benchmarks and demonstrate
its efficacy in the worst-case performance over all tasks, the generalization
power to out-of-distribution tasks, and in training and test time sample
efficiency, over existing state-of-the-art meta-RL algorithms.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:21:49 GMT""},{""version"":""v2"",""created"":""Sat, 27 Feb 2021 13:19:45 GMT""}]","2021-03-02"
"2006.08876","Jonathan Rubin","Jonathan Rubin","Elmendorf constructions for $G$-categories and $G$-posets","15 pages, comments welcome",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce new Elmendorf constructions for equivariant categories and
posets, and we prove that they are compatible with the classical topological
one. Our constructions are more concrete than their model-categorical
counterparts, and they give rise to new proofs of the Elmendorf theorems for
equivariant categories and posets.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:23:44 GMT""}]","2020-06-17"
"2006.08877","Yi Ren","Donald Goldfarb, Yi Ren, Achraf Bahamou","Practical Quasi-Newton Methods for Training Deep Neural Networks",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the development of practical stochastic quasi-Newton, and in
particular Kronecker-factored block-diagonal BFGS and L-BFGS methods, for
training deep neural networks (DNNs). In DNN training, the number of variables
and components of the gradient $n$ is often of the order of tens of millions
and the Hessian has $n^2$ elements. Consequently, computing and storing a full
$n \times n$ BFGS approximation or storing a modest number of (step, change in
gradient) vector pairs for use in an L-BFGS implementation is out of the
question. In our proposed methods, we approximate the Hessian by a
block-diagonal matrix and use the structure of the gradient and Hessian to
further approximate these blocks, each of which corresponds to a layer, as the
Kronecker product of two much smaller matrices. This is analogous to the
approach in KFAC, which computes a Kronecker-factored block-diagonal
approximation to the Fisher matrix in a stochastic natural gradient method.
Because the indefinite and highly variable nature of the Hessian in a DNN, we
also propose a new damping approach to keep the upper as well as the lower
bounds of the BFGS and L-BFGS approximations bounded. In tests on autoencoder
feed-forward neural network models with either nine or thirteen layers applied
to three datasets, our methods outperformed or performed comparably to KFAC and
state-of-the-art first-order stochastic methods.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:27:12 GMT""},{""version"":""v2"",""created"":""Wed, 28 Oct 2020 00:40:51 GMT""},{""version"":""v3"",""created"":""Thu, 7 Jan 2021 19:36:34 GMT""}]","2021-01-11"
"2006.08878","Nikolay Kozyrskiy","Nikolay Kozyrskiy, Anh-Huy Phan","CNN Acceleration by Low-rank Approximation with Quantized Factors",,,,,"cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The modern convolutional neural networks although achieve great results in
solving complex computer vision tasks still cannot be effectively used in
mobile and embedded devices due to the strict requirements for computational
complexity, memory and power consumption. The CNNs have to be compressed and
accelerated before deployment. In order to solve this problem the novel
approach combining two known methods, low-rank tensor approximation in Tucker
format and quantization of weights and feature maps (activations), is proposed.
The greedy one-step and multi-step algorithms for the task of multilinear rank
selection are proposed. The approach for quality restoration after applying
Tucker decomposition and quantization is developed. The efficiency of our
method is demonstrated for ResNet18 and ResNet34 on CIFAR-10, CIFAR-100 and
Imagenet classification tasks. As a result of comparative analysis performed
for other methods for compression and acceleration our approach showed its
promising features.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:28:05 GMT""}]","2020-06-17"
"2006.08879","Mariano Trigo","M. Trigo, P. Giraldo-Gallo, J. N. Clark, M. E. Kozina, T. Henighan, M.
  P. Jiang, M. Chollet, I. R. Fisher, J. M. Glownia, T. Katayama, P. S.
  Kirchmann, D. Leuenberger, H. Liu, D. A. Reis, Z. X. Shen, D. Zhu","Formation of buried domain walls in the ultrafast transition of SmTe$_3$",,"Phys. Rev. B 103, 054109 (2021)","10.1103/PhysRevB.103.054109",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study ultrafast x-ray diffraction on the charge density wave (CDW) of
SmTe$_3$ using an x-ray free electron laser. The CDW peaks show that
photoexcitation with near-infrared pump centered at 800 nm generates domain
walls of the order parameter propagating perpendicular to the sample surface.
These domain walls break the CDW long range order and suppress the diffraction
intensity of the CDW for times much longer than the $\sim 1$~ps recovery of the
local electronic gap. We reconstruct the spatial and temporal dependence of the
order parameter using a simple Ginzburg-Landau model and find good agreement
between the experimental and model fluence dependences. Based on the model we
find that at long times, depending on the pump fluence, multiple domain walls
remain at distances of few nm from the surface.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:30:37 GMT""}]","2021-02-24"
"2006.08880","Zongshun Wang","Zongshun Wang and Jiachao Wu","The SCC-recursiveness Principle in Fuzzy Argumentation Frameworks",,,,,"cs.AI math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dung's abstract argumentation theory plays a guiding role in the field of
formal argumentation. The properties of argumentation semantics have been
deeply explored in the previous literature. The SCC-recursiveness principle is
a property of the extensions which relies on the graph-theoretical notion of
strongly connected components. It provides a general recursive schema for
argumentation semantics, which is an efficient and incremental algorithm for
computing the argumentation semantics. However, in argumentation frameworks
with uncertain arguments and uncertain attack relation, the SCC-recursive
theory is absence. This paper is an exploration of the SCC-recursive theory in
fuzzy argumentation frameworks (FAFs), which add numbers as fuzzy degrees to
the arguments and attacks. In this paper, in order to extend the
SCC-recursiveness principle to FAFs, we first modify the reinstatement
principle and directionality principle to fit the FAFs. Then the
SCC-recursiveness principle in FAFs is formalized by the modified principles.
Additionally, some illustrating examples show that the SCC-recursiveness
principle also provides an efficient and incremental algorithm for simplify the
computation of argumentation semantics in FAFs.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:33:06 GMT""}]","2020-06-17"
"2006.08881","Kellie Webster","Kellie Webster and Emily Pitler","Scalable Cross Lingual Pivots to Model Pronoun Gender for Translation",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Machine translation systems with inadequate document understanding can make
errors when translating dropped or neutral pronouns into languages with
gendered pronouns (e.g., English). Predicting the underlying gender of these
pronouns is difficult since it is not marked textually and must instead be
inferred from coreferent mentions in the context. We propose a novel
cross-lingual pivoting technique for automatically producing high-quality
gender labels, and show that this data can be used to fine-tune a BERT
classifier with 92% F1 for Spanish dropped feminine pronouns, compared with
30-51% for neural machine translation models and 54-71% for a non-fine-tuned
BERT model. We augment a neural machine translation model with labels from our
classifier to improve pronoun translation, while still having parallelizable
translation models that translate a sentence at a time.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:41:46 GMT""}]","2020-06-17"
"2006.08882","Xiulai Xu Prof","Xin Xie, Weixuan Zhang, Xiaowu He, Shiyao Wu, Jianchen Dang, Kai Peng,
  Feilong Song, Longlong Yang, Haiqiao Ni, Zhichuan Niu, Can Wang, Kuijuan Jin,
  Xiangdong Zhang and Xiulai Xu","Cavity Quantum Electrodynamics with Second-Order Topological Corner
  State","17 pages, 3 figures","Laser Photonics Rev. 1900425, 2020","10.1002/lpor.201900425",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological photonics provides a new paradigm in studying cavity quantum
electrodynamics with robustness to disorder. In this work, we demonstrate the
coupling between single quantum dots and the second-order topological corner
state. Based on the second-order topological corner state, a topological
photonic crystal cavity is designed and fabricated into GaAs slabs with quantum
dots embedded. The coexistence of corner state and edge state with high quality
factor close to 2000 is observed. The enhancement of photoluminescence
intensity and emission rate are both observed when the quantum dot is on
resonance with the corner state. This result enables the application of
topology into cavity quantum electrodynamics, offering an approach to
topological devices for quantum information processing.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:42:52 GMT""}]","2020-06-17"
"2006.08883","Ramezan Sahebi","Ramezan Sahebi","Comment on: A significant enhancement in visible-light photodetection
  properties of chemical spray pyrolysis fabricated CdS thin films by novel Eu
  doping concentrations [Sens. Actuator. A Phys. 301 (2020) 111749]",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a recent paper [Sens. Actuator. A Phys. 301 (2020) 111749] Shkir et al.
have studied the structural, optical and photo-electrical properties of the CdS
thin films as a function of Eu doping concentration. The authors have used a
wrong equation to calculate the refractive index and obtained values are
incorrect. Consequently, the optical properties obtained based on the
refractive index such as real and imaginary parts of dielectric constant,
dielectric loss, optical conductivity, nonlinear refractive index (n2), linear
and third-order non-linear optical susceptibility are wrong.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:42:56 GMT""}]","2020-06-17"
"2006.08884","Chang Qing Sun Dr","Chang Q Sun","Rules essential to water molecular undercoordination","11.7 k words, 13 figures,115 refs. Chinese Physics B 2020",,"10.1088/1674-1056/ab8dad",,"cond-mat.soft physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A sequential of concepts developed in last decade has enabled a resolution to
multiple anomalies of water ice and its low-dimensionality, particularly.
Developed concepts include the coupled hydrogen bond oscillator pair, segmental
specific heat, three-body coupling potentials, quasisolidity, and
supersolidity. Resolved anomalies include ice buoyancy, ice slipperiness, water
skin toughness, supercooling and superheating at the nanoscale, etc. Evidence
shows consistently that molecular undercoordination shortens the HO bond and
stiffens its phonon while undercoordination does the OH nonbond contrastingly
associated with strong lone pair polarization, which endows the low-dimensional
water ice with supersolidity. The supersolid phase is hydrophobic, less dense,
viscoelastic, thermally more diffusive and stable, having longer electron and
phonon lifetime. The equal number of lone pairs and protons reserves the
configuration and orientation of the coupled hydrogen bond bonds and restricts
molecular rotation and proton hopping, which entitles water the simplest,
ordered, tetrahedrally-coordinated, fluctuating molecular crystal covered with
a supersolid skin. The hydrogen bond segmental cooperativity and specific-heat
disparity form the soul dictating the extraordinary adaptivity, reactivity,
recoverability, sensitivity of water ice when subjecting to physical
perturbation. It is recommended that the premise of hydrogen bonding and
electronic dynamics would deepen the insight into the core physics and
chemistry of water ice.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:46:27 GMT""}]","2020-06-17"
"2006.08885","Sharif Abuadbba Dr","Bedeuro Kim, Sharif Abuadbba, Hyoungshick Kim","DeepCapture: Image Spam Detection Using Deep Learning and Data
  Augmentation","15 pages, single column. ACISP 2020: Australasian Conference on
  Information Security and Privacy",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image spam emails are often used to evade text-based spam filters that detect
spam emails with their frequently used keywords. In this paper, we propose a
new image spam email detection tool called DeepCapture using a convolutional
neural network (CNN) model. There have been many efforts to detect image spam
emails, but there is a significant performance degrade against entirely new and
unseen image spam emails due to overfitting during the training phase. To
address this challenging issue, we mainly focus on developing a more robust
model to address the overfitting problem. Our key idea is to build a
CNN-XGBoost framework consisting of eight layers only with a large number of
training samples using data augmentation techniques tailored towards the image
spam detection task. To show the feasibility of DeepCapture, we evaluate its
performance with publicly available datasets consisting of 6,000 spam and 2,313
non-spam image samples. The experimental results show that DeepCapture is
capable of achieving an F1-score of 88%, which has a 6% improvement over the
best existing spam detection model CNN-SVM with an F1-score of 82%. Moreover,
DeepCapture outperformed existing image spam detection solutions against new
and unseen image datasets.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:50:04 GMT""}]","2020-06-17"
"2006.08886","Joshua Zahl","Adam Sheffer and Joshua Zahl","Distinct distances in the complex plane","41 pages, 0 figures",,,,"math.CO cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that if $P$ is a set of $n$ points in $\mathbb{C}^2$, then either
the points in $P$ determine $\Omega(n^{1-\epsilon})$ complex distances, or $P$
is contained in a line with slope $\pm i$. If the latter occurs then each pair
of points in $P$ have complex distance 0.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:52:44 GMT""}]","2020-06-17"
"2006.08887","Jo\~ao Paulo Bessa Brito","Jo\~ao P. B. Brito, Rafael P. Bernar, Lu\'is C. B. Crispino","Synchrotron geodesic radiation in Schwarzschild-de Sitter spacetime","9 pages, 8 figures","Phys. Rev. D 101 124019 (2020)","10.1103/PhysRevD.101.124019",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the scalar radiation emitted by a source in geodesic circular
orbits around a Schwarzschild-de Sitter black hole. We obtain the emitted power
using quantum field theory in curved spacetimes framework at tree level. We
compare our results with the scalar synchrotron radiation in Schwarzschild
spacetime.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:53:49 GMT""}]","2020-06-17"
"2006.08888","Xinjie Lan","Xinjie Lan, Xin Guo, Kenneth E. Barner","PAC-Bayesian Generalization Bounds for MultiLayer Perceptrons",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study PAC-Bayesian generalization bounds for Multilayer Perceptrons (MLPs)
with the cross entropy loss. Above all, we introduce probabilistic explanations
for MLPs in two aspects: (i) MLPs formulate a family of Gibbs distributions,
and (ii) minimizing the cross-entropy loss for MLPs is equivalent to Bayesian
variational inference, which establish a solid probabilistic foundation for
studying PAC-Bayesian bounds on MLPs. Furthermore, based on the Evidence Lower
Bound (ELBO), we prove that MLPs with the cross entropy loss inherently
guarantee PAC- Bayesian generalization bounds, and minimizing PAC-Bayesian
generalization bounds for MLPs is equivalent to maximizing the ELBO. Finally,
we validate the proposed PAC-Bayesian generalization bound on benchmark
datasets.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:55:26 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 05:21:00 GMT""}]","2020-06-18"
"2006.08889","Zerun Feng","Zerun Feng, Zhimin Zeng, Caili Guo, Zheng Li","Exploiting Visual Semantic Reasoning for Video-Text Retrieval","Accepted by IJCAI 2020. SOLE copyright holder is IJCAI (International
  Joint Conferences on Artificial Intelligence), all rights reserved.
  http://static.ijcai.org/2020-accepted_papers.html",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video retrieval is a challenging research topic bridging the vision and
language areas and has attracted broad attention in recent years. Previous
works have been devoted to representing videos by directly encoding from
frame-level features. In fact, videos consist of various and abundant semantic
relations to which existing methods pay less attention. To address this issue,
we propose a Visual Semantic Enhanced Reasoning Network (ViSERN) to exploit
reasoning between frame regions. Specifically, we consider frame regions as
vertices and construct a fully-connected semantic correlation graph. Then, we
perform reasoning by novel random walk rule-based graph convolutional networks
to generate region features involved with semantic relations. With the benefit
of reasoning, semantic interactions between regions are considered, while the
impact of redundancy is suppressed. Finally, the region features are aggregated
to form frame-level features for further encoding to measure video-text
similarity. Extensive experiments on two public benchmark datasets validate the
effectiveness of our method by achieving state-of-the-art performance due to
the powerful semantic reasoning.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:56:46 GMT""}]","2020-06-17"
"2006.08890","Daniel Linford","Daniel Linford","The Kalam Cosmological Argument Meets The Mentaculus","36 pages, Forthcoming in The British Journal for Philosophy of
  Science",,"10.1093/bjps/axaa005",,"physics.hist-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  According to the orthodox interpretation of bounce cosmologies, the universe
was born from an entropy reducing phase in a previous universe. To defend the
thesis that the whole of physical reality was caused to exist a finite time
ago, William Lane Craig and co-author James Sinclair have argued the low
entropy interface between universes should instead be understood as the
beginning of two universes. Here, I present Craig and Sinclair with a dilemma.
On the one hand, if the direction of time is reducible, as friends of the
Mentaculus -- e.g., David Albert, Barry Loewer, and David Papineau -- maintain,
then there is reason to think that the direction of time and the entropic arrow
of time align. But on that account, efficient causation is likely reducible to
non-causal phenomena. In consequence, contrary to Craig and Sinclair's
theological aims, things can begin to exist without causes. On the other hand,
if the direction of time is not reducible, Craig and Sinclair's interpretation
of bounce cosmologies is unjustified. Lastly, a reply to a potential objection
motivates a discussion of how to interpret bounce cosmologies on the tensed
theory of absolute time favored by Craig and Sinclair. I offer two
interpretations of bounce cosmologies that, given a tensed theory of absolute
time, are preferable to those Craig and Sinclair offer, yet inconsistent with
their project in natural theology; on one interpretation, the universe does not
require a supernatural cause and, on the other, bounce cosmologies represent
the universe as never having begun to exist.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:56:55 GMT""}]","2020-06-17"
"2006.08891","Shuai Yin","Shuai Yin, Shao-Kai Jian","Fermion-induced Dynamical Critical Point","6+4 pages, 4+4 figures","Phys. Rev. B 103, 125116 (2021)","10.1103/PhysRevB.103.125116",,"cond-mat.stat-mech cond-mat.quant-gas cond-mat.str-el hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamical phase transition (DPT) characterizes the abrupt change of dynamical
properties in nonequilibrium quantum many-body systems. It has been
demonstrated that extra quantum fluctuating modes besides the conventional
order parameter field can drastically change the properties of equilibrium
phase transitions. However, the counterpart phenomena in DPTs have rarely been
explored. Here, we study the DPT in the Dirac system after a sudden quench, and
find that the fermion fluctuations can round a putative first-order DPT into a
dynamical critical point, which is referred to as a fermion-induced dynamical
critical point (FIDCP). It is also a nonthermal critical point, in which the
universal short-time scaling behavior emerges despite the system goes through a
first-order transition after thermalization. In the novel scenario of FIDCP,
the quantum Yukawa coupling $g_q$ is indispensable for inducing the FIDCP
albeit irrelevant in the infrared scale. We call these variables {\it
indispensable irrelevant scaling variables}. Moreover, a dynamical tricritical
point which separates the first-order DPT and the FIDCP is discovered by tuning
this indispensable irrelevant scaling variable. We further mention possible
experimental realizations.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:05:34 GMT""}]","2021-03-11"
"2006.08892","Deng Hanyuan","Mingyao Zeng and Hanyuan Deng","The maximal tree with respect to the exponential of the second Zagreb
  index",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The second Zagreb index is $M_2(G)=\sum_{uv\in E(G)}d_{G}(u)d_{G}(v)$. It was
found to occur in certain approximate expressions of the total $\pi$-electron
energy of alternant hydrocarbons and used by various researchers in their QSPR
and QSAR studies. Recently the exponential of a vertex-degree-based topological
index was introduced. It is known that among all trees with $n$ vertices, the
exponential of the second Zagreb index $e^{M_2}$ attains its minimum value in
the path $P_n$. In this paper, we show that $e^{M_2}$ attains its maximum value
in the balanced double star with $n$ vertices and solve an open problem
proposed by Cruz and Rada [R. Cruz, J. Rada, The path and the star as extremal
values of vertex-degree-based topological indices among trees, MATCH Commun.
Math. Comput. Chem. 82 (3) (2019) 715-732].
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:06:08 GMT""}]","2020-06-17"
"2006.08893","Xiaomei Huang","Guoqiong Liao, Xiaomei Huang, Neal N. Xiong, and Changxuan Wan","An Intelligent Group Event Recommendation System in Social networks",,,,,"cs.SI cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The importance of contexts has been widely recognized in recommender systems
for individuals. However, most existing group recommendation models in
Event-Based Social Networks (EBSNs) focus on how to aggregate group members'
preferences to form group preferences. In these models, the influence of
contexts on groups is considered but simply defined in a manual way, which
cannot model the complex and deep interactions between contexts and groups. In
this paper, we propose an Attention-based Context-aware Group Event
Recommendation model (ACGER) in EBSNs. ACGER models the deep, non-linear
influence of contexts on users, groups, and events through multi-layer neural
networks. Especially, a novel attention mechanism is designed to enable the
influence weights of contexts on users/groups change dynamically with the
events concerned. Considering that groups may have completely different
behavior patterns from group members, we propose that the preference of a group
need to be obtained from indirect and direct perspectives (called indirect
preference and direct preference respectively). In order to obtain the indirect
preference, we propose a method of aggregating preferences based on attention
mechanism. Compared with existing predefined strategies, this method can
flexibly adapt the strategy according to the events concerned by the group. In
order to obtain the direct preference, we employ neural networks to directly
learn it from group-event interactions. Furthermore, to make full use of rich
user-event interactions in EBSNs, we integrate the context-aware individual
recommendation task into ACGER, which enhances the accuracy of learning of user
embeddings and event embeddings. Extensive experiments on two real datasets
from Meetup show that our model ACGER significantly outperforms the
state-of-the-art models.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:09:21 GMT""}]","2020-06-17"
"2006.08894","Chenhao Qi","Chenhao Qi, Peihao Dong, Wenyan Ma, Hua Zhang, Zaichen Zhang and
  Geoffrey Ye Li","Acquisition of Channel State Information for mmWave Massive MIMO:
  Traditional and Machine Learning-based Approaches",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The accuracy of channel state information (CSI) acquisition directly affects
the performance of millimeter wave (mmWave) communications. In this article, we
provide an overview on CSI acquisition, including beam training and channel
estimation for mmWave massive multiple-input multiple-output systems. The beam
training can avoid the estimation of a high-dimension channel matrix while the
channel estimation can flexibly exploit advanced signal processing techniques.
In addition to introducing the traditional and machine learning-based
approaches in this article, we also compare different approaches in terms of
spectral efficiency, computational complexity, and overhead.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:11:51 GMT""},{""version"":""v2"",""created"":""Sat, 12 Mar 2022 10:12:15 GMT""}]","2022-03-15"
"2006.08895","Kento Yasuda","Kento Yasuda, Mizuki Kuroda, and Shigeyuki Komura","Reciprocal microswimmers in a viscoelastic fluid",,"Physics of Fluids 32, 093102 (2020)","10.1063/5.0018540",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We suggest several reciprocal swimming mechanisms that lead to a locomotion
only in viscoelastic fluids. The first situation is to have a difference
between the two amplitudes of the oscillatory arm motion for a three-sphere
microswimmer. The second situation is when one of the frequencies of the arm
motion is twice as large as the other one for a three-sphere microswimmer. The
third situation is when the sphere sizes are different for a two-sphere
microswimmer. In all these three cases, the average velocity is proportional to
the imaginary part of the complex shear viscosity of a surrounding viscoelastic
medium. It is essential for a micromachine to break its structural symmetry in
order to swim in a viscoelastic fluid by performing reciprocal body motions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:12:06 GMT""},{""version"":""v2"",""created"":""Sun, 23 Aug 2020 09:06:21 GMT""}]","2021-06-08"
"2006.08896","Yunfeng He","Yunfeng He, Jing Zhang, Shi Jin, Chao-Kai Wen, and Geoffrey Ye Li","Model-Driven DNN Decoder for Turbo Codes: Design, Simulation and
  Experimental Results","31 pages, 15 figures",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a novel model-driven deep learning (DL) architecture,
called TurboNet, for turbo decoding that integrates DL into the traditional
max-log-maximum a posteriori (MAP) algorithm. The TurboNet inherits the
superiority of the max-log-MAP algorithm and DL tools and thus presents
excellent error-correction capability with low training cost. To design the
TurboNet, the original iterative structure is unfolded as deep neural network
(DNN) decoding units, where trainable weights are introduced to the max-log-MAP
algorithm and optimized through supervised learning. To efficiently train the
TurboNet, a loss function is carefully designed to prevent tricky gradient
vanishing issue. To further reduce the computational complexity and training
cost of the TurboNet, we can prune it into TurboNet+. Compared with the
existing black-box DL approaches, the TurboNet+ has considerable advantage in
computational complexity and is conducive to significantly reducing the
decoding overhead. Furthermore, we also present a simple training strategy to
address the overfitting issue, which enable efficient training of the proposed
TurboNet+. Simulation results demonstrate TurboNet+'s superiority in
error-correction ability, signal-to-noise ratio generalization, and
computational overhead. In addition, an experimental system is established for
an over-the-air (OTA) test with the help of a 5G rapid prototyping system and
demonstrates TurboNet's strong learning ability and great robustness to various
scenarios.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:14:30 GMT""}]","2020-06-17"
"2006.08897","Longwen Zhou","Longwen Zhou","Non-Hermitian Floquet phases with even-integer topological invariants in
  a periodically quenched two-leg ladder","See https://www.mdpi.com/1099-4300/22/7/746 for the published version
  in the special issue of Entropy: Quantum Dynamics with Non-Hermitian
  Hamiltonians (Open Access)",,"10.3390/e22070746",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Periodically driven non-Hermitian systems could possess exotic nonequilibrium
phases with unique topological, dynamical and transport properties. In this
work, we introduce an experimentally realizable two-leg ladder model subjecting
to both time-periodic quenches and non-Hermitian effects, which belongs to an
extended CII symmetry class. Due to the interplay between drivings and
nonreciprocity, rich non-Hermitian Floquet topological phases emerge in the
system, with each of them been characterized by a pair of even-integer
topological invariants $(w_{0},w_{\pi})\in2\mathbb{Z}\times2\mathbb{Z}$. Under
the open boundary condition, these invariants further predict the number of
zero- and $\pi$-quasienergy modes localized around the edges of the system. We
finally construct a generalized version of the mean chiral displacement, which
could be employed as a dynamical probe to the topological invariants of
non-Hermitian Floquet phases in the CII symmetry class. Our work thus
introduces a new type of non-Hermitian Floquet topological matter, and further
reveals the richness of topology and dynamics in driven open systems.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:22:53 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 02:20:07 GMT""}]","2020-08-26"
"2006.08898","Ke-Ji Chen","Ke-Ji Chen, Fan Wu, Shi-Guo Peng, Wei Yi, and Lianyi He","Generating Giant Vortex in a Fermi Superfluid via
  Spin-Orbital-Angular-Momentum Coupling","6+5 pages, 5+5 figures","Phys. Rev. Lett. 125, 260407 (2020)","10.1103/PhysRevLett.125.260407",,"cond-mat.quant-gas nucl-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spin-orbital-angular-momentum (SOAM) coupling has been realized in recent
experiments of Bose-Einstein condensates [Chen et al., Phys. Rev. Lett. 121,
113204 (2018) and Zhang et al., Phys. Rev. Lett. 122, 110402 (2019)], where the
orbital angular momentum imprinted upon bosons leads to quantized vortices. For
fermions, such an exotic synthetic gauge field can provide fertile ground for
fascinating pairing schemes and rich superfluid phases, which are yet to be
explored. Here we demonstrate how SOAM coupling stabilizes vortices in Fermi
superfluids through a unique mechanism that can be viewed as the angular analog
to that of the spin-orbit-coupling-induced Fulde-Ferrell state under a Fermi
surface deformation. Remarkably, the vortex size is comparable with the beam
waist of Raman lasers generating the SOAM coupling, which is typically much
larger than previously observed vortices in Fermi superfluids. With tunable
size and core structure, these giant vortex states provide unprecedented
experimental access to topological defects in Fermi superfluids.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:25:56 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jan 2021 06:38:18 GMT""}]","2021-01-06"
"2006.08899","Brian Keegan","Brian C. Keegan, Chenhao Tan","A Quantitative Portrait of Wikipedia's High-Tempo Collaborations during
  the 2020 Coronavirus Pandemic","25 figures",,,,"cs.SI cs.CY cs.HC physics.soc-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The 2020 coronavirus pandemic was a historic social disruption with
significant consequences felt around the globe. Wikipedia is a
freely-available, peer-produced encyclopedia with a remarkable ability to
create and revise content following current events. Using 973,940 revisions
from 134,337 editors to 4,238 articles, this study examines the dynamics of the
English Wikipedia's response to the coronavirus pandemic through the first five
months of 2020 as a ""quantitative portrait"" describing the emergent
collaborative behavior at three levels of analysis: article revision, editor
contributions, and network dynamics. Across multiple data sources, quantitative
methods, and levels of analysis, we find four consistent themes characterizing
Wikipedia's unique large-scale, high-tempo, and temporary online
collaborations: external events as drivers of activity, spillovers of activity,
complex patterns of editor engagement, and the shadows of the future. In light
of increasing concerns about online social platforms' abilities to govern the
conduct and content of their users, we identify implications from Wikipedia's
coronavirus collaborations for improving the resilience of socio-technical
systems during a crisis.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:28:04 GMT""}]","2020-06-17"
"2006.08900","Ao Zhang","Ao Zhang and Jinwen Ma","DefenseVGAE: Defending against Adversarial Attacks on Graph Data via a
  Variational Graph Autoencoder","11 pages, 2 figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph neural networks (GNNs) achieve remarkable performance for tasks on
graph data. However, recent works show they are extremely vulnerable to
adversarial structural perturbations, making their outcomes unreliable. In this
paper, we propose DefenseVGAE, a novel framework leveraging variational graph
autoencoders(VGAEs) to defend GNNs against such attacks. DefenseVGAE is trained
to reconstruct graph structure. The reconstructed adjacency matrix can reduce
the effects of adversarial perturbations and boost the performance of GCNs when
facing adversarial attacks. Our experiments on a number of datasets show the
effectiveness of the proposed method under various threat models. Under some
settings it outperforms existing defense strategies. Our code has been made
publicly available at https://github.com/zhangao520/defense-vgae.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:30:23 GMT""}]","2020-06-17"
"2006.08901","Suraj Pawar","Suraj Pawar, Omer San","Data assimilation empowered neural network parameterizations for subgrid
  processes in geophysical flows",,,,,"physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  In the past couple of years, there is a proliferation in the use of machine
learning approaches to represent subgrid scale processes in geophysical flows
with an aim to improve the forecasting capability and to accelerate numerical
simulations of these flows. Despite its success for different types of flow,
the online deployment of a data-driven closure model can cause instabilities
and biases in modeling the overall effect of subgrid scale processes, which in
turn leads to inaccurate prediction. To tackle this issue, we exploit the data
assimilation technique to correct the physics-based model coupled with the
neural network as a surrogate for unresolved flow dynamics in multiscale
systems. In particular, we use a set of neural network architectures to learn
the correlation between resolved flow variables and the parameterizations of
unresolved flow dynamics and formulate a data assimilation approach to correct
the hybrid model during their online deployment. We illustrate our framework in
a set of applications of the multiscale Lorenz 96 system for which the
parameterization model for unresolved scales is exactly known, and the
two-dimensional Kraichnan turbulence system for which the parameterization
model for unresolved scales is not known a priori. Our analysis, therefore,
comprises a predictive dynamical core empowered by (i) a data-driven closure
model for subgrid scale processes, (ii) a data assimilation approach for
forecast error correction, and (iii) both data-driven closure and data
assimilation procedures. We show significant improvement in the long-term
prediction of the underlying chaotic dynamics with our framework compared to
using only neural network parameterizations for future prediction.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:32:20 GMT""},{""version"":""v2"",""created"":""Fri, 9 Apr 2021 19:04:32 GMT""}]","2021-04-13"
"2006.08902","Josue Vazquez-Becerra","Josue Vazquez-Becerra","Fluctuation moments induced by conjugation with asymptotically
  liberating random matrix ensembles",,,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  G. Anderson and B. Farrel showed that conjugation of constant matrices by
asymptotically liberating random unitary matrices give rise to asymptotic free
independence. Independent Haar-unitary random matrices and independent
Haar-orthogonal random matrices are examples of asymptotically liberating
ensembles. In this paper, we investigate the fluctuation moments, and higher
order moments, induced on constant matrices by conjugation with asymptotically
liberating ensembles. In particular, we determine fluctuation moments induced
by an ensembles related to the Discrete Fourier Transform matrix.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:34:20 GMT""}]","2020-06-17"
"2006.08903","Alex Kuefler","Ben Goodrich, Alex Kuefler, William D. Richards","Depth by Poking: Learning to Estimate Depth from Self-Supervised
  Grasping","IEEE International Conference on Robotics and Automation (ICRA) 2020",,,,"cs.CV cs.LG cs.RO eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate depth estimation remains an open problem for robotic manipulation;
even state of the art techniques including structured light and LiDAR sensors
fail on reflective or transparent surfaces. We address this problem by training
a neural network model to estimate depth from RGB-D images, using labels from
physical interactions between a robot and its environment. Our network
predicts, for each pixel in an input image, the z position that a robot's end
effector would reach if it attempted to grasp or poke at the corresponding
position. Given an autonomous grasping policy, our approach is self-supervised
as end effector position labels can be recovered through forward kinematics,
without human annotation. Although gathering such physical interaction data is
expensive, it is necessary for training and routine operation of state of the
art manipulation systems. Therefore, this depth estimator comes ``for free''
while collecting data for other tasks (e.g., grasping, pushing, placing). We
show our approach achieves significantly lower root mean squared error than
traditional structured light sensors and unsupervised deep learning methods on
difficult, industry-scale jumbled bin datasets.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:34:26 GMT""}]","2020-06-17"
"2006.08904","J. Felipe Montano-Campos","Victor Zitian Chen, Felipe Montano-Campos and Wlodek Zadrozny","Causal Knowledge Extraction from Scholarly Papers in Social Sciences",,,,,"cs.CL cs.DL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The scale and scope of scholarly articles today are overwhelming human
researchers who seek to timely digest and synthesize knowledge. In this paper,
we seek to develop natural language processing (NLP) models to accelerate the
speed of extraction of relationships from scholarly papers in social sciences,
identify hypotheses from these papers, and extract the cause-and-effect
entities. Specifically, we develop models to 1) classify sentences in scholarly
documents in business and management as hypotheses (hypothesis classification),
2) classify these hypotheses as causal relationships or not (causality
classification), and, if they are causal, 3) extract the cause and effect
entities from these hypotheses (entity extraction). We have achieved high
performance for all the three tasks using different modeling techniques. Our
approach may be generalizable to scholarly documents in a wide range of social
sciences, as well as other types of textual materials.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:37:40 GMT""}]","2020-06-17"
"2006.08905","Masahito Ohue","Masahito Ohue, Kento Aoyama, Yutaka Akiyama","High-performance cloud computing for exhaustive protein-protein docking","11 pages, 2 figures, and 3 tables. To be published in in Proceedings
  of The 26th International Conference on Parallel & Distributed Processing
  Techniques and Applications (PDPTA'20), Transactions on Computational Science
  and Computational Intelligence (Springer)",,,,"cs.DC q-bio.BM q-bio.MN q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Public cloud computing environments, such as Amazon AWS, Microsoft Azure, and
the Google Cloud Platform, have achieved remarkable improvements in
computational performance in recent years, and are also expected to be able to
perform massively parallel computing. As the cloud enables users to use
thousands of CPU cores and GPU accelerators casually, and various software
types can be used very easily by cloud images, the cloud is beginning to be
used in the field of bioinformatics. In this study, we ported the original
protein-protein interaction prediction (protein-protein docking) software,
MEGADOCK, into Microsoft Azure as an example of an HPC cloud environment. A
cloud parallel computing environment with up to 1,600 CPU cores and 960 GPUs
was constructed using four CPU instance types and two GPU instance types, and
the parallel computing performance was evaluated. Our MEGADOCK on Azure system
showed a strong scaling value of 0.93 for the CPU instance when H16 instance
with 100 instances were used compared to 50, and a strong scaling value of 0.89
for the GPU instance when NC24 instance with 20 were used compared to 5.
Moreover, the results of the usage fee and total computation time supported
that using a GPU instance reduced the computation time of MEGADOCK and the
cloud usage fee required for the computation. The developed environment
deployed on the cloud is highly portable, making it suitable for applications
in which an on-demand and large-scale HPC environment is desirable.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:37:50 GMT""}]","2020-06-17"
"2006.08906","Mingde Zhao","Mingde Zhao","META-Learning Eligibility Traces for More Sample Efficient Temporal
  Difference Learning","A thesis submitted to McGill University in partial fulfillment of the
  requirements of the degree of Master of Computer Science",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Temporal-Difference (TD) learning is a standard and very successful
reinforcement learning approach, at the core of both algorithms that learn the
value of a given policy, as well as algorithms which learn how to improve
policies. TD-learning with eligibility traces provides a way to do temporal
credit assignment, i.e. decide which portion of a reward should be assigned to
predecessor states that occurred at different previous times, controlled by a
parameter $\lambda$. However, tuning this parameter can be time-consuming, and
not tuning it can lead to inefficient learning. To improve the sample
efficiency of TD-learning, we propose a meta-learning method for adjusting the
eligibility trace parameter, in a state-dependent manner. The adaptation is
achieved with the help of auxiliary learners that learn distributional
information about the update targets online, incurring roughly the same
computational complexity per step as the usual value learner. Our approach can
be used both in on-policy and off-policy learning. We prove that, under some
assumptions, the proposed method improves the overall quality of the update
targets, by minimizing the overall target error. This method can be viewed as a
plugin which can also be used to assist prediction with function approximation
by meta-learning feature (observation)-based $\lambda$ online, or even in the
control case to assist policy improvement. Our empirical evaluation
demonstrates significant performance improvements, as well as improved
robustness of the proposed algorithm to learning rate variation.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:41:07 GMT""}]","2020-06-17"
"2006.08907","Amirhossein Reisizadeh","Amirhossein Reisizadeh, Farzan Farnia, Ramtin Pedarsani, Ali Jadbabaie","Robust Federated Learning: The Case of Affine Distribution Shifts",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning is a distributed paradigm that aims at training models
using samples distributed across multiple users in a network while keeping the
samples on users' devices with the aim of efficiency and protecting users
privacy. In such settings, the training data is often statistically
heterogeneous and manifests various distribution shifts across users, which
degrades the performance of the learnt model. The primary goal of this paper is
to develop a robust federated learning algorithm that achieves satisfactory
performance against distribution shifts in users' samples. To achieve this
goal, we first consider a structured affine distribution shift in users' data
that captures the device-dependent data heterogeneity in federated settings.
This perturbation model is applicable to various federated learning problems
such as image classification where the images undergo device-dependent
imperfections, e.g. different intensity, contrast, and brightness. To address
affine distribution shifts across users, we propose a Federated Learning
framework Robust to Affine distribution shifts (FLRA) that is provably robust
against affine Wasserstein shifts to the distribution of observed samples. To
solve the FLRA's distributed minimax problem, we propose a fast and efficient
optimization method and provide convergence guarantees via a gradient Descent
Ascent (GDA) method. We further prove generalization error bounds for the
learnt classifier to show proper generalization from empirical distribution of
samples to the true underlying distribution. We perform several numerical
experiments to empirically support FLRA. We show that an affine distribution
shift indeed suffices to significantly decrease the performance of the learnt
classifier in a new test user, and our proposed algorithm achieves a
significant gain in comparison to standard federated learning and adversarial
training methods.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:43:59 GMT""}]","2020-06-17"
"2006.08908","Jingtian Shi","Jihang Zhu and Jingtian Shi and Allan H. MacDonald","Theory of ARPES in Graphene-Based Moir\'e Superlattices",,"Phys. Rev. B 103, 235146 (2021)","10.1103/PhysRevB.103.235146",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphene-based moir\'e superlattices are now established as an interesting
platform for strongly-correlated many-electron physics, and have so far been
characterized mainly by transport and scanning tunneling microscopy (STM)
measurements. Motivated by recent experimental progress, we present a
theoretical model study whose aim is to assess the potential of angle-resolved
photoemission spectroscopy (ARPES) to resolve some of the many open issues in
these systems. The theory is developed specifically for graphene on hexagonal
boron nitride (G/hBN) and twisted bilayer graphene (TBG) moir\'e superlattices,
but is readily generalized to any system with active degrees of freedom in
graphene sheets.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:46:17 GMT""},{""version"":""v2"",""created"":""Mon, 10 Aug 2020 01:31:03 GMT""},{""version"":""v3"",""created"":""Sun, 2 May 2021 04:03:41 GMT""}]","2021-06-30"
"2006.08909","Guo-Niu Han","J.-P. Allouche, G.-N. Han and J. Shallit","On some conjectures of P. Barry","this supersedes also the paper arXiv:2006.04708",,,,"math.NT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a number of conjectures [arXiv:2005.04066] recently stated by P.
Barry, related to the paperfolding sequence and the Rueppel sequence.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:49:56 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 21:18:47 GMT""}]","2020-06-26"
"2006.08910","Yichong Xu","Yichong Xu, Ruosong Wang, Lin F. Yang, Aarti Singh and Artur Dubrawski","Preference-based Reinforcement Learning with Finite-Time Guarantees","Thirty-fourth Conference on Neural Information Processing Systems
  (NeurIPS 2020). Spotlight presentation",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Preference-based Reinforcement Learning (PbRL) replaces reward values in
traditional reinforcement learning by preferences to better elicit human
opinion on the target objective, especially when numerical reward values are
hard to design or interpret. Despite promising results in applications, the
theoretical understanding of PbRL is still in its infancy. In this paper, we
present the first finite-time analysis for general PbRL problems. We first show
that a unique optimal policy may not exist if preferences over trajectories are
deterministic for PbRL. If preferences are stochastic, and the preference
probability relates to the hidden reward values, we present algorithms for
PbRL, both with and without a simulator, that are able to identify the best
policy up to accuracy $\varepsilon$ with high probability. Our method explores
the state space by navigating to under-explored states, and solves PbRL using a
combination of dueling bandits and policy search. Experiments show the efficacy
of our method when it is applied to real-world problems.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:52:41 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 20:24:58 GMT""}]","2020-10-27"
"2006.08911","Hsin-Po Wang","Iwan Duursma and Xiao Li and Hsin-Po Wang","Multilinear Algebra for Distributed Storage","33 pages, 6 figures, 1 table",,"10.1137/20M1346742",,"cs.IT math.AC math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An $(n, k, d, \alpha, \beta, M)$-ERRC (exact-repair regenerating code) is a
collection of $n$ nodes used to store a file. For a file of total size $M$,
each node stores $\alpha$ symbols, any $k$ nodes recover the file, and any $d$
nodes repair any other node via sending out $\beta$ symbols. We establish a
multilinear algebra foundation to assemble $(n, k, d, \alpha, \beta, M)$-ERRCs
for all meaningful $(n, k, d)$ tuples. Our ERRCs tie the
$\alpha/M$-versus-$\beta/M$ trade-off with cascade codes, the best known
construction for this trade-off. We give directions on how these ERRCs repair
multiple failures.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 03:54:53 GMT""}]","2022-01-07"
"2006.08912","Satoru Nakatsuji","Hanshen Tsai, Tomoya Higo, Kouta Kondou, Takuya Nomoto, Akito Sakai,
  Ayuko Kobayashi, Takafumi Nakano, Kay Yakushiji, Ryotaro Arita, Shinji Miwa,
  YoshiChika Otani, and Satoru Nakatsuji","Electrical Manipulation of a Topological Antiferromagnetic State","49 pages, 14 figures","Nature 580, p608 (2020)","10.1038/s41586-020-2211-2",,"cond-mat.mtrl-sci cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electrical manipulation of emergent phenomena due to nontrivial band topology
is a key to realize next-generation technology using topological protection. A
Weyl semimetal is a three-dimensional gapless system that hosts Weyl fermions
as low-energy quasiparticles. It exhibits various exotic phenomena such as
large anomalous Hall effect (AHE) and chiral anomaly, which have robust
properties due to the topologically protected Weyl nodes. To manipulate such
phenomena, the magnetic version of Weyl semimetals would be useful as a
magnetic texture may provide a handle for controlling the locations of Weyl
nodes in the Brillouin zone. Moreover, given the prospects of antiferromagnetic
(AF) spintronics for realizing high-density devices with ultrafast operation,
it would be ideal if one could electrically manipulate an AF Weyl metal.
However, no report has appeared on the electrical manipulation of a Weyl metal.
Here we demonstrate the electrical switching of a topological AF state and its
detection by AHE at room temperature. In particular, we employ a
polycrystalline thin film of the AF Weyl metal Mn$_3$Sn, which exhibits
zero-field AHE. Using the bilayer device of Mn$_3$Sn and nonmagnetic metals
(NMs), we find that an electrical current density of $\sim 10^{10}$-$10^{11}$
A/m$^2$ in NMs induces the magnetic switching with a large change in Hall
voltage, and besides, the current polarity along a bias field and the sign of
the spin Hall angle $\theta_{\rm SH}$ of NMs [Pt ($\theta_{\rm SH} > 0$),
Cu($\theta_{\rm SH} \sim 0$), W ($\theta_{\rm SH} < 0$)] determines the sign of
the Hall voltage. Notably, the electrical switching in the antiferromagnet is
made using the same protocol as the one used for ferromagnetic metals. Our
observation may well lead to another leap in science and technology for
topological magnetism and AF spintronics.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:01:28 GMT""}]","2020-06-17"
"2006.08913","Murray Batchelor","Zi-Min Li, Devid Ferri and Murray T. Batchelor","Non-orthogonal qubit states expansion for the asymmetric quantum Rabi
  model","8 pages, 7 figures, minor revisions","Phys. Rev. A 103, 013711 (2021)","10.1103/PhysRevA.103.013711",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a physically motivated variational wave function for the ground
state of the asymmetric quantum Rabi model (AQRM). The wave function is a
weighted superposition of squeezed coherent states entangled with
non-orthogonal qubit states, and relies only on three variational parameters in
the regimes of interest where the squeezing effect becomes negligible. The
variational expansion describes the ground state remarkably well in almost all
parameter regimes, especially with arbitrary bias. We use the variational
result to calculate various relevant physical observables of the ground state,
and make a comparison with existing approximations and the exact solution. The
results show that the variational expansion is a significant improvement over
the existing approximations for the AQRM.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:01:55 GMT""},{""version"":""v2"",""created"":""Tue, 10 Nov 2020 02:12:26 GMT""},{""version"":""v3"",""created"":""Tue, 1 Dec 2020 11:17:25 GMT""}]","2021-01-15"
"2006.08914","Zhihui Shao","Zhihui Shao, and Jianyi Yang, and Shaolei Ren","Calibrating Deep Neural Network Classifiers on Out-of-Distribution
  Datasets",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To increase the trustworthiness of deep neural network (DNN) classifiers, an
accurate prediction confidence that represents the true likelihood of
correctness is crucial. Towards this end, many post-hoc calibration methods
have been proposed to leverage a lightweight model to map the target DNN's
output layer into a calibrated confidence. Nonetheless, on an
out-of-distribution (OOD) dataset in practice, the target DNN can often
mis-classify samples with a high confidence, creating significant challenges
for the existing calibration methods to produce an accurate confidence. In this
paper, we propose a new post-hoc confidence calibration method, called CCAC
(Confidence Calibration with an Auxiliary Class), for DNN classifiers on OOD
datasets. The key novelty of CCAC is an auxiliary class in the calibration
model which separates mis-classified samples from correctly classified ones,
thus effectively mitigating the target DNN's being confidently wrong. We also
propose a simplified version of CCAC to reduce free parameters and facilitate
transfer to a new unseen dataset. Our experiments on different DNN models,
datasets and applications show that CCAC can consistently outperform the prior
post-hoc calibration methods.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:06:21 GMT""}]","2020-06-17"
"2006.08915","Liya Xu","Liya Xu, Mingzhu Ge, Weili Wu","Edge computing based incentivizing mechanism for mobile blockchain in
  IOT",,,,,"cs.GT cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mining in the blockchain requires high computing power to solve the hash
puzzle for example proof-of-work puzzle. It takes high cost to achieve the
calculation of this problem in devices of IOT, especially the mobile devices of
IOT. It consequently restricts the application of blockchain in mobile
environment. However, edge computing can be utilized to solve the problem for
insufficient computing power of mobile devices in IOT. Edge servers can recruit
many mobile devices to contribute computing power together to mining and share
the reward of mining with these recruited mobile devices. In this paper, we
propose an incentivizing mechanism based on edge computing for mobile
blockchain. We design a two-stage Stackelberg Game to jointly optimize the
reward of edge servers and recruited mobile devices. The edge server as the
leader sets the expected fee for the recruited mobile devices in Stage I. The
mobile device as a follower provides its computing power to mine according to
the expected fee in Stage. It proves that this game can obtain a uniqueness
Nash Equilibrium solution under the same or different expected fee. In the
simulation experiment, we obtain a result curve of the profit for the edge
server with the different ratio between the computing power from the edge
server and mobile devices. In addition, the proposed scheme has been compared
with the MDG scheme for the profit of the edge server. The experimental results
show that the profit of the proposed scheme is more than that of the MDG scheme
under the same total computing power.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:14:24 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 14:40:57 GMT""}]","2020-07-02"
"2006.08916","Dheeraj Nagaraj","Guy Bresler, Prateek Jain, Dheeraj Nagaraj, Praneeth Netrapalli and
  Xian Wu","Least Squares Regression with Markovian Data: Fundamental Limits and
  Algorithms",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of least squares linear regression where the data-points
are dependent and are sampled from a Markov chain. We establish sharp
information theoretic minimax lower bounds for this problem in terms of
$\tau_{\mathsf{mix}}$, the mixing time of the underlying Markov chain, under
different noise settings. Our results establish that in general, optimization
with Markovian data is strictly harder than optimization with independent data
and a trivial algorithm (SGD-DD) that works with only one in every
$\tilde{\Theta}(\tau_{\mathsf{mix}})$ samples, which are approximately
independent, is minimax optimal. In fact, it is strictly better than the
popular Stochastic Gradient Descent (SGD) method with constant step-size which
is otherwise minimax optimal in the regression with independent data setting.
  Beyond a worst case analysis, we investigate whether structured datasets seen
in practice such as Gaussian auto-regressive dynamics can admit more efficient
optimization schemes. Surprisingly, even in this specific and natural setting,
Stochastic Gradient Descent (SGD) with constant step-size is still no better
than SGD-DD. Instead, we propose an algorithm based on experience replay--a
popular reinforcement learning technique--that achieves a significantly better
error rate. Our improved rate serves as one of the first results where an
algorithm outperforms SGD-DD on an interesting Markov chain and also provides
one of the first theoretical analyses to support the use of experience replay
in practice.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:26:50 GMT""}]","2020-06-17"
"2006.08917","Hossein Taheri","Hossein Taheri, Ramtin Pedarsani, and Christos Thrampoulidis","Fundamental Limits of Ridge-Regularized Empirical Risk Minimization in
  High Dimensions",,,,,"stat.ML cs.IT cs.LG eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Empirical Risk Minimization (ERM) algorithms are widely used in a variety of
estimation and prediction tasks in signal-processing and machine learning
applications. Despite their popularity, a theory that explains their
statistical properties in modern regimes where both the number of measurements
and the number of unknown parameters is large is only recently emerging. In
this paper, we characterize for the first time the fundamental limits on the
statistical accuracy of convex ERM for inference in high-dimensional
generalized linear models. For a stylized setting with Gaussian features and
problem dimensions that grow large at a proportional rate, we start with sharp
performance characterizations and then derive tight lower bounds on the
estimation and prediction error that hold over a wide class of loss functions
and for any value of the regularization parameter. Our precise analysis has
several attributes. First, it leads to a recipe for optimally tuning the loss
function and the regularization parameter. Second, it allows to precisely
quantify the sub-optimality of popular heuristic choices: for instance, we show
that optimally-tuned least-squares is (perhaps surprisingly) approximately
optimal for standard logistic data, but the sub-optimality gap grows
drastically as the signal strength increases. Third, we use the bounds to
precisely assess the merits of ridge-regularization as a function of the
over-parameterization ratio. Notably, our bounds are expressed in terms of the
Fisher Information of random variables that are simple functions of the data
distribution, thus making ties to corresponding bounds in classical statistics.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:27:38 GMT""},{""version"":""v2"",""created"":""Sun, 5 Jul 2020 23:54:29 GMT""}]","2020-07-07"
"2006.08918","Alvin Chua","Alvin J. K. Chua, Michele Vallisneri","On parametric tests of relativity with false degrees of freedom","4 pages, 2 figures",,,,"gr-qc astro-ph.IM stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  General relativity can be tested by comparing the binary-inspiral signals
found in LIGO--Virgo data against waveform models that are augmented with
artificial degrees of freedom. This approach suffers from a number of logical
and practical pitfalls. 1) It is difficult to ascribe meaning to the stringency
of the resultant constraints. 2) It is doubtful that the Bayesian model
comparison of relativity against these artificial models can offer actual
validation for the former. 3) It is unknown to what extent these tests might
detect alternative theories of gravity for which there are no computed
waveforms; conversely, when waveforms are available, tests that employ them
will be superior.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:29:32 GMT""}]","2020-06-17"
"2006.08919","Yuya Takeuchi","Yuya Takeuchi","Chern classes of spherical CR manifolds","10 pages, final version. arXiv admin note: text overlap with
  arXiv:2003.10779","Ann. Sc. Norm. Super. Pisa Cl. Sci. 23 (2022), No. 1, 1-13","10.2422/2036-2145.202010_006",,"math.DG math.CV math.GT math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We first construct closed spherical CR manifolds of dimension at least five
having non-trivial first Chern class with real coefficients. We next prove a
constraint on Chern classes with real coefficients of (not necessarily closed)
spherical CR manifolds. Finally, we obtain a topological obstruction to the
existence of spherical CR structures on co-oriented contact manifolds.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:31:38 GMT""},{""version"":""v2"",""created"":""Wed, 12 Oct 2022 01:59:03 GMT""}]","2022-10-13"
"2006.08920","Bi Shihao","Shihao Bi, Minghao Du, Jun Tao and Feiyu Yao","Joule-Thomson Expansion of Born-Infeld AdS Black Holes","20 pages, 18 figures, accepted by Chinese Physics C",,,"CTP-SCU/2020020","gr-qc","http://creativecommons.org/licenses/by/4.0/","  In this paper, the Joule-Thomson expansion of Born-Infeld AdS black holes is
studied in the extended phase space, where the cosmological constant is
identified with the pressure. The Joule-Thomson coefficient, the inversion
curves and the isenthalpic curves are discussed in detail by 4-dimensional
black hole. The critical point of Born-Infeld black hole is depicted with
varying parameter $\beta$ and the charge $Q$. In $T-P$ plane, the inversion
temperature curves and isenthalpic curves are obtained with different parameter
$\beta$ and the charge $Q$. We find that the missing negative slope is still
conserved in Born-Infeld black holes. We also extend our discussion to
arbitrary dimension higher than 4. The critical temperature and the minimum of
inversion temperature are compared, and the ratio is asymptotically $1/2$ as
$Q$ increases or $\beta\to\infty$ in $D=4$, and reproduce the previous results
in higher dimension.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:33:12 GMT""},{""version"":""v2"",""created"":""Fri, 20 Nov 2020 07:45:10 GMT""}]","2020-11-23"
"2006.08921","Weiguo Yin","Weiguo Yin","Frustration-driven unconventional phase transitions at finite
  temperature in a one-dimensional ladder Ising model","13 pages, 4 figures. The Method section and two more references are
  added",,,,"cond-mat.stat-mech cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Ising model, with short-range interactions between constituents, is a
basic mathematical model in statistical mechanics. It has been widely used to
describe collective phenomena such as order-disorder phase transitions in
various physical, biological, economical, and social systems. However, it was
proven that spontaneous phase transitions do not exist in the one-dimensional
Ising models. Besides low dimensionality, frustration is the other well-known
suppressor of phase transitions. Here I show that surprisingly, a strongly
frustrated one-dimensional two-leg ladder Ising model can exhibit a marginal
finite-temperature phase transition. It features a large latent heat, a sharp
peak in specific heat, and unconventional order parameters, which classify the
transition as involving an entropy-favored intermediate-temperature ordered
state and further unveil a crossover to an exotic ""normal state"" in which
frustration effectively decouples the two strongly interacted legs in a
counterintuitive non-mean-field way. These exact results expose a mathematical
structure that has not appeared before in phase-transition problems, and shed
new light on our understanding of phase transitions and the dynamical actions
of frustration. Applications of this model and its mechanisms to various
systems with extensions to consider higher dimensions, quantum characters, or
external fields, etc. are anticipated and briefly discussed---with insights
into the puzzling phenomena of strange strong frustration and
intermediate-temperature orders such as the Bozin-Billinge
orbital-degeneracy-lifting recently discovered in real materials.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:34:01 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 21:19:08 GMT""}]","2020-06-22"
"2006.08922","Zhenyang Zhang","Ilan Adler, Jes\'us A. De Loera, Steven Klee, Zhenyang Zhang","Diameters of Cocircuit Graphs of Oriented Matroids: An Update",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Oriented matroids (often called order types) are combinatorial structures
that generalize point configurations, vector configurations, hyperplane
arrangements, polyhedra, linear programs, and directed graphs. Oriented
matroids have played a key role in combinatorics, computational geometry, and
optimization. This paper surveys prior work and presents an update on the
search for bounds on the diameter of the cocircuit graph of an oriented
matroid.
  We review the diameter problem and show the diameter bounds of general
oriented matroids reduce to those of uniform oriented matroids. We give the
latest exact bounds for oriented matroids of low rank and low corank, and for
all oriented matroids with up to nine elements (this part required a large
computer-based proof). The motivation for our investigations is the complexity
of the simplex method and the criss-cross method. For arbitrary oriented
matroids, we present an improvement to a quadratic bound of Finschi. Our
discussion highlights two very important conjectures related to the polynomial
Hirsch conjecture for polytope diameters.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:39:45 GMT""}]","2020-06-17"
"2006.08923","Yingcong Tan","Yingcong Tan, Daria Terekhov, Andrew Delong","Learning Linear Programs from Optimal Decisions",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a flexible gradient-based framework for learning linear programs
from optimal decisions. Linear programs are often specified by hand, using
prior knowledge of relevant costs and constraints. In some applications, linear
programs must instead be learned from observations of optimal decisions.
Learning from optimal decisions is a particularly challenging bi-level problem,
and much of the related inverse optimization literature is dedicated to special
cases. We tackle the general problem, learning all parameters jointly while
allowing flexible parametrizations of costs, constraints, and loss functions.
We also address challenges specific to learning linear programs, such as empty
feasible regions and non-unique optimal decisions. Experiments show that our
method successfully learns synthetic linear programs and minimum-cost
multi-commodity flow instances for which previous methods are not directly
applicable. We also provide a fast batch-mode PyTorch implementation of the
homogeneous interior point algorithm, which supports gradients by implicit
differentiation or backpropagation.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:43:54 GMT""}]","2020-06-17"
"2006.08924","Shuyue Jia","Yimin Hou, Shuyue Jia, Xiangmin Lun, Ziqian Hao, Yan Shi, Yang Li, Rui
  Zeng, Jinglei Lv","GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding
  Time-resolved EEG Motor Imagery Signals",,,"10.1109/TNNLS.2022.3202569",,"eess.SP cs.LG cs.NE","http://creativecommons.org/licenses/by/4.0/","  Towards developing effective and efficient brain-computer interface (BCI)
systems, precise decoding of brain activity measured by electroencephalogram
(EEG), is highly demanded. Traditional works classify EEG signals without
considering the topological relationship among electrodes. However,
neuroscience research has increasingly emphasized network patterns of brain
dynamics. Thus, the Euclidean structure of electrodes might not adequately
reflect the interaction between signals. To fill the gap, a novel deep learning
framework based on the graph convolutional neural networks (GCNs) is presented
to enhance the decoding performance of raw EEG signals during different types
of motor imagery (MI) tasks while cooperating with the functional topological
relationship of electrodes. Based on the absolute Pearson's matrix of overall
signals, the graph Laplacian of EEG electrodes is built up. The GCNs-Net
constructed by graph convolutional layers learns the generalized features. The
followed pooling layers reduce dimensionality, and the fully-connected softmax
layer derives the final prediction. The introduced approach has been shown to
converge for both personalized and group-wise predictions. It has achieved the
highest averaged accuracy, 93.06% and 88.57% (PhysioNet Dataset), 96.24% and
80.89% (High Gamma Dataset), at the subject and group level, respectively,
compared with existing studies, which suggests adaptability and robustness to
individual variability. Moreover, the performance is stably reproducible among
repetitive experiments for cross-validation. The excellent performance of our
method has shown that it is an important step towards better BCI approaches. To
conclude, the GCNs-Net filters EEG signals based on the functional topological
relationship, which manages to decode relevant features for brain motor
imagery.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:57:12 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 03:18:06 GMT""},{""version"":""v3"",""created"":""Thu, 2 Dec 2021 09:18:07 GMT""},{""version"":""v4"",""created"":""Fri, 26 Aug 2022 07:56:06 GMT""}]","2022-09-19"
"2006.08925","Amit Saha","Ramdoot Pydipaty, Johnu George, Krishna Selvaraju, Amit Saha","Improving the Performance of Deep Learning for Wireless Localization",,,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Indoor localization systems are most commonly based on Received Signal
Strength Indicator (RSSI) measurements of either WiFi or Bluetooth-Low-Energy
(BLE) beacons. In such systems, the two most common techniques are
trilateration and fingerprinting, with the latter providing higher accuracy. In
the fingerprinting technique, Deep Learning (DL) algorithms are often used to
predict the location of the receiver based on the RSSI measurements of multiple
beacons received at the receiver. In this paper, we address two practical
issues with applying Deep Learning to wireless localization -- transfer of
solution from one wireless environment to another \emph{and} small size of
labelled data set. First, we apply automatic hyperparameter optimization to a
deep neural network (DNN) system for indoor wireless localization, which makes
the system easy to port to new wireless environments. Second, we show how to
augment a typically small labelled data set using the unlabelled data set. We
observed improved performance in DL by applying the two techniques.
Additionally, all relevant code has been made freely available.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:58:50 GMT""}]","2020-06-17"
"2006.08926","Ashish Dwivedi","Ashish Dwivedi and Nitin Saxena","Computing Igusa's local zeta function of univariates in deterministic
  polynomial-time","15 pages, ANTS 2020",,,,"math.NT cs.CC cs.DS cs.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Igusa's local zeta function $Z_{f,p}(s)$ is the generating function that
counts the number of integral roots, $N_{k}(f)$, of $f(\mathbf x) \bmod p^k$,
for all $k$. It is a famous result, in analytic number theory, that $Z_{f,p}$
is a rational function in $\mathbb{Q}(p^s)$. We give an elementary proof of
this fact for a univariate polynomial $f$. Our proof is constructive as it
gives a closed-form expression for the number of roots $N_{k}(f)$.
  Our proof, when combined with the recent root-counting algorithm of (Dwivedi,
Mittal, Saxena, CCC, 2019), yields the first deterministic poly($|f|, \log p$)
time algorithm to compute $Z_{f,p}(s)$. Previously, an algorithm was known only
in the case when $f$ completely splits over $\mathbb{Q}_p$; it required the
rational roots to use the concept of generating function of a tree
(Z\'u\~niga-Galindo, J.Int.Seq., 2003).
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:59:41 GMT""}]","2020-06-17"
"2006.08927","Todd Brun","Leonard Mlodinow and Todd A. Brun","Quantum field theory from a quantum cellular automaton in one spatial
  dimension and a no-go theorem in higher dimensions","28 pages, preprint format, small changes from first version. To
  appear in Physical Review A","Phys. Rev. A 102, 042211 (2020)","10.1103/PhysRevA.102.042211",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been shown that certain quantum walks give rise to relativistic wave
equations, such as the Dirac and Weyl equations, in their long-wavelength
limits. This intriguing result raises the question of whether something similar
can happen in the multi-particle case. We construct a one-dimensional quantum
cellular automaton (QCA) model which matches the quantum walk in the single
particle case, and which approaches the quantum field theory of free fermions
in the long-wavelength limit. However, we show that this class of constructions
does not generalize to higher spatial dimensions in any straightforward way,
and that no construction with similar properties is possible in two or more
spatial dimensions. This rules out the most common approaches based on QCAs. We
suggest possible methods to overcome this barrier while retaining locality.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:59:50 GMT""},{""version"":""v2"",""created"":""Thu, 17 Sep 2020 16:58:51 GMT""}]","2020-10-21"
"2006.08928","Callum Jones","Henriette Elvang, Marios Hadjiantonis, Callum R. T. Jones, and Shruti
  Paranjape","Electromagnetic Duality and D3-Brane Scattering Amplitudes Beyond
  Leading Order","59 pages, minor revisions",,"10.1007/JHEP04(2021)173",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use on-shell methods to study the non-supersymmetric and supersymmetric
low-energy S-matrix on a probe D3-brane, including both the 1-loop
contributions of massless states as well as the effects of higher-derivative
operators. Our results include: (1) A derivation of the duality invariance of
Born-Infeld electrodynamics as the dimensional oxidation of the group of
spatial rotations transverse to a probe M2-brane; this is done using a novel
implementation of subtracted on-shell recursion. (2) The first explicit
loop-level BCJ double-copy in a non-gravitational model, namely the calculation
of the 4-point self-dual amplitude of non-supersymmetric Born-Infeld. (3) From
previous results for $n$-point self-dual 1-loop BI amplitudes and the
conjectured dimension-shifting relations in Yang-Mills, we obtain an explicit
all-multiplicity, at all orders in $\epsilon$, expression for the 1-loop
integrand of the MHV sector of $\mathcal{N}=4$ DBI. (4) For all $n>4$, the
explicitly integrated duality-violating 1-loop amplitudes (self-dual and
next-to-self-dual in pure BI as well as MHV in $\mathcal{N}=4$ DBI) are shown
to be removable at $\mathcal{O}(\epsilon^0)$ by adding finite local
counterterms; we propose that this may be true more generally at 1-loop order.
(5) We find that in non-supersymmetric Born-Infeld, not all finite local
counterterms needed to restore electromagnetic duality can be constructed using
the double-copy with higher-derivative corrections, suggesting a fundamental
tension between electromagnetic duality and color-kinematics duality at
loop-level. Finally we comment on oxidation of duality symmetries in
supergravity and the parallels it has to the M2-brane to D3-brane oxidation
demonstrated in this paper.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:00:26 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 21:39:40 GMT""},{""version"":""v3"",""created"":""Sun, 28 Feb 2021 00:04:08 GMT""}]","2021-05-05"
"2006.08929","Kai-Jia Sun","Kai-Jia Sun, Che Ming Ko, Feng Li, Jun Xu, and Lie-Wen Chen","Enhanced yield ratio of light nuclei in heavy ion collisions with a
  first-order QCD phase transition","12 pages, 6 figures",,"10.1140/epja/s10050-021-00607-4",,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using a transport model that includes a first-order chiral phase transition
between the partonic and the hadronic matter, we study the development of
density fluctuations in the matter produced in heavy ion collisions as it
undergoes the phase transition, and their time evolution in later hadronic
stage of the collisions. Using the coalescence model to describe the production
of deuterons and tritons from nucleons at the kinetic freeze out, we find that
the yield ratio $ N_\text{t}N_\text{p}/ N_\text{d}^2$, where $N_\text{p}$,
$N_\text{d}$, and $N_\text{t}$ are, respectively, the proton, deuteron, and
triton numbers, is enhanced if the evolution trajectory of the produced matter
in the QCD phase diagram passes through the spinodal region of a first-order
chiral phase transition.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:18:23 GMT""},{""version"":""v2"",""created"":""Sun, 21 Jun 2020 04:18:04 GMT""}]","2021-12-01"
"2006.08930","Saminathan Ponnusamy Ph.D","Gang Liu, Zhihong Liu and Saminathan Ponnusamy","Refined Bohr inequality for bounded analytic functions","16 pages. With the journal since Dec. 2019",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, by combining appropriate refined Bohr's inequalities with
some techniques concerning bounded analytic functions defined in the unit disk,
we generalize and improve several Bohr type inequalities for such functions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:25:23 GMT""}]","2020-06-17"
"2006.08931","Sajjad Taghiyeh","Sajjad Taghiyeh, David C Lengacher, Amir Hossein Sadeghi, Amirreza
  Sahebifakhrabad, Robert B Handfield","A Multi-Phase Approach for Product Hierarchy Forecasting in Supply Chain
  Management: Application to MonarchFx Inc","25 pages, 2 figures, 8 tables",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hierarchical time series demands exist in many industries and are often
associated with the product, time frame, or geographic aggregations.
Traditionally, these hierarchies have been forecasted using top-down,
bottom-up, or middle-out approaches. The question we aim to answer is how to
utilize child-level forecasts to improve parent-level forecasts in a
hierarchical supply chain. Improved forecasts can be used to considerably
reduce logistics costs, especially in e-commerce. We propose a novel
multi-phase hierarchical (MPH) approach. Our method involves forecasting each
series in the hierarchy independently using machine learning models, then
combining all forecasts to allow a second phase model estimation at the parent
level. Sales data from MonarchFx Inc. (a logistics solutions provider) is used
to evaluate our approach and compare it to bottom-up and top-down methods. Our
results demonstrate an 82-90% improvement in forecast accuracy using the
proposed approach. Using the proposed method, supply chain planners can derive
more accurate forecasting models to exploit the benefit of multivariate data.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:26:11 GMT""},{""version"":""v2"",""created"":""Sat, 21 Jan 2023 03:28:56 GMT""}]","2023-01-24"
"2006.08932","Shigenori Tanaka","Shigenori Tanaka","Appearance of Thermal Time",,"Found. Phys. 51 (2021) 34","10.1007/s10701-021-00445-w",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper a viewpoint that time is an informational and thermal entity is
shown. We consider a model for a simple relaxation process for which a
relationship among event, time and temperature is mathematically formulated. It
is then explicitly illustrated that temperature and time are statistically
inferred through measurement of events. The probability distribution of the
events thus provides a mutual regulation between temperature and time, which
can relevantly be expressed in terms of the Fisher information metric. The
two-dimensional differential geometry of temperature and time then leads us to
a finding of a simple equation for the scalar curvature, R = -1, in this case
of relaxation process. This basic equation, in turn, may be regarded as
characterizing the nonequilibrium dynamical process and having a solution given
by the Fisher information metric. The time can then be interpreted so as to
appear in a thermal way.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:27:43 GMT""}]","2022-10-13"
"2006.08933","Muhammad Umar Karim Khan","Muhammad Umar Karim Khan, Mishal Fatima, Chong-Min Kyung","Plug-and-Play Anomaly Detection with Expectation Maximization Filtering",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomaly detection in crowds enables early rescue response. A plug-and-play
smart camera for crowd surveillance has numerous constraints different from
typical anomaly detection: the training data cannot be used iteratively; there
are no training labels; and training and classification needs to be performed
simultaneously. We tackle all these constraints with our approach in this
paper. We propose a Core Anomaly-Detection (CAD) neural network which learns
the motion behavior of objects in the scene with an unsupervised method. On
average over standard datasets, CAD with a single epoch of training shows a
percentage increase in Area Under the Curve (AUC) of 4.66% and 4.9% compared to
the best results with convolutional autoencoders and convolutional LSTM-based
methods, respectively. With a single epoch of training, our method improves the
AUC by 8.03% compared to the convolutional LSTM-based approach. We also propose
an Expectation Maximization filter which chooses samples for training the core
anomaly-detection network. The overall framework improves the AUC compared to
future frame prediction-based approach by 24.87% when crowd anomaly detection
is performed on a video stream. We believe our work is the first step towards
using deep learning methods with autonomous plug-and-play smart cameras for
crowd anomaly detection.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:28:40 GMT""}]","2020-06-17"
"2006.08934","Martin Reiris","Mart\'in Reiris, Ignacio Bustamante","On the existence of Killing fields in smooth spacetimes with a compact
  Cauchy horizon","15 pages",,,,"gr-qc math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the surface gravity of a compact non-degenerate Cauchy horizon
in a smooth vacuum spacetime, can be normalized to a non-zero constant. This
result, combined with a recent result by Oliver Petersen and Istv\'an R\'acz,
end up proving the Isenberg-Moncrief conjecture on the existence of Killing
fields, in the smooth differentiability class. The well known corollary of
this, in accordance with the strong cosmic censorship conjecture, is that the
presence of compact Cauchy horizons is a non-generic phenomenon. Though we work
in 3+1, the result is valid line by line in any n+1-dimensions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:31:45 GMT""}]","2020-06-17"
"2006.08935","Naoya Takeishi","Naoya Takeishi and Yoshinobu Kawahara","Learning Dynamics Models with Stable Invariant Sets",,"Proceedings of the AAAI Conference on Artificial Intelligence,
  35(11), 9782-9790, 2021",,,"cs.LG math.DS stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Invariance and stability are essential notions in dynamical systems study,
and thus it is of great interest to learn a dynamics model with a stable
invariant set. However, existing methods can only handle the stability of an
equilibrium. In this paper, we propose a method to ensure that a dynamics model
has a stable invariant set of general classes such as limit cycles and line
attractors. We start with the approach by Manek and Kolter (2019), where they
use a learnable Lyapunov function to make a model stable with regard to an
equilibrium. We generalize it for general sets by introducing projection onto
them. To resolve the difficulty of specifying a to-be stable invariant set
analytically, we propose defining such a set as a primitive shape (e.g.,
sphere) in a latent space and learning the transformation between the original
and latent spaces. It enables us to compute the projection easily, and at the
same time, we can maintain the model's flexibility using various invertible
neural networks for the transformation. We present experimental results that
show the validity of the proposed method and the usefulness for long-term
prediction.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:32:38 GMT""},{""version"":""v2"",""created"":""Thu, 29 Oct 2020 20:33:53 GMT""}]","2021-06-08"
"2006.08936","Syed Rizwan","Qandeel Noor, Syedah Afsheen Zahra, Syed Rizwan","Silicon carbide-assisted co-existence of magnetic phases in
  well-optimized Ti$_3$SiC$_2$-etched MXene","16 pages",,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here, we report the first successful exfoliation of two-dimensional
Ti$_3$C$_2$T$_x$ MXene through selective etching of silicon from titanium
silicon carbide (Ti$_3$SiC$_2$) MAX. The successful etching and exfoliation of
MXene is confirmed through the shifting of all (00l) peaks to lower angles
along with the increase in c-lattice parameter as determined by X-ray
diffraction technique to detail the material structure. The c-lattice parameter
of multilayered MXene was found to be 19.34{\AA} which was increased to 26.22
{\AA} after delamination process indicating the successful intercalation of
TMA+ ions within the MXene Sheets. The scanning electron microscopy (SEM)
images show the formation of 2D layered structure. The magnetic measurement of
the etched MXene sample was measured using superconducting quantum interference
device (SQUID: Quantum Design). The magnetization vs magnetic (M-H) curves
clearly indicate the ferromagnetic-dominant hysteresis loops at low-temperature
as well as at room-temperature along with the presence of small diamagnetic
phase due to the presence of silicon carbide (SiC) present in MXene structure.
The presence of SiC phase is confirmed through XRD and Raman spectra that show
the sharp peaks and vibrational modes of SiC within 2D MXene structure. The
present work shows the co-existence of ferromagnetic and diamagnetic phases
making it suitable 2D material for future spintronics devices.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:38:21 GMT""}]","2020-06-17"
"2006.08937","Yuan Minglei","Minglei Yuan and Cunhao Cai and Tong Lu","Channel Relationship Prediction with Forget-Update Module for Few-shot
  Classification",,,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we proposed a pipeline for inferring the relationship of each
class in support set and a query sample using forget-update module. We first
propose a novel architectural module called ""channel vector sequence
construction module"", which boosts the performance of
sequence-prediction-model-based few-shot classification methods by collecting
the overall information of all support samples and a query sample. The channel
vector sequence generated by this module is organized in a way that each time
step of the sequence contains the information from the corresponding channel of
all support samples and the query sample to be inferred. Channel vector
sequence is obtained by a convolutional neural network and a fully connected
network, and the spliced channel vector sequence is spliced of the
corresponding channel vectors of support samples and a query sample in the
original channel order. Also, we propose a forget-update module consisting of
stacked forget-update blocks. The forget block modify the original information
with the learned weights and the update block establishes a dense connection
for the model. The proposed pipeline, which consists of channel vector sequence
construction module and forget-update module, can infer the relationship
between the query sample and support samples in few-shot classification
scenario. Experimental results show that the pipeline can achieve
state-of-the-art results on miniImagenet, CUB dataset, and cross-domain
scenario.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:48:08 GMT""}]","2020-06-17"
"2006.08938","Qingtao Zhao","Qingtao Zhao, Jennie Si, Jian Sun","Online Reinforcement Learning Control by Direct Heuristic Dynamic
  Programming: from Time-Driven to Event-Driven",,,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper time-driven learning refers to the machine learning method that
updates parameters in a prediction model continuously as new data arrives.
Among existing approximate dynamic programming (ADP) and reinforcement learning
(RL) algorithms, the direct heuristic dynamic programming (dHDP) has been shown
an effective tool as demonstrated in solving several complex learning control
problems. It continuously updates the control policy and the critic as system
states continuously evolve. It is therefore desirable to prevent the
time-driven dHDP from updating due to insignificant system event such as noise.
Toward this goal, we propose a new event-driven dHDP. By constructing a
Lyapunov function candidate, we prove the uniformly ultimately boundedness
(UUB) of the system states and the weights in the critic and the control policy
networks. Consequently we show the approximate control and cost-to-go function
approaching Bellman optimality within a finite bound. We also illustrate how
the event-driven dHDP algorithm works in comparison to the original time-driven
dHDP.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:51:25 GMT""}]","2020-06-17"
"2006.08939","Zongyan Han","Zongyan Han, Zhenyong Fu and Jian Yang","Learning the Redundancy-free Features for Generalized Zero-Shot Object
  Recognition","Some researchers and we have found KNN results in 1st version are
  incorrect, due to a careless mistake in the code. Concretely, the parameters
  for accuracy function of KNN were organized in the wrong order by mistake.
  The softmax results are correct. We have removed all KNN results and remove
  the SOTA claims. According to the Program Chairs' suggestion, we have made
  errata request to CVF and IEEE",,,,"cs.CV cs.LG eess.IV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Zero-shot object recognition or zero-shot learning aims to transfer the
object recognition ability among the semantically related categories, such as
fine-grained animal or bird species. However, the images of different
fine-grained objects tend to merely exhibit subtle differences in appearance,
which will severely deteriorate zero-shot object recognition. To reduce the
superfluous information in the fine-grained objects, in this paper, we propose
to learn the redundancy-free features for generalized zero-shot learning. We
achieve our motivation by projecting the original visual features into a new
(redundancy-free) feature space and then restricting the statistical dependence
between these two feature spaces. Furthermore, we require the projected
features to keep and even strengthen the category relationship in the
redundancy-free feature space. In this way, we can remove the redundant
information from the visual features without losing the discriminative
information. We extensively evaluate the performance on four benchmark
datasets. The results show that our redundancy-free feature based generalized
zero-shot learning (RFF-GZSL) approach can achieve competitive results compared
with the state-of-the-arts.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:53:25 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 06:09:22 GMT""}]","2021-05-25"
"2006.08940","Matthew Kunz","M. W. Kunz, J. Squire, A. A. Schekochihin, E. Quataert","Self-sustaining sound in collisionless, high-beta plasma","25 pages, 10 figures, Journal of Plasma Physics, in press",,"10.1017/S0022377820001312",,"astro-ph.HE physics.plasm-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using analytical theory and hybrid-kinetic numerical simulations, we
demonstrate that, in a collisionless plasma, long-wavelength ion-acoustic waves
(IAWs) with amplitudes $\delta n/n_0 \gtrsim 2/\beta$ (where $\beta\gg{1}$ is
the ratio of thermal to magnetic pressure) generate sufficient pressure
anisotropy to destabilize the plasma to firehose and mirror instabilities.
These kinetic instabilities grow rapidly to reduce the pressure anisotropy by
pitch-angle scattering and trapping particles, respectively, thereby impeding
the maintenance of Landau resonances that enable such waves' otherwise potent
collisionless damping. The result is wave dynamics that evince a weakly
collisional plasma: the ion distribution function is near-Maxwellian, the
field-parallel flow of heat resembles its Braginskii form (except in regions
where large-amplitude magnetic mirrors strongly suppress particle transport),
and the relations between various thermodynamic quantities are more
`fluid-like' than kinetic. A nonlinear fluctuation-dissipation relation for
self-sustaining IAWs is obtained by solving a plasma-kinetic Langevin problem,
which demonstrates suppressed damping, enhanced fluctuation levels, and weakly
collisional thermodynamics when IAWs with $\delta n/n_0 \gtrsim 2/\beta$ are
stochastically driven. We investigate how our results depend upon the scale
separation between the wavelength of the IAW and the Larmor radius of the ions,
and discuss briefly their implications for our understanding of turbulence and
transport in the solar wind and the intracluster medium of galaxy clusters.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:10:44 GMT""},{""version"":""v2"",""created"":""Thu, 17 Sep 2020 16:16:13 GMT""}]","2020-11-25"
"2006.08941","Masood Masjoody","Masood Masjoody","Confining the Robber on Cographs","16 pages, 9 figures",,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the notions of {\em trapping} and {\em confining} the robber
on a graph are introduced. We present some structural necessary conditions for
graphs $G$ not containing the path on $k$ vertices (referred to as $P_k$-free
graphs) for some $k\ge 4$, so that $k-3$ cops do not have a strategy to capture
or confine the robber on $G$. Utilizing such conditions, we show that for
planar cographs and planar $P_5$-free graphs the confining cop number is at
most one and two, respectively. It is also shown that the number of vertices of
a connected cograph on which one cop does not have a strategy to confine the
robber has a tight lower-bound of eight. We also explore the effects of twin
operations -- which are well known to provide a characterization of cographs --
on the number of cops required to capture or confine the robber on cographs. We
conclude by posing two conjectures concerning the confining cop number of
$P_5$-free graphs and the smallest planar graph of confining cop number of
three.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:15:34 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 23:36:35 GMT""},{""version"":""v3"",""created"":""Sun, 13 Sep 2020 23:45:41 GMT""}]","2020-09-15"
"2006.08942","Mishal Fatima","Mishal Fatima, Muhammad Umar Karim Khan, and Chong Min Kyung","Global Feature Aggregation for Accident Anticipation",,,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anticipation of accidents ahead of time in autonomous and non-autonomous
vehicles aids in accident avoidance. In order to recognize abnormal events such
as traffic accidents in a video sequence, it is important that the network
takes into account interactions of objects in a given frame. We propose a novel
Feature Aggregation (FA) block that refines each object's features by computing
a weighted sum of the features of all objects in a frame. We use FA block along
with Long Short Term Memory (LSTM) network to anticipate accidents in the video
sequences. We report mean Average Precision (mAP) and Average Time-to-Accident
(ATTA) on Street Accident (SA) dataset. Our proposed method achieves the
highest score for risk anticipation by predicting accidents 0.32 sec and 0.75
sec earlier compared to the best results with Adaptive Loss and dynamic
parameter prediction based methods respectively.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:17:15 GMT""}]","2020-06-17"
"2006.08943","Oren Yakir","Oren Yakir and Ofer Zeitouni","The minimum modulus of Gaussian trigonometric polynomials","18 pages, 1 figure. Added a discussion on the method and a possible
  extension. To appear in the Israel Journal of Mathematics",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the minimum of the modulus of a random trigonometric polynomial
with Gaussian coefficients, properly normalized, has limiting exponential
distribution.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:27:58 GMT""},{""version"":""v2"",""created"":""Thu, 24 Sep 2020 06:11:39 GMT""}]","2020-09-25"
"2006.08944","Chi-Keung Ng","Chi-Wai Leung, Chi-Keung Ng, Ngai-Ching Wong","On a variant of Tingley's problem for some function spaces",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $(\Omega, \mathfrak{A}, \mu)$ and $(\Gamma, \mathfrak{B}, \nu)$ be two
arbitrary measure spaces, and $p\in [1,\infty]$. Set $$L^p(\mu)_+^\mathrm{sp}:=
\{f\in L^p(\mu): \|f\|_p =1; f\geq 0\ \mu\text{-a.e.} \}$$ i.e., the positive
part of the unit sphere of $L^p(\mu)$. We show that every metric preserving
bijection $\Phi: L^p(\mu)_+^\mathrm{sp} \to L^p(\nu)_+^\mathrm{sp}$ can be
extended (necessarily uniquely) to an isometric order isomorphism from
$L^p(\mu)$ onto $L^p(\nu)$. A Lamperti form, i.e., a weighted composition like
form, of $\Phi$ is provided, when $(\Gamma, \mathfrak{B}, \nu)$ is localizable
(in particular, when it is $\sigma$-finite).
  On the other hand, we show that for compact Hausdorff spaces $X$ and $Y$, if
$\Phi$ is a metric preserving bijection from the positive part of the unit
sphere of $C(X)$ to that of $C(Y)$, then there is a homeomorphism $\tau:Y\to X$
satisfying $\Phi(f)(y) = f(\tau(y))$ ($f\in C(X)_+^\mathrm{sp}; y\in Y$).
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:33:17 GMT""}]","2020-06-17"
"2006.08945","Evan Patterson","Evan Patterson","The algebra and machine representation of statistical models","Revised and extended version of author's PhD thesis",,,,"math.ST cs.LO math.CT stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the twin movements of open science and open source bring an ever greater
share of the scientific process into the digital realm, new opportunities arise
for the meta-scientific study of science itself, including of data science and
statistics. Future science will likely see machines play an active role in
processing, organizing, and perhaps even creating scientific knowledge. To make
this possible, large engineering efforts must be undertaken to transform
scientific artifacts into useful computational resources, and conceptual
advances must be made in the organization of scientific theories, models,
experiments, and data.
  This dissertation takes steps toward digitizing and systematizing two major
artifacts of data science, statistical models and data analyses. Using tools
from algebra, particularly categorical logic, a precise analogy is drawn
between models in statistics and logic, enabling statistical models to be seen
as models of theories, in the logical sense. Statistical theories, being
algebraic structures, are amenable to machine representation and are equipped
with morphisms that formalize the relations between different statistical
methods. Turning from mathematics to engineering, a software system for
creating machine representations of data analyses, in the form of Python or R
programs, is designed and implemented. The representations aim to capture the
semantics of data analyses, independent of the programming language and
libraries in which they are implemented.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:33:50 GMT""}]","2020-06-17"
"2006.08946","Vugar Ismailov","Rashid Aliev, Aysel Asgarova, Vugar Ismailov","The double difference property for the class of locally H\""{o}lder
  continuous functions","8 pages",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we show that the pair of classes of locally H\""{o}lder
continuous functions (considered on $\mathbb{R}$ and $\mathbb{R}^{2}$,
respectively) has the double difference property.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:37:16 GMT""}]","2020-06-17"
"2006.08947","Mohammadamin Tavakoli","Mohammadamin Tavakoli, Forest Agostinelli, Pierre Baldi","SPLASH: Learnable Activation Functions for Improving Accuracy and
  Adversarial Robustness",,,,,"cs.LG cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce SPLASH units, a class of learnable activation functions shown to
simultaneously improve the accuracy of deep neural networks while also
improving their robustness to adversarial attacks. SPLASH units have both a
simple parameterization and maintain the ability to approximate a wide range of
non-linear functions. SPLASH units are: 1) continuous; 2) grounded (f(0) = 0);
3) use symmetric hinges; and 4) the locations of the hinges are derived
directly from the data (i.e. no learning required). Compared to nine other
learned and fixed activation functions, including ReLU and its variants, SPLASH
units show superior performance across three datasets (MNIST, CIFAR-10, and
CIFAR-100) and four architectures (LeNet5, All-CNN, ResNet-20, and
Network-in-Network). Furthermore, we show that SPLASH units significantly
increase the robustness of deep neural networks to adversarial attacks. Our
experiments on both black-box and open-box adversarial attacks show that
commonly-used architectures, namely LeNet5, All-CNN, ResNet-20, and
Network-in-Network, can be up to 31% more robust to adversarial attacks by
simply using SPLASH units instead of ReLUs.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:45:55 GMT""}]","2020-06-17"
"2006.08948","Francois Vernay","J.-L. D\'ejardin, F. Vernay, H. Kachkachi","Specific absorption rate of magnetic nanoparticles: nonlinear AC
  susceptibility","6 pages, 5 figures","J. Appl. Phys., 128, 143901 (2020)","10.1063/5.0018685",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of magnetic hyperthermia, several physical parameters are used
to optimize the heat generation and these include the nanoparticles
concentration and the magnitude and frequency of the external AC magnetic
field. Here we extend our previous work by computing nonlinear contributions to
the specific absorption rate, while taking into account (weak) inter-particle
dipolar interactions and DC magnetic field. In the previous work, the latter
were shown to enhance the SAR in some specific geometries and setup. We find
that the cubic correction to the AC susceptibility does not modify the
qualitative behavior observed earlier but does bring a non negligible
quantitative change of specific absorption rate, especially at relatively high
AC field intensities. Incidentally, within our approach based on the AC
susceptibility, we revisit the physiological empirical criterion on the upper
limit of the product of the AC magnetic field intensity $H_{0}$ and its
frequency $f$, and provide a physicist's rationale for it.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:49:36 GMT""},{""version"":""v2"",""created"":""Tue, 13 Oct 2020 06:34:31 GMT""}]","2020-10-14"
"2006.08949","Mahdi Hajiabadi","Mahdi Hajiabadi, Jasbir Singh, Venkatesh Srinivasan, Alex Thomo","Utility-Based Graph Summarization: New and Improved",,,,,"cs.DS cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A fundamental challenge in graph mining is the ever-increasing size of
datasets. Graph summarization aims to find a compact representation resulting
in faster algorithms and reduced storage needs. The flip side of graph
summarization is the loss of utility which diminishes its usability. The key
questions we address in this paper are: (1)How to summarize a graph without any
loss of utility? (2)How to summarize a graph with some loss of utility but
above a user-specified threshold? (3)How to query graph summaries without graph
reconstruction?} We also aim at making graph summarization available for the
masses by efficiently handling web-scale graphs using only a consumer-grade
machine. Previous works suffer from conceptual limitations and lack of
scalability. In this work, we make three key contributions. First, we present a
utility-driven graph summarization method, based on a clique and independent
set decomposition, that produces significant compression with zero loss of
utility. The compression provided is significantly better than state-of-the-art
in lossless graph summarization, while the runtime is two orders of magnitude
lower. Second, we present a highly scalable algorithm for the lossy case, which
foregoes the expensive iterative process that hampers previous work. Our
algorithm achieves this by combining a memory reduction technique and a novel
binary-search approach. In contrast to the competition, we are able to handle
web-scale graphs in a single machine without a performance impediment as the
utility threshold (and size of summary) decreases. Third, we show that our
graph summaries can be used as-is to answer several important classes of
queries, such as triangle enumeration, Pagerank, and shortest paths. This is in
contrast to other works that incrementally reconstruct the original graph for
answering queries, thus incurring additional time costs.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:50:36 GMT""}]","2020-06-17"
"2006.08950","Honglin Yuan","Honglin Yuan, Tengyu Ma","Federated Accelerated Stochastic Gradient Descent","Accepted to NeurIPS 2020. Best paper in International Workshop on
  Federated Learning for User Privacy and Data Confidentiality in Conjunction
  with ICML 2020 (FL-ICML'20). Code repository see
  https://github.com/hongliny/FedAc-NeurIPS20",,,,"cs.LG cs.DC math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose Federated Accelerated Stochastic Gradient Descent (FedAc), a
principled acceleration of Federated Averaging (FedAvg, also known as Local
SGD) for distributed optimization. FedAc is the first provable acceleration of
FedAvg that improves convergence speed and communication efficiency on various
types of convex functions. For example, for strongly convex and smooth
functions, when using $M$ workers, the previous state-of-the-art FedAvg
analysis can achieve a linear speedup in $M$ if given $M$ rounds of
synchronization, whereas FedAc only requires $M^{\frac{1}{3}}$ rounds.
Moreover, we prove stronger guarantees for FedAc when the objectives are
third-order smooth. Our technique is based on a potential-based perturbed
iterate analysis, a novel stability analysis of generalized accelerated SGD,
and a strategic tradeoff between acceleration and stability.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:58:07 GMT""},{""version"":""v2"",""created"":""Fri, 19 Jun 2020 17:55:44 GMT""},{""version"":""v3"",""created"":""Tue, 20 Oct 2020 04:00:01 GMT""},{""version"":""v4"",""created"":""Sat, 5 Jun 2021 06:22:54 GMT""}]","2021-06-08"
"2006.08951","Fengmiao Bian","Fengmiao Bian and Xiaoqun Zhang","A three-operator splitting algorithm for nonconvex sparsity
  regularization","26 pages. Submitted",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sparsity regularization has been largely applied in many fields, such as
signal and image processing and machine learning. In this paper, we mainly
consider nonconvex minimization problems involving three terms, for the
applications such as: sparse signal recovery and low rank matrix recovery. We
employ a three-operator splitting proposed by Davis and Yin (called DYS) to
solve the resulting possibly nonconvex problems and develop the convergence
theory for this three-operator splitting algorithm in the nonconvex case. We
show that if the step size is chosen less than a computable threshold, then the
whole sequence converges to a stationary point. By defining a new decreasing
energy function associated with the DYS method, we establish the global
convergence of the whole sequence and a local convergence rate under an
additional assumption that this energy function is a Kurdyka-$\L$ojasiewicz
function. We also provide sufficient conditions for the boundedness of the
generated sequence. Finally, some numerical experiments are conducted to
compare the DYS algorithm with some classical efficient algorithms for sparse
signal recovery and low rank matrix completion. The numerical results indicate
that DYS method outperforms the exsiting methods for these specific
applications.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:59:54 GMT""}]","2020-06-17"
"2006.08952","Bennett Kleinberg","Bennett Kleinberg","Manipulating emotions for ground truth emotion analysis","preprint",,,,"cs.CL cs.SI","http://creativecommons.org/licenses/by/4.0/","  Text data are being used as a lens through which human cognition can be
studied at a large scale. Methods like emotion analysis are now in the standard
toolkit of computational social scientists but typically rely on third-person
annotation with unknown validity. As an alternative, this paper introduces
online emotion induction techniques from experimental behavioural research as a
method for text-based emotion analysis. Text data were collected from
participants who were randomly allocated to a happy, neutral or sad condition.
The findings support the mood induction procedure. We then examined how well
lexicon approaches can retrieve the induced emotion. All approaches resulted in
statistical differences between the true emotion conditions. Overall, only up
to one-third of the variance in emotion was captured by text-based
measurements. Pretrained classifiers performed poorly on detecting true
emotions. The paper concludes with limitations and suggestions for future
research.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:03:28 GMT""}]","2020-06-17"
"2006.08953","Anton Freund","Anton Freund","What is effective transfinite recursion in reverse mathematics?",,"Mathematical Logic Quarterly 66(4) 2020, pp. 479-483","10.1002/malq.202000042",,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of reverse mathematics, effective transfinite recursion refers
to a principle that allows us to construct sequences of sets by recursion along
arbitrary well orders, provided that each set is $\Delta^0_1$-definable
relative to the previous stages of the recursion. It is known that this
principle is provable in $\mathbf{ACA}_0$. In the present note, we argue that a
common formulation of effective transfinite recursion is too restrictive. We
then propose a more liberal formulation, which appears very natural and is
still provable in $\mathbf{ACA}_0$.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:12:47 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 11:38:54 GMT""}]","2021-07-01"
"2006.08954","Amitesh Roy","Amitesh Roy and R I Sujith","Fractal dimension of premixed flames in multifractal turbulence","7 pages, Preprint version submitted to Combustion and Flame",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In turbulent premixed flames, the fractal dimension of flame iso-surface is
argued to be $\mathbb{D}=7/3$ for Damk\""ohler's large-scale limit $(Da>>1)$ and
$\mathbb{D}=8/3$ for Damk\""ohler's small-scale limit $(Da\sim\mathcal{O}(1))$
based on heuristic scaling arguments. However, such scaling arguments do not
consider the effect of the multifractal nature of turbulent kinetic energy
dissipation on the flame surface. In this paper, we account for the effects of
multifractal dissipation on the fractal dimension of low $Da$ turbulent
premixed flames. We derive two corrections to the upper-limit of fractal
dimension -- $\mathbb{D}=8/3+3/4(1-D_{1/4})$ and
$\mathbb{D}=8/3+2/3(3-D_{1/3})$ -- which correspond to the change in the scalar
flux and the total area of flame interface due to fluctuations in the inner
cut-off scale arising from the intermittent nature of turbulent dissipation,
respectively. We further show that the second correction leads to an explicit
dependence of the fractal dimension $(\mathbb{D})$ on the scaling exponent
$(\xi)$ of the velocity structure function through the relation:
$\mathbb{D}=11/3+\xi$. Thus, we explicitly quantify the effect of the
multifractal nature of turbulence upon low $Da$ premixed combustion.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:14:56 GMT""},{""version"":""v2"",""created"":""Thu, 3 Sep 2020 14:41:03 GMT""}]","2020-09-04"
"2006.08955","J\""org Main","Jan Ertl, Patric Rommel, Michel Mom, J\""org Main, Manfred Bayer","Classical and semiclassical description of Rydberg excitons in cuprous
  oxide","5 pages, 3 figures","Phys. Rev. B 101, 241201(R) (2020)","10.1103/PhysRevB.101.241201",,"cond-mat.mes-hall cond-mat.mtrl-sci nlin.CD quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Experimental and theoretical investigations of excitons in cuprous oxide have
revealed a significant fine-structure splitting of the excitonic Rydberg states
caused by a strong impact of the valence band structure. We provide a
semiclassical interpretation of that splitting by investigating the classical
dynamics of the excitonic electron-hole pair beyond the hydrogen-like model.
Considering the slow motion of Rydberg excitons in coordinate space compared to
the fast dynamics of quasispin and hole spin we use an adiabatic approach and
energy surfaces in momentum space for the computation of the exciton dynamics.
We observe quasi-periodic motion on near-integrable tori. Semiclassical torus
quantization yields the energy regions of the fine-structure splitting of
$n$-manifolds in agreement with quantum mechanical computations.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:15:29 GMT""}]","2020-06-23"
"2006.08956","Valerii Iakovlev","Valerii Iakovlev, Markus Heinonen, Harri L\""ahdesm\""aki","Learning continuous-time PDEs from sparse data with graph neural
  networks",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The behavior of many dynamical systems follow complex, yet still unknown
partial differential equations (PDEs). While several machine learning methods
have been proposed to learn PDEs directly from data, previous methods are
limited to discrete-time approximations or make the limiting assumption of the
observations arriving at regular grids. We propose a general continuous-time
differential model for dynamical systems whose governing equations are
parameterized by message passing graph neural networks. The model admits
arbitrary space and time discretizations, which removes constraints on the
locations of observation points and time intervals between the observations.
The model is trained with continuous-time adjoint method enabling efficient
neural PDE inference. We demonstrate the model's ability to work with
unstructured grids, arbitrary time steps, and noisy observations. We compare
our method with existing approaches on several well-known physical systems that
involve first and higher-order PDEs with state-of-the-art predictive
performance.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:15:40 GMT""},{""version"":""v2"",""created"":""Fri, 2 Oct 2020 13:11:26 GMT""},{""version"":""v3"",""created"":""Fri, 29 Jan 2021 16:33:11 GMT""}]","2021-02-01"
"2006.08957","Yasuyuki Hatsuda","Yasuyuki Hatsuda","Quasinormal modes of Kerr-de Sitter black holes via the Heun function","12 pages; A sample Mathematica notebook available, v2: References
  added",,"10.1088/1361-6382/abc82e","RUP-20-19","gr-qc hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This note addresses quasinormal mode frequencies of four-dimensional
asymptotically de Sitter rotating black holes. The main motivation is that
Mathematica 12.1 has implemented a new family of special functions: Heun
functions. Using the fact that Teukolsky's equations for Kerr-de Sitter black
holes are mapped to Heun's equations, we are able to compute their quasinormal
mode frequencies by the Heun function. In this approach, Mathematica normally
evaluates these frequencies to arbitrary numerical precision in a few seconds.
We further discuss an application to asymptotically flat rotating black holes.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:17:30 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jul 2020 05:50:22 GMT""}]","2021-02-03"
"2006.08958","Eric Hutter","Eric Hutter and Mathias Pacher and Uwe Brinkschulte","On the Hardness of Problems Involving Negator Relationships in an
  Artificial Hormone System",,,,,"cs.AI cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Artificial Hormone System (AHS) is a self-organizing middleware to
allocate tasks in a distributed system. We extended it by so-called negator
hormones to enable conditional task structures. However, this extension
increases the computational complexity of seemingly simple decision problems in
the system: In [1] and [2], we defined the problems Negator-Path and
Negator-Sat and proved their NP-completeness. In this supplementary report to
these papers, we show examples of Negator-Path and Negator-Sat, introduce the
novel problem Negator-Stability and explain why all of these problems involving
negators are hard to solve algorithmically.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:17:40 GMT""}]","2020-06-17"
"2006.08959","Michiya Mori","Michiya Mori","Lattice isomorphisms between projection lattices of von Neumann algebras","21 pages","Forum of Mathematics, Sigma 8 (2020) e49","10.1017/fms.2020.53",,"math.OA math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalizing von Neumann's result on type II$_1$ von Neumann algebras, we
characterize lattice isomorphisms between projection lattices of arbitrary von
Neumann algebras by means of ring isomorphisms between the algebras of locally
measurable operators. Moreover, we give a complete description of ring
isomorphisms of locally measurable operator algebras when the von Neumann
algebras are without type II direct summands.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:18:26 GMT""}]","2020-11-18"
"2006.08960","Naoki Kitazawa","Naoki Kitazawa","Special generic maps and fold maps and information on triple Massey
  products of higher dimensional differentiable manifolds","14 pages, incorrect stuffs are due to my carelessness, this is
  submitted to another (refereed) journal",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Closed (and simply-connected) manifolds whose dimensions are larger than 4
are central geometric objects in classical algebraic topology and differential
topology. They have been classified via algebraic and abstract objects. On the
other hand, It is difficult to understand them in geometric and constructive
ways.
  In the present paper, we show such studies via explicit fold maps, higher
dimensional versions of Morse functions. The author captured information of the
topologies and the differentiable structures of closed (and simply-connected)
manifolds which are not so complicated with respect to homotopy previously and
cohomology rings of more general closed (and simply-connected) manifolds via
construction of these maps. In the present paper, as a more precise work, we
capture so-called (triple) Massey products in this way.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:31:19 GMT""},{""version"":""v2"",""created"":""Sun, 21 Jun 2020 17:19:50 GMT""},{""version"":""v3"",""created"":""Tue, 23 Jun 2020 04:22:06 GMT""},{""version"":""v4"",""created"":""Sat, 11 Jul 2020 07:09:11 GMT""},{""version"":""v5"",""created"":""Tue, 14 Jul 2020 07:45:24 GMT""},{""version"":""v6"",""created"":""Thu, 16 Jul 2020 11:11:05 GMT""},{""version"":""v7"",""created"":""Wed, 7 Oct 2020 16:08:11 GMT""}]","2020-10-08"
"2006.08961","Daniel Roggenkamp","Fabian Klos and Daniel Roggenkamp","Complementary Projection Defects and Decompositions","v2: 16 pages, minor changes",,"10.1007/JHEP03(2021)195",,"hep-th math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As put forward in [arXiv:1907.12339] topological quantum field theories can
be projected using so-called projection defects. The projected theory and its
correlation functions can be completely realized within the unprojected one. An
interesting example is the case of topological quantum field theories
associated to IR fixed points of renormalization group flows, which by this
method can be realized inside the theories associated to the UV. In this note
we show that projection defects in triangulated defect categories (such as
defects in 2d topologically twisted N=(2,2) theories) always come with
complementary projection defects, and that the unprojected theory decomposes
into the theories associated to the two projection defects. We demonstrate this
in the context of Landau-Ginzburg orbifold theories.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:33:48 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 07:54:30 GMT""}]","2021-04-07"
"2006.08962","Xia Hu","Xia Hu, Weiqing Liu, Jiang Bian, Jian Pei","Measuring Model Complexity of Neural Networks with Curve Activation
  Functions","KDD 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is fundamental to measure model complexity of deep neural networks. The
existing literature on model complexity mainly focuses on neural networks with
piecewise linear activation functions. Model complexity of neural networks with
general curve activation functions remains an open problem. To tackle the
challenge, in this paper, we first propose the linear approximation neural
network (LANN for short), a piecewise linear framework to approximate a given
deep model with curve activation function. LANN constructs individual piecewise
linear approximation for the activation function of each neuron, and minimizes
the number of linear regions to satisfy a required approximation degree. Then,
we analyze the upper bound of the number of linear regions formed by LANNs, and
derive the complexity measure based on the upper bound. To examine the
usefulness of the complexity measure, we experimentally explore the training
process of neural networks and detect overfitting. Our results demonstrate that
the occurrence of overfitting is positively correlated with the increase of
model complexity during training. We find that the $L^1$ and $L^2$
regularizations suppress the increase of model complexity. Finally, we propose
two approaches to prevent overfitting by directly constraining model
complexity, namely neuron pruning and customized $L^1$ regularization.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:38:06 GMT""}]","2020-06-17"
"2006.08963","Aykut Argun","Aykut Argun, Tobias Thalheim, Stefano Bo, Frank Cichos, Giovanni Volpe","Enhanced force-field calibration via machine learning","11 Pages, 6 figures",,,,"physics.comp-ph physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The influence of microscopic force fields on the motion of Brownian particles
plays a fundamental role in a broad range of fields, including soft matter,
biophysics, and active matter. Often, the experimental calibration of these
force fields relies on the analysis of the trajectories of these Brownian
particles. However, such an analysis is not always straightforward, especially
if the underlying force fields are non-conservative or time-varying, driving
the system out of thermodynamic equilibrium. Here, we introduce a toolbox to
calibrate microscopic force fields by analyzing the trajectories of a Brownian
particle using machine learning, namely recurrent neural networks. We
demonstrate that this machine-learning approach outperforms standard methods
when characterizing the force fields generated by harmonic potentials if the
available data are limited. More importantly, it provides a tool to calibrate
force fields in situations for which there are no standard methods, such as
non-conservative and time-varying force fields. In order to make this method
readily available for other users, we provide a Python software package named
DeepCalib, which can be easily personalized and optimized for specific
applications.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:38:49 GMT""}]","2020-06-17"
"2006.08964","Ewen Bellec","E. Bellec, V.L.R. Jacques, J. Caillaux and D. Le Bolloc'h","The essential role of surface pinning in the dynamics of charge density
  waves submitted to external dc fields","7 pages of main text, 7 pages of appendices 15 figures","Eur. Phys. J. B (2020) 93: 165",,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Charge Density Wave (CDW) submitted to an electric field displays a strong
shear deformation because of pinning at the lateral surfaces of the sample.
This CDW transverse pinning was recently observed but has received little
attention from a theoretical point of view until now despite important
consequences on electrical conductivity properties. Here, we provide a
description of this phenomenon by considering a CDW submitted to an external dc
electric field and constrained by boundary conditions including both
longitudinal pinning due to electrical contacts and transverse surface pinning.
A simple formula for the CDW phase is obtained in 3D by using the Green
function and image charges method. In addition, an analytical expression of the
threshold field dependence on both length and sample cross section is obtained
by considering the phase slip process. We show that the experimental data are
well reproduced with this model and that bulk pinning can be neglected. This
study shows that the dynamical properties of CDW systems could be mainly driven
by boundary effects, despite the comparatively huge sample volumes.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:42:16 GMT""}]","2021-04-20"
"2006.08965","Shunichi Nomura","Atsumori Takahashi and Shunichi Nomura","Efficient Path Algorithms for Clustered Lasso and OSCAR",,,,,"stat.ML cs.LG stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In high dimensional regression, feature clustering by their effects on
outcomes is often as important as feature selection. For that purpose,
clustered Lasso and octagonal shrinkage and clustering algorithm for regression
(OSCAR) are used to make feature groups automatically by pairwise $L_1$ norm
and pairwise $L_\infty$ norm, respectively. This paper proposes efficient path
algorithms for clustered Lasso and OSCAR to construct solution paths with
respect to their regularization parameters. Despite too many terms in
exhaustive pairwise regularization, their computational costs are reduced by
using symmetry of those terms. Simple equivalent conditions to check
subgradient equations in each feature group are derived by some graph theories.
The proposed algorithms are shown to be more efficient than existing algorithms
in numerical experiments.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:43:57 GMT""}]","2020-06-17"
"2006.08966","Myoungsoo Jung","Jie Zhang, Miryeong Kwon, Sanghyun Han, Nam Sung Kim, Mahmut Kandemir,
  Myoungsoo Jung","FastDrain: Removing Page Victimization Overheads in NVMe Storage Stack",,,,,"cs.OS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Host-side page victimizations can easily overflow the SSD internal buffer,
which interferes I/O services of diverse user applications thereby degrading
user-level experiences. To address this, we propose FastDrain, a co-design of
OS kernel and flash firmware to avoid the buffer overflow, caused by page
victimizations. Specifically, FastDrain can detect a triggering point where a
near-future page victimization introduces an overflow of the SSD internal
buffer. Our new flash firmware then speculatively scrubs the buffer space to
accommodate the requests caused by the page victimization. In parallel, our new
OS kernel design controls the traffic of page victimizations by considering the
target device buffer status, which can further reduce the risk of buffer
overflow. To secure more buffer spaces, we also design a latency-aware FTL,
which dumps the dirty data only to the fast flash pages. Our evaluation results
reveal that FastDrain reduces the 99th response time of user applications by
84%, compared to a conventional system.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:45:22 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 13:11:11 GMT""}]","2020-06-23"
"2006.08967","Marvin Chanc\'an","Marvin Chanc\'an and Michael Milford","Robot Perception enables Complex Navigation Behavior via Self-Supervised
  Learning","Submitted to RSS 2020 Workshop on Self-Supervised Robot Learning",,,,"cs.RO cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Learning visuomotor control policies in robotic systems is a fundamental
problem when aiming for long-term behavioral autonomy. Recent
supervised-learning-based vision and motion perception systems, however, are
often separately built with limited capabilities, while being restricted to few
behavioral skills such as passive visual odometry (VO) or mobile robot visual
localization. Here we propose an approach to unify those successful robot
perception systems for active target-driven navigation tasks via reinforcement
learning (RL). Our method temporally incorporates compact motion and visual
perception data - directly obtained using self-supervision from a single image
sequence - to enable complex goal-oriented navigation skills. We demonstrate
our approach on two real-world driving dataset, KITTI and Oxford RobotCar,
using the new interactive CityLearn framework. The results show that our method
can accurately generalize to extreme environmental changes such as day to night
cycles with up to an 80% success rate, compared to 30% for a vision-only
navigation systems.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:45:47 GMT""}]","2020-06-17"
"2006.08968","Christopher Frei","Christopher Frei and Rodolphe Richard","Constructing abelian extensions with prescribed norms","20 pages; minor revision",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a number field $K$, a finite abelian group $G$ and finitely many
elements $\alpha_1,\ldots,\alpha_t\in K$, we construct abelian extensions $L/K$
with Galois group $G$ that realise all of the elements
$\alpha_1,\ldots,\alpha_t$ as norms of elements in $L$. In particular, this
shows existence of such extensions for any given parameters.
  Our approach relies on class field theory and a recent formulation of Tate's
characterisation of the Hasse norm principle, a local-global principle for
norms. The constructions are sufficiently explicit to be implemented on a
computer, and we illustrate them with concrete examples.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:45:52 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 12:05:32 GMT""}]","2021-04-13"
"2006.08969","Martin Strobel","Neel Patel, Martin Strobel, Yair Zick","High Dimensional Model Explanations: an Axiomatic Approach","31 pages, 10 Figures, 2 Tables",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Complex black-box machine learning models are regularly used in critical
decision-making domains. This has given rise to several calls for algorithmic
explainability. Many explanation algorithms proposed in literature assign
importance to each feature individually. However, such explanations fail to
capture the joint effects of sets of features. Indeed, few works so far
formally analyze high-dimensional model explanations. In this paper, we propose
a novel high dimension model explanation method that captures the joint effect
of feature subsets.
  We propose a new axiomatization for a generalization of the Banzhaf index;
our method can also be thought of as an approximation of a black-box model by a
higher-order polynomial. In other words, this work justifies the use of the
generalized Banzhaf index as a model explanation by showing that it uniquely
satisfies a set of natural desiderata and that it is the optimal local
approximation of a black-box model.
  Our empirical evaluation of our measure highlights how it manages to capture
desirable behavior, whereas other measures that do not satisfy our axioms
behave in an unpredictable manner.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:48:52 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 07:16:52 GMT""}]","2021-03-30"
"2006.08970","Yuta Michimura Dr.","Yuta Michimura, Kentaro Komori, Yutaro Enomoto, Koji Nagano, Atsushi
  Nishizawa, Eiichi Hirose, Matteo Leonardi, Eleonora Capocasa, Naoki Aritomi,
  Yuhang Zhao, Raffaele Flaminio, Takafumi Ushiba, Tomohiro Yamada, Li-Wei Wei,
  Hiroki Takeda, Satoshi Tanioka, Masaki Ando, Kazuhiro Yamamoto, Kazuhiro
  Hayama, Sadakazu Haino, Kentaro Somiya","Prospects for improving the sensitivity of the cryogenic gravitational
  wave detector KAGRA","10 pages, 2 figures","Phys. Rev. D 102, 022008 (2020)","10.1103/PhysRevD.102.022008","JGW-P2011740","gr-qc astro-ph.IM physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Upgrades to improve the sensitivity of gravitational wave detectors enable
more frequent detections and more precise source parameter estimation. Unlike
other advanced interferometric detectors such as Advanced LIGO and Advanced
Virgo, KAGRA requires different approach for the upgrade since it is the only
detector which employs cryogenic cooling of the test masses. In this paper, we
describe possible KAGRA upgrades with technologies focusing on different
detector bands, and compare the impacts on the detection of compact binary
coalescences. We show that either fivefold improvement in the $100
M_{\odot}$--$100 M_{\odot}$ binary black hole range, a factor of 1.3
improvement in the binary neutron star range, or a factor of 1.7 improvement in
the sky localization of binary neutron stars is well feasible with upgrades
that do not require changes in the existing cryogenic or vacuum infrastructure.
We also show that twofold broadband sensitivity improvement is possible by
applying multiple upgrades to the detector.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:54:48 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jul 2020 22:30:23 GMT""}]","2020-07-28"
"2006.08971","Giulio Del Zanna","G. Del Zanna, P.J. Storey, N.R. Badnell, V. Andretta","Helium line emissivities in the solar corona","Accepted for publication in ApJ",,"10.3847/1538-4357/ab9d84",,"physics.atom-ph astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new collisional-radiative models (CRMs) for helium in the
quiescent solar corona, and predict the emissivities of the He and He$^+$ lines
to be observed by DKIST, Solar Orbiter, and Proba-3. We discuss in detail the
rates we selected for these models, highlighting several shortcomings we have
found in previous work. As no previous complete and self-consistent coronal CRM
for helium existed, we have benchmarked our largest model at a density of
10$^{6}$ cm$^{-3}$ and temperature of 20,000 K against recent CRMs developed
for photoionised nebulae. We then present results for the outer solar corona,
using new dielectronic recombination rates we have calculated, which increase
the abundance of neutral helium by about a factor of two. We also find that all
the optical triplet He I lines, and in particular the well known He I 10830 and
5876 A lines are strongly affected by both photo-excitation and
photo-ionisation from the disk radiation, and that extensive CRM models are
required to obtain correct estimates. Close to the Sun, at an electron density
of 10$^{8}$ cm$^{-3}$ and temperature of 1 MK, we predict the emissivity of the
He I 10830 A to be comparable to that of the strong Fe XIII coronal line at
10798 A. However, we expect the He I emissivity to sharply fall in the outer
corona, with respect to Fe XIII. We confirm that the He$^+$ Lyman $\alpha$ at
304 A is also significantly affected by photo-excitation and is expected to be
detectable as a strong coronal line up to several solar radii.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:56:26 GMT""}]","2020-08-05"
"2006.08972","Dorin Popescu","Dorin Popescu","Valuation rings of dimension one as limits of smooth algebras","Theorem 19 is easier in a restrictive case",,,,"math.AC math.AG","http://creativecommons.org/publicdomain/zero/1.0/","  As in Zariski's Uniformization Theorem we show that a valuation ring $V$ of
characteristic $p>0$ of dimension one is a filtered direct limit of smooth
${\bf F}_p$-algebras under some conditions of transcendence degree. Under mild
conditions, the algebraic immediate extensions of valuation rings are dense if
they are filtered direct limit of smooth morphisms.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 07:56:55 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 09:04:08 GMT""},{""version"":""v3"",""created"":""Wed, 23 Sep 2020 12:22:45 GMT""},{""version"":""v4"",""created"":""Mon, 8 Mar 2021 14:35:04 GMT""},{""version"":""v5"",""created"":""Mon, 5 Apr 2021 08:00:59 GMT""}]","2021-04-06"
"2006.08973","Andreas Look","Andreas Look, Melih Kandemir, Barbara Rakitsch, Jan Peters","A Deterministic Approximation to Neural SDEs",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural Stochastic Differential Equations (NSDEs) model the drift and
diffusion functions of a stochastic process as neural networks. While NSDEs are
known to make accurate predictions, their uncertainty quantification properties
have been remained unexplored so far. We report the empirical finding that
obtaining well-calibrated uncertainty estimations from NSDEs is computationally
prohibitive. As a remedy, we develop a computationally affordable deterministic
scheme which accurately approximates the transition kernel, when dynamics is
governed by a NSDE. Our method introduces a bidimensional moment matching
algorithm: vertical along the neural net layers and horizontal along the time
direction, which benefits from an original combination of effective
approximations. Our deterministic approximation of the transition kernel is
applicable to both training and prediction. We observe in multiple experiments
that the uncertainty calibration quality of our method can be matched by Monte
Carlo sampling only after introducing high computational cost. Thanks to the
numerical stability of deterministic training, our method also improves
prediction accuracy.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:00:26 GMT""},{""version"":""v2"",""created"":""Tue, 9 Feb 2021 09:44:54 GMT""},{""version"":""v3"",""created"":""Fri, 12 Feb 2021 13:13:04 GMT""},{""version"":""v4"",""created"":""Wed, 2 Jun 2021 12:58:00 GMT""},{""version"":""v5"",""created"":""Tue, 6 Sep 2022 08:26:53 GMT""},{""version"":""v6"",""created"":""Mon, 12 Sep 2022 07:04:38 GMT""}]","2022-09-13"
"2006.08974","Matteo A. C. Rossi","Matteo A. C. Rossi, Francesco Albarelli, Dario Tamascelli, Marco G.
  Genoni","Noisy quantum metrology enhanced by continuous nondemolition measurement","6+7 pages (including Supplemental Material), accepted version","Phys. Rev. Lett. 125, 200505 (2020)","10.1103/PhysRevLett.125.200505",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that continuous quantum nondemolition (QND) measurement of an atomic
ensemble is able to improve the precision of frequency estimation even in the
presence of independent dephasing acting on each atom. We numerically simulate
the dynamics of an ensemble with up to N = 150 atoms initially prepared in a
(classical) spin coherent state, and we show that, thanks to the spin squeezing
dynamically generated by the measurement, the information obtainable from the
continuous photocurrent scales superclassically with respect to the number of
atoms N. We provide evidence that such superclassical scaling holds for
different values of dephasing and monitoring efficiency. We moreover calculate
the extra information obtainable via a final strong measurement on the
conditional states generated during the dynamics and show that the
corresponding ultimate limit is nearly achieved via a projective measurement of
the spin-squeezed collective spin operator. We also briefly discuss the
difference between our protocol and standard estimation schemes, where the
state preparation time is neglected.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:06:37 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 09:55:16 GMT""},{""version"":""v3"",""created"":""Thu, 12 Nov 2020 18:09:27 GMT""}]","2020-11-13"
"2006.08975","Myoungsoo Jung","Jie Zhang and Myoungsoo Jung","ZnG: Architecting GPU Multi-Processors with New Flash for Scalable Data
  Analysis",,,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose ZnG, a new GPU-SSD integrated architecture, which can maximize the
memory capacity in a GPU and address performance penalties imposed by an SSD.
Specifically, ZnG replaces all GPU internal DRAMs with an ultra-low-latency SSD
to maximize the GPU memory capacity. ZnG further removes performance bottleneck
of the SSD by replacing its flash channels with a high-throughput flash network
and integrating SSD firmware in the GPU's MMU to reap the benefits of hardware
accelerations. Although flash arrays within the SSD can deliver high
accumulated bandwidth, only a small fraction of such bandwidth can be utilized
by GPU's memory requests due to mismatches of their access granularity. To
address this, ZnG employs a large L2 cache and flash registers to buffer the
memory requests. Our evaluation results indicate that ZnG can achieve 7.5x
higher performance than prior work.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:07:21 GMT""}]","2020-06-17"
"2006.08976","Matteo Zampieri Dr","Matteo Zampieri, Andrea Toreti, Andrej Ceglar, Pierluca De Palma,
  Thomas Chatzopoulos","Analysing the resilience of the European commodity production system
  with PyResPro, the Python Production Resilience package","17 pages, 6 figures",,,,"q-fin.GN physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a Python object-oriented software and code to compute the
annual production resilience indicator. The annual production resilience
indicator can be applied to different anthropic and natural systems such as
agricultural production, natural vegetation and water resources. Here, we show
an example of resilience analysis of the economic values of the agricultural
production in Europe. The analysis is conducted for individual time-series in
order to estimate the resilience of a single commodity and to groups of
time-series in order to estimate the overall resilience of diversified
production systems composed of different crops and/or different countries. The
proposed software is powerful and easy to use with publicly available datasets
such as the one used in this study.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:19:13 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 05:37:00 GMT""}]","2020-06-18"
"2006.08977","Michael Ruderman","Michael Ruderman","Stick-slip and convergence of feedback-controlled systems with Coulomb
  friction","14 pages, 8 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  An analysis of stick-slip behavior and convergence of trajectories in the
feedback-controlled motion systems with discontinuous Coulomb friction is
provided. A closed-form parameter-dependent stiction region, around an
invariant equilibrium set, is proved to be always reachable and globally
attractive. It is shown that only asymptotic convergence can be achieved, with
at least one but mostly an infinite number of consecutive stick-slip cycles,
independent of the initial conditions. Theoretical developments are supported
by a number of numerical results with dedicated convergence examples.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:19:15 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jul 2021 15:10:04 GMT""},{""version"":""v3"",""created"":""Tue, 28 Sep 2021 18:24:32 GMT""}]","2021-09-30"
"2006.08978","Shunsuke Kitou","Shunsuke Kitou, Takao Tsumuraya, Hikaru Sawahata, Fumiyuki Ishii,
  Ko-ichi Hiraki, Toshikazu Nakamura, Naoyuki Katayama, and Hiroshi Sawa","Ambient pressure Dirac electron system in quasi-two-dimensional
  molecular conductor ${\alpha}$-(BETS)$_2$I$_3$","9 pages, 6 figures + Supplemental Material","Phys. Rev. B 103, 035135 (2021)","10.1103/PhysRevB.103.035135",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated the precise crystal structures and electronic states in a
quasi-two-dimensional molecular conductor ${\alpha}$-(BETS)$_2$I$_3$ at ambient
pressure. The electronic resistivity of this molecular solid shows
metal-to-insulator (MI) crossover at $T_{MI}$=50 K. Our x-ray diffraction and
$^{13}$C nuclear magnetic resonance experiments revealed that
${\alpha}$-(BETS)$_2$I$_3$ maintains the inversion symmetry below $T_{MI}$.
First-principles calculations found a pair of anisotropic Dirac cones at a
general k-point, with the degenerate contact points at the Fermi level. The
origin of the insulating state in this system is a small energy gap of ~2 meV
opened by the spin-orbit interaction. The Z$_2$ topological invariants indicate
that this system is a weak topological insulator. Our results suggest that
${\alpha}$-(BETS)$_2$I$_3$ is a promising material for studying the bulk Dirac
electron system in two dimensions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:20:09 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 04:52:37 GMT""}]","2021-01-25"
"2006.08979","Pamela Rowden","Pamela Rowden (1), Tam\'as Borkovits (2 and 3), Jon M. Jenkins (4),
  Keivan G. Stassun (5 and 6), Joseph D. Twicken (4 and 7), Elisabeth R. Newton
  (8), Carl Ziegler (9), Coel Hellier (10), Aylin Garcia Soto (8), Elisabeth C.
  Matthews (11), Ulrich Kolb (1), George R. Ricker (11), Roland Vanderspek
  (11), David W. Latham (12), S. Seager (11 and 13 and 14), Joshua N. Winn
  (15), Luke G. Bouma (15), C\'esar Brice\~no (16), David Charbonneau (12),
  William Fong (11), Ana Glidden (13 and 11), Natalia M. Guerrero (11),
  Nicholas Law (17), Andrew W. Mann (17), Mark E. Rose (4), Joshua Schlieder
  (18), Peter Tenenbaum (7 and 4), Eric B. Ting (4) ((1) The Open University,
  (2) Baja Astronomical Observatory of Szeged University, (3) Konkoly
  Observatory, (4) NASA Ames Research Center, (5) Vanderbilt University, (6)
  Fisk University, (7) SETI Institute, (8) Dartmouth College, (9) Dunlap
  Institute for Astronomy and Astrophysics, University of Toronto, (10) Keele
  University, (11) Department of Physics and Kavli Institute for Astrophysics
  and Space Research, Massachusetts Institute of Technology, (12) Center for
  Astrophysics, Harvard and Smithsonian, (13) Department of Earth, Atmospheric
  and Planetary Sciences, Massachusetts Institute of Technology, (14)
  Department of Aeronautics and Astronautics, MIT, (15) Princeton University,
  (16) Cerro Tololo Inter-American Observatory, (17) The University of North
  Carolina at Chapel Hill, (18) NASA Goddard Flight Center)","TIC 278956474: Two close binaries in one young quadruple system,
  identified by \textit{TESS}","Submitted to AJ",,"10.3847/1538-3881/ab9d20",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have identified a quadruple system with two close eclipsing binaries in
TESS data. The object is unresolved in Gaia and appears as a single source at
parallax 1.08~$\pm$0.01 mas. Both binaries have observable primary and
secondary eclipses and were monitored throughout TESS Cycle 1 (sectors 1-13),
falling within the TESS Continuous Viewing Zone. In one eclipsing binary (P =
5.488 d), the smaller star is completely occluded by the larger star during the
secondary eclipse; in the other (P = 5.674 d) both eclipses are grazing. Using
these data, spectroscopy, speckle photometry, SED analysis and evolutionary
stellar tracks, we have constrained the masses and radii of the four stars in
the two eclipsing binaries. The Li I EW indicates an age of 10-50 Myr and, with
an outer period of $858^{+7}_{-5}$ days, our analysis indicates this is one of
the most compact young 2+2 quadruple systems known.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:20:21 GMT""}]","2020-07-29"
"2006.08980","Valentina Fioretti","V. Fioretti and A. Bulgarelli and M. Tavani and S. Sabatini and A.
  Aboudan and A. Argan and P. W. Cattaneo and A. W. Chen and I. Donnarumma and
  F. Longo and M. Galli and A. Giuliani and M. Marisaldi and N. Parmiggiani and
  A. Rappoldi","AGILESim: Monte Carlo simulation of the AGILE gamma-ray telescope",,"The Astrophysical Journal, 896:61 (12pp), 2020 June 10","10.3847/1538-4357/ab929a",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The accuracy of Monte Carlo simulations in reproducing the scientific
performance of space telescopes (e.g. angular resolution) is mandatory for a
correct design of the mission. A brand-new Monte Carlo simulator of the
Astrorivelatore Gamma ad Immagini LEggero (AGILE)/Gamma-Ray Imaging Detector
(GRID) space telescope, AGILESim, is built using the customizable Bologna
Geant4 Multi-Mission Simulator (BoGEMMS) architecture and the latest Geant4
library to reproduce the instrument performance of the AGILE/GRID instrument.
The Monte Carlo simulation output is digitized in the BoGEMMS postprocessing
pipeline, according to the instrument electronic read-out logic, then converted
into the onboard data handling format, and finally analyzed by the standard
mission on-ground reconstruction pipeline, including the Kalman filter, as a
real observation in space. In this paper we focus on the scientific validation
of AGILESim, performed by reproducing (i) the conversion efficiency of the
tracker planes, (ii) the tracker charge readout distribution measured by the
on-ground assembly, integration, and verification activity, and (iii) the
point-spread function of in-flight observations of the Vela pulsar in the 100
MeV - 1 GeV energy range. We measure an in-flight angular resolution (FWHM) for
Vela-like point sources of $2.0^{+0.2}_{-0.3}$ and $0.8^{+0.1}_{-0.1}$ degrees
in the 100 - 300 and 300 - 1000 MeV energy bands, respectively. The successful
cross-comparison of the simulation results with the AGILE on-ground and
in-space performance validates the BoGEMMS framework for its application to
future gamma-ray trackers (e.g. e-ASTROGAM and AMEGO).
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:22:47 GMT""}]","2020-06-17"
"2006.08981","Konstantin Zloshchastiev","Tony C. Scott and Konstantin G. Zloshchastiev","Resolving the puzzle of sound propagation in liquid helium at low
  temperatures","5 pages, 3 figures, final/published version","Low Temp. Phys. 45, 1231 (2019)","10.1063/10.0000200",,"cond-mat.quant-gas physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Experimental data suggests that, at temperatures below 1 K, the pressure in
liquid helium has a cubic dependence on density. Thus the speed of sound scales
as a cubic root of pressure. Near a critical pressure point, this speed
approaches zero whereby the critical pressure is negative, thus indicating a
cavitation instability regime. We demonstrate that to explain this dependence,
one has to view liquid helium as a mixture of three quantum Bose liquids:
dilute (Gross-Pitaevskii-type) Bose-Einstein condensate, Ginzburg-Sobyanin-type
fluid, and logarithmic superfluid. Therefore, the dynamics of such a mixture is
described by a quantum wave equation, which contains not only the polynomial
(Gross-Pitaevskii and Ginzburg-Sobyanin) nonlinearities with respect to a
condensate wavefunction, but also a non-polynomial logarithmic nonlinearity. We
derive an equation of state and speed of sound in our model, and show their
agreement with experiment.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:23:34 GMT""}]","2020-06-17"
"2006.08982","Simon Luo","Simon Luo, Feng Zhou, Lamiae Azizi and Mahito Sugiyama","Additive Poisson Process: Learning Intensity of Higher-Order Interaction
  in Stochastic Processes","14 pages, 8 figures, pre-print",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the Additive Poisson Process (APP), a novel framework that can
model the higher-order interaction effects of the intensity functions in
stochastic processes using lower dimensional projections. Our model combines
the techniques in information geometry to model higher-order interactions on a
statistical manifold and in generalized additive models to use
lower-dimensional projections to overcome the effects from the curse of
dimensionality. Our approach solves a convex optimization problem by minimizing
the KL divergence from a sample distribution in lower dimensional projections
to the distribution modeled by an intensity function in the stochastic process.
Our empirical results show that our model is able to use samples observed in
the lower dimensional space to estimate the higher-order intensity function
with extremely sparse observations.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:25:36 GMT""}]","2020-06-17"
"2006.08983","Urs Staub","Hiroki Ueda, Michael Porer, Jos\'e R. L. Mardegan, Sergii Parchenko,
  Namrata Gurung, Federica Fabrizi, Mahesh Ramakrishnan, Larissa Boie, Martin
  Josef Neugebauer, Bulat Burganov, Max Burian, Steven Lee Johnson, Kai
  Rossnagel and Urs Staub","Correlation between electronic and structural orders in 1T-TiSe2","16 pages, 4 figures + 13 pages supplementary info","Phys. Rev. Research 3, 022003 (2021)","10.1103/PhysRevResearch.3.L022003",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The correlation between electronic and crystal structures of 1T-TiSe2 in the
charge density wave (CDW) state is studied by x-ray diffraction. Three families
of reflections are used to probe atomic displacements and the orbital asymmetry
in Se. Two distinct onset temperatures are found, TCDW and a lower T*
indicative for an onset of Se out-of-plane atomic displacements. T* coincides
with a DC resistivity maximum and the onset of the proposed gyrotropic
electronic structure. However, no indication for chirality is found. The
relation between the atomic displacements and the transport properties is
discussed in terms of Ti 3d and Se 4p states that only weakly couple to the CDW
order.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:26:01 GMT""}]","2021-04-14"
"2006.08984","Alexander Polkovnikov","Alexander Polkovnikov","On initial boundary value problem for parabolic differential operator
  with non-coercive boundary conditions","11 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider initial boundary value problem for uniformly 2-parabolic
differential operator of second order in cylinder domain in ${\mathbb R}^n $
with non-coercive boundary conditions. In this case there is a loss of
smoothness of the solution in Sobolev type spaces compared with the coercive
situation. Using by Faedo-Galerkin method we prove that problem has unique
solution in special Bochner space.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:29:50 GMT""}]","2020-06-17"
"2006.08985","Abhijit Bhattacharyya Prof.","Somenath Pal, Abhijit Bhattacharyya and Rajarshi Ray","Modified Excluded Volume Hadron Resonance Gas Model with Lorentz
  Contraction",,,,,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we discuss a modified version of Excluded Volume Hadron
Resonance Gas model and also study the effect of Lorentz contraction of the
excluded volume on scaled pressure and susceptibilities of conserved charges.
We find that the Lorentz contraction, coupled with the variety of excluded
volume parameters reproduce the lattice QCD data quite satisfactorily.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:30:15 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 07:10:30 GMT""}]","2021-03-10"
"2006.08986","Revaz Tevzadze","Michael Mania and Revaz Tevzadze","On Martingale Transformations of Multidimensional Brownian Motion","12 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the class of functions $f: R^n\to R^m$ which transform a vector
Brownian Motion into a martingale and use this description to give martingale
characterization of the general measurable solution of the multidimensional
Cauchy functional equation.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:31:28 GMT""}]","2020-06-17"
"2006.08987","Eveline Legendre","Eveline Legendre (IMT)","Localizing the Donaldson-Futaki invariant",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use the equivariant localization formula to prove that the
Donaldson-Futaki invariant of a compact smooth (K{\""a}hler) test configuration
coincides with the Futaki invariant of the induced action on the central fiber
when this fiber is smooth or have orbifold singularities. We also localize the
Donaldson-Futaki invariant of the deformation to the normal cone.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:32:16 GMT""}]","2020-06-17"
"2006.08988","Chiara Forlani","Chiara Forlani, Samir Bhatt, Michela Cameletti, Elias Krainski, Marta
  Blangiardo","A joint bayesian space-time model to integrate spatially misaligned air
  pollution data in R-INLA","This paper has been submitted to Environmetrics and is under revision","Environmetrics (2020) 1-17; e2644","10.1002/env.2644",,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In air pollution studies, dispersion models provide estimates of
concentration at grid level covering the entire spatial domain, and are then
calibrated against measurements from monitoring stations. However, these
different data sources are misaligned in space and time. If misalignment is not
considered, it can bias the predictions. We aim at demonstrating how the
combination of multiple data sources, such as dispersion model outputs, ground
observations and covariates, leads to more accurate predictions of air
pollution at grid level. We consider nitrogen dioxide (NO2) concentration in
Greater London and surroundings for the years 2007-2011, and combine two
different dispersion models. Different sets of spatial and temporal effects are
included in order to obtain the best predictive capability. Our proposed model
is framed in between calibration and Bayesian melding techniques for data
fusion red. Unlike other examples, we jointly model the response (concentration
level at monitoring stations) and the dispersion model outputs on different
scales, accounting for the different sources of uncertainty. Our
spatio-temporal model allows us to reconstruct the latent fields of each model
component, and to predict daily pollution concentrations. We compare the
predictive capability of our proposed model with other established methods to
account for misalignment (e.g. bilinear interpolation), showing that in our
case study the joint model is a better alternative.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:33:51 GMT""}]","2020-08-17"
"2006.08989","Paul-Emile Paradan","Paul-Emile Paradan (IMAG)","Horn(p,q)",,,,,"math.DG math.RT math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we obtain a recursive description of the Horn cone Horn(p,q)
with respect to the integers p and q, as in the classical Horn's conjecture.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:34:36 GMT""}]","2020-06-17"
"2006.08990","Manik Banik","Sagnik Dutta, Amit Mukherjee, and Manik Banik","Operational Characterization of Multipartite Nonlocal Correlations","Accepted in Physical Review A [close to accepted version]","Phys. Rev. A 102, 052218 (2020)","10.1103/PhysRevA.102.052218",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonlocality, one of the most puzzling features of multipartite quantum
correlation, has been identified as a useful resource for device-independent
quantum information processing. Motivated by the resource theory of quantum
entanglement recently an operational framework have been proposed by Gallego et
al. [\href{https://doi.org/10.1103/PhysRevLett.109.070401}{Phys. Rev. Lett.
109, 070401 (2012)}] and Bancal et al.
[\href{https://doi.org/10.1103/PhysRevA.88.014102}{Phys. Rev. A 88, 014102
(2013)}] that characterizes the nonlocal resource present in multipartite
quantum correlations. While the bipartite no-signaling correlations allows a
dichotomous classification -- local vs. nonlocal, in multipartite scenario the
authors have shown existence of several types of nonlocality that are
inequivalent under the proposed operational framework. In this work we present
a finer characterization of multipartite no-signaling correlations based on the
same operational framework. We also clarify a statement in Gallego et al.'s
work that could be misinterpreted and make the conclusions of that work more
precise here.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:36:17 GMT""},{""version"":""v2"",""created"":""Tue, 3 Nov 2020 03:18:09 GMT""}]","2020-11-18"
"2006.08991","Fenglong You","Hsian-Hua Tseng, Fenglong You","A mirror theorem for multi-root stacks and applications","30 pages, to appear in Selecta Mathematica","Selecta Mathematica, volume 29, Article number: 6 (2023)",,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a smooth projective variety $X$ with a simple normal crossing divisor
$D:=D_1+D_2+...+D_n$, where $D_i\subset X$ are smooth, irreducible and nef. We
prove a mirror theorem for multi-root stacks $X_{D,\vec r}$ by constructing an
$I$-function, a slice of Givental's Lagrangian cone for Gromov--Witten theory
of multi-root stacks. We provide three applications: (1) We show that some
genus zero invariants of $X_{D,\vec r}$ stabilize for sufficiently large $\vec
r$. (2) We state a generalized local-log-orbifold principle conjecture and
prove a version of it. (3) We show that regularized quantum periods of Fano
varieties coincide with classical periods of the mirror Landau--Ginzburg
potentials using orbifold invariants of $X_{D,\vec r}$.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:37:23 GMT""},{""version"":""v2"",""created"":""Fri, 21 Oct 2022 19:50:34 GMT""}]","2022-11-04"
"2006.08992","Ying Liu","Ying Liu, Jiabin Yuan, Wenjing Dai and Dan Li","Three-state quantum walk on the Cayley Graph of the Dihedral Group",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The finite dihedral group generated by one rotation and one reflection is the
simplest case of the non-abelian group. Cayley graphs are diagrammatic
counterparts of groups. In this paper, much attention is given to the Cayley
graph of the dihedral group. Considering the characteristics of the elements in
the dihedral group, we propose a model of three-state discrete-time quantum
walk (DTQW) on the Caylay graph of the dihedral group with Grover coin. We
derive analytic expressions for the the position probability distribution and
the long-time limit of the return probability starting from the origin. It is
shown that the localization effect is governed by the size of the underlying
dihedral group, coin operator and initial state. We also numerically
investigate the properties of the proposed model via the probability
distribution and the time-averaged probability at the designated position. The
abundant phenomena of three-state Grover DTQW on the Caylay graph of the
dihedral group can help the community to better understand and to develop new
quantum algorithms.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:43:42 GMT""}]","2020-06-17"
"2006.08993","Amine Echraibi","Amine Echraibi (IMT Atlantique - INFO), Joachim Flocon-Cholet,
  St\'ephane Gosselin, Sandrine Vaton (INFO)","On the Variational Posterior of Dirichlet Process Deep Latent Gaussian
  Mixture Models",,"ICML Workshop on Invertible Neural Networks, Normalizing Flows,
  and Explicit Likelihood Models, Jul 2020, Vienna, Austria",,,"stat.ML cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thanks to the reparameterization trick, deep latent Gaussian models have
shown tremendous success recently in learning latent representations. The
ability to couple them however with nonparamet-ric priors such as the Dirichlet
Process (DP) hasn't seen similar success due to its non parameteriz-able
nature. In this paper, we present an alternative treatment of the variational
posterior of the Dirichlet Process Deep Latent Gaussian Mixture Model
(DP-DLGMM), where we show that the prior cluster parameters and the variational
posteriors of the beta distributions and cluster hidden variables can be
updated in closed-form. This leads to a standard reparameterization trick on
the Gaussian latent variables knowing the cluster assignments. We demonstrate
our approach on standard benchmark datasets, we show that our model is capable
of generating realistic samples for each cluster obtained, and manifests
competitive performance in a semi-supervised setting.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:46:18 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jul 2020 12:41:05 GMT""}]","2020-07-28"
"2006.08994","Jean-Yves Charbonnel","Jean-Yves Charbonnel (IMJ, IMJ-PRG (UMR\_7586))","On some subspaces of the exterior algebra of a simple Lie algebra",,,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we are interested in some subspaces of the exterior algebra
of a simple Lie algebra g. In particular, we prove that some graded subspaces
of degree d generate the g-module d (g) for some integers d.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:49:27 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jul 2020 13:31:08 GMT""}]","2020-07-22"
"2006.08995","Le Yang","Le Yang, Fu-Chun Zheng and Shi Jin","Spatio-Temporal Analysis of Cellular Networks with Cell-Center/Edge
  Users","20 pages, 11 figures",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Emergence of various types of services has brought about explosive growth of
traffic as well as diversified traffic characteristics in the cellular
networks. To have a comprehensive understanding of the influences caused by
various traffic status is vital for the deployment of the next-generation
wireless networks. In this paper, we develop a mathematical analytical model by
utilizing queuing theory and stochastic geometry where the randomness of the
traffic and the geographical locations of the interferers can be captured. We
derive the b-th moments of the conditional success probability and the
closed-form expressions of the meta distribution for the cell-center users
(CCUs) and the cell-edge users (CEUs), respectively. Fixed-point equations are
then formulated to obtain the exact value of the meta distribution by taking
the random arrival traffic into consideration and the impact of the random
arrival traffic on the queue status is revealed. In addition, the mean local
delays for CCUs nad CEUs are derived and the corresponding regions for CCUs and
CEUs where the mean local delays maintain finite are obtained. Finally, the
impact of the critical network parameters on the meta distribution and the mean
local delay is investigated with the numerical results.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:50:27 GMT""}]","2020-06-17"
"2006.08996","Stefan Neuwirth","Thierry Coquand (CSE), Stefan Neuwirth (LMB)","Lorenzen's proof of consistency for elementary number theory [with an
  edition and translation of ""Ein halbordnungstheoretischer
  Widerspruchsfreiheitsbeweis'']","History and Philosophy of Logic, Taylor & Francis, 2020. arXiv admin
  note: substantial text overlap with arXiv:1711.06139",,"10.1080/01445340.2020.1752034",,"math.HO math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a manuscript of Paul Lorenzen that provides a proof of consistency
for elementary number theory as an application of the construction of the free
countably complete pseudocomplemented semilattice over a preordered set. This
manuscript rests in the Oskar-Becker-Nachlass at the Philosophisches Archiv of
Universit{\""a}t Konstanz, file OB 5-3b-5. It has probably been written between
March and May 1944. We also compare this proof to Gentzen's and Novikov's, and
provide a translation of the manuscript.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:51:45 GMT""}]","2020-06-17"
"2006.08997","Mathieu Andreux","Mathieu Andreux, Andre Manoel, Romuald Menuet, Charlie Saillard,
  Chlo\'e Simpson","Federated Survival Analysis with Discrete-Time Cox Models","21 pages, 6 figures","International Workshop on Federated Learning for User Privacy and
  Data Confidentiality in Conjunction with ICML 2020 (FL-ICML'20)",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Building machine learning models from decentralized datasets located in
different centers with federated learning (FL) is a promising approach to
circumvent local data scarcity while preserving privacy. However, the prominent
Cox proportional hazards (PH) model, used for survival analysis, does not fit
the FL framework, as its loss function is non-separable with respect to the
samples. The na\""ive method to bypass this non-separability consists in
calculating the losses per center, and minimizing their sum as an approximation
of the true loss. We show that the resulting model may suffer from important
performance loss in some adverse settings. Instead, we leverage the
discrete-time extension of the Cox PH model to formulate survival analysis as a
classification problem with a separable loss function. Using this approach, we
train survival models using standard FL techniques on synthetic data, as well
as real-world datasets from The Cancer Genome Atlas (TCGA), showing similar
performance to a Cox PH model trained on aggregated data. Compared to previous
works, the proposed method is more communication-efficient, more generic, and
more amenable to using privacy-preserving techniques.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:53:19 GMT""}]","2020-07-21"
"2006.08998","Shalom Eliahou","Shalom Eliahou (LMPA), Eshita Mazumdar","Iterated sumsets and Hilbert functions",,,"10.1016/j.jalgebra.2021.11.019",,"math.AC math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let A be a finite subset of an abelian group (G, +). Let h $\ge$ 2 be an
integer. If |A| $\ge$ 2 and the cardinality |hA| of the h-fold iterated sumset
hA = A + $\times$ $\times$ $\times$ + A is known, what can one say about |(h --
1)A| and |(h + 1)A|? It is known that |(h -- 1)A| $\ge$ |hA| (h--1)/h , a
consequence of Pl{\""u}nnecke's inequality. Here we improve this bound with a
new approach. Namely, we model the sequence |hA| h$\ge$0 with the Hilbert
function of a standard graded algebra. We then apply Macaulay's 1927 theorem on
the growth of Hilbert functions, and more specifically a recent condensed
version of it. Our bound implies |(h -- 1)A| $\ge$ $\theta$(x, h) |hA| (h--1)/h
for some factor $\theta$(x, h) > 1, where x is a real number closely linked to
|hA|. Moreover, we show that $\theta$(x, h) asymptotically tends to e $\approx$
2.718 as |A| grows and h lies in a suitable range varying with |A|.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:53:20 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2020 13:22:16 GMT""},{""version"":""v3"",""created"":""Mon, 7 Sep 2020 13:12:54 GMT""}]","2021-11-29"
"2006.08999","Quoc Hoan Tran","Quoc Hoan Tran and Kohei Nakajima","Higher-Order Quantum Reservoir Computing","main (15 pages, 12 pictures), add ""Quantum-innate training""",,,,"quant-ph cs.LG nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum reservoir computing (QRC) is an emerging paradigm for harnessing the
natural dynamics of quantum systems as computational resources that can be used
for temporal machine learning tasks. In the current setup, QRC is difficult to
deal with high-dimensional data and has a major drawback of scalability in
physical implementations. We propose higher-order QRC, a hybrid
quantum-classical framework consisting of multiple but small quantum systems
that are mutually communicated via classical connections like linear feedback.
By utilizing the advantages of both classical and quantum techniques, our
framework enables an efficient implementation to boost the scalability and
performance of QRC. Furthermore, higher-order settings allow us to implement a
FORCE learning or an innate training scheme, which provides flexibility and
high operability to harness high-dimensional quantum dynamics and significantly
extends the application domain of QRC. We demonstrate the effectiveness of our
framework in emulating large-scale nonlinear dynamical systems, including
complex spatiotemporal chaos, which outperforms many of the existing machine
learning techniques in certain situations.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:54:04 GMT""},{""version"":""v2"",""created"":""Tue, 20 Oct 2020 14:41:59 GMT""}]","2020-10-21"
"2006.09000","Kirill Bykov","Kirill Bykov, Marina M.-C. H\""ohne, Klaus-Robert M\""uller, Shinichi
  Nakajima, Marius Kloft","How Much Can I Trust You? -- Quantifying Uncertainties in Explaining
  Neural Networks","12 pages, 10 figures",,,,"cs.LG cs.AI cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Explainable AI (XAI) aims to provide interpretations for predictions made by
learning machines, such as deep neural networks, in order to make the machines
more transparent for the user and furthermore trustworthy also for applications
in e.g. safety-critical areas. So far, however, no methods for quantifying
uncertainties of explanations have been conceived, which is problematic in
domains where a high confidence in explanations is a prerequisite. We therefore
contribute by proposing a new framework that allows to convert any arbitrary
explanation method for neural networks into an explanation method for Bayesian
neural networks, with an in-built modeling of uncertainties. Within the
Bayesian framework a network's weights follow a distribution that extends
standard single explanation scores and heatmaps to distributions thereof, in
this manner translating the intrinsic network model uncertainties into a
quantification of explanation uncertainties. This allows us for the first time
to carve out uncertainties associated with a model explanation and subsequently
gauge the appropriate level of explanation confidence for a user (using
percentiles). We demonstrate the effectiveness and usefulness of our approach
extensively in various experiments, both qualitatively and quantitatively.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:54:42 GMT""}]","2020-06-17"
"2006.09001","Kanishka Rao","Kanishka Rao, Chris Harris, Alex Irpan, Sergey Levine, Julian Ibarz,
  Mohi Khansari","RL-CycleGAN: Reinforcement Learning Aware Simulation-To-Real","Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR 2020)",,,,"cs.RO cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural network based reinforcement learning (RL) can learn appropriate
visual representations for complex tasks like vision-based robotic grasping
without the need for manually engineering or prior learning a perception
system. However, data for RL is collected via running an agent in the desired
environment, and for applications like robotics, running a robot in the real
world may be extremely costly and time consuming. Simulated training offers an
appealing alternative, but ensuring that policies trained in simulation can
transfer effectively into the real world requires additional machinery.
Simulations may not match reality, and typically bridging the
simulation-to-reality gap requires domain knowledge and task-specific
engineering. We can automate this process by employing generative models to
translate simulated images into realistic ones. However, this sort of
translation is typically task-agnostic, in that the translated images may not
preserve all features that are relevant to the task. In this paper, we
introduce the RL-scene consistency loss for image translation, which ensures
that the translation operation is invariant with respect to the Q-values
associated with the image. This allows us to learn a task-aware translation.
Incorporating this loss into unsupervised domain translation, we obtain
RL-CycleGAN, a new approach for simulation-to-real-world transfer for
reinforcement learning. In evaluations of RL-CycleGAN on two vision-based
robotics grasping tasks, we show that RL-CycleGAN offers a substantial
improvement over a number of prior methods for sim-to-real transfer, attaining
excellent real-world performance with only a modest number of real-world
observations.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:58:07 GMT""}]","2020-06-17"
"2006.09002","Walter Morales-Alvarez","Yuzhou Liu, Georg Novotny, Nikita Smirnov, Walter Morales-Alvarez and
  Cristina Olaverri-Monreal","Mobile Delivery Robots: Mixed Reality-Based Simulation Relying on ROS
  and Unity 3D","Paper submitted for publication in the 31st IEEE Intelligent Vehicles
  Symposium",,"10.1109/IV47402.2020.9304701",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of Intelligent Transportation Systems and the delivery of
goods, new technology approaches need to be developed in order to cope with
certain challenges that last mile delivery entails, such as navigation in an
urban environment. Autonomous delivery robots can help overcome these
challenges. We propose a method for performing mixed reality (MR) simulation
with ROS-based robots using Unity, which synchronizes the real and virtual
environment, and simultaneously uses the sensor information of the real robots
to locate themselves and project them into the virtual environment, so that
they can use their virtual doppelganger to perceive the virtual world. Using
this method, real and virtual robots can perceive each other and the
environment in which the other party is located, thereby enabling the exchange
of information between virtual and real objects. Through this approach a more
realistic and reliable simulation can be obtained. Results of the demonstrated
use-cases verified the feasibility and efficiency as well as the stability of
implementing MR using Unity for ROS-based robots.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:59:38 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 14:15:56 GMT""}]","2021-02-23"
"2006.09003","Paul Freulon","Paul Freulon, J\'er\'emie Bigot and Boris P. Hejblum","CytOpT: Optimal Transport with Domain Adaptation for Interpreting Flow
  Cytometry data","25 pages, 17 figures",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  The automated analysis of flow cytometry measurements is an active research
field. We introduce a new algorithm, referred to as CytOpT, using regularized
optimal transport to directly estimate the different cell population
proportions from a biological sample characterized with flow cytometry
measurements. We rely on the regularized Wasserstein metric to compare
cytometry measurements from different samples, thus accounting for possible
mis-alignment of a given cell population across sample (due to technical
variability from the technology of measurements). In this work, we rely on a
supervised learning technique based on the Wasserstein metric that is used to
estimate an optimal re-weighting of class proportions in a mixture model from a
source distribution (with known segmentation into cell sub-populations) to fit
a target distribution with unknown segmentation. Due to the high-dimensionality
of flow cytometry data, we use stochastic algorithms to approximate the
regularized Wasserstein metric to solve the optimization problem involved in
the estimation of optimal weights representing the cell population proportions
in the target distribution. Several flow cytometry data sets are used to
illustrate the performances of CytOpT that are also compared to those of
existing algorithms for automatic gating based on supervised learning.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:01:58 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 16:53:17 GMT""},{""version"":""v3"",""created"":""Thu, 18 Jun 2020 17:25:28 GMT""},{""version"":""v4"",""created"":""Tue, 2 Feb 2021 17:49:34 GMT""},{""version"":""v5"",""created"":""Thu, 30 Jun 2022 16:44:42 GMT""}]","2022-07-01"
"2006.09004","Tokitake Yamaguchi","T. Yamaguchi, K. Iwano, T. Miyamoto, N. Takamura, N. Kida, Y.
  Takahashi, T. Hasegawa, and H. Okamoto","Excitonic optical spectra and energy structures in a one-dimensional
  Mott insulator demonstrated by applying a many-body Wannier functions method
  to a charge model","31 pages, 9 figures","Phys. Rev. B 103, 045124 (2021)","10.1103/PhysRevB.103.045124",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have applied a many-body Wannier functions method to theoretically
calculate an excitonic optical conductivity spectrum and energy structure in a
one-dimensional (1D) Mott insulator at absolute zero temperature with large
system size. Focusing on full charge fluctuations associated with pairs of a
holon and doublon, we employ a charge model, which is interpreted as a good
effective model to investigate photoexcitations of a 1D extended Hubbard model
at half-filling in the spin-charge separation picture. As a result, the
theoretical spectra with appropriate broadenings qualitatively reproduce the
recent experimental data of ET-F$_{2}$TCNQ at 294 K with and without a
modulated electric field. Regarding the excitonic energy structure, we have
found that the excitons, especially for even-parity, are weakly bound by
many-body effects. This is also consistent with the fitting parameters reported
in the recent experiment. Thus, our theoretical method presented in this paper
is practically useful to understand physical roles of charge fluctuations in
many-body excited states of a 1D Mott insulator.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:03:00 GMT""}]","2021-01-22"
"2006.09005","Riccardo Middei","R. Middei, P.-O. Petrucci, S. Bianchi, F. Ursini, M. Cappi, M. Clavel,
  A. De Rosa, A. Marinucci, G. Matt and A. Tortosa","The soft excess of the NLS1 galaxy Mrk 359 studied with an
  XMM-Newton-NuSTAR monitoring campaign","12 pages, 14 figures. Accepted for publication in A&A",,"10.1051/0004-6361/202038112",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  XMM-Newton and NuSTAR multiple exposures allow us to disentangle the
different emission components of active galactic nuclei (AGNs) and to study the
evolution of their different spectral features. In this work, we present the
timing and spectral properties of five simultaneous XMM-Newton and NuSTAR
observations of the Narrow Line Seyfert 1 galaxy Mrk 359. We aim to provide the
first broadband spectral modeling of Mrk 359 describing its emission spectrum
from the UV up to the hard X-rays. To do this, we performed temporal and
spectral data analysis, characterising the amplitude and spectral changes of
the Mrk 359 time series and computing the 2-10 keV normalised excess variance.
The spectral broadband modelling assumes the standard hot Comptonising corona
and reflection component, while for the soft excess we tested two different
models: a warm, optically thick Comptonising corona (the two-corona model) and
a reflection model in which the soft-excess is the result of a blurred
reflected continuum and line emission (the reflection model). High and low flux
states were observed during the campaign. The former state has a softer
spectral shape, while the latter shows a harder one. The photon index is in the
1.75-1.89 range, and only a lower limit to the hot-corona electron temperature
can be found. A constant reflection component, likely associated with distant
matter, is observed. Regarding the soft excess, we found that among the
reflection models we tested, the one providing the better fit (reduced
$\chi^2$=1.14) is the high-density one. However, a significantly better fit
(reduced $\chi^2$=1.08) is found by modelling the soft excess with a warm
Comptonisation model. The present analysis suggests the two-corona model as the
best scenario for the optical-UV to X-ray emission spectrum of Mrk 359.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:07:06 GMT""}]","2020-10-07"
"2006.09006","David Diaz-Guerra","David Diaz-Guerra, Antonio Miguel and Jose R. Beltran","Robust Sound Source Tracking Using SRP-PHAT and 3D Convolutional Neural
  Networks","This is a pre-print of an article published in IEEE/ACM Transactions
  on Audio Speech and Language Processing. The code to reproduce this work can
  be found in our GitHub repository: https://github.com/DavidDiazGuerra/Cross3D","in IEEE/ACM Transactions on Audio, Speech, and Language
  Processing, vol. 29, pp. 300-311, 2021","10.1109/TASLP.2020.3040031",,"eess.AS cs.LG cs.SD eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a new single sound source DOA estimation and
tracking system based on the well-known SRP-PHAT algorithm and a
three-dimensional Convolutional Neural Network. It uses SRP-PHAT power maps as
input features of a fully convolutional causal architecture that uses 3D
convolutional layers to accurately perform the tracking of a sound source even
in highly reverberant scenarios where most of the state of the art techniques
fail. Unlike previous methods, since we do not use bidirectional recurrent
layers and all our convolutional layers are causal in the time dimension, our
system is feasible for real-time applications and it provides a new DOA
estimation for each new SRP-PHAT map. To train the model, we introduce a new
procedure to simulate random trajectories as they are needed during the
training, equivalent to an infinite-size dataset with high flexibility to
modify its acoustical conditions such as the reverberation time. We use both
acoustical simulations on a large range of reverberation times and the actual
recordings of the LOCATA dataset to prove the robustness of our system and its
good performance even using low-resolution SRP-PHAT maps.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:07:33 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 19:07:34 GMT""}]","2020-12-18"
"2006.09007","Andreas Dibiasi","Andreas Dibiasi and Samad Sarferaz","Measuring Macroeconomic Uncertainty: The Labor Channel of Uncertainty
  from a Cross-Country Perspective",,,,,"econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper constructs internationally consistent measures of macroeconomic
uncertainty. Our econometric framework extracts uncertainty from revisions in
data obtained from standardized national accounts. Applying our model to
post-WWII real-time data, we estimate macroeconomic uncertainty for 39
countries. The cross-country dimension of our uncertainty data allows us to
study the impact of uncertainty shocks under different employment protection
legislation. Our empirical findings suggest that the effects of uncertainty
shocks are stronger and more persistent in countries with low employment
protection compared to countries with high employment protection. These
empirical findings are in line with a theoretical model under varying firing
cost.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:09:46 GMT""},{""version"":""v2"",""created"":""Thu, 31 Dec 2020 14:09:35 GMT""}]","2021-01-01"
"2006.09008","Xiang Gao","Xiang Gao, Jennie Si, Yue Wen, Minhan Li and He (Helen) Huang","Reinforcement Learning Control of Robotic Knee with Human in the Loop by
  Flexible Policy Iteration",,,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are motivated by the real challenges presented in a human-robot system to
develop new designs that are efficient at data level and with performance
guarantees such as stability and optimality at systems level. Existing
approximate/adaptive dynamic programming (ADP) results that consider system
performance theoretically are not readily providing practically useful learning
control algorithms for this problem; and reinforcement learning (RL) algorithms
that address the issue of data efficiency usually do not have performance
guarantees for the controlled system. This study fills these important voids by
introducing innovative features to the policy iteration algorithm. We introduce
flexible policy iteration (FPI), which can flexibly and organically integrate
experience replay and supplemental values from prior experience into the RL
controller. We show system level performances including convergence of the
approximate value function, (sub)optimality of the solution, and stability of
the system. We demonstrate the effectiveness of the FPI via realistic
simulations of the human-robot system. It is noted that the problem we face in
this study may be difficult to address by design methods based on classical
control theory as it is nearly impossible to obtain a customized mathematical
model of a human-robot system either online or offline. The results we have
obtained also indicate the great potential of RL control to solving realistic
and challenging problems with high dimensional control inputs.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:09:48 GMT""},{""version"":""v2"",""created"":""Sun, 17 Jan 2021 11:58:50 GMT""}]","2021-01-19"
"2006.09009","Xiaomin Zhang","Xiaomin Zhang, Xiaojin Zhu, Po-Ling Loh","Provable Training Set Debugging for Linear Regression",,,,,"cs.LG stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate problems in penalized $M$-estimation, inspired by applications
in machine learning debugging. Data are collected from two pools, one
containing data with possibly contaminated labels, and the other which is known
to contain only cleanly labeled points. We first formulate a general
statistical algorithm for identifying buggy points and provide rigorous
theoretical guarantees under the assumption that the data follow a linear
model. We then present two case studies to illustrate the results of our
general theory and the dependence of our estimator on clean versus buggy
points. We further propose an algorithm for tuning parameter selection of our
Lasso-based algorithm and provide corresponding theoretical guarantees.
Finally, we consider a two-person ""game"" played between a bug generator and a
debugger, where the debugger can augment the contaminated data set with cleanly
labeled versions of points in the original data pool. We establish a
theoretical result showing a sufficient condition under which the bug generator
can always fool the debugger. Nonetheless, we provide empirical results showing
that such a situation may not occur in practice, making it possible for natural
augmentation strategies combined with our Lasso debugging algorithm to succeed.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:14:44 GMT""},{""version"":""v2"",""created"":""Tue, 10 Aug 2021 03:42:03 GMT""}]","2021-08-11"
"2006.09010","Jun Yang","Lipeng Duan, Suting Wei and Jun Yang","Clustering of Boundary Interfaces for an inhomogeneous Allen-Cahn
  equation on a smooth bounded domain",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the inhomogeneous Allen-Cahn equation $$ \epsilon^2\Delta
u\,+\,V(y)(1-u^2)\,u\,=\,0\quad \mbox{in}\ \Omega, \qquad \frac {\partial
u}{\partial \nu}\,=\,0\quad \mbox{on}\ \partial \Omega, $$ where $\Omega$ is a
bounded domain in ${\mathbb R}^2$ with smooth boundary $\partial\Omega$ and
$V(x)$ is a positive smooth function, $\epsilon>0$ is a small parameter, $\nu$
denotes the unit outward normal of $\partial\Omega$. For any fixed integer
$N\geq 2$, we will show the existence of a clustered solution $u_{\epsilon}$
with $N$-transition layers near $\partial \Omega$ with mutual distance
$O(\epsilon|\ln \epsilon|)$, provided that the generalized mean curvature
$\mathcal{H} $ of $\partial\Omega$ is positive and $\epsilon$ stays away from a
discrete set of values at which resonance occurs. Our result is an extension of
those (with dimension two) by A. Malchiodi, W.-M. Ni, J. Wei in Pacific J.
Math. (Vol. 229, 2007, no. 2, 447-468) and A. Malchiodi, J. Wei in J. Fixed
Point Theory Appl. (Vol. 1, 2007, no. 2, 305-336)
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:15:30 GMT""}]","2020-06-17"
"2006.09011","Yang Song","Yang Song and Stefano Ermon","Improved Techniques for Training Score-Based Generative Models","NeurIPS 2020",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Score-based generative models can produce high quality image samples
comparable to GANs, without requiring adversarial optimization. However,
existing training procedures are limited to images of low resolution (typically
below 32x32), and can be unstable under some settings. We provide a new
theoretical analysis of learning and sampling from score models in high
dimensional spaces, explaining existing failure modes and motivating new
solutions that generalize across datasets. To enhance stability, we also
propose to maintain an exponential moving average of model weights. With these
improvements, we can effortlessly scale score-based generative models to images
with unprecedented resolutions ranging from 64x64 to 256x256. Our score-based
models can generate high-fidelity samples that rival best-in-class GANs on
various image datasets, including CelebA, FFHQ, and multiple LSUN categories.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:17:17 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 19:37:51 GMT""}]","2020-10-27"
"2006.09012","Andrea Cappozzo","Francesco Denti, Andrea Cappozzo and Francesca Greselin","A Two-Stage Bayesian Semiparametric Model for Novelty Detection with
  Robust Prior Information",,,"10.1007/s11222-021-10017-7",,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Novelty detection methods aim at partitioning the test units into already
observed and previously unseen patterns. However, two significant issues arise:
there may be considerable interest in identifying specific structures within
the novelty, and contamination in the known classes could completely blur the
actual separation between manifest and new groups. Motivated by these problems,
we propose a two-stage Bayesian semiparametric novelty detector, building upon
prior information robustly extracted from a set of complete learning units. We
devise a general-purpose multivariate methodology that we also extend to handle
functional data objects. We provide insights on the model behavior by
investigating the theoretical properties of the associated semiparametric
prior. From the computational point of view, we propose a suitable
$\boldsymbol{\xi}$-sequence to construct an independent slice-efficient sampler
that takes into account the difference between manifest and novelty components.
We showcase our model performance through an extensive simulation study and
applications on both multivariate and functional datasets, in which diverse and
distinctive unknown patterns are discovered.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:20:55 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 11:19:18 GMT""},{""version"":""v3"",""created"":""Thu, 17 Jun 2021 08:24:48 GMT""}]","2021-06-18"
"2006.09013","Luca Ferialdi Dr.","Luca Ferialdi, Angelo Bassi","CSL reduction rate for rigid bodies",,"Phys. Rev. A 102, 042213 (2020)","10.1103/PhysRevA.102.042213",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of spontaneous wave function collapse models, we investigate
the properties of the Continuous Spontaneous Localization (CSL) collapse rate
for rigid bodies. By exploiting the Euler-Maclaurin formula, we show that for
standard matter the rate for a continuous mass distribution accurately
reproduces the exact rate (i.e. the one for a point-like distribution). We
compare the exact rate with previous estimates in the literature and we asses
their validity. We find that the reduction rate displays a peculiar mass
difference effect, which we investigate and describe in detail. We show that
the recently proposed layering effect is a consequence of the mass difference
effect.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:26:42 GMT""}]","2020-10-21"
"2006.09014","Ting Xie","T. Xie (1), M. Lepers (2), R. Vexiau (1), A. Orban (3), O. Dulieu (1),
  and N. Bouloufa-Maafa (1)","Optical shielding of destructive chemical reactions between ultracold
  ground-state NaRb molecules",,"Phys. Rev. Lett. 125, 153202 (2020)","10.1103/PhysRevLett.125.153202",,"cond-mat.quant-gas physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a method to suppress the chemical reactions between ultracold
bosonic ground-state $^{23}$Na$^{87}$Rb molecules based on optical shielding.
By applying a laser with a frequency blue-detuned from the transition between
the lowest rovibrational level of the electronic ground state $X^1\Sigma^+
(v_X=0, j_X=0)$, and the long-lived excited level $b^3\Pi_0 (v_b=0, j_b=1)$,
the long-range dipole-dipole interaction between the colliding molecules can be
engineered, leading to a dramatic suppression of reactive and photoinduced
inelastic collisions, for both linear and circular laser polarizations. We
demonstrate that the spontaneous emission from $b^3\Pi_0 (v_b=0, j_b=1)$ does
not deteriorate the shielding process. This opens the possibility for a strong
increase of the lifetime of cold molecule traps, and for an efficient
evaporative cooling. We also anticipate that the proposed mechanism is valid
for alkali-metal diatomics with sufficiently large dipole-dipole interactions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:27:02 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2020 14:26:05 GMT""}]","2020-10-14"
"2006.09015","Isabella Deutsch","Isabella Deutsch and Gordon J. Ross","ABC Learning of Hawkes Processes with Missing or Noisy Event Times","Added comparison to literature",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The self-exciting Hawkes process is widely used to model events which occur
in bursts. However, many real world data sets contain missing events and/or
noisily observed event times, which we refer to as data distortion. The
presence of such distortion can severely bias the learning of the Hawkes
process parameters. To circumvent this, we propose modeling the distortion
function explicitly. This leads to a model with an intractable likelihood
function which makes it difficult to deploy standard parameter estimation
techniques. As such, we develop the ABC-Hawkes algorithm which is a novel
approach to estimation based on Approximate Bayesian Computation (ABC) and
Markov Chain Monte Carlo. This allows the parameters of the Hawkes process to
be learned in settings where conventional methods induce substantial bias or
are inapplicable. The proposed approach is shown to perform well on both real
and simulated data.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:28:05 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jan 2021 19:37:20 GMT""},{""version"":""v3"",""created"":""Wed, 2 Jun 2021 09:16:36 GMT""}]","2021-06-03"
"2006.09016","Dorien Herremans","Balamurali B T, Edwin Jonathan Aslim, Yun Shu Lynn Ng, Tricia Li,
  Chuen Kuo, Jacob Shihang Chen, Dorien Herremans, Lay Guat Ng, Jer-Ming Chen","Acoustic prediction of flowrate: varying liquid jet stream onto a free
  surface",,"Proceedings of the IEEE International Conference on Signal
  Processing and Communications (SPCOM), 2020",,,"physics.comp-ph cs.LG stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Information on liquid jet stream flow is crucial in many real world
applications. In a large number of cases, these flows fall directly onto free
surfaces (e.g. pools), creating a splash with accompanying splashing sounds.
The sound produced is supplied by energy interactions between the liquid jet
stream and the passive free surface. In this investigation, we collect the
sound of a water jet of varying flowrate falling into a pool of water, and use
this sound to predict the flowrate and flowrate trajectory involved. Two
approaches are employed: one uses machine-learning models trained using audio
features extracted from the collected sound to predict the flowrate (and
subsequently the flowrate trajectory). In contrast, the second method directly
uses acoustic parameters related to the spectral energy of the liquid-liquid
interaction to estimate the flowrate trajectory. The actual flowrate, however,
is determined directly using a gravimetric method: tracking the change in mass
of the pooling liquid over time. We show here that the two methods agree well
with the actual flowrate and offer comparable performance in accurately
predicting the flowrate trajectory, and accordingly offer insights for
potential real-life applications using sound.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:29:09 GMT""}]","2020-06-17"
"2006.09017","Zhan Yu","Zhan Yu, Daniel W. C. Ho","Estimates on Learning Rates for Multi-Penalty Distribution Regression",,,,,"cs.LG math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with functional learning by utilizing two-stage
sampled distribution regression. We study a multi-penalty regularization
algorithm for distribution regression under the framework of learning theory.
The algorithm aims at regressing to real valued outputs from probability
measures. The theoretical analysis on distribution regression is far from
maturity and quite challenging, since only second stage samples are observable
in practical setting. In the algorithm, to transform information from samples,
we embed the distributions to a reproducing kernel Hilbert space
$\mathcal{H}_K$ associated with Mercer kernel $K$ via mean embedding technique.
The main contribution of the paper is to present a novel multi-penalty
regularization algorithm to capture more features of distribution regression
and derive optimal learning rates for the algorithm. The work also derives
learning rates for distribution regression in the nonstandard setting
$f_{\rho}\notin\mathcal{H}_K$, which is not explored in existing literature.
Moreover, we propose a distribution regression-based distributed learning
algorithm to face large-scale data or information challenge. The optimal
learning rates are derived for the distributed learning algorithm. By providing
new algorithms and showing their learning rates, we improve the existing work
in different aspects in the literature.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:31:58 GMT""}]","2020-06-17"
"2006.09018","Gerald Williams","Ihechukwu Chinyere and Gerald Williams","Hyperbolicity of T(6) Cyclically Presented Groups","19 pages, 8 figures",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider groups defined by cyclic presentations where the defining word
has length three and the cyclic presentation satisfies the T(6) small
cancellation condition. We classify when these groups are hyperbolic. When
combined with known results, this completely classifies the hyperbolic T(6)
cyclically presented groups.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:35:25 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 13:55:35 GMT""}]","2021-10-22"
"2006.09019","Justinas Miseikis","Justinas Miseikis, Pietro Caroni, Patricia Duchamp, Alina Gasser,
  Rastislav Marko, Nelija Miseikiene, Frederik Zwilling, Charles de
  Castelbajac, Lucas Eicher, Michael Fruh, Hansruedi Fruh","Lio -- A Personal Robot Assistant for Human-Robot Interaction and Care
  Applications","Accepted submission at IEEE Robotics and Automation Letters (RA-L),
  submitted to IEEE IROS 2020",,"10.1109/LRA.2020.3007462",,"cs.RO cs.AI cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lio is a mobile robot platform with a multi-functional arm explicitly
designed for human-robot interaction and personal care assistant tasks. The
robot has already been deployed in several health care facilities, where it is
functioning autonomously, assisting staff and patients on an everyday basis.
Lio is intrinsically safe by having full coverage in soft artificial-leather
material as well as having collision detection, limited speed and forces.
Furthermore, the robot has a compliant motion controller. A combination of
visual, audio, laser, ultrasound and mechanical sensors are used for safe
navigation and environment understanding. The ROS-enabled setup allows
researchers to access raw sensor data as well as have direct control of the
robot. The friendly appearance of Lio has resulted in the robot being well
accepted by health care staff and patients. Fully autonomous operation is made
possible by a flexible decision engine, autonomous navigation and automatic
recharging. Combined with time-scheduled task triggers, this allows Lio to
operate throughout the day, with a battery life of up to 8 hours and recharging
during idle times. A combination of powerful on-board computing units provides
enough processing power to deploy artificial intelligence and deep
learning-based solutions on-board the robot without the need to send any
sensitive data to cloud services, guaranteeing compliance with privacy
requirements. During the COVID-19 pandemic, Lio was rapidly adjusted to perform
additional functionality like disinfection and remote elevated body temperature
detection. It complies with ISO13482 - Safety requirements for personal care
robots, meaning it can be directly tested and deployed in care facilities.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:37:44 GMT""}]","2020-07-20"
"2006.09020","Dinh T Binh","D. T. Binh, V. H. Binh, and H. N. Long","Bounds on Dipole Moments of hidden Dark Matter through kinetic mixing",,,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The existence of dark sectors, consisting of weakly-coupled particles that do
not interact with the known Standard Model forces, is theoretically and
phenomenologically motivated. The hidden particles are candidates for Dark
Matter and can interact with photon through electric dipole moment (EDM) and
magnetic dipole moment (MDM). We investigate the possibility a hidden sector's
Dark Matter which is charged under a hidden $U(1)_X$ gauge symmetry can
interact with photon at loop level. We evaluate the scattering cross section of
hidden Dirac fermion with nuclei and set bounds for dipole moment. Using the
results of the XENON1T experiment for direct detection of Dark Matter, we get
bounds of electromagnetic dipole moment $(\mu_\chi)$ for mass $m_\chi=100$ GeV
: $ 1.93448 \times 10^{-8}\mu_B \leq \mu_\chi \leq 1.9496 \times 10^{-8}\mu_B$
and electric dipole moment $(d_\chi): 3.3204 \times 10^{-23}e\mbox{.}cm \leq
d_\chi \leq 3.3464 \times 10^{-23}e\mbox{.}cm$. Using the condition of the
existence of dipole moment we constraint the kinetic mixing parameter $ 3\times
10^{-3} \leq \epsilon \leq 10^{-2}$ and the mass of the hidden $U(1)_X$ gauge
boson to be in the range of 5 GeV $\leq m_X \leq$ 9 GeV. Our results complement
previous works and are within detection capability of LHC.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:38:39 GMT""}]","2020-06-17"
"2006.09021","Bin Wu","Bin Wu, Chao Wang, Zhen-Ming Xu, Wen-Li Yang","Ruppeiner geometry and thermodynamic phase transition of the black hole
  in massive gravity","28 pages,7 figures; v2:minor changes, references added, match the
  published version","Eur. Phys. J. C 81, 626 (2021)","10.1140/epjc/s10052-021-09407-y",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The phase transition and thermodynamic geometry of a 4-dimensional AdS
topological charged black hole in de Rham, Gabadadze and Tolley (dRGT) massive
gravity have been studied. After introducing a normalized thermodynamic scalar
curvature, it is speculated that its value is related to the interaction
between the underlying black hole molecules if the black hole molecules exist.
We show that there does exist a crucial parameter given in terms of the
topology, charge, and massive parameters of the black hole, which characterizes
the thermodynamic properties of the black hole. It is found that when the
parameter is positive, the singlet large black hole phase does not exist for
sufficient low temperature and there is a weak repulsive interaction dominating
for the small black hole which is similar to the Reissner-Nordstr\""{o}m AdS
black hole; when the parameter is negative, an additional phase region
describing large black holes also implies a dominant repulsive interaction.
These constitute the distinguishable features of dRGT massive topological black
hole from those of the Reissner-Nordstr\""{o}m AdS black hole as well as the Van
der Waals fluid system.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:41:17 GMT""},{""version"":""v2"",""created"":""Sun, 29 Aug 2021 07:27:26 GMT""}]","2021-08-31"
"2006.09022","Shrey Dabhi","Shrey Dabhi and Manojkumar Parmar","NodeNet: A Graph Regularised Neural Network for Node Classification","7 pages, 5 figures",,,,"cs.SI cs.LG stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-world events exhibit a high degree of interdependence and connections,
and hence data points generated also inherit the linkages. However, the
majority of AI/ML techniques leave out the linkages among data points. The
recent surge of interest in graph-based AI/ML techniques is aimed to leverage
the linkages. Graph-based learning algorithms utilize the data and related
information effectively to build superior models. Neural Graph Learning (NGL)
is one such technique that utilizes a traditional machine learning algorithm
with a modified loss function to leverage the edges in the graph structure. In
this paper, we propose a model using NGL - NodeNet, to solve node
classification task for citation graphs. We discuss our modifications and their
relevance to the task. We further compare our results with the current state of
the art and investigate reasons for the superior performance of NodeNet.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:41:58 GMT""}]","2020-06-17"
"2006.09023","Jihong Zhu","Jihong Zhu, David Navarro-Alarcon, Robin Passama and Andrea Cherubini","Vision-based Manipulation of Deformable and Rigid Objects Using Subspace
  Projections of 2D Contours",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a unified vision-based manipulation framework using image
contours of deformable/rigid objects. Instead of using human-defined cues, the
robot automatically learns the features from processed vision data. Our method
simultaneously generates -- from the same data -- both, visual features and the
interaction matrix that relates them to the robot control inputs. Extraction of
the feature vector and control commands is done online and adaptively, with
little data for initialization. The method allows the robot to manipulate an
object without knowing whether it is rigid or deformable. To validate our
approach, we conduct numerical simulations and experiments with both deformable
and rigid objects.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:43:21 GMT""},{""version"":""v2"",""created"":""Mon, 10 Aug 2020 18:16:35 GMT""},{""version"":""v3"",""created"":""Tue, 4 May 2021 19:34:57 GMT""}]","2021-05-06"
"2006.09024","Jonathan Dubois Dr.","J. Dubois, C. Chandre, T. Uzer","Nonadiabatic effects in the double ionization of atoms driven by a
  circularly polarized laser pulse",,"Phys. Rev. E 102, 032218 (2020)","10.1103/PhysRevE.102.032218",,"physics.atom-ph nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the double ionization of atoms subjected to circularly polarized
(CP) laser pulses. We analyze two fundamental ionization processes: the
sequential (SDI) and non-sequential (NSDI) double ionization in the light of
the rotating frame (RF) which naturally embeds nonadiabatic effects in CP
pulses. We use and compare two adiabatic approximations: The adiabatic
approximation in the laboratory frame (LF) and the adiabatic approximation in
the RF. The adiabatic approximation in the RF encapsulates the energy
variations of the electrons on subcycle timescales happening in the LF and
this, by fully taking into account the ion-electron interaction. This allows us
to identify two nonadiabatic effects including the lowering of the threshold
intensity at which over-the-barrier ionization happens and the lowering of the
ionization time of the electrons. As a consequence, these nonadiabatic effects
facilitate over-the-barrier ionization and recollision-induced ionizations. We
analyze the outcomes of these nonadiabatic effects on the recollision
mechanism. We show that the laser envelope plays an instrumental role in a
recollision channel in CP pulses at the heart of NSDI.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:44:50 GMT""}]","2020-09-30"
"2006.09025","Evi Kopelowitz","Ohad Silbert, Yitzhak Peleg and Evi Kopelowitz","Model Agnostic Combination for Ensemble Learning",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ensemble of models is well known to improve single model performance. We
present a novel ensembling technique coined MAC that is designed to find the
optimal function for combining models while remaining invariant to the number
of sub-models involved in the combination. Being agnostic to the number of
sub-models enables addition and replacement of sub-models to the combination
even after deployment, unlike many of the current methods for ensembling such
as stacking, boosting, mixture of experts and super learners that lock the
models used for combination during training and therefore need retraining
whenever a new model is introduced into the ensemble. We show that on the
Kaggle RSNA Intracranial Hemorrhage Detection challenge, MAC outperforms
classical average methods, demonstrates competitive results to boosting via
XGBoost for a fixed number of sub-models, and outperforms it when adding
sub-models to the combination without retraining.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:44:58 GMT""}]","2020-06-17"
"2006.09026","Sergey Paston","S.A. Paston","Dark matter from non-relativistic embedding gravity","LaTeX, 11 pages. This version corresponds to the published one","Modern Physics Letters A, Vol. 36, No. 15, 2150101 (2021)","10.1142/S0217732321501017",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the possibility to explain the mystery of the dark matter through
the transition from General Relativity to embedding gravity. This modification
of gravity, which was proposed by Regge and Teitelboim, is based on a simple
string-inspired geometrical principle: our spacetime is considered here as a
4-dimensional surface in a flat bulk. We show that among the solutions of
embedding gravity, there is a class of solutions equivalent to solutions of GR
with an additional contribution of non-relativistic embedding matter, which can
serve as cold dark matter. We prove the stability of such type of solutions and
obtain an explicit form of the equations of motion of embedding matter in the
non-relativistic limit. According to them, embedding matter turns out to have a
certain self-interaction, which could be useful in the context of solving the
core-cusp problem that appears in the LambdaCDM model.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:46:56 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 09:19:03 GMT""}]","2021-06-08"
"2006.09027","Tobias Mittnacht","Tobias Mittnacht, Prince Gideon Kubendran Amos, Daniel Schneider and
  Britta Nestler","Morphological stability of three-dimensional cementite rods in
  polycrystalline system: A phase-field analysis",,,,,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformations accompanying shape-instability govern the morphological
configuration and distribution of the phases in a microstructure. Owing to the
influence of the microstructure on the properties of a material, the stability
of three-dimensional rods in a representative polycrystalline system is
extensively analysed. A multiphase-field model, which recovers the physical
laws and sharp-interface relations, and includes grain boundary diffusion, is
adopted to investigate the morphological evolution of the precipitate.
Moreover, the efficiency of the numerical approach is ensured by establishing
the volume-preserving chemical equilibrium through the incorporation TCFe8
(CALPHAD) data and solving phase-field evolution in the Allen-Cahn framework.
The morphological evolution of the rod in the multiphase system exhibits a
unique transformation mechanism which is significantly different from the
evolution of an isolated finite-structure. It is realised that, in a
polycrystalline arrangement, irrespective of the initial rod-size , the
shape-change begins with the energy-minimising events at the triple junctions.
This early transformation renders a characteristic morphology at the
longitudinal ends of the structure, which introduces sufficient driving-force
through the curvature-difference for the subsequent morphological changes. The
continued mass transfer to the terminations, ultimately, breaks-off the rod
into separate entities that are entangled in the grain boundary. With
increasing aspect ratio of the rod, it is identified that the source of mass
transfer, which turns into the ovulation site, shifts from the centre. This
increases the number of fragmentation events and introduces satellite particle.
A comprehensive understanding of the transformation kinetics and mechanism
governing the morphological evolution of the rods in a polycrystalline system
is rendered in this work.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:47:10 GMT""}]","2020-06-17"
"2006.09028","Thomas Gobet","Thomas Gobet, Ivan Marin","Hecke algebras of normalizers of parabolic subgroups","31 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of Hecke algebras of complex reflection groups, we prove that
the generalized Hecke algebras of normalizers of parabolic subgroups are
semidirect products, under suitable conditions on the parameters involved in
their definition.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:49:11 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 16:40:50 GMT""}]","2020-10-23"
"2006.09029","Jie An","Jie An, Tao Li, Haozhi Huang, Li Shen, Xuan Wang, Yongyi Tang, Jinwen
  Ma, Wei Liu, and Jiebo Luo","Real-time Universal Style Transfer on High-resolution Images via
  Zero-channel Pruning",,,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extracting effective deep features to represent content and style information
is the key to universal style transfer. Most existing algorithms use VGG19 as
the feature extractor, which incurs a high computational cost and impedes
real-time style transfer on high-resolution images. In this work, we propose a
lightweight alternative architecture - ArtNet, which is based on GoogLeNet, and
later pruned by a novel channel pruning method named Zero-channel Pruning
specially designed for style transfer approaches. Besides, we propose a
theoretically sound sandwich swap transform (S2) module to transfer deep
features, which can create a pleasing holistic appearance and good local
textures with an improved content preservation ability. By using ArtNet and S2,
our method is 2.3 to 107.4 times faster than state-of-the-art approaches. The
comprehensive experiments demonstrate that ArtNet can achieve universal,
real-time, and high-quality style transfer on high-resolution images
simultaneously, (68.03 FPS on 512 times 512 images).
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:50:14 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 03:37:40 GMT""}]","2020-06-24"
"2006.09030","Tobias Skovgaard Jepsen","Tobias Skovgaard Jepsen, Christian S. Jensen, Thomas Dyhre Nielsen","Relational Fusion Networks: Graph Convolutional Networks for Road
  Networks","IEEE Transactions on Intelligent Transportation Systems (2020). arXiv
  admin note: substantial text overlap with arXiv:1908.11567",,"10.1109/TITS.2020.3011799",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The application of machine learning techniques in the setting of road
networks holds the potential to facilitate many important intelligent
transportation applications. Graph Convolutional Networks (GCNs) are neural
networks that are capable of leveraging the structure of a network. However,
many implicit assumptions of GCNs do not apply to road networks. We introduce
the Relational Fusion Network (RFN), a novel type of GCN designed specifically
for road networks. In particular, we propose methods that outperform
state-of-the-art GCNs by 21%-40% on two machine learning tasks in road
networks. Furthermore, we show that state-of-the-art GCNs may fail to
effectively leverage road network structure and may not generalize well to
other road networks.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:51:43 GMT""},{""version"":""v2"",""created"":""Mon, 14 Sep 2020 14:47:58 GMT""}]","2020-09-16"
"2006.09031","Leo Margolis","Andreas B\""achle, Leo Margolis","From examples to methods: Two cases from the study of units in integral
  group rings","To appear in a special volume on the topics of the academic activity
  at Group Algebras, Representations and Computation 2019 held at the ICTS
  Bangalore. 18 pages",,,,"math.RA math.GR math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we review the proofs of the first Zassenhaus Conjecture on
conjugacy of torsion units in integral group rings for the alternating groups
of degree 5 and 6, by Luthar-Passi and Hertweck. We describe how the study of
these examples led to the development of two methods -- the HeLP method and the
lattice method. We exhibit these methods and summarize some results which were
achieved using them. We then apply these methods to the study of the first
Zassenhaus conjecture for the alternating group of degree 7 where only one
critical case remains open for a full answer. Along the way we show in examples
how recently obtained results can be combined with the methods presented and
collect open problems some of which could be attacked using these methods.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:54:38 GMT""}]","2020-06-17"
"2006.09032","Ahsanul Kabir","Ahsanul Kabir, Jacob R. Bowen, Maxim Varenik, Igor Lubomirsky,
  Vincenzo Esposito","Enhanced Electromechanical Response in Defective Sm and Nd Co-doped
  Ceria",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Highly oxygen defective cerium oxide, e.g. Gd-doped ceria is a sustainable
non-classical electrostrictor with electromechanical properties that are
superior to lead-based piezoelectric metal oxides. Here, we report
electrostriction in co-doped ceria (Sm, Nd) with a nominally low short-range
vacancy-dopant association energy. Such a strategy results in a higher
electrostrictive strain coefficient at lower-frequencies, and unexpected
electromechanical strain saturation and relaxation effects. These outcomes
support the hypothesis that electrostriction is strongly influenced by the
local environment of oxygen vacancy and by the ionic migration blocking factors
built-in the microstructure.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:54:56 GMT""}]","2020-06-17"
"2006.09033","Axel B\""ohm","Axel B\""ohm, Michael Sedlmayer, Ern\""o Robert Csetnek, Radu Ioan
  Bo\c{t}","Two steps at a time -- taking GAN training in stride with Tseng's method","19 pages, 5 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the training of Generative Adversarial Networks (GANs), we study
methods for solving minimax problems with additional nonsmooth regularizers. We
do so by employing \emph{monotone operator} theory, in particular the
\emph{Forward-Backward-Forward (FBF)} method, which avoids the known issue of
limit cycling by correcting each update by a second gradient evaluation.
Furthermore, we propose a seemingly new scheme which recycles old gradients to
mitigate the additional computational cost. In doing so we rediscover a known
method, related to \emph{Optimistic Gradient Descent Ascent (OGDA)}. For both
schemes we prove novel convergence rates for convex-concave minimax problems
via a unifying approach. The derived error bounds are in terms of the gap
function for the ergodic iterates. For the deterministic and the stochastic
problem we show a convergence rate of $\mathcal{O}(1/k)$ and
$\mathcal{O}(1/\sqrt{k})$, respectively. We complement our theoretical results
with empirical improvements in the training of Wasserstein GANs on the CIFAR10
dataset.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:55:06 GMT""}]","2020-06-17"
"2006.09034","Jesper Christensen","Jesper Haahr Christensen, Lars Valdemar Mogensen, Ole Ravn","Deep Learning based Segmentation of Fish in Noisy Forward Looking MBES
  Images",,,,,"cs.CV cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this work, we investigate a Deep Learning (DL) approach to fish
segmentation in a small dataset of noisy low-resolution images generated by a
forward-looking multibeam echosounder (MBES). We build on recent advances in DL
and Convolutional Neural Networks (CNNs) for semantic segmentation and
demonstrate an end-to-end approach for a fish/non-fish probability prediction
for all range-azimuth positions projected by an imaging sonar. We use
self-collected datasets from the Danish Sound and the Faroe Islands to train
and test our model and present techniques to obtain satisfying performance and
generalization even with a low-volume dataset. We show that our model proves
the desired performance and has learned to harness the importance of semantic
context and take this into account to separate noise and non-targets from real
targets. Furthermore, we present techniques to deploy models on low-cost
embedded platforms to obtain higher performance fit for edge environments -
where compute and power are restricted by size/cost - for testing and
prototyping.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:57:38 GMT""}]","2020-06-17"
"2006.09035","Miao Li","Miao Li, Haoqi Xiong, Yunbo Cao (Smart Platform Product Department,
  Tencent Inc, China)","The SPPD System for Schema Guided Dialogue State Tracking Challenge",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces one of our group's work on the Dialog System Technology
Challenges 8 (DSTC8), the SPPD system for Schema Guided dialogue state tracking
challenge. This challenge, named as Track 4 in DSTC8, provides a brand new and
challenging dataset for developing scalable multi-domain dialogue state
tracking algorithms for real world dialogue systems. We propose a zero-shot
dialogue state tracking system for this task. The key components of the system
is a number of BERT based zero-shot NLU models that can effectively capture
semantic relations between natural language descriptions of services' schemas
and utterances from dialogue turns. We also propose some strategies to make the
system better to exploit information from longer dialogue history and to
overcome the slot carryover problem for multi-domain dialogues. The
experimental results show that the proposed system achieves a significant
improvement compared with the baseline system.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:57:40 GMT""}]","2020-06-17"
"2006.09036","Shin-Ichiro Seki","Minoru Hirose, Nobuo Sato, Shin-ichiro Seki","The connector for Double Ohno relation","9 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a new connector which generalizes the connector
found by the third author and Yamamoto. The new connector gives a direct proof
of the double Ohno relation recently proved by the first author, the second
author, Murahara, and Onozuka. Furthermore, we obtain a simultaneous
generalization of the ($q$-)Ohno relation and the ($q$-)double Ohno relation.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:57:40 GMT""}]","2020-06-17"
"2006.09037","Pierre Bruneel","Pierre Bruneel, Marc Gabay","Spin texture driven spintronic enhancement at the LaAlO$_3$/SrTiO$_3$
  interface","5 pages, 2 figures","Phys. Rev. B 102, 144407 (2020)","10.1103/PhysRevB.102.144407",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experiments have shown that transition metal oxide heterostructures
such as SrTiO$_3$-based interfaces, exhibit large, gate tunable, spintronic
responses. Our theoretical study showcases key factors controlling the
magnitude of the conversion, measured by the inverse Edelstein and Spin Hall
effects, and their evolution with respect to an electrostatic doping. The
origin of the response can be linked to spin-orbital textures. These stem from
the broken inversion symmetry at the interface which produces an unusual form
of the interfacial spin-orbit coupling, provided a bulk atomic spin-orbit
contribution is present. The amplitudes and variations of these observables are
direct consequences of the multi-orbital subband structure of these materials,
featuring avoided and topological crossings. Interband contributions to the
coefficients lead to enhanced responses and non-monotonic evolution with
doping. We highlight these effects using analytical approaches and low energy
modeling.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:58:13 GMT""}]","2020-10-14"
"2006.09038","Tian-Min Yan","Junyang Yuan, Shiwei Liu, Xincheng Wang, Zhenjie Shen, Yixuan Ma,
  Huanyu Ma, Qiuxiang Meng, Tian-Min Yan, Yizhu Zhang, Alexander Dorn, Matthias
  Weidem\""uller, Difa Ye, Yuhai Jiang","Ellipticity-dependent sequential over-barrier ionization of cold
  rubidium",,"Phys. Rev. A 102, 043112 (2020)","10.1103/PhysRevA.102.043112",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform high-resolution measurements of momentum distribution on Rb$^{n+}$
recoil ions up to charge state $n=4$, where laser-cooled rubidium atoms are
ionized by femtosecond elliptically polarized lasers with the pulse duration of
35 fs and the intensity of 3.3$\times$10$^{15}$ W/cm$^2$ in the over-barrier
ionization (OBI) regime. The momentum distributions of the recoil ions are
found to exhibit multi-band structures as the ellipticity varies from the
linear to circular polarizations. The origin of these band structures can be
explained quantitatively by the classical OBI model and dedicated classical
trajectory Monte Carlo simulations with Heisenberg potential. Specifically,
with back analysis of the classical trajectories, we reveal the ionization time
and the OBI geometry of the sequentially released electrons, disentangling the
mechanisms behind the tilted angle of the band structures. These results
indicate that the classical treatment can describe the strong-field multiple
ionization processes of alkali atoms.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:58:44 GMT""}]","2020-10-28"
"2006.09039","Micha{\l} Farnik","Micha{\l} Farnik and Zbigniew Jelonek","On stable polynomial mappings",,,,,"math.AG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For given natural numbers $d_1,d_2$ let $\Omega_2(d_1,d_2)$ be the set off
all polynomial mappings $F=(f,g):\mathbb{C}^2\to\mathbb{C}^2$ such that deg
$f\le d_1$, deg $g\le d_2$. We say that the mapping $F$ is topologically stable
in $\Omega_2(d_1,d_2)$ if for every small deformation $F_t\in
\Omega_2(d_1,d_2)$ the mapping $F_t$ is topologically equivalent to the mapping
$F$. The aim of this paper is to characterize the topologically stable mappings
in $\Omega_2(d_1,d_2)$. In particular we show how to effectively determine a
member of $\Omega_2(d_1,d_2)$ with generic topology.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:00:12 GMT""}]","2020-06-17"
"2006.09040","Christopher Brix","Christopher Brix, Thomas Noll","Debona: Decoupled Boundary Network Analysis for Tighter Bounds and
  Faster Adversarial Robustness Proofs",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural networks are commonly used in safety-critical real-world applications.
Unfortunately, the predicted output is often highly sensitive to small, and
possibly imperceptible, changes to the input data. Proving that either no such
adversarial examples exist, or providing a concrete instance, is therefore
crucial to ensure safe applications. As enumerating and testing all potential
adversarial examples is computationally infeasible, verification techniques
have been developed to provide mathematically sound proofs of their absence
using overestimations of the network activations. We propose an improved
technique for computing tight upper and lower bounds of these node values,
based on increased flexibility gained by computing both bounds independently of
each other. Furthermore, we gain an additional improvement by re-implementing
part of the original state-of-the-art software ""Neurify"", leading to a faster
analysis. Combined, these adaptations reduce the necessary runtime by up to
94%, and allow a successful search for networks and inputs that were previously
too complex. We provide proofs for tight upper and lower bounds on max-pooling
layers in convolutional networks. To ensure widespread usability, we open
source our implementation ""Debona"", featuring both the implementation specific
enhancements as well as the refined boundary computation for faster and more
exact~results.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:00:33 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 16:53:29 GMT""}]","2021-02-03"
"2006.09041","Andreas Rupp","Andreas Rupp, Moritz Hauck, Vadym Aizinger","A subcell-enriched Galerkin method for advection problems",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we introduce a generalization of the enriched Galerkin (EG)
method. The key feature of our scheme is an adaptive two-mesh approach that, in
addition to the standard enrichment of a conforming finite element
discretization via discontinuous degrees of freedom, allows to subdivide
selected (e.g. troubled) mesh cells in a non-conforming fashion and to use
further discontinuous enrichment on this finer submesh. We prove stability and
sharp a priori error estimates for a linear advection equation by using a
specially tailored projection and conducting some parts of a standard
convergence analysis for both meshes. By allowing an arbitrary degree of
enrichment on both, the coarse and the fine mesh (also including the case of no
enrichment), our analysis technique is very general in the sense that our
results cover the range from the standard continuous finite element method to
the standard discontinuous Galerkin (DG) method with (or without) local subcell
enrichment. Numerical experiments confirm our analytical results and indicate
good robustness of the proposed method.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:00:40 GMT""}]","2020-06-17"
"2006.09042","Muhammad Suhaib Tanveer","Muhammad Suhaib Tanveer, Muhammad Umar Karim Khan, Chong-Min Kyung","Fine-Tuning DARTS for Image Classification","8 pages, 6 figures",,,,"cs.CV cs.AI cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural Architecture Search (NAS) has gained attraction due to superior
classification performance. Differential Architecture Search (DARTS) is a
computationally light method. To limit computational resources DARTS makes
numerous approximations. These approximations result in inferior performance.
We propose to fine-tune DARTS using fixed operations as they are independent of
these approximations. Our method offers a good trade-off between the number of
parameters and classification accuracy. Our approach improves the top-1
accuracy on Fashion-MNIST, CompCars, and MIO-TCD datasets by 0.56%, 0.50%, and
0.39%, respectively compared to the state-of-the-art approaches. Our approach
performs better than DARTS, improving the accuracy by 0.28%, 1.64%, 0.34%,
4.5%, and 3.27% compared to DARTS, on CIFAR-10, CIFAR-100, Fashion-MNIST,
CompCars, and MIO-TCD datasets, respectively.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:00:45 GMT""}]","2020-11-17"
"2006.09043","Maurice Quach","Maurice Quach, Giuseppe Valenzise, Frederic Dufaux","Improved Deep Point Cloud Geometry Compression","Code is available at https://github.com/mauriceqch/pcc_geo_cnn_v2",,,,"cs.CV cs.LG eess.IV eess.SP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Point clouds have been recognized as a crucial data structure for 3D content
and are essential in a number of applications such as virtual and mixed
reality, autonomous driving, cultural heritage, etc. In this paper, we propose
a set of contributions to improve deep point cloud compression, i.e.: using a
scale hyperprior model for entropy coding; employing deeper transforms; a
different balancing weight in the focal loss; optimal thresholding for
decoding; and sequential model training. In addition, we present an extensive
ablation study on the impact of each of these factors, in order to provide a
better understanding about why they improve RD performance. An optimal
combination of the proposed improvements achieves BD-PSNR gains over G-PCC
trisoup and octree of 5.50 (6.48) dB and 6.84 (5.95) dB, respectively, when
using the point-to-point (point-to-plane) metric. Code is available at
https://github.com/mauriceqch/pcc_geo_cnn_v2 .
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:03:14 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 12:56:23 GMT""}]","2020-06-25"
"2006.09044","Austen Lamacraft","Ariel Barr, Willem Gispen, Austen Lamacraft","Quantum Ground States from Reinforcement Learning","Accepted at MSML 2020",,,,"quant-ph cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding the ground state of a quantum mechanical system can be formulated as
an optimal control problem. In this formulation, the drift of the optimally
controlled process is chosen to match the distribution of paths in the
Feynman--Kac (FK) representation of the solution of the imaginary time
Schr\""odinger equation. This provides a variational principle that can be used
for reinforcement learning of a neural representation of the drift. Our
approach is a drop-in replacement for path integral Monte Carlo, learning an
optimal importance sampler for the FK trajectories. We demonstrate the
applicability of our approach to several problems of one-, two-, and
many-particle physics.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:04:28 GMT""}]","2020-06-17"
"2006.09045","Ahsanul Kabir","Ahsanul Kabir, Daoyao Ke, Salvatore Grasso, Benoit Merle and Vincenzo
  Esposito","Effect of Cold Sintering Process (CSP) on the Electro-Chemo-Mechanical
  Properties of Gd-doped Ceria (GDC)",,,,,"cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this report, the effect of the cold sintering process (CSP) on the
electro-chemo-mechanical properties of 10 mol% Gd-doped ceria (GDC) is
investigated. High purity nanoscale GDC powder is sintered via a cold sintering
process (CSP) in pure water followed by post-annealing at 1000 {\deg}C. The
resultant CSP ceramics exhibits high relative density (~92%) with an ultrafine
grain size of ~100 nm. This sample illustrates comparable electrochemical
properties at intermediate/high temperatures and electromechanical properties
at room temperature to the sample prepared via conventional firing, i.e.
sintering in the air at 1450 {\deg}C. Moreover, a large creep constant as well
as a low elastic modulus and hardness are also observed in the CSP sample.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:04:36 GMT""}]","2020-06-17"
"2006.09046","Jeppe N{\o}rregaard","Jeppe N{\o}rregaard and Lars Kai Hansen","Probabilistic Decoupling of Labels in Classification","Submitted to ICML 2020 (not accepted)",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we develop a principled, probabilistic, unified approach to
non-standard classification tasks, such as semi-supervised,
positive-unlabelled, multi-positive-unlabelled and noisy-label learning. We
train a classifier on the given labels to predict the label-distribution. We
then infer the underlying class-distributions by variationally optimizing a
model of label-class transitions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:07:50 GMT""}]","2020-06-17"
"2006.09047","Jos\'e Lu\'is da Silva Dr.","Yuri Kondratiev and Jos\'e L. da Silva","Random potentials for Markov processes","12 pages. arXiv admin note: text overlap with arXiv:2006.07514","Applicable Analysis, 2022","10.1080/00036811.2022.2101453",,"math.PR math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper is devoted to the integral functionals $\int_0^\infty
f(X_t)\,{\mathrm{d}t}$ of Markov processes in $\X$ in the case $d\ge 3$. It is
established that such functionals can be presented as the integrals $\int_{\X}
f(y) \G(x, \mathrm{d}y, \omega)$ with vector valued random measure $\G(x,
\mathrm{d}y, \omega)$. Some examples such as compound Poisson processes,
Brownian motion and diffusions are considered.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:10:12 GMT""}]","2022-07-20"
"2006.09048","Tianyu Liu","Zheng Shi, Hai-Zhou Lu, and Tianyu Liu","Pseudo Landau levels, negative strain resistivity, and enhanced
  thermopower in twisted graphene nanoribbons","13 pages, 7 figures; More data and figures added compared to v1; a
  new author added; published version","Phys. Rev. Research 3, 033139 (2021)","10.1103/PhysRevResearch.3.033139",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a canonical response to the applied magnetic field, the electronic states
of a metal are fundamentally reorganized into Landau levels. In Dirac metals,
Landau levels can be expected without magnetic fields, provided that an
inhomogeneous strain is applied to spatially modulate electron hoppings in a
similar way as the Aharonov-Bohm phase. We here predict that a twisted zigzag
nanoribbon of graphene exhibits strain-induced pseudo Landau levels of
unexplored but analytically solvable dispersions at low energies. The presence
of such dispersive pseudo Landau levels results in a negative strain
resistivity characterizing the $(1+1)$-dimensional chiral anomaly if partially
filled and can greatly enhance the thermopower when fully filled.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:13:59 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 08:41:27 GMT""}]","2021-08-13"
"2006.09049","Aditya Rajagopal","Aditya Rajagopal, Diederik Adriaan Vink, Stylianos I. Venieris,
  Christos-Savvas Bouganis","Multi-Precision Policy Enforced Training (MuPPET): A precision-switching
  strategy for quantised fixed-point training of CNNs","Accepted at the 37th International Conference on Machine Learning
  (ICML), 2020",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale convolutional neural networks (CNNs) suffer from very long
training times, spanning from hours to weeks, limiting the productivity and
experimentation of deep learning practitioners. As networks grow in size and
complexity, training time can be reduced through low-precision data
representations and computations. However, in doing so the final accuracy
suffers due to the problem of vanishing gradients. Existing state-of-the-art
methods combat this issue by means of a mixed-precision approach utilising two
different precision levels, FP32 (32-bit floating-point) and FP16/FP8
(16-/8-bit floating-point), leveraging the hardware support of recent GPU
architectures for FP16 operations to obtain performance gains. This work pushes
the boundary of quantised training by employing a multilevel optimisation
approach that utilises multiple precisions including low-precision fixed-point
representations. The novel training strategy, MuPPET, combines the use of
multiple number representation regimes together with a precision-switching
mechanism that decides at run time the transition point between precision
regimes. Overall, the proposed strategy tailors the training process to the
hardware-level capabilities of the target hardware architecture and yields
improvements in training time and energy efficiency compared to
state-of-the-art approaches. Applying MuPPET on the training of AlexNet,
ResNet18 and GoogLeNet on ImageNet (ILSVRC12) and targeting an NVIDIA Turing
GPU, MuPPET achieves the same accuracy as standard full-precision training with
training-time speedup of up to 1.84$\times$ and an average speedup of
1.58$\times$ across the networks.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:14:36 GMT""}]","2020-06-18"
"2006.09050","Sergio Vitale","Sergio Vitale, Giampaolo Ferraioli and Vito Pascazio","Multi-Objective CNN Based Algorithm for SAR Despeckling",,"IEEE Transactions on Geoscience and Remote Sensing, (2020) 1-14","10.1109/TGRS.2020.3034852",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning (DL) in remote sensing has nowadays become an effective
operative tool: it is largely used in applications such as change detection,
image restoration, segmentation, detection and classification. With reference
to synthetic aperture radar (SAR) domain the application of DL techniques is
not straightforward due to non trivial interpretation of SAR images, specially
caused by the presence of speckle. Several deep learning solutions for SAR
despeckling have been proposed in the last few years. Most of these solutions
focus on the definition of different network architectures with similar cost
functions not involving SAR image properties. In this paper, a convolutional
neural network (CNN) with a multi-objective cost function taking care of
spatial and statistical properties of the SAR image is proposed. This is
achieved by the definition of a peculiar loss function obtained by the weighted
combination of three different terms. Each of this term is dedicated mainly to
one of the following SAR image characteristics: spatial details, speckle
statistical properties and strong scatterers identification. Their combination
allows to balance these effects. Moreover, a specifically designed architecture
is proposed for effectively extract distinctive features within the considered
framework. Experiments on simulated and real SAR images show the accuracy of
the proposed method compared to the State-of-Art despeckling algorithms, both
from quantitative and qualitative point of view. The importance of considering
such SAR properties in the cost function is crucial for a correct noise
rejection and details preservation in different underlined scenarios, such as
homogeneous, heterogeneous and extremely heterogeneous.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:15:42 GMT""},{""version"":""v2"",""created"":""Wed, 19 Aug 2020 09:43:02 GMT""},{""version"":""v3"",""created"":""Fri, 21 Aug 2020 16:24:45 GMT""},{""version"":""v4"",""created"":""Fri, 30 Oct 2020 13:55:51 GMT""}]","2020-11-19"
"2006.09051","Eugenia Usenko Leonidovna","V.A. Sorokin, V.A. Valeev, E.L. Usenko, V.A. Karachevtsev","Mg2+ ion effect on stability of double-stranded popynucleotide formed by
  polyriboinosinic and polyribocytidilic chains","9 pages, 3 figures","Biophysical Bulletin, 2, 68, 2005 (in russian)",,,"physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mg2+ effect on the thermal stability of the double-stranded polynucleotide
polyIpolyC (IC) under conditions close to physiological ones (0.1M Na+, pH7)
was studied by the differential UV spectroscopy. The initial increase of the
ion concentration ([Mg2+]) leads to the increase of the melting temperature
(Tm) and to the decrease of the absorption hyperchromicity value that is caused
by the helix-coil transition (hmax). Mg2+ interacts to p-electrons of
hypoxanthine or cytosine rings (cation-p-interaction). When [Mg2+] reaches a
critical value of about 10-4 M, Tm decreases and hmax increase to values close
to one observed in the absence of magnesium. It is supposed that at
[Mg2+]=[Mg2+]cr IC transits into a new structural state. With [Mg2+>[Mg2+]cr Tm
increases again and hmax slowly decreases. Key words: polynucleotides, thermal
stability, metal ions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:15:47 GMT""}]","2020-06-28"
"2006.09052","Werner Herr","Werner Herr","Mathematical and Numerical Methods for Non-linear Beam Dynamics","39 pages, 12 figures. Proceedings of the 2018
  CERN--Accelerator--School course on Numerical Methods for Analysis, Design
  and Modelling of Particle Accelerators, Thessaloniki, (Greece). arXiv admin
  note: text overlap with arXiv:1601.05411",,,,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most severe limitations in particle accelerators and beam
transport are non-linear effects. Techniques to study and possibly suppress
some of these detrimental effects exist, the most popular are based on particle
tracking and its analysis. This lecture is an introduction to the topic, shows
some of the problems and presents several contemporary tools to treat them
using a systematic and consistent approach.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:17:08 GMT""}]","2020-06-17"
"2006.09053","Robertus Potting","Nenad Manojlovic, Volker Perlick and Robertus Potting","Standing wave solutions in Born-Infeld theory",,"Ann. Phys. (NY) 422, 168303 (2020)","10.1016/j.aop.2020.168303",,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study standing-wave solutions of Born-Infeld electrodynamics, with nonzero
electromagnetic field in a region between two parallel conducting plates. We
consider the simplest case which occurs when the vector potential describing
the electromagnetic field has only one nonzero component depending on time and
on the coordinate perpendicular to the plates. The problem then reduces to
solving the scalar Born-Infeld equation, a nonlinear partial differential
equation in 1+1 dimensions. We apply two alternative methods to obtain
standing-wave solutions to the Born-Infeld equation: an iterative method, and a
``minimal surface'' method. We also study standing wave solutions in a uniform
constant magnetic field background.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:18:33 GMT""},{""version"":""v2"",""created"":""Sat, 27 Jun 2020 15:24:57 GMT""}]","2021-03-25"
"2006.09054","Amrutha Prasad","Amrutha Prasad, Petr Motlicek, Srikanth Madikeri","Quantization of Acoustic Model Parameters in Automatic Speech
  Recognition Framework","Submitted to ICASSP21",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State-of-the-art hybrid automatic speech recognition (ASR) system exploits
deep neural network (DNN) based acoustic models (AM) trained with Lattice
Free-Maximum Mutual Information (LF-MMI) criterion and n-gram language models.
The AMs typically have millions of parameters and require significant parameter
reduction to operate on embedded devices. The impact of parameter quantization
on the overall word recognition performance is studied in this paper. Following
approaches are presented: (i) AM trained in Kaldi framework with conventional
factorized TDNN (TDNN-F) architecture, (ii) the TDNN AM built in Kaldi loaded
into the PyTorch toolkit using a C++ wrapper for post-training quantization,
(iii) quantization-aware training in PyTorch for Kaldi TDNN model, (iv)
quantization-aware training in Kaldi. Results obtained on standard Librispeech
setup provide an interesting overview of recognition accuracy w.r.t. applied
quantization scheme.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:19:23 GMT""},{""version"":""v2"",""created"":""Fri, 20 Nov 2020 12:08:48 GMT""}]","2020-11-23"
"2006.09055","Indranil Biswas","Indranil Biswas and Sorin Dumitrescu","Nonabelian Hodge theory for Fujiki class $\mathcal C$ manifolds","Final version",,,,"math.AG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nonabelian Hodge correspondence (Corlette-Simpson correspondence),
between the polystable Higgs bundles with vanishing Chern classes on a compact
K\""ahler manifold $X$ and the completely reducible flat connections on $X$, is
extended to the Fujiki class $\mathcal C$ manifolds.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:19:50 GMT""},{""version"":""v2"",""created"":""Thu, 22 Sep 2022 18:15:43 GMT""}]","2022-09-26"
"2006.09056","Michele Correggi","Michele Correggi, Davide Fermi","Magnetic Perturbations of Anyonic and Aharonov-Bohm Schr\""{o}dinger
  Operators","28 pages, final version, to appear in J. Math. Phys., pdfLaTex","J. Math. Phys. 62(3) (2021), 032101","10.1063/5.0018933",,"math-ph cond-mat.quant-gas math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Hamiltonian describing two anyons moving in a plane in presence
of an external magnetic field and identify a one-parameter family of
self-adjoint realizations of the corresponding Schr\""{o}dinger operator. We
also discuss the associated model describing a quantum particle immersed in a
magnetic field with a local Aharonov-Bohm singularity. For a special class of
magnetic potentials, we provide a complete classification of all possible
self-adjoint extensions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:21:04 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 08:45:35 GMT""},{""version"":""v3"",""created"":""Fri, 19 Feb 2021 16:34:35 GMT""}]","2021-04-09"
"2006.09057","Ji Qiang","Ji Qiang","Multi-Particle Simulation Techniques","21 pages, 14 figures. Proceedings of the 2018
  CERN--Accelerator--School course on Numerical Methods for Analysis, Design
  and Modelling of Particle Accelerators, Thessaloniki, (Greece). arXiv admin
  note: substantial text overlap with arXiv:1801.05288",,,,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nonlinear space-charge effects play an important role in high
intensity/high brightness accelerators. These effects can be self-consistently
studied using multi-particle simulations. In this lecture, we will discuss the
particle-in-cell method and the symplectic tracking model for self-consistent
multi-particle simulations.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:29:00 GMT""}]","2020-06-17"
"2006.09058","Jan Kunes","A. Niyazi, D. Geffroy and J. Kune\v{s}","Dynamical response and competing orders in two-band Hubbard model","8 pages, 9 figures","Phys. Rev. B 102, 085159 (2020)","10.1103/PhysRevB.102.085159",,"cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a dynamical mean-field study of two-particle dynamical response
functions in two-band Hubbard model across several phase transitions. We
observe that the transition between theexcitonic condensate and spin-state
ordered state is continuous with a narrow strip of supersolidphase separating
the two. Approaching transition from the excitonic condensate is announced
bysoftening of the excitonic mode at theMpoint of the Brillouin zone. Inside
the spin-state orderedphase there is a magnetically ordered state with 2x2
periodicity, which has no precursor in thenormal phase.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:30:42 GMT""}]","2020-09-09"
"2006.09059","Fr\'ed\'eric Ouimet","Fr\'ed\'eric Ouimet","Explicit formulas for the joint third and fourth central moments of the
  multinomial distribution","7 pages, 0 figure",,,,"stat.OT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give the first explicit formulas for the joint third and fourth central
moments of the multinomial distribution, by differentiating the moment
generating function. A general formula for the joint factorial moments was
previously given in Mosimann (1962).
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:36:06 GMT""},{""version"":""v2"",""created"":""Fri, 25 Dec 2020 08:33:40 GMT""}]","2020-12-29"
"2006.09060","Andr\'e Guerra","Daniel Faraco, Andr\'e Guerra","Remarks on Ornstein's non-inequality in $\mathbb{R}^{2\times 2}$","v2: small corrections and change to title","The Quarterly Journal of Mathematics, 2021","10.1093/qmath/haab016",,"math.AP math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a very concise proof of Ornstein's $L^1$ non-inequality for first-
and second-order operators in two dimensions. The proof just needs a
two-dimensional laminate supported on three points.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:40:20 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2021 18:28:55 GMT""}]","2021-03-22"
"2006.09061","Jack Jewson","Beniamino Hadj-Amar, Jack Jewson and Mark Fiecas","Bayesian Approximations to Hidden Semi-Markov Models for Telemetric
  Monitoring of Physical Activity","Paper to appear in Bayesian Analysis",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a Bayesian hidden Markov model for analyzing time series and
sequential data where a special structure of the transition probability matrix
is embedded to model explicit-duration semi-Markovian dynamics. Our formulation
allows for the development of highly flexible and interpretable models that can
integrate available prior information on state durations while keeping a
moderate computational cost to perform efficient posterior inference. We show
the benefits of choosing a Bayesian approach for HSMM estimation over its
frequentist counterpart, in terms of model selection and out-of-sample
forecasting, also highlighting the computational feasibility of our inference
procedure whilst incurring negligible statistical error. The use of our
methodology is illustrated in an application relevant to e-Health, where we
investigate rest-activity rhythms using telemetric activity data collected via
a wearable sensing device. This analysis considers for the first time Bayesian
model selection for the form of the explicit state dwell distribution. We
further investigate the inclusion of a circadian covariate into the emission
density and estimate this in a data-driven manner.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:41:59 GMT""},{""version"":""v2"",""created"":""Fri, 20 May 2022 16:39:39 GMT""}]","2022-05-23"
"2006.09062","Xun Chen Mr","Jing Zhou, Xun Chen, Yan-Qing Zhao, Jialun Ping","Thermodynamics of heavy quarkonium in magnetic field background","21 pages, 13 figures","Phys. Rev. D 102, 086020 (2020)","10.1103/PhysRevD.102.086020",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the effect of magnetic field on heavy quark-antiquark pair in both
Einstein-Maxwell(EM) and Einstein-Maxwell-Dilaton(EMD) model. The interquark
distance, free energy, entropy, binding energy and internal energy of the heavy
quarkonium are calculated. It is found that the free energy suppresses and the
entropy increases quickly with the increase of the magnetic field $B$. The
binding energy vanishes at smaller distance when increasing the magnetic field,
which indicates the quark-antiquark pair dissociates at smaller distance. The
internal energy which consists of free energy and entropy will increase at
large separating distance for non-vanishing magnetic field. These conclusions
are consistent both in the EM and EMD model. Moreover, we also find that the
quarkonium will dissociate easier in the parallel direction than that in the
transverse direction for EMD model, but the conclusion is opposite in EM model.
Lattice results are in favor of EMD model. Besides, a Coulomb-plus-linear
potential(Cornell potential) can be realized only in EMD model. Thus, a dilaton
field is proved to be important in holographic model. Finally, we also show
that the free energy, entropy and internal energy of a single quark in EMD
model with the presence of magnetic field.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:45:47 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 13:07:18 GMT""},{""version"":""v3"",""created"":""Sun, 4 Oct 2020 15:37:58 GMT""}]","2020-10-28"
"2006.09063","Andr\'e Guerra","Andr\'e Guerra, Rita Teixeira da Costa","Numerical evidence towards a positive answer to Morrey's problem",,,,,"math.OC math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on numerical experiments suggesting that rank-one convexity imples
quasiconvexity in the planar case. We give a simple heuristic explanation of
our findings.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:46:26 GMT""}]","2020-06-17"
"2006.09064","Miguel Navascues","Miguel Navascues, Flavio Baccari and Antonio Acin","Entanglement marginal problems","Accepted version","Quantum 5, 589 (2021)","10.22331/q-2021-11-25-589",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We consider the entanglement marginal problem, which consists of deciding
whether a number of reduced density matrices are compatible with an overall
separable quantum state. To tackle this problem, we propose hierarchies of
semidefinite programming relaxations of the set of quantum state marginals
admitting a fully separable extension. We connect the completeness of each
hierarchy to the resolution of an analog classical marginal problem and thus
identify relevant experimental situations where the hierarchies are complete.
For finitely many parties on a star configuration or a chain, we find that we
can achieve an arbitrarily good approximation to the set of nearest-neighbour
marginals of separable states with a time (space) complexity polynomial
(linear) on the system size. Our results even extend to infinite systems, such
as translation-invariant systems in 1D, as well as higher spatial dimensions
with extra symmetries.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:48:56 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 13:45:54 GMT""},{""version"":""v3"",""created"":""Mon, 22 Mar 2021 11:43:06 GMT""},{""version"":""v4"",""created"":""Mon, 22 Nov 2021 09:01:36 GMT""},{""version"":""v5"",""created"":""Tue, 23 Nov 2021 07:04:48 GMT""}]","2021-11-30"
"2006.09065","Ya-Ping Hsieh","Ya-Ping Hsieh, Panayotis Mertikopoulos, Volkan Cevher","The limits of min-max optimization algorithms: convergence to spurious
  non-critical sets",,,,,"math.OC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compared to ordinary function minimization problems, min-max optimization
algorithms encounter far greater challenges because of the existence of
periodic cycles and similar phenomena. Even though some of these behaviors can
be overcome in the convex-concave regime, the general case is considerably more
difficult. On that account, we take an in-depth look at a comprehensive class
of state-of-the art algorithms and prevalent heuristics in non-convex /
non-concave problems, and we establish the following general results: a)
generically, the algorithms' limit points are contained in the ICT sets of a
common, mean-field system; b) the attractors of this system also attract the
algorithms in question with arbitrarily high probability; and c) all algorithms
avoid the system's unstable sets with probability 1. On the surface, this
provides a highly optimistic outlook for min-max algorithms; however, we show
that there exist spurious attractors that do not contain any stationary points
of the problem under study. In this regard, our work suggests that existing
min-max algorithms may be subject to inescapable convergence failures. We
complement our theoretical analysis by illustrating such attractors in simple,
two-dimensional, almost bilinear problems.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:49:27 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 21:54:24 GMT""}]","2021-02-16"
"2006.09066","Mohamed Sana","Mohamed Sana, Antonio De Domenico, Wei Yu, Yves Lostanlen, and Emilio
  Calvanese Strinati","Multi-Agent Reinforcement Learning for Adaptive User Association in
  Dynamic mmWave Networks","Part of this work has been presented in IEEE Globecom 2019",,,,"eess.SP cs.AI cs.LG cs.MA","http://creativecommons.org/licenses/by/4.0/","  Network densification and millimeter-wave technologies are key enablers to
fulfill the capacity and data rate requirements of the fifth generation (5G) of
mobile networks. In this context, designing low-complexity policies with local
observations, yet able to adapt the user association with respect to the global
network state and to the network dynamics is a challenge. In fact, the
frameworks proposed in literature require continuous access to global network
information and to recompute the association when the radio environment
changes. With the complexity associated to such an approach, these solutions
are not well suited to dense 5G networks. In this paper, we address this issue
by designing a scalable and flexible algorithm for user association based on
multi-agent reinforcement learning. In this approach, users act as independent
agents that, based on their local observations only, learn to autonomously
coordinate their actions in order to optimize the network sum-rate. Since there
is no direct information exchange among the agents, we also limit the signaling
overhead. Simulation results show that the proposed algorithm is able to adapt
to (fast) changes of radio environment, thus providing large sum-rate gain in
comparison to state-of-the-art solutions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:51:27 GMT""}]","2020-06-17"
"2006.09067","Mostafa Kiani","M. Kiani","A specifically designed machine learning algorithm for GNSS position
  time series prediction and its applications in outlier and anomaly detection
  and earthquake prediction",,,,,"eess.SP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present a simple yet efficient supervised machine learning algorithm that
is designed for the GNSS position time series prediction. This algorithm has
four steps. First, the mean value of the time series is subtracted from it.
Second, the trends in the time series are removed. Third, wavelets are used to
separate the high and low frequencies. And fourth, a number of frequencies are
derived and used for finding the weights between the hidden and the output
layers, using the product of the identity and sine and cosine functions. The
role of the observation precision is taken into account in this algorithm. A
large-scale study of three thousand position times series of GNSS stations
across the globe is presented. Seventeen different machine learning algorithms
are examined. The accuracy levels of these algorithms are checked against the
rigorous statistical method of Theta. It is shown that the most accurate
machine learning algorithm is the method we present, in addition to being
faster. Two applications of the algorithm are presented. In the first
application, it is shown that the outliers and anomalies in a time series can
be detected and removed by the proposed algorithm. In a large scale study, ten
other methods of time series outlier detection are compared with the proposed
algorithm. The study reveals that the proposed algorithm is approximately 3.22
percent more accurate in detecting outliers. In the second application, the
suitability of the algorithm for earthquake prediction is investigated. A case
study is presented for the Tohoku 2011 earthquake. It is shown that this
earthquake could have been predicted approximately 2 hours before its
happening, solely based on each of the 845 GEONET station time series.
Comparison with four different studies show the improvement in prediction of
the time of the earthquake.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:55:10 GMT""}]","2020-06-17"
"2006.09068","Tadahiro Kimura","Tadahiro Kimura and Masahiro Ikoma","Formation of aqua planets with water of nebular origin: Effects of water
  enrichment on the structure and mass of captured atmospheres of terrestrial
  planets","14 pages, 11 figures, accepted for publication in MNRAS",,"10.1093/mnras/staa1778",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent detection of exoplanets with Earth-like insolation attracts growing
interest in how common Earth-like aqua planets are beyond the solar system.
While terrestrial planets are often assumed to capture icy or water-rich
planetesimals, a primordial atmosphere of nebular origin itself can produce
water through oxidation of the atmospheric hydrogen with oxidising minerals
from incoming planetesimals or the magma ocean. Thermodynamically, normal
oxygen buffers produce water comparable in mole number to or more than
hydrogen. Thus, the primordial atmosphere would likely be highly enriched with
water vapour; however, the primordial atmosphereshave been always assumed to
have the solar abundances. Here we integrate the 1D structure of such an
enriched atmosphere of sub-Earths embedded in a protoplanetary disc around an M
dwarf of 0.3$M_\odot$ and investigate the effects of water enrichment on the
atmospheric properties with focus on water amount. We find that the well-mixed,
highly-enriched atmosphere is more massive by a few orders of magnitude than
the solar-abundance atmosphere, and that even a Mars-mass planet can obtain
water comparable to the present Earth's oceans. Although close-in Mars-mass
planets likely lose the captured water via disc dispersal and
photo-evaporation, these results suggest that there are more sub-Earths with
Earth-like water contents than previously predicted. How much water terrestrial
planets really obtain and retain against subsequent loss, however, depends on
efficiencies of water production, mixing in the atmosphere and magma ocean, and
photo-evaporation, detailed investigation for which should be made in the
future.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:56:02 GMT""}]","2020-07-01"
"2006.09069","Sara Murciano","Sara Murciano, Giuseppe Di Giulio and Pasquale Calabrese","Entanglement and symmetry resolution in two dimensional free quantum
  field theories","42 pages, 11 figures","JHEP 2008 (2020) 073","10.1007/JHEP08(2020)073",,"hep-th cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a thorough analysis of the entanglement entropies related to
different symmetry sectors of free quantum field theories (QFT) with an
internal U(1) symmetry. We provide explicit analytic computations for the
charged moments of Dirac and complex scalar fields in two spacetime dimensions,
both in the massive and massless cases, using two different approaches. The
first one is based on the replica trick, the computation of the partition
function on Riemann surfaces with the insertion of a flux $\alpha$, and the
introduction of properly modified twist fields, whose two-point function
directly gives the scaling limit of the charged moments. With the second
method, the diagonalisation in replica space maps the problem to the
computation of a partition function on a cut plane, that can be written exactly
in terms of the solutions of non-linear differential equations of the
Painlev\'e V type. Within this approach, we also derive an asymptotic expansion
for the short and long distance behaviour of the charged moments. Finally, the
Fourier transform provides the desired symmetry resolved entropies: at the
leading order, they satisfy entanglement equipartition and we identify the
subleading terms that break it. Our analytical findings are tested against
exact numerical calculations in lattice models.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:59:33 GMT""}]","2020-08-25"
"2006.09070","Wen-He Jiao","Wen-He Jiao, Xiao-Meng Xie, Yi Liu, Xiaofeng Xu, Bin Li, Chun-Qiang
  Xu, Ji-Yong Liu, Wei Zhou, Yu-Ke Li, Hai-Yang Yang, Shan Jiang, Yongkang Luo,
  Zeng-Wei Zhu, and Guang-Han Cao","Topological Dirac states in a layered telluride TaPdTe$_5$ with
  quasi-one-dimensional PdTe$_2$ chains","12 pages,6 figures","Phys. Rev. B 102, 075141 (2020)","10.1103/PhysRevB.102.075141",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the synthesis and systematic studies of a new layered ternary
telluride TaPdTe5 with quasi-one-dimensional PdTe2 chains. This compound
crystalizes in a layered orthorhombic structure with space group Cmcm. Analysis
of its curved field-dependent Hall resistivity, using the two-band model,
indicates the hole-dominated transport with a high mobility ${\mu}_h$ = 2.38
$\times$ 10$^3$ cm$^2$ V$^{-1}$ s$^{-1}$ at low temperatures. The in-plane
magnetoresistance (MR) displays significant anisotropy with field applied along
the crystallographic $b$ axis. The MR with the current applied along the
$c$-axis is also measured in high magnetic fields up to 51.7 T. Remarkably, it
follows a power-law dependence and reaches (9.5 $\times$ 10$^3$)% at 2.1 K
without any signature of saturation. The De Haas-van Alphen oscillations show a
small Fermi-surface pocket with a nontrivial Berry phase. The Shubnikov-de Haas
(SdH) oscillations are detected at low temperatures and under magnetic fields
above 28.5 T. Two effective masses $m^*$ (0.26$m_e$ and 0.41$m_e$) are
extracted from the oscillatory SdH data. Our first-principles calculations
unveil a topological Dirac cone in its surface states, and, in particular, the
topological index indicates that TaPdTe$_5$ is a topologically nontrivial
material.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:00:52 GMT""},{""version"":""v2"",""created"":""Fri, 14 Aug 2020 06:49:33 GMT""}]","2020-09-02"
"2006.09071","Kangwei Li","Kangwei Li","Multilinear commutators in the two-weight setting","18 pages. v3: incorporated referee comments, to appear in Bull. Lond.
  Math. Soc",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the recently much-studied two-weight commutator estimates to the
multilinear setting. In contrast to previous results, our result respects the
multilinear nature of the problem fully and is formulated with the genuinely
multilinear weights.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:02:16 GMT""},{""version"":""v2"",""created"":""Sun, 15 Nov 2020 02:55:44 GMT""},{""version"":""v3"",""created"":""Wed, 6 Oct 2021 08:53:42 GMT""}]","2021-10-07"
"2006.09072","Laurent Baratchart","L. Baratchart and D. Hardin and C. Villalobos-Guill\'en","Divergence-free measures in the plane and inverse potential problems in
  divergence form","40 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that a divergence-free measure on the plane is a continuous sum of
unit tangent vector fields on rectifiable Jordan curves. This loop
decomposition is more precise than the general decomposition in elementary
solenoids given by S.K. Smirnov, when applied to the planar case. The proof
involves extending the Fleming-Rishel formula to homogeneous BV functions (in
any dimension), and establishing for such functions approximate continuity of
measure theoretic connected components of suplevel sets as functions of the
level. We apply these results to inverse potential problems whose source term
is the divergence of some unknown (vector-valued) measure. A prototypical case
is that of inverse magnetization problems when magnetizations are modeled by
R3-valued Borel measures. We investigate methods for recovering a magnetization
{\mu} by penalizing its measure theoretic total variation norm (TV). In
particular, we prove that if a magnetization is supported in a plane, then
TV-regularization schemes always have a unique minimizer, even in the presence
of noise. It is further shown thatTV-norm minimization (among magnetizations
generating the same field) uniquely recovers planar magnetizations in the
following cases: when the magnetization is carried by a collection of
sufficiently separated line segments and a set that is purely 1-unrectifiable,
or when a superset of the support is tree-like. We note that such
magnetizations can be recovered via TV-regularization schemes in the zero noise
limit, by taking the regularization parameter to zero. This suggests
definitions of sparsity in the present infinite dimensional context, that
generate results akin to compressed sensing
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:02:32 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jan 2021 14:27:38 GMT""}]","2021-01-12"
"2006.09073","Zihao Zhu","Zihao Zhu, Jing Yu, Yujing Wang, Yajing Sun, Yue Hu, Qi Wu","Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual
  Question Answering",,,,,"cs.CV cs.AI cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fact-based Visual Question Answering (FVQA) requires external knowledge
beyond visible content to answer questions about an image, which is challenging
but indispensable to achieve general VQA. One limitation of existing FVQA
solutions is that they jointly embed all kinds of information without
fine-grained selection, which introduces unexpected noises for reasoning the
final answer. How to capture the question-oriented and
information-complementary evidence remains a key challenge to solve the
problem. In this paper, we depict an image by a multi-modal heterogeneous
graph, which contains multiple layers of information corresponding to the
visual, semantic and factual features. On top of the multi-layer graph
representations, we propose a modality-aware heterogeneous graph convolutional
network to capture evidence from different layers that is most relevant to the
given question. Specifically, the intra-modal graph convolution selects
evidence from each modality and cross-modal graph convolution aggregates
relevant information across different modalities. By stacking this process
multiple times, our model performs iterative reasoning and predicts the optimal
answer by analyzing all question-oriented evidence. We achieve a new
state-of-the-art performance on the FVQA task and demonstrate the effectiveness
and interpretability of our model with extensive experiments.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:03:37 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 00:49:02 GMT""},{""version"":""v3"",""created"":""Wed, 4 Nov 2020 01:36:36 GMT""}]","2020-11-05"
"2006.09074","Amir Lellouche","Uriel Feige, Amir Lellouche","Quantitative Group Testing and the rank of random matrices",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a random Bernoulli matrix $ A\in \{0,1\}^{m\times n} $, an integer $ 0<
k < n $ and the vector $ y:=Ax $, where $ x \in \{0,1\}^n $ is of Hamming
weight $ k $, the objective in the {\em Quantitative Group Testing} (QGT)
problem is to recover $ x $. This problem is more difficult the smaller $m$ is.
For parameter ranges of interest to us, known polynomial time algorithms
require values of $m$ that are much larger than $k$.
  In this work, we define a seemingly easier problem that we refer to as {\em
Subset Select}. Given the same input as in QGT, the objective in Subset Select
is to return a subset $ S \subseteq [n] $ of cardinality $ m $, such that for
all $ i\in [n] $, if $ x_i = 1 $ then $ i\in S $. We show that if the square
submatrix of $A$ defined by the columns indexed by $S$ has nearly full rank,
then from the solution of the Subset Select problem we can recover in
polynomial-time the solution $x$ to the QGT problem. We conjecture that for
every polynomial time Subset Select algorithm, the resulting output matrix will
satisfy the desired rank condition. We prove the conjecture for some classes of
algorithms. Using this reduction, we provide some examples of how to improve
known QGT algorithms. Using theoretical analysis and simulations, we
demonstrate that the modified algorithms solve the QGT problem for values of $
m $ that are smaller than those required for the original algorithms.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:08:22 GMT""}]","2020-06-17"
"2006.09075","Eyal Ben-Davd","Eyal Ben-David, Carmel Rabinovitz, Roi Reichart","PERL: Pivot-based Domain Adaptation for Pre-trained Deep Contextualized
  Embedding Models","Accepted to TACL in June 2020",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Pivot-based neural representation models have lead to significant progress in
domain adaptation for NLP. However, previous works that follow this approach
utilize only labeled data from the source domain and unlabeled data from the
source and target domains, but neglect to incorporate massive unlabeled corpora
that are not necessarily drawn from these domains. To alleviate this, we
propose PERL: A representation learning model that extends contextualized word
embedding models such as BERT with pivot-based fine-tuning. PERL outperforms
strong baselines across 22 sentiment classification domain adaptation setups,
improves in-domain model performance, yields effective reduced-size models and
increases model stability.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:14:06 GMT""}]","2020-06-17"
"2006.09076","Shin-Ichiro Seki","Shin-ichiro Seki","Connectors","This survey article is based on the talk by the author at the
  workshop ""Various Aspects of Multiple Zeta Values'' held at RIMS, Kyoto Univ.
  (November 18-22, 2019) and will be published without peer review in RIMS
  Kokyuroku",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the author and Yamamoto invented a new proof of the duality for
multiple zeta values. The technique is applicable in other series identities.
In this article, we exhibit such proofs for some series identities.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:15:25 GMT""},{""version"":""v2"",""created"":""Sun, 21 Jun 2020 16:39:11 GMT""}]","2020-06-23"
"2006.09077","Dipak Debnath","D. Chatterjee, D. Debnath, A. Jana, J.-R. Shang, S. K. Chakrabarti,
  H.-K. Chang, A. Banerjee, A. Bhattacharjee, K. Chatterjee, R. Bhowmick, S. K.
  Nath","AstroSat Observation of Non-Resonant Type-C QPOs in MAXI J1535-571","15 pages, 6 figures, 3 tables (accepted for publication in Ap&SS)",,"10.1007/s10509-021-03988-6",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galactic transient black hole candidate (BHC) MAXI J1535-571 was discovered
on 2017 September 02 simultaneously by {\it MAXI}/GSC and {\it Swift}/BAT
instruments. It has also been observed by India's first multi-wavelength
astronomy-mission satellite {\it AstroSat}, during the rising phase of its
2017-18 outburst. We make both the spectral and the temporal analysis of the
source during 2017 September 12-17 using data of {\it AstroSat}'s Large Area
X-ray Proportional Counter (LAXPC) in the energy range of $3-40$~keV to infer
the accretion flow properties of the source. Spectral analysis is done with the
physical two-component advective flow (TCAF) solution-based {\it fits} file.
From the nature of the variation of the TCAF model fitted physical flow
parameters, we conclude and confirm that the source was in the intermediate
spectral state during our analysis period. We observe sharp type-C
quasi-periodic oscillations (QPOs) in the frequency range of $\sim
1.75-2.81$~Hz. For a better understanding of the nature and evolution of these
type-C QPOs, a dynamic study of the power density spectra is done. We also
investigate the origin of these QPOs from the shock oscillation model. We find
that non-satisfaction of Rankine-Hugoniot conditions for non-dissipative shocks
and not their resonance oscillations is the cause of the observed type-C QPOs.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:22:02 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 12:05:06 GMT""}]","2021-09-08"
"2006.09078","Sebastian Franke","Sebastian Franke, Juanjuan Ren, Stephen Hughes, Marten Richter","Fluctuation-dissipation theorem and fundamental photon commutation
  relations in lossy nanostructures using quasinormal modes","20 pages, 4 figures","Phys. Rev. Research 2, 033332 (2020)","10.1103/PhysRevResearch.2.033332",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide theory and formal insight on the Green function quantization
method for absorptive and dispersive spatial-inhomogeneous media in the context
of dielectric media. We show that a fundamental Green function identity, which
appears, e.g., in the fundamental commutation relation of the electromagnetic
fields, is also valid in the limit of non-absorbing media. We also demonstrate
how the zero-point field fluctuations yields a non-vanishing surface term in
configurations without absorption, when using a more formal procedure of the
Green function quantization method. We then apply the presented method to a
recently developed theory of photon quantization using quasinormal modes
[Franke et al., Phys. Rev. Lett. 122, 213901 (2019)] for finite nanostructures
embedded in a lossless background medium. We discuss the strict dielectric
limit of the commutation relations of the quasinormal mode operators and
present different methods to obtain them, connected to the radiative loss for
non-absorptive but open resonators. We show exemplary calculations of a fully
three-dimensional photonic crystal beam cavity, including the lossless limit,
which supports a single quasinormal mode and discuss the limits of the
commutation relation for vanishing damping (no material loss and no radiative
loss).
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:24:03 GMT""},{""version"":""v2"",""created"":""Mon, 3 Aug 2020 12:16:30 GMT""}]","2020-09-01"
"2006.09079","Kevin Olsen","Kevin S. Olsen, Franck Lef\`evre, Franck Montmessin, Alexander
  Trokhimovskiy, Lucio Baggio, Anna Fedorova, Juan Alday, Alexander Lomakin,
  Denis A. Belyaev, Andrey Patrakeev, Alexey Shakun, Oleg Korablev","First detection of ozone in the mid-infrared at Mars: implications for
  methane detection","7 pages, 6 figures","A&A 639, A141 (2020)","10.1051/0004-6361/202038125",,"astro-ph.EP astro-ph.IM physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  The ExoMars Trace Gas Orbiter (TGO) was sent to Mars in March 2016 to search
for trace gases diagnostic of active geological or biogenic processes. We
report the first observation of the spectral features of Martian ozone (O3) in
the mid-infrared range using the Atmospheric Chemistry Suite (ACS) Mid-InfaRed
(MIR) channel, a cross-dispersion spectrometer operating in solar occultation
mode with the finest spectral resolution of any remote sensing mission to Mars.
Observations of ozone were made at high northern latitudes (>65N) prior to the
onset of the 2018 global dust storm (Ls = 163-193). During this fast transition
phase between summer and winter ozone distribution, the O3 volume mixing ratio
observed is 100-200 ppbv near 20 km. These amounts are consistent with past
observations made at the edge of the southern polar vortex in the ultraviolet
range. The observed spectral signature of ozone at 3000-3060 cm-1 directly
overlaps with the spectral range of the methane (CH4) nu3 vibration-rotation
band, and it, along with a newly discovered CO2 band in the same region, may
interfere with measurements of methane abundance.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:24:44 GMT""}]","2020-07-29"
"2006.09080","Nicolas Mounet","Nicolas Mounet","Direct Vlasov solvers","25 pages, 2 figures",,,,"physics.acc-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In these proceedings we will describe the theory and practical steps required
to build Vlasov solvers such as those commonly used to compute coherent
instabilities in synchrotrons. Thanks to a Hamiltonian formalism, we will
derive a compact and general form of the linearized Vlasov equation, written
using Poisson brackets. This in turn will be the basis of a procedure to build
Vlasov solvers, applied to the specific example of transverse instabilities
arising from beam coupling impedance.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:25:27 GMT""}]","2020-06-17"
"2006.09081","Pau De Jorge Aranda","Pau de Jorge, Amartya Sanyal, Harkirat S. Behl, Philip H.S. Torr,
  Gregory Rogez, Puneet K. Dokania","Progressive Skeletonization: Trimming more fat from a network at
  initialization",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies have shown that skeletonization (pruning parameters) of
networks \textit{at initialization} provides all the practical benefits of
sparsity both at inference and training time, while only marginally degrading
their performance. However, we observe that beyond a certain level of sparsity
(approx $95\%$), these approaches fail to preserve the network performance, and
to our surprise, in many cases perform even worse than trivial random pruning.
To this end, we propose an objective to find a skeletonized network with
maximum {\em foresight connection sensitivity} (FORCE) whereby the
trainability, in terms of connection sensitivity, of a pruned network is taken
into consideration. We then propose two approximate procedures to maximize our
objective (1) Iterative SNIP: allows parameters that were unimportant at
earlier stages of skeletonization to become important at later stages; and (2)
FORCE: iterative process that allows exploration by allowing already pruned
parameters to resurrect at later stages of skeletonization. Empirical analyses
on a large suite of experiments show that our approach, while providing at
least as good a performance as other recent approaches on moderate pruning
levels, provides remarkably improved performance on higher pruning levels
(could remove up to $99.5\%$ parameters while keeping the networks trainable).
Code can be found in https://github.com/naver/force.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:32:47 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 14:41:08 GMT""},{""version"":""v3"",""created"":""Tue, 14 Jul 2020 12:02:15 GMT""},{""version"":""v4"",""created"":""Wed, 21 Oct 2020 13:54:26 GMT""},{""version"":""v5"",""created"":""Fri, 19 Mar 2021 13:06:16 GMT""}]","2021-03-22"
"2006.09082","Xiao Yang","GangHua Lin, GaoFei Zhu, Xiao Yang, YongLiang Song, Mei Zhang, Suo
  Liu, XiaoFan Wang, JiangTao Su, Sheng Zheng, JiaFeng Zhang, DongYi Tao,
  ShuGuang Zeng, HaiMin Wang, Chang Liu, Yan Xu","A New Comprehensive Data Set of Solar Filaments of 100 yr Interval. I","20 pages, 17 figures, 1 table, accepted for publication in ApJS","ApJS 249 (2020) 11","10.3847/1538-4365/ab92a5",,"astro-ph.SR astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Filaments are very common physical phenomena on the Sun and are often taken
as important proxies of solar magnetic activities. The study of filaments has
become a hot topic in the space weather research. For a more comprehensive
understanding of filaments, especially for an understanding of solar activities
of multiple solar cycles, it is necessary to perform a combined multifeature
analysis by constructing a data set of multiple solar cycle data. To achieve
this goal, we constructed a centennial data set that covers the H$\alpha$ data
from five observatories around the world. During the data set construction, we
encountered varieties of problems, such as data fusion, accurate determination
of the solar edge, classifying data by quality, dynamic threshold, and so on,
which arose mainly due to multiple sources and a large time span of data. But
fortunately, these problems were well solved. The data set includes seven types
of data products and eight types of feature parameters with which we can
implement the functions of data searching and statistical analyses. It has the
characteristics of better continuity and highly complementary to space
observation data, especially in the wavelengths not covered by space
observations, and covers many solar cycles (including more than 60 yr of
high-cadence data). We expect that this new comprehensive data set as well as
the tools will help researchers to significantly speed up their search for
features or events of interest, for either statistical or case study purposes,
and possibly help them get a better and more comprehensive understanding of
solar filament mechanisms.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:37:57 GMT""}]","2020-07-08"
"2006.09083","Roberto L. Castro","Roberto L. Castro, Diego Andrade, Basilio Fraguela","Reusing Trained Layers of Convolutional Neural Networks to Shorten
  Hyperparameters Tuning Time",,,,,"cs.LG cs.DC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hyperparameters tuning is a time-consuming approach, particularly when the
architecture of the neural network is decided as part of this process. For
instance, in convolutional neural networks (CNNs), the selection of the number
and the characteristics of the hidden (convolutional) layers may be decided.
This implies that the search process involves the training of all these
candidate network architectures.
  This paper describes a proposal to reuse the weights of hidden
(convolutional) layers among different trainings to shorten this process. The
rationale is that if a set of convolutional layers have been trained to solve a
given problem, the weights calculated in this training may be useful when a new
convolutional layer is added to the network architecture.
  This idea has been tested using the CIFAR-10 dataset, testing different CNNs
architectures with up to 3 convolutional layers and up to 3 fully connected
layers. The experiments compare the training time and the validation loss when
reusing and not reusing convolutional layers. They confirm that this strategy
reduces the training time while it even increases the accuracy of the resulting
neural network. This finding opens up the future possibility of integrating
this strategy in existing AutoML methods with the purpose of reducing the total
search time.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:39:39 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jul 2020 15:30:27 GMT""}]","2020-07-31"
"2006.09084","Haizhou Liu","Haizhou Liu, Xinwei Shen, Qinglai Guo, Hongbin Sun, Wenzhi Zhao and
  Xinyi Zhao","Stochastic Unit Commitment in Electricity-Gas Coupled Integrated Energy
  Systems based on Modified Progressive Hedging",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increasing number of gas-fired units has significantly intensified the
coupling between power and gas networks. Traditionally, the nonlinearity and
nonconvexity in gas flow equations, together with renewable-induced
stochasticity, result in a computationally expensive model for unit commitment
in electricity-gas coupled integrated energy systems (IES). To accelerate
stochastic day-ahead scheduling, we applied and modified Progressive Hedging
(PH), a heuristic approach that can be computed in parallel to yield
scenario-independent unit commitment. By applying a termination and enumeration
technique, the modified PH algorithm saves considerable computational time,
especially when the unit production prices are similar for all generators, and
when the scale of IES is large. Moreover, an adapted second-order cone
relaxation (SOCR) is utilized to tackle the nonconvex gas flow equation. Case
studies are performed on the IEEE 24-bus system/Belgium 20-node gas system and
the IEEE 118-bus system/Belgium 20-node gas system. The computational
efficiency when employing PH is 188 times that of commercial software, even
outperforming Benders Decomposition. Meanwhile, the gap between the PH
algorithm and the benchmark is less than 0.01% in both IES systems, which
proves that the solution produced by PH reaches acceptable optimality in this
stochastic UC problem.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:41:23 GMT""}]","2020-06-17"
"2006.09085","Leonardo Pellegrina","Leonardo Pellegrina, Cyrus Cousins, Fabio Vandin, Matteo Riondato","MCRapper: Monte-Carlo Rademacher Averages for Poset Families and
  Approximate Pattern Mining",,,"10.1145/3394486.3403267",,"cs.LG cs.DB cs.DS stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present MCRapper, an algorithm for efficient computation of Monte-Carlo
Empirical Rademacher Averages (MCERA) for families of functions exhibiting
poset (e.g., lattice) structure, such as those that arise in many pattern
mining tasks. The MCERA allows us to compute upper bounds to the maximum
deviation of sample means from their expectations, thus it can be used to find
both statistically-significant functions (i.e., patterns) when the available
data is seen as a sample from an unknown distribution, and approximations of
collections of high-expectation functions (e.g., frequent patterns) when the
available data is a small sample from a large dataset. This feature is a strong
improvement over previously proposed solutions that could only achieve one of
the two. MCRapper uses upper bounds to the discrepancy of the functions to
efficiently explore and prune the search space, a technique borrowed from
pattern mining itself. To show the practical use of MCRapper, we employ it to
develop an algorithm TFP-R for the task of True Frequent Pattern (TFP) mining.
TFP-R gives guarantees on the probability of including any false positives
(precision) and exhibits higher statistical power (recall) than existing
methods offering the same guarantees. We evaluate MCRapper and TFP-R and show
that they outperform the state-of-the-art for their respective tasks.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:42:56 GMT""}]","2020-06-17"
"2006.09086","Siegfried Beckus","Siegfried Beckus and Latif Eliaz","Growth of Eigenfunctions and R-limits on Graphs",,,,,"math.SP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A characterization of the essential spectrum $\sigma_{\text ess}$ of
Schr\""odinger operators on infinite graphs is derived involving the concept of
$\mathcal{R}$-limits. This concept, which was introduced previously for
operators on $\mathbb{N}$ and $\mathbb{Z}^d$ as ""right-limits"", captures the
behaviour of the operator at infinity. For graphs with sub-exponential growth
rate we show that each point in $\sigma_{\text ess}(H)$ corresponds to a
bounded generalized eigenfunction of a corresponding $\mathcal{R}$-limit of
$H$. If, additionally, the graph is of uniform sub-exponential growth, also the
converse inclusion holds.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:42:58 GMT""}]","2020-06-17"
"2006.09087","Yunhui Chen","Yunhui Chen, Samuel J. Clark, Lorna Sinclair, Chu Lun Alex Leung,
  Sebastian Marussi, Thomas Connolley, Oxana V. Magdysyuk, Robert C. Atwood,
  Gavin J. Baxter, Martyn A. Jones, David G. McCartney, Iain Todd and Peter D.
  Lee","In situ and Operando X-ray Imaging of Directed Energy Deposition
  Additive Manufacturing","20 pages, 4 figures, submitted to Science Advances",,,,"physics.app-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mechanical performance of Directed Energy Deposition Additive
Manufactured (DED-AM) components can be highly material dependent. Through in
situ and operando synchrotron X-ray imaging we capture the underlying phenomena
controlling build quality of stainless steel (SS316) and titanium alloy (Ti6242
or Ti-6Al-2Sn-4Zr-2Mo). We reveal three mechanisms influencing the build
efficiency of titanium alloys compared to stainless steel: blown powder
sintering; reduced melt-pool wetting due to the sinter; and pore pushing in the
melt-pool. The former two directly increase lack of fusion porosity, while the
later causes end of track porosity. Each phenomenon influences the melt-pool
characteristics, wetting of the substrate and hence build efficacy and
undesirable microstructural feature formation. We demonstrate that porosity is
related to powder characteristics, pool flow, and solidification front
morphology. Our results clarify DED-AM process dynamics, illustrating why each
alloy builds differently, facilitating the wider application of additive
manufacturing to new materials.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:44:50 GMT""}]","2020-06-17"
"2006.09088","Adam Szereszewski","Eryk Buk, Jerzy Lewandowski, Adam Szereszewski","Lie point symmetries of near-horizon geometry equation",,"Phys. Rev. D 102, 124064 (2020)","10.1103/PhysRevD.102.124064",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  All the Lie point symmetries of the near extremal horizon geometry equation,
in the case of 4-dimensional Einstein vacuum spacetime with cosmological
constant, are the diffeomorphisms of the space of the null generators of the
horizon. This result is also generalised to the Maxwell-Einstein spacetime.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:47:20 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 14:09:21 GMT""}]","2021-01-04"
"2006.09089","Raphael Alexandre","Rapha\""el Alexandre (OURAGAN, IMJ-PRG (UMR\_7586), SU)","Redundancy of triangle groups in spherical CR representations",,,,,"math.DG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Falbel, Koseleff and Rouillier computed a large number of boundary unipotent
CR representations of fundamental groups of non compact three-manifolds. Those
representations are not always discrete. By experimentally computing their
limit set, one can determine that those with fractal limit sets are discrete.
Many of those discrete representations can be related to (3,3,n) complex
hyperbolic triangle groups. By exact computations, we verify the existence of
those triangle representations, which have boundary unipotent holonomy. We also
show that many representations are redundant: for n fixed, all the (3,3,n)
representations encountered are conjugate and only one among them is
uniformizable.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:52:06 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 14:55:00 GMT""}]","2021-10-29"
"2006.09090","Walter Morales-Alvarez","Walter Morales Alvarez, Miguel \'Angel de Miguel, Fernando Garc\'ia,
  Cristina Olaverri-Monreal","Response of Vulnerable Road Users to Visual Information from Autonomous
  Vehicles in Shared Spaces","Published paper in the IEEE Intelligent Transportation Systems
  Conference - ITSC 2019","2019 IEEE Intelligent Transportation Systems Conference (ITSC),
  Auckland, New Zealand, 2019, pp. 3714-3719","10.1109/ITSC.2019.8917501",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Completely unmanned autonomous vehicles have been anticipated for a while.
Initially, these are expected to drive only under certain conditions on some
roads, and advanced functionality is required to cope with the ever-increasing
challenges of safety. To enhance the public's perception of road safety and
trust in new vehicular technologies, we investigate in this paper the effect of
several interaction paradigms with vulnerable road users by developing and
applying algorithms for the automatic analysis of pedestrian body language. We
assess behavioral patterns and determine the impact of the coexistence of AVs
and other road users on general road safety in a shared space for VRUs and
vehicles. Results showed that the implementation of visual communication cues
for interacting with VRUs is not necessarily required for a shared space in
which informal traffic rules apply.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:54:16 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 10:07:33 GMT""},{""version"":""v3"",""created"":""Wed, 22 Jul 2020 09:48:54 GMT""}]","2020-07-23"
"2006.09091","Diego Granziol","Diego Granziol","Flatness is a False Friend","9 pages, 10 figures",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hessian based measures of flatness, such as the trace, Frobenius and spectral
norms, have been argued, used and shown to relate to generalisation. In this
paper we demonstrate that for feed forward neural networks under the cross
entropy loss, we would expect low loss solutions with large weights to have
small Hessian based measures of flatness. This implies that solutions obtained
using $L2$ regularisation should in principle be sharper than those without,
despite generalising better. We show this to be true for logistic regression,
multi-layer perceptrons, simple convolutional, pre-activated and wide residual
networks on the MNIST and CIFAR-$100$ datasets. Furthermore, we show that for
adaptive optimisation algorithms using iterate averaging, on the VGG-$16$
network and CIFAR-$100$ dataset, achieve superior generalisation to SGD but are
$30 \times$ sharper. This theoretical finding, along with experimental results,
raises serious questions about the validity of Hessian based sharpness measures
in the discussion of generalisation. We further show that the Hessian rank can
be bounded by the a constant times number of neurons multiplied by the number
of classes, which in practice is often a small fraction of the network
parameters. This explains the curious observation that many Hessian eigenvalues
are either zero or very near zero which has been reported in the literature.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:55:24 GMT""}]","2020-06-17"
"2006.09092","Diego Granziol","Diego Granziol, Stefan Zohren, Stephen Roberts","Learning Rates as a Function of Batch Size: A Random Matrix Theory
  Approach to Neural Network Training",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the effect of mini-batching on the loss landscape of deep neural
networks using spiked, field-dependent random matrix theory. We demonstrate
that the magnitude of the extremal values of the batch Hessian are larger than
those of the empirical Hessian. We also derive similar results for the
Generalised Gauss-Newton matrix approximation of the Hessian. As a consequence
of our theorems we derive an analytical expressions for the maximal learning
rates as a function of batch size, informing practical training regimens for
both stochastic gradient descent (linear scaling) and adaptive algorithms, such
as Adam (square root scaling), for smooth, non-convex deep neural networks.
Whilst the linear scaling for stochastic gradient descent has been derived
under more restrictive conditions, which we generalise, the square root scaling
rule for adaptive optimisers is, to our knowledge, completely novel. %For
stochastic second-order methods and adaptive methods, we derive that the
minimal damping coefficient is proportional to the ratio of the learning rate
to batch size. We validate our claims on the VGG/WideResNet architectures on
the CIFAR-$100$ and ImageNet datasets. Based on our investigations of the
sub-sampled Hessian we develop a stochastic Lanczos quadrature based on the fly
learning rate and momentum learner, which avoids the need for expensive
multiple evaluations for these key hyper-parameters and shows good preliminary
results on the Pre-Residual Architecure for CIFAR-$100$.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:55:45 GMT""},{""version"":""v2"",""created"":""Fri, 6 Nov 2020 22:57:21 GMT""},{""version"":""v3"",""created"":""Sun, 31 Oct 2021 09:17:21 GMT""},{""version"":""v4"",""created"":""Wed, 3 Nov 2021 15:29:07 GMT""},{""version"":""v5"",""created"":""Thu, 4 Nov 2021 15:58:13 GMT""},{""version"":""v6"",""created"":""Fri, 5 Nov 2021 09:01:59 GMT""}]","2021-11-08"
"2006.09093","Udaya Sampath Karunathilaka Perera Miriya Thanthrige","Udaya S.K.P. Miriya Thanthrige, Jan Barowski, Ilona Rolfes, Daniel
  Erni, Thomas Kaiser and Aydin Sezgin","Characterization of Dielectric Materials by Sparse Signal Processing
  with Iterative Dictionary Updates","5 Pages, Accepted in IEEE Sensor Letters, Sept. 2020",,"10.1109/LSENS.2020.3019924",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Estimating parameters and properties of various materials without causing
damage to the material under test (MUT) is important in many applications.
Thus, in this letter, we address this by wireless sensing. Here, the accuracy
of the estimation depends on the accurate estimation of the properties of the
reflected signal from the MUT (e.g., number of reflections, their amplitudes
and time delays). For a layered MUT, there are multiple reflections and, due to
the limited bandwidth at the receiver, these reflections superimpose each
other. Since the number of reflections coming from the MUT is limited, we
propose sparse signal processing (SSP) to decompose the reflected signal. In
SSP, a so called dictionary is required to obtain a sparse representation of
the signal. Here, instead of a fixed dictionary, a dictionary update technique
is proposed to improve the estimation of the reflected signal. To validate the
proposed method, a vector network analyzer (VNA) based measurement setup is
used. It turns out that the estimated dielectric constants are in close
agreement with the dielectric constants of the MUTs reported in literature.
Further, the proposed approach outperforms the state-of-the-art model-based
curve-fitting approach in thickness estimation.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:57:06 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jul 2020 19:23:20 GMT""},{""version"":""v3"",""created"":""Wed, 26 Aug 2020 07:23:03 GMT""},{""version"":""v4"",""created"":""Wed, 28 Oct 2020 08:48:35 GMT""}]","2020-10-29"
"2006.09094","Matthieu Rosenfeld","Matthieu Rosenfeld","Another approach to non-repetitive colorings of graphs of bounded degree",,,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new proof technique that aims to be applied to the same problems
as the Lov\'asz Local Lemma or the entropy-compression method. We present this
approach in the context of non-repetitive colorings and we use it to improve
upper-bounds relating different non-repetitive numbers to the maximal degree of
a graph. It seems that there should be other interesting applications to the
presented approach.
  In terms of upper-bound our approach seems to be as strong as
entropy-compression, but the proofs are more elementary and shorter. The
application we provide in this paper are upper bounds for graphs of maximal
degree at most $\Delta$: a minor improvement on the upper-bound of the
non-repetitive number, a $4.25\Delta +o(\Delta)$ upper-bound on the weak total
non-repetitive number and a $
\Delta^2+\frac{3}{2^\frac{1}{3}}\Delta^{\frac{5}{3}}+ o(\Delta^{\frac{5}{3}})$
upper-bound on the total non-repetitive number of graphs. This last result
implies the same upper-bound for the non-repetitive index of graphs, which
improves the best known bound.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:59:11 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 09:38:19 GMT""}]","2020-06-24"
"2006.09095","Kuldeep Singh Charak","Kuldeep Singh Charak, Anil Singh and Manish Kumar","Fatou and Julia like sets II","10",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is a continuation of authors work: Fatou and Julia like
sets,Ukranian J. Math., to appear/arXiv:2006.08308[math.CV](see [4]). Here, we
introduce escaping like set and generalized escaping like set for a family of
holomorphic functions on an arbitrary domain, and establish some distinctive
properties of these sets. The connectedness of the Julia like set is also
proved.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:59:36 GMT""}]","2020-06-17"
"2006.09096","Joachim Schreurs","Hannes De Meulemeester, Joachim Schreurs, Micha\""el Fanuel, Bart De
  Moor and Johan A.K. Suykens","The Bures Metric for Generative Adversarial Networks","Additional empirical results",,,,"cs.LG eess.IV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative Adversarial Networks (GANs) are performant generative methods
yielding high-quality samples. However, under certain circumstances, the
training of GANs can lead to mode collapse or mode dropping, i.e. the
generative models not being able to sample from the entire probability
distribution. To address this problem, we use the last layer of the
discriminator as a feature map to study the distribution of the real and the
fake data. During training, we propose to match the real batch diversity to the
fake batch diversity by using the Bures distance between covariance matrices in
feature space. The computation of the Bures distance can be conveniently done
in either feature space or kernel space in terms of the covariance and kernel
matrix respectively. We observe that diversity matching reduces mode collapse
substantially and has a positive effect on the sample quality. On the practical
side, a very simple training procedure, that does not require additional
hyperparameter tuning, is proposed and assessed on several datasets.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:04:41 GMT""},{""version"":""v2"",""created"":""Tue, 6 Oct 2020 12:58:02 GMT""},{""version"":""v3"",""created"":""Tue, 27 Apr 2021 14:45:45 GMT""}]","2021-04-28"
"2006.09097","Nazariy Tupitsa","Nazarii Tupitsa","Accelerated Alternating Minimization and Adaptability to Strong
  Convexity","15 pages, in Russian",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the first part of the paper we consider accelerated first order
optimization method for convex functions with $L$-Lipschitz-continuous
gradient, that is able to automatically adapts to problems which satisfies
Polyak-{\L}ojasiewicz condition or which is strongly convex with the value of
parameter equal to $\mu$. In these cases method poses linear convergence with
factor $\frac{\mu}{L}$, if $\mu$ is unknown. If the problem is strongly convex
and $\mu$ is known, than the method possesses linear convergence with the
factor $\sqrt{\frac{\mu}{L}}$. If that are not the cases, the method converges
with a rate $O(1/k^2)$. The second part contains generalization of the method
to the problems, that allows alternating minimization and proofs of the same
asymptotic convergence rates. Also it is considered the approach called
Adaptive Catalyst, which allows to increase convergence rate up to $O(1/k^2)$
and also it is provided an experimental comparison of the approach with AGM,
Alternating AGM, APDAGD and Sinkhorn's algorithm for the dual problem to the
discrete entropically regularized optimal transport problem. The result of the
work is the attempt to explain the reason why Alternating AGM converge faster
than AGM or Adaptive Catalyst despite of the asymptotic theoretical rate
$O(1/k^2)$. The hypothesis relies on the fact that Alternating AGM adapts to
strong convexity. The hypothesis was tested on quadratic functions, on that
Alternating AGM also showed faster convergence.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:05:21 GMT""}]","2020-06-17"
"2006.09098","Cornel Marius Murea","Cornel Marius Murea and Dan Tiba","Periodic Hamiltonian systems in shape optimization problems with Neumann
  boundary conditions",,"Journal of Differential Equations, 321 (2022), Pages 1-39","10.1016/j.jde.2022.03.007",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent approach based on Hamiltonian systems and the implicit
parametri\-za\-tion theorem, provides a general fixed domain approximation
method in shape optimization problems, using optimal control theory. In
previous works, we have examined Dirichlet boundary conditions with distributed
or boundary observation. Here, we discuss the case of Neumann boundary
conditions, with a combined cost functional, including both distributed and
boundary observation. Extensions to nonlinear state systems are possible. This
new technique allows simultaneous boundary and topological variations and we
also report numerical experiments confirming the theoretical results.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:07:59 GMT""}]","2022-05-03"
"2006.09099","Philipp H. Kindt","Christian Gentner, Daniel G\""unther, Philipp H. Kindt","Identifying the BLE Advertising Channel for Reliable Distance Estimation
  on Smartphones",,,,,"cs.NI cs.SI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a response to the global COVID-19 surge in 2020, many countries have
implemented lockdown or stay-at-home policies. If, however, the contact persons
of every infected patient could be identified, the number of virus
transmissions could be reduced, while the more incisive measures could be
softened. For this purpose, contact tracing using smartphones is being
considered as a promising technique. Here, smartphones emit and scan for
Bluetooth Low Energy (BLE) signals for detecting devices in range. When a
device is detected, its distance is estimated by evaluating its received signal
strength. The main insight that is exploited for distance estimation is that
the attenuation of a signal increases with the distance along which it has
traveled. However, besides distance, there are multiple additional factors that
impact the attenuation and hence disturb distance estimation. Among them,
frequency-selective hardware and signal propagation belong to the most
significant ones. For example, a BLE device transmits beacons on three
different frequencies (channels), while the transmit power and the receiver
sensitivity depend on the frequency. As a result, the received signal strength
varies for each channel, even when the distance remains constant. However, the
information on which wireless channel a beacon has been received is not made
available to a smartphone. Hence, this error cannot be compensated, e.g., by
calibration. In this paper, we for the first time provide a solution to detect
the wireless channel on which a packet has been received on a smartphone. We
experimentally evaluate our proposed technique on multiple different smartphone
models. Our results help to make contact tracing more robust by improving the
accuracy of distance estimation.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:08:09 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 22:50:41 GMT""},{""version"":""v3"",""created"":""Mon, 27 Jul 2020 09:46:24 GMT""}]","2020-07-28"
"2006.09100","Jonas Falkner","Jonas K. Falkner and Lars Schmidt-Thieme","Learning to Solve Vehicle Routing Problems with Time Windows through
  Joint Attention",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many real-world vehicle routing problems involve rich sets of constraints
with respect to the capacities of the vehicles, time windows for customers etc.
While in recent years first machine learning models have been developed to
solve basic vehicle routing problems faster than optimization heuristics,
complex constraints rarely are taken into consideration. Due to their general
procedure to construct solutions sequentially route by route, these methods
generalize unfavorably to such problems. In this paper, we develop a policy
model that is able to start and extend multiple routes concurrently by using
attention on the joint action space of several tours. In that way the model is
able to select routes and customers and thus learns to make difficult
trade-offs between routes. In comprehensive experiments on three variants of
the vehicle routing problem with time windows we show that our model called
JAMPR works well for different problem sizes and outperforms the existing
state-of-the-art constructive model. For two of the three variants it also
creates significantly better solutions than a comparable meta-heuristic solver.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:08:10 GMT""}]","2020-06-17"
"2006.09101","Tali Pinsky","Adam Clay and Tali Pinsky","Graph manifolds that admit arbitrarily many Anosov flows","20 pages, 7 figures. This version corrects the main result of the
  previous version",,,,"math.DS math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For each natural number n, we construct an example of a graph manifold
supporting at least n different Anosov flows that are not orbit equivalent. Our
construction is reminiscent of the Thurston-Handel construction: we cut a
geodesic flow on a surface of constant negative curvature into two pieces,
modify the flow in each piece by pulling back to finite covers, and glue
together compatible pairs of pullback flows along their boundary tori to get
many distinct flows on the resulting graph manifold.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:10:39 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 18:26:11 GMT""}]","2021-03-23"
"2006.09102","Kacper Kania","Kacper Kania, Maciej Zi\k{e}ba, Tomasz Kajdanowicz","UCSG-Net -- Unsupervised Discovering of Constructive Solid Geometry Tree","Accepted to Thirty-fourth Conference on Neural Information Processing
  Systems (NeurIPS 2020). Project page: https://kacperkan.github.io/ucsgnet.
  Project video: https://www.youtube.com/watch?v=s1p4UHtUG3g&feature=emb_title.
  Comments: 13 pages, 7 figures; apply reviewers' remarks, fix the reference to
  the CSG-Net work",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Signed distance field (SDF) is a prominent implicit representation of 3D
meshes. Methods that are based on such representation achieved state-of-the-art
3D shape reconstruction quality. However, these methods struggle to reconstruct
non-convex shapes. One remedy is to incorporate a constructive solid geometry
framework (CSG) that represents a shape as a decomposition into primitives. It
allows to embody a 3D shape of high complexity and non-convexity with a simple
tree representation of Boolean operations. Nevertheless, existing approaches
are supervised and require the entire CSG parse tree that is given upfront
during the training process. On the contrary, we propose a model that extracts
a CSG parse tree without any supervision - UCSG-Net. Our model predicts
parameters of primitives and binarizes their SDF representation through
differentiable indicator function. It is achieved jointly with discovering the
structure of a Boolean operators tree. The model selects dynamically which
operator combination over primitives leads to the reconstruction of high
fidelity. We evaluate our method on 2D and 3D autoencoding tasks. We show that
the predicted parse tree representation is interpretable and can be used in CAD
software.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:13:37 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 07:24:14 GMT""},{""version"":""v3"",""created"":""Tue, 20 Oct 2020 17:32:15 GMT""}]","2020-10-21"
"2006.09103","Andrii Shidlich L","F. G. Abdullayev, S. O. Chaichenko, M. Imashkyzy, A. L. Shidlich","Jackson-type inequalities and widths of functional classes in the
  Musielak-Orlicz type spaces","arXiv admin note: substantial text overlap with arXiv:2005.05597",,,,"math.CA cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the Musielak-Orlicz type spaces ${\mathcal S}_{\bf M}$, exact Jackson-type
inequalities are obtained in terms of best approximations of functions and the
averaged values of their generalized moduli of smoothness. The values of
Kolmogorov, Bernstein, linear, and projective widths in ${\mathcal S}_{\bf M}$
are found for classes of periodic functions defined by certain conditions on
the averaged values of the generalized moduli of smoothness.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:24:21 GMT""}]","2020-06-17"
"2006.09104","Jiacheng Sun","Jiacheng Sun, Xiangyong Cao, Hanwen Liang, Weiran Huang, Zewei Chen,
  Zhenguo Li","New Interpretations of Normalization Methods in Deep Learning","Accepted by AAAI 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, a variety of normalization methods have been proposed to
help train neural networks, such as batch normalization (BN), layer
normalization (LN), weight normalization (WN), group normalization (GN), etc.
However, mathematical tools to analyze all these normalization methods are
lacking. In this paper, we first propose a lemma to define some necessary
tools. Then, we use these tools to make a deep analysis on popular
normalization methods and obtain the following conclusions: 1) Most of the
normalization methods can be interpreted in a unified framework, namely
normalizing pre-activations or weights onto a sphere; 2) Since most of the
existing normalization methods are scaling invariant, we can conduct
optimization on a sphere with scaling symmetry removed, which can help
stabilize the training of network; 3) We prove that training with these
normalization methods can make the norm of weights increase, which could cause
adversarial vulnerability as it amplifies the attack. Finally, a series of
experiments are conducted to verify these claims.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:26:13 GMT""}]","2020-06-17"
"2006.09105","Anvar Baimuratov","Michael F\""org, Anvar S. Baimuratov, Stanislav Yu. Kruchinin, Ilia A.
  Vovk, Johannes Scherzer, Jonathan F\""orste, Victor Funk, Kenji Watanabe,
  Takashi Taniguchi, Alexander H\""ogele","Moir\'e excitons in MoSe$_2$-WSe$_2$ heterobilayers and heterotrilayers",,,"10.1038/s41467-021-21822-z",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Layered two-dimensional materials exhibit rich transport and optical
phenomena in twisted or lattice-incommensurate heterostructures with spatial
variations of interlayer hybridization arising from moir\'e interference
effects. Here, we report experimental and theoretical studies of excitons in
twisted heterobilayers and heterotrilayers of transition metal dichalcogenides.
Using MoSe$_2$-WSe$_2$ stacks as representative realizations of twisted van der
Waals bilayer and trilayer heterostructures, we observe contrasting optical
signatures and interpret them in the theoretical framework of interlayer
moir\'e excitons in different spin and valley configurations. We conclude that
the photoluminescence of MoSe$_2$-WSe$_2$ heterobilayer is consistent with
joint contributions from radiatively decaying valley-direct interlayer excitons
and phonon-assisted emission from momentum-indirect reservoirs that reside in
spatially distinct regions of moir\'e supercells, whereas the heterotrilayer
emission is entirely due to momentum-dark interlayer excitons of hybrid-layer
valleys. Our results highlight the profound role of interlayer hybridization
for transition metal dichalcogenide heterostacks and other realizations of
multi-layered semiconductor van der Waals heterostructures.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:27:14 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 14:42:54 GMT""}]","2021-03-16"
"2006.09106","Noah Rosenberg","Filippo Disanto, Michael Fuchs, Ariel R. Paningbatan, Noah A.
  Rosenberg","The distributions under two species-tree models of the number of root
  ancestral configurations for matching gene trees and species trees","28 pages, 9 figures",,,,"math.CO q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a pair consisting of a gene tree and a species tree, the ancestral
configurations at an internal node of the species tree are the distinct sets of
gene lineages that can be present at that node. Ancestral configurations appear
in computations of gene tree probabilities under evolutionary models
conditional on fixed species trees, and the enumeration of root ancestral
configurations -- ancestral configurations at the root of the species tree --
assists in describing the complexity of these computations. In the case that
the gene tree matches the species tree in topology, we study the distribution
of the number of root ancestral configurations of a random labeled tree
topology under each of two models.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:29:28 GMT""}]","2020-06-17"
"2006.09107","Yordan Hristov","Yordan Hristov, Subramanian Ramamoorthy","Learning from Demonstration with Weakly Supervised Disentanglement","18 pages, 16 figures, accepted at the International Conference on
  Learning Representations (ICLR) 2021, supplementary website at
  https://sites.google.com/view/weak-label-lfd",,,,"cs.RO cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robotic manipulation tasks, such as wiping with a soft sponge, require
control from multiple rich sensory modalities. Human-robot interaction, aimed
at teaching robots, is difficult in this setting as there is potential for
mismatch between human and machine comprehension of the rich data streams. We
treat the task of interpretable learning from demonstration as an optimisation
problem over a probabilistic generative model. To account for the
high-dimensionality of the data, a high-capacity neural network is chosen to
represent the model. The latent variables in this model are explicitly aligned
with high-level notions and concepts that are manifested in a set of
demonstrations. We show that such alignment is best achieved through the use of
labels from the end user, in an appropriately restricted vocabulary, in
contrast to the conventional approach of the designer picking a prior over the
latent variables. Our approach is evaluated in the context of two table-top
robot manipulation tasks performed by a PR2 robot -- that of dabbing liquids
with a sponge (forcefully pressing a sponge and moving it along a surface) and
pouring between different containers. The robot provides visual information,
arm joint positions and arm joint efforts. We have made videos of the tasks and
data available - see supplementary materials at:
https://sites.google.com/view/weak-label-lfd.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:29:51 GMT""},{""version"":""v2"",""created"":""Fri, 26 Mar 2021 12:15:52 GMT""}]","2021-03-29"
"2006.09108","Jinghua Yu","Jinghua Yu, Stefan Wagner, Feng Luo","An STPA-based Approach for Systematic Security Analysis of In-vehicle
  Diagnostic and Software Update Systems","6 pages, 7 figures, submitted to FISITA 2020 World Congress",,,"F2020-VES-020, FISITA Web Congress 2020","cs.CR cs.SE cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The in-vehicle diagnostic and software update system, which supports remote
diagnostic and Over-The-Air (OTA) software updates, is a critical attack goal
in automobiles. Adversaries can inject malicious software into vehicles or
steal sensitive information through communication channels. Therefore, security
analysis, which identifies potential security issues, needs to be conducted in
system design. However, existing security analyses of in-vehicle systems are
threat-oriented, which start with threat identification and assess risks by
brainstorming. In this paper, a system-oriented approach is proposed on the
basis of the System-Theoretic Process Analysis (STPA). The proposed approach
extends the original STPA from the perspective of data flows and is applicable
for information-flow-based systems. Besides, we propose a general model for
in-vehicle diagnostic and software update systems and use it to establish a
security analysis guideline. In comparison with threat-oriented approaches, the
proposed approach shifts from focusing on threats to system vulnerabilities and
seems to be efficient to prevent the system from known or even unknown threats.
Furthermore, as an extension of the STPA, which has been proven to be
applicable to high level designs, the proposed approach can be well integrated
into high-level analyses and perform co-design in different disciplines within
a unified STPA framework.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:34:17 GMT""}]","2020-12-01"
"2006.09109","Steffen Eger","Steffen Eger and Johannes Daxenberger and Iryna Gurevych","How to Probe Sentence Embeddings in Low-Resource Languages: On
  Structural Design Choices for Probing Task Evaluation","Accepted for Publication at CONLL 2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sentence encoders map sentences to real valued vectors for use in downstream
applications. To peek into these representations - e.g., to increase
interpretability of their results - probing tasks have been designed which
query them for linguistic knowledge. However, designing probing tasks for
lesser-resourced languages is tricky, because these often lack large-scale
annotated data or (high-quality) dependency parsers as a prerequisite of
probing task design in English. To investigate how to probe sentence embeddings
in such cases, we investigate sensitivity of probing task results to structural
design choices, conducting the first such large scale study. We show that
design choices like size of the annotated probing dataset and type of
classifier used for evaluation do (sometimes substantially) influence probing
outcomes. We then probe embeddings in a multilingual setup with design choices
that lie in a 'stable region', as we identify for English, and find that
results on English do not transfer to other languages. Fairer and more
comprehensive sentence-level probing evaluation should thus be carried out on
multiple languages in the future.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:37:50 GMT""},{""version"":""v2"",""created"":""Wed, 28 Oct 2020 12:38:37 GMT""}]","2020-10-29"
"2006.09110","Chaibata Seida","Chaibata Seida, Abderrahim El allati, Nasser Metwally, Yassine
  Hassouni","Bidirectional Teleportation using Fisher Information",,,"10.1142/S0217732320502727",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this contribution, we reformulated the bidirectional teleportation
protocol suggested in [7], by means of Bloch vectors as well as the local
operations are represented by using Pauli operators. Analytical and numerical
calculations for the teleported state and Fisher information are introduced. It
is shown that both quantities depend on the initial state settings of the
teleported qubits and their triggers. The Fidelities and the Fisher information
of the bidirectionally teleported states are maximized when the qubit and its
trigger are polarized in the same direction. The minimum values are predicted
if both initial qubits have different polarization or non-zero phase. The
maximum values of the Fidelity and the quantum Fisher information are the same,
but they are predicted at different polarization angles. We display that the
multi-parameter form is much better than the single parameter form, where it
satisfies the bounds of classical, entangled systems and the uncertainty
principle.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:39:29 GMT""}]","2020-08-24"
"2006.09111","Shuisheng Zhou","Zhou Shuisheng and Zhou Wendi","Unified SVM Algorithm Based on LS-DC Loss",,"Machine Learning 2021","10.1007/s10994-021-05996-7",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the past two decades, support vector machine (SVM) has become a popular
supervised machine learning model, and plenty of distinct algorithms are
designed separately based on different KKT conditions of the SVM model for
classification/regression with different losses, including the convex loss or
nonconvex loss. In this paper, we propose an algorithm that can train different
SVM models in a \emph{unified} scheme. First, we introduce a definition of the
\emph{LS-DC} (\textbf{l}east \textbf{s}quares type of \textbf{d}ifference of
\textbf{c}onvex) loss and show that the most commonly used losses in the SVM
community are LS-DC loss or can be approximated by LS-DC loss. Based on DCA
(difference of convex algorithm), we then propose a unified algorithm, called
\emph{UniSVM}, which can solve the SVM model with any convex or nonconvex LS-DC
loss, in which only a vector is computed, especially by the specifically chosen
loss. Particularly, for training robust SVM models with nonconvex losses,
UniSVM has a dominant advantage over all existing algorithms because it has a
closed-form solution per iteration, while the existing algorithms always need
to solve an L1SVM/L2SVM per iteration. Furthermore, by the low-rank
approximation of the kernel matrix, UniSVM can solve the large-scale nonlinear
problems with efficiency. To verify the efficacy and feasibility of the
proposed algorithm, we perform many experiments on some small artificial
problems and some large benchmark tasks with/without outliers for
classification and regression for comparison with state-of-the-art algorithms.
The experimental results demonstrate that UniSVM can achieve comparable
performance in less training time. The foremost advantage of UniSVM is that its
core code in Matlab is less than 10 lines; hence, it can be easily grasped by
users or researchers.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:40:06 GMT""},{""version"":""v2"",""created"":""Fri, 4 Sep 2020 03:40:52 GMT""},{""version"":""v3"",""created"":""Tue, 26 Jan 2021 04:07:45 GMT""},{""version"":""v4"",""created"":""Tue, 11 May 2021 03:25:01 GMT""}]","2022-04-04"
"2006.09112","Panagiotis Stylianou","Stephen Brown, Christoph Englert, Peter Galler, Panagiotis Stylianou","Electroweak Top Couplings, Partial Compositeness and Top Partner
  Searches","14 pages, 5 figures, 1 table; v2: version accepted in PRD","Phys. Rev. D 102, 075021 (2020)","10.1103/PhysRevD.102.075021",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Partial top quark compositeness is a crucial aspect of theories with strong
electroweak symmetry breaking. Together with the heavy top partners that lift
the top quark mass to its observed value, these theories predict correlated
modifications of the top quark's electroweak couplings. Associated measurements
therefore provide direct constraints on the ultraviolet structure of the
underlying hypercolour dynamics. In this paper we employ a minimal version of
top compositeness to discuss how measurements related to the top's electroweak
gauge interactions can inform the potential composite nature of the TeV scale.
In doing so, we identify the dominant factors that limit the BSM sensitivity.
Extrapolating to a future 100 TeV hadron collider, we demonstrate that top
quark measurements performed at highest precision can provide complementary
information to resonance search by performing a representative resonant top
partner search that specifically targets the correlated resonant electroweak
top partner signatures.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:40:10 GMT""},{""version"":""v2"",""created"":""Wed, 7 Oct 2020 11:11:00 GMT""}]","2020-10-28"
"2006.09113","Maxim Chernodub","M. N. Chernodub, Harold Erbin, V. A. Goy, A. V. Molochkov","Topological defects and confinement with machine learning: the case of
  monopoles in compact electrodynamics","15 pages, 36 figures; minor revisions, published version","Phys. Rev. D 102, 054501 (2020)","10.1103/PhysRevD.102.054501",,"hep-lat cs.LG hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the advantages of machine learning techniques to recognize the
dynamics of topological objects in quantum field theories. We consider the
compact U(1) gauge theory in three spacetime dimensions as the simplest example
of a theory that exhibits confinement and mass gap phenomena generated by
monopoles. We train a neural network with a generated set of monopole
configurations to distinguish between confinement and deconfinement phases,
from which it is possible to determine the deconfinement transition point and
to predict several observables. The model uses a supervised learning approach
and treats the monopole configurations as three-dimensional images (holograms).
We show that the model can determine the transition temperature with accuracy,
which depends on the criteria implemented in the algorithm. More importantly,
we train the neural network with configurations from a single lattice size
before making predictions for configurations from other lattice sizes, from
which a reliable estimation of the critical temperatures are obtained.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:41:19 GMT""},{""version"":""v2"",""created"":""Sat, 24 Oct 2020 08:33:09 GMT""}]","2020-10-27"
"2006.09114","Olof Mogren","David Ericsson, Adam \""Ostberg, Edvin Listo Zec, John Martinsson, Olof
  Mogren","Adversarial representation learning for private speech generation","Submitted to ICML 2020 Workshop on Self-supervision in Audio and
  Speech (SAS)",,,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As more and more data is collected in various settings across organizations,
companies, and countries, there has been an increase in the demand of user
privacy. Developing privacy preserving methods for data analytics is thus an
important area of research. In this work we present a model based on generative
adversarial networks (GANs) that learns to obfuscate specific sensitive
attributes in speech data. We train a model that learns to hide sensitive
information in the data, while preserving the meaning in the utterance. The
model is trained in two steps: first to filter sensitive information in the
spectrogram domain, and then to generate new and private information
independent of the filtered one. The model is based on a U-Net CNN that takes
mel-spectrograms as input. A MelGAN is used to invert the spectrograms back to
raw audio waveforms. We show that it is possible to hide sensitive information
such as gender by generating new data, trained adversarially to maintain
utility and realism.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:44:35 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 09:28:18 GMT""}]","2020-06-18"
"2006.09115","Jevgenijs Ivanovs","Jevgenijs Ivanovs and Jakob D. Th{\o}stesen","Discretization of the Lamperti representation of a positive self-similar
  Markov process",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers discretization of the L\'evy process appearing in the
Lamperti representation of a strictly positive self-similar Markov process.
Limit theorems for the resulting approximation are established under some
regularity assumptions on the given L\'evy process. Additionally, the scaling
limit of a positive self-similar Markov process at small times is provided.
Finally, we present an application to simulation of self-similar L\'evy
processes conditioned to stay positive.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:49:28 GMT""}]","2020-06-17"
"2006.09116","Junting Pan","Siyu Chen, Junting Pan, Guanglu Song, Manyuan Zhang, Hao Shao, Ziyi
  Lin, Jing Shao, Hongsheng Li, Yu Liu","1st place solution for AVA-Kinetics Crossover in AcitivityNet Challenge
  2020","arXiv admin note: substantial text overlap with arXiv:2006.07976",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This technical report introduces our winning solution to the spatio-temporal
action localization track, AVA-Kinetics Crossover, in ActivityNet Challenge
2020. Our entry is mainly based on Actor-Context-Actor Relation Network. We
describe technical details for the new AVA-Kinetics dataset, together with some
experimental results. Without any bells and whistles, we achieved 39.62 mAP on
the test set of AVA-Kinetics, which outperforms other entries by a large
margin. Code will be available at: https://github.com/Siyu-C/ACAR-Net.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:52:59 GMT""}]","2020-06-17"
"2006.09117","Anh Nguyen","Anh Nguyen, Dennis Kundrat, Giulio Dagnino, Wenqiang Chi, Mohamed E.
  M. K. Abdelaziz, Yao Guo, YingLiang Ma, Trevor M. Y. Kwok, Celia Riga, and
  Guang-Zhong Yang","End-to-End Real-time Catheter Segmentation with Optical Flow-Guided
  Warping during Endovascular Intervention","ICRA 2020",,,,"eess.IV cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate real-time catheter segmentation is an important pre-requisite for
robot-assisted endovascular intervention. Most of the existing learning-based
methods for catheter segmentation and tracking are only trained on small-scale
datasets or synthetic data due to the difficulties of ground-truth annotation.
Furthermore, the temporal continuity in intraoperative imaging sequences is not
fully utilised. In this paper, we present FW-Net, an end-to-end and real-time
deep learning framework for endovascular intervention. The proposed FW-Net has
three modules: a segmentation network with encoder-decoder architecture, a flow
network to extract optical flow information, and a novel flow-guided warping
function to learn the frame-to-frame temporal continuity. We show that by
effectively learning temporal continuity, the network can successfully segment
and track the catheters in real-time sequences using only raw ground-truth for
training. Detailed validation results confirm that our FW-Net outperforms
state-of-the-art techniques while achieving real-time performance.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:53:27 GMT""}]","2020-06-17"
"2006.09118","Kunhe Yang","Kunhe Yang, Lin F. Yang, Simon S. Du","$Q$-learning with Logarithmic Regret","Accepted by AISTATS 2021",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents the first non-asymptotic result showing that a model-free
algorithm can achieve a logarithmic cumulative regret for episodic tabular
reinforcement learning if there exists a strictly positive sub-optimality gap
in the optimal $Q$-function. We prove that the optimistic $Q$-learning studied
in [Jin et al. 2018] enjoys a ${\mathcal{O}}\left(\frac{SA\cdot
\mathrm{poly}\left(H\right)}{\Delta_{\min}}\log\left(SAT\right)\right)$
cumulative regret bound, where $S$ is the number of states, $A$ is the number
of actions, $H$ is the planning horizon, $T$ is the total number of steps, and
$\Delta_{\min}$ is the minimum sub-optimality gap. This bound matches the
information theoretical lower bound in terms of $S,A,T$ up to a
$\log\left(SA\right)$ factor. We further extend our analysis to the discounted
setting and obtain a similar logarithmic cumulative regret bound.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:01:33 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 11:44:44 GMT""}]","2021-02-24"
"2006.09119","Samin Mohammadi","Samin Mohammadi, Mathieu Chapon, Arthur Fremond","Query Intent Detection from the SEO Perspective",,,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Google users have different intents from their queries such as acquiring
information, buying products, comparing or simulating services, looking for
products, and so on. Understanding the right intention of users helps to
provide i) better content on web pages from the Search Engine Optimization
(SEO) perspective and ii) more user-satisfying results from the search engine
perspective. In this study, we aim to identify the user query's intent by
taking advantage of Google results and machine learning methods. Our proposed
approach is a clustering model that exploits some features to detect query's
intent. A list of keywords extracted from the clustered queries is used to
identify the intent of a new given query. Comparing the clustering results with
the intents predicted by filtered keywords show the efficiency of the extracted
keywords for detecting intents.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:08:29 GMT""}]","2020-06-17"
"2006.09120","Antonio Trusiani","Antonio Trusiani","Continuity method with movable singularities for classical
  Monge-Amp\`ere equations","Proof of Theorem C changed, some typos corrected",,,,"math.DG math.AP math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On a compact K\""ahler manifold $(X,\omega)$, we study the strong continuity
of solutions with prescribed singularities of complex Monge-Amp\`ere equations
with integrable Lebesgue densities. Moreover, we give sufficient conditions for
the strong continuity of solutions when the right-hand sides are modified to
include all (log) K\""ahler-Einstein metrics with prescribed singularities. Our
findings can be interpreted as closedness of new continuity methods in which
the densities vary together with the prescribed singularities. For
Monge-Amp\`ere equations of Fano type, we also prove an openness result when
the singularities decrease. As an application, we deduce a strong stability
result for (log-)K\""ahler Einstein metrics on semi-K\""ahler classes given as
modifications of $\{\omega\}$.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:10:46 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 20:48:20 GMT""},{""version"":""v3"",""created"":""Mon, 18 Apr 2022 10:31:55 GMT""}]","2022-04-19"
"2006.09123","Sergei Vassilvitskii","Michael Mitzenmacher and Sergei Vassilvitskii","Algorithms with Predictions","survey is to appear as a chapter in Beyond the Worst-Case Analysis of
  Algorithms, a collection edited by Tim Roughgarden. We hope to occasionally
  update the survey here, with new versions that include discussions of new
  results and advances in the area of Algorithms with Predictions",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce algorithms that use predictions from machine learning applied to
the input to circumvent worst-case analysis. We aim for algorithms that have
near optimal performance when these predictions are good, but recover the
prediction-less worst case behavior when the predictions have large errors.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:13:28 GMT""}]","2020-06-17"
"2006.09124","Alexandros Karam Dr.","Ioannis D. Gialamas, Alexandros Karam, Antonio Racioppi","Dynamically induced Planck scale and inflation in the Palatini
  formulation","section 4 extended, references added","JCAP 11 (2020) 014","10.1088/1475-7516/2020/11/014",,"gr-qc astro-ph.CO hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study non-minimal Coleman-Weinberg inflation in the Palatini formulation
of gravity in the presence of an $R^2$ term. The Planck scale is dynamically
generated by the vacuum expectation value of the inflaton via its non-minimal
coupling to the curvature scalar $R$. We show that the addition of the $R^2$
term in Palatini gravity makes non-minimal Coleman-Weinberg inflation again
compatible with observational data.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:13:52 GMT""},{""version"":""v2"",""created"":""Tue, 17 Nov 2020 16:28:08 GMT""}]","2020-11-20"
"2006.09125","Mohsen Chitsaz","Mohsen Chitsaz","A small molecule drug candidate targeting SARS-CoV-2 main protease",,,,,"q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new coronavirus identified as SARS-CoV-2 virus has brought the world to a
state of crisis, causing a major pandemic, claiming more than 433,000 lives and
instigating major financial damage to the global economy. Despite current
efforts, developing safe and effective treatments remains a major challenge.
Moreover, new strains of the virus are likely to emerge in the future. To
prevent future pandemics, several drugs with various mechanisms of action are
required. Drug discovery efforts against the virus fall into two main
categories: (a) monoclonal antibodies targeting the spike protein of the virus
and blocking it from entry; (b) small molecule inhibitors targeting key
proteins of the virus, interfering with replication and translation of the
virus. In this study, we are presenting a computational investigation of a
potential drug candidate that targets SARS-CoV-2 protease, a viral protein
critical for replication and translation of the virus.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:14:31 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 02:25:06 GMT""}]","2020-06-18"
"2006.09126","Amirhossein Rajabi","Amirhossein Rajabi and Carsten Witt","Evolutionary Algorithms with Self-adjusting Asymmetric Mutation","16 pages. An extended abstract of this paper will be published in the
  proceedings of PPSN 2020",,"10.1007/978-3-030-58112-1_46",,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Evolutionary Algorithms (EAs) and other randomized search heuristics are
often considered as unbiased algorithms that are invariant with respect to
different transformations of the underlying search space. However, if a certain
amount of domain knowledge is available the use of biased search operators in
EAs becomes viable. We consider a simple (1+1) EA for binary search spaces and
analyze an asymmetric mutation operator that can treat zero- and one-bits
differently. This operator extends previous work by Jansen and Sudholt (ECJ
18(1), 2010) by allowing the operator asymmetry to vary according to the
success rate of the algorithm. Using a self-adjusting scheme that learns an
appropriate degree of asymmetry, we show improved runtime results on the class
of functions OneMax$_a$ describing the number of matching bits with a fixed
target $a\in\{0,1\}^n$.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:16:50 GMT""}]","2020-10-26"
"2006.09127","Harald Koestler Prof. Dr.","Michael Holzmann and Harald Koestler","Quantum simulation and circuit design for solving multidimensional
  Poisson equations",,,,,"cs.ET quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many methods solve Poisson equations by using grid techniques which
discretize the problem in each dimension. Most of these algorithms are subject
to the curse of dimensionality, so that they need exponential runtime. In the
paper ""Quantum algorithm and circuit design solving the Poisson equation"" a
quantum algorithm is shown running in polylog time to produce a quantum state
representing the solution of the Poisson equation. In this paper a quantum
simulation of an extended circuit design based on this algorithm is made on a
classical computer. Our purpose is to test an efficient circuit design which
can break the curse of dimensionality on a quantum computer. Due to the
exponential rise of the Hilbert space this design is optimized on a small
number of qubits. We use Microsoft's Quantum Development Kit and its simulator
of an ideal quantum computer to validate the correctness of this algorithm.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:17:31 GMT""}]","2020-06-17"
"2006.09128","Suraj Srinivas","Suraj Srinivas, Francois Fleuret","Rethinking the Role of Gradient-Based Attribution Methods for Model
  Interpretability","Oral Presentation at ICLR 2021",,,,"cs.LG cs.CV stat.ML","http://creativecommons.org/licenses/by/4.0/","  Current methods for the interpretability of discriminative deep neural
networks commonly rely on the model's input-gradients, i.e., the gradients of
the output logits w.r.t. the inputs. The common assumption is that these
input-gradients contain information regarding $p_{\theta} ( y \mid x)$, the
model's discriminative capabilities, thus justifying their use for
interpretability. However, in this work we show that these input-gradients can
be arbitrarily manipulated as a consequence of the shift-invariance of softmax
without changing the discriminative function. This leaves an open question: if
input-gradients can be arbitrary, why are they highly structured and
explanatory in standard models?
  We investigate this by re-interpreting the logits of standard softmax-based
classifiers as unnormalized log-densities of the data distribution and show
that input-gradients can be viewed as gradients of a class-conditional density
model $p_{\theta}(x \mid y)$ implicit within the discriminative model. This
leads us to hypothesize that the highly structured and explanatory nature of
input-gradients may be due to the alignment of this class-conditional model
$p_{\theta}(x \mid y)$ with that of the ground truth data distribution
$p_{\text{data}} (x \mid y)$. We test this hypothesis by studying the effect of
density alignment on gradient explanations. To achieve this alignment we use
score-matching, and propose novel approximations to this algorithm to enable
training large-scale models.
  Our experiments show that improving the alignment of the implicit density
model with the data distribution enhances gradient structure and explanatory
power while reducing this alignment has the opposite effect. Overall, our
finding that input-gradients capture information regarding an implicit
generative model implies that we need to re-think their use for interpreting
discriminative models.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:17:32 GMT""},{""version"":""v2"",""created"":""Wed, 3 Mar 2021 09:42:58 GMT""}]","2021-03-04"
"2006.09129","Neel Patel","Neel Patel, Reza Shokri, Yair Zick","Model Explanations with Differential Privacy","33 pages, 9 figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Black-box machine learning models are used in critical decision-making
domains, giving rise to several calls for more algorithmic transparency. The
drawback is that model explanations can leak information about the training
data and the explanation data used to generate them, thus undermining data
privacy. To address this issue, we propose differentially private algorithms to
construct feature-based model explanations. We design an adaptive
differentially private gradient descent algorithm, that finds the minimal
privacy budget required to produce accurate explanations. It reduces the
overall privacy loss on explanation data, by adaptively reusing past
differentially private explanations. It also amplifies the privacy guarantees
with respect to the training data. We evaluate the implications of
differentially private models and our privacy mechanisms on the quality of
model explanations.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:18:02 GMT""}]","2020-06-17"
"2006.09130","Antonio Trusiani","Antonio Trusiani","K\""ahler-Einstein metrics with prescribed singularities on Fano
  manifolds","Definition of the $\alpha_{\omega}$-function and Theorem A modified,
  other related changes. Improved and final version: to appear in ""Journal
  f\""ur die reine und angewandte Mathematik (Crelle's Journal)""",,,,"math.DG math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a Fano manifold $(X,\omega)$ we develop a variational approach to
characterize analytically the existence of K\""ahler-Einstein metrics with
prescribed singularities, assuming that these singularities can be approximated
algebraically. Moreover, we define a function $\alpha_{\omega}$ on the set of
prescribed singularities which generalizes Tian's $\alpha$-invariant, showing
that its upper level set $\{\alpha_{\omega}(\cdot)>\frac{n}{n+1}\}$ produces a
subset of the K\""ahler-Einstein locus, i.e. of the locus given by all
prescribed singularities that admit K\""ahler-Einstein metrics. In particular,
we prove that many $K$-stable manifolds admit all possible K\""ahler-Einstein
metrics with prescribed singularities. Conversely, we show that enough
positivity of the $\alpha$-invariant function at non-trivial prescribed
singularities (or other conditions) implies the existence of genuine
K\""ahler-Einstein metrics. Finally, through a continuity method, we also prove
the strong continuity of K\""ahler-Einstein metrics on curves of totally ordered
prescribed singularities when the relative automorphism groups are discrete.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:18:52 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 10:09:18 GMT""},{""version"":""v3"",""created"":""Mon, 19 Jul 2021 10:20:40 GMT""},{""version"":""v4"",""created"":""Thu, 7 Jul 2022 08:53:16 GMT""}]","2022-07-08"
"2006.09131","Scott A. Crooker","K.W. Post, A. Legros, D.G. Rickel, J. Singleton, R.D. McDonald, Xi He,
  I. Bozovic, X. Xu, X. Shi, N.P. Armitage, S.A. Crooker","Observation of cyclotron resonance and measurement of the hole mass in
  optimally-doped La$_{2-x}$Sr$_{x}$CuO$_4$","6 pages, 4 figures","Phys. Rev. B 103, 134515 (2021)","10.1103/PhysRevB.103.134515",,"cond-mat.supr-con cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using time-domain terahertz spectroscopy in pulsed magnetic fields up to 31
T, we measure the terahertz optical conductivity in an optimally-doped thin
film of the high temperature superconducting cuprate
La$_{1.84}$Sr$_{0.16}$CuO$_4$. We observe systematic changes in the
circularly-polarized complex optical conductivity that are consistent with
cyclotron absorption of p-type charge carriers characterized by a cyclotron
mass of $4.9\pm 0.8$ $m_{\rm e}$, and a scattering rate that increases with
magnetic field. These results open the door to studies aimed at characterizing
the degree to which electron-electron interactions influence carrier masses in
cuprate superconductors.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:19:22 GMT""}]","2021-05-05"
"2006.09132","Amaury Pouly","Mohan Dantam, Amaury Pouly","On the Decidability of Reachability in Continuous Time Linear
  Time-Invariant Systems",,,,,"math.OC cs.LO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the decidability of state-to-state reachability in linear
time-invariant control systems over continuous time. We analyse this problem
with respect to the allowable control sets, which are assumed to be the image
under a linear map of the unit hypercube. This naturally models bounded
(sometimes called saturated) controls. Decidability of the version of the
reachability problem in which control sets are affine subspaces of
$\mathbb{R}^n$ is a fundamental result in control theory. Our first result is
decidability in two dimensions ($n=2$) if the matrix $A$ satisfies some
spectral conditions, and conditional decidablility in general. If the
transformation matrix $A$ is diagonal with rational entries (or rational
multiples of the same algebraic number) then the reachability problem is
decidable. If the transformation matrix $A$ only has real eigenvalues, the
reachability problem is conditionally decidable. The time-bounded reachability
problem is conditionally decidable, and unconditionally decidable in two
dimensions. Some of our decidability results are conditional in that they rely
on the decidability of certain mathematical theories, namely the theory of the
reals with exponential ($\mathfrak{R}_{\exp}$) and with bounded sine
($\mathfrak{R}_{\exp,\sin}$). We also obtain a hardness result for a mild
generalization of the problem where the target is simple set (hypercube of
dimension $n-1$ or hyperplane) instead of a point, and the control set is a
convex bounded polytope. In this case, we show that the problem is at least as
hard as the \emph{Continuous Positivity problem} or the \emph{Nontangential
Continuous Positivity problem}.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:20:30 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 17:13:24 GMT""}]","2021-03-16"
"2006.09133","Alexei Kulik","Alexei Kulik, Szymon Peszat, Enrico Priola","Gradient formula for transition semigroup corresponding to stochastic
  equation driven by a system of independent L\'evy processes",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $(P_t)$ be the transition semigroup of the Markov family $(X^x(t))$
defined by SDE $$ d X= b(X) dt + d Z, \qquad X(0)=x, $$ where $Z=\left(Z_1,
\ldots, Z_d\right)^*$ is a system of independent real-valued L\'evy processes.
Using the Malliavin calculus we establish the following gradient formula $$
\nabla P_tf(x)= \mathbb{E}\, f\left(X^x(t)\right) Y(t,x), \qquad f\in
B_b(\mathbb{R}^d), $$ where the random field $Y$ does not depend on $f$. Sharp
estimates on $\nabla P_tf(x)$ when $Z_1, \ldots , Z_d$ are $\alpha$-stable
processes, $\alpha \in (0,2)$, are also given.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:22:06 GMT""},{""version"":""v2"",""created"":""Thu, 17 Feb 2022 12:26:33 GMT""}]","2022-02-18"
"2006.09134","Li Shen","Yuesong Tian, Li Shen, Li Shen, Guinan Su, Zhifeng Li, Wei Liu","AlphaGAN: Fully Differentiable Architecture Search for Generative
  Adversarial Networks","In IEEE Transactions on Pattern Analysis and Machine Intelligence",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative Adversarial Networks (GANs) are formulated as minimax game
problems, whereby generators attempt to approach real data distributions by
virtue of adversarial learning against discriminators. The intrinsic problem
complexity poses the challenge to enhance the performance of generative
networks. In this work, we aim to boost model learning from the perspective of
network architectures, by incorporating recent progress on automated
architecture search into GANs. To this end, we propose a fully differentiable
search framework for generative adversarial networks, dubbed alphaGAN. The
searching process is formalized as solving a bi-level minimax optimization
problem, in which the outer-level objective aims for seeking a suitable network
architecture towards pure Nash Equilibrium conditioned on the generator and the
discriminator network parameters optimized with a traditional GAN loss in the
inner level. The entire optimization performs a first-order method by
alternately minimizing the two-level objective in a fully differentiable
manner, enabling architecture search to be completed in an enormous search
space. Extensive experiments on CIFAR-10 and STL-10 datasets show that our
algorithm can obtain high-performing architectures only with 3-GPU hours on a
single GPU in the search space comprised of approximate 2 ? 1011 possible
configurations. We also provide a comprehensive analysis on the behavior of the
searching process and the properties of searched architectures, which would
benefit further research on architectures for generative models. Pretrained
models and codes are available at https://github.com/yuesongtian/AlphaGAN.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:27:30 GMT""},{""version"":""v2"",""created"":""Fri, 11 Dec 2020 08:08:18 GMT""},{""version"":""v3"",""created"":""Sat, 7 Aug 2021 07:53:29 GMT""}]","2021-08-10"
"2006.09135","David H. Cohen","David H. Cohen (1), Jiaming Wang (1), V\'eronique Petit (2), Maurice
  A. Leutenegger (3), Lamiaa Dakir (4), Chloe Mayhue (1), Alexandre David-Uraz
  (2) ((1) Swarthmore, (2) U. Delaware, (3) NASA/GSFC, (4) Bryn Mawr)","Chandra spectral measurements of the O supergiant $\zeta$ Puppis
  indicate a surprising increase in the wind mass-loss rate over 18 years","Accepted by MNRAS. No longer a letter, but rather a nine page paper
  with several multi-panel figures showing all the line profiles. We have now
  included an analysis of the entire cycle 19 data set and present two
  model-independent confirmations of the line profile changes",,"10.1093/mnras/staa3124",,"astro-ph.SR astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  New long Chandra grating observations of the O supergiant $\zeta$ Pup show
not only a brightening of the x-ray emission line flux of 13 per cent in the 18
years since Chandra's first observing cycle, but also clear evidence - at more
than four sigma significance - of increased wind absorption signatures in its
Doppler-broadened x-ray emission line profiles. We demonstrate this with
non-parametric analysis of the profiles as well as Gaussian fitting and then
use the line-profile model fitting to derive a mass-loss rate of $2.47 \pm 0.09
\times 10^{-6}$ Msun/yr, which is a 40 per cent increase over the value
obtained from the cycle 1 data. The increase in the individual emission line
fluxes is greater for short-wavelength lines than long-wavelength lines, as
would be expected if a uniform increase in line emission is accompanied by an
increase in the wavelength-dependent absorption by the cold wind in which the
shock-heated plasma is embedded.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:28:53 GMT""},{""version"":""v2"",""created"":""Thu, 8 Oct 2020 15:04:35 GMT""}]","2020-10-21"
"2006.09136","Yuning You","Yuning You, Tianlong Chen, Zhangyang Wang, Yang Shen","When Does Self-Supervision Help Graph Convolutional Networks?","Supplementary materials are available at
  https://yyou1996.github.io/files/icml2020_ssgcn_supplement.pdf. ICML 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervision as an emerging technique has been employed to train
convolutional neural networks (CNNs) for more transferrable, generalizable, and
robust representation learning of images. Its introduction to graph
convolutional networks (GCNs) operating on graph data is however rarely
explored. In this study, we report the first systematic exploration and
assessment of incorporating self-supervision into GCNs. We first elaborate
three mechanisms to incorporate self-supervision into GCNs, analyze the
limitations of pretraining & finetuning and self-training, and proceed to focus
on multi-task learning. Moreover, we propose to investigate three novel
self-supervised learning tasks for GCNs with theoretical rationales and
numerical comparisons. Lastly, we further integrate multi-task self-supervision
into graph adversarial training. Our results show that, with properly designed
task forms and incorporation mechanisms, self-supervision benefits GCNs in
gaining more generalizability and robustness. Our codes are available at
https://github.com/Shen-Lab/SS-GCNs.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:29:48 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 18:08:01 GMT""},{""version"":""v3"",""created"":""Sat, 4 Jul 2020 21:52:20 GMT""},{""version"":""v4"",""created"":""Sat, 18 Jul 2020 00:24:26 GMT""}]","2020-07-21"
"2006.09137","Tomasz Antosiewicz","Krzysztof M. Czajkowski, Maria Bancerek and Tomasz J. Antosiewicz","Multipole analysis of substrate-supported dielectric nanoresonator
  arrays with T-matrix method",,"Phys. Rev. B 102, 085431 (2020)","10.1103/PhysRevB.102.085431",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Substrates, and layered media in general, are ubiquitous, affect the
properties of whatever is in their vicinity, and their influence is, in an
arbitrary framework, challenging to quantify analytically, especially for large
arrays which escape explicit numerical treatment due to the computational
burden. In this work, we develop a versatile T-matrix based framework in which
we generalize the coupled multipole model towards arbitrarily high multipole
orders and substrate-supported arrays. It allows us to study
substrate-supported random/amorphous arrays of high index dielectric
nanoparticles which are of wide interest due to relatively low losses and a
highly tunable optical response, making them promising elements for
nanophotonic devices. We discuss how multipole coupling rules evolve in the
presence of a substrate in amorphous arrays for three interaction mechanisms:
direct coupling between particles, substrate-mediated interparticle coupling
and substrate-mediated self-coupling. We show the interplay between array
density, distance from the substrate and its refractive in determining the
optical response of an array. As an example, we use this framework to analyze
refractometric sensing with substrate-supported arrays and demonstrate that the
substrate plays a crucial role in determining the array sensitivity.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:30:25 GMT""}]","2020-09-02"
"2006.09138","Xiaoyu Lei","Xiaoyu Lei and Zhennan Zhou","Multi-level Monte Carlo path integral molecular dynamics for thermal
  average calculation in the nonadiabatic regime",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the path integral approach, the thermal average in a
multi-electronic-state quantum systems can be approximated by the ring polymer
representation on an extended configuration space, where the additional degrees
of freedom are associated with the surface index of each bead. The primary goal
of this work is to propose a more efficient sampling algorithm for the
calculation of such thermal averages. We reformulate the extended ring polymer
approximation according to the configurations of the surface indexes, and by
introducing a proper reference measure, the reformulation is recast as a ratio
of two expectations of function expansions. By quantitatively estimating the
sub-estimators, and minimizing the total variance of the sampled average, we
propose a multi-level Monte Carlo path integral molecular dynamics method
(MLMC-PIMD) to achieve an optimal balance of computational cost and accuracy.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:32:59 GMT""},{""version"":""v2"",""created"":""Tue, 15 Sep 2020 10:05:36 GMT""},{""version"":""v3"",""created"":""Sat, 21 Nov 2020 02:45:38 GMT""}]","2020-11-24"
"2006.09139","Yangming Li","Yangming Li","Finite Groups with Some s-semipermutable subgroups",,,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Suppose that $G$ is a finite group and $H$ is a subgroup of $G$. We say that
$H$ is s-semipermutable in $G$ if $HG_p = G_pH$ for any Sylow $p$-subgroup
$G_p$ of $G$ with $(p, |H|) = 1$. We investigate the influence of
s-semipermutable subgroups on the structure of finite groups. Some recent
results are generalized.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:33:15 GMT""}]","2020-06-17"
"2006.09140","Jos\'e Lu\'is da Silva Dr.","Yuri Kondratiev and Yuliya Mishura and Jos\'e L. da Silva","Perpetual Integral Functionals of Multidimensional Stochastic Processes","11 pages","Stochastics, 2021","10.1080/17442508.2021.1900185",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper is devoted to the existence of integral functionals $\int_0^\infty
f(X(t))\,{\mathrm{d}t}$ for several classes of processes in $\mathbb{R}$ with
$d\ge 3$. Some examples such as Brownian motion, fractional Brownian motion,
compound Poisson process, Markov processes admitting densities of transitional
probabilities are considered.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:33:48 GMT""}]","2021-04-02"
"2006.09141","Javier Ferrando","Javier Ferrando and Juan Luis Dominguez and Jordi Torres and Raul
  Garcia and David Garcia and Daniel Garrido and Jordi Cortada and Mateo Valero","Improving accuracy and speeding up Document Image Classification through
  parallel systems",,,"10.1007/978-3-030-50417-5_29",,"cs.CV cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a study showing the benefits of the EfficientNet models
compared with heavier Convolutional Neural Networks (CNNs) in the Document
Classification task, essential problem in the digitalization process of
institutions. We show in the RVL-CDIP dataset that we can improve previous
results with a much lighter model and present its transfer learning
capabilities on a smaller in-domain dataset such as Tobacco3482. Moreover, we
present an ensemble pipeline which is able to boost solely image input by
combining image model predictions with the ones generated by BERT model on
extracted text by OCR. We also show that the batch size can be effectively
increased without hindering its accuracy so that the training process can be
sped up by parallelizing throughout multiple GPUs, decreasing the computational
time needed. Lastly, we expose the training performance differences between
PyTorch and Tensorflow Deep Learning frameworks.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:36:07 GMT""}]","2020-06-17"
"2006.09142","Li'an Zhuo","Li'an Zhuo, Baochang Zhang, Linlin Yang, Hanlin Chen, Qixiang Ye,
  David Doermann, Guodong Guo, Rongrong Ji","Cogradient Descent for Bilinear Optimization","9 pages, 6 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventional learning methods simplify the bilinear model by regarding two
intrinsically coupled factors independently, which degrades the optimization
procedure. One reason lies in the insufficient training due to the asynchronous
gradient descent, which results in vanishing gradients for the coupled
variables. In this paper, we introduce a Cogradient Descent algorithm (CoGD) to
address the bilinear problem, based on a theoretical framework to coordinate
the gradient of hidden variables via a projection function. We solve one
variable by considering its coupling relationship with the other, leading to a
synchronous gradient descent to facilitate the optimization procedure. Our
algorithm is applied to solve problems with one variable under the sparsity
constraint, which is widely used in the learning paradigm. We validate our CoGD
considering an extensive set of applications including image reconstruction,
inpainting, and network pruning. Experiments show that it improves the
state-of-the-art by a significant margin.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:41:54 GMT""}]","2020-06-17"
"2006.09143","Sara Beck","Sara C. Beck, John Lacy, Jean Turner, Hauyu Baobab Liu, Thomas
  Greathouse, S.M.Consiglio, and Paul T.P. Ho","Ionized Gas in the NGC 5253 Supernebula:High Spatial and Spectral
  Resolution Observations with the JVLA and TEXES","Accepted for publication in MNRAS, 16 June 2020",,"10.1093/mnras/staa1819",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The youngest, closest and most compact embedded massive star cluster known
excites the supernebula in the nearby dwarf galaxy NGC 5253. It is a crucial
target and test case for studying the birth and evolution of the most massive
star clusters. We present observations of the ionized gas in this source with
high spatial and spectral resolution. The data includes continuum images of
free-free emission with ~0.15'' resolution made with the JVLA at 15, 22 and 33
GHz, and a full data cube of the [SIV]10.5 micron fine-structure emission line
with ~4.5 km/s velocity resolution and 0.3'' beam, obtained with TEXES on
Gemini North. We find that 1) the ionized gas extends out from the cluster in
arms or jets, and 2) the ionized gas comprises two components offset both
spatially and in velocity. We discuss mechanisms that may have created the
observed velocity field; possibilities include large-scale jets or a subcluster
falling onto the main source.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:43:59 GMT""}]","2020-07-01"
"2006.09145","Zin Lin","Zin Lin, Charles Roques-Carmes, Rapha\""el Pestourie, Marin
  Solja\v{c}i\'c, Arka Majumdar and Steven G. Johnson","End-to-End Nanophotonic Inverse Design for Imaging and Polarimetry","19 pages, 4 figures. Initially submitted on June 16, 2020. Expanded
  version submitted on October 10, 2020",,,,"physics.optics eess.IV physics.app-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By co-designing a meta-optical front end in conjunction with an
image-processing back end, we demonstrate noise sensitivity and compactness
substantially superior to either an optics-only or a computation-only approach,
illustrated by two examples: subwavelength imaging and reconstruction of the
full polarization coherence matrices of multiple light sources. Our end-to-end
inverse designs couple the solution of the full Maxwell equations---exploiting
all aspects of wave physics arising in subwavelength scatterers---with
inverse-scattering algorithms in a single large-scale optimization involving
$\gtrsim 10^4$ degrees of freedom. The resulting structures scatter light in a
way that is radically different from either a conventional lens or a random
microstructure, and suppress the noise sensitivity of the inverse-scattering
computation by several orders of magnitude. Incorporating the full wave physics
is especially crucial for detecting spectral and polarization information that
is discarded by geometric optics and scalar diffraction theory.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:45:22 GMT""},{""version"":""v2"",""created"":""Sat, 10 Oct 2020 22:10:08 GMT""}]","2020-10-13"
"2006.09146","Ivo Souza","Thomas Olsen, Tom\'a\v{s} Rauch, David Vanderbilt, Ivo Souza","Gapless hinge states from adiabatic pumping of axion coupling","11 pages, 11 figures","Phys. Rev. B 102, 035166 (2020)","10.1103/PhysRevB.102.035166",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate that chiral hinge modes naturally emerge in insulating
crystals undergoing a slow cyclic evolution that changes the Chern-Simons axion
angle $\theta$ by $2\pi$. This happens when the surface (not just the bulk)
returns to its initial state at the end of the cycle, in which case it must
pass through a metallic state to dispose of the excess quantum of surface
anomalous Hall conductivity pumped from the bulk. If two adjacent surfaces
become metallic at different points along the cycle, there is an interval in
which they are in topologically distinct insulating states, with chiral modes
propagating along the connecting hinge. We illustrate these ideas for a
tight-binding model consisting of coupled layers of the Haldane model with
alternating parameters. The surface topology is determined in a slab geometry
using two different markers, surface anomalous Hall conductivity and
surface-localized charge pumping (flow of surface-localized Wannier bands), and
we find that both correctly predict the appearance of gapless hinge modes in a
rod geometry. When viewing the axion pump as a four-dimensional (4D) crystal
with one synthetic dimension, the hinge modes trace Fermi arcs in the Brillouin
zone of the 2D hinge connecting a pair of 3D surfaces of the 4D crystal.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:45:22 GMT""}]","2020-08-05"
"2006.09150","Stefano Almi","Stefano Almi and Emanuele Tasso","Brittle fracture in linearly elastic plates",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we derive by Gamma-convergence techniques a model for brittle
fracture linearly elastic plates. Precisely, we start from a brittle linearly
elastic thin film with positive thickness $\rho$ and study the limit as $\rho$
tends to 0. The analysis is performed with no a priori restrictions on the
admissible displacements and on the geometry of the fracture set. The limit
model is characterized by a Kirchhoff-Love type of structure.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:47:54 GMT""},{""version"":""v2"",""created"":""Mon, 26 Apr 2021 12:27:58 GMT""}]","2021-04-27"
"2006.09151","Martin Mootz","Martin Mootz, Jigang Wang, and Ilias E. Perakis","Lightwave Terahertz Quantum Manipulation of Non-equilibrium
  Superconductor Phases and their Collective Modes","19 pages, 11 figures","Phys. Rev. B 102, 054517 (2020)","10.1103/PhysRevB.102.054517",,"cond-mat.supr-con cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a gauge-invariant density matrix description of non-equilibrium
superconductor (SC) states with spatial and temporal correlations driven by
intense terahertz (THz) lightwaves. We derive superconductor Bloch--Maxwell
equations of motion that extend Anderson pseudo-spin models to include the
Cooper pair center-of-mass motion and electromagnetic propagation effects. We
thus describe quantum control of dynamical phases, collective modes,
quasi-particle coherence, and high nonlinearities during cycles of carrier wave
oscillations, which relate to our recent experiments. Coherent photogeneration
of a nonlinear supercurrent with dc component via condensate acceleration by an
effective lightwave field dynamically breaks the equilibrium inversion
symmetry. Experimental signatures include high harmonic light emission at
equilibrium-symmetry-forbidden frequencies, Rabi--Higgs collective modes and
quasi-particle coherence, and non-equilibrium moving condensate states tuned by
few-cycle THz fields. We use such lightwaves as an oscillating accelerating
force that drives strong nonlinearities and anisotropic quasi-particle
populations to control and amplify different classes of collective modes, e.g.,
damped oscillations, persistent oscillations, and overdamped dynamics via Rabi
flopping. Recent phase-coherent nonlinear spectroscopy experiments can be
modeled by solving the full nonlinear quantum dynamics including
self-consistent light--matter coupling.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:48:02 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 02:52:19 GMT""}]","2020-09-02"
"2006.09152","Oli Luiz Dors Jr","O. L. Dors, R. Maiolino, M. V. Cardaci, G. F. Hagele, A. C. Krabbe, E.
  Perez-Montero, M. Armah","Chemical abundances of Seyfert 2 AGNs-III. Reducing the oxygen abundance
  discrepancy","14 pages, 10 figures, Accepted for publication in MNRAS",,"10.1093/mnras/staa1781",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the discrepancy between oxygen abundance estimations for
narrow-line regions (NLRs) of Active Galactic Nuclei (AGNs) type Seyfert 2
derived by using direct estimations of the electron temperature (Te-method) and
those derived by using photoionization models. In view of this, observational
emission-line ratios in the optical range (3000 < \lambda(\AA) < 7000) of
Seyfert 2 nuclei compiled from the literature were reproduced by detailed
photoionization models built with the Cloudy code. We find that the derived
discrepancies are mainly due to the inappropriate use of the relations between
temperatures of the low (t2) and high (t3) ionization gas zones derived for H
II regions in AGN chemical abundance studies. Using a photoionization model
grid, we derived a new expression for t2 as a function of t3 valid for Seyfert
2 nuclei. The use of this new expression in the AGN estimation of the O/H
abundances based on Te-method produces O/H abundances slightly lower (about 0.2
dex) than those derived from detailed photoionization models. We also find that
the new formalism for the Te-method reduces by about 0.4 dex the O/H
discrepancies between the abundances obtained from strong emission-line
calibrations and those derived from direct estimations.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:48:56 GMT""}]","2020-07-01"
"2006.09153","Rfaqat Ali","R. Ali, F. A. Pinheiro, R. S. Dutra, and P. A. Maia Neto","Tailoring optical pulling forces with composite microspheres","8 pages 4 figures","Phys. Rev. A 102, 023514 (2020)","10.1103/PhysRevA.102.023514",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Optical pulling forces or tractor beams can pull particles against light
propagation by redirecting the incident photons forward. This is typically
achieved using Bessel beams with very small half-cone angles, which
considerably limits its applicability. One can circumvent such issue by using a
superposition of plane waves. In order to investigate optical pulling forces
exerted by a pair of non-colinear plane waves, we develop a theoretical
framework based on Mie theory, Debye potentials and Wigner rotation matrices.
We apply this framework to calculate the optical pulling force on
metallo-dielectric composite particles, which we put forward as an alternative
material platform to optimize and tailor tractor beams. Indeed we demonstrate
that by adding a few plasmonic inclusions to low-refractive index dielectric
particles of arbitrary sizes, we are able to produce polarization dependent
optical pulling forces that cannot occur in the corresponding homogeneous
particles. Altogether our findings not only provide innovative theoretical
methods to compute optical pulling forces, but also provide new strategies to
tailor and optimize them, paving the way to increase their applicability.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:49:18 GMT""}]","2020-08-19"
"2006.09155","Ahsanul Kabir","Ahsanul Kabira, Haiwu Zhang, Sofie Colding-J{\o}rgensen, Simone
  Santucci, Sebastian Molin, Vincenzo Esposito","Electro-Chemo-Mechanical Properties in Nanostructured Ca-doped Ceria
  (CDC) by Field Assisted Sintering",,,,,"cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent investigations have shown that highly oxygen defective cerium oxides
generate non-classical electrostriction that is superior to lead-based
ferroelectrics. In this work, we report the effect of field-assisted spark
plasma sintering (SPS) on electro-chemo-mechanical properties on Ca-doped ceria
(CDC). Nanometric powders of ca. 10 nm are rapidly consolidated to form
polycrystalline nanostructures with a high degree of crystalline disorder.
Remarkably, the resultant material demonstrates a large electromechanical
strain without a frequency-related relaxation effect. We conclude that
electromechanical activity in CDC materials strictly depends on the Ca-VO
interaction, while disorder at the crystalline boundaries has a minor effect.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:49:49 GMT""}]","2020-06-17"
"2006.09156","John Klauder","John R. Klauder","Using Affine Quantization to Analyze Non-renormalizable Scalar Fields
  and the Quantization of Einstein's Gravity","19 pages; Carefully choosing favored variables to promote to
  operators, featuring non-renormalizable scalar fields and quantum gravity",,,,"gr-qc hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Affine quantization is a parallel procedure to canonical quantization, which
is ideally suited to deal with non-renormalizable scalar models as well as
quantum gravity. The basic applications of this approach lead to the common
goals of any quantization, such as Schroedinger's representation and
Schroedinger's equation. Careful attention is paid toward seeking favored
classical variables, which are those that should be promoted to the principal
quantum operators. This effort leads toward classical variables that have a
constant positive, zero, or negative curvature, which typically characterize
such favored variables. This focus leans heavily toward affine variables with a
constant negative curvature, which leads to a surprisingly accommodating
analysis of non-renormalizable scalar models as well as Einstein's general
relativity.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:59:37 GMT""}]","2020-06-17"
"2006.09157","Laura Wendelberger","Laura J. Wendelberger, Brian J. Reich, Alyson G. Wilson","Selecting Diverse Models for Scientific Insight","37 Pages, 14 Figures. Presented at Conference on Data Analysis (CoDA)
  2020 (Feb 25-27)",,,,"stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model selection often aims to choose a single model, assuming that the form
of the model is correct. However, there may be multiple possible underlying
explanatory patterns in a set of predictors that could explain a response.
Model selection without regard for model uncertainty can fail to bring these
patterns to light. We explore multi-model penalized regression (MMPR) to
acknowledge model uncertainty in the context of penalized regression. We
examine how different penalty settings can promote either shrinkage or sparsity
of coefficients in separate models. The method is tuned to explicitly limit
model similarity. A choice of penalty form that enforces variable selection is
applied to predict stacking fault energy (SFE) from steel alloy composition.
The aim is to identify multiple models with different subsets of covariates
that explain a single type of response.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:06:55 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 03:56:26 GMT""},{""version"":""v3"",""created"":""Thu, 16 Dec 2021 01:17:34 GMT""}]","2021-12-17"
"2006.09159","Alessandro B. Romeo","Alessandro B. Romeo, Oscar Agertz, Florent Renaud","From lenticulars to blue compact dwarfs: the stellar mass fraction is
  regulated by disc gravitational instability","MNRAS, in press. Fig. 4, Sect. 4 and the last itemized paragraph of
  Sect. 5 are new, and demonstrate the importance of our results for the
  simulation community","MNRAS, 499, 5656 (2020)","10.1093/mnras/staa3245",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The stellar-to-halo mass relation (SHMR) is not only one of the main sources
of information we have on the connection between galaxies and their dark matter
haloes, but also an important indicator of the performance of galaxy formation
models. Here we use one of the largest sample of galaxies with both
high-quality rotation curves and near-infrared surface photometry, and perform
a detailed comparative analysis of the SHMR. Our analysis shows that there are
significant statistical differences between popular forms of the SHMR, and
illustrates the predictive power of a new physically motivated scaling
relation, which connects the stellar mass fraction ($M_{\star}/M_{\mathrm{h}}$)
to the stellar specific angular momentum ($j_{\star}$) and the stellar radial
velocity dispersion ($\sigma_{\star}$) via disc gravitational instability.
Making use of such a relation, we demonstrate (i) how challenging it is to
reproduce the efficiency of galaxy formation even for state-of-the-art
cosmological hydrodynamical simulations, and (ii) that the evolution of the
stellar mass fraction is regulated by disc gravitational instability: when
$M_{\star}/M_{\mathrm{h}}$ varies, $j_{\star}$ and $\sigma_{\star}$ also vary
as predicted by our scaling relation, thus erasing the memory of such
evolution. This implies that the process of disc gravitational instability is
intriguingly uniform across disc galaxies of all morphological types: from
lenticulars to blue compact dwarfs. In particular, the cosmic variance of
Toomre's $Q$ is 0.2 dex, a universal value for both stars and atomic gas.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:08:44 GMT""},{""version"":""v2"",""created"":""Thu, 15 Oct 2020 15:16:06 GMT""}]","2023-05-03"
"2006.09160","Karl Heuer","Karl Heuer and Deniz Sarikaya","Forcing Hamiltonicity in locally finite graphs via forbidden induced
  subgraphs I: nets and bulls","27 pages, 5 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a series of papers, of which this is the first, we study sufficient
conditions for Hamiltonicity in terms of forbidden induced subgraphs and extend
such results to locally finite infinite graphs. For this we use topological
circles within the Freudenthal compactification of a locally finite graph as
infinite cycles. In this paper we focus on conditions involving claws, nets and
bulls as induced subgraphs. We extend Hamiltonicity results for finite
claw-free and net-free graphs by Shepherd to locally finite graphs. Moreover,
we generalise a classification of finite claw-free and net-free graphs by
Shepherd to locally finite ones. Finally, we extend to locally finite graphs a
Hamiltonicity result by Ryj\'{a}\v{c}ek involving a relaxed condition of being
bull-free.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:10:16 GMT""}]","2020-06-17"
"2006.09162","Sergio Fortes","Carlos Baena, Sergio Fortes, Eduardo Baena, Raquel Barco","Estimation of Video Streaming KQIs for Radio Access Negotiation in
  Network Slicing Scenarios","4 pages, 4 figures","IEEE Communications Letters, vol. 24, no. 6, pp. 1304-1307, June
  2020","10.1109/LCOMM.2020.2979713",,"cs.NI cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of multimedia content has hugely increased in recent times, becoming
one of the most important services for the users of mobile networks.
Consequently, network operators struggle to optimize their infrastructure to
support the best video service-provision. As an additional challenge, 5G
introduces the concept of network slicing as a new paradigm that presents a
completely different view of the network configuration and optimization. A main
challenge of this scheme is to establish which specific resources would provide
the necessary quality of service for the users using the slice. To address
this, the present work presents a complete framework for this support of the
slice negotiation process through the estimation of the provided Video
Streaming Key Quality Indicators (KQIs), which are calculated from network
low-layer configuration parameters and metrics. The proposed estimator is then
evaluated in a real cellular scenario.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:10:54 GMT""}]","2020-06-17"
"2006.09164","Xiaofeng Xu","C. Q. Xu, Y. Liu, P. G. Cai, B. Li, W. H. Jiao, Y. L. Li, J. Y. Zhang,
  W. Zhou, B. Qian, X. F. Jiang, Z. X. Shi, R. Sankar, J. L. Zhang, F. Yang,
  Zengwei Zhu, P. K. Biswas, Dong Qian, X. Ke, and Xiaofeng Xu","Anisotropic transport and quantum oscillations in the
  quasi-one-dimensional TaNiTe5: Evidence for the nontrivial band topology","5 figures, 1 table","J. Phys. Chem. Lett. 11, 7782 (2020)",,,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The past decade has witnessed the burgeoning discovery of a variety of
topological states of matter with distinct nontrivial band topologies. Thus
far, most of materials studied possess two-dimensional or three-dimensional
electronic structures, with only a few exceptions that host
quasi-one-dimensional (quasi-1D) topological electronic properties. Here we
present the clear-cut evidence for Dirac fermions in the quasi-1D telluride
TaNiTe5. We show that its transport behaviors are highly anisotropic and we
observe nontrivial Berry phases via the quantum oscillation measurements. The
nontrivial band topology is further corroborated by first-principles
calculations. Our results may help to guide the future quest for topological
states in this new family of quasi-1D ternary chalcogenides.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:13:49 GMT""}]","2020-09-17"
"2006.09165","Dirk Lebiedz","Dirk Lebiedz","Holomorphic Hamiltonian $\xi$-Flow and Riemann Zeros","5 pages, no figures",,,,"math-ph math.DS math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With a view on the formal analogy between Riemann-von-Mangoldts explicit
formula and semiclassical quantum mechanics in terms of the Gutzwiller trace
formula we construct a complex-valued Hamiltonian $H(q,p)=\xi(q)p$ from the
holomorphic flow $\dot{q}=\xi(q)$ and its variational differential equation.
The Hamiltonian phase portrait $q(p)$ is a Riemann surface equivalent to
reparameterized $\xi$-Newton flow solutions in complex-time, its flow map
differential is determined by all Riemann zeros and reminiscent of a 'spectral
sum' in trace formulas. Canonical quantization for particle quantum mechanics
on a circle leads to a Dirac-type momentum operator with discrete spectrum
given by classical closed orbit periods determined by derivatives
$\xi'(\rho_n)$ at Riemann zeros.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:15:15 GMT""},{""version"":""v2"",""created"":""Sun, 29 Nov 2020 16:03:52 GMT""}]","2020-12-01"
"2006.09166","Karl Heuer","Karl Heuer and Deniz Sarikaya","Forcing Hamiltonicity in locally finite graphs via forbidden induced
  subgraphs II: paws","20 pages, 5 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we extend a result about a sufficient condition for
Hamiltonicity for finite graphs by Broersma and Veldmann to locally finite
graphs. In order to do this we use topological circles within the Freudenthal
compactification of a locally finite graph as infinite cycles. The condition we
focus on in this paper is in terms of forbidden induced subgraphs, namely being
claw-free and a relaxation of being paw-free.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:15:32 GMT""}]","2020-06-17"
"2006.09167","Szil\'ard P\'all","Szil\'ard P\'all, Artem Zhmurov, Paul Bauer, Mark Abraham, Magnus
  Lundborg, Alan Gray, Berk Hess, Erik Lindahl","Heterogeneous Parallelization and Acceleration of Molecular Dynamics
  Simulations in GROMACS","The following article has been submitted to the Journal of Chemical
  Physics",,"10.1063/5.0018516",,"physics.comp-ph cs.DC cs.DS cs.PF","http://creativecommons.org/licenses/by/4.0/","  The introduction of accelerator devices such as graphics processing units
(GPUs) has had profound impact on molecular dynamics simulations and has
enabled order-of-magnitude performance advances using commodity hardware. To
fully reap these benefits, it has been necessary to reformulate some of the
most fundamental algorithms, including the Verlet list, pair searching and
cut-offs. Here, we present the heterogeneous parallelization and acceleration
design of molecular dynamics implemented in the GROMACS codebase over the last
decade. The setup involves a general cluster-based approach to pair lists and
non-bonded pair interactions that utilizes both GPUs and CPU SIMD acceleration
efficiently, including the ability to load-balance tasks between CPUs and GPUs.
The algorithm work efficiency is tuned for each type of hardware, and to use
accelerators more efficiently we introduce dual pair lists with rolling pruning
updates. Combined with new direct GPU-GPU communication as well as GPU
integration, this enables excellent performance from single GPU simulations
through strong scaling across multiple GPUs and efficient multi-node
parallelization.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:19:26 GMT""},{""version"":""v2"",""created"":""Mon, 7 Sep 2020 22:54:40 GMT""}]","2020-10-28"
"2006.09170","Matthias Voigt","Ines Dorschky, Timo Reis, Matthias Voigt","Balanced truncation model reduction for symmetric second order systems
  -- A passivity-based approach","32 pages, 2 figures",,,,"math.NA cs.NA cs.SY eess.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a model reduction approach for linear time-invariant second
order systems based on positive real balanced truncation. Our method guarantees
asymptotic stability and passivity of the reduced order model as well as the
positive definiteness of the mass and stiffness matrices. Moreover, we receive
an a priori gap metric error bound. Finally, we show that our method based on
positive real balanced truncation preserves the structure of overdamped second
order systems.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:22:14 GMT""}]","2020-06-17"
"2006.09171","Fu Song","Pengfei Gao, Hongyi Xie, Fu Song, Taolue Chen","A Hybrid Approach to Formal Verification of Higher-Order Masked
  Arithmetic Programs",,,,,"cs.CR cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Side-channel attacks, which are capable of breaking secrecy via side-channel
information, pose a growing threat to the implementation of cryptographic
algorithms. Masking is an effective countermeasure against side-channel attacks
by removing the statistical dependence between secrecy and power consumption
via randomization. However, designing efficient and effective masked
implementations turns out to be an error-prone task. Current techniques for
verifying whether masked programs are secure are limited in their applicability
and accuracy, especially when they are applied. To bridge this gap, in this
article, we first propose a sound type system, equipped with an efficient type
inference algorithm, for verifying masked arithmetic programs against
higher-order attacks. We then give novel model-counting based and
pattern-matching based methods which are able to precisely determine whether
the potential leaky observable sets detected by the type system are genuine or
simply spurious. We evaluate our approach on various implementations of
arithmetic cryptographicprograms.The experiments confirm that our approach out
performs the state-of-the-art base lines in terms of applicability, accuracy
and efficiency.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:22:18 GMT""}]","2020-06-17"
"2006.09174","Anastasios Nentidis","Anastasios Nentidis, Konstantinos Bougiatiotis, Anastasia Krithara,
  Georgios Paliouras","Results of the seventh edition of the BioASQ Challenge","17 pages, 2 figures","Cellier P., Driessens K. (eds) Machine Learning and Knowledge
  Discovery in Databases. ECML PKDD 2019. Communications in Computer and
  Information Science, vol 1168. Springer, Cham","10.1007/978-3-030-43887-6_51",,"cs.CL cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The results of the seventh edition of the BioASQ challenge are presented in
this paper. The aim of the BioASQ challenge is the promotion of systems and
methodologies through the organization of a challenge on the tasks of
large-scale biomedical semantic indexing and question answering. In total, 30
teams with more than 100 systems participated in the challenge this year. As in
previous years, the best systems were able to outperform the strong baselines.
This suggests that state-of-the-art systems are continuously improving, pushing
the frontier of research.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:23:27 GMT""}]","2020-06-17"
"2006.09175","Antonin Eddi","Maxime Lanoy and Fabrice Lemoult and Antonin Eddi and Claire Prada","Dirac cones and chiral selection of elastic waves in a soft strip",,,"10.1073/pnas.2010812117",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the propagation of in-plane elastic waves in a soft thin strip; a
specific geometrical and mechanical hybrid framework which we expect to exhibit
Dirac-like cone. We separate the low frequencies guided modes (typically 100 Hz
for a centimetre wide strip) and obtain experimentally the full dispersion
diagram. Dirac cones are evidenced together with other remarkable wave
phenomena such as negative wave velocity or pseudo-zero group velocity (ZGV).
Our measurements are convincingly supported by a model (and numerical
simulation) for both Neumann and Dirichlet boundary conditions. Finally, we
perform one-way chiral selection by carefully setting the source position and
polarization. Therefore, we show that soft materials support atypical
wave-based phenomena, which is all the more interesting as they make most of
the biological tissues.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:24:08 GMT""},{""version"":""v2"",""created"":""Wed, 25 Nov 2020 20:52:09 GMT""}]","2020-11-30"
"2006.09176","Arne Christoph Reimers","Arne Christoph Reimers (for the CMS Collaboration)","Searches for new heavy particles coupling to third-generation quarks at
  CMS","Accepted by the proceedings of ""European Physical Society Conference
  on High Energy Physics - EPS-HEP2019"", 10-17 July 2019, Ghent, Belgium; 8
  pages, 5 figures",,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Results from searches for new particles with enhanced couplings to
third-generation quarks are presented. They are based on proton-proton
collision data at a center-of-mass energy of 13 TeV recorded by the CMS
experiment. The signatures include single and pair production of vector-like
quarks and heavy resonances decaying to third-generation quarks. A wide range
of final states, from multi-leptonic to entirely hadronic is covered. Jet
substructure techniques are employed to identify highly boosted heavy standard
model particles in their hadronic decay modes.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:24:29 GMT""}]","2020-06-17"
"2006.09179","Michele Buzzicotti","M. Buzzicotti, F. Bonaccorso, P. Clark Di Leoni, L. Biferale","Reconstruction of turbulent data with deep generative models for
  semantic inpainting from TURB-Rot database",,"Phys. Rev. Fluids 6, 050503 (2021)","10.1103/PhysRevFluids.6.050503",,"physics.flu-dyn cond-mat.stat-mech cs.CV cs.LG nlin.CD","http://creativecommons.org/licenses/by/4.0/","  We study the applicability of tools developed by the computer vision
community for features learning and semantic image inpainting to perform data
reconstruction of fluid turbulence configurations. The aim is twofold. First,
we explore on a quantitative basis, the capability of Convolutional Neural
Networks embedded in a Deep Generative Adversarial Model (Deep-GAN) to generate
missing data in turbulence, a paradigmatic high dimensional chaotic system. In
particular, we investigate their use in reconstructing two-dimensional damaged
snapshots extracted from a large database of numerical configurations of 3d
turbulence in the presence of rotation, a case with multi-scale random features
where both large-scale organised structures and small-scale highly intermittent
and non-Gaussian fluctuations are present. Second, following a reverse
engineering approach, we aim to rank the input flow properties (features) in
terms of their qualitative and quantitative importance to obtain a better set
of reconstructed fields. We present two approaches both based on Context
Encoders. The first one infers the missing data via a minimization of the L2
pixel-wise reconstruction loss, plus a small adversarial penalisation. The
second searches for the closest encoding of the corrupted flow configuration
from a previously trained generator. Finally, we present a comparison with a
different data assimilation tool, based on Nudging, an equation-informed
unbiased protocol, well known in the numerical weather prediction community.
The TURB-Rot database, http://smart-turb.roma2.infn.it, of roughly 300K 2d
turbulent images is released and details on how to download it are given.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:26:07 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 09:26:53 GMT""}]","2021-06-15"
"2006.09181","Subhro Das","Nathan Fulton, Nathan Hunt, Nghia Hoang, Subhro Das","Formal Verification of End-to-End Learning in Cyber-Physical Systems:
  Progress and Challenges","7 pages, 4 figures. NeurIPS Workshop on Safety and Robustness in
  Decision Making, 2019",,,,"cs.SE cs.AI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autonomous systems -- such as self-driving cars, autonomous drones, and
automated trains -- must come with strong safety guarantees. Over the past
decade, techniques based on formal methods have enjoyed some success in
providing strong correctness guarantees for large software systems including
operating system kernels, cryptographic protocols, and control software for
drones. These successes suggest it might be possible to ensure the safety of
autonomous systems by constructing formal, computer-checked correctness proofs.
This paper identifies three assumptions underlying existing formal verification
techniques, explains how each of these assumptions limits the applicability of
verification in autonomous systems, and summarizes preliminary work toward
improving the strength of evidence provided by formal verification.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:50:47 GMT""}]","2020-06-17"
"2006.09182","Rafael Copstein","R. Copstein, F. Dotti","Distributed File System for an Edge-Based Environment","10 pages, 3 figures, 1 table",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent developments in the industry of personal computing led to a greater
number of the so-called edge devices. Such devices typically do not collaborate
or foresee the possibility of collaboration to offer aggregated storage and
computing capabilities. The concept of distributed file system (DFS) is not new
to the field of distributed systems, in fact, it is widely used in dedicated
infrastructures, for example, in cloud computing applications.
  In this work, we discuss reasonable assumptions for an environment composed
of edge devices, the main design issues and implementation challenges of a DFS
in the given environment and how they would impact this application. Thereafter
we define a system model for an environment composed of edge devices while
taking into consideration their high mobility and common cases of network
partitioning. Next, we describe an architecture for a DFS that withstands the
proposed system model while offering most capabilities that a DFS at a
dedicated infrastructure would.
  We conclude that the development of a distributed file system is a very
complex task and, given the broad assumptions of the system model, also hard to
verify. Some important aspects of the development lie as future work, but we
believe that the developed DFS can be used not only as a tool on it's own, but
also as a reference for further development of distributed file systems and,
specially, of systems for infrastructures composed of edge devices.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:27:13 GMT""}]","2020-06-17"
"2006.09185","Laura Bonavera","L. Bonavera, J. Gonz\'alez-Nuevo, M. M. Cueli, T. Ronconi, M.
  Migliaccio, L. Dunne, A. Lapi, S. J. Maddox, M. Negrello","Cosmology with the submillimetre galaxies magnification bias: Proof of
  concept","accepted in Astronomy & Astrophysics","A&A 639, A128 (2020)","10.1051/0004-6361/202038050",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context. As recently demonstrated, high-z submillimetre galaxies (SMGs) are
the perfect background sample for tracing the mass density profiles of galaxies
and clusters (baryonic and dark matter) and their time-evolution through
gravitational lensing. Their magnification bias, a weak gravitational lensing
effect, is a powerful tool for constraining the free parameters of a halo
occupation distribution (HOD) model and potentially also some of the main
cosmological parameters. Aims. The aim of this work is to test the capability
of the magnification bias produced on high-z SMGs as a cosmological probe. We
exploit cross-correlation data to constrain not only astrophysical parameters
($M_{min}$, $M_1$, and $\alpha$), but also some of the cosmological ones
($\Omega_m$, $\sigma_8$, and $H_0$) for this proof of concept. Methods. The
measured cross-correlation function between a foreground sample of GAMA
galaxies with spectroscopic redshifts in the range 0.2 < z < 0.8 and a
background sample of H-ATLAS galaxies with photometric redshifts >1.2 is
modelled using the traditional halo model description that depends on HOD and
cosmological parameters. These parameters are then estimated by performing a
Markov chain Monte Carlo analysis using different sets of priors to test the
robustness of the results and to study the performance of this novel observable
with the current set of data Results. With our current results, $\Omega_m$ and
$H_0$ cannot be well constrained. However, we can set a lower limit of >0.24 at
95\% confidence level (CL) on $\Omega_m$ and we see a slight trend towards
$H_0>70$ values. For our constraints on $\sigma_8$ we obtain only a tentative
peak around 0.75, but an interesting upper limit of $\sigma_8\lesssim 1$ at
95\% CL. We also study the possibility to derive better constraints by imposing
more restrictive priors on the astrophysical parameters.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:28:25 GMT""}]","2020-07-22"
"2006.09186","Hugo Manuel Proen\c{c}a","Hugo M. Proen\c{c}a, Peter Gr\""unwald, Thomas B\""ack, Matthijs van
  Leeuwen","Discovering outstanding subgroup lists for numeric targets using MDL","Extended version of conference paper at ECML-PKDD","ECML PKDD 2020, LNAI 12457, pp. 19-35, 2021","10.1007/978-3-030-67658-2_2",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The task of subgroup discovery (SD) is to find interpretable descriptions of
subsets of a dataset that stand out with respect to a target attribute. To
address the problem of mining large numbers of redundant subgroups, subgroup
set discovery (SSD) has been proposed. State-of-the-art SSD methods have their
limitations though, as they typically heavily rely on heuristics and/or
user-chosen hyperparameters.
  We propose a dispersion-aware problem formulation for subgroup set discovery
that is based on the minimum description length (MDL) principle and subgroup
lists. We argue that the best subgroup list is the one that best summarizes the
data given the overall distribution of the target. We restrict our focus to a
single numeric target variable and show that our formalization coincides with
an existing quality measure when finding a single subgroup, but that-in
addition-it allows to trade off subgroup quality with the complexity of the
subgroup. We next propose SSD++, a heuristic algorithm for which we empirically
demonstrate that it returns outstanding subgroup lists: non-redundant sets of
compact subgroups that stand out by having strongly deviating means and small
spread.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:29:52 GMT""}]","2021-03-16"
"2006.09187","Jianbo Cui","Jianbo Cui, Luca Dieci, Haomin Zhou","Time Discretizations of Wasserstein-Hamiltonian Flows","34 pages",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study discretizations of Hamiltonian systems on the probability density
manifold equipped with the $L^2$-Wasserstein metric. Based on discrete optimal
transport theory, several Hamiltonian systems on graph (lattice) with different
weights are derived, which can be viewed as spatial discretizations to the
original Hamiltonian systems. We prove the consistency and provide the
approximate orders for those discretizations. By regularizing the system using
Fisher information, we deduce an explicit lower bound for the density function,
which guarantees that symplectic schemes can be used to discretize in time.
Moreover, we show desirable long time behavior of these schemes, and
demonstrate their performance on several numerical examples.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:31:16 GMT""}]","2020-06-17"
"2006.09188","Chao Sun","Chao Sun, Ce Yu, Chenzhou Cui, Boliang He, Jian Xiao, Zhen Li,
  Shanjiang Tang and Jizhou Sun","A Redistribution Tool for Long-Term Archive of Astronomical Observation
  Data",,"Astronomy and Computing, 2020, Vol: 32","10.1016/j.ascom.2020.100400",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Astronomical observation data require long-term preservation, and the rapid
accumulation of observation data makes it necessary to consider the cost of
long-term archive storage. In addition to low-speed disk-based online storage,
optical disk or tape-based offline storage can be used to save costs. However,
for astronomical research that requires historical data (particularly
time-domain astronomy), the performance and energy consumption of
data-accessing techniques cause problems because the requested data (which are
organized according to observation time) may be located across multiple storage
devices. In this study, we design and develop a tool referred to as AstroLayout
to redistribute the observation data using spatial aggregation. The core
algorithm uses graph partitioning to generate an optimized data placement
according to the original observation data statistics and the target storage
system. For the given observation data, AstroLayout can copy the long-term
archive in the target storage system in accordance with this placement. An
efficiency evaluation shows that AstroLayout can reduce the number of devices
activated when responding to data-access requests in time-domain astronomy
research. In addition to improving the performance of data-accessing
techniques, AstroLayout can also reduce the storage systems power consumption.
For enhanced adaptability, it supports storage systems of any media, including
optical disks, tapes, and hard disks.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:31:53 GMT""}]","2020-06-17"
"2006.09189","Parul Maheshwari","Parul Maheshwari and R\'eka Albert","Network model and analysis of the spread of Covid-19 with social
  distancing","16 pages, 10 figures",,,,"physics.soc-ph q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The first mitigation response to the Covid-19 pandemic was to limit
person-to-person interaction as much as possible. This was implemented by the
temporary closing of many workplaces and people were required to follow social
distancing. Networks are a great way to represent interactions among people and
the temporary severing of these interactions. Here, we present a network model
of human-human interactions that could be mediators of disease spread. The
nodes of this network are individuals and different types of edges denote
family cliques, workplace interactions, interactions arising from essential
needs, and social interactions. Each individual can be in one of four states:
susceptible, infected, immune, and dead. The network and the disease parameters
are informed by the existing literature on Covid-19. Using this model, we
simulate the spread of an infectious disease in the presence of various
mitigation scenarios. For example, lockdown is implemented by deleting edges
that denote non-essential interactions. We validate the simulation results with
the real data by matching the basic and effective reproduction numbers during
different phases of the spread. We also simulate different possibilities of the
slow lifting of the lockdown by varying the transmission rate as facilities are
slowly opened but people follow prevention measures like wearing masks etc. We
make predictions on the probability and intensity of a second wave of infection
in each of these scenarios.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:34:12 GMT""}]","2020-06-17"
"2006.09190","Shih-Si Hsiao","Shih-Si Hsiao, Ko-Tang Chen, and Ite A. Yu","Mean field theory of weakly-interacting Rydberg polaritons in the EIT
  system based on the nearest-neighbor distribution",,"Optics Express. 28(19): 28414-28429 (2020)","10.1364/OE.401310",,"quant-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The combination of high optical nonlinearity in the electromagnetically
induced transparency (EIT) effect and strong electric dipole-dipole interaction
(DDI) among the Rydberg-state atoms can lead to important applications in
quantum information processing and many-body physics. One can utilize the
Rydberg-EIT system in the strongly-interacting regime to mediate photon-photon
interaction or qubit-qubit operation. One can also employ the Rydberg-EIT
system in the weaklyinteracting regime to study the Bose-Einstein condensation
of Rydberg polaritons. Most of the present theoretical models dealt with the
strongly-interacting cases. Here, we consider the weaklyinteracting regime and
develop a mean field model based on the nearest-neighbor distribution. Using
the mean field model, we further derive the analytical formulas for the
attenuation coefficient and phase shift of the output probe field. The
predictions from the formulas are consistent with the experimental data in the
weakly-interacting regime, verifying the validity of our model. As the
DDI-induced phase shift and attenuation can be seen as the consequences of
elastic and inelastic collisions among particles, this work provides a very
useful tool for conceiving ideas relevant to the EIT system of
weakly-interacting Rydberg polaritons, and for evaluating experimental
feasibility.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:34:20 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 05:27:46 GMT""},{""version"":""v3"",""created"":""Fri, 11 Sep 2020 08:50:06 GMT""}]","2020-09-14"
"2006.09191","Erik Daxberger","Austin Tripp, Erik Daxberger, Jos\'e Miguel Hern\'andez-Lobato","Sample-Efficient Optimization in the Latent Space of Deep Generative
  Models via Weighted Retraining","23 pages, 14 figures; Includes supplementary material; NeurIPS 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many important problems in science and engineering, such as drug design,
involve optimizing an expensive black-box objective function over a complex,
high-dimensional, and structured input space. Although machine learning
techniques have shown promise in solving such problems, existing approaches
substantially lack sample efficiency. We introduce an improved method for
efficient black-box optimization, which performs the optimization in the
low-dimensional, continuous latent manifold learned by a deep generative model.
In contrast to previous approaches, we actively steer the generative model to
maintain a latent manifold that is highly useful for efficiently optimizing the
objective. We achieve this by periodically retraining the generative model on
the data points queried along the optimization trajectory, as well as weighting
those data points according to their objective function value. This weighted
retraining can be easily implemented on top of existing methods, and is
empirically shown to significantly improve their efficiency and performance on
synthetic and real-world optimization problems.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:34:40 GMT""},{""version"":""v2"",""created"":""Sun, 25 Oct 2020 23:11:44 GMT""}]","2020-10-27"
"2006.09194","Sara Kalisnik Hintz","Sara Kalisnik, Davorin Lesnik","Finding the Homology of Manifolds using Ellipsoids",,,,,"math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A standard problem in applied topology is how to discover topological
invariants of data from a noisy point cloud that approximates it. We consider
the case where a sample is drawn from a properly embedded C1-submanifold
without boundary in a Euclidean space. We show that we can deformation retract
the union of ellipsoids, centered at sample points and stretching in the
tangent directions, to the manifold. Hence the homotopy type, and therefore
also the homology type, of the manifold is the same as that of the nerve
complex of the cover by ellipsoids. By thickening sample points to ellipsoids
rather than balls, our results require a smaller sample density than comparable
results in the literature. They also advocate using elongated shapes in the
construction of barcodes in persistent homology.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:35:18 GMT""},{""version"":""v2"",""created"":""Thu, 16 Sep 2021 15:08:14 GMT""}]","2021-09-17"
"2006.09195","Bochao Liu","Bo-Chao Liu and Ke Wang","Studying $\Lambda^*$ resonances in the $p \bar p \rightarrow \Lambda
  \bar\Lambda \eta$ reaction","8 pages, 5 figures","Phys. Rev. D 101, 114030 (2020)","10.1103/PhysRevD.101.114030",,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we make a theoretical study on the $p \bar p \rightarrow
\Lambda \bar\Lambda \eta$ reaction for antiproton beam energy from threshold to
4GeV within an effective Lagrangian approach and isobar model. By assuming this
reaction is dominated by the excitation of $\Lambda$ and $\bar \Lambda$
resonances in intermediate states, we calculate the total cross sections and
give the predictions of the angular distribution and invariant mass spectrum of
final particles. In particular, we discuss the possibility to verify the
existence of a narrow $\Lambda$ resonance found in the process of $K^- p\to
\eta \Lambda$ in the present reaction. It shows that the $p \bar p \rightarrow
\bar \Lambda \Lambda \eta$ reaction can provide us with valuable information
about the $\Lambda$ resonances having significant couplings to $\bar K N$ and
$\Lambda\eta$ channels. Thus the experimental data of this reaction will be a
good supplement to the $\bar K N\to\eta \Lambda$ scattering data for studying
$\Lambda$ resonances.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:35:25 GMT""}]","2020-07-01"
"2006.09198","Leon Kos","Dejan Penko (1), Leon Kos (1), Guido Huijsmans (2), Simon D. Pinches
  (2) ((1) University of Ljubljana, (2) ITER organization)","The initial step towards JOREK integration in IMAS","8 pages 4 figures",,,"Int. conf. NENE 2019 pp.707","physics.comp-ph physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  JOREK is being adapted to work with the Integrated Modelling & Analysis Suite
(IMAS) which is being actively developed and used by the ITER Organization, the
EUROfusion community and other ITER Members. The list of codes adapted to use
the IMAS Data Model is gradually increasing with examples including SOLPS-ITER
and JINTRAC. The main goal of the integration of JOREK with IMAS is to enable
interaction with the plasma scenarios stored in the IMAS databases in the form
of Interface Data Structures (IDSs): input conditions can be read from the
databases and nonlinear plasma states determined by JOREK stored. IDSs provide
a uniform way of representing data within the IMAS framework and allow to
transfer data between codes and to storage within larger integrated modelling
workflows. In order to integrate JOREK within IMAS it is therefore necessary
that transformation tools are developed to facilitate the reading and writing
of the relevant IDSs, including the MHD IDS, with its underlying Generalized
Grid Description (GGD). For this purpose, utilities have been developed that
extract JOREK simulation plasma state, namely the grid geometry and computed
physical quantities for each time slice, and then transform them to the
appropriate output IDSs. In this article, these initial steps towards full
JOREK integration into IMAS is presented.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:37:58 GMT""}]","2020-06-17"
"2006.09199","Andrew Rouditchenko","Andrew Rouditchenko, Angie Boggust, David Harwath, Brian Chen, Dhiraj
  Joshi, Samuel Thomas, Kartik Audhkhasi, Hilde Kuehne, Rameswar Panda, Rogerio
  Feris, Brian Kingsbury, Michael Picheny, Antonio Torralba, James Glass","AVLnet: Learning Audio-Visual Language Representations from
  Instructional Videos","A version of this work has been accepted to Interspeech 2021",,,,"cs.CV cs.CL cs.MM cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current methods for learning visually grounded language from videos often
rely on text annotation, such as human generated captions or machine generated
automatic speech recognition (ASR) transcripts. In this work, we introduce the
Audio-Video Language Network (AVLnet), a self-supervised network that learns a
shared audio-visual embedding space directly from raw video inputs. To
circumvent the need for text annotation, we learn audio-visual representations
from randomly segmented video clips and their raw audio waveforms. We train
AVLnet on HowTo100M, a large corpus of publicly available instructional videos,
and evaluate on image retrieval and video retrieval tasks, achieving
state-of-the-art performance. We perform analysis of AVLnet's learned
representations, showing our model utilizes speech and natural sounds to learn
audio-visual concepts. Further, we propose a tri-modal model that jointly
processes raw audio, video, and text captions from videos to learn a
multi-modal semantic embedding space useful for text-video retrieval. Our code,
data, and trained models will be released at avlnet.csail.mit.edu
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:38:03 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 18:44:50 GMT""}]","2021-07-01"
"2006.09200","Nick Sharples","Evelyne Miot (CNRS and IF, Universit\'e Grenoble-Alpes, France),
  Nicholas Sharples (Middlesex University, UK)","On solutions of the transport equation in the presence of singularities",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the transport equation on $[0,T]\times \mathbb{R}^n$ in the
situation where the vector field is $BV$ off a set $S\subset [0,T]\times
\mathbb{R}^n$. We demonstrate that solutions exist and are unique provided that
the set of singularities has a sufficiently small anisotropic fractal dimension
and the normal component of the vector field is sufficiently integrable near
the singularities. This result improves upon recent results of Ambrosio who
requires the vector field to be of bounded variation everywhere. In addition,
we demonstrate that under these conditions almost every trajectory of the
associated regular Lagrangian flow does not intersect the set $S$ of
singularities. Finally, we consider the particular case of an initial set of
singularities that evolve in time so the singularities consists of curves in
the phase space, which is typical in applications such as vortex dynamics. We
demonstrate that solutions of the transport equation exist and are unique
provided that the box-counting dimension of the singularities is bounded in
terms of the H\""older exponent of the curves.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:38:35 GMT""},{""version"":""v2"",""created"":""Wed, 2 Mar 2022 10:30:34 GMT""}]","2022-03-03"
"2006.09201","Shangjia Dong","Shangjia Dong, Tianbo Yu, Hamed Farahmand, Ali Mostafavi","A Hybrid Deep Learning Model for Predictive Flood Warning and Situation
  Awareness using Channel Network Sensors Data",,,,,"eess.SP cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The objective of this study is to create and test a hybrid deep learning
model, FastGRNN-FCN (Fast, Accurate, Stable and Tiny Gated Recurrent Neural
Network-Fully Convolutional Network), for urban flood prediction and situation
awareness using channel network sensors data. The study used Harris County,
Texas as the testbed, and obtained channel sensor data from three historical
flood events (e.g., 2016 Tax Day Flood, 2016 Memorial Day flood, and 2017
Hurricane Harvey Flood) for training and validating the hybrid deep learning
model. The flood data are divided into a multivariate time series and used as
the model input. Each input comprises nine variables, including information of
the studied channel sensor and its predecessor and successor sensors in the
channel network. Precision-recall curve and F-measure are used to identify the
optimal set of model parameters. The optimal model with a weight of 1 and a
critical threshold of 0.59 are obtained through one hundred iterations based on
examining different weights and thresholds. The test accuracy and F-measure
eventually reach 97.8% and 0.792, respectively. The model is then tested in
predicting the 2019 Imelda flood in Houston and the results show an excellent
match with the empirical flood. The results show that the model enables
accurate prediction of the spatial-temporal flood propagation and recession and
provides emergency response officials with a predictive flood warning tool for
prioritizing the flood response and resource allocation strategies.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:25:34 GMT""},{""version"":""v2"",""created"":""Tue, 8 Sep 2020 14:55:54 GMT""}]","2020-09-09"
"2006.09203","Yuzuru Kato","Yuzuru Kato, Hiroya Nakao","Quantum Coherence Resonance","12pages, 5 figures",,"10.1088/1367-2630/abf1d7",,"nlin.AO quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that coherence resonance, a phenomenon in which regularity of
noise-induced oscillations in nonlinear excitable systems is maximized at a
certain optimal noise intensity, can be observed in quantum dissipative
systems. We analyze a quantum van der Pol system subjected to squeezing, which
exhibits bistable excitability in the classical limit, by numerical simulations
of the quantum master equation. We first demonstrate that quantum coherence
resonance occurs in the semiclassical regime, namely, the regularity of the
system's oscillatory response is maximized at an optimal intensity of quantum
fluctuations, and interpret this phenomenon by analogy with classical noisy
excitable systems using semiclassical stochastic differential equations. This
resonance persists under moderately strong quantum fluctuations for which the
semiclassical description is invalid. Moreover, we investigate even stronger
quantum regimes and demonstrate that the regularity of the system's response
can exhibit the second peak as the intensity of the quantum fluctuations is
further increased. We show that this second peak of resonance is a strong
quantum effect that cannot be interpreted by a semiclassical picture, in which
only a few energy states participate in the system dynamics.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:40:28 GMT""},{""version"":""v2"",""created"":""Fri, 9 Apr 2021 05:09:51 GMT""}]","2021-04-12"
"2006.09205","Andrew Dowsey","William Andrew, Jing Gao, Siobhan Mullan, Neill Campbell, Andrew W
  Dowsey, Tilo Burghardt","Visual Identification of Individual Holstein-Friesian Cattle via Deep
  Metric Learning","41 pages, 18 figures, 2 tables; Submitted to Computers and
  Electronics in Agriculture ; Source code and network weights available at
  https://github.com/CWOA/MetricLearningIdentification ; OpenCows2020 dataset
  available at https://doi.org/10.5523/bris.10m32xl88x2b61zlkkgz3fml17","Computers and Electronics in Agriculture 185, 106133 (2021)","10.1016/j.compag.2021.106133",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Holstein-Friesian cattle exhibit individually-characteristic black and white
coat patterns visually akin to those arising from Turing's reaction-diffusion
systems. This work takes advantage of these natural markings in order to
automate visual detection and biometric identification of individual
Holstein-Friesians via convolutional neural networks and deep metric learning
techniques. Existing approaches rely on markings, tags or wearables with a
variety of maintenance requirements, whereas we present a totally hands-off
method for the automated detection, localisation, and identification of
individual animals from overhead imaging in an open herd setting, i.e. where
new additions to the herd are identified without re-training. We propose the
use of SoftMax-based reciprocal triplet loss to address the identification
problem and evaluate the techniques in detail against fixed herd paradigms. We
find that deep metric learning systems show strong performance even when many
cattle unseen during system training are to be identified and re-identified --
achieving 93.8% accuracy when trained on just half of the population. This work
paves the way for facilitating the non-intrusive monitoring of cattle
applicable to precision farming and surveillance for automated productivity,
health and welfare monitoring, and to veterinary research such as behavioural
analysis, disease outbreak tracing, and more. Key parts of the source code,
network weights and datasets are available publicly.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:41:55 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jul 2020 11:38:09 GMT""},{""version"":""v3"",""created"":""Wed, 14 Oct 2020 10:58:30 GMT""}]","2021-05-04"
"2006.09206","Jes\'us Ma\'iz Apell\'aniz","J. Ma\'iz Apell\'aniz, M. Pantaleoni Gonz\'alez, R. H. Barb\'a, P.
  Garc\'ia-Lario, and F. Nogueras-Lara","Galactic extinction laws: I. A global NIR analysis with 2MASS photometry","13 pages, accepted for publication in MNRAS",,"10.1093/mnras/staa1790",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have started an ambitious program to determine if the full diversity of
extinction laws is real or if some of it is due to calibration or
methodological issues. Here we start by analyzing the information on NIR
extinction in a 2MASS stellar sample with good quality photometry and very red
colours. We calculate the extinction at 1 $\mu$m, $A_1$, and the power-law
exponent, $\alpha$ ($A_\lambda = A_1 \lambda^{-\alpha}$), for the 2MASS stars
located in the extinction trajectory in the $H-K$ vs. $J-H$ plane expected for
red giants with $A_1 > 5$ mag. We test the validity of the assumption about the
nature of those stars, whether a single or multiple values of $\alpha$ are
needed, and the spatial variations of the results. Most ($\sim$83%) of those
stars can indeed be explained by high-extinction red giants and the rest is
composed of extinguished AGB stars (mostly O-rich), blended sources, and
smaller numbers of other objects, a contaminant fraction that can be reduced
with the help of Gaia} DR2 data. Galactic red giants experience a NIR
extinction with $\alpha\sim 2.27$ and an uncertainty of a few hundredths of a
magnitude. There is no significant spread in $\alpha$ even though our sample is
widely distributed and has a broad range of extinctions. Differences with
previous results are ascribed to the treatment of non-linear photometric
effects and/or the contaminant correction. Future research should concentrate
in finding the correct functional form for the NIR extinction law. In the
appendix we detail the treatment of non-linear photometric effects in the 2MASS
bands.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:42:09 GMT""}]","2020-07-01"
"2006.09210","Shuangjian Guo","Shengxiang Wang, Xiaohui Zhang, Shuangjian Guo","The Hom-Long dimodule category and nonlinear equations","23 pages",,,,"math.RA math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we construct a kind of new braided monoidal category over two
Hom-Hopf algerbas $(H,\alpha)$ and $(B,\beta)$ and associate it with two
nonlinear equations. We first introduce the notion of an $(H,B)$-Hom-Long
dimodule and show that the Hom-Long dimodule category $^{B}_{H} \Bbb L$ is an
autonomous category. Second, we prove that the category $^{B}_{H} \Bbb L$ is a
braided monoidal category if $(H,\alpha)$ is quasitriangular and $(B,\beta)$ is
coquasitriangular and get a solution of the quantum Yang-Baxter equation. Also,
we show that the category $^{B}_{H} \Bbb L$ can be viewed as a subcategory of
the Hom-Yetter-Drinfeld category $^{H\o B}_{H\o B} \Bbb {HYD}$. Finally, we
obtain a solution of the Hom-Long equation from the Hom-Long dimodules.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:43:02 GMT""}]","2020-06-17"
"2006.09211","Alexander Patkowski","Alexander E Patkowski","A Note on the Axisymmetric Diffusion equation",,"The ANZIAM Journal, Volume 63, Issue 3, July 2021, pp. 333--341","10.1017/S1446181121000110",,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the explicit solution to the axisymmetric diffusion equation. We
recast the solution in the form of a Mellin inversion formula, and outline a
method to compute a formula for $u(r,t)$ as a series using the Cauchy residue
theorem. As a consequence, we are able to represent the solution to the
axisymmetric diffusion equation as rapidly converging series.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:43:24 GMT""}]","2021-10-07"
"2006.09219","Alexander Henzi","Alexander Henzi, Gian-Reto Kleger, Johanna F. Ziegel","Distributional (Single) Index Models",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Distributional (Single) Index Model (DIM) is a semi-parametric model for
distributional regression, that is, estimation of conditional distributions
given covariates. The method is a combination of classical single index models
for the estimation of the conditional mean of a response given covariates, and
isotonic distributional regression. The model for the index is parametric,
whereas the conditional distributions are estimated non-parametrically under a
stochastic ordering constraint. We show consistency of our estimators and apply
them to a highly challenging data set on the length of stay (LoS) of patients
in intensive care units. We use the model to provide skillful and calibrated
probabilistic predictions for the LoS of individual patients, that outperform
the available methods in the literature.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:50:09 GMT""},{""version"":""v2"",""created"":""Wed, 3 Aug 2022 10:49:25 GMT""}]","2022-08-04"
"2006.09220","Yazan Abu Farha","Shijie Li, Yazan Abu Farha, Yun Liu, Ming-Ming Cheng, Juergen Gall","MS-TCN++: Multi-Stage Temporal Convolutional Network for Action
  Segmentation","IEEE Transactions on Pattern Analysis and Machine Intelligence. arXiv
  admin note: substantial text overlap with arXiv:1903.01945",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the success of deep learning in classifying short trimmed videos, more
attention has been focused on temporally segmenting and classifying activities
in long untrimmed videos. State-of-the-art approaches for action segmentation
utilize several layers of temporal convolution and temporal pooling. Despite
the capabilities of these approaches in capturing temporal dependencies, their
predictions suffer from over-segmentation errors. In this paper, we propose a
multi-stage architecture for the temporal action segmentation task that
overcomes the limitations of the previous approaches. The first stage generates
an initial prediction that is refined by the next ones. In each stage we stack
several layers of dilated temporal convolutions covering a large receptive
field with few parameters. While this architecture already performs well, lower
layers still suffer from a small receptive field. To address this limitation,
we propose a dual dilated layer that combines both large and small receptive
fields. We further decouple the design of the first stage from the refining
stages to address the different requirements of these stages. Extensive
evaluation shows the effectiveness of the proposed model in capturing
long-range dependencies and recognizing action segments. Our models achieve
state-of-the-art results on three datasets: 50Salads, Georgia Tech Egocentric
Activities (GTEA), and the Breakfast dataset.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:50:47 GMT""},{""version"":""v2"",""created"":""Wed, 2 Sep 2020 10:18:47 GMT""}]","2020-09-04"
"2006.09221","Alexander Barvinok","Alexander Barvinok","Testing systems of real quadratic equations for approximate solutions","Corrected several typos",,,,"math.OC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider systems of equations $q_i(x)=0$, where $q_i: {\Bbb R}^n
\longrightarrow {\Bbb R}$, $i=1, \ldots, m$, are quadratic forms. Our goal is
to tell efficiently systems with many non-trivial solutions or near-solutions
$x \ne 0$ from systems that are far from having a solution. For that, we pick a
delta-shaped penalty function $F: {\Bbb R} \longrightarrow [0, 1]$ with
$F(0)=1$ and $F(y) < 1$ for $y \ne 0$ and compute the expectation of $F(q_1(x))
\cdots F(q_m(x))$ for a random $x$ sampled from the standard Gaussian measure
in ${\Bbb R}^n$. We choose $F(y)=y^{-2}\sin^2 y$ and show that the expectation
can be approximated within relative error $0< \epsilon < 1$ in quasi-polynomial
time $(m+n)^{O(\ln (m+n)-\ln \epsilon)}$, provided each form $q_i$ depends on
not more than $r$ real variables, has common variables with at most $r-1$ other
forms and satisfies $|q_i(x)| \leq \gamma \|x\|^2/r$, where $\gamma >0$ is an
absolute constant. This allows us to distinguish between ""easily solvable"" and
""badly unsolvable"" systems in some non-trivial situations.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:50:50 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 16:39:43 GMT""}]","2020-06-24"
"2006.09222","Sebastian Bayerl","Sebastian P. Bayerl, Florian H\""onig, Joelle Reister and Korbinian
  Riedhammer","Towards Automated Assessment of Stuttering and Stuttering Therapy","10 pages, 3 figures, 1 table Accepted at TSD 2020, 23rd International
  Conference on Text, Speech and Dialogue",,,,"q-bio.QM cs.CL cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stuttering is a complex speech disorder that can be identified by
repetitions, prolongations of sounds, syllables or words, and blocks while
speaking. Severity assessment is usually done by a speech therapist. While
attempts at automated assessment were made, it is rarely used in therapy.
Common methods for the assessment of stuttering severity include percent
stuttered syllables (% SS), the average of the three longest stuttering
symptoms during a speech task, or the recently introduced Speech Efficiency
Score (SES). This paper introduces the Speech Control Index (SCI), a new method
to evaluate the severity of stuttering. Unlike SES, it can also be used to
assess therapy success for fluency shaping. We evaluate both SES and SCI on a
new comprehensively labeled dataset containing stuttered German speech of
clients prior to, during, and after undergoing stuttering therapy. Phone
alignments of an automatic speech recognition system are statistically
evaluated in relation to their relative position to labeled stuttering events.
The results indicate that phone length distributions differ with respect to
their position in and around labeled stuttering events
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:50:56 GMT""}]","2020-06-17"
"2006.09223","Vincent Plassier","Vincent Plassier, Fran\c{c}ois Portier, Johan Segers","Risk bounds when learning infinitely many response functions by ordinary
  linear regression","27 pages",,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider the problem of learning a large number of response functions
simultaneously based on the same input variables. The training data consist of
a single independent random sample of the input variables drawn from a common
distribution together with the associated responses. The input variables are
mapped into a high-dimensional linear space, called the feature space, and the
response functions are modelled as linear functionals of the mapped features,
with coefficients calibrated via ordinary least squares. We provide convergence
guarantees on the worst-case excess prediction risk by controlling the
convergence rate of the excess risk uniformly in the response function. The
dimension of the feature map is allowed to tend to infinity with the sample
size. The collection of response functions, although potentially infinite, is
supposed to have a finite Vapnik-Chervonenkis dimension. The bound derived can
be applied when building multiple surrogate models in a reasonable computing
time.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:54:21 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 14:44:26 GMT""},{""version"":""v3"",""created"":""Sat, 27 Nov 2021 15:07:08 GMT""}]","2021-11-30"
"2006.09224","Paola Popesso","P. Popesso, A. Concas, L. Morselli, G. Rodighiero, A. Enia, S. Qua","The dust and cold gas content of local star forming galaxies","Accepted for publication in MNRAS, 12 pages, 9 figures",,"10.1093/mnras/staa1737",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use dust masses ($M_{dust}$) derived from far-infrared data and molecular
gas masses ($M_{mol}$) based on CO luminosity, to calibrate proxies based on a
combination of the galaxy Balmer decrement, disk inclination and gas
metallicity. We use such proxies to estimate $M_{dust}$ and $M_{mol}$ in the
local SDSS sample of star-forming galaxies (SFGs). We study the distribution of
$M_{dust}$ and $M_{mol}$ along and across the Main Sequence (MS) of SFGs. We
find that $M_{dust}$ and $M_{mol}$ increase rapidly along the MS with
increasing stellar mass ($M_*$), and more marginally across the MS with
increasing SFR (or distance from the relation). The dependence on $M_*$ is
sub-linear for both $M_{dust}$ and $M_{mol}$. Thus, the fraction of dust
($f_{dust}$) and molecular gas mass ($f_{mol}$) decreases monotonically towards
large $M_*$. The star formation efficiency (SFE, the inverse of the molecular
gas depletion time) depends strongly on the distance from the MS and it is
constant along the MS. As nearly all galaxies in the sample are central
galaxies, we estimate the dependence of $f_{dust}$ and $f_{gas}$ on the host
halo mass and find a tight anti-correlation. As the region where the MS is
bending is numerically dominated by massive halos, we conclude that the bending
of the MS is due to lower availability of molecular gas mass in massive halos
rather than a lower efficiency in forming stars.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:54:45 GMT""}]","2020-06-24"
"2006.09225","Hongruixuan Chen","Hongruixuan Chen and Chen Wu and Bo Du and Liangpei Zhang","DSDANet: Deep Siamese Domain Adaptation Convolutional Neural Network for
  Cross-domain Change Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Change detection (CD) is one of the most vital applications in remote
sensing. Recently, deep learning has achieved promising performance in the CD
task. However, the deep models are task-specific and CD data set bias often
exists, hence it is inevitable that deep CD models would suffer degraded
performance after transferring it from original CD data set to new ones, making
manually label numerous samples in the new data set unavoidable, which costs a
large amount of time and human labor. How to learn a transferable CD model in
the data set with enough labeled data (original domain) but can well detect
changes in another data set without labeled data (target domain)? This is
defined as the cross-domain change detection problem. In this paper, we propose
a novel deep siamese domain adaptation convolutional neural network (DSDANet)
architecture for cross-domain CD. In DSDANet, a siamese convolutional neural
network first extracts spatial-spectral features from multi-temporal images.
Then, through multi-kernel maximum mean discrepancy (MK-MMD), the learned
feature representation is embedded into a reproducing kernel Hilbert space
(RKHS), in which the distribution of two domains can be explicitly matched. By
optimizing the network parameters and kernel coefficients with the source
labeled data and target unlabeled data, DSDANet can learn transferrable feature
representation that can bridge the discrepancy between two domains. To the best
of our knowledge, it is the first time that such a domain adaptation-based deep
network is proposed for CD. The theoretical analysis and experimental results
demonstrate the effectiveness and potential of the proposed method.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:00:54 GMT""}]","2020-06-17"
"2006.09226","Francesco Faccio","Francesco Faccio, Louis Kirsch and J\""urgen Schmidhuber","Parameter-Based Value Functions","Published as a conference paper at ICLR 2021",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional off-policy actor-critic Reinforcement Learning (RL) algorithms
learn value functions of a single target policy. However, when value functions
are updated to track the learned policy, they forget potentially useful
information about old policies. We introduce a class of value functions called
Parameter-Based Value Functions (PBVFs) whose inputs include the policy
parameters. They can generalize across different policies. PBVFs can evaluate
the performance of any policy given a state, a state-action pair, or a
distribution over the RL agent's initial states. First we show how PBVFs yield
novel off-policy policy gradient theorems. Then we derive off-policy
actor-critic algorithms based on PBVFs trained by Monte Carlo or Temporal
Difference methods. We show how learned PBVFs can zero-shot learn new policies
that outperform any policy seen during training. Finally our algorithms are
evaluated on a selection of discrete and continuous control tasks using shallow
policies and deep neural networks. Their performance is comparable to
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:04:49 GMT""},{""version"":""v2"",""created"":""Tue, 6 Oct 2020 17:14:32 GMT""},{""version"":""v3"",""created"":""Fri, 15 Jan 2021 15:01:49 GMT""},{""version"":""v4"",""created"":""Fri, 13 Aug 2021 14:33:27 GMT""}]","2021-08-16"
"2006.09227","Felix Casanova","Franz Herling, C. K. Safeer, Josep Ingla-Ayn\'es, Nerea Ontoso, Luis
  E. Hueso, F\`elix Casanova","Gate tunability of highly efficient spin-to-charge conversion by spin
  Hall effect in graphene proximitized with WSe$_2$","12 pages, 4 figures, 1 table, Supplementary Material","APL Materials 8, 071103 (2020)","10.1063/5.0006101",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The proximity effect opens ways to transfer properties from one material into
another and is especially important in two-dimensional materials. In van der
Waals heterostructures, transition metal dichalcogenides (TMD) can be used to
enhance the spin-orbit coupling of graphene leading to the prediction of gate
controllable spin-to-charge conversion (SCC). Here, we report for the first
time and quantify the SHE in graphene proximitized with WSe$_2$ up to room
temperature. Unlike in other graphene/TMD devices, the sole SCC mechanism is
the spin Hall effect and no Rashba-Edelstein effect is observed. Importantly,
we are able to control the SCC by applying a gate voltage. The SCC shows a high
efficiency, measured with an unprecedented SCC length larger than 20 nm. These
results show the capability of two-dimensional materials to advance towards the
implementation of novel spin-based devices and future applications.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:06:10 GMT""}]","2020-08-10"
"2006.09228","Sujay Kadam","Sujay D. Kadam and Harish J. Palanthandalam-Madapusi","Trackability for Discrete-Time LTI Systems: A Brief Review and New
  Insights",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  `Trackability', the ability of systems to follow arbitrary reference
commands, is investigated in this work. Controllability is not useful in
explaining the tracking behavior of system outputs, a gap that is often
overlooked. Trackability addresses this gap by characterizing whether system
dynamics permits tracking of certain reference commands, irrespective of the
controller/control action used. While earlier literature has discussed
closely-related ideas, lack of consistency in terminology and focus in the
literature has necessitated defining trackability in a simple but rigorous
manner. We present definitions for trackability based on elementary linear
algebra and propose a rank test for determining trackability of systems, while
posing tracking control as an existence question. We discuss in some detail the
relationship of this rank test with other results in the literature. These
results are then used to generate insights about trackable systems and more
importantly to gain insights in to tracking behavior of systems that are not
trackable. We also define three indices that indicate the expected tracking
behavior of the system. Furthermore, we also present a Venn diagram explaining
in detail the connections between trackability and other fundamental system
properties like controllability, observability and output controllability,
while discussing several facts that elaborate these connections. Specifically,
we show that trackability is fundamentally different from controllability and
output controllability. The presented work is expected to serve as a foundation
for a deeper investigation into the topic of tracking control and provide a
framework for receiving new theoretical insights on trackability.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:06:47 GMT""}]","2020-06-17"
"2006.09229","Stefano Melacci","Matteo Tiezzi, Stefano Melacci, Alessandro Betti, Marco Maggini, Marco
  Gori","Focus of Attention Improves Information Transfer in Visual Features",,,,,"cs.LG cs.IT math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised learning from continuous visual streams is a challenging problem
that cannot be naturally and efficiently managed in the classic batch-mode
setting of computation. The information stream must be carefully processed
accordingly to an appropriate spatio-temporal distribution of the visual data,
while most approaches of learning commonly assume uniform probability density.
In this paper we focus on unsupervised learning for transferring visual
information in a truly online setting by using a computational model that is
inspired to the principle of least action in physics. The maximization of the
mutual information is carried out by a temporal process which yields online
estimation of the entropy terms. The model, which is based on second-order
differential equations, maximizes the information transfer from the input to a
discrete space of symbols related to the visual features of the input, whose
computation is supported by hidden neurons. In order to better structure the
input probability distribution, we use a human-like focus of attention model
that, coherently with the information maximization model, is also based on
second-order differential equations. We provide experimental results to support
the theory by showing that the spatio-temporal filtering induced by the focus
of attention allows the system to globally transfer more information from the
input stream over the focused areas and, in some contexts, over the whole
frames with respect to the unfiltered case that yields uniform probability
distributions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:07:25 GMT""}]","2020-06-17"
"2006.09230","Ruilin Li","Ruilin Li, Hongyuan Zha, Molei Tao","Hessian-Free High-Resolution Nesterov Acceleration for Sampling",,,,,"cs.LG cs.NA math.NA stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nesterov's Accelerated Gradient (NAG) for optimization has better performance
than its continuous time limit (noiseless kinetic Langevin) when a finite
step-size is employed \citep{shi2021understanding}. This work explores the
sampling counterpart of this phenonemon and proposes a diffusion process, whose
discretizations can yield accelerated gradient-based MCMC methods. More
precisely, we reformulate the optimizer of NAG for strongly convex functions
(NAG-SC) as a Hessian-Free High-Resolution ODE, change its high-resolution
coefficient to a hyperparameter, inject appropriate noise, and discretize the
resulting diffusion process. The acceleration effect of the new hyperparameter
is quantified and it is not an artificial one created by time-rescaling.
Instead, acceleration beyond underdamped Langevin in $W_2$ distance is
quantitatively established for log-strongly-concave-and-smooth targets, at both
the continuous dynamics level and the discrete algorithm level. Empirical
experiments in both log-strongly-concave and multi-modal cases also numerically
demonstrate this acceleration.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:07:37 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 01:42:23 GMT""},{""version"":""v3"",""created"":""Mon, 26 Apr 2021 20:15:51 GMT""},{""version"":""v4"",""created"":""Sat, 18 Jun 2022 01:50:00 GMT""}]","2022-06-22"
"2006.09231","Haji M. Furqan Madni","H. M. Furqan, M. A. Aygul, M. Nazzal, H. Arslan","Primary User Emulation and Jamming Attack Detection in Cognitive Radio
  via Sparse Coding","Accepted for publication in EURASIP Journal on Wireless
  Communications and Networking, TO BE APPEAR: Journal on Wireless
  Communications and Networking, 2020","J Wireless Com Network 2020, 141 (2020)","10.1186/s13638-020-01736-y","JWCN-D-19-00704","eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cognitive radio is an intelligent and adaptive radio that improves the
utilization of the spectrum by its opportunistic sharing. However, it is
inherently vulnerable to primary user emulation and jamming attacks that
degrade the spectrum utilization. In this paper, an algorithm for the detection
of primary user emulation and jamming attacks in cognitive radio is proposed.
The proposed algorithm is based on the sparse coding of the compressed received
signal over a channel-dependent dictionary. More specifically, the convergence
patterns in sparse coding according to such a dictionary are used to
distinguish between a spectrum hole, a legitimate primary user, and an emulator
or a jammer. The process of decision-making is carried out as a machine
learning-based classification operation. Extensive numerical experiments show
the effectiveness of the proposed algorithm in detecting the aforementioned
attacks with high success rates. This is validated in terms of the confusion
matrix quality metric. Besides, the proposed algorithm is shown to be superior
to energy detection-based machine learning techniques in terms of receiver
operating characteristics curves and the areas under these curves
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:07:38 GMT""}]","2020-07-06"
"2006.09232","Francois Pachet","Fran\c{c}ois Pachet and Pierre Roy and Benoit Carr\'e","Assisted music creation with Flow Machines: towards new categories of
  new","This paper is a hyperlinked version of chapter 18 of the book
  ""Handbook of Artificial Intelligence for Music"", Eduardo Miranda ed.,
  Springer, 2020. Accompanying website:
  https://www.francoispachet.fr/flow-machines-synthesis-paper/ This version
  corrects some typos",,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This chapter reflects on about 10 years of research in AI- assisted music
composition, in particular during the Flow Machines project. We reflect on the
motivations for such a project, its background, its main results and impact,
both technological and musical, several years after its completion. We conclude
with a proposal for new categories of new, created by the many uses of AI
techniques to generate novel material.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:08:22 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 20:02:46 GMT""},{""version"":""v3"",""created"":""Mon, 4 Jan 2021 16:02:30 GMT""}]","2021-01-05"
"2006.09233","Mario Gleirscher","Simon Foster and Mario Gleirscher and Radu Calinescu","Towards Deductive Verification of Control Algorithms for Autonomous
  Marine Vehicles",,,"10.1109/ICECCS51672.2020.00020",,"cs.SE cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of autonomous vehicles in real-world applications is often precluded
by the difficulty of providing safety guarantees for their complex controllers.
The simulation-based testing of these controllers cannot deliver sufficient
safety guarantees, and the use of formal verification is very challenging due
to the hybrid nature of the autonomous vehicles. Our work-in-progress paper
introduces a formal verification approach that addresses this challenge by
integrating the numerical computation of such a system (in GNU/Octave) with its
hybrid system verification by means of a proof assistant (Isabelle). To show
the effectiveness of our approach, we use it to verify differential invariants
of an Autonomous Marine Vehicle with a controller switching between multiple
modes.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:09:38 GMT""}]","2021-12-22"
"2006.09234","Chao Qu","Xiaoyu Tan, Chao Qu, Junwu Xiong, James Zhang","Model Embedding Model-Based Reinforcement Learning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model-based reinforcement learning (MBRL) has shown its advantages in
sample-efficiency over model-free reinforcement learning (MFRL). Despite the
impressive results it achieves, it still faces a trade-off between the ease of
data generation and model bias. In this paper, we propose a simple and elegant
model-embedding model-based reinforcement learning (MEMB) algorithm in the
framework of the probabilistic reinforcement learning. To balance the
sample-efficiency and model bias, we exploit both real and imaginary data in
the training. In particular, we embed the model in the policy update and learn
$Q$ and $V$ functions from the real data set. We provide the theoretical
analysis of MEMB with the Lipschitz continuity assumption on the model and
policy. At last, we evaluate MEMB on several benchmarks and demonstrate our
algorithm can achieve state-of-the-art performance.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:10:28 GMT""}]","2020-06-17"
"2006.09235","Fengmao Lv","Tao Liang, Wenya Wang, Fengmao Lv","Weakly-supervised Domain Adaption for Aspect Extraction via Multi-level
  Interaction Transfer","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fine-grained aspect extraction is an essential sub-task in aspect based
opinion analysis. It aims to identify the aspect terms (a.k.a. opinion targets)
of a product or service in each sentence. However, expensive annotation process
is usually involved to acquire sufficient token-level labels for each domain.
To address this limitation, some previous works propose domain adaptation
strategies to transfer knowledge from a sufficiently labeled source domain to
unlabeled target domains. But due to both the difficulty of fine-grained
prediction problems and the large domain gap between domains, the performance
remains unsatisfactory. This work conducts a pioneer study on leveraging
sentence-level aspect category labels that can be usually available in
commercial services like review sites to promote token-level transfer for the
extraction purpose. Specifically, the aspect category information is used to
construct pivot knowledge for transfer with assumption that the interactions
between sentence-level aspect category and token-level aspect terms are
invariant across domains. To this end, we propose a novel multi-level
reconstruction mechanism that aligns both the fine-grained and coarse-grained
information in multiple levels of abstractions. Comprehensive experiments
demonstrate that our approach can fully utilize sentence-level aspect category
labels to improve cross-domain aspect extraction with a large performance gain.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:11:51 GMT""}]","2020-06-17"
"2006.09236","Vasil Rokaj","Vasil Rokaj, Michael Ruggenthaler, Florian G. Eich, and Angel Rubio","The Free Electron Gas in Cavity Quantum Electrodynamics",,"Phys. Rev. Research 4 (1), 013012 (2022)","10.1103/PhysRevResearch.4.013012",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cavity modification of material properties and phenomena is a novel research
field largely motivated by the advances in strong light-matter interactions.
Despite this progress, exact solutions for extended systems strongly coupled to
the photon field are not available, and both theory and experiments rely mainly
on finite-system models. Therefore a paradigmatic example of an exactly
solvable extended system in a cavity becomes highly desireable. To fill this
gap we revisit Sommerfeld's theory of the free electron gas in cavity quantum
electrodynamics (QED). We solve this system analytically in the long-wavelength
limit for an arbitrary number of non-interacting electrons, and we demonstrate
that the electron-photon ground state is a Fermi liquid which contains virtual
photons. In contrast to models of finite systems, no ground state exists if the
diamagentic $\textbf{A}^2$ term is omitted. Further, by performing linear
response we show that the cavity field induces plasmon-polariton excitations
and modifies the optical and the DC conductivity of the electron gas. Our exact
solution allows us to consider the thermodynamic limit for both electrons and
photons by constructing an effective quantum field theory. The continuum of
modes leads to a many-body renormalization of the electron mass, which modifies
the fermionic quasiparticle excitations of the Fermi liquid and the
Wigner-Seitz radius of the interacting electron gas. Lastly, we show how the
matter-modified photon field leads to a repulsive Casimir force and how the
continuum of modes introduces dissipation into the light-matter system. Several
of the presented findings should be experimentally accessible.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:12:20 GMT""},{""version"":""v2"",""created"":""Sun, 25 Oct 2020 17:37:52 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jan 2021 09:54:39 GMT""},{""version"":""v4"",""created"":""Thu, 27 May 2021 19:11:45 GMT""}]","2022-01-13"
"2006.09237","Stephen Schecter","Stephen Schecter","Geometric Singular Perturbation Theory Analysis of an Epidemic Model
  with Spontaneous Human Behavioral Change",,,,,"q-bio.PE math.DS physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a model due to Piero Poletti and collaborators that adds
spontaneous human behavioral change to the standard SIR epidemic model. In its
simplest form, the Poletti model adds one differential equation, motivated by
evolutionary game theory, to the SIR model. The new equation describes the
evolution of a variable $x$ that represents the fraction of the population
using normal behavior. The remaining fraction $1-x$ uses altered behavior such
as staying home, social isolation, mask wearing, etc. Normal behavior offers a
higher payoff when the number of infectives is low; altered behavior offers a
higher payoff when the number is high. We show that the entry-exit function of
geometric singular perturbation theory can be used to analyze the model in the
limit in which behavior changes on a much faster time scale than that of the
epidemic. In particular, behavior does not change as soon as a different
behavior has a higher payoff; current behavior is sticky. The delay until
behavior changes in predicted by the entry-exit function.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:13:32 GMT""},{""version"":""v2"",""created"":""Sun, 21 Jun 2020 19:18:13 GMT""}]","2020-06-23"
"2006.09238","Chen Joya","Joya Chen, Qi Wu, Dong Liu, Tong Xu","Foreground-Background Imbalance Problem in Deep Object Detectors: A
  Review","Accepted by IEEE MIPR 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent years have witnessed the remarkable developments made by deep learning
techniques for object detection, a fundamentally challenging problem of
computer vision. Nevertheless, there are still difficulties in training
accurate deep object detectors, one of which is owing to the
foreground-background imbalance problem. In this paper, we survey the recent
advances about the solutions to the imbalance problem. First, we analyze the
characteristics of the imbalance problem in different kinds of deep detectors,
including one-stage and two-stage ones. Second, we divide the existing
solutions into two categories: sampling heuristics and non-sampling schemes,
and review them in detail. Third, we experimentally compare the performance of
some state-of-the-art solutions on the COCO benchmark. Promising directions for
future work are also discussed.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:15:53 GMT""}]","2020-06-17"
"2006.09239","Bertrand Charpentier","Bertrand Charpentier, Daniel Z\""ugner, Stephan G\""unnemann","Posterior Network: Uncertainty Estimation without OOD Samples via
  Density-Based Pseudo-Counts","Neurips 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate estimation of aleatoric and epistemic uncertainty is crucial to
build safe and reliable systems. Traditional approaches, such as dropout and
ensemble methods, estimate uncertainty by sampling probability predictions from
different submodels, which leads to slow uncertainty estimation at inference
time. Recent works address this drawback by directly predicting parameters of
prior distributions over the probability predictions with a neural network.
While this approach has demonstrated accurate uncertainty estimation, it
requires defining arbitrary target parameters for in-distribution data and
makes the unrealistic assumption that out-of-distribution (OOD) data is known
at training time.
  In this work we propose the Posterior Network (PostNet), which uses
Normalizing Flows to predict an individual closed-form posterior distribution
over predicted probabilites for any input sample. The posterior distributions
learned by PostNet accurately reflect uncertainty for in- and
out-of-distribution data -- without requiring access to OOD data at training
time. PostNet achieves state-of-the art results in OOD detection and in
uncertainty calibration under dataset shifts.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:16:32 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 10:39:20 GMT""}]","2020-10-23"
"2006.09240","Marek We\.zgowiec","M. Wezgowiec (Jagiellonian University), M. Ehle (ESA/ESAC), M. Soida
  (Jagiellonian University), R.-J. Dettmar (Ruhr-University Bochum), R. Beck
  (Max Planck Institute for Radio Astronomy), and M. Urbanik (Jagiellonian
  University)","Hot gas heating via magnetic arms in spiral galaxies. The case of M 83","15 pages, 10 figures, A&A accepted","A&A 640, A109 (2020)","10.1051/0004-6361/202037842",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reconnection heating has been considered as a potential source of the heating
of the interstellar medium. In some galaxies, significant polarised radio
emission has been found between the spiral arms. This emission has a form of
`magnetic arms' that resembles the spiral structure of the galaxy. Reconnection
effects could convert some of the energy of the turbulent magnetic field into
the thermal energy of the surrounding medium, leaving more ordered magnetic
fields, as is observed in the magnetic arms. Sensitive radio and X-ray data for
the grand-design spiral galaxy M 83 are used for a detailed analysis of the
possible interactions of magnetic fields with hot gas, including a search for
signatures of gas heating by magnetic reconnection effects. Magnetic field
strengths and energies derived from the radio emission are compared with the
parameters of the hot gas calculated from the model fits to sensitive X-ray
spectra of the hot gas emission. The available X-ray data allowed us to
distinguish two thermal components in the halo of M 83. We found slightly
higher average temperatures of the hot gas in the interarm regions, which
results in higher energies per particle and is accompanied by a decrease in the
energy density of the magnetic fields. The observed differences in the energy
budget between the spiral arms and the interarm regions suggest that, similar
to the case of another spiral galaxy NGC 6946, we may be observing hints for
gas heating by magnetic reconnection effects in the interarm regions. These
effects, which act more efficiently on the turbulent component of the magnetic
field, are expected to be stronger in the spiral arms. However, with the
present data it is only possible to trace them in the interarm regions, where
the star formation and the resulting turbulence is low.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:18:22 GMT""}]","2020-08-26"
"2006.09241","Sheila Seidel","Sheila W. Seidel, John Murray-Bruce, Yanting Ma, Christopher Yu,
  William T. Freeman, and Vivek K Goyal","Two-Dimensional Non-Line-of-Sight Scene Estimation from a Single Edge
  Occluder","14 pages, 15 figures",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Passive non-line-of-sight imaging methods are often faster and stealthier
than their active counterparts, requiring less complex and costly equipment.
However, many of these methods exploit motion of an occluder or the hidden
scene, or require knowledge or calibration of complicated occluders. The edge
of a wall is a known and ubiquitous occluding structure that may be used as an
aperture to image the region hidden behind it. Light from around the corner is
cast onto the floor forming a fan-like penumbra rather than a sharp shadow.
Subtle variations in the penumbra contain a remarkable amount of information
about the hidden scene. Previous work has leveraged the vertical nature of the
edge to demonstrate 1D (in angle measured around the corner) reconstructions of
moving and stationary hidden scenery from as little as a single photograph of
the penumbra. In this work, we introduce a second reconstruction dimension:
range measured from the edge. We derive a new forward model, accounting for
radial falloff, and propose two inversion algorithms to form 2D reconstructions
from a single photograph of the penumbra. Performances of both algorithms are
demonstrated on experimental data corresponding to several different hidden
scene configurations. A Cramer-Rao bound analysis further demonstrates the
feasibility (and utility) of the 2D corner camera.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:19:20 GMT""}]","2020-06-17"
"2006.09242","Martin Schmitt","Martin Schmitt, Leonardo F. R. Ribeiro, Philipp Dufter, Iryna
  Gurevych, Hinrich Sch\""utze","Modeling Graph Structure via Relative Position for Text Generation from
  Knowledge Graphs","Accepted as a long paper at TextGraphs 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We present Graformer, a novel Transformer-based encoder-decoder architecture
for graph-to-text generation. With our novel graph self-attention, the encoding
of a node relies on all nodes in the input graph - not only direct neighbors -
facilitating the detection of global patterns. We represent the relation
between two nodes as the length of the shortest path between them. Graformer
learns to weight these node-node relations differently for different attention
heads, thus virtually learning differently connected views of the input graph.
We evaluate Graformer on two popular graph-to-text generation benchmarks,
AGENDA and WebNLG, where it achieves strong performance while using many fewer
parameters than other approaches.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:20:04 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 12:52:33 GMT""},{""version"":""v3"",""created"":""Tue, 27 Apr 2021 09:13:08 GMT""}]","2021-04-28"
"2006.09243","Kunal Swami","Kunal Swami, Prasanna Vishnu Bondada, Pankaj Kumar Bajpai","AcED: Accurate and Edge-consistent Monocular Depth Estimation","Accepted in IEEE ICIP 2020",,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Single image depth estimation is a challenging problem. The current
state-of-the-art method formulates the problem as that of ordinal regression.
However, the formulation is not fully differentiable and depth maps are not
generated in an end-to-end fashion. The method uses a na\""ive threshold
strategy to determine per-pixel depth labels, which results in significant
discretization errors. For the first time, we formulate a fully differentiable
ordinal regression and train the network in end-to-end fashion. This enables us
to include boundary and smoothness constraints in the optimization function,
leading to smooth and edge-consistent depth maps. A novel per-pixel confidence
map computation for depth refinement is also proposed. Extensive evaluation of
the proposed model on challenging benchmarks reveals its superiority over
recent state-of-the-art methods, both quantitatively and qualitatively.
Additionally, we demonstrate practical utility of the proposed method for
single camera bokeh solution using in-house dataset of challenging real-life
images.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:21:00 GMT""}]","2020-06-17"
"2006.09244","Gennaro Infante","Gennaro Infante","Eigenvalues of elliptic functional differential systems via a
  Birkhoff--Kellogg type theorem","9 pages. arXiv admin note: text overlap with arXiv:1903.10900","Mathematics 2021, 9, no. 1: 4","10.3390/math9010004",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by recent interest on Kirchhoff-type equations, in this short note
we utilize a classical, yet very powerful, tool of nonlinear functional
analysis in order to investigate the existence of positive eigenvalues of
systems of elliptic functional differential equations. An example is presented
to illustrate the theory.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:22:26 GMT""}]","2021-02-09"
"2006.09245","Mucahit Cevik","Ozan Ozyegen and Sanaz Mohammadjafari and Karim El mokhtari and
  Mucahit Cevik and Jonathan Ethier and Ayse Basar","An empirical study on using CNNs for fast radio signal prediction",,,,,"cs.LG eess.IV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate radio frequency power prediction in a geographic region is a
computationally expensive part of finding the optimal transmitter location
using a ray tracing software. We empirically analyze the viability of deep
learning models to speed up this process. Specifically, deep learning methods
including CNNs and UNET are typically used for segmentation, and can also be
employed in power prediction tasks. We consider a dataset that consists of
radio frequency power values for five different regions with four different
frame dimensions. We compare deep learning-based prediction models including
RadioUNET and four different variations of the UNET model for the power
prediction task. More complex UNET variations improve the model on higher
resolution frames such as 256x256. However, using the same models on lower
resolutions results in overfitting and simpler models perform better. Our
detailed numerical analysis shows that the deep learning models are effective
in power prediction and they are able to generalize well to the new regions.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:21:44 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 16:03:07 GMT""},{""version"":""v3"",""created"":""Mon, 20 Sep 2021 17:10:55 GMT""}]","2021-09-21"
"2006.09246","Daniel Kennedy","Daniel Kennedy and Per Helander","Coulomb collisions in strongly anisotropic plasmas I. Cyclotron cooling
  in electron-ion plasmas",,,,,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The behaviour of a collisional plasma which is optically thin to cyclotron
radiation is considered, and the distribution functions accessible to it on the
various timescales in the system are calculated. Particular attention is paid
to the limit in which the collision time exceeds the radiation emission time,
making the electron distribution function strongly anisotropic. Unusually for
plasma physics, the collision operator can nevertheless be calculated
analytically although the plasma is far from Maxwellian. The rate of radiation
emission is calculated and found to be governed by the collision frequency
multiplied by a factor that only depends logarithmically on plasma parameters.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:22:31 GMT""},{""version"":""v2"",""created"":""Fri, 11 Sep 2020 17:10:47 GMT""},{""version"":""v3"",""created"":""Fri, 18 Sep 2020 08:52:18 GMT""},{""version"":""v4"",""created"":""Wed, 28 Oct 2020 13:11:25 GMT""}]","2020-10-29"
"2006.09247","Jie Fang","Jie Fang and Jianwu Lin","Prior knowledge distillation based on financial time series","Published on IEEE-INDIN-2020, 6 pages","IEEE INDIN 2020 Conference",,,"cs.LG q-fin.TR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the major characteristics of financial time series is that they
contain a large amount of non-stationary noise, which is challenging for deep
neural networks. People normally use various features to address this problem.
However, the performance of these features depends on the choice of
hyper-parameters. In this paper, we propose to use neural networks to represent
these indicators and train a large network constructed of smaller networks as
feature layers to fine-tune the prior knowledge represented by the indicators.
During back propagation, prior knowledge is transferred from human logic to
machine logic via gradient descent. Prior knowledge is the deep belief of
neural network and teaches the network to not be affected by non-stationary
noise. Moreover, co-distillation is applied to distill the structure into a
much smaller size to reduce redundant features and the risk of overfitting. In
addition, the decisions of the smaller networks in terms of gradient descent
are more robust and cautious than those of large networks. In numerical
experiments, we find that our algorithm is faster and more accurate than
traditional methods on real financial datasets. We also conduct experiments to
verify and comprehend the method.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:26:06 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 07:29:31 GMT""},{""version"":""v3"",""created"":""Mon, 20 Jul 2020 10:07:58 GMT""},{""version"":""v4"",""created"":""Sat, 10 Oct 2020 04:35:33 GMT""},{""version"":""v5"",""created"":""Thu, 26 Nov 2020 05:58:52 GMT""}]","2020-11-30"
"2006.09248","Daniel Kennedy","Daniel Kennedy and Per Helander","Coulomb collisions in strongly anisotropic plasmas II. Cyclotron cooling
  in laboratory pair plasmas",,,"10.1017/S0022377820001233",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The behaviour of a strongly-magnetized collisional electron-positron plasma
which is optically thin to cyclotron radiation is considered, and the
distribution functions accessible to it on the various timescales in the system
are calculated. Particular attention is paid to the limit in which the
collision time exceeds the radiation emission time, making the electron
distribution function strongly anisotropic. Indeed, these are the exact
conditions likely to be attained in the first laboratory electron-positron
plasma experiments currently being developed, which will typically have very
low densities and be confined in very strong magnetic fields. The constraint of
strong-magnetization adds an additional complication in that long-range Coulomb
collisions, which are usually negligible, must now be considered. A rigorous
collision operator for these long-range collisions has never been written down.
Nevertheless, we show that the collisional scattering can be accounted for
without knowing the explicit form of this collision operator. The rate of
radiation emission is calculated and it is found that the loss of energy from
the plasma is proportional to the parallel collision frequency multiplied by a
factor that only depends logarithmically on plasma parameters. That is, this is
a self-accelerating process, meaning that the bulk of the energy will be lost
in a few collision times. We show that in a simple case, that of straight
field-line geometry, there are no unstable drift waves in such plasmas, despite
being far from Maxwellian.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:27:14 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 08:49:33 GMT""},{""version"":""v3"",""created"":""Tue, 8 Sep 2020 09:46:57 GMT""}]","2021-02-17"
"2006.09249","Mikhail Kats","A. Shahsafi, J. Salman, B. E. Rubio Perez, Y. Xiao, C. Wan, and M. A.
  Kats","Infrared polarizer based on direct coupling to surface-plasmon
  polaritons","Main text + supplementary",,"10.1021/acs.nanolett.0c02492",,"physics.optics physics.app-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new type of reflective polarizer based on polarization-dependent
coupling to surface-plasmon polaritons (SPPs) from free space. This inexpensive
polarizer is relatively narrowband but features an extinction ratio of up to
1000 with efficiency of up to 95% for the desired polarization (numbers from a
calculation), and thus can be stacked to achieve extinction ratios of 106 or
more. As a proof of concept, we experimentally realized a polarizer based on
nanoporous aluminum oxide that operates around a wavelength of 10.6 um,
corresponding to the output of a CO2 laser, using aluminum anodization, a
low-cost electrochemical process.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:07:57 GMT""},{""version"":""v2"",""created"":""Wed, 9 Sep 2020 05:00:48 GMT""}]","2020-12-30"
"2006.09250","Giovanni Bussi","Mattia Bernetti and Giovanni Bussi","Pressure control using stochastic cell rescaling","Supporting information included in ancillary files. The article has
  been accepted by J. Chem. Phys","J. Chem. Phys. 153, 114107 (2020)","10.1063/5.0020514",,"physics.comp-ph cond-mat.stat-mech physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Molecular dynamics simulations require barostats to be performed at constant
pressure. The usual recipe is to employ the Berendsen barostat first, which
displays a first-order volume relaxation efficient in equilibration but results
in incorrect volume fluctuations, followed by a second order or Monte Carlo
barostat for production runs. In this paper, we introduce stochastic cell
rescaling, a first-order barostat that samples the correct volume fluctuations
by including a suitable noise term. The algorithm is shown to report volume
fluctuations compatible with the isobaric ensemble and its anisotropic variant
is tested on a membrane simulation. Stochastic cell rescaling can be
straightforwardly implemented in existing codes and can be used effectively
both in equilibration and in production phases.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:27:49 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 08:56:54 GMT""},{""version"":""v3"",""created"":""Wed, 1 Jul 2020 10:24:14 GMT""},{""version"":""v4"",""created"":""Wed, 26 Aug 2020 18:22:54 GMT""}]","2020-09-17"
"2006.09252","Giorgos Bouritsas","Giorgos Bouritsas, Fabrizio Frasca, Stefanos Zafeiriou, Michael M.
  Bronstein","Improving Graph Neural Network Expressivity via Subgraph Isomorphism
  Counting",,,,,"cs.LG cs.SI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While Graph Neural Networks (GNNs) have achieved remarkable results in a
variety of applications, recent studies exposed important shortcomings in their
ability to capture the structure of the underlying graph. It has been shown
that the expressive power of standard GNNs is bounded by the Weisfeiler-Leman
(WL) graph isomorphism test, from which they inherit proven limitations such as
the inability to detect and count graph substructures. On the other hand, there
is significant empirical evidence, e.g. in network science and bioinformatics,
that substructures are often intimately related to downstream tasks. To this
end, we propose ""Graph Substructure Networks"" (GSN), a topologically-aware
message passing scheme based on substructure encoding. We theoretically analyse
the expressive power of our architecture, showing that it is strictly more
expressive than the WL test, and provide sufficient conditions for
universality. Importantly, we do not attempt to adhere to the WL hierarchy;
this allows us to retain multiple attractive properties of standard GNNs such
as locality and linear network complexity, while being able to disambiguate
even hard instances of graph isomorphism. We perform an extensive experimental
evaluation on graph classification and regression tasks and obtain
state-of-the-art results in diverse real-world settings including molecular
graphs and social networks. The code is publicly available at
https://github.com/gbouritsas/graph-substructure-networks.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:30:31 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 15:03:04 GMT""},{""version"":""v3"",""created"":""Mon, 5 Jul 2021 13:22:05 GMT""}]","2021-07-06"
"2006.09255","Teodor Vanislavov Marinov","Raman Arora, Teodor V. Marinov, Mehryar Mohri","Corralling Stochastic Bandit Algorithms",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of corralling stochastic bandit algorithms, that is
combining multiple bandit algorithms designed for a stochastic environment,
with the goal of devising a corralling algorithm that performs almost as well
as the best base algorithm. We give two general algorithms for this setting,
which we show benefit from favorable regret guarantees. We show that the regret
of the corralling algorithms is no worse than that of the best algorithm
containing the arm with the highest reward, and depends on the gap between the
highest reward and other rewards.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:33:12 GMT""},{""version"":""v2"",""created"":""Sun, 28 Jun 2020 15:55:01 GMT""},{""version"":""v3"",""created"":""Sun, 28 Feb 2021 07:33:03 GMT""}]","2021-03-02"
"2006.09256","Wei Xiong","Wei Xiong, Jiaojiao Chen, Baolong Fang, Mingfeng Wang, Liu Ye, and J.
  Q. You","Strong tunable spin-spin interaction in a weakly coupled nitrogen
  vacancy spin-cavity electromechanical system","8 pages, 4 figures","Phys. Rev. B 103, 174106 (2021)","10.1103/PhysRevB.103.174106",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The long coherence time of a single nitrogen vacancy (NV) center spin in
diamond is a crucial advantage for implementing quantum information processing.
However, the realization of strong coupling between single NV spins is
challenging. Here we propose a method to greatly enchance the interaction
between two single NV spins in diamond which are only weakly coupled to an
electromechanical cavity. Owing to the presence of a critical point for the
linearized electromechanical subsystem, the coupling between a single NV spin
and the high-frequency polariton (formed by the mechanical and cavity modes)
can be fully decoupled, but the coupling between the single NV spin and the
low-frequency polariton is however greatly enhanced. Thus, AC Stark shift of
the single NV spin can be measured. With the low-frequency polariton as a
quantum bus, a strong coupling between two single NV centers is achievable.
This effective strong coupling can ensure coherent quantum-information exchange
between two spin qubits in the weakly coupled spin-cavity elecromechanical
system.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:34:08 GMT""},{""version"":""v2"",""created"":""Sun, 28 Jun 2020 10:37:25 GMT""},{""version"":""v3"",""created"":""Mon, 3 Aug 2020 15:53:22 GMT""},{""version"":""v4"",""created"":""Wed, 12 May 2021 22:56:50 GMT""}]","2021-05-19"
"2006.09257","Leela Ganesh Chandra Lakkaraju","Leela Ganesh Chandra Lakkaraju, Srijon Ghosh, Saptarshi Roy, Aditi Sen
  De","Distribution of entanglement with variable range interactions","v1: 13 pages, 8 figures; v2: 16 pages, 11 figures, new results added,
  close to the published version","Phys. Lett. A 418, 127703 (2021)","10.1016/j.physleta.2021.127703",,"quant-ph cond-mat.other cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distribution of quantum entanglement is investigated for an anisotropic
quantum XY model with variable range interactions and in the presence of a
uniform transverse magnetic field. We report the possibility of
\emph{qualitative} growth in the entanglement between distant sites with an
increase in the range of interactions that vary either exponentially or
polynomially as the distance between the sites increases. Interestingly, we
find that such entanglement enhancement is not ubiquitous and is dependent on
the factorization points, a specific set of system parameters where the
zero-temperature state of the system is fully separable. In particular, we
observe that at zero-temperature, when the system parameters are chosen beyond
the pair of factorization points, the increments in entanglement length due to
variable range interactions are more pronounced compared to the situation when
the parameters lie in between the factorization points. By employing the sum of
all the bipartite entanglements with respect to a single site, we also show
that the shareability of the bipartite entanglements are constrained, thereby
establishing their monogamous nature. Furthermore, we note that the
factorization points get reallocated depending on the laws of interaction
fall-offs and provide an ansatz for the same. We reveal that the temperature at
which the canonical equilibrium state becomes entangled from an unentangled one
increases with the increase in the range of interactions, thereby demonstrating
enhanced robustness in entanglement against temperature in the presence of
long-range interactions and only when the system parameters are chosen between
the pair of factorization points. We apply an energy-based entanglement witness
to provide a justification to the observed robustness with temperature.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:34:31 GMT""},{""version"":""v2"",""created"":""Tue, 2 Nov 2021 11:29:13 GMT""}]","2021-11-03"
"2006.09258","Sergio Fortes","Sergio Fortes, David Palacios, Inmaculada Serrano, Raquel Barco","Applying Social Event Data for the Management of Cellular Networks","9 pages, 5 figures","IEEE Communications Magazine, vol. 56, no. 11, pp. 36-43, November
  2018","10.1109/MCOM.2018.1700580",,"cs.NI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Internet provides a growing variety of social data sources: calendars, event
aggregators, social networks, browsers, etc. Also, the mechanisms to gather
information from these sources, such as web services, semantic web and big data
techniques have become more accessible and efficient. This allows a detailed
prediction of the main expected events and their associated crowds. Due to the
increasing requirements for service provision, particularly in urban areas,
having information on those events would be extremely useful for Operations,
Administration and Maintenance (OAM) tasks, since the social events largely
affect the cellular network performance. Therefore, this paper presents a
framework for the automatic acquisition and processing of social data, as well
as their association with network elements (NEs) and their performance. The
main functionalities of this system, which have been devised to directly work
in real networks, are defined and developed. Different OAM applications of the
proposed approach are analyzed and the system is evaluated in a real
deployment.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:35:38 GMT""}]","2020-06-17"
"2006.09259","Luca Giacomelli","Luca Giacomelli and Iacopo Carusotto","Ergoregion instabilities in rotating two-dimensional Bose--Einstein
  condensates: new perspectives on the stability of quantized vortices","This work should have been submitted as a replacement of
  arXiv:1905.02447",,,,"cond-mat.quant-gas gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the stability of vortices in two-dimensional Bose--Einstein
condensates. In analogy with rotating spacetimes and with a careful account of
boundary conditions, we show that the dynamical instability of multiply
quantized vortices in trapped condensates persists in untrapped, spatially
homogeneous geometries and has an ergoregion nature with some modification due
to the peculiar dispersion of Bogoliubov sound. Our results open new
perspectives to the physics of vortices in trapped condensates, where multiply
quantized vortices can be stabilized by interference effects and singly charged
vortices can become unstable in suitably designed trap potentials. We show how
superradiant scattering can be observed also in the short-time dynamics of
dynamically unstable systems, providing an alternative point of view on
dynamical (in)stability phenomena in spatially finite systems.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:36:17 GMT""},{""version"":""v2"",""created"":""Sat, 27 Jun 2020 12:58:06 GMT""}]","2020-06-30"
"2006.09260","Ross Pinsky","Ross G. Pinsky","Comparing the inversion statistic for distribution-biased and
  distribution-shifted permutations with the geometric and the GEM
  distributions","The previous revised version had a new result--Theorem 4. In this
  revised version, the remark after Theorem 4 was removed",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a distribution $p:=\{p_k\}_{k=1}^\infty$ on the positive integers, there
are two natural ways to construct a random permutation in $S_n$ or of
$\mathbb{N}$ from IID samples from $p$--the $p$-biased construction and the
$p$-shifted construction. First we consider the case that $p$ is the geometric
distribution with parameter $1-q\in(0,1)$. In this case, the $p$-shifted random
permutation has the Mallows distribution with parameter $q$. Let
$P_n^{b;\text{Geo}(1-q)}$ and $P_n^{s;\text{Geo}(1-q)}$denote the biased and
the shifted distributions on $S_n$. The expected number of inversions of a
permutation under $P_n^{s;\text{Geo}(1-q)}$ is greater than under
$P_n^{b;\text{Geo}(1-q)}$, and under either of these, a permutation tends to
have many fewer inversions than it would have under the uniform distribution.
For fixed $n$, both $P_n^{b;\text{Geo}(1-q)}$ and $P_n^{s;\text{Geo}(1-q)}$
converge weakly as $q\to1$ to the uniform distribution on $S_n$. We compare the
biased and the shifted distributions by studying the inversion statistic under
$P_n^{b;\text{Geo}(q_n)}$ and $P_n^{s;\text{Geo}(q_n)}$ for various rates of
convergence of $q_n$ to 1. Then we consider $p$-biased and $p$-shifted
permutations in the case that the distribution $p$ is itself random and
distributed as a GEM$(\theta)$-distribution. In both the GEM$(\theta)$-biased
and the GEM$(\theta)$-shifted cases, the expected number of inversions behaves
asymptotically as it does under the Geo$(1-q)$-shifted distribution with
$\theta=\frac q{1-q}$. Thus, one can consider the GEM$(\theta)$-shifted case as
the random counterpart of the Geo$(q)$-shifted case. We also consider another
$p$-biased distribution with random $p$ for which the expected number of
inversions behaves asymptotically as it does under the Geo$(1-q)$-biased case
with $\theta$ and $q$ as above, and with $\theta\to\infty$ and $q\to1$.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:38:08 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 16:10:34 GMT""},{""version"":""v3"",""created"":""Thu, 25 Jun 2020 09:50:30 GMT""},{""version"":""v4"",""created"":""Tue, 30 Jun 2020 20:17:03 GMT""},{""version"":""v5"",""created"":""Wed, 8 Jul 2020 09:54:29 GMT""},{""version"":""v6"",""created"":""Sun, 8 Nov 2020 16:07:51 GMT""},{""version"":""v7"",""created"":""Wed, 6 Jan 2021 09:30:07 GMT""},{""version"":""v8"",""created"":""Sun, 10 Jan 2021 07:04:46 GMT""},{""version"":""v9"",""created"":""Sun, 21 Feb 2021 09:34:32 GMT""}]","2021-02-23"
"2006.09261","Alex Nowak-Vila","Thomas Eboli, Alex Nowak-Vila, Jian Sun, Francis Bach, Jean Ponce,
  Alessandro Rudi","Structured and Localized Image Restoration",,,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel approach to image restoration that leverages ideas from
localized structured prediction and non-linear multi-task learning. We optimize
a penalized energy function regularized by a sum of terms measuring the
distance between patches to be restored and clean patches from an external
database gathered beforehand. The resulting estimator comes with strong
statistical guarantees leveraging local dependency properties of overlapping
patches. We derive the corresponding algorithms for energies based on the
mean-squared and Euclidean norm errors. Finally, we demonstrate the practical
effectiveness of our model on different image restoration problems using
standard benchmarks.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:43:12 GMT""}]","2020-06-17"
"2006.09262","Jordan Wheeler","Jordan Wheeler, Jason Glenn, Naseem Rangwala, Adalyn Fyhrie","Arp 220: New Observational Insights into the Structure and Kinematics of
  the Nuclear Molecular Disks and Surrounding Gas",,"2020 June 11 The Astrophysical Journal, Volume 896, Number 1,
  Pages 43 The Astrophysical Journal, Volume 896, Number 1","10.3847/1538-4357/ab8f32",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  ALMA cycle 3 observations of $^{12}$CO $ J = 3\rightarrow2$, $^{13}$CO $J =
4\rightarrow 3$, SiO J = $8 \rightarrow 7$, and HCN J = $ 5 \rightarrow 4$ are
presented. Significant extended emission is detected in $^{12}$CO J $ =
3\rightarrow2$ with a morphology that is indicative of m = 2 tidal features,
suggesting gas inflow. In addition, outflow for both nuclei are found in the
$^{12}$CO J $ = 3\rightarrow2$. Significant SiO absorption is detected in the
western nucleus. HCN that is morphologically distinct from CO is detected in
both nuclei. These observations are compared to non-LTE radiative transfer
models created using the Line Modeling Engine (LIME) for simple gas dynamics to
gain insight into how physical parameters, such as rotational velocity,
turbulent velocity, gas temperature, dust temperature, and gas mass can
reproduce the observed kinematic and spatial features. The eastern nucleus is
found to be best modeled with an inclusion of a temperature asymmetry from one
side of the disk to the other. It is also found that the western nucleus is
optically thick even in the less abundant species of $^{13}$CO, absorbing
significant amounts of continuum radiation.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:43:59 GMT""}]","2020-06-17"
"2006.09263","Quoc Tran-Dinh","Yuzixuan Zhu and Deyi Liu and Quoc Tran-Dinh","A New Primal-Dual Algorithm for a Class of Nonlinear Compositional
  Convex Optimization Problems","26 pages, 2 figures, 1 table",,,"UNC-STOR-2020-June 16","math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a novel primal-dual algorithm to solve a class of nonsmooth and
nonlinear compositional convex minimization problems, which covers many
existing and brand-new models as special cases. Our approach relies on a
combination of a new nonconvex potential function, Nesterov's accelerated
scheme, and an adaptive parameter updating strategy. Our algorithm is
single-loop and has low per-iteration complexity. Under only general convexity
and mild assumptions, our algorithm achieves $\mathcal{O}(1/k)$ convergence
rates through three different criteria: primal objective residual, dual
objective residual, and primal-dual gap, where $k$ is the iteration counter.
Our rates are both ergodic (i.e., on an averaging sequence) and non-ergodic
(i.e., on the last-iterate sequence). These convergence rates can be
accelerated up to $\mathcal{O}(1/k^2)$ if only one objective term is strongly
convex (or equivalently, its conjugate is $L$-smooth). To the best of our
knowledge, this is the first algorithm achieving optimal rates on the primal
last-iterate sequence for nonlinear compositional convex minimization. As a
by-product, we specify our algorithm to solve a general convex cone constrained
program with both ergodic and non-ergodic rate guarantees. We test our
algorithms and compare them with two recent methods on a binary classification
and a convex-concave game model.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:44:14 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 02:02:17 GMT""}]","2021-04-20"
"2006.09266","Javier Nistal","Javier Nistal, Stefan Lattner and Ga\""el Richard","Comparing Representations for Audio Synthesis Using Generative
  Adversarial Networks","5 pages, 1 figure, 5 tables, to be published in European Signal
  Processing Conference (EUSIPCO)",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we compare different audio signal representations, including
the raw audio waveform and a variety of time-frequency representations, for the
task of audio synthesis with Generative Adversarial Networks (GANs). We conduct
the experiments on a subset of the NSynth dataset. The architecture follows the
benchmark Progressive Growing Wasserstein GAN. We perform experiments both in a
fully non-conditional manner as well as conditioning the network on the pitch
information. We quantitatively evaluate the generated material utilizing
standard metrics for assessing generative models, and compare training and
sampling times. We show that complex-valued as well as the magnitude and
Instantaneous Frequency of the Short-Time Fourier Transform achieve the best
results, and yield fast generation and inversion times. The code for feature
extraction, training and evaluating the model is available online.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:48:17 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 11:28:17 GMT""}]","2020-06-18"
"2006.09267","Gustav Nilsson","Amani Jaafer and Gustav Nilsson and Giacomo Como","Data Augmentation of IMU Signals and Evaluation via a Semi-Supervised
  Classification of Driving Behavior","Extended version of the paper accepted to The 23rd IEEE International
  Conference on Intelligent Transportation Systems",,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the past years, interest in classifying drivers' behavior from data has
surged. Such interest is particularly relevant for car insurance companies who,
due to privacy constraints, often only have access to data from Inertial
Measurement Units (IMU) or similar. In this paper, we present a semi-supervised
learning solution to classify portions of trips according to whether drivers
are driving aggressively or normally based on such IMU data. Since the amount
of labeled IMU data is limited and costly to generate, we utilize Recurrent
Conditional Generative Adversarial Networks (RCGAN) to generate more labeled
data. Our results show that, by utilizing RCGAN-generated labeled data, the
classification of the drivers is improved in 79% of the cases, compared to when
the drivers are classified with no generated data.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:49:21 GMT""}]","2020-06-17"
"2006.09268","Carl-Johann Simon-Gabriel","Carl-Johann Simon-Gabriel and Alessandro Barp and Bernhard Sch\""olkopf
  and Lester Mackey","Metrizing Weak Convergence with Maximum Mean Discrepancies","14 pages. Corrects in particular Thm.12 of Simon-Gabriel and
  Sch\""olkopf, JMLR, 19(44):1-29, 2018. See
  http://jmlr.org/papers/v19/16-291.html",,,,"cs.LG math.PR math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper characterizes the maximum mean discrepancies (MMD) that metrize
the weak convergence of probability measures for a wide class of kernels. More
precisely, we prove that, on a locally compact, non-compact, Hausdorff space,
the MMD of a bounded continuous Borel measurable kernel k, whose reproducing
kernel Hilbert space (RKHS) functions vanish at infinity, metrizes the weak
convergence of probability measures if and only if k is continuous and
integrally strictly positive definite (i.s.p.d.) over all signed, finite,
regular Borel measures. We also correct a prior result of Simon-Gabriel &
Sch\""olkopf (JMLR, 2018, Thm.12) by showing that there exist both bounded
continuous i.s.p.d. kernels that do not metrize weak convergence and bounded
continuous non-i.s.p.d. kernels that do metrize it.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:49:33 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jun 2021 11:35:16 GMT""},{""version"":""v3"",""created"":""Fri, 3 Sep 2021 13:03:54 GMT""}]","2021-09-06"
"2006.09269","Carl Feghali","Zden\v{e}k Dvo\v{r}\'ak and Carl Feghali","A Thomassen-type method for planar graph recoloring","20 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The reconfiguration graph $R_k(G)$ for the $k$-colorings of a graph $G$ has
as vertices all possible $k$-colorings of $G$ and two colorings are adjacent if
they differ in the color of exactly one vertex. We use a list coloring
technique inspired by results of Thomassen to prove that for a planar graph $G$
with $n$ vertices, $R_{10}(G)$ has diameter at most $8n$, and if $G$ is
triangle-free, then $R_7(G)$ has diameter at most $7n$.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:53:49 GMT""}]","2020-06-17"
"2006.09270","Adil Salim","Adil Salim and Peter Richt\'arik","Primal Dual Interpretation of the Proximal Stochastic Gradient Langevin
  Algorithm",,,,,"stat.ML cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  We consider the task of sampling with respect to a log concave probability
distribution. The potential of the target distribution is assumed to be
composite, \textit{i.e.}, written as the sum of a smooth convex term, and a
nonsmooth convex term possibly taking infinite values. The target distribution
can be seen as a minimizer of the Kullback-Leibler divergence defined on the
Wasserstein space (\textit{i.e.}, the space of probability measures). In the
first part of this paper, we establish a strong duality result for this
minimization problem. In the second part of this paper, we use the duality gap
arising from the first part to study the complexity of the Proximal Stochastic
Gradient Langevin Algorithm (PSGLA), which can be seen as a generalization of
the Projected Langevin Algorithm. Our approach relies on viewing PSGLA as a
primal dual algorithm and covers many cases where the target distribution is
not fully supported. In particular, we show that if the potential is strongly
convex, the complexity of PSGLA is $O(1/\varepsilon^2)$ in terms of the
2-Wasserstein distance. In contrast, the complexity of the Projected Langevin
Algorithm is $O(1/\varepsilon^{12})$ in terms of total variation when the
potential is convex.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:57:09 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 15:12:16 GMT""}]","2021-02-23"
"2006.09271","Edward Raff","Edward Raff, Charles Nicholas","A Survey of Machine Learning Methods and Challenges for Windows Malware
  Classification","To appear in NeurIPS 2020 Workshop: ML Retrospectives, Surveys &
  Meta-Analyses (ML-RSA)",,,,"cs.CR cs.LG stat.AP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Malware classification is a difficult problem, to which machine learning
methods have been applied for decades. Yet progress has often been slow, in
part due to a number of unique difficulties with the task that occur through
all stages of the developing a machine learning system: data collection,
labeling, feature creation and selection, model selection, and evaluation. In
this survey we will review a number of the current methods and challenges
related to malware classification, including data collection, feature
extraction, and model construction, and evaluation. Our discussion will include
thoughts on the constraints that must be considered for machine learning based
solutions in this domain, and yet to be tackled problems for which machine
learning could also provide a solution. This survey aims to be useful both to
cybersecurity practitioners who wish to learn more about how machine learning
can be applied to the malware problem, and to give data scientists the
necessary background into the challenges in this uniquely complicated space.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 17:46:12 GMT""},{""version"":""v2"",""created"":""Sun, 15 Nov 2020 16:35:36 GMT""}]","2020-11-17"
"2006.09372","Birgit Fuhrmeister","B. Fuhrmeister, S. Czesla, L. Hildebrandt, E. Nagel, J. H. M. M.
  Schmitt, S. V. Jeffers, J. A. Caballero, D. Hintz, E. N. Johnson, P.
  Sch\""ofer, M. Zechmeister, A. Reiners, I. Ribas, P. J. Amado, A. Quirrenbach,
  L. Nortmann, F. F. Bauer, V. J. S. B\'ejar, M. Cort\'es-Contreras, S.
  Dreizler, D. Galad\'i-Enr\'iquez, A. P. Hatzes, A. Kaminski, M K\""urster, M.
  Lafarga, D. Montes","The CARMENES search for exoplanets around M dwarfs. Variability of the
  He I line at 10830 \AA","14 pages, 12 figures, accepted by A&A, full Table 2 only available
  electronically at CDS","A&A 640, A52 (2020)","10.1051/0004-6361/202038279",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The He I infrared (IR) triplet at 10830 \AA is known as an activity indicator
in solar-type stars and has become a primary diagnostic in exoplanetary
transmission spectroscopy. He I lines are a tracer of the stellar
extreme-ultraviolet irradiation from the transition region and corona. We study
the variability of the He I IR triplet lines in a spectral time series of 319
M~dwarf stars that was obtained with the CARMENES high-resolution optical and
near-infrared spectrograph at Calar Alto. We detect He I IR line variability in
18% of our sample stars, all of which show H$\alpha$ in emission. Therefore, we
find detectable He I IR variability in 78% of the sub-sample of stars with
H$\alpha$ emission. Detectable variability is strongly concentrated in the
latest spectral sub-types, where the He I IR lines during quiescence are
typically weak. The fraction of stars with detectable He I IR variation remains
lower than 10% for stars earlier than M3.0 V, while it exceeds 30% for the
later spectral sub-types. Flares are accompanied by particularly pronounced
line variations, including strongly broadened lines with red and blue
asymmetries. However, we also find evidence for enhanced He I IR absorption,
which is potentially associated with increased high-energy irradiation levels
at flare onset. Generally, He I IR and H$\alpha$ line variations tend to be
correlated, with H$\alpha$ being the most sensitive indicator in terms of
pseudo-equivalent width variation. This makes the He I IR triplet a favourable
target for planetary transmission spectroscopy.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 11:10:17 GMT""}]","2020-08-12"
"2006.09813","Peter K\""oves\'arki PhD","Peter K\""ovesarki","Occam's Ghost",,,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article applies the principle of Occam's Razor to non-parametric model
building of statistical data, by finding a model with the minimal number of
bits, leading to an exceptionally effective regularization method for
probability density estimators. The idea comes from the fact that likelihood
maximization also minimizes the number of bits required to encode a dataset.
However, traditional methods overlook that the optimization of model parameters
may also inadvertently play the part in encoding data points. The article shows
how to extend the bit counting to the model parameters as well, providing the
first true measure of complexity for parametric models. Minimizing the total
bit requirement of a model of a dataset favors smaller derivatives, smoother
probability density function estimates and most importantly, a phase space with
fewer relevant parameters. In fact, it is able prune parameters and detect
features with small probability at the same time. It is also shown, how it can
be applied to any smooth, non-parametric probability density estimator.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:25:09 GMT""}]","2020-06-18"
"2006.09832","Karl-Hermann Neeb","Karl-Hermann Neeb and Gestur Olafsson","Nets of standard subspaces on Lie groups","50 pages; error in Thm. 5.3 has been corrected",,,,"math-ph math.MP math.OA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let G be a Lie group with Lie algebra $\mathfrak{g}$, $h \in \frak{g}$ an
element for which the derivation ad(h) defines a 3-grading of $\mathfrak{g}$
and $\tau_G$ an involutive automorphism of G inducing on $\mathfrak{g}$ the
involution $e^{\pi i ad(h)}$. We consider antiunitary representations $U$ of
the Lie group $G_\tau = G \rtimes \{e,\tau_G\}$ for which the positive cone
$C_U = \{ x \in \mathfrak{g} : -i \partial U(x) \geq 0\}$ and $h$ span
$\mathfrak{g}$. To a real subspace E of distribution vectors invariant under
$exp(\mathbb{R} h)$ and an open subset $O \subseteq G$, we associate the real
subspace $H_E(O) \subseteq H$, generated by the subspaces $U(\varphi)E$, where
$\varphi \in C^\infty_c(O,\mathbb{R})$ is a real-valued test function on $O$.
Then $H_E(O)$ is dense in $H_E(G)$ for every non-empty open subset $O \subseteq
G$ (Reeh--Schlider property).
  For the real standard subspace $V \subseteq H$, for which $J_V = U(\tau_G)$
is the modular conjugation and $\Delta_V^{-it/2\pi} = U(\exp th)$ is the
modular group, we obtain sufficient conditions to be of the form $H_E(S)$ for
an open subsemigroup $S \subseteq G$. If $\mathfrak{g}$ is semisimple with
simple hermitian ideals of tube type, we verify these criteria and obtain nets
of cyclic subspacs $H_E(O)$, $O \subseteq G$, satisfying the Bisognano--Wichman
property for some domains O. Our construction also yields such nets on simple
Jordan space-times and compactly causal symmetric spaces of Cayley type. By
second quantization, these nets lead to free quantum fields in the sense of
Haag--Kastler on causal homogeneous spaces whose groups are generated by
modular groups and conjugations.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:59:35 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 15:52:59 GMT""}]","2020-06-24"
"2006.09833","Hao Hao Tan","Hao Hao Tan, Yin-Jyun Luo, Dorien Herremans","Generative Modelling for Controllable Audio Synthesis of Expressive
  Piano Performance",,"Published at ICML Workshop on Machine Learning for Media Discovery
  Workshop (ML4MD) 2020",,,"eess.AS cs.LG cs.MM cs.SD","http://creativecommons.org/licenses/by/4.0/","  We present a controllable neural audio synthesizer based on Gaussian Mixture
Variational Autoencoders (GM-VAE), which can generate realistic piano
performances in the audio domain that closely follows temporal conditions of
two essential style features for piano performances: articulation and dynamics.
We demonstrate how the model is able to apply fine-grained style morphing over
the course of synthesizing the audio. This is based on conditions which are
latent variables that can be sampled from the prior or inferred from other
pieces. One of the envisioned use cases is to inspire creative and brand new
interpretations for existing pieces of piano music.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 12:54:41 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 03:44:38 GMT""}]","2020-07-14"
"2006.09836","Semen Kutateladze S","S.S. Kutateladze","A Class of Second Order Tangent Sets","4 pages",,"10.1134/S0037446620050079",,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Under consideration are the construction and properties of some special class
of second other tangent sets on using the technique of nonstandard analysis.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:18:52 GMT""}]","2020-09-03"
"2006.09837","Meridith Joyce","Meridith Joyce, Shing-Chi Leung, L\'aszl\'o Moln\'ar, Michael J.
  Ireland, Chiaki Kobayashi, Ken'ichi Nomoto","Standing on the shoulders of giants: New mass and distance estimates for
  Betelgeuse through combined evolutionary, asteroseismic, and hydrodynamical
  simulations with MESA","v5: published in the Astrophysical Journal v3/v4: first revision with
  the Astrophysical Journal (v4: abstract corrected). v1/v2: submitted version
  and minor updates. Photometry available at
  https://konkoly.hu/staff/lmolnar/data/alpha_Ori_SMEI_1d-avg_native-plus-Vmag.txt","The Astrophysical Journal, Volume 902, Number 1, 2020","10.3847/1538-4357/abb8db",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We conduct a rigorous examination of the nearby red supergiant Betelgeuse by
drawing on the synthesis of new observational data and three different modeling
techniques. Our observational results include the release of new, processed
photometric measurements collected with the space-based SMEI instrument prior
to Betelgeuse's recent, unprecedented dimming event. We detect the first radial
overtone in the photometric data and report a period of $185\pm13.5$ d. Our
theoretical predictions include self-consistent results from multi-timescale
evolutionary, oscillatory, and hydrodynamic simulations conducted with the
Modules for Experiments in Stellar Astrophysics (MESA) software suite.
Significant outcomes of our modeling efforts include a precise prediction for
the star's radius: $764^{+116}_{-62} R_{\odot}$. In concert with additional
constraints, this allows us to derive a new, independent distance estimate of
$168^ {+27}_{-15}$ pc and a parallax of $\pi=5.95^{+0.58}_{-0.85}$ mas, in good
agreement with Hipparcos but less so with recent radio measurements. Seismic
results from both perturbed hydrostatic and evolving hydrodynamic simulations
constrain the period and driving mechanisms of Betelgeuse's dominant
periodicities in new ways. Our analyses converge to the conclusion that
Betelgeuse's $\approx 400$ day period is the result of pulsation in the
fundamental mode, driven by the $\kappa$-mechanism. Grid-based hydrodynamic
modeling reveals that the behavior of the oscillating envelope is
mass-dependent, and likewise suggests that the non-linear pulsation excitation
time could serve as a mass constraint. Our results place $\alpha$ Ori
definitively in the core helium-burning phase near the base of the red
supergiant branch. We report a present-day mass of $16.5$--$19
~M_{\odot}$---slightly lower than typical literature values.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 08:20:54 GMT""},{""version"":""v2"",""created"":""Fri, 19 Jun 2020 11:07:29 GMT""},{""version"":""v3"",""created"":""Sat, 15 Aug 2020 22:24:20 GMT""},{""version"":""v4"",""created"":""Fri, 4 Sep 2020 08:00:55 GMT""},{""version"":""v5"",""created"":""Tue, 13 Oct 2020 22:02:55 GMT""}]","2020-10-15"
"2006.09838","Xin Xu","Xin Xu","LSTM Networks for Music Generation",,,,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper presents a method of the music generation based on LSTM (Long
Short-Term Memory), contrasts the effects of different network structures on
the music generation and introduces other methods used by some researchers.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 04:44:30 GMT""}]","2020-06-18"
"2006.09852","Yen-Chen Chen","Yen-Chen Chen","Boost the Public Demand for Soft Matter Education and Career
  Opportunities with a Homemade Video",,,,,"physics.ed-ph cond-mat.soft","http://creativecommons.org/publicdomain/zero/1.0/","  The study aims to promote the awareness and education of soft matter which
has become a popular research topic owing to its capability of developing
self-assembling materials for numerous industries such as self-healing
materials. To pursue after this aim, we composed a homemade video to illustrate
the soft matter concepts, followed by distributing a pre/post attitudinal
survey to evaluate the effectiveness of the video on promoting the awareness of
soft matter. The survey showed that the video effectively stimulated the public
interest in soft matter-related knowledge, research, and careers by 27.8
percent on average. Moreover, the participants demanded more investment and
soft matter education, suggesting that WPI provide more resources on developing
soft matter education.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:33:25 GMT""}]","2020-06-18"
"2006.09857","Azam Imomov","Azam A. Imomov, Abror Kh.Meyliev","On asymptotic structure of continuous-time Markov Branching Processes
  allowing Immigration and without high-order moments",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We observe the continuous-time Markov Branching Process without high-order
moments and allowing Immigration. Limit properties of transition functions and
their convergence to invariant measures are investigated. Main mathematical
tool is regularly varying generating functions with remainder.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:02:54 GMT""}]","2020-06-18"
"2006.09996","Micha{\l} Okulewicz","Micha{\l} Okulewicz and Jacek Ma\'ndziuk","Dynamic Vehicle Routing Problem: A Monte Carlo approach",,"Information Technologies: Research and Their Interdisciplinary
  Applications 2015, 119-138, Institute of Computer Science Polish Academy of
  Sciences, ISBN 978-83-63159-23-8",,,"cs.NE cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we solve the Dynamic Vehicle Routing Problem (DVRP). DVRP is a
modification of the Vehicle Routing Problem, in which the clients' requests
(cities) number and location might not be known at the beginning of the working
day Additionally, all requests must be served during one working day by a fleet
of vehicles with limited capacity. In this work we propose a Monte Carlo method
(MCTree), which directly approaches the dynamic nature of arriving requests in
the DVRP. The method is also hybridized (MCTree+PSO) with our previous
Two-Phase Multi-swarm Particle Swarm Optimization (2MPSO) algorithm.
  Our method is based on two assumptions. First, that we know a bounding
rectangle of the area in which the requests might appear. Second, that the
initial requests' sizes and frequency of appearance are representative for the
yet unknown clients' requests. In order to solve the DVRP we divide the working
day into several time slices in which we solve a static problem. In our Monte
Carlo approach we randomly generate the unknown clients' requests with uniform
spatial distribution over the bounding rectangle and requests' sizes uniformly
sampled from the already known requests' sizes. The solution proposal is
constructed with the application of a clustering algorithm and a route
construction algorithm.
  The MCTree method is tested on a well established set of benchmarks proposed
by Kilby et al. and is compared with the results achieved by applying our
previous 2MPSO algorithm and other literature results. The proposed MCTree
approach achieves a better time to quality trade-off then plain heuristic
algorithms. Moreover, a hybrid MCTree+PSO approach achieves better time to
quality trade-off then 2MPSO for small optimization time limits, making the
hybrid a good candidate for handling real world scale goods delivery problems.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:10:00 GMT""}]","2020-06-18"
"2006.10172","Orly Liba","Orly Liba, Longqi Cai, Yun-Ta Tsai, Elad Eban, Yair Movshovitz-Attias,
  Yael Pritch, Huizhong Chen, Jonathan T. Barron","Sky Optimization: Semantically aware image processing of skies in
  low-light photography","Published in Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition Workshops. 2020",,,,"cs.CV cs.GR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The sky is a major component of the appearance of a photograph, and its color
and tone can strongly influence the mood of a picture. In nighttime
photography, the sky can also suffer from noise and color artifacts. For this
reason, there is a strong desire to process the sky in isolation from the rest
of the scene to achieve an optimal look. In this work, we propose an automated
method, which can run as a part of a camera pipeline, for creating accurate sky
alpha-masks and using them to improve the appearance of the sky. Our method
performs end-to-end sky optimization in less than half a second per image on a
mobile device. We introduce a method for creating an accurate sky-mask dataset
that is based on partially annotated images that are inpainted and refined by
our modified weighted guided filter. We use this dataset to train a neural
network for semantic sky segmentation. Due to the compute and power constraints
of mobile devices, sky segmentation is performed at a low image resolution. Our
modified weighted guided filter is used for edge-aware upsampling to resize the
alpha-mask to a higher resolution. With this detailed mask we automatically
apply post-processing steps to the sky in isolation, such as automatic
spatially varying white-balance, brightness adjustments, contrast enhancement,
and noise reduction.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:19:12 GMT""}]","2020-06-19"
"2006.11371","Arun Das","Arun Das and Paul Rad","Opportunities and Challenges in Explainable Artificial Intelligence
  (XAI): A Survey","24 pages, 20 figures, survey paper, submitting to IEEE",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays, deep neural networks are widely used in mission critical systems
such as healthcare, self-driving vehicles, and military which have direct
impact on human lives. However, the black-box nature of deep neural networks
challenges its use in mission critical applications, raising ethical and
judicial concerns inducing lack of trust. Explainable Artificial Intelligence
(XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools,
techniques, and algorithms that can generate high-quality interpretable,
intuitive, human-understandable explanations of AI decisions. In addition to
providing a holistic view of the current XAI landscape in deep learning, this
paper provides mathematical summaries of seminal work. We start by proposing a
taxonomy and categorizing the XAI techniques based on their scope of
explanations, methodology behind the algorithms, and explanation level or usage
which helps build trustworthy, interpretable, and self-explanatory deep
learning models. We then describe the main principles used in XAI research and
present the historical timeline for landmark studies in XAI from 2007 to 2020.
After explaining each category of algorithms and approaches in detail, we then
evaluate the explanation maps generated by eight XAI algorithms on image data,
discuss the limitations of this approach, and provide potential future
directions to improve XAI evaluation.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:58:10 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 01:48:56 GMT""}]","2020-06-24"
"2006.11377","Cristina Olaverri-Monreal","Verena Brandst\""atter, Cristina Olaverri-Monreal","Efficient Transport Logistics, An Approach for Urban Freight Transport
  in Austria","6 pages, 5 figures, 2 Tables, accepted for publication in the
  proceedings of the CISTI'2020 - 15th Iberian Conference on Information
  Systems and Technologies",,"10.23919/CISTI49556.2020.9140843",,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To alleviate traffic congestion that results from the growth of e-commerce we
propose an approach in the city of Linz, Austria by relying on shared
distribution centers from different companies. We develop two algorithms to
find out the optimal location for the hubs and calculate the shortest path
between locations. Results showed that in an urban environment, the
implementation of hubs results in a reduction of the number of delivery
vehicles. It reduces driving distances from hub to the customers, and also
benefits the drivers that need to return home every day.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:50:11 GMT""},{""version"":""v2"",""created"":""Sun, 16 Aug 2020 11:58:44 GMT""}]","2020-08-18"
"2006.11388","Graeme Milton","Graeme W. Milton","A unifying perspective on linear continuum equations prevalent in
  science. Part VI: rapidly converging series expansions for their solution","15 pages, 4 figures",,,,"math-ph math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain rapidly convergent series expansions of resolvents of operators
taking the form ${\bf A}=\Gamma_1{\bf B}\Gamma_1$ where $\Gamma_1({\bf k})$ is
a projection that acts locally in Fourier space and ${\bf B}({\bf x})$ is an
operator that acts locally in real space. Such resolvents arise naturally when
one wants to solve any of the large class of linear physical equations surveyed
in Parts I, II, III, and IV that can be reformulated as problems in the
extended abstract theory of composites. We show how the information about the
spectrum of ${\bf A}$ can be used to greatly improve the convergence rate.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:47:49 GMT""}]","2020-06-23"
"2006.11411","Alexander S. Sakharov","Alexander S. Sakharov and Konstantin Zhukov","Study of Air Curtain in Context of Individual Protection from Exposure
  to Coronavirus (SARS-CoV-2) Contained in Cough-Generated Fluid Particles","17 pages, 4 figures, version accepted for publication in Physics MDPI","Physics 2020, 2(3), 340-351","10.3390/physics2030018",,"physics.med-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ongoing respiratory COVID-19 pandemic has heavily impacted the social and
private lives of the majority of the global population. This infection is
primarily transmitted via virus-laden fluid particles (i.e., droplets and
aerosols) that are formed in the respiratory tract of infected individuals and
expelled from the mouth in the course of breathing, talking, coughing, and
sneezing. To mitigate the risk of virus transmission, in many places of the
world, the public has been asked or even obliged to use face covers. It is
plausible that in the years ahead we will see the use of face masks, face
shields and respirators become a normal practice in our life. However, wearing
face covers is uncomfortable in some situations, like, for example, in summer
heat, while staying on beaches or at hotel swimming pools, doing exercises in
gyms, etc. Also, most types of face cover become contaminated with time and
need to be periodically replaced or disinfected. These nuisances are caused by
the fact that face covers are based on material barriers, which prevent inward
and outward propagation of aerosol and droplets containing the pathogen.
Applying well established gas-particle flow formalism, we study a non-material
based protection barrier created by a flow of well directed down stream of air
across the front of the open face. The~protection is driven by dragging
virus-laden particles inside the width of the air flow and hence, as a
consequence, displacing them away from their primary trajectories. The study,
shows that such, potentially portable, air curtains can effectively provide
both inward and outward protection and serve as an effective personal
protective equipment (PPE) mitigating human to human transmission of virus
infection like COVID-19.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 18:12:37 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 13:03:56 GMT""},{""version"":""v3"",""created"":""Mon, 6 Jul 2020 09:54:09 GMT""}]","2020-07-07"
"2006.12248","Andrew Charman","A.E. Charman, J.S. Wurtele, and G. Penn","Variational Principle for Spontaneous Wiggler and Synchrotron Radiation","technical report",,,,"physics.class-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the framework of a Hilbert space theory, we develop a
maximum-``power'' variational principle (MPVP) applicable to classical
spontaneous electromagnetic radiation from relativistic electron beams or other
prescribed classical current sources. A simple proof is summarized for the case
of three-dimensional fields propagating in vacuum, and specialization to the
important case of paraxial optics is also discussed. The techniques have been
developed to model undulator radiation from relativistic electron beams, but
are more broadly applicable to synchrotron or other radiation problems, and may
generalize to certain structured media. We illustrate applications with a
simple, mostly analytic example involving spontaneous undulator radiation
(requiring a few additional approximations), as well as a mostly numerical
example involving x-ray generation via high harmonic generation in sequenced
undulators
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 02:32:03 GMT""}]","2020-06-23"
"2006.12261","Emel Aslankarayigit Ugurlu","Emel Aslankarayigit Ugurlu","Generalizations of r-ideals of commutative rings",,,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we present the generalization of the concept of $r$-ideals in
commutative rings with nonzero identity. Let $R$ be a commutative ring with
$0\neq1$ and $L(R)$ be the lattice of all ideals of $R$. Suppose that
$\phi:L(R)\rightarrow L(R)\cup\left\{\emptyset\right\}$ is a function. A proper
ideal $I$ of $R$ is called a $\phi-r$-ideal of $R$ if whenever $ab\in I$ and
$Ann(a)=(0)$ imply that $b\in I$ for each $a,b\in R.$ In addition to giving
many properties of $\phi-r$-ideal, we also examine the concept of
$\phi-r$-ideal in trivial ring extension and use them to characterize total
quotient rings.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 16:35:33 GMT""}]","2020-06-23"
"2006.12372","Liya Xu","Liya Xu, Mingzhu Ge, Weili Wu","Edge server deployment scheme of blockchain in IoVs",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the development of intelligent vehicles, security and reliability
communication between vehicles has become a key problem to be solved in
Internet of vehicles(IoVs). Blockchain is considered as a feasible solution due
to its advantages of decentralization, unforgeability and collective
maintenance. However, the computing power of nodes in IoVs is limited, while
the consensus mechanism of blockchain requires that the miners in the system
have strong computing power for mining calculation. It consequently cannot
satisfy the requirements, which is the challenges for the application of
blockchain in IoVs. In fact, the application of blockchain in IoVs can be
implemented by employing edge computing. The key entity of edge computing is
the edge servers(ESs). Roadside nodes(RSUs) can be deployed as ESs of edge
computing in IoVs. We have studied the ES deployment scheme for covering more
vehicle nodes in IoVs, and propose a randomized algorithm to calculate
approximation solutions. Finally, we simulated the performance of the proposed
scheme and compared it with other deployment schemes.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 14:41:24 GMT""}]","2023-04-06"
"2006.12965","Cristina Olaverri-Monreal","Aso Validi, Nicole Polasek, Leonie Alabi, Michael Leitner, Cristina
  Olaverri-Monreal","Environmental Impact of Bundling Transport Deliveries Using SUMO:
  Analysis of a cooperative approach in Austria","5 pages, 7 figures, 2 tables, paper accepted for the proceedings of
  the CISTI'2020 - 15th Iberian Conference on Information Systems and
  Technologies",,"10.23919/CISTI49556.2020.9141129",,"cs.OH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Urban Traffic is recognized as one of the major CO2 contributors that puts a
high burden on the environment. Different attempts have been made for reducing
the impacts ranging from traffic management actions to shared-vehicle concepts
to simply reducing the number of vehicles on the streets. By relying on
cooperative approaches between different logistics companies, such as sharing
and pooling resources for bundling deliveries in the same zone, an increased
environmental benefit can be attained. To quantify this benefit we compare the
CO2 emissions, fuel consumption and total delivery time resulting from
deliveries performed by one cargo truck with two trailers versus by two
single-trailer cargo trucks under real conditions in a simulation scenario in
the city of Linz in Austria. Results showed a fuel consumption and CO2
emissions reduction of 28% and 34% respectively in the scenario in which
resources were bundled in one single truck.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 09:59:08 GMT""},{""version"":""v2"",""created"":""Sun, 16 Aug 2020 11:57:07 GMT""}]","2020-08-18"
"2006.13109","Saurabh Deochake","Saurabh Deochake and Debajyoti Mukhopadhyay","An Agent-based Cloud Service Negotiation in Hybrid Cloud Computing","Fifth International Conference on ICT for Sustainable Development",,,,"cs.MA cs.DC cs.NI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  With the advent of evolution of cloud computing, large organizations have
been scaling the on-premise IT infrastructure to the cloud. Although this being
a popular practice, it lacks comprehensive efforts to study the aspects of
automated negotiation of resources among cloud customers and providers. This
paper proposes a full-fledged framework for the multi-party, multi-issue
negotiation system for cloud resources. It introduces a robust cloud
marketplace system to buy and sell cloud resources. The Belief-Desire-Intention
(BDI) model-based cloud customer and provider agents concurrently negotiate on
multiple issues, pursuing a hybrid tactic of time and resource-based dynamic
deadline algorithms to generate offers and counter-offers. The cloud
marketplace-based system is further augmented with the assignment of behavior
norm score and reputation index to the agents to establish trust among them.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 05:23:38 GMT""}]","2020-06-24"
"2006.13276","Xiaocong Chen","Xiaocong Chen and Lina Yao and Tao Zhou and Jinming Dong and Yu Zhang","Momentum Contrastive Learning for Few-Shot COVID-19 Diagnosis from Chest
  CT Images",,,"10.1016/j.patcog.2021.107826",,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The current pandemic, caused by the outbreak of a novel coronavirus
(COVID-19) in December 2019, has led to a global emergency that has
significantly impacted economies, healthcare systems and personal wellbeing all
around the world. Controlling the rapidly evolving disease requires highly
sensitive and specific diagnostics. While real-time RT-PCR is the most commonly
used, these can take up to 8 hours, and require significant effort from
healthcare professionals. As such, there is a critical need for a quick and
automatic diagnostic system. Diagnosis from chest CT images is a promising
direction. However, current studies are limited by the lack of sufficient
training samples, as acquiring annotated CT images is time-consuming. To this
end, we propose a new deep learning algorithm for the automated diagnosis of
COVID-19, which only requires a few samples for training. Specifically, we use
contrastive learning to train an encoder which can capture expressive feature
representations on large and publicly available lung datasets and adopt the
prototypical network for classification. We validate the efficacy of the
proposed model in comparison with other competing methods on two publicly
available and annotated COVID-19 CT datasets. Our results demonstrate the
superior performance of our model for the accurate diagnosis of COVID-19 based
on chest CT images.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:14:58 GMT""}]","2021-01-19"
"2006.13685","Alessandra Aloisi","Alessandra Aloisi and Neill Reid","(Un)conscious Bias in the Astronomical Profession: Universal
  Recommendations to improve Fairness, Inclusiveness, and Representation","7 pages, 3 figures, White Paper for Planetary Science and
  Astrobiology Decadal Survey 2022. arXiv admin note: substantial text overlap
  with arXiv:1907.05261",,"10.3847/25c2cfeb.299343eb",,"astro-ph.IM astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  (Un)conscious bias affects every aspect of the astronomical profession, from
scientific activities (e.g., invitations to join collaborations, proposal
selections, grant allocations, publication review processes, and invitations to
attend and speak at conferences) to activities more strictly related to career
advancement (e.g., reference letters, fellowships, hiring, promotion, and
tenure). For many, (un)conscious bias is still the main hurdle to achieving
excellence, as the most diverse talents encounter bigger challenges and
difficulties to reach the same milestones than their more privileged
colleagues. Over the past few years, the Space Telescope Science Institute
(STScI) has constructed tools to raise awareness of (un)conscious bias and has
designed guidelines and goals to increase diversity representation and outcome
in its scientific activities, including career-related matters and STScI
sponsored fellowships, conferences, workshops, and colloquia. STScI has also
addressed (un)conscious bias in the peer-review process by anonymizing
submission and evaluation of Hubble Space Telescope (and soon to be James Webb
Space Telescope) observing proposals. In this white paper we present a plan to
standardize these methods with the expectation that these universal
recommendations will truly increase diversity, inclusiveness and fairness in
Astronomy if applied consistently throughout all the scientific activities of
the Astronomical community.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 21:54:23 GMT""}]","2022-07-13"
"2006.13816","Bernal Jimenez Gutierrez","Bernal Jim\'enez Guti\'errez, Juncheng Zeng, Dongdong Zhang, Ping
  Zhang, Yu Su","Document Classification for COVID-19 Literature","8 pages, 9 figures",,,,"cs.IR cs.CL","http://creativecommons.org/licenses/by/4.0/","  The global pandemic has made it more important than ever to quickly and
accurately retrieve relevant scientific literature for effective consumption by
researchers in a wide range of fields. We provide an analysis of several
multi-label document classification models on the LitCovid dataset, a growing
collection of 23,000 research papers regarding the novel 2019 coronavirus. We
find that pre-trained language models fine-tuned on this dataset outperform all
other baselines and that BioBERT surpasses the others by a small margin with
micro-F1 and accuracy scores of around 86% and 75% respectively on the test
set. We evaluate the data efficiency and generalizability of these models as
essential features of any system prepared to deal with an urgent situation like
the current health crisis. Finally, we explore 50 errors made by the best
performing models on LitCovid documents and find that they often (1) correlate
certain labels too closely together and (2) fail to focus on discriminative
sections of the articles; both of which are important issues to address in
future work. Both data and code are available on GitHub.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 20:03:28 GMT""},{""version"":""v2"",""created"":""Wed, 9 Sep 2020 21:58:17 GMT""}]","2020-09-11"
"2006.14001","J\""urgen Maier","J\""urgen Maier and Andreas Steininger","Efficient Metastability Characterization for Schmitt-Triggers","10 pages, 15 figures","2019 25th IEEE International Symposium on Asynchronous Circuits
  and Systems (ASYNC)","10.1109/ASYNC.2019.00024",,"cs.OH eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite their attractiveness as metastability filters, Schmitt-Triggers can
suffer from metastability themselves. Therefore, in the selection or
construction of a suitable Schmitt-Trigger implementation, it is a necessity to
accurately determine the metastable behavior. Only then one is able to compare
different designs and thus guide proper optimizations, and only then one can
assess the potential for residual metastable upsets. However, while the state
of the art provides a lot of research and practical characterization approaches
for flip-flops, comparatively little is known about Schmitt-Trigger
characterization. Unlike the flip-flop with its single metastable point, the
Schmitt-Trigger exhibits a whole range of metastable points depending on the
input voltage. Thus the task of characterization gets much more challenging.
  In this paper we present different approaches to determine the metastable
behavior of Schmitt-Triggers using novel methods and mechanisms. We compare
their accuracy and runtime by applying them to three common circuit
implementations. The achieved results are then used to reason about the
metastable behavior of the chosen designs which turns out to be problematic in
some cases. Overall the approaches proposed in this paper are generic and can
be extended beyond the Schmitt-Trigger, i.e., to efficiently characterize
metastable states in other circuits as well.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 06:28:54 GMT""}]","2020-06-26"
"2006.14540","Mirfarid Musavian","Mirfarid Musavian Ghazani and Anh Huy Phan","Graph Convolutional Neural Networks for analysis of EEG signals, BCI
  application","11 pages, 5 figures",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Decoding brain signals has gained many attention and has found much
applications in recent years such as Brain Computer Interfaces, communicating
with controlling external devices using the user's intentions, occupies an
emerging field with the potential of changing the world, with diverse
applications from rehabilitation to human augmentation. This being said brain
signal analysis, EEG brain signal analysis in particular, is a challenging
task. With the advances and achievements in the field of deep learning in
problem solving with using only raw data, few attempts has been carried in
recent years, to apply deep learning to tackle EEG among other types of brain
signals. In this study, we propose a novel loss function, called DeepCSP to
extend the classical Common Spatial Patterns to a non linear, differentiable
module to serve as the loss function to enforce linearly separable latent
representations of EEG signals belonging to different classes in an end to end
manner on raw signals without the need to perform extensive feature
engineering. With recent generalizations of deep learning methods to work on
arbitrarily structured graphs and the introduced loss we have proposed two
light weight models to decode EEG signals and carried experiments to show their
performance.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 10:56:43 GMT""}]","2020-06-26"
"2006.15972","Emilio Mart\'inez-Pa\~neda","M.A. Saeimi Sadigh, B. Paygozar, L.F.M. da Silva, E.
  Mart\'inez-Pa\~neda","Creep Behaviour and Tensile Response of Adhesively Bonded Polyethylene
  Joints: Single-Lap and Double-Strap",,"International Journal of Adhesion and Adhesives 102, 102666 (2020)","10.1016/j.ijadhadh.2020.102666",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The static and time-dependent behaviours of adhesively bonded polyethylene
Double-Strap (DS) joints were investigated to assess the viability of this
joint configuration relative to the Single-Lap (SL) joints. Both experiments
and finite element simulations are conducted. First, we individually
characterise the tensile and creep behaviour of the adhesive and adherent
materials; an epoxy-based adhesive and polyethylene, respectively. This
information is used to develop suitable constitutive models that are then
implemented in the commercial finite element package ABAQUS by means of user
material subroutines, UMATs. The numerical models are used to design the creep
tests on the adhesive joints. Afterwards, an extensive experimental campaign is
conducted where we characterise the static and creep behaviour of two joint
configurations, SL and DS joints, and three selected values of the overlap
length. In regard to the static case, results reveal an increase in the failure
load with increasing overlap length, of up to 10% for an overlap length of 39
mm. Also, slightly better performance is observed for the SL joint
configuration. For the creep experiments, we show that the DS adhesive joint
configuration leads to much shorter elongations, relative to the SL joints.
These differences diminish with increasing overlap length but remain
substantial in all cases. In both joint configurations, the elongation
increases with decreasing overlap length. For instance, increasing the overlap
length to 39 mm led to a 50% and a 30% reduction in elongation for SL and DS
joints, respectively. Moreover, the numerical predictions show a good agreement
with the experiments. The stress redistribution is investigated and it is found
that the shear stress is highly sensitive to the testing time, with differences
being more noticeable for the DS joint system.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 15:22:49 GMT""}]","2020-06-30"
"2007.04249","Subramaniam Kazhuparambil Mr.","Subramaniam Kazhuparambil (1) and Abhishek Kaushik (1 and 2) ((1)
  Dublin Business School, (2) Dublin City University)","Cooking Is All About People: Comment Classification On Cookery Channels
  Using BERT and Classification Models (Malayalam-English Mix-Code)","Rectified typos",,,,"cs.CL cs.IR cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  The scope of a lucrative career promoted by Google through its video
distribution platform YouTube has attracted a large number of users to become
content creators. An important aspect of this line of work is the feedback
received in the form of comments which show how well the content is being
received by the audience. However, volume of comments coupled with spam and
limited tools for comment classification makes it virtually impossible for a
creator to go through each and every comment and gather constructive feedback.
Automatic classification of comments is a challenge even for established
classification models, since comments are often of variable lengths riddled
with slang, symbols and abbreviations. This is a greater challenge where
comments are multilingual as the messages are often rife with the respective
vernacular. In this work, we have evaluated top-performing classification
models for classifying comments which are a mix of different combinations of
English and Malayalam (only English, only Malayalam and Mix of English and
Malayalam). The statistical analysis of results indicates that Multinomial
Naive Bayes, K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Random
Forest and Decision Trees offer similar level of accuracy in comment
classification. Further, we have also evaluated 3 multilingual transformer
based language models (BERT, DISTILBERT and XLM) and compared their performance
to the traditional machine learning classification techniques. XLM was the
top-performing BERT model with an accuracy of 67.31. Random Forest with Term
Frequency Vectorizer was the best performing model out of all the traditional
classification models with an accuracy of 63.59.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 19:07:06 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jul 2020 12:57:24 GMT""},{""version"":""v3"",""created"":""Wed, 22 Jul 2020 08:40:09 GMT""}]","2020-07-23"
"2007.12270","Pinaki Patra","Pinaki Patra and Kalpana Biswas","Entropy uncertainty principle for Dirac system with mass jump",,,,,"quant-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dependency on the preparation of state for the Heisenberg uncertainty
principle can be removed with the help of entropy uncertainty principle. The
shortness of the uncertainty principle (UP) can be overcome with the help of
the concept of Shannon's information entropy (SE). In this article, we have
shown that UP in terms of SE holds for a position-dependent effective mass
system. We have considered the Dirac system with a mass-jump at the origin. We
have proved the existence of a lower bound for a UP for this position-dependent
effective mass.
","[{""version"":""v1"",""created"":""Tue, 16 Jun 2020 13:02:00 GMT""}]","2020-07-27"
"2008.01718","Liangyun Chen","Liming Tang, Lingyi Meng, Liangyun Chen","Super-Biderivations and Linear Super-Commuting Maps on the Lie
  Superalgebras","10 pages, Communications in Algebra (2020)",,"10.1080/00927872.2020.1778715",,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Suppose the ground field is algebraically closed and of characteristic
different from 2. In this paper, we described the intrinsic connections among
linear super-commuting maps, super-biderivations and centroids for Lie
superalgebras satisfying certain assumptions. This is a generalization of the
results of Bre$\check{s}$ar and Zhao on Lie algebras.
","[{""version"":""v1"",""created"":""Mon, 15 Jun 2020 23:32:48 GMT""}]","2020-08-05"
