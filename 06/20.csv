"2006.11200","Victor Yakhot","Victor Yakhot","Transitions and Multi-Scaling in Rayliegh-Benard Convection. Small-Scale
  Universality",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Asymptotically large Reynolds number hydrodynamic turbulence is characterized
by multi-scaling of moments of velocity increments and spatial derivatives.
With decreasing Reynolds number toward $R_{\lambda}=R^{tr}_{\lambda}\approx
9.0$, the anomalous scaling disappears in favor of the ""normal"" one and
close-to-Gaussian probability densities [Yakhot \& Donzis, {\bf 119}, 044501
(2017)]. The nature of this transition and its universality are subjects of
this work.
  Here we consider Benard convection ( Prandtl number $Pr=1$) between infinite
horizontal plates. It is shown that in this system the ""competition"" between
Bolgiano and Kolmogorov processes, results in small-scale velocity fluctuations
driven by effective ""large-scale"" Gaussian random temperature field. Therefore,
the intermittent dynamics of velocity derivatives are similar or even identical
to that in homogeneous and isotropic turbulence generated by the large-scale
random forcing. It is shown that low-Rayleigh number instabilities make the
problem much more involved and may lead to transition from Gaussian to
exponential PDF of the temperature field. The developed {\it mean-field theory}
yielded dimensionless heat flux $Nu\propto Ra^{\beta}$ with $\beta\approx
15/56\approx 0.27$, close to the outcome of Chicago experiment. These results
point to an unusual small-scale universality of turbulent flows. It is also
shown that at $R_{\lambda}\leq 9.0$, a flow ""remembers"" its laminar background
and, therefore, cannot be universal.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:03:04 GMT""}]","2020-06-22"
"2006.11201","Le-Yu Chen","Le-Yu Chen, Sokbae Lee","Sparse Quantile Regression","51 pages, 3 figures, 3 tables",,,,"stat.ME econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider both $\ell _{0}$-penalized and $\ell _{0}$-constrained quantile
regression estimators. For the $\ell _{0}$-penalized estimator, we derive an
exponential inequality on the tail probability of excess quantile prediction
risk and apply it to obtain non-asymptotic upper bounds on the mean-square
parameter and regression function estimation errors. We also derive analogous
results for the $\ell _{0}$-constrained estimator. The resulting rates of
convergence are nearly minimax-optimal and the same as those for $\ell
_{1}$-penalized and non-convex penalized estimators. Further, we characterize
expected Hamming loss for the $\ell _{0}$-penalized estimator. We implement the
proposed procedure via mixed integer linear programming and also a more
scalable first-order approximation algorithm. We illustrate the finite-sample
performance of our approach in Monte Carlo experiments and its usefulness in a
real data application concerning conformal prediction of infant birth weights
(with $n\approx 10^{3}$ and up to $p>10^{3}$). In sum, our $\ell _{0}$-based
method produces a much sparser estimator than the $\ell _{1}$-penalized and
non-convex penalized approaches without compromising precision.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:04:17 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 11:18:30 GMT""},{""version"":""v3"",""created"":""Thu, 16 Jun 2022 16:33:20 GMT""},{""version"":""v4"",""created"":""Wed, 29 Mar 2023 05:12:21 GMT""}]","2023-03-30"
"2006.11202","Marcus Scheele","Andre Maier, Ronny Loeffler, Marcus Scheele","Fabrication of nanocrystal superlattice microchannels by
  soft-lithography for electronic measurements of single crystalline domains","22 pages, 12 Figures",,"10.1088/1361-6528/ab9c52",,"physics.app-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a high-throughput and easy-to-implement approach to fabricate
microchannels of nanocrystal superlattices with dimensions of ~4 micrometer^2,
thus approaching the size of typical single-crystalline domains. By means of
microcontact printing, highly ordered superlattices with microscale dimensions
are transferred onto photolithographically prepatterned microelectrodes,
obtaining well-defined superlattice microchannels. We present step-by-step
guidelines for microfabrication, nanocrystal self-assembly and patterning to
archive large quantities of up to 330 microchannels per device for
statistically meaningful investigations of charge transport in
single-crystalline superlattice domains. As proof-of-concept, we perform
conductivity and field-effect transistor measurements on microchannels of PbS
nanocrystal superlattices. We find that the electric transport within
microchannel superlattices is orders of magnitude more efficient than within
conventional large-scale channels, highlighting the advantage of the near
single-crystalline microchannels presented in this paper.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:11:44 GMT""}]","2020-06-22"
"2006.11203","Morten Christensen","Morten H. Christensen, Xiaoyu Wang, Yoni Schattner, Erez Berg, and
  Rafael M. Fernandes","Modeling unconventional superconductivity at the crossover between
  strong and weak electronic interactions","6 pages + 9 page supplementary. Published version","Phys. Rev. Lett. 125, 247001 (2020)","10.1103/PhysRevLett.125.247001",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-temperature superconductivity emerges in a host of different quantum
materials, often in a region of the phase diagram where the electronic kinetic
energy is comparable in magnitude with the electron-electron Coulomb repulsion.
Describing such an intermediate-coupling regime has proven challenging, as
standard perturbative approaches are inapplicable. Hence, it is of enormous
interest to find models that are amenable to be solved using exact methods.
While important advances have been made in elucidating the properties of one
such minimal model -- the Hubbard model -- via numerical simulations, the
infamous fermionic sign-problem significantly limits the accessible parameter
space. Here, we employ Quantum Monte Carlo (QMC) methods to solve a multi-band
version of the Hubbard model that does not suffer from the sign-problem and in
which only repulsive interband interactions are present. In contrast to
previous sign-problem-free QMC studies, this model does not have pre-existing
fine-tuned magnetic order, and thus treats superconducting, magnetic, and
charge degrees of freedom on an equal footing. We find that, as the
electron-electron repulsion increases, a dome of antiferromagnetic order
emerges in the intermediate-coupling regime, accompanied by a
metal-to-insulator crossover line. Superconductivity is found only near the
antiferromagnetic quantum phase transition located on the metallic side of the
magnetic dome. Across the antiferromagnetic quantum phase transition we find a
change in the dynamical character of the magnetic fluctuations, from slow and
overdamped in the metallic side to fast and propagating in the insulating side.
Our findings shed new light on the intertwining between superconductivity,
magnetism, and charge correlations in quantum materials.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:11:47 GMT""},{""version"":""v2"",""created"":""Fri, 11 Dec 2020 09:59:14 GMT""}]","2020-12-14"
"2006.11204","Tsubasa Takahashi","Tsubasa Takahashi, Shun Takagi, Hajime Ono, Tatsuya Komatsu","Differentially Private Variational Autoencoders with Term-wise Gradient
  Aggregation","10 pages",,,,"cs.LG cs.CR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies how to learn variational autoencoders with a variety of
divergences under differential privacy constraints. We often build a VAE with
an appropriate prior distribution to describe the desired properties of the
learned representations and introduce a divergence as a regularization term to
close the representations to the prior. Using differentially private SGD
(DP-SGD), which randomizes a stochastic gradient by injecting a dedicated noise
designed according to the gradient's sensitivity, we can easily build a
differentially private model. However, we reveal that attaching several
divergences increase the sensitivity from O(1) to O(B) in terms of batch size
B. That results in injecting a vast amount of noise that makes it hard to
learn. To solve the above issue, we propose term-wise DP-SGD that crafts
randomized gradients in two different ways tailored to the compositions of the
loss terms. The term-wise DP-SGD keeps the sensitivity at O(1) even when
attaching the divergence. We can therefore reduce the amount of noise. In our
experiments, we demonstrate that our method works well with two pairs of the
prior distribution and the divergence.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:12:28 GMT""}]","2020-06-22"
"2006.11205","Souma Mazumdar Mr","Souma Mazumdar","Path Planning in a Riemannian Manifold using Optimal Control","18 pages no figures",,"10.1142/S0219887820501819",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the motion planning of an object in a Riemannian manifold where
the object is steered from an initial point to a final point utilizing optimal
control. Considering Pontryagin Minimization Principle we compute the Optimal
Controls needed for steering the object from initial to final point. The
Optimal Controls were solved with respect to time t and shown to have norm 1
which should be the case when the extremal trajectories, which are the
solutions of Pontryagin Principle, are arc length parametrized. The extremal
trajectories are supposed to be the geodesics on the Riemannian manifold. So we
compute the geodesic curvature and the Gaussian curvature of the Riemannian
structure.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:12:40 GMT""}]","2020-12-02"
"2006.11206","Yuval Wigderson","Avi Wigderson and Yuval Wigderson","The uncertainty principle: variations on a theme","43 pages",,,,"math.FA cs.IT math-ph math.CO math.GR math.IT math.MP","http://creativecommons.org/licenses/by/4.0/","  We show how a number of well-known uncertainty principles for the Fourier
transform, such as the Heisenberg uncertainty principle, the Donoho--Stark
uncertainty principle, and Meshulam's non-abelian uncertainty principle, have
little to do with the structure of the Fourier transform itself. Rather, all of
these results follow from very weak properties of the Fourier transform (shared
by numerous linear operators), namely that it is bounded as an operator $L^1
\to L^\infty$, and that it is unitary. Using a single, simple proof template,
and only these (or weaker) properties, we obtain some new proofs and many
generalizations of these basic uncertainty principles, to new operators and to
new settings, in a completely unified way. Together with our general overview,
this paper can also serve as a survey of the many facets of the phenomena known
as uncertainty principles.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:19:15 GMT""},{""version"":""v2"",""created"":""Fri, 21 Aug 2020 16:48:19 GMT""},{""version"":""v3"",""created"":""Fri, 11 Sep 2020 15:18:20 GMT""}]","2020-09-14"
"2006.11207","Nathan Somavarapu","Nathan Somavarapu and Chih-Yao Ma and Zsolt Kira","Frustratingly Simple Domain Generalization via Image Stylization","Code: https://github.com/GT-RIPL/DomainGeneralization-Stylization",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Convolutional Neural Networks (CNNs) show impressive performance in the
standard classification setting where training and testing data are drawn
i.i.d. from a given domain. However, CNNs do not readily generalize to new
domains with different statistics, a setting that is simple for humans. In this
work, we address the Domain Generalization problem, where the classifier must
generalize to an unknown target domain. Inspired by recent works that have
shown a difference in biases between CNNs and humans, we demonstrate an
extremely simple yet effective method, namely correcting this bias by
augmenting the dataset with stylized images. In contrast with existing
stylization works, which use external data sources such as art, we further
introduce a method that is entirely in-domain using no such extra sources of
data. We provide a detailed analysis as to the mechanism by which the method
works, verifying our claim that it changes the shape/texture bias, and
demonstrate results surpassing or comparable to the state of the arts that
utilize much more complex methods.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:20:40 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jul 2020 15:13:11 GMT""}]","2020-07-13"
"2006.11208","Kristina D. Launey","A. C. Dreyfuss, K. D. Launey, J. E. Escher, G. H. Sargsyan, R. B.
  Baker, T. Dytrych, J. P. Draayer","Alpha clustering and alpha-capture reaction rate from ab initio
  symmetry-adapted description of $^{20}$Ne","16 pages, 7 figures","Phys. Rev. C 102, 044608 (2020)","10.1103/PhysRevC.102.044608",,"nucl-th astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new framework for studying clustering and for calculating
alpha partial widths using ab initio wave functions. We demonstrate the
formalism for $^{20}$Ne, by calculating the overlap between the
$^{16}$O$+\alpha$ cluster configuration and states in $^{20}$Ne computed in the
ab initio symmetry-adapted no-core shell model. We present spectroscopic
amplitudes and spectroscopic factors, and compare those to no-core symplectic
shell-model results in larger model spaces, to gain insight into the underlying
physics that drives alpha-clustering. Specifically, we report on the alpha
partial width of the lowest $1^-$ resonance in $^{20}$Ne, which is found to be
in good agreement with experiment. We also present first no-core shell-model
estimates for asymptotic normalization coefficients for the ground state, as
well as for the first excited $4^{+}$ state in $^{20}$Ne that lies in a close
proximity to the $^{16}$O$+\alpha$ threshold. This outcome highlights the
importance of correlations for developing cluster structures and for describing
alpha widths. The widths can then be used to calculate alpha-capture reaction
rates for narrow resonances of interest to astrophysics. We explore the
reaction rate for the alpha-capture reaction $^{16}$O$(\alpha,\gamma)^{20}$Ne
at astrophysically relevant temperatures and determine its impact on simulated
X-ray burst abundances.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:24:22 GMT""}]","2020-10-14"
"2006.11209","Franco Pellegrini","Franco Pellegrini and Giulio Biroli","An analytic theory of shallow networks dynamics for hinge loss
  classification","16 pages, 6 figures",,"10.1088/1742-5468/ac3a76",,"stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural networks have been shown to perform incredibly well in classification
tasks over structured high-dimensional datasets. However, the learning dynamics
of such networks is still poorly understood. In this paper we study in detail
the training dynamics of a simple type of neural network: a single hidden layer
trained to perform a classification task. We show that in a suitable mean-field
limit this case maps to a single-node learning problem with a time-dependent
dataset determined self-consistently from the average nodes population. We
specialize our theory to the prototypical case of a linearly separable dataset
and a linear hinge loss, for which the dynamics can be explicitly solved. This
allow us to address in a simple setting several phenomena appearing in modern
networks such as slowing down of training dynamics, crossover between rich and
lazy learning, and overfitting. Finally, we asses the limitations of mean-field
theory by studying the case of large but finite number of nodes and of training
samples.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:25:29 GMT""}]","2022-01-12"
"2006.11210","B.R. Littlejohn","M. Andriamirado, A. B. Balantekin, H. R. Band, C. D. Bass, D. E.
  Bergeron, D. Berish, N. S. Bowden, J. P. Brodsky, C. D. Bryan, T. Classen, A.
  J. Conant, G. Deichert, M. V. Diwan, M. J. Dolinski, A. Erickson, B. T.
  Foust, J. K. Gaison, A. Galindo-Uribarri, C. E. Gilbert, B. W. Goddard, B. T.
  Hackett, S. Hans, A. B. Hansell, K. M. Heeger, B. Heffron, D. E. Jaffe, X.
  Ji, D. C. Jones, O. Kyzylova, C. E. Lane, T. J. Langford, J. LaRosa, B. R.
  Littlejohn, X. Lu, J. Maricic, M. P. Mendenhall, A. M. Meyer, R. Milincic, I.
  Mitchell, P. E. Mueller, H. P. Mumm, J. Napolitano, C. Nave, R. Neilson, J.
  A. Nikkel, D. Norcini, S. Nour, J. L. Palomino, D. A. Pushin, X. Qian, E.
  Romero-Romero, R. Rosero, P. T. Surukuchi, M. A. Tyra, R. L. Varner, D.
  Venegas-Vargas, P. B. Weatherly, C. White, J. Wilhelmi, A. Woolverton, M.
  Yeh, A. Zhang, C. Zhang, and X. Zhang","Improved Short-Baseline Neutrino Oscillation Search and Energy Spectrum
  Measurement with the PROSPECT Experiment at HFIR","42 pages, 52 Figures. Submitted to Phys. Rev. D. Supplementary
  Material Included","Phys. Rev. D 103, 032001 (2021)","10.1103/PhysRevD.103.032001",,"hep-ex nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a detailed report on sterile neutrino oscillation and U-235
antineutrino energy spectrum measurement results from the PROSPECT experiment
at the highly enriched High Flux Isotope Reactor (HFIR) at Oak Ridge National
Laboratory. In 96 calendar days of data taken at an average baseline distance
of 7.9 m from the center of the 85 MW HFIR core, the PROSPECT detector has
observed more than 50,000 interactions of antineutrinos produced in beta decays
of U-235 fission products. New limits on the oscillation of antineutrinos to
light sterile neutrinos have been set by comparing the detected energy spectra
of ten reactor-detector baselines between 6.7 and 9.2 meters. Measured
differences in energy spectra between baselines show no statistically
significant indication of antineutrinos to sterile neutrino oscillation and
disfavor the Reactor Antineutrino Anomaly best-fit point at the 2.5$\sigma$
confidence level. The reported U-235 antineutrino energy spectrum measurement
shows excellent agreement with energy spectrum models generated via conversion
of the measured U-235 beta spectrum, with a $\chi^2$/DOF of 31/31. PROSPECT is
able to disfavor at 2.4$\sigma$ confidence level the hypothesis that U-235
antineutrinos are solely responsible for spectrum discrepancies between model
and data obtained at commercial reactor cores. A data-model deviation in
PROSPECT similar to that observed by commercial core experiments is preferred
with respect to no observed deviation, at a 2.2$\sigma$ confidence level.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:26:13 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 20:42:10 GMT""}]","2021-02-10"
"2006.11211","Miklos Z. Racz","Miklos Z. Racz, Jacob Richey","Rumor source detection with multiple observations under adaptive
  diffusions","30 pages, 3 figures",,,,"cs.SI cs.CR math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work, motivated by anonymous messaging platforms, has introduced
adaptive diffusion protocols which can obfuscate the source of a rumor: a
""snapshot adversary"" with access to the subgraph of ""infected"" nodes can do no
better than randomly guessing the entity of the source node. What happens if
the adversary has access to multiple independent snapshots? We study this
question when the underlying graph is the infinite $d$-regular tree. We show
that (1) a weak form of source obfuscation is still possible in the case of two
independent snapshots, but (2) already with three observations there is a
simple algorithm that finds the rumor source with constant probability,
regardless of the adaptive diffusion protocol. We also characterize the
tradeoff between local spreading and source obfuscation for adaptive diffusion
protocols (under a single snapshot). These results raise questions about the
robustness of anonymity guarantees when spreading information in social
networks.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:27:26 GMT""}]","2020-06-22"
"2006.11212","Wei Zhang","Wei Zhang","Some new results on relative entropy production, time reversal, and
  optimal control of time-inhomogeneous diffusion processes","accepted manuscript","J. Math. Phys. 62(4), 043302, 2021","10.1063/5.0038740",,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies time-inhomogeneous nonequilibrium diffusion processes,
including both Brownian dynamics and Langevin dynamics. We derive upper bounds
of the relative entropy production of the time-inhomogeneous process with
respect to the transient invariant probability measures. We also study the time
reversal of the reverse process in Crooks' fluctuation theorem. We show that
the time reversal of the reverse process coincides with the optimally
controlled forward process that leads to zero variance importance sampling
estimator based on Jarzynski's equality.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:27:47 GMT""},{""version"":""v2"",""created"":""Fri, 16 Apr 2021 20:03:27 GMT""}]","2021-04-20"
"2006.11213","Feng Zhang","Feng Zhang, Niladri Gomes, Noah F. Berthusen, Peter P. Orth,
  Cai-Zhuang Wang, Kai-Ming Ho, Yong-Xin Yao","Shallow-circuit variational quantum eigensolver based on
  symmetry-inspired Hilbert space partitioning for quantum chemical
  calculations",,"Phys. Rev. Research 3, 013039 (2021)","10.1103/PhysRevResearch.3.013039",,"quant-ph cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Development of resource-friendly quantum algorithms remains highly desirable
for noisy intermediate-scale quantum computing. Based on the variational
quantum eigensolver (VQE) with unitary coupled cluster ansatz, we demonstrate
that partitioning of the Hilbert space made possible by the point group
symmetry of the molecular systems greatly reduces the number of variational
operators by confining the variational search within a subspace. In addition,
we found that instead of including all subterms for each excitation operator, a
single-term representation suffices to reach required accuracy for various
molecules tested, resulting in an additional shortening of the quantum circuit.
With these strategies, VQE calculations on a noiseless quantum simulator
achieve energies within a few meVs of those obtained with the full UCCSD ansatz
for $\mathrm{H}_4$ square, $\mathrm{H}_4$ chain and $\mathrm{H}_6$ hexagon
molecules; while the number of controlled-NOT (CNOT) gates, a measure of the
quantum-circuit depth, is reduced by a factor of as large as 35. Furthermore,
we introduced an efficient ""score"" parameter to rank the excitation operators,
so that the operators causing larger energy reduction can be applied first.
Using $\mathrm{H}_4$ square and $\mathrm{H}_4$ chain as examples, We
demonstrated on noisy quantum simulators that the first few variational
operators can bring the energy within the chemical accuracy, while additional
operators do not improve the energy since the accumulative noise outweighs the
gain from the expansion of the variational ansatz.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:28:26 GMT""}]","2021-01-20"
"2006.11214","Paolo Sibani","Paolo Sibani and Jacob M{\o}ller Kirketerp","Spin-glass thermo-remanent magnetization revisited: a numerical and
  analytical study","7 pages, 5 figures","Phys. Rev. E 102, 042131 (2020)","10.1103/PhysRevE.102.042131",,"cond-mat.stat-mech cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermoremanent magnetization data for the 3D Edwards-Anderson spin glass are
generated using the Waiting Time Method as simulational tool and interpreted
using Record Dynamics. We verify that clusters of contiguous spins are
overturned by quakes, non-equilibrium events linked to record sized energy
fluctuations and show that quaking is a log-Poisson process, i.e. a Poisson
process whose average depends on the logarithm of the system age, counted from
the initial quench. Our results compare favorably with experimental
thermoremanent magnetization findings and with the spontaneous fluctuation
dynamics of the E-A model.
  The logarithm growth of the size of overturned clusters is related to similar
experimental results and to the growing length scale of the spin-spin spatial
correlation function. The analysis buttresses the applicability of the Waiting
Time Method as a simulational tool and of Record Dynamics as coarse-graining
method for aging dynamics.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:33:33 GMT""},{""version"":""v2"",""created"":""Tue, 27 Oct 2020 09:47:08 GMT""}]","2021-07-23"
"2006.11215","Giacomo Venturi","Giacomo Venturi (1 and 2) and Alessandro Marconi (3 and 2) ((1)
  Instituto de Astrof\'isica, Pontificia Universidad Cat\'olica de Chile,
  Santiago, Chile, (2) INAF - Osservatorio Astrofisico di Arcetri, Firenze,
  Italy, (3) Dipartimento di Fisica e Astronomia, Universit\`a degli Studi di
  Firenze, Sesto Fiorentino (FI), Italy)","The physical properties and impact of AGN outflows from high to low
  redshift","8 pages, 2 figures, to be published in Proceeding IAU Symposium No.
  359, 2020, ""Galaxy evolution and feedback across different environments"",
  Eds. T. Storchi-Bergmann, R. Overzier, W. Forman and R. Riffel",,"10.1017/S1743921320002203",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feedback from active galactic nuclei (AGN) on their host galaxies, in the
form of gas outflows capable of quenching star formation, is considered a major
player in galaxy evolution. However, clear observational evidence of such major
impact is still missing; uncertainties in measuring outflow properties might be
partly responsible because of their critical role in comparisons with models
and in constraining the impact of outflows on galaxies. Here we briefly review
the challenges in measuring outflow physical properties and present an overview
of outflow studies from high to low redshift. Finally, we present highlights
from our MAGNUM survey of nearby AGN with VLT/MUSE, where the high intrinsic
spatial resolution (down to $\sim$10 pc) allows us to accurately measure the
physical and kinematic properties of ionised gas outflows.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:33:56 GMT""}]","2021-04-07"
"2006.11216","Luc\'ia Duarte","Luc\'ia Duarte, Gabriel Zapata, O.A. Sampayo","Angular and polarization observables for Majorana-mediated B decays with
  effective interactions","7 figures, 3 tables",,"10.1140/epjc/s10052-020-08471-0",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We probe the effective field theory extending the Standard Model with a
sterile neutrino in B meson decays at B factories and lepton colliders, using
angular and polarization observables. We put bounds on different effective
operators characterized by their distinct Dirac-Lorentz structure, and probe
the $N$-mediated B decays sensitivity to these interactions. We define a
Forward-Backward asymmetry $A_{FB}^{\ell \gamma}$ between the muon and photon
directions for the $B \to \mu \nu \gamma$ decay, which allows us to separate
the SM contribution from the effective lepton number conserving and violating
processes, mediated by a near on-shell $N$. Using the most stringent
constraints on the effective parameter space from Belle and BaBar we find that
a measurement of the final polarization $P_{\tau}$ in the rare $B^-\rightarrow
\ell^-_{1}\ell^-_{2} \pi^+$ decays can help us infer the scalar or vector
interaction content in the $N$ production or decay vertices. We find that the B
meson decays are more sensitive to scalar operators.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:38:35 GMT""}]","2020-10-28"
"2006.11217","William J. Torres Bobadilla Dr.","J. Jesus Aguilera-Verdugo, Roger J. Hernandez-Pinto, German Rodrigo,
  German F. R. Sborlini, William J. Torres Bobadilla","Causal representation of multi-loop Feynman integrands within the
  loop-tree duality","24 pages, 8 figures. v2: references added; matches published version",,"10.1007/JHEP01(2021)069","IFIC/20-27","hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  The numerical evaluation of multi-loop scattering amplitudes in the Feynman
representation usually requires to deal with both physical (causal) and
unphysical (non-causal) singularities. The loop-tree duality (LTD) offers a
powerful framework to easily characterise and distinguish these two types of
singularities, and then simplify analytically the underling expressions. In
this paper, we work explicitly on the dual representation of multi-loop Feynman
integrals generated from three parent topologies, which we refer to as Maximal,
Next-to-Maximal and Next-to-Next-to-Maximal loop topologies. In particular, we
aim at expressing these dual contributions, independently of the number of
loops and internal configurations, in terms of causal propagators only. Thus,
providing very compact and causal integrand representations to all orders. In
order to do so, we reconstruct their analytic expressions from numerical
evaluation over finite fields. This procedure implicitly cancels out all
unphysical singularities. We also interpret the result in terms of entangled
causal thresholds. In view of the simple structure of the dual expressions, we
integrate them numerically up to four loops in integer space-time dimensions,
taking advantage of their smooth behaviour at integrand level.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:42:36 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 16:08:33 GMT""}]","2021-06-23"
"2006.11218","Yusuf Aydin","Yusuf Aydin and Ozan Tokatli and Volkan Patoglu and Cagatay Basdogan","A Computational Multi-Criteria Optimization Approach to Controller
  Design for Physical Human-Robot Interaction","13 pages, 13 figures. Accepted to IEEE Transaction on Robotics",,"10.1109/TRO.2020.2998606",,"cs.RO cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physical human-robot interaction (pHRI) integrates the benefits of human
operator and a collaborative robot in tasks involving physical interaction,
with the aim of increasing the task performance. However, the design of
interaction controllers that achieve safe and transparent operations is
challenging, mainly due to the contradicting nature of these objectives.
Knowing that attaining perfect transparency is practically unachievable,
controllers that allow better compromise between these objectives are
desirable. In this paper, we propose a multi-criteria optimization framework,
which jointly optimizes the stability robustness and transparency of a
closed-loop pHRI system for a given interaction controller. In particular, we
propose a Pareto optimization framework that allows the designer to make
informed decisions by thoroughly studying the trade-off between stability
robustness and transparency. The proposed framework involves a search over the
discretized controller parameter space to compute the Pareto front curve and a
selection of controller parameters that yield maximum attainable transparency
and stability robustness by studying this trade-off curve. The proposed
framework not only leads to the design of an optimal controller, but also
enables a fair comparison among different interaction controllers. In order to
demonstrate the practical use of the proposed approach, integer and fractional
order admittance controllers are studied as a case study and compared both
analytically and experimentally. The experimental results validate the proposed
design framework and show that the achievable transparency under fractional
order admittance controller is higher than that of integer order one, when both
controllers are designed to ensure the same level of stability robustness.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:46:45 GMT""}]","2020-08-13"
"2006.11219","Samuel Chamberlin","Angelo Bianchi and Samuel Chamberlin","An Integral Basis for the Universal Enveloping Algebra of the Onsager
  Algebra",,,,,"math.RA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct an integral form for the universal enveloping algebra of the
Onsager algebra and an explicit integral basis for this integral form. We also
formulate straightening identities among some products of basis elements.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:48:59 GMT""}]","2020-06-22"
"2006.11220","David Shuman","David I Shuman","Localized Spectral Graph Filter Frames: A Unifying Framework, Survey of
  Design Considerations, and Numerical Comparison (Extended Cut)","This is the extended cut version of a November 2020 Signal Processing
  Magazine article. This version contains additional references and numerical
  experiments",,"10.1109/MSP.2020.3015024",,"eess.SP cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Representing data residing on a graph as a linear combination of building
block signals can enable efficient and insightful visual or statistical
analysis of the data, and such representations prove useful as regularizers in
signal processing and machine learning tasks. Designing collections of building
block signals -- or more formally, dictionaries of atoms -- that specifically
account for the underlying graph structure as well as any available
representative training signals has been an active area of research over the
last decade. In this article, we survey a particular class of dictionaries
called localized spectral graph filter frames, whose atoms are created by
localizing spectral patterns to different regions of the graph. After showing
how this class encompasses a variety of approaches from spectral graph wavelets
to graph filter banks, we focus on the two main questions of how to design the
spectral filters and how to select the center vertices to which the patterns
are localized. Throughout, we emphasize computationally efficient methods that
ensure the resulting transforms and their inverses can be applied to data
residing on large, sparse graphs. We demonstrate how this class of transform
methods can be used in signal processing tasks such as denoising and non-linear
approximation, and provide code for readers to experiment with these methods in
new application domains.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:49:33 GMT""},{""version"":""v2"",""created"":""Wed, 5 Aug 2020 03:32:28 GMT""}]","2020-12-02"
"2006.11221","Jan-Lukas Wynen","Jan-Lukas Wynen, Evan Berkowitz, Stefan Krieg, Thomas Luu, Johann
  Ostmeyer","Leveraging Machine Learning to Alleviate Hubbard Model Sign Problems","30 pages, 16 figures","Phys. Rev. B 103, 125153 (2021)","10.1103/PhysRevB.103.125153",,"cond-mat.str-el cond-mat.dis-nn hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lattice Monte Carlo calculations of interacting systems on non-bipartite
lattices exhibit an oscillatory imaginary phase known as the phase or sign
problem, even at zero chemical potential. One method to alleviate the sign
problem is to analytically continue the integration region of the state
variables into the complex plane via holomorphic flow equations. For
asymptotically large flow times the state variables approach manifolds of
constant imaginary phase known as Lefschetz thimbles. However, flowing such
variables and calculating the ensuing Jacobian is a computationally demanding
procedure. In this paper we demonstrate that neural networks can be trained to
parameterize suitable manifolds for this class of sign problem and drastically
reduce the computational cost. We apply our method to the Hubbard model on the
triangle and tetrahedron, both of which are non-bipartite. At strong
interaction strengths and modest temperatures the tetrahedron suffers from a
severe sign problem that cannot be overcome with standard reweighting
techniques, while it quickly yields to our method. We benchmark our results
with exact calculations and comment on future directions of this work.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:50:20 GMT""}]","2021-03-31"
"2006.11222","Sanjay Mansabdar","Sanjay Mansabdar and Hussain C Yaganti","Valuing the quality option in agricultural commodity futures: a Monte
  Carlo simulation based approach","12 pages",,,,"q-fin.CP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Agricultural commodity futures are often settled by delivery. Quality options
that allow the futures short to deliver one of several underlying assets are
commonly used in such contracts to prevent manipulation. Inclusion of these
options reduces the price of the futures contract and leads to degraded
contract hedging performance. Valuation of these options is a first step in
assessing the impact of the quality options embedded into a futures contract.
This paper demonstrates a Monte Carlo simulation based approach to estimate the
value of a quality option. In order to improve simulation efficiency, the
technique of antithetic variables is used. This approach can help in the
assessment of the impact of embedded quality options.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:51:49 GMT""}]","2020-06-22"
"2006.11223","Ghada Zamzmi","Ghada Zamzmi, Sivaramakrishnan Rajaraman, Sameer Antani","Unified Representation Learning for Efficient Medical Image Analysis",,"Under Review 2020",,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Medical image analysis typically includes several tasks such as enhancement,
segmentation, and classification. Traditionally, these tasks are implemented
using separate deep learning models for separate tasks, which is not efficient
because it involves unnecessary training repetitions, demands greater
computational resources, and requires a relatively large amount of labeled
data. In this paper, we propose a multi-task training approach for medical
image analysis, where individual tasks are fine-tuned simultaneously through
relevant knowledge transfer using a unified modality-specific feature
representation (UMS-Rep). We explore different fine-tuning strategies to
demonstrate the impact of the strategy on the performance of target medical
image tasks. We experiment with different visual tasks (e.g., image denoising,
segmentation, and classification) to highlight the advantages offered with our
approach for two imaging modalities, chest X-ray and Doppler echocardiography.
Our results demonstrate that the proposed approach reduces the overall demand
for computational resources and improves target task generalization and
performance. Further, our results prove that the performance of target tasks in
medical images is highly influenced by the utilized fine-tuning strategy.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:52:16 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 00:04:34 GMT""}]","2021-06-09"
"2006.11224","Udayan Darji","Udayan B. Darji, Daniel Gon\c{c}alves, Marcelo Sobottka","Shadowing, Finite Order Shifts and Ultrametric Spaces","40 pages",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by a recent novel work of Good and Meddaugh, we establish
fundamental connections between shadowing, finite order shifts, and ultrametric
complete spaces. We develop a theory of shifts of finite type for infinite
alphabets. We call them shifts of finite order. We develop the basic theory of
the shadowing property in general metric spaces, exhibiting similarities and
differences with the theory in compact spaces. We connect these two theories in
the setting of zero-dimensional complete spaces, showing that a uniformly
continuous map of an ultrametric complete space has the finite shadowing
property if, and only if, it is an inverse limit of a system of shifts of
finite order satisfying the Mittag-Leffler Condition. Furthermore, in this
context, we show that the shadowing property is equivalent to the finite
shadowing property and the fulfillment of the Mittag-Leffler Condition in the
inverse limit description of the system. As corollaries, we obtain that a
variety of maps in ultrametric spaces have the shadowing property, such as
similarities and, more generally, maps which themselves, or their inverses,
have Lipschitz constant 1. Finally, we apply our results to the dynamics of
$p$-adic integers and $p$-adic rationals.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:53:34 GMT""},{""version"":""v2"",""created"":""Sun, 23 Aug 2020 13:30:56 GMT""},{""version"":""v3"",""created"":""Mon, 28 Dec 2020 01:10:21 GMT""}]","2020-12-29"
"2006.11225","Patrick Foldenauer","Dorian Warren Praia do Amaral, David G. Cerdeno, Patrick Foldenauer,
  and Elliott Reid","Solar neutrino probes of the muon anomalous magnetic moment in the
  gauged $U(1)_{L_\mu-L_\tau}$","21 pages + appendices and references, 8 figures; v2: added
  references, updated description of loop-induced kinetic mixing suitable for
  low-energy processes; v3: matches published version","J. High Energ. Phys. 2020, 155 (2020)","10.1007/JHEP12(2020)155","IPPP/20/24, IFT-UAM/CSIC-20-70","hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Models of gauged $U(1)_{L_\mu-L_\tau}$ can provide a solution to the
long-standing discrepancy between the theoretical prediction for the muon
anomalous magnetic moment and its measured value. The extra contribution is due
to a new light vector mediator, which also helps to alleviate an existing
tension in the determination of the Hubble parameter. In this article, we
explore ways to probe this solution via the scattering of solar neutrinos with
electrons and nuclei in a range of experiments and considering high and low
solar metallicity scenarios. In particular, we reevaluate Borexino constraints
on neutrino-electron scattering, finding them to be more stringent than
previously reported, and already excluding a part of the $(g-2)_\mu$
explanation with mediator masses smaller than $2\times10^{-2}$ GeV. We then
show that future direct dark matter detectors will be able to probe most of the
remaining solution. Due to its large exposure, LUX-ZEPLIN will explore regions
with mediator masses up to $5\times10^{-2}$ GeV and DARWIN will be able to
extend the search beyond $10^{-1}$ GeV, thereby covering most of the area
compatible with $(g-2)_\mu$. For completeness, we have also computed the
constraints derived from the recent XENON1T electron recoil search and from the
CENNS-10 LAr detector, showing that none of them excludes new areas of the
parameter space. Should the excess in the muon anomalous magnetic moment be
confirmed, our work suggests that direct detection experiments could provide
crucial information with which to test the $U(1)_{L_\mu-L_\tau}$ solution,
complementary to efforts in neutrino experiments and accelerators.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:59:15 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 15:20:55 GMT""},{""version"":""v3"",""created"":""Fri, 15 Jan 2021 14:15:14 GMT""}]","2021-01-18"
"2006.11226","Matus Telgarsky","Ziwei Ji, Miroslav Dud\'ik, Robert E. Schapire, Matus Telgarsky","Gradient descent follows the regularization path for general losses","To appear, COLT 2020",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work across many machine learning disciplines has highlighted that
standard descent methods, even without explicit regularization, do not merely
minimize the training error, but also exhibit an implicit bias. This bias is
typically towards a certain regularized solution, and relies upon the details
of the learning process, for instance the use of the cross-entropy loss.
  In this work, we show that for empirical risk minimization over linear
predictors with arbitrary convex, strictly decreasing losses, if the risk does
not attain its infimum, then the gradient-descent path and the
algorithm-independent regularization path converge to the same direction
(whenever either converges to a direction). Using this result, we provide a
justification for the widely-used exponentially-tailed losses (such as the
exponential loss or the logistic loss): while this convergence to a direction
for exponentially-tailed losses is necessarily to the maximum-margin direction,
other losses such as polynomially-tailed losses may induce convergence to a
direction with a poor margin.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:01:25 GMT""}]","2020-06-22"
"2006.11227","Hadi Jamali-Rad","Hadi Jamali-Rad, Attila Szabo","Lookahead Adversarial Learning for Near Real-Time Semantic Segmentation","25 pages",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semantic segmentation is one of the most fundamental problems in computer
vision with significant impact on a wide variety of applications. Adversarial
learning is shown to be an effective approach for improving semantic
segmentation quality by enforcing higher-level pixel correlations and
structural information. However, state-of-the-art semantic segmentation models
cannot be easily plugged into an adversarial setting because they are not
designed to accommodate convergence and stability issues in adversarial
networks. We bridge this gap by building a conditional adversarial network with
a state-of-the-art segmentation model (DeepLabv3+) at its core. To battle the
stability issues, we introduce a novel lookahead adversarial learning (LoAd)
approach with an embedded label map aggregation module. We focus on semantic
segmentation models that run fast at inference for near real-time field
applications. Through extensive experimentation, we demonstrate that the
proposed solution can alleviate divergence issues in an adversarial semantic
segmentation setting and results in considerable performance improvements (+5%
in some classes) on the baseline for three standard datasets.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:04:38 GMT""},{""version"":""v2"",""created"":""Sat, 5 Sep 2020 08:46:07 GMT""},{""version"":""v3"",""created"":""Thu, 21 Jan 2021 15:00:09 GMT""}]","2021-01-22"
"2006.11228","Hanwen Xing","Hanwen Xing, Geoff K. Nicholls, Jeong Eun Lee","Distortion estimates for approximate Bayesian inference",,,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current literature on posterior approximation for Bayesian inference offers
many alternative methods. Does our chosen approximation scheme work well on the
observed data? The best existing generic diagnostic tools treating this kind of
question by looking at performance averaged over data space, or otherwise lack
diagnostic detail. However, if the approximation is bad for most data, but good
at the observed data, then we may discard a useful approximation. We give
graphical diagnostics for posterior approximation at the observed data. We
estimate a ""distortion map"" that acts on univariate marginals of the
approximate posterior to move them closer to the exact posterior, without
recourse to the exact posterior.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:05:45 GMT""}]","2020-06-22"
"2006.11229","Syeda Nasim","Gaia Fabj, Syeda S. Nasim, Freddy Caban, K. E. Saavik Ford, Barry
  McKernan, Jillian M. Bellovary","Aligning Nuclear Cluster Orbits with an Active Galactic Nucleus
  Accretion Disk","Submitted to MNRAS; 10 pages, 6 figures","Monthly Notices of the Royal Astronomical Society, Volume 499,
  Issue 2, December 2020, Pages 2608-2616","10.1093/mnras/staa3004",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active galactic nuclei (AGN) are powered by the accretion of disks of gas
onto supermassive black holes (SMBHs). Stars and stellar remnants orbiting the
SMBH in the nuclear star cluster (NSC) will interact with the AGN disk.
Orbiters plunging through the disk experience a drag force and, through
repeated passage, can have their orbits captured by the disk. A population of
embedded objects in AGN disks may be a significant source of binary black hole
mergers, supernovae, tidal disruption events and embedded gamma-ray bursts. For
two representative AGN disk models we use geometric drag and
Bondi-Hoyle-Littleton drag to determine the time to capture for stars and
stellar remnants. We assume a range of initial inclination angles and
semi-major axes for circular Keplerian prograde orbiters. Capture time strongly
depends on the density and aspect ratio of the chosen disk model, the relative
velocity of the stellar object with respect to the disk, and the AGN lifetime.
We expect that for an AGN disk density $\rho \gtrsim 10^{-11}\rm g/cm^3$ and
disk lifetime $\geq 1$Myr, there is a significant population of embedded
stellar objects, which can fuel mergers detectable in gravitational waves with
LIGO-Virgo and LISA.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:08:17 GMT""},{""version"":""v2"",""created"":""Fri, 30 Oct 2020 17:28:50 GMT""}]","2020-11-02"
"2006.11230","Lhoussain El Fadil","L. El Fadil","On Power integral bases for certain pure number fields","To appear in Pub. Math. Deb",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $K=\mathbb{Q}(\alpha)$ be a number field generated by a complex root
$\alpha$ of a monic irreducible polynomial $f(x)=x^{12}-m$, with $m\neq 1$ is a
square free rational integer. In this paper, we prove that if $m \equiv 2$ or
$3$ (mod 4) and $m\not\equiv \mp 1$ (mod 9), then the number field $K$ is
monogenic. If $m \equiv 1$ (mod 8) or $m\equiv \mp 1$ (mod 9), then the number
field $K$ is not monogenic.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:08:51 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 13:04:23 GMT""},{""version"":""v3"",""created"":""Mon, 31 May 2021 22:44:03 GMT""}]","2021-06-02"
"2006.11231","Krishna Chaitanya Pitike","Krishna Chaitanya Pitike, Santosh KC, Markus Eisenbach, Craig A.
  Bridges, Valentino R. Cooper","Predicting the phase stability of multi-component high entropy compounds","43 pages, 5 main figures and 8 supplemental figures. Being considered
  for Chemistry of Materials",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A generic method to estimate the relative feasibility of formation of high
entropy compounds in a single phase, directly from first principles, is
developed. As a first step, the relative formation abilities of 56
multi-component, AO, oxides were evaluated. These were constructed from 5
cation combinations chosen from A={Ca, Co, Cu, Fe, Mg, Mn, Ni, Zn}. Candidates
for multi-component oxides are predicted from descriptors related to the
enthalpy and configurational entropy obtained from the mixing enthalpies of two
component oxides. The utility of this approach is evaluated by comparing the
predicted combinations with the experimentally realized entropy stabilized
oxide, (MgCoCuNiZn)O. In the second step, Monte Carlo simulations are utilized
to investigate the phase composition and local ionic segregation as a function
of temperature. This approach allows for the evaluation of potential secondary
phases, thereby making realistic predictions of novel multi-component compounds
that can be synthesized.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:09:54 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 16:22:14 GMT""}]","2020-06-29"
"2006.11232","Davron Jumaev","Jumaev Davron Ilxomovich, Ishniyazov Baxrom Normamatovich,
  Tagaymuratov Abror Olimovich","Cartesian products of the $g$-topologies are a $g$-topology","9 pages",,,,"math.GN math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that unlike the usual topologies the $g$-topologies are closed with
respect to the Cartesian products. Moreover, we bring much detailed
explanations some examples of concepts related the statistical metric spaces.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:11:08 GMT""}]","2020-06-22"
"2006.11233","Elliot Fairweather","Elliot Fairweather, Rudolf Wittner, Martin Chapman, Petr Holub, Vasa
  Curcin","Non-repudiable provenance for clinical decision support systems","Accepted at International Provenance & Annotation Workshop (IPAW),
  June 2020",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Provenance templates are now a recognised methodology for the construction of
data provenance records. Each template defines the provenance of a
domain-specific action in abstract form, which may then be instantiated as
required by a single call to the provenance template service. As data
reliability and trustworthiness becomes a critical issue in an increasing
number of domains, there is a corresponding need to ensure that the provenance
of that data is non-repudiable. In this paper we contribute two new,
complementary modules to our template model and implementation to produce
non-repudiable data provenance. The first, a module that traces the operation
of the provenance template service itself, and records a provenance trace of
the construction of an object-level document, at the level of individual
service calls. The second, a non-repudiation module that generates evidence for
the data recorded about each call, annotates the service trace accordingly, and
submits a representation of that evidence to a provider-agnostic notary
service. We evaluate the applicability of our approach in the context of a
clinical decision support system. We first define a policy to ensure the
non-repudiation of evidence with respect to a security threat analysis in order
to demonstrate the suitability of our solution. We then select three use cases
from within a particular system, Consult, with contrasting data provenance
recording requirements and analyse the subsequent performance of our prototype
implementation against three different notary providers.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:13:08 GMT""}]","2020-06-22"
"2006.11234","Yu Chen","Yu Chen, Tom Diethe, Peter Flach","Semi-Discriminative Representation Loss for Online Continual Learning",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of episodic memory in continual learning has demonstrated
effectiveness for alleviating catastrophic forgetting. In recent studies,
gradient-based approaches have been developed to make more efficient use of
compact episodic memory. Such approaches refine the gradients resulting from
new samples by those from memorized samples, aiming to reduce the diversity of
gradients from different tasks. In this paper, we clarify the relation between
diversity of gradients and discriminativeness of representations, showing
shared as well as conflicting interests between Deep Metric Learning and
continual learning, thus demonstrating pros and cons of learning discriminative
representations in continual learning. Based on these findings, we propose a
simple method -- Semi-Discriminative Representation Loss (SDRL) -- for
continual learning. In comparison with state-of-the-art methods, SDRL shows
better performance with low computational cost on multiple benchmark tasks in
the setting of online continual learning.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:13:42 GMT""},{""version"":""v2"",""created"":""Fri, 30 Oct 2020 05:10:05 GMT""},{""version"":""v3"",""created"":""Thu, 18 Mar 2021 10:25:13 GMT""},{""version"":""v4"",""created"":""Thu, 14 Apr 2022 11:01:59 GMT""}]","2022-04-15"
"2006.11235","Evan McDonough","Mikhail M. Ivanov, Evan McDonough, J. Colin Hill, Marko Simonovi\'c,
  Michael W. Toomey, Stephon Alexander, Matias Zaldarriaga","Constraining Early Dark Energy with Large-Scale Structure","26 pages, 12 figures. v2: Version to appear in Phys Rev D. Appendices
  B and C demonstrate that EDE provides a worse fit than LCDM to Planck+BOSS
  data, and that constraints are not driven by prior volume effects","Phys. Rev. D 102, 103502 (2020)","10.1103/PhysRevD.102.103502","INR-TH-2020-035; CERN-TH-2020-103","astro-ph.CO gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An axion-like field comprising $\sim 10\%$ of the energy density of the
universe near matter-radiation equality is a candidate to resolve the Hubble
tension; this is the ""early dark energy"" (EDE) model. However, as shown in Hill
et al. (2020), the model fails to simultaneously resolve the Hubble tension and
maintain a good fit to both cosmic microwave background (CMB) and large-scale
structure (LSS) data. Here, we use redshift-space galaxy clustering data to
sharpen constraints on the EDE model. We perform the first EDE analysis using
the full-shape power spectrum likelihood from the Baryon Oscillation
Spectroscopic Survey (BOSS), based on the effective field theory (EFT) of LSS.
The inclusion of this likelihood in the EDE analysis yields a $25\%$ tighter
error bar on $H_0$ compared to primary CMB data alone, yielding $H_0 =
68.54^{+0.52}_{-0.95}$ km/s/Mpc ($68\%$ CL). In addition, we constrain the
maximum fractional energy density contribution of the EDE to $f_{\rm EDE} <
0.072$ ($95\%$ CL). We explicitly demonstrate that the EFT BOSS likelihood
yields much stronger constraints on EDE than the standard BOSS likelihood.
Including further information from photometric LSS surveys,the constraints
narrow by an additional $20\%$, yielding $H_0 = 68.73^{+0.42}_{-0.69}$ km/s/Mpc
($68\%$ CL) and $f_{\rm EDE}<0.053$ ($95\%$ CL). These bounds are obtained
without including local-universe $H_0$ data, which is in strong tension with
the CMB and LSS, even in the EDE model. We also refute claims that MCMC
analyses of EDE that omit SH0ES from the combined dataset yield misleading
posteriors. Finally, we demonstrate that upcoming Euclid/DESI-like
spectroscopic galaxy surveys can greatly improve the EDE constraints. We
conclude that current data preclude the EDE model as a resolution of the Hubble
tension, and that future LSS surveys can close the remaining parameter space of
this model.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:15:28 GMT""},{""version"":""v2"",""created"":""Wed, 7 Oct 2020 17:52:42 GMT""}]","2020-11-04"
"2006.11236","Gyanendra Bohara","Gyanendra Bohara, Azar Sadeghnejad Barkousaraie, Steve Jiang, Dan
  Nguyen","Using Deep Learning to Predict Beam-Tunable Pareto Optimal Dose
  Distribution for Intensity Modulated Radiation Therapy","12 figures",,"10.1002/mp.14374",,"physics.med-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  We propose to develop deep learning models that can predict Pareto optimal
dose distributions by using any given set of beam angles, along with patient
anatomy, as input to train the deep neural networks. We implement and compare
two deep learning networks that predict with two different beam configuration
modalities. We generated Pareto optimal plans for 70 patients with prostate
cancer. We used fluence map optimization to generate 500 IMRT plans that
sampled the Pareto surface for each patient, for a total of 35,000 plans. We
studied and compared two different models, Model I and Model II. Model I
directly uses beam angles as a second input to the network as a binary vector.
Model II converts the beam angles into beam doses that are conformal to the
PTV. Our deep learning models predicted voxel-level dose distributions that
precisely matched the ground truth dose distributions. Quantitatively, Model I
prediction error of 0.043 (confirmation), 0.043 (homogeneity), 0.327 (R50),
2.80% (D95), 3.90% (D98), 0.6% (D50), 1.10% (D2) was lower than that of Model
II, which obtained 0.076 (confirmation), 0.058 (homogeneity), 0.626 (R50),
7.10% (D95), 6.50% (D98), 8.40% (D50), 6.30% (D2). Treatment planners who use
our models will be able to use deep learning to control the tradeoffs between
the PTV and OAR weights, as well as the beam number and configurations in real
time. Our dose prediction methods provide a stepping stone to building
automatic IMRT treatment planning.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:15:45 GMT""}]","2021-01-27"
"2006.11237","Christoph Andreas Ternes","P. F. de Salas, D. V. Forero, S. Gariazzo, P. Mart\'inez-Mirav\'e, O.
  Mena, C. A. Ternes, M. T\'ortola, J. W. F. Valle","2020 Global reassessment of the neutrino oscillation picture","35 pages, 15 figures, 3 tables, version 2 includes updated analyses
  of reactor and accelerator data, matches version accepted for publication in
  JHEP","J. High Energ. Phys. 2021, 71 (2021)","10.1007/JHEP02(2021)071",,"hep-ph astro-ph.CO hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an updated global fit of neutrino oscillation data in the simplest
three-neutrino framework. In the present study we include up-to-date analyses
from a number of experiments. Concerning the atmospheric and solar sectors, we
give updated analyses of DeepCore and SNO data, respectively. We have also
included the latest electron antineutrino data collected by the Daya Bay and
RENO reactor experiments, and the long-baseline T2K and NO$\nu$A measurements.
These new analyses result in more accurate measurements of $\theta_{13}$,
$\theta_{12}$, $\Delta m_{21}^2$ and $|\Delta m_{31}^2|$. The best fit value
for the atmospheric angle $\theta_{23}$ lies in the second octant, but first
octant solutions remain allowed at $\sim2.4\sigma$. Regarding CP violation
measurements, the preferred value of $\delta$ we obtain is 1.08$\pi$
(1.58$\pi$) for normal (inverted) neutrino mass ordering. The global analysis
prefers normal neutrino mass ordering with 2.5$\sigma$. This preference is
milder than the one found in previous global analyses. The new results should
be regarded as robust due to the agreement found between our Bayesian and
frequentist approaches. Taking into account only oscillation data, there is a
weak/moderate preference for the normal neutrino mass ordering of $2.00\sigma$.
While adding neutrinoless double beta decay from the latest Gerda, CUORE and
KamLAND-Zen results barely modifies this picture, cosmological measurements
raise the preference to $2.68\sigma$ within a conservative approach. A more
aggressive data set combination of cosmological observations leads to a similar
preference, namely $2.70\sigma$. This very same cosmological data set provides
$2\sigma$ upper limits on the total neutrino mass corresponding to
$\sum\nu<0.12$ ($0.15$)~eV for normal (inverted) neutrino mass ordering.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:21:48 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 09:50:37 GMT""}]","2021-02-12"
"2006.11238","Caucher Birkar","Caucher Birkar","Geometry of polarised varieties","V2: To appear in Pub. Math IHES, 49 pages; the results on moduli and
  their proofs are moved to a forthcoming paper, so the title is slightly
  changed",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we investigate the geometry of projective varieties polarised
by ample and more generally nef and big Weil divisors. First we study
birational boundedness of linear systems. We show that if $X$ is a projective
variety of dimension $d$ with $\epsilon$-lc singularities for $\epsilon>0$, and
if $N$ is a nef and big Weil divisor on $X$ such that $N-K_X$ is
pseudo-effective, then the linear system $|mN|$ defines a birational map for
some natural number $m$ depending only on $d,\epsilon$. This is key to proving
various other results. For example, it implies that if $N$ is a big Weil
divisor (not necessarily nef) on a klt Calabi-Yau variety of dimension $d$,
then the linear system $|mN|$ defines a birational map for some natural number
$m$ depending only on $d$. It also gives new proofs of some known results, for
example, if $X$ is an $\epsilon$-lc Fano variety of dimension $d$ then taking
$N=-K_X$ we recover birationality of $|-mK_X|$ for bounded $m$.
  We prove similar birational boundedness results for nef and big Weil divisors
$N$ on projective klt varieties $X$ when both $K_X$ and $N-K_X$ are
pseudo-effective (here $X$ is not assumed $\epsilon$-lc).
  Using the above, we show boundedness of polarised varieties under some
natural conditions. We extend these to boundedness of semi-log canonical
Calabi-Yau pairs polarised by effective ample Weil divisors not containing lc
centres. We will briefly discuss applications to existence of projective coarse
moduli spaces of such polarised Calabi-Yau pairs.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:23:37 GMT""},{""version"":""v2"",""created"":""Mon, 19 Sep 2022 06:47:36 GMT""}]","2022-09-20"
"2006.11239","Jonathan Ho","Jonathan Ho, Ajay Jain, Pieter Abbeel","Denoising Diffusion Probabilistic Models",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present high quality image synthesis results using diffusion probabilistic
models, a class of latent variable models inspired by considerations from
nonequilibrium thermodynamics. Our best results are obtained by training on a
weighted variational bound designed according to a novel connection between
diffusion probabilistic models and denoising score matching with Langevin
dynamics, and our models naturally admit a progressive lossy decompression
scheme that can be interpreted as a generalization of autoregressive decoding.
On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and
a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality
similar to ProgressiveGAN. Our implementation is available at
https://github.com/hojonathanho/diffusion
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:24:44 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 21:15:05 GMT""}]","2020-12-18"
"2006.11240","Fabio Botelho Ph.D.","Alexandre Molter and Fabio Silva Botelho","Optimal control for the nonlinear Fisher-Kolmogorov system with
  applications to aquatic plant management","15 pages",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spatiotemporal dynamics of populations may be described by the
reaction-diffusion Fisher-Kolmogorov model. In this work we have proposed a new
formulation for a control problem of aquatic plants in a temporal dynamics. The
solution of this problem is extended to a spatiotemporal Fisher-Kolmogorov
system with multiple species of plants interacting in the same place. The
control consists on human intervention as a strategy for management of the
aquatic plants. In our applications, one plant and two plants cases have been
considered. Simulation results are presented to show the effectiveness of the
proposed control strategies.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:25:43 GMT""}]","2020-06-22"
"2006.11241","Gordon Slade","Gordon Slade","A simple convergence proof for the lace expansion","An improvement of Section 3 of arXiv:2006.06532v1, which has been
  divided into two independent papers. 9 pages. Minor changes in this version.
  To be published in Annales de l'Institut Henri Poincar\'e (B) Probabilit\'es
  et Statistiques",,,,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use the lace expansion to give a simple proof that the critical two-point
function for weakly self-avoiding walk on $\mathbb{Z}^d$ has decay
$|x|^{-(d-2)}$ in dimensions $d>4$. The proof uses elementary Fourier analysis
and the Riemann--Lebesgue Lemma.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:26:15 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 22:18:44 GMT""}]","2021-03-09"
"2006.11242","Yuhua Chen","Yuhua Chen, Luc Van Gool, Cordelia Schmid, Cristian Sminchisescu","Consistency Guided Scene Flow Estimation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consistency Guided Scene Flow Estimation (CGSF) is a self-supervised
framework for the joint reconstruction of 3D scene structure and motion from
stereo video. The model takes two temporal stereo pairs as input, and predicts
disparity and scene flow. The model self-adapts at test time by iteratively
refining its predictions. The refinement process is guided by a consistency
loss, which combines stereo and temporal photo-consistency with a geometric
term that couples disparity and 3D motion. To handle inherent modeling error in
the consistency loss (e.g. Lambertian assumptions) and for better
generalization, we further introduce a learned, output refinement network,
which takes the initial predictions, the loss, and the gradient as input, and
efficiently predicts a correlated output update. In multiple experiments,
including ablation studies, we show that the proposed model can reliably
predict disparity and scene flow in challenging imagery, achieves better
generalization than the state-of-the-art, and adapts quickly and robustly to
unseen domains.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:28:07 GMT""},{""version"":""v2"",""created"":""Mon, 17 Aug 2020 09:58:47 GMT""}]","2020-08-18"
"2006.11243","Lennert J. Thormaehlen","Gonzalo Alonso-\'Alvarez, Fatih Ertas, Joerg Jaeckel, Felix Kahlhoefer
  and Lennert J. Thormaehlen","Hidden Photon Dark Matter in the Light of XENON1T and Stellar Cooling","15 pages, 2 figures, improved statistical analysis",,"10.1088/1475-7516/2020/11/029","TTK-20-19","hep-ph astro-ph.CO hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The low-energy electronic recoil spectrum in XENON1T provides an intriguing
hint for potential new physics. At the same time, observations of horizontal
branch stars favor the existence of a small amount of extra cooling compared to
the one expected from the Standard Model particle content. In this note, we
argue that a hidden photon with a mass of $\sim 2.5$ keV and a kinetic mixing
of $\sim 10^{-15}$ allows for a good fit to both of these excesses. In this
scenario, the signal detected in XENON1T is due to the absorption of hidden
photon dark matter particles, whereas the anomalous cooling of horizontal
branch stars arises from resonant production of hidden photons in the stellar
interior.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:29:31 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 16:19:02 GMT""},{""version"":""v3"",""created"":""Fri, 18 Sep 2020 10:30:51 GMT""}]","2020-11-25"
"2006.11244","Lucien Hardy","Lucien Hardy","Counting Risk Increments to Make Decisions During an Epidemic","51 pages, many diagrams",,,,"cs.CY physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I propose a smartphone app that will allow people to participate in the
management of their own safety during an epidemic or pandemic such as COVID-19
by enabling them to view, in advance, the risks they would take if they visit
some given venue (a cafe, the gym, the workplace, the park,...) and,
furthermore, track the accumulation of such risks during the course of any
given day or week. This idea can be presented to users of the app as counting
points. One point represents some constant probability, $p_\text{point}$, of
infection. Then the app would work in a similar way to a calorie counting app
(instead of counting calories we count probability increments of being
infected). Government could set a maximum recommended number of daily (or
weekly) points available to each user in accord with its objectives (bringing
the disease under control, allowing essential workers to work, protecting
vulnerable individuals, ...). It is posited that this, along with other
proposed ""levers"" would allow government to manage a gradual transition to
normalcy. I discuss a circuit framework with wires running between boxes. In
this framework the wires represent possible sources of infection, namely
individuals and the venues themselves (through deposits of pathogens left at
the venue). The boxes represent interactions of these sources (when individuals
visit a venue). This circuit framework allows (i) calculation of points cost
for visiting venues and (ii) probabilistic contact tracing. The points systems
proposed here could complement existing contact tracing apps by adding
functionality to permit users to participate in decision making up front.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:35:03 GMT""}]","2020-06-22"
"2006.11245","Julia Lieb","Julia Lieb and Diego Napp and Raquel Pinto","List decoding of Convolutional Codes over integer residue rings",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A convolutional code $\C$ over $\ZZ[D]$ is a $\ZZ[D]$-submodule of $\ZZN[D]$
where $\ZZ[D]$ stands for the ring of polynomials with coefficients in $\ZZ$.
In this paper, we study the list decoding problem of these codes when the
transmission is performed over an erasure channel, that is, we study how much
information one can recover from a codeword $w\in \C$ when some of its
coefficients have been erased. We do that using the $p$-adic expansion of $w$
and particular representations of the parity-check polynomial matrix of the
code. From these matrix polynomial representations we recursively select
certain equations that $w$ must satisfy and have only coefficients in the field
$p^{r-1}\ZZ$. We exploit the natural block Toeplitz structure of the sliding
parity-check matrix to derive a step by step methodology to obtain a list of
possible codewords for a given corrupted codeword $w$, that is, a list with the
closest codewords to $w$.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:35:29 GMT""},{""version"":""v2"",""created"":""Tue, 8 Sep 2020 17:27:10 GMT""}]","2020-09-09"
"2006.11246","Marcel Hennes","M. Hennes, A. Merhe, X. Liu, D. Weder, C. von Korff Schmising, M.
  Schneider, C. M. G\""unther, B. Mahieu, G. Malinowski, M. Hehn, D. Lacour, F.
  Capotondi, E. Pedersoli, I. P. Nikolov, V. Chardonnet, E. Jal, J. L\""uning,
  and B. Vodungbo","Laser-induced ultrafast demagnetization and perpendicular magnetic
  anisotropy reduction in a Co$_{88}$Tb$_{12}$ thin film with stripe domains",,,"10.1103/PhysRevB.102.174437",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use time-resolved x-ray resonant magnetic scattering (tr-XRMS) at the Co
M$_{2,3}$- and Tb O$_1$-edges to study ultrafast demagnetization in an
amorphous Co$_{88}$Tb$_{12}$ alloy with stripe domains. Combining the
femtosecond temporal with nanometer spatial resolution of our experiment, we
demonstrate that the equilibrium spin texture of the thin film remains
unaltered by the optical pump-pulse on ultrashort timescales ($<$1 ps).
However, after $\simeq$ 4 ps, we observe the onset of a significant domain wall
broadening, which we attribute to a reduction of the uniaxial magnetic
anisotropy of the system, due to energy transfer to the lattice. Static
temperature dependent magnetometry measurements combined with analytical
modeling of the magnetic structure of the thin film corroborate this
interpretation.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:35:35 GMT""}]","2020-12-30"
"2006.11247","Artem Ryabov","David Vor\'a\v{c}, Philipp Maass, and Artem Ryabov","Cycle completion times probe interactions with environment","13 pages, 4 figures","J. Phys. Chem. Lett. 2020, 11, 16, 6887-6891 (2020)","10.1021/acs.jpclett.0c01998",,"cond-mat.stat-mech cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent measurements of durations of non-equilibrium processes provide
valuable information on microscopic mechanisms and energetics. Comprehensive
theory for corresponding experiments so far is well developed for
single-particle systems only. Little is known for interacting systems in
non-equilibrium environments. Here, we introduce and study a basic model for
cycle processes interacting with an environment that can exhibit a net particle
flow. We find a surprising richness of cycle time variations with environmental
conditions. This manifests itself in unequal cycle times $\tau^+$ and $\tau^-$
in forward and backward cycle direction with both asymmetries $\tau^-<\tau^+$
and $\tau^->\tau^+$, speeding up of backward cycles by interactions, and
dynamical phase transitions, where cycle times become multimodal functions of
the bias. The model allows us to relate these effects to specific microscopic
mechanisms, which can be helpful for interpreting experiments.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:36:50 GMT""}]","2020-09-04"
"2006.11249","Jennifer Hom","Jennifer Hom and Tye Lidman","Dehn surgery and non-separating two-spheres","6 pages","Open Book Series 5 (2022) 145-153","10.2140/obs.2022.5.145",,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When can surgery on a null-homologous knot K in a rational homology sphere
produce a non-separating sphere? We use Heegaard Floer homology to give
sufficient conditions for K to be unknotted. We also discuss some applications
to homology cobordism, concordance, and Mazur manifolds.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:37:40 GMT""}]","2022-11-02"
"2006.11250","Aaron C. Vincent","Celine Boehm, David G. Cerdeno, Malcolm Fairbairn, Pedro A. N.
  Machado, Aaron C. Vincent","Light new physics in XENON1T","6 pages, 3 figures. Matches published version","Phys. Rev. D 102, 115013 (2020)","10.1103/PhysRevD.102.115013","FERMILAB-PUB-20-247-T, IFT-UAM/CSIC-20-88","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the recently-reported low-energy electron recoil spectrum observed
at the XENON1T underground dark matter direct detection experiment, in the
context of new interactions with solar neutrinos. In particular we show that
scalar and vector mediators with masses $\lesssim 50$ keV coupled to leptons
could already leave a visible signature in the XENON1T experiment, similar to
the observed peak below 7 keV. This signals that dark matter detectors are
already competing with neutrino scattering experiments such as GEMMA, CHARM-II
and Borexino. If these results from XENON1T are interpreted as a new signal of
such physics, the parameters which fit the excess face challenges from
astrophysics which seem very difficult to overcome. If they are rather viewed
as a constraint on new couplings, they herald the start of an era of novel
precise probes of physics beyond the standard model with dark matter detectors.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:38:17 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 21:45:47 GMT""}]","2021-11-22"
"2006.11251","Kyriakos Akos Matszangosz","L\'aszl\'o M. Feh\'er and \'Akos K. Matszangosz","Halving spaces and lower bounds in real enumerative geometry","30 pages","Algebr. Geom. Topol. 22 (2022) 433-472","10.2140/agt.2022.22.433",,"math.AT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop the theory of halving spaces to obtain lower bounds in real
enumerative geometry. Halving spaces are topological spaces with an action of a
Lie group $\Gamma$ with additional cohomological properties. For
$\Gamma=\mathbb{Z}_2$ we recover the conjugation spaces of Hausmann, Holm and
Puppe. For $\Gamma=\mathrm{U}(1)$ we obtain the circle spaces. We show that
real even and quaternionic partial flag manifolds are circle spaces leading to
non-trivial lower bounds for even real and quaternionic Schubert problems. To
prove that a given space is a halving space, we generalize results of Borel and
Haefliger on the cohomology classes of real subvarieties and their
complexifications. The novelty is that we are able to obtain results in
rational cohomology instead of modulo 2. The equivariant extension of the
theory of circle spaces leads to generalizations of the results of Borel and
Haefliger on Thom polynomials.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:39:07 GMT""}]","2022-05-04"
"2006.11253","Tobias Hansen","Parijat Dey, Tobias Hansen, Mykola Shpot","Operator expansions, layer susceptibility and two-point functions in
  BCFT","34 pages, 1 figure, v2: minor improvements",,"10.1007/JHEP12(2020)051","UUITP-21/20","hep-th cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We show that in boundary CFTs, there exists a one-to-one correspondence
between the boundary operator expansion of the two-point correlation function
and a power series expansion of the layer susceptibility. This general property
allows the direct identification of the boundary spectrum and expansion
coefficients from the layer susceptibility and opens a new way for efficient
calculations of two-point correlators in BCFTs. To show how it works we derive
an explicit expression for the correlation function $\langle\phi_i
\phi^i\rangle$ of the O(N) model at the extraordinary transition in
4-$\epsilon$ dimensional semi-infinite space to order $O(\epsilon)$. The bulk
operator product expansion of the two-point function gives access to the
spectrum of the bulk CFT. In our example, we obtain the averaged anomalous
dimensions of scalar composite operators of the O(N) model to order
$O(\epsilon^2)$. These agree with the known results both in $\epsilon$ and
large-N expansions.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:40:47 GMT""},{""version"":""v2"",""created"":""Sun, 6 Dec 2020 18:45:45 GMT""}]","2020-12-11"
"2006.11256","Alexander Stolyar","Seva Shneer, Alexander Stolyar","Large-scale parallel server system with multi-component jobs","21 pages, 1 figure. Revision",,,,"math.PR cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A broad class of parallel server systems is considered, for which we prove
the steady-state asymptotic independence of server workloads, as the number of
servers goes to infinity, while the system load remains sub-critical. Arriving
jobs consist of multiple components. There are multiple job classes, and each
class may be of one of two types, which determines the rule according to which
the job components add workloads to the servers. The model is broad enough to
include as special cases some popular queueing models with redundancy, such as
cancel-on-start and cancel-on-completion redundancy.
  Our analysis uses mean-field process representation and the corresponding
mean-field limits. In essence, our approach relies almost exclusively on three
fundamental properties of the model: (a) monotonicity, (b) work conservation,
(c) the property that, on average, ""new arriving workload prefers to go to
servers with lower workloads.""
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:42:44 GMT""},{""version"":""v2"",""created"":""Thu, 17 Dec 2020 19:39:39 GMT""}]","2020-12-21"
"2006.11258","You Lai","Y. Lai, K. Wei, G. Chappell, J. Diaz, T. Siegrist, P. J. W. Moll, D.
  Graf, R. E. Baumbach","Tuning the structural and antiferromagnetic phase transitions in
  UCr$_{2}$Si$_2$: hydrostatic pressure and chemical substitution","Main text 9 pages, 7 figures. Supplementary materials included at the
  end","Phys. Rev. Materials 4, 075003 (2020)","10.1103/PhysRevMaterials.4.075003",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Structural phase transitions in $f$-electron materials have attracted
sustained attention both for practical and basic science reasons, including
that they offer an environment to directly investigate relationships between
structure and the $f$-state. Here we present results for UCr$_2$Si$_2$, where
structural (tetragonal $\rightarrow$ monoclinic) and antiferromagnetic phase
transitions are seen at $T_{\rm{S}}$ $=$ 205 K and $T_{\rm{N}}$ $=$ 25 K,
respectively. We also provide evidence for an additional second order phase
transition at $T_{\rm{X}}$ = 280 K. We show that $T_{\rm{X}}$, $T_{\rm{S}}$,
and $T_{\rm{N}}$ respond in distinct ways to the application of hydrostatic
pressure and Cr $\rightarrow$ Ru chemical substitution. In particular,
hydrostatic compression increases the structural ordering temperature,
eventually causes it to merge with $T_{\rm{X}}$ and destroys the
antiferromagnetism. In contrast, chemical substitution in the series
UCr$_{2-x}$Ru$_x$Si$_2$ suppresses both $T_{\rm{S}}$ and $T_{\rm{N}}$, causing
them to approach zero temperature near $x$ $\approx$ 0.16 and 0.08,
respectively. The distinct $T-P$ and $T-x$ phase diagrams are related to the
evolution of the rigid Cr-Si and Si-Si substructures, where applied pressure
semi-uniformly compresses the unit cell and Cr $\rightarrow$ Ru substitution
results in uniaxial lattice compression along the tetragonal $c$-axis and an
expansion in the $ab$-plane. These results provide insights into an interesting
class of strongly correlated quantum materials where degrees of freedom
associated with $f$-electron magnetism, strong electronic correlations, and
structural instabilities are readily controlled.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:47:58 GMT""}]","2020-08-05"
"2006.11259","Eser Ayg\""un","Eser Ayg\""un, Zafarali Ahmed, Ankit Anand, Vlad Firoiu, Xavier Glorot,
  Laurent Orseau, Doina Precup, Shibl Mourad","Learning to Prove from Synthetic Theorems","17 pages, 6 figures, submitted to NeurIPS 2020",,,,"cs.LO cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A major challenge in applying machine learning to automated theorem proving
is the scarcity of training data, which is a key ingredient in training
successful deep learning models. To tackle this problem, we propose an approach
that relies on training with synthetic theorems, generated from a set of
axioms. We show that such theorems can be used to train an automated prover and
that the learned prover transfers successfully to human-generated theorems. We
demonstrate that a prover trained exclusively on synthetic theorems can solve a
substantial fraction of problems in TPTP, a benchmark dataset that is used to
compare state-of-the-art heuristic provers. Our approach outperforms a model
trained on human-generated problems in most axiom sets, thereby showing the
promise of using synthetic data for this task.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:48:09 GMT""}]","2020-06-22"
"2006.11260","Raffaele Marcovecchio","Raffaele Marcovecchio","Vectors of type II Hermite-Pad\'e approximations and a new linear
  independence criterion","29 pages, 67 references; section 4 expanded with more examples","Ann. Mat. Pura Appl. (4) 200 (2021), 2829-2861","10.1007/s10231-021-01104-7",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a linear independence criterion, and outline an application of it.
Down to its simplest case, it aims at solving this problem: given three real
numbers, typically as special values of analytic functions, how to prove that
the $\mathbb{Q}$-vector space spanned by $1$ and those three numbers has
dimension at least 3, whenever we are unable to achieve full linear
independence, by using simultaneous approximations, i.e. those usually arising
from Hermite-Pad\'e approximations of type II and their suitable
generalizations. It should be recalled that approximations of type I and II are
related, at least in principle: when the numerical application consists in
specializing actual functional constructions of the two types, they can be
obtained, one from the other, as explained in a well-known paper by K.Mahler
[34]. That relation is reflected in a relation between the asymptotic behavior
of the approximations at the infinite place of $\mathbb{Q}$. Rather
interestingly, the two view-points split away regarding the asymptotic
behaviors at finite places (i.e. primes) of $\mathbb{Q}$, and this makes the
use of type II more convenient for particular purposes. In addition, sometimes
we know type II approximations to a given set of functions, for which type I
approximations are not known explicitly. Our approach can be regarded as a dual
version of the standard linear independence criterion, which goes back to
Siegel.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:48:45 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 07:06:49 GMT""}]","2022-01-11"
"2006.11261","Adriana Salerno","Adriana Salerno and Ursula Whitcher","Hasse--Witt matrices and mirror toric pencils",,,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mirror symmetry suggests unexpected relationships between arithmetic
properties of distinct families of algebraic varieties. For example, Wan and
others have shown that for some mirror pairs, the number of rational points
over a finite field matches modulo the order of the field. In this paper, we
obtain a similar result for certain mirror pairs of toric hypersurfaces. We use
recent results by Huang, Lian, Yau and Yu describing the relationship between
the Picard-Fuchs equations of these varieties and their Hasse--Witt matrices,
which encapsulate information about the number of points. The result allows us
to compute the number of points modulo the order of the field explicitly. We
illustrate this by computing K3 surface examples related to hypergeometric
functions.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:50:09 GMT""},{""version"":""v2"",""created"":""Tue, 1 Feb 2022 16:07:39 GMT""}]","2022-02-02"
"2006.11262","Csaba D. Toth","Fabrizio Frati, Michael Hoffmann, Csaba D. T\'oth","Universal Geometric Graphs","20 pages, 8 figures; a 12-page extended abstracts of this paper will
  appear in the Proceedings of the 46th Workshop on Graph-Theoretic Concepts in
  Computer Science (WG 2020)",,,,"math.CO cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce and study the problem of constructing geometric graphs that have
few vertices and edges and that are universal for planar graphs or for some
sub-class of planar graphs; a geometric graph is \emph{universal} for a class
$\mathcal H$ of planar graphs if it contains an embedding, i.e., a
crossing-free drawing, of every graph in $\mathcal H$.
  Our main result is that there exists a geometric graph with $n$ vertices and
$O(n \log n)$ edges that is universal for $n$-vertex forests; this extends to
the geometric setting a well-known graph-theoretic result by Chung and Graham,
which states that there exists an $n$-vertex graph with $O(n \log n)$ edges
that contains every $n$-vertex forest as a subgraph. Our $O(n \log n)$ bound on
the number of edges cannot be improved, even if more than $n$ vertices are
allowed.
  We also prove that, for every positive integer $h$, every $n$-vertex convex
geometric graph that is universal for $n$-vertex outerplanar graphs has a
near-quadratic number of edges, namely $\Omega_h(n^{2-1/h})$; this almost
matches the trivial $O(n^2)$ upper bound given by the $n$-vertex complete
convex geometric graph.
  Finally, we prove that there exists an $n$-vertex convex geometric graph with
$n$ vertices and $O(n \log n)$ edges that is universal for $n$-vertex
caterpillars.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:50:28 GMT""}]","2020-06-22"
"2006.11263","Adam Pound","Jeremy Miller and Adam Pound","Two-timescale evolution of extreme-mass-ratio inspirals: waveform
  generation scheme for quasicircular orbits in Schwarzschild spacetime","41 pages, 3 figures. The third version corrects more typos","Phys. Rev. D 103, 064048 (2021)","10.1103/PhysRevD.103.064048",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extreme-mass-ratio inspirals, in which a stellar-mass compact object spirals
into a supermassive black hole in a galactic core, are expected to be key
sources for LISA. Modelling these systems with sufficient accuracy for LISA
science requires going to second (or {\em post-adiabatic}) order in
gravitational self-force theory. Here we present a practical two-timescale
framework for achieving this and generating post-adiabatic waveforms. The
framework comprises a set of frequency-domain field equations that apply on the
fast, orbital timescale, together with a set of ordinary differential equations
that determine the evolution on the slow, inspiral timescale. Our analysis is
restricted to the special case of quasicircular orbits around a Schwarzschild
black hole, but its general structure carries over to the realistic case of
generic (inclined and eccentric) orbits in Kerr spacetime. In our restricted
context, we also develop a tool that will be useful in all cases: a formulation
of the frequency-domain field equations using hyperboloidal slicing, which
significantly improves the behavior of the sources near the boundaries. We give
special attention to the slow evolution of the central black hole, examining
its impact on both the two-timescale evolution and the earlier self-consistent
evolution scheme.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:51:08 GMT""},{""version"":""v2"",""created"":""Tue, 18 Aug 2020 12:27:32 GMT""},{""version"":""v3"",""created"":""Wed, 24 Feb 2021 23:58:55 GMT""}]","2021-03-31"
"2006.11264","Bartosz Fornal","Bartosz Fornal, Pearl Sandick, Jing Shu, Meng Su, Yue Zhao","Boosted Dark Matter Interpretation of the XENON1T Excess","5 pages, 2 figures; v2: Extended discussion of the predicted daily
  modulation of the signal","Phys. Rev. Lett. 125, 161804 (2020)","10.1103/PhysRevLett.125.161804",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose boosted dark matter (BDM) as a possible explanation for the excess
of keV electron recoil events observed by XENON1T. BDM particles have
velocities much larger than those typical of virialized dark matter, and, as
such, BDM-electron scattering can naturally produce keV electron recoils. We
show that the required BDM-electron scattering cross sections can be easily
realized in a simple model with a heavy vector mediator. Though these cross
sections are too large for BDM to escape from the Sun, the BDM flux can
originate from the Galactic Center or from halo dark matter annihilations.
Furthermore, a daily modulation of the BDM signal will be present, which could
not only be used to differentiate it from various backgrounds, but would also
provide important directional information for the BDM flux.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:51:37 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 07:59:02 GMT""}]","2020-10-15"
"2006.11265","Matteo Iacopini","Matteo Iacopini and Francesco Ravazzolo and Luca Rossini","Proper scoring rules for evaluating asymmetry in density forecasting",,,,,"stat.ME econ.EM stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a novel asymmetric continuous probabilistic score (ACPS)
for evaluating and comparing density forecasts. It extends the proposed score
and defines a weighted version, which emphasizes regions of interest, such as
the tails or the center of a variable's range. A test is also introduced to
statistically compare the predictive ability of different forecasts. The ACPS
is of general use in any situation where the decision maker has asymmetric
preferences in the evaluation of the forecasts. In an artificial experiment,
the implications of varying the level of asymmetry in the ACPS are illustrated.
Then, the proposed score and test are applied to assess and compare density
forecasts of macroeconomic relevant datasets (US employment growth) and of
commodity prices (oil and electricity prices) with particular focus on the
recent COVID-19 crisis period.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:53:02 GMT""},{""version"":""v2"",""created"":""Tue, 1 Sep 2020 14:17:35 GMT""}]","2020-09-02"
"2006.11266","Dibya Ghosh","Dibya Ghosh, Marlos C. Machado, Nicolas Le Roux","An operator view of policy gradient methods","NeurIPS 2020",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We cast policy gradient methods as the repeated application of two operators:
a policy improvement operator $\mathcal{I}$, which maps any policy $\pi$ to a
better one $\mathcal{I}\pi$, and a projection operator $\mathcal{P}$, which
finds the best approximation of $\mathcal{I}\pi$ in the set of realizable
policies. We use this framework to introduce operator-based versions of
traditional policy gradient methods such as REINFORCE and PPO, which leads to a
better understanding of their original counterparts. We also use the
understanding we develop of the role of $\mathcal{I}$ and $\mathcal{P}$ to
propose a new global lower bound of the expected return. This new perspective
allows us to further bridge the gap between policy-based and value-based
methods, showing how REINFORCE and the Bellman optimality operator, for
example, can be seen as two sides of the same coin.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:55:07 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 14:48:01 GMT""},{""version"":""v3"",""created"":""Thu, 22 Oct 2020 23:16:04 GMT""}]","2020-10-26"
"2006.11267","Geoff Pleiss","Geoff Pleiss, Martin Jankowiak, David Eriksson, Anil Damle, Jacob R.
  Gardner","Fast Matrix Square Roots with Applications to Gaussian Processes and
  Bayesian Optimization","NeurIPS 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Matrix square roots and their inverses arise frequently in machine learning,
e.g., when sampling from high-dimensional Gaussians $\mathcal{N}(\mathbf 0,
\mathbf K)$ or whitening a vector $\mathbf b$ against covariance matrix
$\mathbf K$. While existing methods typically require $O(N^3)$ computation, we
introduce a highly-efficient quadratic-time algorithm for computing $\mathbf
K^{1/2} \mathbf b$, $\mathbf K^{-1/2} \mathbf b$, and their derivatives through
matrix-vector multiplication (MVMs). Our method combines Krylov subspace
methods with a rational approximation and typically achieves $4$ decimal places
of accuracy with fewer than $100$ MVMs. Moreover, the backward pass requires
little additional computation. We demonstrate our method's applicability on
matrices as large as $50,\!000 \times 50,\!000$ - well beyond traditional
methods - with little approximation error. Applying this increased scalability
to variational Gaussian processes, Bayesian optimization, and Gibbs sampling
results in more powerful models with higher accuracy.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:56:24 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 21:52:07 GMT""}]","2020-12-02"
"2006.11268","Dale Harshman","Dale R. Harshman and Anthony T. Fiory","High-$T$$_\textrm{C}$ Superconductivity in Hydrogen Clathrates Mediated
  by Coulomb Interactions between Hydrogen and Central-Atom Electrons","25 pages, 9 figures, 3 tables",,"10.1007/s10948-020-05557-4",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The uniquely characteristic macrostructures of binary hydrogen-clathrate
compounds $M$H$_\textrm{n}$ formed at high pressure, a cage of hydrogens
surrounding a central-atom host, is theoretically predicted in various studies
to include structurally stable phonon-mediated superconductors. High
superconductive transition temperatures $T$$_\textrm{C}$ have thus far been
measured for syntheses with $M$ = La, Y, and Th. In compressed
LaH$_\textrm{10}$, independent studies report $T$$_\textrm{C}$ of 250 K and
over 260 K, a maximum in $T$$_\textrm{C}$ with pressure $P$, and normal-state
resistance scaling with temperature (suggesting unconventional pairing).
According to reported band structure calculations of $Fm$$\bar{3}$$m$-phase
LaH$_\textrm{10}$, the La is anionic, with the chemical valence electrons
appearing evenly split between La and H$_\textrm{10}$. Thus, compressed
LaH$_\textrm{10}$ contains the combination of structure, charge separation, and
optimal balanced allocation of valence electrons for supporting unconventional
high-$T$$_\textrm{C}$ superconductivity mediated by Coulomb interactions
between electronic charges associated with La and H$_\textrm{10}$. A general
expression for the optimal superconducting transition temperature for
$M$H$_\textrm{n}$ clathrates is derived as $T$$_\textrm{C0}$ =
$k$$_\textrm{B}$$^{-1}$$\Lambda$[(n + $v$)/2$A$]$^{1/2}$$e$$^{2}$/$\zeta$,
where $\Lambda$ is a universal constant, (n + $v$) is the chemical valence sum
per formula unit, taking unity for H and $v$ for atom $M$, $A$ is the surface
area of the H-polyhedron cage, and $\zeta$ is the mean distance between the $M$
site and the centroids of the polyhedron faces. Applied to $Fm$$\bar{3}$$m$
LaH$_\textrm{10}$, $T$$_\textrm{C0}$ values of 249.8(1.3) K and 260.7(2.0) K
are found for the two experiments. Associated attributes of charge allocation,
structure, effective Coulomb potential, . . .
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:58:00 GMT""}]","2020-06-22"
"2006.11269","Nathan Jones","Hao Chen, Nathan Jones, Vlad Serban","The Lang-Trotter Conjecture for products of non-CM elliptic curves",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by the work of Lang-Trotter on the densities of primes with fixed
Frobenius traces for elliptic curves defined over $\mathbb{Q}$ and by the
subsequent generalization of Cojocaru-Davis-Silverberg-Stange to generic
abelian varieties, we study the analogous question for abelian surfaces
isogenous to products of non-CM elliptic curves over $\mathbb{Q}$. We formulate
the corresponding conjectural asymptotic, provide upper bounds, and explicitly
compute (when the elliptic curves lie outside a thin set) the arithmetically
significant constants appearing in the asymptotic. This allows us to provide
computational evidence for the conjecture.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:58:13 GMT""}]","2020-06-22"
"2006.11270","Sayantari Ghosh","Sayantari Ghosh and Saumik Bhattacharya","Computational model on COVID-19 Pandemic using Probabilistic Cellular
  Automata","13 pages, 6 Figures",,,,"physics.soc-ph cs.SI nlin.CG q-bio.PE q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coronavirus disease (COVID-19) which is caused by SARS-COV2 has become a
pandemic. This disease is highly infectious and potentially fatal, causing a
global public health concern. To contain the spread of COVID-19, governments
are adopting nationwide interventions, like lockdown, containment and
quarantine, restrictions on travel, cancelling social events and extensive
testing. To understand the effects of these measures on the control of the
epidemic in a data-driven manner, we propose a probabilistic cellular automata
(PCA) based modified SEIQR model. The transitions associated with the model is
driven by data available on chronology, symptoms, pathogenesis and
transmissivity of the virus. By arguing that the lattice-based model captures
the features of the dynamics along with the existing fluctuations, we perform
rigorous computational analyses of the model to take into account of the
spatial dynamics of social distancing measures imposed on the people.
Considering the probabilistic behavioural aspects associated with mitigation
strategies, we study the model considering factors like population density and
testing efficiency. Using the model, we focus on the variability of epidemic
dynamics data for different countries and point out the reasons behind these
contrasting observations. To the best of our knowledge, this is the first
attempt to model COVID-19 spread using PCA that gives us both spatial and
temporal variations of the infection spread with the insight about the
contributions of different infection parameters.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:58:14 GMT""}]","2020-06-22"
"2006.11271","Daniel Sch\""onke","Daniel Sch\""onke, Robert M. Reeve, Hermann Stoll, Mathias Kl\""aui","Quantification of competing magnetic states and switching pathways in
  curved nanowires by direct dynamic imaging",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For viable applications, spintronic devices based e.g. on domain wall motion
need to be highly reliable with stable magnetization states and highly
reproducible switching pathways transforming one state to another. The
existence of multiple stable states and switching pathways in a system is a
definitive barrier for device operation, yet rare and stochastic events are
difficult to detect and understand. We demonstrate an approach to quantify
competing magnetic states and stochastic switching pathways based on
time-resolved scanning electron microscopy with polarization analysis, applied
to the technologically relevant control of vortex domain wall chirality via
field and curvature in curved wires. While being a pump-probe technique, our
analysis scheme nonetheless allows for the disentanglement of different
occurring dynamic pathways and we can even identify the rare events leading to
changes from one magnetization switching pathway to another pathway via
temperature- and geometry-dependent measurements. The experimental imaging is
supported by micromagnetic simulations to reveal the mechanisms responsible for
the change of the pathway. Together the results allow us to explain the origin
and details of the domain wall chirality control and to quantify the frequency
and the associated energy barriers of thermally activated changes of the states
and switching pathways.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:58:30 GMT""}]","2020-06-22"
"2006.11274","Ruosong Wang","Ruosong Wang, Simon S. Du, Lin F. Yang, Ruslan Salakhutdinov","On Reward-Free Reinforcement Learning with Linear Function Approximation",,,,,"cs.LG cs.AI math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reward-free reinforcement learning (RL) is a framework which is suitable for
both the batch RL setting and the setting where there are many reward functions
of interest. During the exploration phase, an agent collects samples without
using a pre-specified reward function. After the exploration phase, a reward
function is given, and the agent uses samples collected during the exploration
phase to compute a near-optimal policy. Jin et al. [2020] showed that in the
tabular setting, the agent only needs to collect polynomial number of samples
(in terms of the number states, the number of actions, and the planning
horizon) for reward-free RL. However, in practice, the number of states and
actions can be large, and thus function approximation schemes are required for
generalization. In this work, we give both positive and negative results for
reward-free RL with linear function approximation. We give an algorithm for
reward-free RL in the linear Markov decision process setting where both the
transition and the reward admit linear representations. The sample complexity
of our algorithm is polynomial in the feature dimension and the planning
horizon, and is completely independent of the number of states and actions. We
further give an exponential lower bound for reward-free RL in the setting where
only the optimal $Q$-function admits a linear representation. Our results imply
several interesting exponential separations on the sample complexity of
reward-free RL.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:59:36 GMT""}]","2020-06-22"
"2006.11275","Tianwei Yin","Tianwei Yin, Xingyi Zhou, Philipp Kr\""ahenb\""uhl","Center-based 3D Object Detection and Tracking","update nuScenes and Waymo results","Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR) 2021",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three-dimensional objects are commonly represented as 3D boxes in a
point-cloud. This representation mimics the well-studied image-based 2D
bounding-box detection but comes with additional challenges. Objects in a 3D
world do not follow any particular orientation, and box-based detectors have
difficulties enumerating all orientations or fitting an axis-aligned bounding
box to rotated objects. In this paper, we instead propose to represent, detect,
and track 3D objects as points. Our framework, CenterPoint, first detects
centers of objects using a keypoint detector and regresses to other attributes,
including 3D size, 3D orientation, and velocity. In a second stage, it refines
these estimates using additional point features on the object. In CenterPoint,
3D object tracking simplifies to greedy closest-point matching. The resulting
detection and tracking algorithm is simple, efficient, and effective.
CenterPoint achieved state-of-the-art performance on the nuScenes benchmark for
both 3D detection and tracking, with 65.5 NDS and 63.8 AMOTA for a single
model. On the Waymo Open Dataset, CenterPoint outperforms all previous single
model method by a large margin and ranks first among all Lidar-only
submissions. The code and pretrained models are available at
https://github.com/tianweiy/CenterPoint.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:59:39 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 18:56:03 GMT""}]","2021-10-11"
"2006.11276","Yadira Gaibor","Yadira Gaibor, Peter Garnavich, Colin Littlefield, Stephen B. Potter,
  David A. H. Buckley","An Improved Spin-Down Rate for the Proposed White-Dwarf Pulsar AR
  Scorpii","9 pages, 8 figures, 3 tables. Accepted for publication in MNRAS","Monthly Notices of the Royal Astronomical Society, Volume 496,
  Issue 4, August 2020, Pages 4849 to 4856","10.1093/mnras/staa1901",,"astro-ph.SR astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze rapid-cadence, multiwavelength photometry of AR Scorpii from three
observatories, covering five observing seasons. We measure the arrival times of
the system's beat pulses and use them to compute an updated ephemeris. The
white dwarf spin-down rate is estimated with an uncertainty of only 4%. These
results confirm, beyond any doubt, that the white dwarf's spin period is
increasing at the rate consistent with by that of Stiller et al. (2018). We
study the evolution of the beat pulse's color index across the orbit. The color
of the primary pulse maxima varies significantly across the orbit, with the
peaks being bluer after superior conjunction than in the first half of the
orbit. Specifically, at orbital phase 0.5, the color index of the primary pulse
shows a very sharp discontinuity towards bluer indices. This supports the
Potter & Buckley (2018b) synchrotron emission model where the two emitting
poles differ significantly in color. However, no corresponding jump in the
color of the secondary pulses is seen. Furthermore, our analysis reveals that
the arrival times of the pulses can differ by as much as 6s in simultaneous $u$
and $r$ photometry, depending on the binary orbital phase. If left uncorrected,
this wavelength-dependent timing offset could lead to erroneous measurements of
the spin-period derivative, particularly with heterogeneous datasets.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:59:59 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jul 2020 22:20:50 GMT""}]","2020-07-31"
"2006.11283","Derya Malak","Derya Malak and Muriel M\'edard and Jeffrey G. Andrews","Spatial Concentration of Caching in Wireless Heterogeneous Networks","to appear, IEEE TWC. arXiv admin note: text overlap with
  arXiv:1901.11102",,,,"cs.IT cs.NI math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a decentralized caching policy for wireless heterogeneous networks
that makes content placement decisions based on pairwise interactions between
cache nodes. We call our proposed scheme {\gamma}-exclusion cache placement
(GEC), where a parameter {\gamma} controls an exclusion radius that discourages
nearby caches from storing redundant content. GEC takes into account item
popularity and the nodes' caching priorities and leverages negative dependence
to relax the classic 0-1 knapsack problem to yield spatially balanced sampling
across caches. We show that GEC guarantees a better concentration (reduced
variance) of the required cache storage size than the state of the art, and
that the cache size constraints can be satisfied with high probability. Given a
cache hit probability target, we compare the 95\% confidence intervals of the
required cache sizes for three caching schemes: (i) independent placement, (ii)
hard exclusion caching (HEC), and (iii) the proposed GEC approach. For uniform
spatial traffic, we demonstrate that GEC provides approximately a 3x and 2x
reduction in required cache size over (i) and (ii), respectively. For
non-uniform spatial traffic based on realistic peak-hour variations in urban
scenarios, the gains are even greater.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:17:11 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 23:39:18 GMT""}]","2021-01-08"
"2006.11284","Omid Jafari","Omid Jafari, Parth Nagarkar, Jonathan Monta\~no","Improving Locality Sensitive Hashing by Efficiently Finding Projected
  Nearest Neighbors","arXiv admin note: text overlap with arXiv:2003.06415","SISAP 2020. Lecture Notes in Computer Science, vol 12440.
  Springer, Cham","10.1007/978-3-030-60936-8_25",,"cs.DB cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Similarity search in high-dimensional spaces is an important task for many
multimedia applications. Due to the notorious curse of dimensionality,
approximate nearest neighbor techniques are preferred over exact searching
techniques since they can return good enough results at a much better speed.
Locality Sensitive Hashing (LSH) is a very popular random hashing technique for
finding approximate nearest neighbors. Existing state-of-the-art Locality
Sensitive Hashing techniques that focus on improving performance of the overall
process, mainly focus on minimizing the total number of IOs while sacrificing
the overall processing time. The main time-consuming process in LSH techniques
is the process of finding neighboring points in projected spaces. We present a
novel index structure called radius-optimized Locality Sensitive Hashing
(roLSH). With the help of sampling techniques and Neural Networks, we present
two techniques to find neighboring points in projected spaces efficiently,
without sacrificing the accuracy of the results. Our extensive experimental
analysis on real datasets shows the performance benefit of roLSH over existing
state-of-the-art LSH techniques.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:46:30 GMT""}]","2020-10-16"
"2006.11285","Omid Jafari","Omid Jafari, Parth Nagarkar","Experimental Analysis of Locality Sensitive Hashing Techniques for
  High-Dimensional Approximate Nearest Neighbor Searches","arXiv admin note: text overlap with arXiv:2003.06415","ADC 2021. Lecture Notes in Computer Science, vol. 12610. Springer,
  Cham, pp. 62-73","10.1007/978-3-030-69377-0_6",,"cs.DB cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding nearest neighbors in high-dimensional spaces is a fundamental
operation in many multimedia retrieval applications. Exact tree-based indexing
approaches are known to suffer from the notorious curse of dimensionality for
high-dimensional data. Approximate searching techniques sacrifice some accuracy
while returning good enough results for faster performance. Locality Sensitive
Hashing (LSH) is a very popular technique for finding approximate nearest
neighbors in high-dimensional spaces. Apart from providing theoretical
guarantees on the query results, one of the main benefits of LSH techniques is
their good scalability to large datasets because they are external memory
based. The most dominant costs for existing LSH techniques are the algorithm
time and the index I/Os required to find candidate points. Existing works do
not compare both of these dominant costs in their evaluation. In this
experimental survey paper, we show the impact of both these costs on the
overall performance of the LSH technique. We compare three state-of-the-art
techniques on four real-world datasets, and show that, in contrast to recent
works, C2LSH is still the state-of-the-art algorithm in terms of performance
while achieving similar accuracy as its recent competitors.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:57:41 GMT""}]","2021-02-16"
"2006.11286","Jakub Klencki","J. Klencki, G. Nelemans, A. G. Istrate, M. Chruslinska","It has to be cool: on supergiant progenitors of binary black hole
  mergers from common-envelope evolution","20 pages + App., accepted for publication in A&A. For $\lambda_{\rm
  CE}$ fits, see: https://ftp.science.ru.nl/astro/jklencki/","A&A 645, A54 (2021)","10.1051/0004-6361/202038707",,"astro-ph.SR astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Common-envelope (CE) evolution in massive binary systems is thought to be one
of the most promising channels for the formation of compact binary mergers. In
the case of merging binary black holes (BBHs), the essential CE phase takes
place at a stage when the first BH is already formed and the companion star
expands as a supergiant. We study which BH binaries with supergiant companions
will evolve through and potentially survive a CE phase. To this end, we compute
envelope binding energies from detailed massive stellar models at different
evolutionary stages and metallicities. We make multiple physically extreme
choices of assumptions that favor easier CE ejection as well as account for
recent advancements in mass transfer stability criteria. We find that even with
the most optimistic assumptions, a successful CE ejection in BH (and also NS)
binaries is only possible if the donor is a massive convective-envelope giant,
a red supergiant (RSG). In other words, pre-CE progenitors of BBH mergers are
BH binaries with RSG companions. We find that due to its influence on the
radial expansion of massive giants, metallicity has an indirect but a very
strong effect on the envelope structure and binding energies of RSGs. Our
results suggest that merger rates from population synthesis models could be
severely overestimated, especially at low metallicity. Additionally, the lack
of observed RSGs with luminosities above log($L/L_{\odot}$) = 5.6-5.8,
corresponding to stars with $M > 40 M_{\odot}$, puts into question the
viability of the CE channel for the formation of the most massive BBH mergers.
Either such RSGs elude detection due to very short lifetimes, or they do not
exist and the CE channel can only produce BBH systems with total mass $< 50
M_{\odot}$. We discuss an alternative CE scenario, in which a partial envelope
ejection is followed by a phase of possibly long and stable mass transfer.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 12 Oct 2020 05:52:54 GMT""}]","2021-01-13"
"2006.11287","Miles Cranmer","Miles Cranmer, Alvaro Sanchez-Gonzalez, Peter Battaglia, Rui Xu, Kyle
  Cranmer, David Spergel, Shirley Ho","Discovering Symbolic Models from Deep Learning with Inductive Biases","Accepted to NeurIPS 2020. 9 pages content + 16 pages
  appendix/references. Supporting code found at
  https://github.com/MilesCranmer/symbolic_deep_learning",,,,"cs.LG astro-ph.CO astro-ph.IM physics.comp-ph stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a general approach to distill symbolic representations of a
learned deep model by introducing strong inductive biases. We focus on Graph
Neural Networks (GNNs). The technique works as follows: we first encourage
sparse latent representations when we train a GNN in a supervised setting, then
we apply symbolic regression to components of the learned model to extract
explicit physical relations. We find the correct known equations, including
force laws and Hamiltonians, can be extracted from the neural network. We then
apply our method to a non-trivial cosmology example-a detailed dark matter
simulation-and discover a new analytic formula which can predict the
concentration of dark matter from the mass distribution of nearby cosmic
structures. The symbolic expressions extracted from the GNN using our technique
also generalized to out-of-distribution data better than the GNN itself. Our
approach offers alternative directions for interpreting neural networks and
discovering novel physical principles from the representations they learn.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 18 Nov 2020 01:16:09 GMT""}]","2020-11-19"
"2006.11288","Julia Becker Tjus","O. de Bruijn, I. Bartos, P.L. Biermann and J. Becker Tjus","Recurrent Neutrino Emission from Supermassive Black Hole Mergers","6 pages, 3 figures, submitted",,"10.3847/2041-8213/abc950",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent detection of possible neutrino emission from the blazar TXS
0506+056 was the first high-energy neutrino associated with an astrophysical
source, making this special type of active galaxies promising neutrino
emitters. The fact that two distinct episodes of neutrino emission were
detected with a separation of around 3 years suggests that emission could be
periodic. Periodic emission is expected from supermassive binary black hole
systems due to jet precession close to the binary's merger. Here we show that
if TXS 0506+056 is a binary source then the next neutrino flare could occur
before the end of 2021. We derive the binary properties that would lead to the
detection of gravitational waves from this system by LISA. Our results for the
first time quantify the time scale of these correlations for the example of TXS
0506+056, providing clear predictions for both the neutrino and
gravitational-wave signatures of such sources.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:01 GMT""}]","2020-12-23"
"2006.11290","Georgios K. Karananas Dr.","Georgios K.Karananas, Marco Michel, Javier Rubio","One residue to rule them all: Electroweak symmetry breaking, inflation
  and field-space geometry","Journal version---discussion extended, typos corrected, references
  added","Phys. Lett. B 811 (2020) 135876","10.1016/j.physletb.2020.135876","LMU-ASC 29/20, MPP-2020-102, HIP-2020-19/TH","hep-th astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We point out that the successful generation of the electroweak scale via
gravitational instanton configurations in certain scalar-tensor theories can be
viewed as the aftermath of a simple requirement: the existence of a quadratic
pole with a sufficiently small residue in the Einstein-frame kinetic term for
the Higgs field. In some cases, the inflationary dynamics may also be
controlled by this residue and therefore related to the Fermi-to-Planck mass
ratio, up to possible uncertainties associated with the instanton
regularization. We present here a unified framework for this hierarchy
generation mechanism, showing that the aforementioned residue can be associated
with the curvature of the Einstein-frame target manifold in models displaying
spontaneous breaking of dilatations. Our findings are illustrated through
examples previously considered in the literature.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Mon, 2 Nov 2020 13:16:08 GMT""}]","2020-11-03"
"2006.11291","Nadine Stritzelberger","Nadine Stritzelberger, Laura J. Henderson, Valentina Baccetti, Nicolas
  C. Menicucci, and Achim Kempf","Entanglement harvesting with coherently delocalized matter",,"Phys. Rev. D 103, 016007 (2021)","10.1103/PhysRevD.103.016007",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study entanglement harvesting for matter systems such as atoms, ions or
molecules, whose center of mass degrees of freedom are quantum delocalized and
which couple to a relativistic quantum field. We employ a generalized
Unruh-deWitt detector model for the light-matter interaction, and we
investigate how the coherent spreading of the quantum center of mass wave
function of two delocalized detector systems impacts their ability to become
entangled with one another, via their respective interaction with a quantum
field. For very massive detectors with initially highly localized centers of
mass, we recover the results of entanglement harvesting for pointlike
Unruh-deWitt detectors with classical center of mass degrees of freedom. We
find that entanglement harvesting is Gaussian suppressed in the initial center
of mass delocalization of the detectors. We further find that spatial smearing
profiles, which are commonly employed to model the finite size of atoms due to
their atomic orbitals, are not suited to model center of mass delocalization.
Finally, for coherently delocalized detectors, we compare entanglement
harvesting in the vacuum to entanglement harvesting in media. We find that
entanglement harvesting is significantly suppressed in media in which the wave
propagation speed is much smaller than the vacuum speed of light.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:02 GMT""}]","2021-01-13"
"2006.11292","Luke Corcoran","Luke Corcoran and Matthias Staudacher","The Dual Conformal Box Integral in Minkowski Space","40 pages, 9 figures. v2 - added preprint # and acknowledgement. v3 -
  fixed typos/revised introduction, mentioned relation to integrability",,"10.1016/j.nuclphysb.2021.115310",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  The dual conformal box integral in Minkowski space is not fully determined by
the conformal invariants $z$ and $\bar{z}$. Depending on the kinematic region
its value is on a 'branch' of the Bloch-Wigner function which occurs in the
Euclidean case. Dual special conformal transformations in Minkowski space can
change the kinematic region in such a way that the value of the integral jumps
to another branch of this function, encoding a subtle breaking of dual
conformal invariance for the integral. We classify conformally equivalent
configurations of four points in compactified Minkowski space. We show that
starting with any configuration, one can reach up to four branches of the
integral using dual special conformal transformations. We also show that most
configurations with real $z$ and $\bar{z}$ can be conformally mapped to a
configuration in the same kinematic region with two points at infinity, where
the box integral can be calculated directly in Minkowski space using only the
residue theorem.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 15:14:18 GMT""},{""version"":""v3"",""created"":""Fri, 25 Sep 2020 14:39:14 GMT""}]","2021-02-24"
"2006.11293","Michael Zevin","Michael Zevin, Christopher P. L. Berry, Scott Coughlin, Katerina
  Chatziioannou, Salvatore Vitale","You Can't Always Get What You Want: The Impact of Prior Assumptions on
  Interpreting GW190412","12 pages, 2 figures, 1 table, published in ApJL","The Astrophysical Journal Letters 899, L17 (2020)","10.3847/2041-8213/aba8ef","LIGO-P2000181","astro-ph.HE astro-ph.SR gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  GW190412 is the first observation of a black hole binary with definitively
unequal masses. GW190412's mass asymmetry, along with the measured positive
effective inspiral spin, allowed for inference of a component black hole spin:
the primary black hole in the system was found to have a dimensionless spin
magnitude between 0.17 and 0.59 (90% credible range). We investigate how the
choice of priors for the spin magnitudes and tilts of the component black holes
affect the robustness of parameter estimates for GW190412, and report Bayes
factors across a suite of prior assumptions. Depending on the waveform family
used to describe the signal, we find either marginal to moderate (2:1-6:1) or
strong ($\gtrsim$ 20:1) support for the primary black hole being spinning
compared to cases where only the secondary is allowed to have spin. We show how
these choices influence parameter estimates, and find the asymmetric masses and
positive effective inspiral spin of GW190412 to be qualitatively, but not
quantitatively, robust to prior assumptions. Our results highlight the
importance of both considering astrophysically motivated or population-based
priors in interpreting observations and considering their relative support from
the data.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:05 GMT""},{""version"":""v2"",""created"":""Tue, 11 Aug 2020 18:46:47 GMT""}]","2020-08-13"
"2006.11294","Wolfgang Ziller","Luigi Verdiani, Wolfgang Ziller","Curvature homogeneous manifolds in dimension 4","Final version, to appear in Transformation Groups",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify complete curvature homogeneous metrics on simply connected four
dimensional manifolds which are invariant under a cohomogeneity one action. We
show that they are either isometric to a symmetric space with one of its
cohomogeneity one actions, or to a complete example by Tsukada on the normal
bundle of the Veronese surface in CP^2. Along the way we show (in any
dimension) that via an equivariant diffeomorphism the functions describing the
metric can be partially diagonalized, a fact that may be useful for other
problems as well
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:06 GMT""},{""version"":""v2"",""created"":""Mon, 19 Oct 2020 13:40:26 GMT""}]","2020-10-20"
"2006.11295","Antonios Alvertis","Antonios M. Alvertis, Raj Pandya, Claudio Quarti, Laurent Legrand,
  Thierry Barisien, Bartomeu Monserrat, Andrew J. Musser, Akshay Rao, Alex W.
  Chin and David Beljonne","First principles modeling of exciton-polaritons in polydiacetylene
  chains",,,"10.1063/5.0019009",,"cond-mat.mtrl-sci physics.chem-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exciton-polaritons in organic materials are hybrid states that result from
the strong interaction of photons and the bound excitons that these materials
host. Organic polaritons hold great interest for optoelectronic applications,
however progress towards this end has been impeded by the lack of a first
principles approach that quantifies light-matter interactions in these systems,
and which would allow the formulation of molecular design rules. Here we
develop such a first principles approach, quantifying light-matter
interactions. We exemplify our approach by studying variants of the conjugated
polymer polydiacetylene, and we show that a large polymer conjugation length is
critical towards strong exciton-photon coupling, hence underlying the
importance of pure structures without static disorder. By comparing to our
experimental reflectivity measurements, we show that the coupling of excitons
to vibrations, manifested by phonon side bands in the absorption, has a strong
impact on the magnitude of light-matter coupling over a range of frequencies.
Our approach opens the way towards a deeper understanding of polaritons in
organic materials, and we highlight that a quantitatively accurate calculation
of the exciton-photon interaction would require accounting for all sources of
disorder self-consistently.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:08 GMT""}]","2020-09-07"
"2006.11296","Christer Sandin","Christer Sandin and Lars Mattsson","Three-component modelling of C-rich AGB star winds V. Effects of
  frequency-dependent radiative transfer including drift","32 pages, 19 figures, accepted for publication in MNRAS","Mon. Not. R. Astron. Soc. 499 (2020) 1531-1560","10.1093/mnras/staa2714","NORDITA-2020-062","astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stellar winds of cool carbon stars enrich the interstellar medium with
significant amounts of carbon and dust. We present a study of the influence of
two-fluid flow on winds where we add descriptions of frequency-dependent
radiative transfer. Our radiation hydrodynamic models in addition include
stellar pulsations, grain growth and ablation, gas-to-dust drift using one mean
grain size, dust extinction based on both the small particle limit and Mie
scattering, and an accurate numerical scheme. We calculate models at high
spatial resolution using 1024 gridpoints and solar metallicities at 319
frequencies, and we discern effects of drift by comparing drift models to
non-drift models. Our results show differences of up to 1000 per cent in
comparison to extant results. Mass-loss rates and wind velocities of drift
models are typically, but not always, lower than in non-drift models.
Differences are larger when Mie scattering is used instead of the small
particle limit. Amongst other properties, the mass-loss rates of the gas and
dust, dust-to-gas density ratio, and wind velocity show an exponential
dependence on the dust-to-gas speed ratio. Yields of dust in the least massive
winds increase by a factor four when drift is used. We find drift velocities in
the range 10-67 km/s, which is drastically higher than in our earlier works
that use grey radiative transfer. It is necessary to include an estimate of
drift velocities to reproduce high yields of dust and low wind velocities.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:09 GMT""},{""version"":""v2"",""created"":""Fri, 4 Sep 2020 07:24:48 GMT""}]","2020-10-20"
"2006.11297","Rossana Ruggeri","Rossana Ruggeri and Chris Blake","Compressing combined probes: redshift weights for joint lensing and
  clustering analyses","9 pages, 7 figures",,"10.1093/mnras/staa2537",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Combining different observational probes, such as galaxy clustering and weak
lensing, is a promising technique for unveiling the physics of the Universe
with upcoming dark energy experiments. Whilst this strategy significantly
improves parameter constraints, decreasing the degeneracies of individual
analyses and controlling the systematics, processing data from tens of millions
of galaxies is not a trivial task. In this work we derive and test a new
estimator for joint clustering and lensing data analysis, maximising the
scientific return and decreasing the computational cost. Our estimator
compresses the data by up-weighting the components most sensitive to the
parameters of interest, with no loss of information, taking into account
information from the cross-correlation between the two probes. We derive
optimal redshift weights which may be applied to individual galaxies when
testing a given statistic and cosmological model.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:19 GMT""}]","2020-09-02"
"2006.11298","Xihan Ji","Xihan Ji, Renbin Yan, Rogerio Riffel, Niv Drory, and Kai Zhang","Upper boundaries of AGN regions in optical diagnostic diagrams","17 pages, 19 figures, accepted by MNRAS",,"10.1093/mnras/staa1521",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The distribution of galaxies in optical diagnostic diagrams can provide
information about their physical parameters when compared with ionization
models under proper assumptions. By using a sample of central emitting regions
from the MaNGA survey, we find evidence of the existence of upper boundaries
for narrow-line regions (NLRs) of active galactic nuclei (AGN) in optical BPT
diagrams, especially in the diagrams involving [S II]$\lambda \lambda$6716,
6731/H$\alpha$. Photoionization models can well reproduce the boundaries as a
consequence of the decrease of [S II]$\lambda \lambda$6716, 6731/H$\alpha$ and
[O III]$\lambda$5007/H$\beta$ ratios at very high metallicity. Whilst the exact
location of the upper boundary in the [S II] BPT diagram only weakly depends on
the electron density of the ionized cloud and the secondary nitrogen
prescription, its dependence on the shapes of the input SEDs is much stronger.
This allows us to constrain the power-law index of the AGN SED between 1 Ryd
and $\sim100$ Ryd to be less than or equal to $-1.40\pm 0.05$. The coverage of
the photoionization models in the [N II] BPT diagram has a stronger dependence
on the electron density and the secondary nitrogen prescription. With the
density constrained by the [S II] doublet ratio and the input SED constrained
by the [S II] BPT diagram, we find that the extent of the data in the [N II]
BPT diagram favors those prescriptions with high N/O ratios. Although
shock-ionized cloud can produce similar line ratios as those by
photoionization, the resulting shapes of the upper boundaries, if exist, would
likely be different from those of a photoionizing origin.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:22 GMT""}]","2020-07-01"
"2006.11299","Andrea Colcelli","Andrea Colcelli, Giuseppe Mussardo, German Sierra, Andrea Trombettoni","Dynamics of one-dimensional quantum many-body systems in time-periodic
  linear potentials","22 pages, 4 figures","Phys. Rev. A 102, 033310 (2020)","10.1103/PhysRevA.102.033310",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a system of one-dimensional interacting quantum particles subjected
to a time-periodic potential linear in space. After discussing the cases of
driven one- and two-particles systems, we derive the analogous results for the
many-particles case in presence of a general interaction two-body potential and
the corresponding Floquet Hamiltonian. When the undriven model is integrable,
the Floquet Hamitlonian is shown to be integrable too. We determine the
micro-motion operator and the expression for a generic time evolved state of
the system. We discuss various aspects of the dynamics of the system both at
stroboscopic and intermediate times, in particular the motion of the center of
mass of a generic wavepacket and its spreading over time. We also discuss the
case of accelerated motion of the center of mass, obtained when the integral of
the coeffcient strenght of the linear potential on a time period is
non-vanishing, and we show that the Floquet Hamiltonian gets in this case an
additional static linear potential. We also discuss the application of the
obtained results to the Lieb-Liniger model.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:00:23 GMT""}]","2020-09-16"
"2006.11301","Qidong Xu","Qidong Xu, Shadi Ali Ahmad, Alexander R. H. Smith","Gravitational waves affect vacuum entanglement","6 + 8 pages, 6 figures","Phys. Rev. D 102, 065019 (2020)","10.1103/PhysRevD.102.065019",,"quant-ph gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The entanglement harvesting protocol is an operational way to probe vacuum
entanglement. This protocol relies on two atoms, modelled by Unruh-DeWitt
detectors, that are initially unentangled. These atoms then interact locally
with the field and become entangled. If the atoms remain spacelike separated,
any entanglement between them is a result of entanglement that is `harvested'
from the field. Thus, quantifying this entanglement serves as a proxy for how
entangled the field is across the regions in which the atoms interacted. Using
this protocol, it is demonstrated that while the transition probability of an
individual inertial atom is unaffected by the presence of a gravitational wave,
the entanglement harvested by two atoms depends sensitively on the frequency of
the gravitational wave, exhibiting novel resonance effects when the energy gap
of the detectors is tuned to the frequency of the gravitational wave. This
suggests that the entanglement signature left by a gravitational wave may be
useful in characterizing its properties, and potentially useful in exploring
the gravitational-wave memory effect and gravitational-wave induced
decoherence.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:01:04 GMT""}]","2020-10-07"
"2006.11302","Patrycja {\L}yd\.zba","Patrycja {\L}yd\.zba, Marcos Rigol, Lev Vidmar","Eigenstate Entanglement Entropy in Random Quadratic Hamiltonians",,"Phys. Rev. Lett. 125, 180604 (2020)","10.1103/PhysRevLett.125.180604",,"cond-mat.stat-mech cond-mat.quant-gas cond-mat.str-el hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The eigenstate entanglement entropy has been recently shown to be a powerful
tool to distinguish integrable from generic quantum-chaotic models. In
integrable models, a unique feature of the average eigenstate entanglement
entropy (over all Hamiltonian eigenstates) is that the volume-law coefficient
depends on the subsystem fraction. Hence, it deviates from the maximal
(subsystem fraction independent) value encountered in quantum-chaotic models.
Using random matrix theory for quadratic Hamiltonians, we obtain a closed-form
expression for the average eigenstate entanglement entropy as a function of the
subsystem fraction. We test its correctness against numerical results for the
quadratic Sachdev-Ye-Kitaev model. We also show that it describes the average
entanglement entropy of eigenstates of the power-law random banded matrix model
(in the delocalized regime), and that it is close but not the same as the
result for quadratic models that exhibit localization in quasimomentum space.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:01:15 GMT""},{""version"":""v2"",""created"":""Wed, 4 Nov 2020 09:52:56 GMT""}]","2020-11-05"
"2006.11303","Felix Riehn","Lorenzo Cazon, Ruben Concei\c{c}\~ao, Miguel Alexandre Martins, Felix
  Riehn","Constraining the energy spectrum of neutral pions in ultra-high-energy
  proton-air interactions",,"Phys. Rev. D 103, 022001 (2021)","10.1103/PhysRevD.103.022001",,"astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fluctuations in the muon content of extensive air showers are anticorrelated
to the fluctuations of the energy taken by the neutral pions which emerge from
the first interaction of the cosmic ray in the atmosphere. We show that the
high-energy tail of the neutral pion spectrum produced in the first proton-air
interaction can be constrained, within the uncertainties of present cosmic ray
experiments, through the analysis of the shower-to-shower distribution of the
muon content of the air showers, $P(N_{\mu})$.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:01:51 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jan 2021 15:10:21 GMT""}]","2021-01-12"
"2006.11304","Brian Lacki","Brian C. Lacki, Bryan Brzycki, Steve Croft, Daniel Czech, David
  DeBoer, Julia DeMarines, Vishal Gajjar, Howard Isaacson, Matt Lebofsky, David
  H. E. MacMahon, Danny C. Price, Sofia Z. Sheikh, Andrew P. V. Siemion, Jamie
  Drew and S. Pete Worden","One of Everything: The Breakthrough Listen Exotica Catalog","Corresponds to version published in ApJS. 122 pages (29 pages + full
  appendices and references), 13 tables, 6 figures","ApJS 257, 42 (2021)","10.3847/1538-4365/ac168a",,"astro-ph.IM physics.pop-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present Breakthrough Listen's ""Exotica"" Catalog as the centerpiece of our
efforts to expand the diversity of targets surveyed in the Search for
Extraterrestrial Intelligence (SETI). As motivation, we introduce the concept
of survey breadth, the diversity of objects observed during a program. Several
reasons for pursuing a broad program are given, including increasing the chance
of a positive result in SETI, commensal astrophysics, and characterizing
systematics. The Exotica Catalog is a 963 entry collection of 816 distinct
targets intended to include ""one of everything"" in astronomy. It contains four
samples: the Prototype sample, with an archetype of every known major type of
non-transient celestial object; the Superlative sample of objects with the most
extreme properties; the Anomaly sample of enigmatic targets that are in some
way unexplained; and the Control sample with sources not expected to produce
positive results. As far as we are aware, this is the first object list in
recent times with the purpose of spanning the breadth of astrophysics. We share
it with the community in hopes that it can guide treasury surveys and as a
general reference work. Accompanying the catalog is extensive discussion of
classification of objects and a new classification system for anomalies.
Extensive notes on the objects in the catalog are available online. We discuss
how we intend to proceed with observations in the catalog, contrast it with our
extant Exotica efforts, and suggest similar tactics may be applied to other
programs.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:03:11 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 19:20:14 GMT""}]","2021-12-02"
"2006.11306","Mansi Kasliwal","Mansi M. Kasliwal, Shreya Anand, Tomas Ahumada, Robert Stein, Ana
  Sagues Carracedo, Igor Andreoni, Michael W. Coughlin, Leo P. Singer, Erik C.
  Kool, Kishalay De, Harsh Kumar, Mouza AlMualla, Yuhan Yao, Mattia Bulla,
  Dougal Dobie, Simeon Reusch, Daniel A. Perley, S. Bradley Cenko, Varun
  Bhalerao, David L. Kaplan, Jesper Sollerman, Ariel Goobar, Christopher M.
  Copperwheat, Eric C. Bellm, G.C. Anupama, Alessandra Corsi, Samaya Nissanke,
  Ivan Agudo, Ashot Bagdasaryan, Sudhanshu Barway, Justin Belicki, Joshua S.
  Bloom, Bryce Bolin, David A. H. Buckley, Kevin B. Burdge, Rick Burruss, Maria
  D. Caballero-Garc{\i}a, Chris Cannella, Alberto J. Castro-Tirado, David O.
  Cook, Jeff Cooke, Virginia Cunningham, Aishwarya Dahiwale, Kunal Deshmukh,
  Simone Dichiara, Dmitry A. Duev, Anirban Dutta, Michael Feeney, Anna
  Franckowiak, Sara Frederick, Christoffer Fremling, Avishay Gal-Yam, Pradip
  Gatkine, Shaon Ghosh, Daniel A. Goldstein, V. Zach Golkhou, Matthew J.
  Graham, Melissa L. Graham, Matthew J. Hankins, George Helou, Youdong Hu,
  Wing-Huen Ip, Amruta Jaodand, Viraj Karambelkar, Albert K. H. Kong, Marek
  Kowalski, Maitreya Khandagale, S. R. Kulkarni, Brajesh Kumar, Russ R. Laher,
  K.L. Li, Ashish Mahabal, Frank J. Masci, Adam A. Miller, Moses Mogotsi,
  Siddharth Mohite, Kunal Mooley, Przemek Mroz, Jeffrey A. Newman, Chow-Choong
  Ngeow, Samantha R. Oates, Atharva Sunil Patil, Shashi B. Pandey, M. Pavana,
  Elena Pian, Reed Riddle, Ruben Sanchez-Ram{\i}rez, Yashvi Sharma, Avinash
  Singh, Roger Smith, Maayane T. Soumagnac, Kirsty Taggart, Hanjie Tan,
  Anastasios Tzanidakis, Eleonora Troja, Azamat F. Valeev, Richard Walters,
  Gaurav Waratkar, Sara Webb, Po-Chieh Yu, Bin-Bin Zhang, Rongpu Zhou, and
  Jeffry Zolkower","Kilonova Luminosity Function Constraints based on Zwicky Transient
  Facility Searches for 13 Neutron Star Mergers","Submitted to ApJ",,"10.3847/1538-4357/abc335",,"astro-ph.HE astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a systematic search for optical counterparts to 13 gravitational
wave (GW) triggers involving at least one neutron star during LIGO/Virgo's
third observing run. We searched binary neutron star (BNS) and neutron star
black hole (NSBH) merger localizations with the Zwicky Transient Facility (ZTF)
and undertook follow-up with the Global Relay of Observatories Watching
Transients Happen (GROWTH) collaboration. The GW triggers had a median
localization of 4480 deg^2, median distance of 267 Mpc and false alarm rates
ranging from 1.5 to 1e-25 per yr. The ZTF coverage had a median enclosed
probability of 39%, median depth of 20.8mag, and median response time of 1.5
hr. The O3 follow-up by the GROWTH team comprised 340 UVOIR photometric points,
64 OIR spectra, and 3 radio. We find no promising kilonova
(radioactivity-powered counterpart) and we convert the upper limits to
constrain the underlying kilonova luminosity function. Assuming that all
kilonovae are at least as luminous as GW170817 at discovery (-16.1mag), we
calculate our joint probability of detecting zero kilonovae is only 4.2%. If we
assume that all kilonovae are brighter than -16.6mag (extrapolated peak
magnitude of GW170817) and fade at 1 mag/day (similar to GW170817), the joint
probability of zero detections is 7%. If we separate the NSBH and BNS
populations, the joint probability of zero detections, assuming all kilonovae
are brighter than -16.6mag, is 9.7% for NSBH and 7.9% for BNS mergers.
Moreover, <57% (<89%) of putative kilonovae could be brighter than -16.6mag
assuming flat (fading) evolution, at 90% confidence. If we further account for
the online terrestrial probability for each GW trigger, we find that <68% of
putative kilonovae could be brighter than -16.6mag. Comparing to model grids,
we find that some kilonovae must have Mej < 0.03 Msun or Xlan>1e-4 or phi>30deg
to be consistent with our limits. (Abridged)
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:04:25 GMT""}]","2021-01-06"
"2006.11307","Ramanujan K Sheshadri","Ramanujan K Sheshadri, Eugene Chai, Karthikeyan Sundaresan, Sampath
  Rangarajan","SkyHaul: An Autonomous Gigabit Network Fabric in the Sky","15 pages report (with 32 figures including experiment results) on a
  novel solution for a 5g mmWave enabled drone-network. This hasn't been
  published in conferences/journals yet",,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We design and build SKYHAUL, the first large-scale, autonomous,
self-organizing network of Unmanned Aerial Vehicles (UAVs) that are connected
using a mmWave wireless mesh backhaul. While the use of a mmWave backhaul paves
the way for a new class of bandwidth-intensive, latency-sensitive cooperative
applications (e.g., LTE coverage during disasters, surveillance during rescue
in challenging terrains), the network of UAVs allows these applications to be
executed at operating ranges that are far beyond the line-of-sight distances
that limit individual UAVs today. To realize the challenging vision of
deploying and maintaining an airborne mmWave mesh backhaul to cater to dynamic
applications, SKYHAUL's design incorporates various elements: (1) Role-specific
UAV operations that simultaneously address application tracking and backhaul
connectivity (2) Novel algorithms to jointly address the problem of deployment
(position, yaw of UAVs) and traffic routing across the UAV network; and (3) A
provably optimal solution for fast and safe reconfiguration of UAV backhaul
during application dynamics. We implement SKYHAUL on four DJI Matrice 600 Pros
to demonstrate its practicality and performance through autonomous flight
operations, complemented by large scale simulations.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:12:06 GMT""}]","2020-06-23"
"2006.11308","Jens Hoeijmakers","H. J. Hoeijmakers, J. V. Seidel, L. Pino, D. Kitzmann, J. P. Sindel,
  D. Ehrenreich, A. V. Oza, V. Bourrier, R. Allart, A. Gebek, C. Lovis, S. N.
  Yurchenko, N. Astudillo-Defru, D. Bayliss, H. Cegla, B. Lavie, M. Lendl, C.
  Melo, F. Murgas, V. Nascimbeni, F. Pepe, D. S\'egransan, S. Udry, A.
  Wyttenbach, Kevin Heng","Hot Exoplanet Atmospheres Resolved with Transit Spectroscopy (HEARTS)
  IV. A spectral inventory of atoms and molecules in the high-resolution
  transmission spectrum of WASP-121 b","Accepted for publication in A&A - June 19, 2020",,"10.1051/0004-6361/202038365",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aims: We survey the transmission spectrum of WASP-121 b for line-absorption
by metals and molecules at high spectral resolution, and elaborate on existing
interpretations of the optical transmission spectrum observed with HST/STIS and
WFC3. Methods: We use the cross-correlation technique and direct differential
spectroscopy to search for sodium and other neutral and ionised atoms, TiO, VO
and SH in high-resolution transit spectra obtained with the HARPS spectrograph.
We inject models assuming chemical and hydrostatic equilibrium with varying
temperature and composition to enable model comparison, and employ two
bootstrap methods to test the robustness of our detections. Results: We detect
neutral Mg, Na, Ca, Cr, Fe, Ni and V, which we predict exists in equilibrium
with a significant quantity of VO, supporting earlier observations by HST/WFC3.
Non-detections of Ti and TiO support the hypothesis that Ti is depleted via a
cold-trap mechanism as has been proposed in the literature. Atomic line depths
are under-predicted by hydrostatic models by a factor of 1.5 to 8, confirming
recent findings that the atmosphere is extended. We predict the existence of
significant concentrations of gas-phase TiO$_2$, VO$_2$ and TiS, which could be
important absorbers at optical and NIR wavelengths in hot Jupiter atmospheres,
but for which accurate line-list data is currently not available. We find no
evidence for absorption by SH, and find that inflated atomic lines can
plausibly explain the slope of the transmission spectrum observed in the NUV
with HST/STIS. The Na D lines are significantly broadened and show a difference
in their respective depths of 15 scale heights, which is not expected from
isothermal hydrostatic theory.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:18:22 GMT""}]","2020-09-30"
"2006.11309","Tom Bewley","Tom Bewley, Jonathan Lawry, Arthur Richards","Modelling Agent Policies with Interpretable Imitation Learning","6 pages, 3 figures; under review for the 1st TAILOR Workshop, due to
  take place 29-30 August 2020 in Santiago de Compostela",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As we deploy autonomous agents in safety-critical domains, it becomes
important to develop an understanding of their internal mechanisms and
representations. We outline an approach to imitation learning for
reverse-engineering black box agent policies in MDP environments, yielding
simplified, interpretable models in the form of decision trees. As part of this
process, we explicitly model and learn agents' latent state representations by
selecting from a large space of candidate features constructed from the Markov
state. We present initial promising results from an implementation in a
multi-agent traffic environment.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:19:08 GMT""}]","2020-06-23"
"2006.11310","Adrian Melott","Adrian L. Melott and Brian C. Thomas","From Cosmic Explosions to Terrestrial Fires?: A Reply","Published online ahead of print: Journal of Geology, 128 (2020)",,,,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deschamps and Mottez (hereafter DM) argue that the Gauss-Matuyama terrestrial
magnetic field reversal may have left a vanishing main dipole moment to the
field for a time of order 10,000 years. They say this may have allowed an
enhanced cosmic ray flux, boosting the effect we proposed in Melott and Thomas
(2019). We point out that the bulk of the cosmic ray flux from a nearby
supernova should be too energetic, up to a million times more energetic than
the limits of deflection by the terrestrial magnetic field. In fact, only those
highly energetic ones will directly reach the troposphere, relevant for
cloud-to-ground lightning. From Cosmic Explosions to Terrestrial Fires?: A
Discussion. F. Deschamps and F. Mottez. J. Geology 128, online ahead of print.
(2020) From Cosmic Explosions to Terrestrial Fires?: A Reply A.L. Melott and
B.C. Thomas. J. Geology 128, online ahead of print. (2020) From cosmic
explosions to terrestrial fires? (A.L. Melott and B.C. Thomas) Journal of
Geology, 127, 475-481 10.1086/703418 (2019) [arXiv:1903.01501]
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:21:39 GMT""}]","2020-06-23"
"2006.11311","Mohamed Majdoub","Eadah Ahmad Alzahrani, Mohamed Majdoub","Remarks on blow-up phenomena in p-Laplacian heat equation with
  inhomogeneous nonlinearity",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the $p-$Laplace heat equation $u_t-\Delta_p u=\zeta(t)f(u)$ on
a bounded smooth domain $\Omega\subset\mathbb{R}^N$. Using differential
inequalities arguments, we prove blow-up results under suitable conditions on
$\zeta, f$, and the initial data $u_0$. We also give an upper bound for the
blow-up time in each case.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:23:30 GMT""}]","2020-06-23"
"2006.11312","Martin Aleksandrov D","Martin Aleksandrov","Envy-freeness up to one item: Shall we add or remove resources?","10 pages, 1 table, 2 figures, v1 is a working version, v2 is the
  polished version",,,,"cs.GT cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a fair division model in which agents have general valuations for
bundles of indivisible items. We propose two new axiomatic properties for
allocations in this model: EF1+- and EFX+-. We compare these with the existing
EF1 and EFX. Although EF1 and EF1+- allocations often exist, our results assert
eloquently that EFX+- and PO allocations exist in each case where EFX and PO
allocations do not exist. Additionally, we prove several new impossibility and
incompatibility results.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:29:05 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 14:49:28 GMT""}]","2020-06-24"
"2006.11313","Cl\'ement Luneau","Cl\'ement Luneau, Jean Barbier and Nicolas Macris","Information theoretic limits of learning a sparse rule","56 pages, 4 figures, accepted to the 34th Conference on Neural
  Information Processing Systems (NeurIPS 2020). Extended version that includes
  the supplementary material",,,,"cs.IT cs.LG math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider generalized linear models in regimes where the number of nonzero
components of the signal and accessible data points are sublinear with respect
to the size of the signal. We prove a variational formula for the asymptotic
mutual information per sample when the system size grows to infinity. This
result allows us to derive an expression for the minimum mean-square error
(MMSE) of the Bayesian estimator when the signal entries have a discrete
distribution with finite support. We find that, for such signals and suitable
vanishing scalings of the sparsity and sampling rate, the MMSE is nonincreasing
piecewise constant. In specific instances the MMSE even displays an
all-or-nothing phase transition, that is, the MMSE sharply jumps from its
maximum value to zero at a critical sampling rate. The all-or-nothing
phenomenon has previously been shown to occur in high-dimensional linear
regression. Our analysis goes beyond the linear case and applies to learning
the weights of a perceptron with general activation function in a
teacher-student scenario. In particular, we discuss an all-or-nothing
phenomenon for the generalization error with a sublinear set of training
examples.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:29:10 GMT""},{""version"":""v2"",""created"":""Tue, 27 Oct 2020 20:36:08 GMT""}]","2020-10-29"
"2006.11314","Robert Laterveer","Robert Laterveer","On the Chow ring of Fano varieties of type $S2$","11 pages, to appear (in slightly different from) in Abhandlungen Mat.
  Sem. Univ. Hamburg, comments welcome !",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that certain Fano eightfolds (obtained as hyperplane sections of an
orthogonal Grassmannian, and studied by Ito-Miura-Okawa-Ueda and by
Fatighenti-Mongardi) have a multiplicative Chow-K\""unneth decomposition. As a
corollary, the Chow ring of these eightfolds behaves like that of K3 surfaces.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:38:05 GMT""}]","2020-06-23"
"2006.11315","David Nash","David A. Nash and Alexander Betz","Classifying groups with a small number of subgroups","12 pages, 3 tables; V2 Fixes an error (which has no effect on the
  final results) and also adds a few citations/details suggested by early
  readers; V3 fixes minor typographical errors and clarifies the explanation of
  Slattery's previous work",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide lower bounds on the number of subgroups of a group $G$ as a
function of the primes and exponents appearing in the prime factorization of
$|G|$. Using these bounds, we classify all abelian groups with 22 or fewer
subgroups, and all non-abelian groups with 19 or fewer subgroups. This allows
us to extend the integer sequence A274847 \cite{OEIS} introduced by Slattery in
\cite{Slattery}.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:39:58 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 11:41:53 GMT""},{""version"":""v3"",""created"":""Wed, 8 Jul 2020 10:40:21 GMT""}]","2020-07-09"
"2006.11316","Forrest Iandola","Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, Kurt W. Keutzer","SqueezeBERT: What can computer vision teach NLP about efficient neural
  networks?","9 pages + appendix",,,,"cs.CL cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humans read and write hundreds of billions of messages every day. Further,
due to the availability of large datasets, large computing systems, and better
neural network models, natural language processing (NLP) technology has made
significant strides in understanding, proofreading, and organizing these
messages. Thus, there is a significant opportunity to deploy NLP in myriad
applications to help web users, social networks, and businesses. In particular,
we consider smartphones and other mobile devices as crucial platforms for
deploying NLP models at scale. However, today's highly-accurate NLP neural
network models such as BERT and RoBERTa are extremely computationally
expensive, with BERT-base taking 1.7 seconds to classify a text snippet on a
Pixel 3 smartphone. In this work, we observe that methods such as grouped
convolutions have yielded significant speedups for computer vision networks,
but many of these techniques have not been adopted by NLP neural network
designers. We demonstrate how to replace several operations in self-attention
layers with grouped convolutions, and we use this technique in a novel network
architecture called SqueezeBERT, which runs 4.3x faster than BERT-base on the
Pixel 3 while achieving competitive accuracy on the GLUE test set. The
SqueezeBERT code will be released.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:40:29 GMT""}]","2020-06-23"
"2006.11317","Gustavo Joaquin Turiaci","Henry Maxfield and Gustavo J. Turiaci","The path integral of 3D gravity near extremality; or, JT gravity with
  defects as a matrix integral","57 pp; v2 typos corrected, ref added and new section 3.5",,"10.1007/JHEP01(2021)118",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose that a class of new topologies, for which there is no classical
solution, should be included in the path integral of three-dimensional pure
gravity, and that their inclusion solves pathological negativities in the
spectrum, replacing them with a nonperturbative shift of the BTZ extremality
bound. We argue that a two-dimensional calculation using a dimensionally
reduced theory captures the leading effects in the near extremal limit. To make
this argument, we study a closely related two-dimensional theory of
Jackiw-Teitelboim gravity with dynamical defects. We show that this theory is
equivalent to a matrix integral.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:44:55 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jul 2020 21:10:52 GMT""}]","2021-02-24"
"2006.11318","Martin Lonsky","Martin Lonsky and Axel Hoffmann","Coupled skyrmion breathing modes in synthetic ferri- and
  antiferromagnets","Accepted for publication in Physical Review B","Phys. Rev. B 102, 104403 (2020)","10.1103/PhysRevB.102.104403",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present micromagnetic simulations of the dynamic GHz-range resonance modes
of skyrmions excited by either out-of-plane ac magnetic fields or spin torques
in prototypical synthetic ferri- and antiferromagnetic trilayer structures. The
observed features in the calculated power spectra exhibit a systematic
dependence on the coupling strength between the individual magnetic layers and
are related to pure in-phase and anti-phase breathing modes as well as to
hybridizations of breathing and spin-wave modes that are characteristic for the
considered circular-shaped geometry. The experimental detection of these
resonant oscillation modes may provide a means for skyrmion sensing
applications and for the general characterization of skyrmion states in
multilayer stacks with antiferromagnetic interlayer exchange coupling.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:51:06 GMT""},{""version"":""v2"",""created"":""Mon, 17 Aug 2020 16:58:55 GMT""}]","2020-09-09"
"2006.11319","Niels Gronbech-Jensen","Joshua Finkelstein, Chungho Cheng, Giacomo Fiorin, Benjamin Seibold,
  Niels Gr{\o}nbech-Jensen","The Challenge of Stochastic St{\o}rmer-Verlet Thermostats Generating
  Correct Statistics","25 pages, 8 figures","Journal of Chemical Physics Vol.153, 134101 (2020)","10.1063/5.0018962",,"cond-mat.stat-mech physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In light of the recently developed complete GJ set of single random variable
stochastic, discrete-time St{\o}rmer-Verlet algorithms for statistically
accurate simulations of Langevin equations, we investigate two outstanding
questions: 1) Are there any algorithmic or statistical benefits from including
multiple random variables per time-step, and 2) are there objective reasons for
using one or more methods from the available set of statistically correct
algorithms? To address the first question, we assume a general form for the
discrete-time equations with two random variables and then follow the
systematic, brute-force GJ methodology by enforcing correct thermodynamics in
linear systems. It is concluded that correct configurational Boltzmann sampling
of a particle in a harmonic potential implies correct configurational
free-particle diffusion, and that these requirements only can be accomplished
if the two random variables per time step are identical. We consequently submit
that the GJ set represents all possible stochastic St{\o}rmer-Verlet methods
that can reproduce time-step-independent statistics of linear systems. The
second question is thus addressed within the GJ set. Based in part on numerical
simulations of complex molecular systems, and in part on analytic scaling of
time, we analyze the apparent difference in stability between different
methods. We attribute this difference to the inherent time scaling in each
method, and suggest that this scaling may lead to inconsistencies in the
interpretation of dynamical and statistical simulation results. We therefore
suggest that the method with the least inherent time-scaling, the GJ-I/GJF-2GJ
method, be preferred for statistical applications where spurious rescaling of
time is undesirable.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:53:25 GMT""}]","2020-10-05"
"2006.11320","Rustem Khasanov","Rustem Khasanov, Gediminas Simutis, Yurii G. Pashkevich, Tatyana
  Shevtsova, William R. Meier, Sergey L. Bud'ko, Vladimir G. Kogan, and Paul C.
  Canfield","Magnetism and its coexistence with superconductivity in
  CaK(Fe$_{0.949}$Ni$_{0.051}$)$_4$As$_4$: muon spin rotation/relaxation
  studies","15 pages, 14 figures","Phys. Rev. B 102, 094504 (2020)","10.1103/PhysRevB.102.094504",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The magnetic response of CaK(Fe$_{0.949}$Ni$_{0.051}$)$_4$As$_4$ was
investigated by means of the muon-spin rotation/relaxation. The long-range
commensurate magnetic order sets in below the N\'{e}el temperature $T_{\rm N}=
50.0(5)$~K. The density-functional theory calculations have identified three
possible muon stopping sites. The experimental data were found to be consistent
with only one type of magnetic structure, namely, the long-range magnetic
spin-vortex-crystal order with the hedgehog motif within the $ab-$plane and the
antiferromagnetic stacking along the $c-$direction. The value of the ordered
magnetic moment at $T\approx3$ K was estimated to be $m_{\rm Fe}=0.38(11)$
$\mu_{\rm B}$ ($\mu_{\rm B}$ is the Bohr magneton). A microscopic coexistence
of magnetic and superconducting phases accompanied by a reduction of the
magnetic order parameter below the superconducting transition temperature
$T_{\rm c}\simeq 9$ K is observed. Comparison with 11, 122, and 1144 families
of Fe-based pnictides points to existence of correlation between the reduction
of the magnetic order parameter at $T\rightarrow 0$ and the ratio of the
transition temperatures $T_{\rm c}/T_{\rm N}$. Such correlations were found to
be described by Machida's model for coexistence of itinerant spin-density wave
magnetism and superconductivity [Machida, J. Phys. Soc. Jpn. 50, 2195 (1981)
and Bud'ko et al., Phys. Rev. B 98, 144520 (2018)].
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:54:51 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 21:40:58 GMT""}]","2020-09-09"
"2006.11321","Yuening Li","Yuening Li, Zhengzhang Chen, Daochen Zha, Kaixiong Zhou, Haifeng Jin,
  Haifeng Chen, Xia Hu","AutoOD: Automated Outlier Detection via Curiosity-guided Search and
  Self-imitation Learning",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Outlier detection is an important data mining task with numerous practical
applications such as intrusion detection, credit card fraud detection, and
video surveillance. However, given a specific complicated task with big data,
the process of building a powerful deep learning based system for outlier
detection still highly relies on human expertise and laboring trials. Although
Neural Architecture Search (NAS) has shown its promise in discovering effective
deep architectures in various domains, such as image classification, object
detection, and semantic segmentation, contemporary NAS methods are not suitable
for outlier detection due to the lack of intrinsic search space, unstable
search process, and low sample efficiency. To bridge the gap, in this paper, we
propose AutoOD, an automated outlier detection framework, which aims to search
for an optimal neural network model within a predefined search space.
Specifically, we firstly design a curiosity-guided search strategy to overcome
the curse of local optimality. A controller, which acts as a search agent, is
encouraged to take actions to maximize the information gain about the
controller's internal belief. We further introduce an experience replay
mechanism based on self-imitation learning to improve the sample efficiency.
Experimental results on various real-world benchmark datasets demonstrate that
the deep model identified by AutoOD achieves the best performance, comparing
with existing handcrafted models and traditional search methods.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:57:51 GMT""}]","2020-06-23"
"2006.11322","Wim Ubachs","K.-F. Lai, E. J. Salumbides, W. Ubachs","Two-photon Doppler-free ultraviolet laser spectroscopy on sulphur atoms","J. Phys. B: At. Mol. Opt. Phys (2020)",,"10.1088/1361-6455/ab9c37",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $3p^{4}$ $^{3}$P$_{J}$ - $3p^{3}4p$ $^{3}$P$_{J}$ transition in the
sulphur atom is investigated in a precision two-photon excitation scheme under
Doppler-free and collision-free circumstances yielding an absolute accuracy of
0.0009 cm$^{-1}$, using a narrowband pulsed laser. This verifies and improves
the level separations between amply studied odd parity levels with even parity
levels in S I. An improved value for the $^{3}$P$_{2}$ - $^{3}$P$_{1}$ ground
state fine structure splitting is determined at $396.0564$ (7) cm$^{-1}$. A
$^{34}$S - $^{32}$S atomic isotope shift was measured from combining
time-of-flight mass spectrometry with laser spectroscopy.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:58:29 GMT""}]","2020-06-23"
"2006.11323","Leonid E. Golub","L. E. Golub, E. L. Ivchenko, and B. Spivak","Semiclassical theory of the circular photogalvanic effect in gyrotropic
  systems","8 pages, 1 figure","Phys. Rev. B 102, 085202 (2020)","10.1103/PhysRevB.102.085202",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a theory of circular photogalvanic effect (CPGE) for classically
high photon energies which exceed the electron scattering rate but are small
compared to the average electron kinetic energy. In this frequency range one
can calculate the CPGE by using two different approaches. In the fully
quantum-mechanical approach we find the photocurrent density by applying
Fermi's golden rule for indirect intraband optical transitions with virtual
intermediate states both in the conduction and valence bands. In the framework
of the semiclassical approach, we apply a generalized Boltzmann equation with
accounts for the Berry-curvature induced anomalous velocity, side jumps and
skew scattering. The calculation is carried out for a wurtzite symmetry
crystal. Both methods yield the same results for the CPGE current demonstrating
consistency between the two approaches and applicability of the semiclassical
theory for the description of nonlinear high-frequency transport.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:59:36 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jul 2020 15:51:22 GMT""}]","2020-09-07"
"2006.11324","Katrina Morgan","Katrina Morgan","The effect of metric behavior at spatial infinity on pointwise wave
  decay in the asymptotically flat stationary setting",,,,,"math.AP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The current work considers solutions to the wave equation on asymptotically
flat, stationary, Lorentzian spacetimes in (1+3) dimensions. We investigate the
relationship between the rate at which the geometry tends to flat and the
pointwise decay rate of solutions. The case where the spacetime tends toward
flat at a rate of $|x|^{-1}$ was studied in \cite{tat2013}, where a $t^{-3}$
pointwise decay rate was established. Here we extend the result to geometries
tending toward flat at a rate of $|x|^{-\kappa}$ and establish a pointwise
decay rate of $t^{-\kappa-2}$ for $\kappa \in \mathbb{N}$ with $\kappa \ge 2$.
We assume a weak local energy decay estimate holds, which restricts the
geodesic trapping allowed on the underlying geometry. We use the resolvent to
connect the time Fourier Transform of a solution to the Cauchy data. Ultimately
the rate of pointwise wave decay depends on the low frequency behavior of the
resolvent, which is sensitive to the rate at which the background geometry
tends to flat.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:00:09 GMT""}]","2020-06-23"
"2006.11325","Carlos Roberto Medina Temme","Carlos Medina, Arnout Devos, Matthias Grossglauser","Self-Supervised Prototypical Transfer Learning for Few-Shot
  Classification","Extended version of work presented at the 7th ICML Workshop on
  Automated Machine Learning (2020). Code available at
  https://github.com/indy-lab/ProtoTransfer ; 17 pages, 3 figures, 12 tables",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most approaches in few-shot learning rely on costly annotated data related to
the goal task domain during (pre-)training. Recently, unsupervised
meta-learning methods have exchanged the annotation requirement for a reduction
in few-shot classification performance. Simultaneously, in settings with
realistic domain shift, common transfer learning has been shown to outperform
supervised meta-learning. Building on these insights and on advances in
self-supervised learning, we propose a transfer learning approach which
constructs a metric embedding that clusters unlabeled prototypical samples and
their augmentations closely together. This pre-trained embedding is a starting
point for few-shot classification by summarizing class clusters and
fine-tuning. We demonstrate that our self-supervised prototypical transfer
learning approach ProtoTransfer outperforms state-of-the-art unsupervised
meta-learning methods on few-shot tasks from the mini-ImageNet dataset. In
few-shot experiments with domain shift, our approach even has comparable
performance to supervised methods, but requires orders of magnitude fewer
labels.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:00:11 GMT""}]","2020-06-23"
"2006.11326","Luciano Abreu","L. M. Abreu, M. de Montigny and P. P. A. Ouimet","An effective field theory approach to monopolium","14 pages, 9 figures, 2 tables; accepted for publication in The
  European Physical Journal Plus","Eur. Phys. J. Plus 135, 543 (2020)","10.1140/epjp/s13360-020-00550-1",,"hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we investigate the interaction between spin-zero and spin-one
monopoles by making use of an effective field theory based on two-body and
four-body interaction parts. In particular, we analyze the formation of bound
state of monopole-antimonopole (i.e. monopolium). The magnetic-charge
conjugation symmetry is studied in analogy to the usual charge conjugation to
define a particle basis, for which we find bound-state solutions with
relatively small binding energies and which allows us to identify the bounds on
the parameters in the effective Lagrangians. Estimations of their masses,
binding energies and scattering lengths are performed as functions of monopole
masses and interaction strength in a specific renormalization scheme. We also
examine the general validity of the approach and the feasibility of detecting
the monopolium.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:01:29 GMT""}]","2020-07-08"
"2006.11327","Nathalia da Cruz Alves","Nathalia da Cruz Alves, Christiane Gresse von Wangenheim and Jean
  Carlo Rossa Hauck","Teaching Programming to Novices: A Large-scale Analysis of App Inventor
  Projects","10 pages, 11 figures","2020 XV Conferencia Latinoamericana de Tecnologias de Aprendizaje
  (LACLO), 2020, pp. 1-10","10.1109/LACLO50806.2020.9381172",,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Teaching programming to K-12 students has become essential. In this context,
App Inventor is a popular block-based programming environment used by a wide
audience, from K-12 to higher education, including end-users to create mobile
applications to support their primary job or hobbies. Although learning
programming with App Inventor has been investigated, a question that remains is
which programming concepts are typically used and how this compares to other
block-based programming environments. Therefore, we explore the characteristics
of App Inventor projects through a large-scale analysis of 88,606 apps from the
App Inventor Gallery. We discovered that the size of App Inventor projects
varies from projects with very few blocks to some surprisingly large projects
with more than 60,000 blocks. In general, much fewer design components are used
than programming blocks, as typically, to work properly, several programming
blocks are necessary for each design component in an App Inventor project. In
addition, we also compare our results with the analysis of 233,491 Scratch
projects reported by Aivaloglou and Hermans [4]. Several differences can be
observed, as in App Inventor projects events are more predominant, with lesser
use of conditionals and loops. These findings may guide the decision on the
adoption of App Inventor for teaching computing depending on the specific
learning objectives or indicate the need for tailoring the curricula.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:02:02 GMT""},{""version"":""v2"",""created"":""Sun, 25 Apr 2021 03:19:02 GMT""}]","2021-04-27"
"2006.11328","Ivan Skorokhodov","Ivan Skorokhodov, Mohamed Elhoseiny","Class Normalization for (Continual)? Generalized Zero-Shot Learning","22 pages, 7 figures, 7 tables",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Normalization techniques have proved to be a crucial ingredient of successful
training in a traditional supervised learning regime. However, in the zero-shot
learning (ZSL) world, these ideas have received only marginal attention. This
work studies normalization in ZSL scenario from both theoretical and practical
perspectives. First, we give a theoretical explanation to two popular tricks
used in zero-shot learning: normalize+scale and attributes normalization and
show that they help training by preserving variance during a forward pass.
Next, we demonstrate that they are insufficient to normalize a deep ZSL model
and propose Class Normalization (CN): a normalization scheme, which alleviates
this issue both provably and in practice. Third, we show that ZSL models
typically have more irregular loss surface compared to traditional classifiers
and that the proposed method partially remedies this problem. Then, we test our
approach on 4 standard ZSL datasets and outperform sophisticated modern SotA
with a simple MLP optimized without any bells and whistles and having ~50 times
faster training speed. Finally, we generalize ZSL to a broader problem --
continual ZSL, and introduce some principled metrics and rigorous baselines for
this new setup. The project page is located at
https://universome.github.io/class-norm.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:05:24 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 16:12:34 GMT""}]","2021-04-15"
"2006.11329","Lev A. Sakhnovich","Lev Sakhnovich","Quantum and classical approaches in statistical physics: some basic
  inequalities","We develop and generalize our previous results from the book ""Levy
  processes, integral equations, statistical physics: connections and
  interactions"" and earlier preprints arXiv:1105.4633 and arXiv:1105.0208. In
  the fourth version of the paper, the first part is improved and the second
  part (on quasi-classical limits) is added. The game theoretic interpretation
  is modified and improved as well",,,,"math-ph math.MP math.OC quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present some basic inequalities between the classical and quantum values
of free energy, entropy and mean energy. We investigate the transition from the
deterministic case (classical mechanics) to the probabilistic case (quantum
mechanics). In the first part of the paper, we assume that the reduced Planck
constant $\hbar$, the absolute temperature $T$, the frequency of an oscillator
$\omega$, and the degree of freedom of a system $N$ are fixed. This approach to
the problem of comparing quantum and classical mechanics is new (see
[35]--[37]).
  In the second part of the paper, we simultaneously derive the semiclassical
limits for four cases, that is, for $\hbar{\to}0$, $T{\to}\infty$,
$\omega{\to}0$, and $N{\to}\infty$. We note that only the case $\hbar{\to}0$ is
usually considered in quantum mechanics (see [21]). The cases $T{\to}\infty$
and $\omega{\to}0$ in quantum mechanics were initially studied by M. Planck and
by A. Einstein, respectively.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:06:10 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 16:14:30 GMT""},{""version"":""v3"",""created"":""Sun, 27 Sep 2020 13:45:05 GMT""},{""version"":""v4"",""created"":""Sat, 9 Jul 2022 17:56:03 GMT""}]","2022-07-12"
"2006.11330","Henry Pinkard","Henry Pinkard, Nico Stuurman, Laura Waller","Pycro-manager: open-source software for integrated microscopy hardware
  control and image processing",,,,,"q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  {\mu}Manager, an open-source microscopy acquisition software, has been an
essential tool for many microscopy experiments over the past 15 years, but is
not easy to use for experiments in which image acquisition and analysis are
closely coupled. This is because {\mu}Manager libraries are written in C++ and
Java, whereas image processing is increasingly carried out with data science
and machine learning tools most easily accessible through the Python
programming language. We present Pycro-Manager, a tool that enables rapid
development of such experiments, while also providing access to the wealth of
existing tools within {\mu}Manager through Python.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:06:37 GMT""}]","2020-06-23"
"2006.11331","Aniket Bhattacharya","Swarnadeep Seth and Aniket Bhattacharya","Polymer escape through a three dimensional Double-Nanopore System","Previously this appeared as arXiv:2003.07755v2, which was uploaded as
  a replacement by mistake",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study escape dynamics of a double-stranded DNA (dsDNA) through an
idealized double nanopore (DNP) geometry subject to two equal and opposite
forces (tug-of-war) using Brownian dynamics (BD) simulation. In addition to the
geometrical restrictions imposed on the cocaptured dsDNA segment in between the
pores, the presence of tug-of-war forces at each pore results in a variation of
the local chain stiffness for the segment of the chain in between the pores
which increases the overall stiffness of the chain. We use BD simulation
results to understand how the intrinsic chain stiffness and the TOW forces
affect the escape dynamics by monitoring the local chain persistence length
$\ell_p$, the residence time of the individual monomers $W(m)$ in the
nanopores, and the chain length dependence of the escape time $\langle \tau
\rangle$ and its distribution. Finally, we generalize the scaling theory for
the unbiased single nanopore translocation for a fully flexible chain for the
escape of a semi-flexible chain through a DNP in presence of TOW forces. We
establish that the stiffness dependent part of the escape time is approximately
independent of the translocation mechanism so that $\langle \tau \rangle \sim
\ell_p^{2/D+2}$, and therefore the generalized escape time for a semi-flexible
chain can be written as $\langle \tau \rangle = AN^\alpha\ell_p^{2/D+2}$. We
use BD simulation results to compare the predictions of the scaling theory. Our
numerical studies supplemented by scaling analysis provide fundamental insights
to design new experiments where a dsDNA moves slowly through a series of
graphene nanopores.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:26:05 GMT""}]","2020-06-23"
"2006.11332","Elija Perrier","Elija Perrier, Christopher Ferrie, Dacheng Tao","Quantum Geometric Machine Learning for Quantum Circuits and Control","28 pages, 14 figures. Code and select datasets available at
  https://github.com/eperrier/quant-geom-machine-learning",,"10.1088/1367-2630/abbf6b",,"quant-ph cs.LG math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The application of machine learning techniques to solve problems in quantum
control together with established geometric methods for solving optimisation
problems leads naturally to an exploration of how machine learning approaches
can be used to enhance geometric approaches to solving problems in quantum
information processing. In this work, we review and extend the application of
deep learning to quantum geometric control problems. Specifically, we
demonstrate enhancements in time-optimal control in the context of quantum
circuit synthesis problems by applying novel deep learning algorithms in order
to approximate geodesics (and thus minimal circuits) along Lie group manifolds
relevant to low-dimensional multi-qubit systems, such as SU(2), SU(4) and
SU(8). We demonstrate the superior performance of greybox models, which combine
traditional blackbox algorithms with prior domain knowledge of quantum
mechanics, as means of learning underlying quantum circuit distributions of
interest. Our results demonstrate how geometric control techniques can be used
to both (a) verify the extent to which geometrically synthesised quantum
circuits lie along geodesic, and thus time-optimal, routes and (b) synthesise
those circuits. Our results are of interest to researchers in quantum control
and quantum information theory seeking to combine machine learning and
geometric techniques for time-optimal control problems.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:12:14 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 13:13:48 GMT""}]","2020-12-02"
"2006.11333","Shira Chapman Ms.","Constantin Bachas, Shira Chapman, Dongsheng Ge and Giuseppe Policastro","Energy Reflection and Transmission at 2D Holographic Interfaces","5 pages, 1 figure",,"10.1103/PhysRevLett.125.231602",,"hep-th cond-mat.str-el gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scattering from conformal interfaces in two dimensions is universal in that
the flux of reflected and transmitted energy does not depend on the details of
the initial state. In this letter, we present the first gravitational
calculation of energy reflection and transmission coefficients for interfaces
with thin-brane holographic duals. Our result for the reflection coefficient
depends monotonically on the tension of the dual string anchored at the
interface, and obeys the lower bound recently derived from the ANEC in
conformal field theory. The B(oundary)CFT limit is recovered for infinite ratio
of the central charges.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:12:52 GMT""}]","2020-12-30"
"2006.11334","Stephen Flood","Stephen Flood, Matthew Jura, Oscar Levin, Tyler Markkanen","The computational strength of matchings in countable graphs","38 pages, 5 figures",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a 1977 paper, Steffens identified an elegant criterion for determining
when a countable graph has a perfect matching. In this paper, we will
investigate the proof-theoretic strength of this result and related theorems.
We show that a number of natural variants of these theorems are equivalent, or
closely related, to the ``big five'' subsystems of reverse mathematics.
  The results of this paper explore the relationship between graph theory and
logic by showing the way in which specific changes to a single graph-theoretic
principle impact the corresponding proof-theoretical strength. Taken together,
the results and questions of this paper suggest that the existence of matchings
in countable graphs provides a rich context for understanding reverse
mathematics more broadly.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:20:08 GMT""}]","2020-06-23"
"2006.11335","Branislav Nikolic","Kapildeb Dolui, Branislav K. Nikolic","Spin-orbit-proximitized ferromagnetic metal by monolayer transition
  metal dichalcogenide: Atlas of spectral functions, spin textures and
  spin-orbit torques in Co/MoSe$_2$, Co/WSe$_2$ and Co/TaSe$_2$
  heterostructures","12 pages, 7 figures","Phys. Rev. Materials 4, 104007 (2020)","10.1103/PhysRevMaterials.4.104007",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The bilayer heterostructures composed of an ultrathin ferromagnetic metal
(FM) and a material hosting strong spin-orbit (SO) coupling are principal
resource for SO torque and spin-to-charge conversion nonequilibrium effects in
spintronics. We demonstrate how hybridization of wavefunctions of Co layer and
a monolayer of transition metal dichalcogenides (TMDs)---such as semiconducting
MoSe$_2$ and WSe$_2$ or metallic TaSe$_2$---can lead to dramatic transmutation
of electronic and spin structure of Co within some distance away from its
interface with TMD, when compared to the bulk of Co or its surface in contact
with vacuum. This is due to proximity induced SO splitting of Co bands encoded
in the spectral functions and spin textures on its monolayers, which we obtain
using noncollinear density functional theory (ncDFT) combined with equilibrium
Green function (GF) calculations. In fact, SO splitting is present due to
structural inversion asymmetry of the bilayer even if SO coupling within TMD
monolayer is artificially switched off in ncDFT calculations, but switching it
on makes the effects associated with proximity SO coupling within Co layer
about five times larger. Injecting spin-unpolarized charge current through
SO-proximitized monolayers of Co generates nonequilibrium spin density over
them, so that its cross product with the magnetization of Co determines SO
torque. The SO torque computed via first-principles quantum transport
methodology, which combines ncDFT with nonequilibrium GF calculations, can be
used as the screening parameter to identify optimal combination of materials
and their interfaces for applications in spintronics. In particular, we
identify heterostructure two-monolayer-Co/monolayer-WSe$_2$ as the most
optimal.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:21:46 GMT""}]","2020-10-28"
"2006.11337","Tianlang Chen","Tianlang Chen, Wei Xiong, Haitian Zheng, Jiebo Luo","Image Sentiment Transfer",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we introduce an important but still unexplored research task --
image sentiment transfer. Compared with other related tasks that have been
well-studied, such as image-to-image translation and image style transfer,
transferring the sentiment of an image is more challenging. Given an input
image, the rule to transfer the sentiment of each contained object can be
completely different, making existing approaches that perform global image
transfer by a single reference image inadequate to achieve satisfactory
performance. In this paper, we propose an effective and flexible framework that
performs image sentiment transfer at the object level. It first detects the
objects and extracts their pixel-level masks, and then performs object-level
sentiment transfer guided by multiple reference images for the corresponding
objects. For the core object-level sentiment transfer, we propose a novel
Sentiment-aware GAN (SentiGAN). Both global image-level and local object-level
supervisions are imposed to train SentiGAN. More importantly, an effective
content disentanglement loss cooperating with a content alignment step is
applied to better disentangle the residual sentiment-related information of the
input image. Extensive quantitative and qualitative experiments are performed
on the object-oriented VSO dataset we create, demonstrating the effectiveness
of the proposed framework.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:28:08 GMT""}]","2020-06-23"
"2006.11338","Donald Reames","Donald V. Reames","Distinguishing the Rigidity Dependences of Acceleration and Transport in
  Solar Energetic Particles","25 pages, 13 figure, submitted to Solar Physics","Solar Physics 195 113 (2020)","10.1007/s11207-020-01680-6",,"astro-ph.SR physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In solar energetic particle (SEP) events, the power-law dependence of element
abundance enhancements on their mass-to-charge ratios A/Q provides a new tool
that measures the combined rigidity dependences from both acceleration and
transport. Distinguishing these two processes can be more challenging. However,
the effects of acceleration dominate when SEP events are small or when the ions
even propagate scatter-free, and transport can dominate the time evolution of
large events with streaming-limited intensities. Magnetic reconnection in solar
jets produces positive powers of A/Q from +2 to +7 and shock acceleration
produces mostly negative powers from -2 to +1 in small and moderate SEP events
where transport effects are minimal. This variation in the rigidity dependence
of shock acceleration may reflect the non-planer structure, complexity, and
time variation of coronal shocks themselves. Wave amplification by streaming
protons in the largest SEP events suppresses the escape of ions with low A/Q,
creating observed powers of A/Q from +1 to +3 upstream of the accelerating
shock, decreasing to small negative powers downstream. Of course, the powers of
A/Q are correlated with the spectral indices of He, O, and Fe, yet unexplained
departures exist.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:30:11 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jul 2020 19:57:51 GMT""},{""version"":""v3"",""created"":""Sun, 16 Aug 2020 19:50:58 GMT""}]","2020-08-18"
"2006.11339","Dahun Kim","Dahun Kim, Sanghyun Woo, Joon-Young Lee, In So Kweon","Video Panoptic Segmentation","CVPR 2020 Oral. Code: see https://github.com/mcahny/vps",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Panoptic segmentation has become a new standard of visual recognition task by
unifying previous semantic segmentation and instance segmentation tasks in
concert. In this paper, we propose and explore a new video extension of this
task, called video panoptic segmentation. The task requires generating
consistent panoptic segmentation as well as an association of instance ids
across video frames. To invigorate research on this new task, we present two
types of video panoptic datasets. The first is a re-organization of the
synthetic VIPER dataset into the video panoptic format to exploit its
large-scale pixel annotations. The second is a temporal extension on the
Cityscapes val. set, by providing new video panoptic annotations
(Cityscapes-VPS). Moreover, we propose a novel video panoptic segmentation
network (VPSNet) which jointly predicts object classes, bounding boxes, masks,
instance id tracking, and semantic segmentation in video frames. To provide
appropriate metrics for this task, we propose a video panoptic quality (VPQ)
metric and evaluate our method and several other baselines. Experimental
results demonstrate the effectiveness of the presented two datasets. We achieve
state-of-the-art results in image PQ on Cityscapes and also in VPQ on
Cityscapes-VPS and VIPER datasets. The datasets and code are made publicly
available.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:35:47 GMT""}]","2020-06-23"
"2006.11340","Alon Faraggi","Alon E. Faraggi, Viktor G. Matyas, Benjamin Percival","Towards the Classification of Tachyon-Free Models From Tachyonic
  Ten-Dimensional Heterotic String Vacua","33 pages. 7 figures. Standard LaTex. Published version","Nuclear Physics B 961 (2020) 115231","10.1016/j.nuclphysb.2020.115231","LTH-1236","hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently it was proposed that ten-dimensional tachyonic string vacua may
serve as starting points for the construction of viable four dimensional
phenomenological string models which are tachyon free. This is achieved by
projecting out the tachyons in the four-dimensional models using projectors
other than the projector which is utilised in the supersymmetric models and
those of the $SO(16)\times SO(16)$ heterotic string. We continue the
exploration of this class of models by developing systematic computerised tools
for their classification, the analysis of their tachyonic and massless spectra,
as well as analysis of their partition functions and vacuum energy. We explore
a randomly generated space of $2\times10^9$ string vacua in this class and find
that tachyon--free models occur with $\sim 5\times 10^{-3}$ probability, and of
those, phenomenologically inclined $SO(10)$ vacua with $a_{00}=N_b^0-N_f^0=0$,
i.e. equal number of fermionic and bosonic massless states, occur with
frequency $\sim 2\times 10^{-6}$. Extracting larger numbers of phenomenological
vacua therefore requires adaptation of fertility conditions that we discuss,
and significantly increase the frequency of tachyon--free models. Our results
suggest that spacetime supersymmetry may not be a necessary ingredient in
phenomenological string models, even at the Planck scale.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:35:59 GMT""},{""version"":""v2"",""created"":""Tue, 10 Nov 2020 20:47:57 GMT""}]","2020-11-12"
"2006.11341","Artsiom Ablavatski","Artsiom Ablavatski, Andrey Vakunov, Ivan Grishchenko, Karthik
  Raveendran, Matsvei Zhdanovich","Real-time Pupil Tracking from Monocular Video for Digital Puppetry",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a simple, real-time approach for pupil tracking from live video on
mobile devices. Our method extends a state-of-the-art face mesh detector with
two new components: a tiny neural network that predicts positions of the pupils
in 2D, and a displacement-based estimation of the pupil blend shape
coefficients. Our technique can be used to accurately control the pupil
movements of a virtual puppet, and lends liveliness and energy to it. The
proposed approach runs at over 50 FPS on modern phones, and enables its usage
in any real-time puppeteering pipeline.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:39:32 GMT""}]","2020-06-23"
"2006.11342","R.J. Vanderbei","J. Richard Gott III and Robert J. Vanderbei","A Simple 3D Isometric Embedding of the Flat Square Torus","9 pages, 3 figures",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Start with Gott (2019)'s envelope polyhedron (Squares-4 around a point): a
unit cube missing its top and bottom faces. Stretch by a factor of 2 in the
vertical direction so its sides become (2x1 unit) rectangles. This has 8 faces
(4 exterior, 4 interior), 8 vertices, and 16 edges. F-E+V = 0, implying a
(toroidal) genus = 1. It is isometric to a flat square torus. Like any
polyhedron it has zero intrinsic Gaussian curvature on its faces and edges.
Since 4 right angled rectangles meet at each vertex, there is no angle deficit
and zero Gaussian curvature there as well. All meridian and latitudinal
circumferences are equal (4 units long).
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:42:35 GMT""}]","2020-06-23"
"2006.11343","Gautam Kishore Shahi","Gautam Kishore Shahi, Durgesh Nandini","FakeCovid -- A Multilingual Cross-domain Fact Check News Dataset for
  COVID-19","CySoc 2020 International Workshop on Cyber Social Threats, ICWSM 2020",,"10.36190/2020.14",,"cs.CY cs.SI","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a first multilingual cross-domain dataset of 5182
fact-checked news articles for COVID-19, collected from 04/01/2020 to
15/05/2020. We have collected the fact-checked articles from 92 different
fact-checking websites after obtaining references from Poynter and Snopes. We
have manually annotated articles into 11 different categories of the
fact-checked news according to their content. The dataset is in 40 languages
from 105 countries. We have built a classifier to detect fake news and present
results for the automatic fake news detection and its class. Our model achieves
an F1 score of 0.76 to detect the false class and other fact check articles.
The FakeCovid dataset is available at Github.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:48:00 GMT""}]","2020-06-23"
"2006.11344","Thiago de Assis","Caio P. de Castro, Thiago A. de Assis, Roberto Rivelino, Fernando de
  B. Mota, Caio M. C. de Castilho, Richard G. Forbes","Modeling the Field Emission Enhancement Factor for Capped Carbon
  Nanotubes using the Induced Electron Density",,,"10.1021/acs.jcim.9b00896",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many field electron emission experiments on single-walled carbon nanotubes
(SWCNTs), the SWCNT stands on one of two well-separated parallel plane plates,
with a macroscopic field FM applied between them. For any given location ""L"" on
the SWCNT surface, a field enhancement factor (FEF) is defined as
$F_{\rm{L}}$/$F_{\rm{M}}$, where $F_{\rm{L}}$ is a local field defined at ""L"".
The best emission measurements from small-radii capped SWCNTs exhibit
characteristic FEFs that are constant (i.e., independent of $F_{\rm{M}}$). This
paper discusses how to retrieve this result in quantum-mechanical (as opposed
to classical electrostatic) calculations. Density functional theory (DFT) is
used to analyze the properties of two short, floating SWCNTS, capped at both
ends, namely a (6,6) and a (10,0) structure. Both have effectively the same
height ($\sim 5.46$ nm) and radius ($\sim 0.42$ nm). It is found that apex
values of local induced FEF are similar for the two SWCNTs, are independent of
$F_{\rm{M}}$, and are similar to FEF-values found from classical conductor
models. It is suggested that these induced-FEF values relate to the SWCNT
longitudinal system polarizabilities, which are presumed similar. The DFT
calculations also generate ""real"", as opposed to ``induced"", potential-energy
(PE) barriers for the two SWCNTs, for FM-values from 3 V/$\mu$m to 2 V/nm. PE
profiles along the SWCNT axis and along a parallel ``observation line"" through
one of the topmost atoms are similar. At low macroscopic fields the details of
barrier shape differ for the two SWCNT types. Even for $F_{\rm{M}}=0$, there
are distinct PE structures present at the emitter apex (different for the two
SWCNTs); this suggests the presence of structure-specific chemically induced
charge transfers and related patch-field distributions.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:49:12 GMT""}]","2020-06-23"
"2006.11345","Adam Loy","Adam Loy","Bringing Visual Inference to the Classroom","22 pages, 9 figures",,,,"stat.OT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the classroom, we traditionally visualize inferential concepts using
static graphics or interactive apps. For example, there is a long history of
using apps to visualize sampling distributions. Recent developments in
statistical graphics have created an opportunity to bring additional
visualizations into the classroom to hone student understanding. Specifically,
the lineup protocol for visual inference provides a framework for students see
the difference between signal and noise by embedding a plot of observed data in
a field of null (noise) plots. Lineups have proven valuable in visualizing
randomization/permutation tests, diagnosing models, and even conducting valid
inference when distributional assumptions break down. This paper provides an
overview of how the lineup protocol for visual inference can be used to hone
understanding of key statistical topics throughout the statistics curricula.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:49:55 GMT""}]","2020-06-23"
"2006.11346","Carrie Fry","Carrie E. Fry and Laura A. Hatfield","Do Methodological Birds of a Feather Flock Together?","21 pages, 2 tables, 3 figures",,,,"stat.ME econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quasi-experimental methods have proliferated over the last two decades, as
researchers develop causal inference tools for settings in which randomization
is infeasible. Two popular such methods, difference-in-differences (DID) and
comparative interrupted time series (CITS), compare observations before and
after an intervention in a treated group to an untreated comparison group
observed over the same period. Both methods rely on strong, untestable
counterfactual assumptions. Despite their similarities, the methodological
literature on CITS lacks the mathematical formality of DID. In this paper, we
use the potential outcomes framework to formalize two versions of CITS - a
general version described by Bloom (2005) and a linear version often used in
health services research. We then compare these to two corresponding DID
formulations - one with time fixed effects and one with time fixed effects and
group trends. We also re-analyze three previously published studies using these
methods. We demonstrate that the most general versions of CITS and DID impute
the same counterfactuals and estimate the same treatment effects. The only
difference between these two designs is the language used to describe them and
their popularity in distinct disciplines. We also show that these designs
diverge when one constrains them using linearity (CITS) or parallel trends
(DID). We recommend defaulting to the more flexible versions and provide advice
to practitioners on choosing between the more constrained versions by
considering the data-generating mechanism. We also recommend greater attention
to specifying the outcome model and counterfactuals in papers, allowing for
transparent evaluation of the plausibility of causal assumptions.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:49:58 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 17:36:42 GMT""}]","2020-07-09"
"2006.11347","Mithun Poozhiyil","Mithun. P, Shaunak A. Mehta, Suril V. Shah, Gaurav Bhatnagar,
  K.Madhava Krishna","Student Mixture Model Based Visual Servoing","35 pages, 17 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classical Image-Based Visual Servoing (IBVS) makes use of geometric image
features like point, straight line and image moments to control a robotic
system. Robust extraction and real-time tracking of these features are crucial
to the performance of the IBVS. Moreover, such features can be unsuitable for
real world applications where it might not be easy to distinguish a target from
the rest of the environment. Alternatively, an approach based on complete
photometric data can avoid the requirement of feature extraction, tracking and
object detection. In this work, we propose one such probabilistic model based
approach which uses entire photometric data for the purpose of visual servoing.
A novel image modelling method has been proposed using Student Mixture Model
(SMM), which is based on Multivariate Student's t-Distribution. Consequently, a
vision-based control law is formulated as a least squares minimisation problem.
Efficacy of the proposed framework is demonstrated for 2D and 3D positioning
tasks showing favourable error convergence and acceptable camera trajectories.
Numerical experiments are also carried out to show robustness to distinct image
scenes and partial occlusion.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:52:47 GMT""}]","2020-06-23"
"2006.11348","Vin\'icius Da Silva","Vinicius da Silva and Luiz Velho","Ray-VR: Ray Tracing Virtual Reality in Falcor","8 pages, 7 figures",,,,"cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  NVidia RTX platform has been changing and extending the possibilities for
real time Computer Graphics applications. It is the first time in history that
retail graphics cards have full hardware support for ray tracing primitives. It
still a long way to fully understand and optimize its use and this task itself
is a fertile field for scientific progression. However, another path is to
explore the platform as an expansion of paradigms for other problems. For
example, the integration of real time Ray Tracing and Virtual Reality can
result in interesting applications for visualization of Non-Euclidean Geometry
and 3D Manifolds. In this paper we present Ray-VR, a novel algorithm for real
time stereo ray tracing, constructed on top of Falcor, NVidia's scientific
prototyping framework.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:54:50 GMT""}]","2020-06-23"
"2006.11349","Fabian Wunderlich","Fabian Wunderlich, Markus Scheucher, Mareike Godolt, John Lee
  Grenfell, Franz Schreier, P. Christian Schneider, David J. Wilson, Alejandro
  S\'anchez L\'opez, Manuel L\'opez Puertas and Heike Rauer","Distinguishing between wet and dry atmospheres of TRAPPIST-1 e and f","37 pages, 18 figures, accepted for publication in ApJ",,"10.3847/1538-4357/aba59c",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nearby TRAPPIST-1 planetary system is an exciting target for
characterizing the atmospheres of terrestrial planets. The planets e, f and g
lie in the circumstellar habitable zone and could sustain liquid water on their
surfaces. During the extended pre-main sequence phase of TRAPPIST-1, however,
the planets may have experienced extreme water loss, leading to a desiccated
mantle. The presence or absence of an ocean is challenging to determine with
current and next generation telescopes. Therefore, we investigate whether
indirect evidence of an ocean and/or a biosphere can be inferred from
observations of the planetary atmosphere. We introduce a newly developed
photochemical model for planetary atmospheres, coupled to a
radiative-convective model and validate it against modern Earth, Venus and
Mars. The coupled model is applied to the TRAPPIST-1 planets e and f, assuming
different surface conditions and varying amounts of CO$_2$ in the atmosphere.
As input for the model we use a constructed spectrum of TRAPPIST-1, based on
near-simultaneous data from X-ray to optical wavelengths. We compute cloud-free
transmission spectra of the planetary atmospheres and determine the
detectability of molecular features using the Extremely Large Telescope (ELT)
and the James Webb Space Telescope (JWST). We find that under certain
conditions, the existence or non-existence of a biosphere and/or an ocean can
be inferred by combining 30 transit observations with ELT and JWST within the
K-band. A non-detection of CO could suggest the existence of an ocean, whereas
significant CH$_4$ hints at the presence of a biosphere.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:08:23 GMT""}]","2020-10-07"
"2006.11350","Preetam Nandy","Preetam Nandy, Cyrus Diciccio, Divya Venugopalan, Heloise Logan,
  Kinjal Basu, Noureddine El Karoui","Achieving Fairness via Post-Processing in Web-Scale Recommender Systems",,,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Building fair recommender systems is a challenging and crucial area of study
due to its immense impact on society. We extended the definitions of two
commonly accepted notions of fairness to recommender systems, namely equality
of opportunity and equalized odds. These fairness measures ensure that equally
""qualified"" (or ""unqualified"") candidates are treated equally regardless of
their protected attribute status (such as gender or race). We propose scalable
methods for achieving equality of opportunity and equalized odds in rankings in
the presence of position bias, which commonly plagues data generated from
recommender systems. Our algorithms are model agnostic in the sense that they
depend only on the final scores provided by a model, making them easily
applicable to virtually all web-scale recommender systems. We conduct extensive
simulations as well as real-world experiments to show the efficacy of our
approach.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:12:13 GMT""},{""version"":""v2"",""created"":""Fri, 5 Feb 2021 17:30:14 GMT""},{""version"":""v3"",""created"":""Thu, 11 Aug 2022 06:42:18 GMT""}]","2022-08-12"
"2006.11351","Shuntaro Tani","Shuntaro Tani, Yutsuki Aoyagi and Yohei Kobayashi","Neural-network-assisted in situ processing monitoring by speckle pattern
  observation",,,,,"eess.IV eess.SP physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a method to monitor the progress of laser processing using laser
speckle patterns. Laser grooving and percussion drilling were performed using
femtosecond laser pulses. The speckle patterns from a processing point were
monitored with a high-speed camera and analyzed with a deep neural network. The
deep neural network enabled us to extract multiple information from the speckle
pattern without a need for analytical formulation. The trained neural network
was able to predict the ablation depth with an uncertainty of 2 \micron, as
well as the material under processing, which will be useful for composite
material processing.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:12:41 GMT""}]","2020-06-23"
"2006.11352","Douglas Duarte Novaes Dr.","Kamila da S. Andrade, Oscar A. R. Cespedes, Dayane R. Cruz, Douglas D.
  Novaes","Higher order Melnikov analysis for planar piecewise linear vector fields
  with nonlinear switching curve",,"Journal of Differential Equations 287 (2021) 1-36","10.1016/j.jde.2021.03.039",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we are interested in providing lower estimations for the
maximum number of limit cycles $H(n)$ that planar piecewise linear differential
systems with two zones separated by the curve $y=x^n$ can have, where $n$ is a
positive integer. For this, we perform a higher order Melnikov analysis for
piecewise linear perturbations of the linear center. In particular, we obtain
that $H(2)\geq 4,$ $H(3)\geq 8,$ $H(n)\geq7,$ for $n\geq 4$ even, and $H(n)\geq
9,$ for $n\geq 5$ odd. This improves all the previous results for $n\geq2.$ Our
analysis is mainly based on some recent results about Chebyshev systems with
positive accuracy and Melnikov theory, which will be developed at any order for
a class of nonsmooth differential systems with nonlinear switching manifold.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:15:54 GMT""},{""version"":""v2"",""created"":""Fri, 23 Apr 2021 17:04:07 GMT""}]","2021-04-26"
"2006.11353","Gwena\""el Joret","Gwena\""el Joret and Piotr Micek and Bruce Reed and Michiel Smid","Tight Bounds on the Clique Chromatic Number","v2: revised following referees' comments","Electronic Journal of Combinatorics, 28/3:P3.51, 2021","10.37236/9659",,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The clique chromatic number of a graph is the minimum number of colours
needed to colour its vertices so that no inclusion-wise maximal clique which is
not an isolated vertex is monochromatic. We show that every graph of maximum
degree $\Delta$ has clique chromatic number
$O\left(\frac{\Delta}{\log~\Delta}\right)$. We obtain as a corollary that every
$n$-vertex graph has clique chromatic number $O\left(\sqrt{\frac{n}{\log
~n}}\right)$. Both these results are tight.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:16:48 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 18:59:41 GMT""}]","2021-09-13"
"2006.11354","Karen Renaud","James Conacher, Karen Renaud, Jacques Ophoff","Caveat Venditor, Used USB Drive Owner",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  USB drives are a great way of transferring and backing up files. The problem
is that they are easily lost, and users do not understand how to secure or
properly erase them. When used to store private and sensitive information, this
constitutes a risk that users may be unaware of. Consider that people sell used
USB drives online -- presumably either their own or drives others have lost.
This raises some interesting questions, such as whether sellers know how to
ensure that private data is erased before they relinquish the drive to an
unknown buyer, and whether sellers use these drives in an attempt to compromise
an unwary buyer's device. Governments do indeed issue advice about the risks of
used mobile media, but we do not yet know whether this advice is reaching, and
being heeded by, the general public. To assess the situation, a sample of used
USB drives were purchased from eBay sellers to determine, first hand, what was
on the drives. This acts as an indicator of actual security-related behaviours
to answer the questions posed above. Using forensic analysis, it was found that
a great deal of private and sensitive information remained on many of the
drives, but there was no trace of malicious software. More effective ways of
enlightening the public are needed, so that private data is not unwittingly
leaked via sold used media.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:20:29 GMT""}]","2020-06-23"
"2006.11355","Tao Jiang","Tao Jiang, Stephen Vavasis","Certifying clusters from sum-of-norms clustering",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sum-of-norms clustering is a clustering formulation based on convex
optimization that automatically induces hierarchy. Multiple algorithms have
been proposed to solve the optimization problem: subgradient descent by Hocking
et al., ADMM and ADA by Chi and Lange, stochastic incremental algorithm by
Panahi et al. and semismooth Newton-CG augmented Lagrangian method by Sun et
al. All algorithms yield approximate solutions, even though an exact solution
is demanded to determine the correct cluster assignment. The purpose of this
paper is to close the gap between the output from existing algorithms and the
exact solution to the optimization problem. We present a clustering test that
identifies and certifies the correct cluster assignment from an approximate
solution yielded by any primal-dual algorithm. Our certification validates
clustering for both unit and multiplicative weights. The test may not succeed
if the approximation is inaccurate. However, we show the correct cluster
assignment is guaranteed to be certified by a primal-dual path following
algorithm after sufficiently many iterations, provided that the model parameter
$\lambda$ avoids a finite number of bad values. Numerical experiments are
conducted on Gaussian mixture and half-moon data, which indicate that carefully
chosen multiplicative weights increase the recovery power of sum-of-norms
clustering.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:26:26 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 06:13:34 GMT""}]","2021-07-09"
"2006.11356","Stacy Hobson","Stacy Hobson, Michael Hind, Aleksandra Mojsilovic, Kush R. Varshney","Trust and Transparency in Contact Tracing Applications","9 pages",,,,"cs.CY cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The global outbreak of COVID-19 has led to focus on efforts to manage and
mitigate the continued spread of the disease. One of these efforts include the
use of contact tracing to identify people who are at-risk of developing the
disease through exposure to an infected person. Historically, contact tracing
has been primarily manual but given the exponential spread of the virus that
causes COVID-19, there has been significant interest in the development and use
of digital contact tracing solutions to supplement the work of human contact
tracers. The collection and use of sensitive personal details by these
applications has led to a number of concerns by the stakeholder groups with a
vested interest in these solutions. We explore digital contact tracing
solutions in detail and propose the use of a transparent reporting mechanism,
FactSheets, to provide transparency of and support trust in these applications.
We also provide an example FactSheet template with questions that are specific
to the contact tracing application domain.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:29:24 GMT""}]","2020-06-23"
"2006.11357","Yamir Moreno","Jiachen Ye, Peng Ji, David Waxman, Wei Lin, Yamir Moreno","Impact of intra and inter-cluster coupling balance on the performance of
  nonlinear networked systems","14 pages and 5 figures. Submitted for publication",,"10.1016/j.chaos.2020.110065",,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dynamical and structural aspects of cluster synchronization (CS) in
complex systems have been intensively investigated in recent years. Here, we
study CS of dynamical systems with intra and inter-cluster couplings. We
propose new metrics that describe the performance of such systems and evaluate
them as a function of the strength of the couplings within and between
clusters. We obtain analytical results that indicate that spectral differences
between the Laplacian matrices associated with the partition between intra and
inter-couplings directly affect the proposed metrics of system performance. Our
results show that the dynamics of the system might exhibit an optimal balance
that optimizes its performance. Our work provides new insights into the way
specific symmetry properties relate to collective behavior, and could lead to
new forms to increase the controllability of complex systems and to optimize
their stability.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:32:29 GMT""}]","2020-08-26"
"2006.11358","George Younes","G. Younes (1,2), M. G. Baring (3), C. Kouveliotou (1,2), Z.
  Arzoumanian (4), T. Enoto (5), J. Doty (6), K. C. Gendreau (4), E.
  G\""o\u{g}\""u\c{s} (7), S. Guillot (8), T. G\""uver (9), A. K. Harding (4), W.
  C. G. Ho (10), A. J. van der Horst (1,2), G. K. Jaisawal (11), Y. Kaneko (7),
  B. J. LaMarr (12), L. Lin (13), W. Majid (14), T. Okajima (4), J. Pope (4),
  P. S. Ray (15), O. J. Roberts (16), M. Saylor (4), J. F. Steiner (17), Z.
  Wadiasingh (4) ((1 and 2) GWU, (3) Rice University, (4) NASA/GSFC, (5) RIKEN
  research, (6) Noqsi Aerospace, (7) Sabanci University, (8) IRAP, (9) Istanbul
  University, (10) Haverford college, (11) Technical University, (12) MIT, (13)
  Normal University of Beijing, (14) JPL, (15) NRL, (16) Harvard)","Broadband X-ray Burst Spectroscopy of the FRB-Emitting Galactic Magnetar","Resubmitted to Nature Astronomy - main results unchanged",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetars are young, magnetically-powered neutron stars possessing the
strongest magnetic fields in the Universe. Fast Radio Bursts (FRBs) are
extremely intense millisecond-long radio pulses of primarily extragalactic
origin, and a leading attribution for their genesis focuses on magnetars. A
hallmark signature of magnetars is their emission of bright, hard X-ray bursts
of sub-second duration. On April 27th 2020, the Galactic magnetar SGR
J1935+2154 emitted hundreds of X-ray bursts in a few hours. One of these
temporally coincided with an FRB, the first detection of an FRB from the Milky
Way. Here we present spectral and temporal analyses of 24 X-ray bursts emitted
13 hours prior to the FRB and seen simultaneously with the NASA NICER and
Fermi/GBM missions in their combined energy range, 0.2 keV-30 MeV. These
broadband spectra permit direct comparison with the spectrum of the
FRB-associated X-ray burst (FRB-X). We demonstrate that all 24 NICER/GBM bursts
are very similar temporally, albeit strikingly different spectrally, from
FRB-X. The singularity of the FRB-X burst is perhaps indicative of an uncommon
locale for its origin. We suggest that this event originated in quasi-polar
open or closed magnetic field lines that extend to high altitudes.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:32:51 GMT""},{""version"":""v2"",""created"":""Thu, 7 Jan 2021 17:35:39 GMT""}]","2021-01-08"
"2006.11359","Olivia Curtis","Olivia Curtis, Tereasa G. Brainerd","Fast Generation of Large-scale Structure Density Maps via Generative
  Adversarial Networks","3 pages, 1 figure, published in RNAAS","Res. Notes AAS, 4, 90 (2020)","10.3847/2515-5172/ab9e01",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative Adversarial Networks (GANs) are a recent advancement in
unsupervised machine learning. They are a cat-and-mouse game between two neural
networks: [1] a discriminator network which learns to validate whether a sample
is real or fake compared to a training set and [2] a generator network which
learns to generate data that appear to belong to the training set. Both
networks learn from each other until training is complete and the generator
network is able to produce samples that are indistinguishable from the training
set. We find that GANs are well-suited for fast generation of novel 3D density
maps that are indistinguishable from those obtained from N-body simulations. In
a matter of seconds, a fully trained GAN can generate thousands of density maps
at different epochs in the history of the universe. These GAN-generated maps
can then be used to study the evolution of large-scale structure over time.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:35:26 GMT""}]","2020-06-23"
"2006.11360","Shahrokh Hamidi","Shahrokh Hamidi and Safieddin Safavi-Naeini","CDM Based Virtual FMCW MIMO Radar Imaging at 79GHz",,,,,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  Multiple Input Multiple Output (MIMO) Frequency Modulated Continuous Wave
(FMCW) radars operating at 79GHz are compact, light and cost effective devices
with low peak-to-average power ratio that have applications in different areas
such as automotive industry and Unmanned Arial Vehicle (UAV) based radar
imaging. In order to keep the structure small and simple, these radars come
with small number of transmitters and receivers. The number of elements can be
virtually increased using techniques such as Time Division Multiplexing (TDM),
Frequency Division Multiplexing (FDM) or Code Division Multiplexing (CDM) and
as a result higher angular resolution can be achieved. Both TDM and FDM based
virtual FMCW MIMO radar imaging process have been reported in literature.
However, to the best of our knowledge CDM based virtual FMCW MIMO radar has not
received any attention. In this paper we will be using an 79GHz FMCW MIMO radar
and apply the idea of the CDM method to increase the number of elements
virtually which in turn enhances the angular resolution.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:38:23 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 14:04:01 GMT""},{""version"":""v3"",""created"":""Fri, 16 Oct 2020 21:38:27 GMT""}]","2020-10-20"
"2006.11361","Bingnan Zhang","Bingnan Zhang","Evidences of the Generalizations of BKT Transition in Quantum Clock
  Model",,"Phys. Rev. E 102, 042110 (2020)","10.1103/PhysRevE.102.042110",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We calculate the ground state energy density $\epsilon(g)$ for the one
dimensional N-state quantum clock model up to order 18, where $g$ is the
coupling and $N=3,4,5,...,10,20$. Using methods based on Pad\'e approximation,
we extract the singular structure of $\epsilon''(g)$ or $\epsilon(g)$. They
correspond to the specific heat and free energy of the classical 2D clock
model. We find that, for $N=3,4$, there is a single critical point at
$g_c=1$.The heat capacity exponent of the corresponding 2D classical model is
$\alpha=0.34\pm0.01$ for $N=3$, and $\alpha=-0.01\pm 0.01$ for $N=4$. For
$N>4$, There are two exponential singularities related by $g_{c1}=1/g_{c2}$,
and $\epsilon(g)$ behaves as $Ae^{-\frac{c}{|g_c-g|^{\sigma}}}+analytic\ terms$
near $g_c$. The exponent $\sigma$ gradually grows from $0.2$ to $0.5$ as N
increases from 5 to 9, and it stabilizes at 0.5 when $N>9$. These phase
transitions should be generalizations of Kosterlitz-Thouless transition, which
has $\sigma=0.5$. The physical pictures of these phase transitions are still
unclear.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:38:59 GMT""},{""version"":""v2"",""created"":""Mon, 12 Oct 2020 12:49:08 GMT""},{""version"":""v3"",""created"":""Sat, 10 Dec 2022 16:09:51 GMT""}]","2022-12-13"
"2006.11362","Lirong Xia","Lirong Xia","Optimal Statistical Hypothesis Testing for Social Choice",,,,,"math.ST cs.AI cs.GT stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the following question in this paper: ""What are the most robust
statistical methods for social choice?'' By leveraging the theory of uniformly
least favorable distributions in the Neyman-Pearson framework to finite models
and randomized tests, we characterize uniformly most powerful (UMP) tests,
which is a well-accepted statistical optimality w.r.t. robustness, for testing
whether a given alternative is the winner under Mallows' model and under
Condorcet's model, respectively.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:40:33 GMT""}]","2020-06-23"
"2006.11363","Andr\'es P\'aez","Andr\'es P\'aez","Moore's Paradox and the logic of belief",,"Manuscrito 43(2), 2020",,,"cs.LO cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Moores Paradox is a test case for any formal theory of belief. In Knowledge
and Belief, Hintikka developed a multimodal logic for statements that express
sentences containing the epistemic notions of knowledge and belief. His account
purports to offer an explanation of the paradox. In this paper I argue that
Hintikkas interpretation of one of the doxastic operators is philosophically
problematic and leads to an unnecessarily strong logical system. I offer a
weaker alternative that captures in a more accurate way our logical intuitions
about the notion of belief without sacrificing the possibility of providing an
explanation for problematic cases such as Moores Paradox.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:41:19 GMT""}]","2020-06-23"
"2006.11364","Alexander Lavin","Louise Naud and Alexander Lavin","Manifolds for Unsupervised Visual Anomaly Detection",,,,,"cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomalies are by definition rare, thus labeled examples are very limited or
nonexistent, and likely do not cover unforeseen scenarios. Unsupervised
learning methods that don't necessarily encounter anomalies in training would
be immensely useful. Generative vision models can be useful in this regard but
do not sufficiently represent normal and abnormal data distributions. To this
end, we propose constant curvature manifolds for embedding data distributions
in unsupervised visual anomaly detection. Through theoretical and empirical
explorations of manifold shapes, we develop a novel hyperspherical Variational
Auto-Encoder (VAE) via stereographic projections with a gyroplane layer - a
complete equivalent to the Poincar\'e VAE. This approach with manifold
projections is beneficial in terms of model generalization and can yield more
interpretable representations. We present state-of-the-art results on visual
anomaly benchmarks in precision manufacturing and inspection, demonstrating
real-world utility in industrial AI scenarios. We further demonstrate the
approach on the challenging problem of histopathology: our unsupervised
approach effectively detects cancerous brain tissue from noisy whole-slide
images, learning a smooth, latent organization of tissue types that provides an
interpretable decisions tool for medical professionals.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:41:58 GMT""}]","2020-06-23"
"2006.11365","John G. Cramer","John G. Cramer and Carver A. Mead","Symmetry, Transactions, and the Mechanism of Wave Function Collapse","48 pages, 19 figures; published in special Symmetry issue ""Symmetries
  in Quantum Mechanics""; revised to reflect referee suggestions","Symmetry 2020, 12(8), 1373","10.3390/sym12081373",,"quant-ph physics.hist-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Transactional Interpretation of quantum mechanics exploits the intrinsic
time-symmetry of wave mechanics to interpret the $\psi$ and $\psi$* wave
functions present in all wave mechanics calculations as representing retarded
and advanced waves moving in opposite time directions that form a quantum
""handshake"" or transaction. This handshake is a 4D standing-wave that builds up
across space-time to transfer the conserved quantities of energy, momentum, and
angular momentum in an interaction. Here we derive a two-atom quantum formalism
describing a transaction. We show that the bi-directional electromagnetic
coupling between atoms can be factored into a matched pair of vector potential
Green's functions: one retarded and one advanced, and that this combination
uniquely enforces the conservation of energy in a transaction. Thus factored,
the single-electron wave functions of electromagnetically-coupled atoms can be
analyzed using Schr\""odinger's original wave mechanics. The technique
generalizes to any number of electromagnetically coupled single-electron
states---no higher-dimensional space is needed. Using this technique, we show a
worked example of the transfer of energy from a hydrogen atom in an excited
state to a nearby hydrogen atom in its ground state. It is seen that the
initial exchange creates a dynamically unstable situation that avalanches to
the completed transaction, demonstrating that wave function collapse,
considered mysterious in the literature, can be implemented with solutions of
Schr\""odinger's original wave mechanics, coupled by this unique combination of
retarded/advanced vector potentials, without the introduction of any additional
mechanism or formalism. We also analyse a simplified version of the
photon-splitting and Freedman-Clauser three-electron experiments and show that
their results can be predicted by this formalism.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:43:09 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jul 2020 22:42:29 GMT""},{""version"":""v3"",""created"":""Tue, 4 Aug 2020 01:45:05 GMT""},{""version"":""v4"",""created"":""Wed, 19 Aug 2020 00:46:08 GMT""}]","2020-08-20"
"2006.11366","Dan Zeng","Dan Zeng, Raymond Veldhuis and Luuk Spreeuwers","A survey of face recognition techniques under occlusion",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The limited capacity to recognize faces under occlusions is a long-standing
problem that presents a unique challenge for face recognition systems and even
for humans. The problem regarding occlusion is less covered by research when
compared to other challenges such as pose variation, different expressions,
etc. Nevertheless, occluded face recognition is imperative to exploit the full
potential of face recognition for real-world applications. In this paper, we
restrict the scope to occluded face recognition. First, we explore what the
occlusion problem is and what inherent difficulties can arise. As a part of
this review, we introduce face detection under occlusion, a preliminary step in
face recognition. Second, we present how existing face recognition methods cope
with the occlusion problem and classify them into three categories, which are
1) occlusion robust feature extraction approaches, 2) occlusion aware face
recognition approaches, and 3) occlusion recovery based face recognition
approaches. Furthermore, we analyze the motivations, innovations, pros and
cons, and the performance of representative approaches for comparison. Finally,
future challenges and method trends of occluded face recognition are thoroughly
discussed.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:44:02 GMT""}]","2020-06-23"
"2006.11367","Julianne Moses","J. I. Moses, T. Cavalie, L. N. Fletcher, M. T. Roman","Atmospheric chemistry on Uranus and Neptune","review paper accepted in Philos. Trans. R. Soc. A",,"10.1098/rsta.2019.0477",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Comparatively little is known about atmospheric chemistry on Uranus and
Neptune, because remote spectral observations of these cold, distant ``Ice
Giants'' are challenging, and each planet has only been visited by a single
spacecraft during brief flybys in the 1980s. Thermochemical equilibrium is
expected to control the composition in the deeper, hotter regions of the
atmosphere on both planets, but disequilibrium chemical processes such as
transport-induced quenching and photochemistry alter the composition in the
upper atmospheric regions that can be probed remotely. Surprising disparities
in the abundance of disequilibrium chemical products between the two planets
point to significant differences in atmospheric transport. The atmospheric
composition of Uranus and Neptune can provide critical clues for unravelling
details of planet formation and evolution, but only if it is fully understood
how and why atmospheric constituents vary in a three-dimensional sense and how
material coming in from outside the planet affects observed abundances. Future
mission planning should take into account the key outstanding questions that
remain unanswered about atmospheric chemistry on Uranus and Neptune,
particularly those questions that pertain to planet formation and evolution,
and those that address the complex, coupled atmospheric processes that operate
on Ice Giants within our solar system and beyond.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:44:44 GMT""}]","2021-03-03"
"2006.11368","Raffaele Barretta","Raffaele Barretta, Andrea Caporale, S. Ali Faghidian, Raimondo
  Luciano, Francesco Marotti de Sciarra, Carlo Maria Medaglia","A stress-driven local-nonlocal mixture model for Timoshenko nano-beams",,,,,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A well-posed stress-driven mixture is proposed for Timoshenko nano-beams. The
model is a convex combination of local and nonlocal phases and circumvents some
problems of ill-posedness emerged in strain-driven Eringen-like formulations
for structures of nanotechnological interest. The nonlocal part of the mixture
is the integral convolution between stress field and a bi-exponential averaging
kernel function characterized by a scale parameter. The stress-driven mixture
is equivalent to a differential problem equipped with constitutive boundary
conditions involving bending and shear fields. Closed-form solutions of
Timoshenko nano-beams for selected boundary and loading conditions are
established by an effective analytical strategy. The numerical results exhibit
a stiffening behavior in terms of scale parameter.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:46:12 GMT""}]","2020-06-23"
"2006.11369","Ashwin Sah","Ashwin Sah, Mehtaab Sawhney","Local limit theorems for subgraph counts",,,"10.1112/jlms.12523",,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a general framework for studying anticoncentration and local
limit theorems for random variables, including graph statistics. Our methods
involve an interplay between Fourier analysis, decoupling, hypercontractivity
of Boolean functions, and transference between ``fixed-size'' and
``independent'' models. We also adapt a notion of ``graph factors'' due to
Janson.
  As a consequence, we derive a local central limit theorem for connected
subgraph counts in the Erd\H{o}s-Renyi random graph $G(n,p)$, building on work
of Gilmer and Kopparty and of Berkowitz. These results improve an
anticoncentration result of Fox, Kwan, and Sauermann and partially answers a
question of Fox, Kwan, and Sauermann. We also derive a local limit central
limit theorem for induced subgraph counts, as long as $p$ is bounded away from
a set of ``problematic'' densities, partially answering a question of Fox,
Kwan, and Sauermann. We then prove these restrictions are necessary by
exhibiting a disconnected graph for which anticoncentration for subgraph counts
at the optimal scale fails for all constant $p$, and finding a graph $H$ for
which anticoncentration for induced subgraph counts fails in $G(n,1/2)$. These
counterexamples resolve anticoncentration conjectures of Fox, Kwan, and
Sauermann in the negative.
  Finally, we also examine the behavior of counts of $k$-term arithmetic
progressions in subsets of $\mathbb{Z}/n\mathbb{Z}$ and deduce a local limit
theorem wherein the behavior is Gaussian at a global scale but has nontrivial
local oscillations (according to a Ramanujan theta function). These results
improve on results of and answer questions of the authors and Berkowitz, and
answer a question of Fox, Kwan, and Sauermann.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:47:02 GMT""}]","2022-03-09"
"2006.11370","Michael Martinez","Michael N. Martinez, Alex G. Smith, Miaochen Jin, Kevin B. Slater,
  Linsey M. Nowack, Binhua Lin, and Stuart A. Rice","Influence of Water Vapor on the Interaction Between Dodecane Thiol
  Ligated Au Nanoparticles","26 pages, 11 figures. Accepted for publication in JCP",,"10.1063/5.0065718",,"cond-mat.soft cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well-known that the interaction between passivated nanoparticles can be
tuned by their complete immersion in a chosen solvent, such as water. What
remains unclear on a molecular level is how nanoparticle interactions may be
altered in the presence of solvent vapor where complete immersion is not
achieved. In this paper, we report an all-atom molecular dynamics simulation
study of the change in pair potential of mean force between dodecane thiol
ligated gold nanoparticles (AuNPs) when exposed to water vapor. With the
equilibrium vapor pressure of water at 25 \degree C, there is very rapid
condensation of water molecules onto the surface of the AuNPs in the form of
mobile clusters of 100-2000 molecules that eventually coalesce into a few large
clusters. When the distance between two AuNPs decreases, a water cluster
bridging them provides an adhesive force that increases the depth and alters
the shape of the pair-potential of mean force. That change of shape includes a
decreased curvature near the minimum, consistent with experimental data showing
that cyclic exposure to water vapor and its removal reversibly decreases and
increases the Young's modulus of a freely suspended self-assembled monolayer of
these AuNPs.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:47:52 GMT""},{""version"":""v2"",""created"":""Fri, 25 Sep 2020 01:48:45 GMT""},{""version"":""v3"",""created"":""Tue, 21 Sep 2021 17:41:20 GMT""}]","2022-02-04"
"2006.11380","Marian-Gabriel Hancean","Marian-Gabriel H\^ancean (1), Miranda J. Lubbers (2) and Jos\'e Luis
  Molina (2) ((1) Department of Sociology, University of Bucharest, (2)
  Department of Social and Cultural Anthropology, Universitat Aut\`onoma de
  Barcelona)","Measuring transnational social fields through binational link-tracing
  sampling","37 pages, 8 figures",,"10.1371/journal.pone.0253042",,"cs.SI stat.ME","http://creativecommons.org/licenses/by/4.0/","  We advance binational link-tracing sampling design, an innovative data
collection methodology for sampling from transnational social fields, i.e.,
transnational networks embedding migrants and non-migrants. This paper shows
the practical challenges of such a design, the representativeness of the
samples and the qualities of the resulted networks. We performed 303
face-to-face structured interviews on sociodemographic variables, migration
trajectories and personal networks of people living in a Romanian migration
sending community (D\^ambovi\c{t}a) and in a migration receiving Spanish town
(Castell\'on), simultaneously in both sites. Inter-connecting the personal
networks, we built a multi-layered complex network structure embedding 4,855
nominated people, 5,477 directed ties (nominations) and 2,540 edges. Results
indicate that the participants' unique identification is a particularly
difficult challenge, the representativeness of the data is not optimal
(homophily on observed attributes was detected in the nomination patterns), and
the relational and attribute data allow to explore the social organization of
the Romanian migrant enclave in Castell\'on, as well as its connectivity to
other places. Furthermore, we provide methodological suggestions for improving
link-tracing sampling from transnational networks of migration. Our research
contributes to the emerging efforts of applying social network analysis to the
study of international migration.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:03:11 GMT""}]","2021-07-14"
"2006.11381","Lucas Pagliosa","Lucas Pagliosa, Alexandru Telea, Rodrigo Mello","Supporting Optimal Phase Space Reconstructions Using Neural Network
  Architecture for Time Series Modeling","13 pages (16 including references), 12 figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The reconstruction of phase spaces is an essential step to analyze time
series according to Dynamical System concepts. A regression performed on such
spaces unveils the relationships among system states from which we can derive
their generating rules, that is, the most probable set of functions responsible
for generating observations along time. In this sense, most approaches rely on
Takens' embedding theorem to unfold the phase space, which requires the
embedding dimension and the time delay. Moreover, although several methods have
been proposed to empirically estimate those parameters, they still face
limitations due to their lack of consistency and robustness, which has
motivated this paper. As an alternative, we here propose an artificial neural
network with a forgetting mechanism to implicitly learn the phase spaces
properties, whatever they are. Such network trains on forecasting errors and,
after converging, its architecture is used to estimate the embedding
parameters. Experimental results confirm that our approach is either as
competitive as or better than most state-of-the-art strategies while revealing
the temporal relationship among time-series observations.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:04:47 GMT""}]","2020-06-23"
"2006.11382","Frank Tackmann","Markus A. Ebert, Johannes K. L. Michel, Iain W. Stewart, and Frank J.
  Tackmann","Drell-Yan $q_T$ Resummation of Fiducial Power Corrections at N$^3$LL","81 pages + appendices, beautiful figures [abstract abridged]; v2:
  more beautiful figures (illustration of Born lepton projection, comparisons
  to normalized CMS spectra); v3: journal version (added figure with
  uncertainty breakdown)",,"10.1007/JHEP04(2021)102","DESY 20-016, MIT-CTP 5205","hep-ph hep-ex nucl-th","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We consider Drell-Yan production $pp\to V^* X \to L X$ at small $q_T \ll Q$.
Experimental measurements require fiducial cuts on the leptonic state $L$,
which introduce enhanced, linear power corrections in $q_T/Q$. We show that
they can be unambiguously predicted from factorization, and resummed to the
same order as the leading-power contribution. We thus obtain predictions for
the fiducial $q_T$ spectrum to N3LL and next-to-leading-power in $q_T/Q$.
Matching to full NNLO ($\alpha_s^2$), we find that the linear power corrections
are indeed the dominant ones, and the remaining fixed-order corrections become
almost negligible below $q_T \lesssim 40$ GeV. We also discuss the implications
for more complicated observables, and provide predictions for the fiducial
$\phi^*$ spectrum at N3LL+NNLO. We find excellent agreement with ATLAS and CMS
measurements of $q_T$ and $\phi^*$. We also consider the $p_T^\ell$ spectrum.
We show that it develops leptonic power corrections in $q_T/(Q - 2p_T^\ell)$,
which diverge near the Jacobian peak $p_T^\ell \sim Q/2$ and must be kept to
all powers to obtain a meaningful result there. Doing so, we obtain for the
first time an analytically resummed result for the $p_T^\ell$ spectrum around
the Jacobian peak at N3LL+NNLO. Our method is based on performing a complete
tensor decomposition for hadronic and leptonic tensors. In practice this is
equivalent to often-used recoil prescriptions, for which our results now
provide rigorous, formal justification. Our tensor decomposition yields nine
Lorentz-scalar hadronic structure functions, which directly map onto the
commonly used angular coefficients, but also holds for arbitrary leptonic final
states. In particular, for suitably defined Born-projected leptons it still
yields a LO-like angular decomposition even when including QED final-state
radiation. We also discuss the application to $q_T$ subtractions.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:07:16 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jul 2020 07:41:54 GMT""},{""version"":""v3"",""created"":""Thu, 24 Jun 2021 13:09:55 GMT""}]","2021-06-25"
"2006.11383","Yuantong Li","Yuantong Li, Qi Ma, and Sujit K. Ghosh","A Non-Iterative Quantile Change Detection Method in Mixture Model with
  Heavy-Tailed Components",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Estimating parameters of mixture model has wide applications ranging from
classification problems to estimating of complex distributions. Most of the
current literature on estimating the parameters of the mixture densities are
based on iterative Expectation Maximization (EM) type algorithms which require
the use of either taking expectations over the latent label variables or
generating samples from the conditional distribution of such latent labels
using the Bayes rule. Moreover, when the number of components is unknown, the
problem becomes computationally more demanding due to well-known label
switching issues \cite{richardson1997bayesian}. In this paper, we propose a
robust and quick approach based on change-point methods to determine the number
of mixture components that works for almost any location-scale families even
when the components are heavy tailed (e.g., Cauchy). We present several
numerical illustrations by comparing our method with some of popular methods
available in the literature using simulated data and real case studies. The
proposed method is shown be as much as 500 times faster than some of the
competing methods and are also shown to be more accurate in estimating the
mixture distributions by goodness-of-fit tests.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:08:11 GMT""}]","2020-06-23"
"2006.11385","Benyamin Ghojogh","Benyamin Ghojogh, Fakhri Karray, Mark Crowley","Quantile-Quantile Embedding for Distribution Transformation and Manifold
  Embedding with Ability to Choose the Embedding Distribution","Published in Machine Learning with Applications, Elsevier, Volume 6,
  Pages 100088, 2021","Machine Learning with Applications, Elsevier, Volume 6, Pages
  100088, 2021","10.1016/j.mlwa.2021.100088",,"stat.ML cs.CV cs.LG stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new embedding method, named Quantile-Quantile Embedding (QQE),
for distribution transformation and manifold embedding with the ability to
choose the embedding distribution. QQE, which uses the concept of
quantile-quantile plot from visual statistical tests, can transform the
distribution of data to any theoretical desired distribution or empirical
reference sample. Moreover, QQE gives the user a choice of embedding
distribution in embedding the manifold of data into the low dimensional
embedding space. It can also be used for modifying the embedding distribution
of other dimensionality reduction methods, such as PCA, t-SNE, and deep metric
learning, for better representation or visualization of data. We propose QQE in
both unsupervised and supervised forms. QQE can also transform a distribution
to either an exact reference distribution or its shape. We show that QQE allows
for better discrimination of classes in some cases. Our experiments on
different synthetic and image datasets show the effectiveness of the proposed
embedding method.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:09:09 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 03:06:05 GMT""}]","2021-07-12"
"2006.11386","Jason Hartford","Jason Hartford, Victor Veitch, Dhanya Sridhar, Kevin Leyton-Brown","Valid Causal Inference with (Some) Invalid Instruments",,,,,"stat.ME cs.LG econ.EM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Instrumental variable methods provide a powerful approach to estimating
causal effects in the presence of unobserved confounding. But a key challenge
when applying them is the reliance on untestable ""exclusion"" assumptions that
rule out any relationship between the instrument variable and the response that
is not mediated by the treatment. In this paper, we show how to perform
consistent IV estimation despite violations of the exclusion assumption. In
particular, we show that when one has multiple candidate instruments, only a
majority of these candidates---or, more generally, the modal candidate-response
relationship---needs to be valid to estimate the causal effect. Our approach
uses an estimate of the modal prediction from an ensemble of instrumental
variable estimators. The technique is simple to apply and is ""black-box"" in the
sense that it may be used with any instrumental variable estimator as long as
the treatment effect is identified for each valid instrument independently. As
such, it is compatible with recent machine-learning based estimators that allow
for the estimation of conditional average treatment effects (CATE) on complex,
high dimensional data. Experimentally, we achieve accurate estimates of
conditional average treatment effects using an ensemble of deep network-based
estimators, including on a challenging simulated Mendelian Randomization
problem.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:09:26 GMT""}]","2020-06-23"
"2006.11387","Michael Florian","Michael K. Florian, Jane R. Rigby, Ayan Acharyya, Keren Sharon,
  Michael D. Gladders, Lisa Kewley, Gourav Khullar, Katya Gozman, Gabriel
  Brammer, Ivelina Momcheva, David Nicholls, Stephanie LaMassa, Hakon Dahle,
  Matthew B. Bayliss, Eva Wuyts, Traci Johnson, Katherine Whitaker","Spatial Variation in Strong Line Ratios and Physical Conditions in Two
  Strongly-Lensed Galaxies at z~1.4","24 pages, including references, 6 tables, 17 figures, and appendix.
  Submitted to ApJ June 19, 2020",,"10.3847/1538-4357/ac0257",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For studies of galaxy formation and evolution, one of the major benefits of
the James Webb Space Telescope is that space-based IFUs like those on its
NIRSpec and MIRI instruments will enable spatially resolved spectroscopy of
distant galaxies, including spectroscopy at the scale of individual
star-forming regions in galaxies that have been gravitationally lensed. In the
meantime, there is only a very small subset of lensed sources where work like
this is possible even with the Hubble Space Telescope's Wide Field Camera 3
infrared channel grisms. We examine two of these sources, SDSS J1723+3411 and
SDSS J2340+2947, using HST WFC3/IR grism data and supporting
spatially-unresolved spectroscopy from several ground-based instruments to
explore the size of spatial variations in observed strong emission line ratios
like O32, R23, which are sensitive to ionization parameter and metallicity, and
the Balmer decrement as an indicator of reddening. We find significant spatial
variation in the reddening and the reddening-corrected O32 and R23 values which
correspond to spreads of a few tenths of a dex in ionization parameter and
metallicity. We also find clear evidence of a negative radial gradient in star
formation in SDSS J2340+2947 and tentative evidence of one in SDSS J1723+3411,
though its star formation is quite asymmetric. Finally, we find that reddening
can vary enough spatially to make spatially-resolved reddening corrections
necessary in order to characterize gradients in line ratios and the physical
conditions inferred from them, necessitating the use of space-based IFUs for
future work on larger, more statistically robust samples.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:10:02 GMT""}]","2021-08-04"
"2006.11390","Yunlong Feng","Yunlong Feng","New Insights into Learning with Correntropy Based Regression",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stemming from information-theoretic learning, the correntropy criterion and
its applications to machine learning tasks have been extensively explored and
studied. Its application to regression problems leads to the robustness
enhanced regression paradigm -- namely, correntropy based regression. Having
drawn a great variety of successful real-world applications, its theoretical
properties have also been investigated recently in a series of studies from a
statistical learning viewpoint. The resulting big picture is that correntropy
based regression regresses towards the conditional mode function or the
conditional mean function robustly under certain conditions. Continuing this
trend and going further, in the present study, we report some new insights into
this problem. First, we show that under the additive noise regression model,
such a regression paradigm can be deduced from minimum distance estimation,
implying that the resulting estimator is essentially a minimum distance
estimator and thus possesses robustness properties. Second, we show that the
regression paradigm, in fact, provides a unified approach to regression
problems in that it approaches the conditional mean, the conditional mode, as
well as the conditional median functions under certain conditions. Third, we
present some new results when it is utilized to learn the conditional mean
function by developing its error bounds and exponential convergence rates under
conditional $(1+\epsilon)$-moment assumptions. The saturation effect on the
established convergence rates, which was observed under $(1+\epsilon)$-moment
assumptions, still occurs, indicating the inherent bias of the regression
estimator. These novel insights deepen our understanding of correntropy based
regression, help cement the theoretic correntropy framework, and also enable us
to investigate learning schemes induced by general bounded nonconvex loss
functions.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:14:34 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 18:55:19 GMT""},{""version"":""v3"",""created"":""Sun, 19 Jul 2020 04:36:20 GMT""},{""version"":""v4"",""created"":""Tue, 21 Jul 2020 20:42:20 GMT""}]","2020-07-23"
"2006.11398","Mark Whiting","Abdullah Almaatouq, Joshua Becker, James P. Houghton, Nicolas Paton,
  Duncan J. Watts, Mark E. Whiting","Empirica: a virtual lab for high-throughput macro-level experiments","36 pages, 6 figures. Accepted to Behavioral Research Methods. Behav
  Res (2021)",,"10.3758/s13428-020-01535-9",,"cs.HC cs.CY cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Virtual labs allow researchers to design high-throughput and macro-level
experiments that are not feasible in traditional in-person physical lab
settings. Despite the increasing popularity of online research, researchers
still face many technical and logistical barriers when designing and deploying
virtual lab experiments. While several platforms exist to facilitate the
development of virtual lab experiments, they typically present researchers with
a stark trade-off between usability and functionality. We introduce Empirica: a
modular virtual lab that offers a solution to the usability-functionality
trade-off by employing a ""flexible defaults"" design strategy. This strategy
enables us to maintain complete ""build anything"" flexibility while offering a
development platform that is accessible to novice programmers. Empirica's
architecture is designed to allow for parameterizable experimental designs,
reusable protocols, and rapid development. These features will increase the
accessibility of virtual lab experiments, remove barriers to innovation in
experiment design, and enable rapid progress in the understanding of
distributed human computation.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:28:07 GMT""},{""version"":""v2"",""created"":""Wed, 30 Dec 2020 15:57:28 GMT""}]","2021-04-13"
"2006.11399","Andreas Eckart","Basel Ali, Daria Paul, Andreas Eckart, Marzieh Parsa, Michal Zajacek,
  Florian Pei{\ss}ker, Matthias Subroweit, Monica Valencia-S., Lauritz
  Thomkins, and Gunther Witzel","Kinematic Structure of the Galactic Center S-cluster","published in Astrophysical Journal 23 pages, 6 tabels, 16 figures,
  ENHANCED GRAPHICS in ApJ in fullorbits.gif circularized.gif normalized.gif",,"10.3847/1538-4357/ab93ae",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a detailed analysis of the kinematics of 112 stars that mostly
comprise the high velocity S-cluster and orbit the super massive black hole
SgrA* at the center of the Milky Way. For 39 of them orbital elements are
known, for the remainder we know proper motions. The distribution of
inclinations, and proper motion flight directions deviate significantly from a
uniform distribution which one expects if the orientation of the orbits are
random. Across the central arcseconds the S-cluster stars are arranged in two
almost edge on disks that are located at a position angle approximately +-45 o
with respect to the Galactic plane. The angular momentum vectors for stars in
each disk point in both directions, i.e. the stars in a given disk rotate in
opposite ways. The poles of this structure are located only about 25 o from the
line of sight. This structure may be the result of a resonance process that
started with the formation of the young B-dwarf stars in the cluster about 6
Myr ago. Alternatively, it indicated the presence of a disturber at a distance
from the center comparable to the distance of the compact stellar association
IRS13.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:36:39 GMT""}]","2020-07-01"
"2006.11400","James Weatherall","James Owen Weatherall","Two Dogmas of Dynamicism","33 pages",,,,"physics.hist-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I critically discuss two dogmas of the ""dynamical approach"" to spacetime in
general relativity, as advanced by Harvey Brown [Physical Relativity (2005)
Oxford:Oxford University Press] and collaborators. The first dogma is that
positing a ""spacetime geometry"" has no implications for the behavior of matter.
The second dogma is that postulating the ""Strong Equivalence Principle""
suffices to ensure that matter is ""adapted"" to spacetime geometry. I conclude
by discussing ""spacetime functionalism"". The discussion is presented in
reaction to and sympathy with recent work by James Read [""Explanation,
geometry, and conspiracy in relativity theory""(20??) Thinking about Spacetime.
Boston: Birkauser].
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:37:22 GMT""},{""version"":""v2"",""created"":""Thu, 17 Sep 2020 05:28:03 GMT""}]","2020-09-18"
"2006.11401","Peijun Xiao","Tian Ye, Peijun Xiao and Ruoyu Sun","DEED: A General Quantization Scheme for Communication Efficiency in Bits",,,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In distributed optimization, a popular technique to reduce communication is
quantization. In this paper, we provide a general analysis framework for
inexact gradient descent that is applicable to quantization schemes. We also
propose a quantization scheme Double Encoding and Error Diminishing (DEED).
DEED can achieve small communication complexity in three settings:
frequent-communication large-memory, frequent-communication small-memory, and
infrequent-communication (e.g. federated learning). More specifically, in the
frequent-communication large-memory setting, DEED can be easily combined with
Nesterov's method, so that the total number of bits required is $\tilde{O}(
\sqrt{\kappa} \log 1/\epsilon )$, where $\tilde{O}$ hides numerical constant
and $\log \kappa$ factors. In the frequent-communication small-memory setting,
DEED combined with SGD only requires $\tilde{O}( \kappa \log 1/\epsilon)$
number of bits in the interpolation regime. In the infrequent communication
setting, DEED combined with Federated averaging requires a smaller total number
of bits than Federated Averaging. All these algorithms converge at the same
rate as their non-quantized versions, while using a smaller number of bits.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:38:44 GMT""}]","2020-06-23"
"2006.11402","Domenico D'Alessandro","Francesca Albertini and Domenico D'Alessandro","Subspace controllability of multi-partite spin networks","14 pages, 3 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a network of spin 1/2 particles, controlled through an external
electro-magnetic field, the gyromagnetic ratio of each spin is a parameter that
characterizes the interaction of the spin with the external control field.
Multipartite networks are such that the spins are divided into subsets
according to their gyromagnetic ratio and spins in one set interact in the same
way with all spins in another set. Due to the presence of symmetries in this
type of systems, the underlying Hilbert state space splits into invariant
subspaces for the dynamics. Subspace controllability is verified if every
unitary evolution can be generated by the dynamics on these subspaces. We give
an exact characterization, in term of graph theoretic conditions, of subspace
controllability for multipartite quantum spin networks. This extends and
unifies previous results.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:38:49 GMT""}]","2020-06-23"
"2006.11414","Andre Sieverding","Zewei Xiong, Andre Sieverding, Manibrata Sen, Yong-Zhong Qian","Potential Impact of Fast Flavor Oscillations on Neutrino-driven Winds
  and Their Nucleosynthesis","12 pages, 7 figures, 2 tables, submitted to ApJ","The Astrophysical Journal, Volume 900, Issue 2, id.144, 10 pp.
  (2020)","10.3847/1538-4357/abac5e",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The wind driven by the intense neutrino emission from a protoneutron star
(PNS) is an important site for producing nuclei heavier than the Fe group.
Because of certain features in the neutrino angular distributions, the
so-called fast flavor oscillations may occur very close to the PNS surface,
effectively resetting the neutrino luminosities and energy spectra that drive
the wind.
  Using the unoscillated neutrino emission characteristics from two
core-collapse supernova simulations representative of relevant progenitors at
the lower and higher mass end, we study the potential effects of fast flavor
oscillations on neutrino-driven winds and their nucleosynthesis.
  We find that such oscillations can increase the total mass loss by factors up
to ~ 1.5-1.7 and lead to significantly more proton-rich conditions. The latter
effect can greatly enhance the production of 64Zn and the so-called light
p-nuclei 74Se, 78Kr, and 84Sr. Implications for abundances in metal-poor stars,
Galactic chemical evolution in general, and isotopic anomalies in meteorites
are discussed.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:48:13 GMT""}]","2020-12-21"
"2006.11415","Robert Dennis","R. C. Dennis and E. I. Corwin","Dionysian Hard Sphere Packings are Mechanically Stable at Vanishingly
  Low Densities","4 pages, 3 figures",,,,"cond-mat.soft cond-mat.mtrl-sci cond-mat.stat-mech physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High strength-to-weight ratio materials can be constructed by either
maximizing strength or minimizing weight. Tensegrity structures and aerogels
take very different paths to achieving high strength-to-weight ratios but both
rely on internal tensile forces. In the absence of tensile forces, removing
material eventually destabilizes a structure. Attempts to maximize the
strength-to-weight ratio with purely repulsive spheres have proceeded by
removing spheres from already stable crystalline structures. This results in a
modestly low density and a strength-to-weight ratio much worse than can be
achieved with tensile materials. Here, we demonstrate the existence of a
packing of hard spheres that has asymptotically zero density and yet maintains
finite strength, thus achieving an unbounded strength-to-weight ratio. This
construction, which we term Dionysian, is the diametric opposite to the
Apollonian sphere packing which completely and stably fills space. We create
tools to evaluate the stability and strength of compressive sphere packings.
Using these we find that our structures have asymptotically finite bulk and
shear moduli and are linearly resistant to every applied deformation, both
internal and external. By demonstrating that there is no lower bound on the
density of stable structures, this work allows for the construction of
arbitrarily lightweight high-strength materials.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:51:16 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 23:40:00 GMT""},{""version"":""v3"",""created"":""Thu, 2 Sep 2021 20:49:23 GMT""}]","2021-09-06"
"2006.11416","S V Aruna Kumar","S V Aruna Kumar, Ehsan Yaghoubi and Hugo Proen\c{c}a","A Symbolic Temporal Pooling method for Video-based Person
  Re-Identification","11 pages",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In video-based person re-identification, both the spatial and temporal
features are known to provide orthogonal cues to effective representations.
Such representations are currently typically obtained by aggregating the
frame-level features using max/avg pooling, at different points of the models.
However, such operations also decrease the amount of discriminating information
available, which is particularly hazardous in case of poor separability between
the different classes. To alleviate this problem, this paper introduces a
symbolic temporal pooling method, where frame-level features are represented in
the distribution valued symbolic form, yielding from fitting an Empirical
Cumulative Distribution Function (ECDF) to each feature. Also, considering that
the original triplet loss formulation cannot be applied directly to this kind
of representations, we introduce a symbolic triplet loss function that infers
the similarity between two symbolic objects. Having carried out an extensive
empirical evaluation of the proposed solution against the state-of-the-art, in
four well known data sets (MARS, iLIDS-VID, PRID2011 and P-DESTRE), the
observed results point for consistent improvements in performance over the
previous best performing techniques.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:52:33 GMT""}]","2020-06-23"
"2006.11417","Marcio Sampaio Gomes-Filho","M\'arcio S. Gomes-Filho, Andr\'e L. A. Penna and Fernando A. Oliveira","The Kardar-Parisi-Zhang exponents for the $2+1$ dimensions",,"Results in Physics, p. 104435, v. 26 (2021)","10.1016/j.rinp.2021.104435",,"cond-mat.stat-mech nlin.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Kardar-Parisi-Zhang (KPZ) equation has been connected to a large number
of important stochastic processes in physics, chemistry and growth phenomena,
ranging from classical to quantum physics. The central quest in this field is
the search for ever more precise universal growth exponents. Notably, exact
growth exponents are only known for $1+1$ dimensions. In this work, we present
physical and geometric analytical methods that directly associate these
exponents to the fractal dimension of the rough interface. Based on this, we
determine the growth exponents for the $2+1$ dimensions, which are in agreement
with the results of thin films experiments and precise simulations. We also
make a first step towards a solution in $d+1$ dimensions, where our results
suggest the inexistence of an upper critical dimension.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:56:13 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 19:31:09 GMT""},{""version"":""v3"",""created"":""Sun, 28 Jun 2020 20:01:36 GMT""},{""version"":""v4"",""created"":""Thu, 16 Jul 2020 13:42:27 GMT""},{""version"":""v5"",""created"":""Mon, 29 Nov 2021 20:12:00 GMT""}]","2021-12-01"
"2006.11418","Renato J Cintra","D. R. Canterle, T. L. T. da Silveira, F. M. Bayer, R. J. Cintra","A Multiparametric Class of Low-complexity Transforms for Image and Video
  Coding","Fixed Figure 1 and typos in the reference list","Signal Processing, Volume 176, November 2020","10.1016/j.sigpro.2020.107685",,"eess.SP cs.CV cs.MM eess.IV stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Discrete transforms play an important role in many signal processing
applications, and low-complexity alternatives for classical transforms became
popular in recent years. Particularly, the discrete cosine transform (DCT) has
proven to be convenient for data compression, being employed in well-known
image and video coding standards such as JPEG, H.264, and the recent high
efficiency video coding (HEVC). In this paper, we introduce a new class of
low-complexity 8-point DCT approximations based on a series of works published
by Bouguezel, Ahmed and Swamy. Also, a multiparametric fast algorithm that
encompasses both known and novel transforms is derived. We select the
best-performing DCT approximations after solving a multicriteria optimization
problem, and submit them to a scaling method for obtaining larger size
transforms. We assess these DCT approximations in both JPEG-like image
compression and video coding experiments. We show that the optimal DCT
approximations present compelling results in terms of coding efficiency and
image quality metrics, and require only few addition or bit-shifting
operations, being suitable for low-complexity and low-power systems.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:56:58 GMT""}]","2020-06-23"
"2006.11419","Chuangchuang Sun","Chuangchuang Sun, Dong-Ki Kim, Jonathan P. How","FISAR: Forward Invariant Safe Reinforcement Learning with a Deep Neural
  Network-Based Optimize","Accepted to ICML 2020 Workshop Theoretical Foundations of RL;
  Accepted to ICRA 2021",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates reinforcement learning with constraints, which are
indispensable in safety-critical environments. To drive the constraint
violation monotonically decrease, we take the constraints as Lyapunov functions
and impose new linear constraints on the policy parameters' updating dynamics.
As a result, the original safety set can be forward-invariant. However, because
the new guaranteed-feasible constraints are imposed on the updating dynamics
instead of the original policy parameters, classic optimization algorithms are
no longer applicable. To address this, we propose to learn a generic deep
neural network (DNN)-based optimizer to optimize the objective while satisfying
the linear constraints. The constraint-satisfaction is achieved via projection
onto a polytope formulated by multiple linear inequality constraints, which can
be solved analytically with our newly designed metric. To the best of our
knowledge, this is the \textit{first} DNN-based optimizer for constrained
optimization with the forward invariance guarantee. We show that our optimizer
trains a policy to decrease the constraint violation and maximize the
cumulative reward monotonically. Results on numerical constrained optimization
and obstacle-avoidance navigation validate the theoretical findings.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 21:58:42 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 03:11:59 GMT""},{""version"":""v3"",""created"":""Tue, 3 Nov 2020 16:16:15 GMT""},{""version"":""v4"",""created"":""Wed, 5 May 2021 23:42:55 GMT""}]","2021-05-07"
"2006.11420","Sergio Correia","Sergio Alvarez","From H\""older Triangles to the Whole Plane",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how to determine whether two given real polynomial functions of a
single variable are Lipschitz equivalent by comparing the values and also the
multiplicities of the given polynomial functions at their critical points. Then
we show how to reduce the problem of ${\cal R}$-semialgebraic Lipschitz
classification of $\beta$-quasihomogeneous polynomials of two real variables to
the problem of Lipschitz classification of real polynomial functions of a
single variable, under some fairly general conditions.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:01:29 GMT""}]","2020-06-23"
"2006.11421","Xingyou Song","Krzysztof Choromanski, Jared Quincy Davis, Valerii Likhosherstov,
  Xingyou Song, Jean-Jacques Slotine, Jacob Varley, Honglak Lee, Adrian Weller,
  Vikas Sindhwani","An Ode to an ODE","20 pages, 9 figures",,,,"cs.LG math.CA math.DS math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new paradigm for Neural ODE algorithms, called ODEtoODE, where
time-dependent parameters of the main flow evolve according to a matrix flow on
the orthogonal group O(d). This nested system of two flows, where the
parameter-flow is constrained to lie on the compact manifold, provides
stability and effectiveness of training and provably solves the gradient
vanishing-explosion problem which is intrinsically related to training deep
neural network architectures such as Neural ODEs. Consequently, it leads to
better downstream models, as we show on the example of training reinforcement
learning policies with evolution strategies, and in the supervised learning
setting, by comparing with previous SOTA baselines. We provide strong
convergence results for our proposed mechanism that are independent of the
depth of the network, supporting our empirical studies. Our results show an
intriguing connection between the theory of deep neural networks and the field
of matrix flows on compact manifolds.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:05:19 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 01:01:05 GMT""}]","2020-06-24"
"2006.11422","Ian Melbourne","Alexey Korepanov, Zemer Kosloff and Ian Melbourne","Deterministic homogenization under optimal moment assumptions for
  fast-slow systems. Part 1",,"Ann. Inst. H. Poincare (B) Probab. Statist. 58 (2022) 1305-1327",,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider deterministic homogenization (convergence to a stochastic
differential equation) for multiscale systems of the form \[
  x_{k+1} = x_k + n^{-1} a_n(x_k,y_k) + n^{-1/2} b_n(x_k,y_k), \quad y_{k+1} =
T_n y_k, \] where the fast dynamics is given by a family $T_n$ of nonuniformly
expanding maps. Part 1 builds on our recent work on martingale approximations
for families of nonuniformly expanding maps. We prove an iterated weak
invariance principle and establish optimal iterated moment bounds for such
maps. (The iterated moment bounds are new even for a fixed nonuniformly
expanding map T.) The homogenization results are a consequence of this together
with parallel developments on rough path theory in Part 2 by Chevyrev, Friz,
Korepanov, Melbourne & Zhang.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:12:08 GMT""}]","2022-07-19"
"2006.11423","Long Peng","Long Peng, Yong Tang, Lamine Mili, Yingbiao Li, Bing Zhao, Yijun Xu,
  Fan Cheng","An Adaptive MMC Synchronous Stability Control Method Based on Local PMU
  measurements","8 pages, 15 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reducing the current is a common method to ensure the synchronous stability
of a modular multilevel converter (MMC) when there is a short-circuit fault at
its AC side. However, the uncertainty of the fault location of the AC system
leads to a significant difference in the maximum allowable stable operating
current during the fault. This paper proposes an adaptive MMC fault-current
control method using local phasor measurement unit (PMU) measurements. Based on
the estimated Thevenin equivalent (TE) parameters of the system, the current
can be directly calculated to ensure the maximum output power of the MMC during
the fault. This control method does not rely on off-line simulation and adapts
itself to various fault conditions. The effective measurements are firstly
selected by the voltage threshold and parameter constraints, which allow us to
handle the error due to the change on the system-side. The proposed TE
estimation method can fast track the change of the system impedance without
depending on the initial value and can deal with the TE potential changes after
a large disturbance. The simulation shows that the TE estimation can accurately
track the TE parameters after the fault, and the current control instruction
during an MMC fault can ensure the maximum output power of the MMC.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:12:26 GMT""}]","2020-06-23"
"2006.11424","Pavan Madhusudana","Pavan C. Madhusudana, Neil Birkbeck, Yilin Wang, Balu Adsumilli, Alan
  C. Bovik","Capturing Video Frame Rate Variations via Entropic Differencing",,"IEEE Signal Processing Letters. 27 (2020) 1809-1813","10.1109/LSP.2020.3028687",,"cs.MM cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High frame rate videos are increasingly getting popular in recent years,
driven by the strong requirements of the entertainment and streaming industries
to provide high quality of experiences to consumers. To achieve the best
trade-offs between the bandwidth requirements and video quality in terms of
frame rate adaptation, it is imperative to understand the effects of frame rate
on video quality. In this direction, we devise a novel statistical entropic
differencing method based on a Generalized Gaussian Distribution model
expressed in the spatial and temporal band-pass domains, which measures the
difference in quality between reference and distorted videos. The proposed
design is highly generalizable and can be employed when the reference and
distorted sequences have different frame rates. Our proposed model correlates
very well with subjective scores in the recently proposed LIVE-YT-HFR database
and achieves state of the art performance when compared with existing
methodologies.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:16:52 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 01:02:00 GMT""}]","2020-10-22"
"2006.11425","Maximilian Schlosshauer","Mathew R. Coleman, Kaylin G. Ingalls, John T. Kavulich, Sawyer J.
  Kemmerly, Nicolas C. Salinas, Efrain Venegas Ramirez, Maximilian Schlosshauer","Parity-based, bias-free optical quantum random number generation with
  min-entropy estimation","9 pages, 1 figure, matches published version","J. Opt. Soc. Am. B 37, 2088-2094 (2020)","10.1364/JOSAB.392286",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the generation of sequences of random bits from the parity of
photon counts produced by polarization measurements on a polarization-entangled
state. The resulting sequences are bias free, pass the applicable tests in the
NIST battery of statistical randomness tests, and are shown to be Borel normal,
without the need for experimental calibration stages or postprocessing of the
output. Because the photon counts are produced in the course of a measurement
of the violation of the Clauser-Horne-Shimony-Holt inequality, we are able to
concurrently verify the nonclassical nature of the photon statistics and
estimate a lower bound on the min-entropy of the bit-generating source. The
rate of bit production in our experiment is around 13 bits/s.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:21:34 GMT""}]","2020-06-23"
"2006.11426","Bastien Baldacci","Bastien Baldacci, Jerome Benveniste","A note on Almgren-Chriss optimal execution problem with geometric
  Brownian motion",,,,,"q-fin.TR q-fin.CP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We solve explicitly the Almgren-Chriss optimal liquidation problem where the
stock price process follows a geometric Brownian motion. Our technique is to
work in terms of cash and to use functional analysis tools. We show that this
framework extends readily to the case of a stochastic drift for the price
process and the liquidation of a portfolio.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:26:08 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 20:18:56 GMT""}]","2020-06-25"
"2006.11427","Patrick Neunteufel","Patrick Neunteufel","Velocity limits in the thermonuclear supernova ejection scenario for
  hypervelocity stars and the origin of US 708","17 pages, 14 figures, accepted for publication by A&A, replacement
  due to typo in Fig. 11","A&A 641, A52 (2020)","10.1051/0004-6361/202037792",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hypervelocity stars (HVS) are a class of stars moving at high enough
velocities to be gravitationally unbound from the Galaxy. Ejection from a close
binary system in which one of the components undergoes a thermonuclear
supernova (SN) has emerged as a promising candidate production mechanism for
the least massive specimens of this class. This study presents a thorough
theoretical analysis of candidate progenitor systems of thermonuclear SNe in
the single degenerate helium donor scenario in the relevant parameter space
leading to the ejection of HVS. The primary goal is investigation of the,
previously unclear, characteristics of the velocity spectra of the ejected
component. Presented are the results of 390 binary model sequences computed
with the MESA framework, investigating the evolution of supernova progenitors
composed of a helium-rich hot subdwarf and a accreting white dwarf. Results are
then correlated with an idealized kinematic analysis of the observed object US
708. It is seen that the ejection velocity spectra reach a maximum in the range
$0.19~M_\odot < M_{HVS} < 0.25~M_\odot$. Depending on the local Galactic
potential, all donors below $0.4~\text{M}_\odot$ are expected to become HVS.
This channel is able to account for runaway velocities up to $\sim1150~\text{km
s}^{-1}$ with a Chandrasekhar mass accretor, exceeding $1200~\text{km s}^{-1}$
if super-Chandrasekhar mass detonations are taken into account. It is found
that the previously assumed mass of $0.3~M_\odot$ for US 708, combined with
more recently obtained proper motions, favor a sub-Chandrasekhar mass explosion
with a terminal WD mass between $1.1~M_\odot$ and $1.2~M_\odot$. The presence
of clear ejection velocity maxima provides constraints on the terminal state of
a supernova progenitor. It is possible to discern certain types of explosion
mechanisms from the inferred ejection velocities alone.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:28:08 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 15:40:34 GMT""}]","2020-09-09"
"2006.11428","Karl Grosse-Erdmann","Antonio Bonilla, Karl-G. Grosse-Erdmann, Antoni L\'opez-Mart\'inez,
  Alfred Peris","Frequently recurrent operators",,"Journal of Functional Analysis, Volume 283, Issue 12, 15 December
  2022, 109713","10.1016/j.jfa.2022.109713",,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by a recent investigation of Costakis et al. on the notion of
recurrence in linear dynamics, we study various stronger forms of recurrence
for linear operators, in particular that of frequent recurrence. We study,
among other things, the relationship between a type of recurrence and the
corresponding notion of hypercyclicity, the influence of power boundedness, and
the interplay between recurrence and spectral properties. We obtain, in
particular, Ansari- and L\'eon-M\""uller-type theorems for
$\mathcal{F}$-recurrence under very weak assumptions on the Furstenberg family
$\mathcal{F}$. This allows us, as a by-product, to deduce Ansari- and
L\'eon-M\""uller-type theorems for $\mathcal{F}$-hypercyclicity.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:33:20 GMT""},{""version"":""v2"",""created"":""Fri, 23 Sep 2022 18:00:36 GMT""}]","2022-12-22"
"2006.11429","Tom Kennedy","Tom Kennedy","Absence of renormalization group pathologies in some critical
  Dyson-Ising ferromagnets","23 pages, no figures",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Dyson-Ising ferromagnet is a one-dimensional Ising model with a power law
interaction. When the power is between -1 and -2, the model has a phase
transition. Van Enter and Le Ny proved that at sufficiently low temperatures
the decimation renormalization group transformation is not defined in the sense
that the renormalized measure is not a Gibbs measure. We consider a modified
model in which the nearest neighbor couplings are much larger than the other
couplings. For a family of Hamiltonians which includes critical cases, we prove
that the first step of the renormalization group transformation can be
rigorously defined for majority rule and decimation.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:38:01 GMT""}]","2020-06-23"
"2006.11430","Arun Sai Suggala","Kartik Gupta, Arun Sai Suggala, Adarsh Prasad, Praneeth Netrapalli,
  Pradeep Ravikumar","Learning Minimax Estimators via Online Learning","60 pages. Under review",,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of designing minimax estimators for estimating the
parameters of a probability distribution. Unlike classical approaches such as
the MLE and minimum distance estimators, we consider an algorithmic approach
for constructing such estimators. We view the problem of designing minimax
estimators as finding a mixed strategy Nash equilibrium of a zero-sum game. By
leveraging recent results in online learning with non-convex losses, we provide
a general algorithm for finding a mixed-strategy Nash equilibrium of general
non-convex non-concave zero-sum games. Our algorithm requires access to two
subroutines: (a) one which outputs a Bayes estimator corresponding to a given
prior probability distribution, and (b) one which computes the worst-case risk
of any given estimator. Given access to these two subroutines, we show that our
algorithm outputs both a minimax estimator and a least favorable prior. To
demonstrate the power of this approach, we use it to construct provably minimax
estimators for classical problems such as estimation in the finite Gaussian
sequence model, and linear regression.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:49:42 GMT""}]","2020-06-23"
"2006.11431","Miguel Campo PhD","Miguel Campo, Zhengxing Chen, Luke Kung, Kittipat Virochsiri and
  Jianyu Wang","Band-limited Soft Actor Critic Model","8 pages plus additional material",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Soft Actor Critic (SAC) algorithms show remarkable performance in complex
simulated environments. A key element of SAC networks is entropy
regularization, which prevents the SAC actor from optimizing against fine
grained features, oftentimes transient, of the state-action value function.
This results in better sample efficiency during early training. We take this
idea one step further by artificially bandlimiting the target critic spatial
resolution through the addition of a convolutional filter. We derive the closed
form solution in the linear case and show that bandlimiting reduces the
interdependency between the low and high frequency components of the
state-action value approximation, allowing the critic to learn faster. In
experiments, the bandlimited SAC outperformed the classic twin-critic SAC in a
number of Gym environments, and displayed more stability in returns. We derive
novel insights about SAC by adding a stochastic noise disturbance, a technique
that is increasingly being used to learn robust policies that transfer well to
the real world counterparts.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:52:43 GMT""}]","2020-06-23"
"2006.11432","Yeojoon Youn","Yeojoon Youn, Neil Thistlethwaite, Sang Keun Choe, Jacob Abernethy","Online Kernel based Generative Adversarial Networks",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the major breakthroughs in deep learning over the past five years has
been the Generative Adversarial Network (GAN), a neural network-based
generative model which aims to mimic some underlying distribution given a
dataset of samples. In contrast to many supervised problems, where one tries to
minimize a simple objective function of the parameters, GAN training is
formulated as a min-max problem over a pair of network parameters. While
empirically GANs have shown impressive success in several domains, researchers
have been puzzled by unusual training behavior, including cycling so-called
mode collapse. In this paper, we begin by providing a quantitative method to
explore some of the challenges in GAN training, and we show empirically how
this relates fundamentally to the parametric nature of the discriminator
network. We propose a novel approach that resolves many of these issues by
relying on a kernel-based non-parametric discriminator that is highly amenable
to online training---we call this the Online Kernel-based Generative
Adversarial Networks (OKGAN). We show empirically that OKGANs mitigate a number
of training issues, including mode collapse and cycling, and are much more
amenable to theoretical guarantees. OKGANs empirically perform dramatically
better, with respect to reverse KL-divergence, than other GAN formulations on
synthetic data; on classical vision datasets such as MNIST, SVHN, and CelebA,
show comparable performance.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:54:01 GMT""}]","2020-06-23"
"2006.11433","Sander Rhebergen","Yunhui He and Sander Rhebergen and Hans De Sterck","Local Fourier analysis of multigrid for hybridized and embedded
  discontinuous Galerkin methods",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present a geometric multigrid method with Jacobi and Vanka
relaxation for hybridized and embedded discontinuous Galerkin discretizations
of the Laplacian. We present a local Fourier analysis (LFA) of the two-grid
error-propagation operator and show that the multigrid method applied to an
embedded discontinuous Galerkin (EDG) discretization is almost as efficient as
when applied to a continuous Galerkin discretization. We furthermore show that
multigrid applied to an EDG discretization outperforms multigrid applied to a
hybridized discontinuous Galerkin (HDG) discretization. Numerical examples
verify our LFA predictions.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 23:11:03 GMT""}]","2020-06-23"
"2006.11434","Hussein Ammar","Hussein A. Ammar, Abdel-karim Ajami, Hassan Artail","ADDENDUM Details of the Derivation of the Probability of Coverage for
  the Relaying Scheme (Section IV in the paper: ""A Poisson Line Process based
  Framework for Determining the Needed RSU Density and Relaying Hops in
  Vehicular Networks'')","Addendum for a paper",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops a framework to study multi-hop relaying in a vehicular
network consisting of vehicles and Road Side Units (RSUs), and the effect of
this relaying on the network coverage and the communication delay. We use a
stochastic geometry model that consists of a combination of Poisson Line
Process (PLP) and 1D Poisson Point Process (PPP) to reliably characterize the
vehicular network layout and the locations of the vehicles and the RSUs. Using
this model, we analyze the effect of the different network parameters on the
coverage provided by the RSUs to the vehicles. Then, we investigate how the
uncovered vehicles can receive their intended packets by relaying them through
multiple hops that form connected paths to the RSUs. We also analyze the delay
introduced to packet delivery due to multi-hop relaying. Namely, we present
results that illustrate the coverage gains achieved through multi-hop relaying
and the delays induced. Such results could be used by network planners and
operators to decide on the different configurations and operational parameters
of the vehicular network to suit particular scenarios and objectives.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 23:11:44 GMT""}]","2020-06-23"
"2006.11435","Yudi Dong","Yudi Dong, Huaxia Wang, and Yu-Dong Yao","Channel Estimation for One-Bit Multiuser Massive MIMO Using Conditional
  GAN","5 pages;7 figures; 1 Table","IEEE Communications Letters (2020)","10.1109/LCOMM.2020.3035326",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Channel estimation is a challenging task, especially in a massive
multiple-input multiple-output (MIMO) system with one-bit analog-to-digital
converters (ADC). Traditional deep learning (DL) methods, that learn the
mapping from inputs to real channels, have significant difficulties in
estimating accurate channels because their loss functions are not well designed
and investigated. In this paper, a conditional generative adversarial networks
(cGAN) is developed to predict more realistic channels by adversarially
training two DL networks. cGANs not only learn the mapping from quantized
observations to real channels but also learn an adaptive loss function to
correctly train the networks. Numerical results show that the proposed cGAN
based approach outperforms existing DL methods and achieves high robustness in
massive MIMO systems.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 23:24:49 GMT""},{""version"":""v2"",""created"":""Thu, 29 Oct 2020 16:29:12 GMT""}]","2021-06-04"
"2006.11436","Mong Ng","Mong H. Ng, Kaahan Radia, Jianfei Chen, Dequan Wang, Ionel Gog, and
  Joseph E. Gonzalez","BEV-Seg: Bird's Eye View Semantic Segmentation Using Geometry and
  Semantic Point Cloud","Accepted into CVPR 2020 Workshop Scalability in Autonomous Driving by
  Waymo",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bird's-eye-view (BEV) is a powerful and widely adopted representation for
road scenes that captures surrounding objects and their spatial locations,
along with overall context in the scene. In this work, we focus on bird's eye
semantic segmentation, a task that predicts pixel-wise semantic segmentation in
BEV from side RGB images. This task is made possible by simulators such as
Carla, which allow for cheap data collection, arbitrary camera placements, and
supervision in ways otherwise not possible in the real world. There are two
main challenges to this task: the view transformation from side view to bird's
eye view, as well as transfer learning to unseen domains. Existing work
transforms between views through fully connected layers and transfer learns via
GANs. This suffers from a lack of depth reasoning and performance degradation
across domains. Our novel 2-staged perception pipeline explicitly predicts
pixel depths and combines them with pixel semantics in an efficient manner,
allowing the model to leverage depth information to infer objects' spatial
locations in the BEV. In addition, we transfer learning by abstracting
high-level geometric features and predicting an intermediate representation
that is common across different domains. We publish a new dataset called
BEVSEG-Carla and show that our approach improves state-of-the-art by 24% mIoU
and performs well when transferred to a new domain.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 23:30:11 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 16:45:07 GMT""}]","2020-06-24"
"2006.11437","Yasushi Suto","Yuta Nakagawa (1), Takanori Kodama (2), Masaki Ishiwatari (3), Hajime
  Kawahara (1), Yasushi Suto (1), Yoshiyuki O. Takahashi (4), George L.
  Hashimoto (5), Kiyoshi Kuramoto (3), Kensuke Nakajima (6), Shin-ichi Takehiro
  (7), and Yoshi-Yuki Hayashi (4), ( (1) Univ. of Tokyo, (2) Univ. of Bordeaux,
  (3) Hokkaido Univ. (4) Kobe Univ. (5) Okayama Univ. (6) Kyushu Univ. (7)
  Kyoto Univ.)","Obliquity of an Earth-like planet from frequency modulation of its
  direct imaged lightcurve: mock analysis from general circulation model
  simulation","29 pages, 18 figures, accepted for publication in ApJ",,"10.3847/1538-4357/ab9eb8",,"astro-ph.EP astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Direct-imaging techniques of exoplanets have made significant progress
recently, and will eventually enable to monitor photometric and spectroscopic
signals of earth-like habitable planets in the future. The presence of clouds,
however, would remain as one of the most uncertain components in deciphering
such direct-imaged signals of planets. We attempt to examine how the planetary
obliquity produce different cloud patterns by performing a series of GCM
(General Circulation Model) simulation runs using a set of parameters relevant
for our Earth. Then we use the simulated photometric lightcurves to compute
their frequency modulation due to the planetary spin-orbit coupling over an
entire orbital period, and attempt to see to what extent one can estimate the
obliquity of an Earth-twin. We find that it is possible to estimate the
obliquity of an Earth-twin within the uncertainty of several degrees with a
dedicated 4 m space telescope at 10 pc away from the system if the stellar flux
is completely blocked. While our conclusion is based on several idealized
assumptions, a frequency modulation of a directly-imaged earth-like planet
offers a unique methodology to determine its obliquity.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 23:40:44 GMT""}]","2020-08-05"
"2006.11438","Sheng Li","Sheng Li, Jayesh K. Gupta, Peter Morales, Ross Allen, Mykel J.
  Kochenderfer","Deep Implicit Coordination Graphs for Multi-agent Reinforcement Learning",,,,,"cs.LG cs.AI cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-agent reinforcement learning (MARL) requires coordination to
efficiently solve certain tasks. Fully centralized control is often infeasible
in such domains due to the size of joint action spaces. Coordination graph
based formalization allows reasoning about the joint action based on the
structure of interactions. However, they often require domain expertise in
their design. This paper introduces the deep implicit coordination graph (DICG)
architecture for such scenarios. DICG consists of a module for inferring the
dynamic coordination graph structure which is then used by a graph neural
network based module to learn to implicitly reason about the joint actions or
values. DICG allows learning the tradeoff between full centralization and
decentralization via standard actor-critic methods to significantly improve
coordination for domains with large number of agents. We apply DICG to both
centralized-training-centralized-execution and
centralized-training-decentralized-execution regimes. We demonstrate that DICG
solves the relative overgeneralization pathology in predatory-prey tasks as
well as outperforms various MARL baselines on the challenging StarCraft II
Multi-agent Challenge (SMAC) and traffic junction environments.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 23:41:49 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 23:29:50 GMT""}]","2021-02-05"
"2006.11439","Debarghya Mukherjee","Debarghya Mukherjee, Mikhail Yurochkin, Moulinath Banerjee, Yuekai Sun","Two Simple Ways to Learn Individual Fairness Metrics from Data","To appear in ICML 2020",,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Individual fairness is an intuitive definition of algorithmic fairness that
addresses some of the drawbacks of group fairness. Despite its benefits, it
depends on a task specific fair metric that encodes our intuition of what is
fair and unfair for the ML task at hand, and the lack of a widely accepted fair
metric for many ML tasks is the main barrier to broader adoption of individual
fairness. In this paper, we present two simple ways to learn fair metrics from
a variety of data types. We show empirically that fair training with the
learned metrics leads to improved fairness on three machine learning tasks
susceptible to gender and racial biases. We also provide theoretical guarantees
on the statistical performance of both approaches.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 23:47:15 GMT""}]","2020-06-23"
"2006.11440","Josue Ortega Caro","Josue Ortega Caro, Yilong Ju, Ryan Pyle, Sourav Dey, Wieland Brendel,
  Fabio Anselmi, Ankit Patel","Local Convolutions Cause an Implicit Bias towards High Frequency
  Adversarial Examples","23 pages, 11 figures, 12 Tables",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Adversarial Attacks are still a significant challenge for neural networks.
Recent work has shown that adversarial perturbations typically contain
high-frequency features, but the root cause of this phenomenon remains unknown.
Inspired by theoretical work on linear full-width convolutional models, we
hypothesize that the local (i.e. bounded-width) convolutional operations
commonly used in current neural networks are implicitly biased to learn high
frequency features, and that this is one of the root causes of high frequency
adversarial examples. To test this hypothesis, we analyzed the impact of
different choices of linear and nonlinear architectures on the implicit bias of
the learned features and the adversarial perturbations, in both spatial and
frequency domains. We find that the high-frequency adversarial perturbations
are critically dependent on the convolution operation because the
spatially-limited nature of local convolutions induces an implicit bias towards
high frequency features. The explanation for the latter involves the Fourier
Uncertainty Principle: a spatially-limited (local in the space domain) filter
cannot also be frequency-limited (local in the frequency domain). Furthermore,
using larger convolution kernel sizes or avoiding convolutions (e.g. by using
Vision Transformers architecture) significantly reduces this high frequency
bias, but not the overall susceptibility to attacks. Looking forward, our work
strongly suggests that understanding and controlling the implicit bias of
architectures will be essential for achieving adversarial robustness.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 23:50:51 GMT""},{""version"":""v2"",""created"":""Mon, 16 Nov 2020 07:58:09 GMT""},{""version"":""v3"",""created"":""Sat, 29 May 2021 06:42:45 GMT""},{""version"":""v4"",""created"":""Wed, 8 Dec 2021 00:10:16 GMT""},{""version"":""v5"",""created"":""Wed, 8 Mar 2023 20:43:36 GMT""}]","2023-03-10"
"2006.11441","Mengdi Xu","Mengdi Xu, Wenhao Ding, Jiacheng Zhu, Zuxin Liu, Baiming Chen, Ding
  Zhao","Task-Agnostic Online Reinforcement Learning with an Infinite Mixture of
  Gaussian Processes","16 pages, 6 figures",,,,"cs.LG cs.AI cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuously learning to solve unseen tasks with limited experience has been
extensively pursued in meta-learning and continual learning, but with
restricted assumptions such as accessible task distributions, independently and
identically distributed tasks, and clear task delineations. However, real-world
physical tasks frequently violate these assumptions, resulting in performance
degradation. This paper proposes a continual online model-based reinforcement
learning approach that does not require pre-training to solve task-agnostic
problems with unknown task boundaries. We maintain a mixture of experts to
handle nonstationarity, and represent each different type of dynamics with a
Gaussian Process to efficiently leverage collected data and expressively model
uncertainty. We propose a transition prior to account for the temporal
dependencies in streaming data and update the mixture online via sequential
variational inference. Our approach reliably handles the task distribution
shift by generating new models for never-before-seen dynamics and reusing old
models for previously seen dynamics. In experiments, our approach outperforms
alternative methods in non-stationary tasks, including classic control with
changing dynamics and decision making in different driving scenarios.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 23:52:45 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 14:20:43 GMT""},{""version"":""v3"",""created"":""Mon, 30 Nov 2020 17:06:14 GMT""}]","2020-12-01"
"2006.11442","Katherina Feng","Y. Katherina Feng, Michael R. Line, Jonathan J. Fortney","2D Retrieval Frameworks for Hot Jupiter Phase Curves","Accepted at AJ. 23 pages, 30 figures - see figure 2 for quick
  takeaway",,"10.3847/1538-3881/aba8f9",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spectroscopic phase curves provide unique access to the three-dimensional
properties of transiting exoplanet atmospheres. However, a modeling framework
must be developed to deliver accurate inferences of atmospheric properties for
these complex data sets. Here, we develop an approach to retrieve temperature
structures and molecular abundances from phase curve spectra at any orbital
phase. In the context of a representative hot Jupiter with a large day-night
temperature contrast, we examine the biases in typical one-dimensional (1D)
retrievals as a function of orbital phase/geometry, compared to two-dimensional
(2D) models that appropriately capture the disk-integrated phase geometry. We
guide our intuition by applying our new framework on a simulated HST+Spitzer
phase curve data set in which the ""truth"" is known, followed by an application
to the spectroscopic phase curve of the canonical hot Jupiter, WASP-43b. We
also demonstrate the retrieval framework on simulated JWST phase curve
observations. We apply our new geometric framework to a joint-fit of all
spectroscopic phases, assuming longitudinal molecular abundance homogeneity,
resulting in an a factor of 2 improvement in abundances precision when compared
to individual phase constraints. With a 1D retrieval model on simulated
HST+Spitzer data, we find strongly biased molecular abundances for CH$_4$ and
CO$_2$ at most orbital phases. With 2D, the day and night profiles retrieved
from WASP-43b remain consistent throughout the orbit. JWST retrievals show that
a 2D model is strongly favored at all orbital phases. Based on our new 2D
retrieval implementation, we provide recommendations on when 1D models are
appropriate and when more complex phase geometries involving multiple TP
profiles are required to obtain an unbiased view of tidally locked planetary
atmospheres.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:00:35 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jul 2020 18:26:33 GMT""}]","2020-09-02"
"2006.11443","Shaohan Wu","Shaohan Wu and Brian L. Hughes","PCA-based Antenna Impedance Estimation in Rayleigh Fading Channels","33 pages, 5 figures, journal",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Impedance matching between receive antenna and front-end significantly
impacts channel capacity in wireless channels. To implement capacity-optimal
matching, the receiver must know the antenna impedance. But oftentimes this
impedance varies with loading conditions in the antenna near-field. To mitigate
this variation, several authors have proposed antenna impedance estimation
techniques. However, the optimality of these techniques remains unclear. In
this paper, we consider antenna impedance estimation at MISO receivers over
correlated Rayleigh fading channels.
  We derive in closed-form the optimal ML estimator under i.i.d. fading and
then show it can be found via a scalar optimization in generally correlated
fading channels. Numerical results suggest a computationally efficient,
principal-components approach that estimates antenna impedance in real-time for
all Rayleigh fading channels. Furthermore, ergodic capacity can be
significantly boosted at originally poorly matched receivers with adaptive
matching using our proposed approach.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:07:52 GMT""}]","2020-06-23"
"2006.11444","Aneta Neumann","Aneta Neumann and Frank Neumann","Optimising Monotone Chance-Constrained Submodular Functions Using
  Evolutionary Multi-Objective Algorithms","Paper accepted for publication in the proceedings of PPSN 2020",,,,"cs.NE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many real-world optimisation problems can be stated in terms of submodular
functions. A lot of evolutionary multi-objective algorithms have recently been
analyzed and applied to submodular problems with different types of
constraints. We present a first runtime analysis of evolutionary
multi-objective algorithms for chance-constrained submodular functions. Here,
the constraint involves stochastic components and the constraint can only be
violated with a small probability of alpha. We show that the GSEMO algorithm
obtains the same worst case performance guarantees as recently analyzed greedy
algorithms. Furthermore, we investigate the behavior of evolutionary
multi-objective algorithms such as GSEMO and NSGA-II on different submodular
chance constrained network problems. Our experimental results show that this
leads to significant performance improvements compared to the greedy algorithm.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:17:44 GMT""}]","2020-06-23"
"2006.11445","Daniel Cranston","Daniel W. Cranston and Matthew P. Yancey","Vertex Partitions into an Independent Set and a Forest with Each
  Component Small","21 pages, 9 figures and 2 tables; this version incorporates reviewer
  feedback; to appear in SIAM J. Discrete Math","SIAM Journal on Discrete Math. Vol. 35(3), 2021, pp. 1769-1791",,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For each integer k >= 2, we determine a sharp bound on mad(G) such that V(G)
can be partitioned into sets I and F_k, where I is an independent set and
G[F_k] is a forest in which each component has at most k vertices. For each k
we construct an infinite family of examples showing our result is best
possible. Our results imply that every planar graph G of girth at least 9
(resp. 8, 7) has a partition of V(G) into an independent set I and a set F such
that G[F] is a forest with each component of order at most 3 (resp. 4, 6).
  Hendrey, Norin, and Wood asked for the largest function g(a,b) such that if
mad(G) < g(a,b) then V(G) has a partition into sets A and B such that mad(G[A])
< a and mad(G[B]) < b. They specifically asked for the value of g(1,b), i.e.,
the case when A is an independent set. Previously, the only values known were
g(1,4/3) and g(1,2). We find g(1,b) whenever 4/3 < b < 2.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:18:10 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 03:41:17 GMT""}]","2021-10-06"
"2006.11446","Nidhi Rastogi","Nidhi Rastogi, Sharmishtha Dutta, Mohammed J. Zaki, Alex Gittens, and
  Charu Aggarwal","MALOnt: An Ontology for Malware Threat Intelligence",,,"10.13140/RG.2.2.16426.64962",,"cs.CR cs.AI cs.IR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Malware threat intelligence uncovers deep information about malware, threat
actors, and their tactics, Indicators of Compromise(IoC), and vulnerabilities
in different platforms from scattered threat sources. This collective
information can guide decision making in cyber defense applications utilized by
security operation centers(SoCs). In this paper, we introduce an open-source
malware ontology - MALOnt that allows the structured extraction of information
and knowledge graph generation, especially for threat intelligence. The
knowledge graph that uses MALOnt is instantiated from a corpus comprising
hundreds of annotated malware threat reports. The knowledge graph enables the
analysis, detection, classification, and attribution of cyber threats caused by
malware. We also demonstrate the annotation process using MALOnt on exemplar
threat intelligence reports. A work in progress, this research is part of a
larger effort towards auto-generation of knowledge graphs (KGs)for gathering
malware threat intelligence from heterogeneous online resources.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:25:07 GMT""}]","2020-06-23"
"2006.11447","Stephen Pankavich","Stephen Pankavich","Exact Large Time Behavior of Spherically-Symmetric Plasmas","39 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the classical and relativistic Vlasov-Poisson systems with
spherically-symmetric initial data and prove the optimal decay rates for all
suitable $L^p$ norms of the charge density and electric field, as well as, the
optimal growth rates for the largest particle position and momentum on the
support of the distribution function. Though a previous work \cite{Horst}
established upper bounds on the decay of the supremum of the charge density and
electric field, we provide a slightly different proof, attain optimal rates,
and extend this result to include all other norms. Additionally, we prove sharp
lower bounds on each of the aforementioned quantities and establish the
time-asymptotic behavior of all spatial and momentum characteristics. Finally,
we investigate the limiting behavior of the spatial average of the particle
distribution as $t \to \infty$. In particular, we show that it converges
uniformly to a smooth, compactly-supported function that preserves the mass,
angular momentum, and energy of the system and depends only upon limiting
particle momenta.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:36:35 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jul 2020 18:40:46 GMT""},{""version"":""v3"",""created"":""Sun, 13 Jun 2021 22:18:59 GMT""}]","2021-06-15"
"2006.11448","Milind Hegde","Riddhipratim Basu, Shirshendu Ganguly, Alan Hammond, Milind Hegde","Interlacing and scaling exponents for the geodesic watermelon in last
  passage percolation","62 pages, 11 figures",,,,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In discrete planar last passage percolation (LPP), random values are assigned
independently to each vertex in $\mathbb Z^2$, and each finite upright path in
$\mathbb Z^2$ is ascribed the weight given by the sum of values of its
vertices. The weight of a collection of disjoint paths is the sum of its
members' weights. The notion of a geodesic, a maximum weight path between two
vertices, has a natural generalization concerning several disjoint paths: a
$k$-geodesic watermelon in $[1,n]^2\cap\mathbb Z^2$ is a collection of $k$
disjoint paths contained in this square that has maximum weight among all such
collections. While the weights of such collections are known to be important
objects, the maximizing paths have been largely unexplored beyond the $k=1$
case. For exactly solvable models, such as exponential and geometric LPP, it is
well known that for $k=1$ the exponents that govern fluctuation in weight and
transversal distance are $1/3$ and $2/3$; that is, typically, the weight of the
geodesic on the route $(1,1) \to (n,n)$ fluctuates around a dominant linear
growth of the form $\mu n$ by the order of $n^{1/3}$; and the maximum Euclidean
distance of the geodesic from the diagonal has order $n^{2/3}$. Assuming a
strong but local form of convexity and one-point moderate deviation bounds for
the geodesic weight profile---which are available in all known exactly solvable
models---we establish that, typically, the $k$-geodesic watermelon's weight
falls below $\mu nk$ by order $k^{5/3}n^{1/3}$, and its transversal fluctuation
is of order $k^{1/3}n^{2/3}$. Our arguments crucially rely on, and develop, a
remarkable deterministic interlacing property that the watermelons admit. Our
methods also yield sharp rigidity estimates for naturally associated point
processes, which improve on estimates obtained via tools from the theory of
determinantal point processes available in the integrable setting.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:46:29 GMT""}]","2020-06-23"
"2006.11449","Lionel London","Lionel London","Bi-orthogonal harmonics for the decomposition of gravitational radiation
  I: angular modes, completeness, and the introduction of adjoint-spheroidal
  harmonics",,,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The estimation of radiative modes is a central problem in gravitational wave
theory, with essential applications in signal modeling and data analysis. This
problem is complicated by most astrophysically relevant systems' not having
modes that are analytically tractable. A ubiquitous workaround is to use not
modes, but multipole moments defined by spin weighted spherical harmonics.
However, spherical multipole moments are only related to the modes of systems
without angular momentum. As a result, they can obscure the underlying physics
of astrophysically relevant systems, such as binary black hole merger and
ringdown. In such cases, spacetime angular momentum means that radiative modes
are not spherical, but spheroidal in nature. Here, we work through various
problems related to spheroidal harmonics. We show for the first time that
spheroidal harmonics are not only capable of representing arbitrary
gravitational wave signals, but that they also possess a kind of orthogonality
not used before in general relativity theory. Along the way we present a new
class of spin weighted harmonic functions dubbed ``adjoint-spheroidal""
harmonics. These new functions may be used for the general estimation of
spheroidal multipole moments via complete bi-orthogonal decomposition (in the
angular domain). By construction, adjoint-spheroidal harmonics suppress
mode-mixing effects known to plague spherical harmonic decomposition; as a
result, they better approximate a system's true radiative modes. We discuss
potential applications of these results. Lastly, we briefly comment on the
challenges posed by the analogous problem with Teukolsky's radial functions
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:48:04 GMT""},{""version"":""v2"",""created"":""Thu, 24 Dec 2020 03:37:19 GMT""},{""version"":""v3"",""created"":""Thu, 30 Jun 2022 12:41:56 GMT""}]","2022-07-01"
"2006.11450","Norbert Remenyi","Norbert Remenyi, Xiaodong Luo","Demand Estimation from Sales Transaction Data -- Practical Extensions",,,,,"math.OC stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we discuss practical limitations of the standard choice-based
demand models used in the literature to estimate demand from sales transaction
data. We present modifications and extensions of the models and discuss data
preprocessing and solution techniques which are useful for practitioners
dealing with sales transaction data. Among these, we present an algorithm to
split sales transaction data observed under partial availability, we extend a
popular Expectation Maximization (EM) algorithm for non-homogeneous product
sets, and we develop two iterative optimization algorithms which can handle
much of the extensions discussed in the paper.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:48:29 GMT""},{""version"":""v2"",""created"":""Sat, 22 Aug 2020 18:30:41 GMT""}]","2020-08-25"
"2006.11451","Yasushi Suto","Yasushi Suto (Univ. of Tokyo)","Beyond a pale blue dot : how to search for possible bio-signatures on
  earth-like planets","11 pages, 5 figures, published in Yamagishi A., Kakegawa T., Usui T.
  (eds) Astrobiology. Springer, Singapore (2019)",,"10.1007/978-981-13-3639-3_29",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Earth viewed from outside the Solar system would be identified merely
like a pale blue dot, as coined by Carl Sagan. In order to detect possible
signatures of the presence of life on a second earth among several terrestrial
planets discovered in a habit-able zone, one has to develop and establish a
methodology to characterize the planet as something beyond a mere pale blue
dot. We pay particular attention to the periodic change of the color of the dot
according to the rotation of the planet. Because of the large-scale
inhomogeneous distribution of the planetary surface, the reflected light of the
dot comprises different color components corresponding to land, ocean, ice, and
cloud that cover the surface of the planet. If we decompose the color of the
dot into several principle components, in turn, one can identify the presence
of the different surface components. Furthermore, the vegetation on the earth
is known to share a remarkable reflection signature; the reflection becomes
significantly enhanced at wave-lengths longer than 760nm, which is known as a
red-edge of the vegetation. If one can identify the corresponding color
signature in a pale blue dot, it can be used as a unique probe of the presence
of life. I will describe the feasibility of the methodology for future space
missions, and consider the direction towards astrobiology from an
astrophysicist's point of view.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:48:29 GMT""}]","2020-06-23"
"2006.11452","Davide Silvagni","D. Silvagni, T. Eich, T. Happel, G. F. Harrer, M. Griener, M. Dunne,
  M. Cavedon, M. Faitsch, L. Gil, D. Nille, B. Tal, R. Fischer, U. Stroth, D.
  Brida, P. David, P. Manz, E. Viezzer, the ASDEX Upgrade team and the
  EUROfusion MST1 team","I-mode pedestal relaxation events at ASDEX Upgrade",,,"10.1088/1741-4326/abb423",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The I-mode confinement regime can feature small edge temperature drops that
can lead to an increase in the energy deposited onto the divertor targets. In
this work, we show that these events are associated with a relaxation of both
electron temperature and density edge profiles, with the largest drop found at
the pedestal top position. Stability analysis of edge profiles reveals that the
operational points are far from the ideal peeling-ballooning boundary. Also, we
show that these events appear close to the H-mode transition in the typical
I-mode operational space in ASDEX Upgrade, and that no further enhancement of
energy confinement is found when they occur. Moreover, scrape-off layer
transport during these events is found to be very similar to type-I ELMs, with
regard to timescales ($\approx$ 800 $\mu$s), filament propagation, toroidally
asymmetric energy effluxes at the midplane and asymmetry between inner and
outer divertor deposited energy. In particular, the latter reveals that more
energy reaches the outer divertor target. Lastly, first measurements of the
divertor peak energy fluence are reported, and projections to ARC - a reactor
designed to operate in I-mode - are drawn.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:00:27 GMT""}]","2020-10-22"
"2006.11453","Jackson Shields","Jackson Shields, Oscar Pizarro, Stefan B. Williams","Towards Adaptive Benthic Habitat Mapping","To be published in ICRA2020 conference proceedings. 6 pages, 7
  figures",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autonomous Underwater Vehicles (AUVs) are increasingly being used to support
scientific research and monitoring studies. One such application is in benthic
habitat mapping where these vehicles collect seafloor imagery that complements
broadscale bathymetric data collected using sonar. Using these two data
sources, the relationship between remotely-sensed acoustic data and the sampled
imagery can be learned, creating a habitat model. As the areas to be mapped are
often very large and AUV systems collecting seafloor imagery can only sample
from a small portion of the survey area, the information gathered should be
maximised for each deployment. This paper illustrates how the habitat models
themselves can be used to plan more efficient AUV surveys by identifying where
to collect further samples in order to most improve the habitat model. A
Bayesian neural network is used to predict visually-derived habitat classes
when given broad-scale bathymetric data. This network can also estimate the
uncertainty associated with a prediction, which can be deconstructed into its
aleatoric (data) and epistemic (model) components. We demonstrate how these
structured uncertainty estimates can be utilised to improve the model with
fewer samples. Such adaptive approaches to benthic surveys have the potential
to reduce costs by prioritizing further sampling efforts. We illustrate the
effectiveness of the proposed approach using data collected by an AUV on
offshore reefs in Tasmania, Australia.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:03:41 GMT""}]","2020-06-23"
"2006.11454","Kostas Zoumpatianos","Karima Echihabi, Kostas Zoumpatianos, Themis Palpanas, Houda Benbrahim","The Lernaean Hydra of Data Series Similarity Search: An Experimental
  Evaluation of the State of the Art",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Increasingly large data series collections are becoming commonplace across
many different domains and applications. A key operation in the analysis of
data series collections is similarity search, which has attracted lots of
attention and effort over the past two decades. Even though several relevant
approaches have been proposed in the literature, none of the existing studies
provides a detailed evaluation against the available alternatives. The lack of
comparative results is further exacerbated by the non-standard use of
terminology, which has led to confusion and misconceptions. In this paper, we
provide definitions for the different flavors of similarity search that have
been studied in the past, and present the first systematic experimental
evaluation of the efficiency of data series similarity search techniques. Based
on the experimental results, we describe the strengths and weaknesses of each
approach and give recommendations for the best approach to use under typical
use cases. Finally, by identifying the shortcomings of each method, our
findings lay the ground for solid further developments in the field.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:04:27 GMT""}]","2020-06-23"
"2006.11455","Takao Tsumuraya","Takao Tsumuraya, Yoshikazu Suzumura","First-principles study of the effective Hamiltonian for Dirac fermions
  with spin-orbit coupling in two-dimensional molecular conductor
  $\alpha$-(BETS)$_2$I$_3$","The manuscript has been accepted for publication in the European
  Physical Journal B on Dec. 15th, 2020","Eur. Phys. J.l B, 94, 17 (2021)","10.1140/epjb/s10051-020-00038-y",,"cond-mat.str-el cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We employed first-principles density-functional theory (DFT) calculations to
characterize Dirac electrons in quasi-two-dimensional molecular conductor
$\alpha$-(BETS)$_2$I$_3$ [= $\alpha$-(BEDT-TSeF)$_2$I$_3$] at a low temperature
of 30K. We provide a tight-binding model with intermolecular transfer energies
evaluated from maximally localized Wannier functions, where the number of
relevant transfer integrals is relatively large due to the delocalized
character of Se $p$ orbitals. The spin-orbit coupling gives rise to an exotic
insulating state with an indirect band gap of about 2 meV. We analyzed the
energy spectrum with a Dirac cone close to the Fermi level to develop an
effective Hamiltonian with site-potentials, which reproduces the spectrum
obtained by the DFT band structure.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:09:07 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jul 2020 07:15:41 GMT""},{""version"":""v3"",""created"":""Wed, 16 Dec 2020 07:02:57 GMT""}]","2021-01-18"
"2006.11456","Abiola Osho","Abiola Osho and Ethan Tucker and George Amariucai","Implicit Crowdsourcing for Identifying Abusive Behavior in Online Social
  Networks",,,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increased use of online social networks for the dissemination of
information comes with the misuse of the internet for cyberbullying,
cybercrime, spam, vandalism, amongst other things. To proactively identify
abuse in the networks, we propose a model to identify abusive posts by
crowdsourcing. The crowdsourcing part of the detection mechanism is implemented
implicitly, by simply observing the natural interaction between users
encountering the messages. We explore the node-to-node spread of information on
Twitter and propose a model that predicts the abuse level (abusive, hate, spam,
normal) associated with the tweet by observing the attributes of the message,
along with those of the users interacting with it. We demonstrate that the
difference in users' interactions with abusive posts can be leveraged in
identifying posts of varying abuse levels.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:14:30 GMT""}]","2020-06-23"
"2006.11457","Maxim Buzdalov","Maxim Buzdalov and Carola Doerr","Optimal Mutation Rates for the $(1+\lambda)$ EA on OneMax","This is an extended version of the paper accepted to the PPSN 2020
  conference",,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The OneMax problem, alternatively known as the Hamming distance problem, is
often referred to as the ""drosophila of evolutionary computation (EC)"", because
of its high relevance in theoretical and empirical analyses of EC approaches.
It is therefore surprising that even for the simplest of all mutation-based
algorithms, Randomized Local Search and the (1+1) EA, the optimal mutation
rates were determined only very recently, in a GECCO 2019 poster.
  In this work, we extend the analysis of optimal mutation rates to two
variants of the $(1+\lambda)$ EA and to the $(1+\lambda)$ RLS. To do this, we
use dynamic programming and, for the $(1+\lambda)$ EA, numeric optimization,
both requiring $\Theta(n^3)$ time for problem dimension $n$. With this in hand,
we compute for all population sizes $\lambda \in \{2^i \mid 0 \le i \le 18\}$
and for problem dimension $n \in \{1000, 2000, 5000\}$ which mutation rates
minimize the expected running time and which ones maximize the expected
progress.
  Our results do not only provide a lower bound against which we can measure
common evolutionary approaches, but we also obtain insight into the structure
of these optimal parameter choices. For example, we show that, for large
population sizes, the best number of bits to flip is not monotone in the
distance to the optimum. We also observe that the expected remaining running
time are not necessarily unimodal for the $(1+\lambda)$ EA$_{0 \rightarrow 1}$
with shifted mutation.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:23:14 GMT""}]","2020-06-23"
"2006.11458","Argyris Kalogeratos","Anthea M\'erida Montes de Oca, Argyris Kalogeratos, Mathilde Mougeot","Model family selection for classification using Neural Decision Trees","4 pages, 3 figures, 1 table",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model selection consists in comparing several candidate models according to a
metric to be optimized. The process often involves a grid search, or such, and
cross-validation, which can be time consuming, as well as not providing much
information about the dataset itself. In this paper we propose a method to
reduce the scope of exploration needed for the task. The idea is to quantify
how much it would be necessary to depart from trained instances of a given
family, reference models (RMs) carrying `rigid' decision boundaries (e.g.
decision trees), so as to obtain an equivalent or better model. In our
approach, this is realized by progressively relaxing the decision boundaries of
the initial decision trees (the RMs) as long as this is beneficial in terms of
performance measured on an analyzed dataset. More specifically, this relaxation
is performed by making use of a neural decision tree, which is a neural network
built from DTs. The final model produced by our method carries non-linear
decision boundaries. Measuring the performance of the final model, and its
agreement to its seeding RM can help the user to figure out on which family of
models he should focus on.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:27:01 GMT""}]","2020-06-23"
"2006.11459","Kostas Zoumpatianos","Karima Echihabi, Kostas Zoumpatianos, Themis Palpanas, Houda Benbrahim","Return of the Lernaean Hydra: Experimental Evaluation of Data Series
  Approximate Similarity Search",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data series are a special type of multidimensional data present in numerous
domains, where similarity search is a key operation that has been extensively
studied in the data series literature. In parallel, the multidimensional
community has studied approximate similarity search techniques. We propose a
taxonomy of similarity search techniques that reconciles the terminology used
in these two domains, we describe modifications to data series indexing
techniques enabling them to answer approximate similarity queries with quality
guarantees, and we conduct a thorough experimental evaluation to compare
approximate similarity search techniques under a unified framework, on
synthetic and real datasets in memory and on disk. Although data series differ
from generic multidimensional vectors (series usually exhibit correlation
between neighboring values), our results show that data series techniques
answer approximate %similarity queries with strong guarantees and an excellent
empirical performance, on data series and vectors alike. These techniques
outperform the state-of-the-art approximate techniques for vectors when
operating on disk, and remain competitive in memory.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:27:49 GMT""}]","2020-06-23"
"2006.11460","Boliang Lin","Boliang Lin","Optimization of Express Train Service Network: Under the Competition of
  Highway Transportation","10 pages, 2 figures, 1 table",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to reduce the carbon emission, the related government departments
encourage road freights to be transferred more by railway transportation. In
China freight transport system, the road transportation is usually responsible
for the freights that are in a short distance or the ones with high
value-added. To transfer more high value-added freights from highway to
railway, except the transportation expenses of railway have an advantage over
the road, the transportation time is of certain competitive force as well.
Therefore, it is very essential for railway to provide freight train products
that are of competitive power. Under such circumstance, a multi-objective
programming model of optimizing the rail express train network is devised in
this work on the basis of taking both road and railway transportation modes
into account. The aims of optimization are to minimize the operation costs of
rail trains, and to maximize the railway transport revenue. In a network with a
given set of express train services, either the all-or-nothing (AON) method or
the logit model can be employed when assigning high value-added freights. These
two flow assignment patterns are investigated in this work.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:30:22 GMT""}]","2020-06-23"
"2006.11461","Tongjia Zheng","Tongjia Zheng, Qing Han, and Hai Lin","PDE-based Dynamic Density Estimation for Large-scale Agent Systems",,,"10.1109/LCSYS.2020.3004417",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale agent systems have foreseeable applications in the near future.
Estimating their macroscopic density is critical for many density-based
optimization and control tasks, such as sensor deployment and city traffic
scheduling. In this paper, we study the problem of estimating their dynamically
varying probability density, given the agents' individual dynamics (which can
be nonlinear and time-varying) and their states observed in real-time. The
density evolution is shown to satisfy a linear partial differential equation
uniquely determined by the agents' dynamics. We present a density filter which
takes advantage of the system dynamics to gradually improve its estimation and
is scalable to the agents' population. Specifically, we use kernel density
estimators (KDE) to construct a noisy measurement and show that, when the
agents' population is large, the measurement noise is approximately
``Gaussian''. With this important property, infinite-dimensional Kalman filters
are used to design density filters. It turns out that the covariance of
measurement noise depends on the true density. This state-dependence makes it
necessary to approximate the covariance in the associated operator Riccati
equation, rendering the density filter suboptimal. The notion of input-to-state
stability is used to prove that the performance of the suboptimal density
filter remains close to the optimal one. Simulation results suggest that the
proposed density filter is able to quickly recognize the underlying modes of
the unknown density and automatically ignore outliers, and is robust to
different choices of kernel bandwidth of KDE.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:32:37 GMT""}]","2020-07-06"
"2006.11462","Tongjia Zheng","Tongjia Zheng, Qing Han, and Hai Lin","Transporting Robotic Swarms via Mean-Field Feedback Control",,,"10.1109/TAC.2021.3108672",,"eess.SY cs.RO cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the rapid development of AI and robotics, transporting a large swarm of
networked robots has foreseeable applications in the near future. Existing
research in swarm robotics has mainly followed a bottom-up philosophy with
predefined local coordination and control rules. However, it is arduous to
verify the global requirements and analyze their performance. This motivates us
to pursue a top-down approach, and develop a provable control strategy for
deploying a robotic swarm to achieve a desired global configuration.
Specifically, we use mean-field partial differential equations (PDEs) to model
the swarm and control its mean-field density (i.e., probability density) over a
bounded spatial domain using mean-field feedback. The presented control law
uses density estimates as feedback signals and generates corresponding velocity
fields that, by acting locally on individual robots, guide their global
distribution to a target profile. The design of the velocity field is therefore
centralized, but the implementation of the controller can be fully distributed
-- individual robots sense the velocity field and derive their own velocity
control signals accordingly. The key contribution lies in applying the concept
of input-to-state stability (ISS) to show that the perturbed closed-loop system
(a nonlinear and time-varying PDE) is locally ISS with respect to density
estimation errors. The effectiveness of the proposed control laws is verified
using agent-based simulations.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:48:18 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 20:16:55 GMT""},{""version"":""v3"",""created"":""Thu, 18 Mar 2021 23:26:02 GMT""}]","2022-10-04"
"2006.11463","Kaushal Sharma","Kaushal Sharma, Harinder P. Singh, Ranjan Gupta, Ajit Kembhavi,
  Kaustubh Vaghmare, Jianrong Shi, Yongheng Zhao, Jiannan Zhang, Yue Wu","Stellar Spectral Interpolation using Machine Learning","Accepted for publication in MNRAS. 16 pages, 16 figures",,"10.1093/mnras/staa1809",,"astro-ph.SR astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Theoretical stellar spectra rely on model stellar atmospheres computed based
on our understanding of the physical laws at play in the stellar interiors.
These models, coupled with atomic and molecular line databases, are used to
generate theoretical stellar spectral libraries (SSLs) comprising of stellar
spectra over a regular grid of atmospheric parameters (temperature, surface
gravity, abundances) at any desired resolution. Another class of SSLs is
referred to as empirical spectral libraries; these contain observed spectra at
limited resolution. SSLs play an essential role in deriving the properties of
stars and stellar populations. Both theoretical and empirical libraries suffer
from limited coverage over the parameter space. This limitation is overcome to
some extent by generating spectra for specific sets of atmospheric parameters
by interpolating within the grid of available parameter space. In this work, we
present a method for spectral interpolation in the optical region using machine
learning algorithms that are generic, easily adaptable for any SSL without much
change in the model parameters, and computationally inexpensive. We use two
machine learning techniques, Random Forest (RF) and Artificial Neural Networks
(ANN), and train the models on the MILES library. We apply the trained models
to spectra from the CFLIB for testing and show that the performance of the two
models is comparable. We show that both the models achieve better accuracy than
the existing methods of polynomial based interpolation and the Gaussian radial
basis function (RBF) interpolation.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:48:35 GMT""}]","2020-07-01"
"2006.11464","Jonathan Meddaugh","Jonathan Meddaugh, Brian Raines","A characterization of $\omega$-limit sets in subshifts of Baire space",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the structure of $\omega$-limit sets in subshifts
of Baire space. We consider both subshifts of finite type and subshifts of
bounded type and we demonstrate that many classical structure theorems for
$\omega$-limit sets fail in this context. Nevertheless, we obtain
characterizations of $\omega$-limit sets in subshift of finite types and of
attracting $\omega$-limit sets in subshifts of bounded type.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:51:21 GMT""}]","2020-06-23"
"2006.11465","Junpei Zhong","Junpei Zhong and Angelo Cangelosi and Stefan Wermter","Towards a self-organizing pre-symbolic neural model representing
  sensorimotor primitives",,"Frontiers in behavioral neuroscience, 8, 22 (2014)","10.3389/fnbeh.2014.00022",,"cs.NE cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The acquisition of symbolic and linguistic representations of sensorimotor
behavior is a cognitive process performed by an agent when it is executing
and/or observing own and others' actions. According to Piaget's theory of
cognitive development, these representations develop during the sensorimotor
stage and the pre-operational stage. We propose a model that relates the
conceptualization of the higher-level information from visual stimuli to the
development of ventral/dorsal visual streams. This model employs neural network
architecture incorporating a predictive sensory module based on an RNNPB
(Recurrent Neural Network with Parametric Biases) and a horizontal product
model. We exemplify this model through a robot passively observing an object to
learn its features and movements. During the learning process of observing
sensorimotor primitives, i.e. observing a set of trajectories of arm movements
and its oriented object features, the pre-symbolic representation is
self-organized in the parametric units. These representational units act as
bifurcation parameters, guiding the robot to recognize and predict various
learned sensorimotor primitives. The pre-symbolic representation also accounts
for the learning of sensorimotor primitives in a latent learning context.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:58:28 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jul 2020 04:30:56 GMT""}]","2020-07-14"
"2006.11466","Zizong Yan","Zi-zong Yan, Xiang-jun Li and Jinhai Guo","The existence of a strongly polynomial time simplex algorithm for linear
  programs","16 pages, 0 figure",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  It is well known that the most challenging question in optimization and
discrete geometry is whether there is a strongly polynomial time simplex
algorithm for linear programs (LPs). This paper gives a positive answer to this
question by using the parameter analysis technique presented by us
(arXiv:2006.08104). We show that there is a simplex algorithm whose number of
pivoting steps does not exceed the number of variables of a LP problem.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:00:50 GMT""},{""version"":""v10"",""created"":""Tue, 2 Nov 2021 03:16:50 GMT""},{""version"":""v11"",""created"":""Sat, 13 Nov 2021 01:18:04 GMT""},{""version"":""v12"",""created"":""Wed, 12 Jan 2022 02:10:06 GMT""},{""version"":""v13"",""created"":""Mon, 25 Jul 2022 06:22:44 GMT""},{""version"":""v14"",""created"":""Fri, 30 Sep 2022 06:58:48 GMT""},{""version"":""v2"",""created"":""Sat, 27 Jun 2020 03:29:47 GMT""},{""version"":""v3"",""created"":""Sun, 5 Jul 2020 10:30:34 GMT""},{""version"":""v4"",""created"":""Sun, 26 Jul 2020 02:21:00 GMT""},{""version"":""v5"",""created"":""Sun, 2 Aug 2020 02:46:13 GMT""},{""version"":""v6"",""created"":""Sun, 8 Aug 2021 12:48:36 GMT""},{""version"":""v7"",""created"":""Thu, 12 Aug 2021 00:45:35 GMT""},{""version"":""v8"",""created"":""Fri, 17 Sep 2021 01:57:35 GMT""},{""version"":""v9"",""created"":""Wed, 20 Oct 2021 10:45:00 GMT""}]","2022-10-03"
"2006.11467","Steven Senger","Shelby Kilmer, Caleb Marshall, and Steven Senger","Dot product chains","18 pages, 1 figure",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a variant of Erd\H os' unit distance problem, concerning dot
products between successive pairs of points chosen from a large finite point
set. Specifically, given a large finite set of $n$ points $E$, and a sequence
of nonzero dot products $(\alpha_1,\ldots,\alpha_k)$, we give upper and lower
bounds on the maximum possible number of tuples of distinct points $(A_1,\dots,
A_{k+1})\in E^{k+1}$ satisfying $A_j \cdot A_{j+1}=\alpha_j$ for every $1\leq j
\leq k$.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:03:30 GMT""},{""version"":""v2"",""created"":""Tue, 8 Sep 2020 00:12:38 GMT""}]","2020-09-09"
"2006.11468","Jiong Zhu","Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, Danai
  Koutra","Beyond Homophily in Graph Neural Networks: Current Limitations and
  Effective Designs","Accepted to NeurIPS 2020; version with full appendix",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the representation power of graph neural networks in the
semi-supervised node classification task under heterophily or low homophily,
i.e., in networks where connected nodes may have different class labels and
dissimilar features. Many popular GNNs fail to generalize to this setting, and
are even outperformed by models that ignore the graph structure (e.g.,
multilayer perceptrons). Motivated by this limitation, we identify a set of key
designs -- ego- and neighbor-embedding separation, higher-order neighborhoods,
and combination of intermediate representations -- that boost learning from the
graph structure under heterophily. We combine them into a graph neural network,
H2GCN, which we use as the base method to empirically evaluate the
effectiveness of the identified designs. Going beyond the traditional
benchmarks with strong homophily, our empirical analysis shows that the
identified designs increase the accuracy of GNNs by up to 40% and 27% over
models without them on synthetic and real networks with heterophily,
respectively, and yield competitive performance under homophily.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:05:01 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 08:43:25 GMT""}]","2020-10-26"
"2006.11469","Takeshi Teshima","Takeshi Teshima, Isao Ishikawa, Koichi Tojo, Kenta Oono, Masahiro
  Ikeda, and Masashi Sugiyama","Coupling-based Invertible Neural Networks Are Universal Diffeomorphism
  Approximators","29 pages, 3 figures. Accepted at Thirty-fourth Conference on Neural
  Information Processing Systems (NeurIPS 2020) for oral presentation",,,,"cs.LG cs.NE math.CA math.DG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Invertible neural networks based on coupling flows (CF-INNs) have various
machine learning applications such as image synthesis and representation
learning. However, their desirable characteristics such as analytic
invertibility come at the cost of restricting the functional forms. This poses
a question on their representation power: are CF-INNs universal approximators
for invertible functions? Without a universality, there could be a well-behaved
invertible transformation that the CF-INN can never approximate, hence it would
render the model class unreliable. We answer this question by showing a
convenient criterion: a CF-INN is universal if its layers contain affine
coupling and invertible linear functions as special cases. As its corollary, we
can affirmatively resolve a previously unsolved problem: whether normalizing
flow models based on affine coupling can be universal distributional
approximators. In the course of proving the universality, we prove a general
theorem to show the equivalence of the universality for certain diffeomorphism
classes, a theoretical insight that is of interest by itself.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:07:37 GMT""},{""version"":""v2"",""created"":""Wed, 4 Nov 2020 01:24:34 GMT""}]","2020-11-05"
"2006.11470","Riddhi Bandyopadhyay","Riddhi Bandyopadhyay, William H. Matthaeus, Alexandros Chasapis,
  Christopher T. Russell, Robert J. Strangeway, Roy B. Torbert, Barbara L.
  Giles, Daniel J. Gershman, Craig J. Pollock, James L. Burch","Direct Measurement of the Solar-Wind Taylor Microscale using MMS
  Turbulence Campaign Data","Accepted for publication in the Astrophysical Journal",,"10.3847/1538-4357/ab9ebe",,"physics.space-ph astro-ph.SR physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the novel Magnetospheric Multiscale (MMS) mission data accumulated
during the 2019 MMS Solar Wind Turbulence Campaign, we calculate the Taylor
microscale $(\lambda_{\mathrm{T}})$ of the turbulent magnetic field in the
solar wind. The Taylor microscale represents the onset of dissipative processes
in classical turbulence theory. An accurate estimation of Taylor scale from
spacecraft data is, however, usually difficult due to low time cadence, the
effect of time decorrelation, and other factors. Previous reports were based
either entirely on the Taylor frozen-in approximation, which conflates time
dependence, or that were obtained using multiple datasets, which introduces
sample-to-sample variation of plasma parameters, or where inter-spacecraft
distance were larger than the present study. The unique configuration of linear
formation with logarithmic spacing of the 4 MMS spacecraft, during the
campaign, enables a direct evaluation of the $\lambda_{\mathrm{T}}$ from a
single dataset, independent of the Taylor frozen-in approximation. A value of
$\lambda_{\mathrm{T}} \approx 7000 \, \mathrm{km}$ is obtained, which is about
3 times larger than the previous estimates.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:10:08 GMT""}]","2020-08-19"
"2006.11471","Xi-Guang Wang","L. Chotorlishvili, Z. Toklikishvili, X.-G. Wang, V.K. Dugaev, J.
  Barna\'s, J. Berakdar","Stratonovich-Ito integration scheme in ultrafast spin caloritronics","to appear in Phys. Rev. B",,"10.1103/PhysRevB.102.024413",,"cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The magnonic spin Seebeck effect is a key element of spin caloritronic, a
field that exploits thermal effects for spintronic applications. Early studies
were focused on investigating the steady-state nonequilibrium magnonic spin
Seebeck current, and the underlying physics of the magnonic spin Seebeck effect
is now relatively well established. However, the initial steps of the formation
of the spin Seebeck current are in the scope of recent interest. To address
this dynamical aspect theoretically we propose here a new approach to the
time-resolved spin Seebeck effect. Our method exploits the supersymmetric
theory of stochastics and Ito - Stratonovich integration scheme. We found that
in the early step the spin Seebeck current has both nonzero transversal and
longitudinal components. As the magnetization dynamics approaches the
steady-state, the transversal components decay through dephasing over the
dipole-dipole reservoir. The time scale for this process is typically in the
sub-nanoseconds pointing thus to the potential of an ultrafast control of the
dynamical spin Seebeck during its buildup.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:10:42 GMT""}]","2020-08-26"
"2006.11472","Simone Franchini Dr.","Simone Franchini, Riccardo Balzan","Energy of the Interacting Self-Avoiding Walk at the $\theta-$point","10 pages, 4 figures","Phys. Rev. E 102, 032143 (2020)","10.1103/PhysRevE.102.032143",,"cond-mat.stat-mech cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a numerical study of a new microcanonical polymer model on the
three dimensional cubic lattice, consisting of ideal chains whose range and
number of nearest-neighbor contacts are fixed to given values. Our simulations
suggest an interesting exact relation concerning the internal energy per
monomer of the Interacting Self-Avoiding Walk at the $\theta-$point.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:12:25 GMT""},{""version"":""v2"",""created"":""Thu, 10 Sep 2020 16:56:33 GMT""},{""version"":""v3"",""created"":""Tue, 29 Sep 2020 16:53:39 GMT""}]","2020-09-30"
"2006.11473","Hongqiang Song","Hongqiang Song and Shuo Yao","Characteristics and applications of interplanetary coronal mass ejection
  composition",,,"10.1007/s11431-020-1680-y",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In situ measurements of interplanetary coronal mass ejection (ICME)
composition, including elemental abundances and charge states of heavy ions,
open a new avenue to study coronal mass ejections (CMEs) besides remote-sensing
observations. The ratios between different elemental abundances can diagnose
the plasma origin of CMEs (e.g., from the corona or chromosphere/photosphere)
due to the first ionization potential (FIP) effect, which means elements with
different FIP get fractionated between the photosphere and corona. The ratios
between different charge states of a specific element can provide the electron
temperature of CMEs in the corona due to the freeze-in effect, which can be
used to investigate their eruption process. In this review, we first give an
overview of the ICME composition and then demonstrate their applications in
investigating some important subjects related to CMEs, such as the origin of
filament plasma and the eruption process of magnetic flux ropes. Finally, we
point out several important questions that should be addressed further for
better utilizing the ICME composition to study CMEs.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:18:50 GMT""}]","2020-11-03"
"2006.11474","Kostas Zoumpatianos","Haridimos Kondylakis, Niv Dayan, Kostas Zoumpatianos, Themis Palpanas","Coconut: sortable summarizations for scalable indexes over static and
  streaming data series",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many modern applications produce massive streams of data series that need to
be analyzed, requiring efficient similarity search operations. However, the
state-of-the-art data series indexes that are used for this purpose do not
scale well for massive datasets in terms of performance, or storage costs. We
pinpoint the problem to the fact that existing summarizations of data series
used for indexing cannot be sorted while keeping similar data series close to
each other in the sorted order. To address this problem, we present Coconut,
the first data series index based on sortable summarizations and the first
efficient solution for indexing and querying streaming series. The first
innovation in Coconut is an inverted, sortable data series summarization that
organizes data series based on a z-order curve, keeping similar series close to
each other in the sorted order. As a result, Coconut is able to use bulk
loading and updating techniques that rely on sorting to quickly build and
maintain a contiguous index using large sequential disk I/Os. We then explore
prefix-based and median-based splitting policies for bottom-up bulk loading,
showing that median-based splitting outperforms the state of the art, ensuring
that all nodes are densely populated. Finally, we explore the impact of
sortable summarizations on variable-sized window queries, showing that they can
be supported in the presence of updates through efficient merging of temporal
partitions. Overall, we show analytically and empirically that Coconut
dominates the state-of-the-art data series indexes in terms of construction
speed, query speed, and storage costs.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:18:51 GMT""},{""version"":""v2"",""created"":""Fri, 16 Apr 2021 07:33:22 GMT""}]","2021-04-19"
"2006.11475","Khang Tran","Summer Al Hamdani and Khang Tran","Zeros of a binomial combination of Chebyshev polynomials",,,,,"math.CA math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For $0<\alpha<1$, we study the zeros of the sequence of polynomials $\left\{
P_{m}(z)\right\} _{m=0}^{\infty}$ generated by the reciprocal of
$(1-t)^{\alpha}(1-2zt+t^{2})$, expanded as a power series in $t$. Equivalently,
this sequence is obtained from a linear combination of Chebyshev polynomials
whose coefficients have a binomial form. We show that the number of zeros of
$P_{m}(z)$ outside the interval $(-1,1)$ is bounded by a constant independent
of $m$.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:21:07 GMT""}]","2020-06-23"
"2006.11476","Yuan Yao","Yuan Yao, Chang Liu, Dezhao Luo, Yu Zhou, Qixiang Ye","Video Playback Rate Perception for Self-supervisedSpatio-Temporal
  Representation Learning","CVPR 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In self-supervised spatio-temporal representation learning, the temporal
resolution and long-short term characteristics are not yet fully explored,
which limits representation capabilities of learned models. In this paper, we
propose a novel self-supervised method, referred to as video Playback Rate
Perception (PRP), to learn spatio-temporal representation in a
simple-yet-effective way. PRP roots in a dilated sampling strategy, which
produces self-supervision signals about video playback rates for representation
model learning. PRP is implemented with a feature encoder, a classification
module, and a reconstructing decoder, to achieve spatio-temporal semantic
retention in a collaborative discrimination-generation manner. The
discriminative perception model follows a feature encoder to prefer perceiving
low temporal resolution and long-term representation by classifying
fast-forward rates. The generative perception model acts as a feature decoder
to focus on comprehending high temporal resolution and short-term
representation by introducing a motion-attention mechanism. PRP is applied on
typical video target tasks including action recognition and video retrieval.
Experiments show that PRP outperforms state-of-the-art self-supervised models
with significant margins. Code is available at github.com/yuanyao366/PRP
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:26:07 GMT""}]","2020-06-23"
"2006.11477","Michael Auli","Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli","wav2vec 2.0: A Framework for Self-Supervised Learning of Speech
  Representations",,,,,"cs.CL cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show for the first time that learning powerful representations from speech
audio alone followed by fine-tuning on transcribed speech can outperform the
best semi-supervised methods while being conceptually simpler. wav2vec 2.0
masks the speech input in the latent space and solves a contrastive task
defined over a quantization of the latent representations which are jointly
learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER
on the clean/other test sets. When lowering the amount of labeled data to one
hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour
subset while using 100 times less labeled data. Using just ten minutes of
labeled data and pre-training on 53k hours of unlabeled data still achieves
4.8/8.2 WER. This demonstrates the feasibility of speech recognition with
limited amounts of labeled data.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:35:02 GMT""},{""version"":""v2"",""created"":""Tue, 22 Sep 2020 04:26:03 GMT""},{""version"":""v3"",""created"":""Thu, 22 Oct 2020 06:09:10 GMT""}]","2020-10-23"
"2006.11478","Zhun Deng","Zhun Deng, Frances Ding, Cynthia Dwork, Rachel Hong, Giovanni
  Parmigiani, Prasad Patil, Pragya Sur","Representation via Representations: Domain Generalization via
  Adversarially Learned Invariant Representations",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the power of censoring techniques, first developed for
learning {\em fair representations}, to address domain generalization. We
examine {\em adversarial} censoring techniques for learning invariant
representations from multiple ""studies"" (or domains), where each study is drawn
according to a distribution on domains. The mapping is used at test time to
classify instances from a new domain. In many contexts, such as medical
forecasting, domain generalization from studies in populous areas (where data
are plentiful), to geographically remote populations (for which no training
data exist) provides fairness of a different flavor, not anticipated in
previous work on algorithmic fairness.
  We study an adversarial loss function for $k$ domains and precisely
characterize its limiting behavior as $k$ grows, formalizing and proving the
intuition, backed by experiments, that observing data from a larger number of
domains helps. The limiting results are accompanied by non-asymptotic
learning-theoretic bounds. Furthermore, we obtain sufficient conditions for
good worst-case prediction performance of our algorithm on previously unseen
domains. Finally, we decompose our mappings into two components and provide a
complete characterization of invariance in terms of this decomposition. To our
knowledge, our results provide the first formal guarantees of these kinds for
adversarial invariant domain generalization.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:35:03 GMT""}]","2020-06-23"
"2006.11479","Jongouk Choi","Jongouk Choi, Qingrui Liu, Changhee Jung","Compiler Directed Speculative Intermittent Computation",,,,,"cs.AR cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents CoSpec, a new architecture/compiler co-design scheme that
works for commodity in-order processors used in energy-harvesting systems. To
achieve crash consistency without requiring unconventional architectural
support, CoSpec leverages speculation assuming that power failure is not going
to occur and thus holds all committed stores in a store buffer (SB), as if they
were speculative, in case of mispeculation. CoSpec compiler first partitions a
given program into a series of recoverable code regions with the SB size in
mind, so that no region overflows the SB. When the program control reaches the
end of each region, the speculation turns out to be successful, thus releasing
all the buffered stores of the region to NVM. If power failure occurs during
the execution of a region, all its speculative stores disappear in the volatile
SB, i.e., they never affect program states in NVM. Consequently, the
interrupted region can be restarted with consistent program states in the wake
of power failure. To hide the latency of the SB release, i.e., essentially NVM
writes, at each region boundary, CoSpec overlaps the NVM writes of the current
region with the speculative execution of the next region. Such instruction
level parallelism gives an illusion of out-of-order execution on top of the
in-order processor, achieving a speedup of more than 1.2X when there is no
power outage. Our experiments on a set of real energy harvesting traces with
frequent outages demonstrate that CoSpec outperforms the state-of-the-art
scheme by 1.8~3X on average.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:50:12 GMT""}]","2020-06-23"
"2006.11480","Di Xie","Weijie Chen and Shiliang Pu and Di Xie and Shicai Yang and Yilu Guo
  and Luojun Lin","Unsupervised Image Classification for Deep Representation Learning","Accepted by ECCV2020 Workshop VIPriors",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep clustering against self-supervised learning is a very important and
promising direction for unsupervised visual representation learning since it
requires little domain knowledge to design pretext tasks. However, the key
component, embedding clustering, limits its extension to the extremely
large-scale dataset due to its prerequisite to save the global latent embedding
of the entire dataset. In this work, we aim to make this framework more simple
and elegant without performance decline. We propose an unsupervised image
classification framework without using embedding clustering, which is very
similar to standard supervised training manner. For detailed interpretation, we
further analyze its relation with deep clustering and contrastive learning.
Extensive experiments on ImageNet dataset have been conducted to prove the
effectiveness of our method. Furthermore, the experiments on transfer learning
benchmarks have verified its generalization to other downstream tasks,
including multi-label image classification, object detection, semantic
segmentation and few-shot image classification.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:57:06 GMT""},{""version"":""v2"",""created"":""Thu, 20 Aug 2020 06:42:41 GMT""}]","2020-08-21"
"2006.11481","Haojie Liu","Haojie Liu, Kang Liao, Chunyu Lin, Yao Zhao and Yulan Guo","Pseudo-LiDAR Point Cloud Interpolation Based on 3D Motion Representation
  and Spatial Supervision","10 pages, 6 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pseudo-LiDAR point cloud interpolation is a novel and challenging task in the
field of autonomous driving, which aims to address the frequency mismatching
problem between camera and LiDAR. Previous works represent the 3D spatial
motion relationship induced by a coarse 2D optical flow, and the quality of
interpolated point clouds only depends on the supervision of depth maps. As a
result, the generated point clouds suffer from inferior global distributions
and local appearances. To solve the above problems, we propose a Pseudo-LiDAR
point cloud interpolation network to generates temporally and spatially
high-quality point cloud sequences. By exploiting the scene flow between point
clouds, the proposed network is able to learn a more accurate representation of
the 3D spatial motion relationship. For the more comprehensive perception of
the distribution of point cloud, we design a novel reconstruction loss function
that implements the chamfer distance to supervise the generation of
Pseudo-LiDAR point clouds in 3D space. In addition, we introduce a multi-modal
deep aggregation module to facilitate the efficient fusion of texture and depth
features. As the benefits of the improved motion representation, training loss
function, and model structure, our approach gains significant improvements on
the Pseudo-LiDAR point cloud interpolation task. The experimental results
evaluated on KITTI dataset demonstrate the state-of-the-art performance of the
proposed network, quantitatively and qualitatively.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 03:11:04 GMT""}]","2020-06-23"
"2006.11482","Marcus Khuri","Gregory J. Galloway, Marcus A. Khuri, Eric Woolgar","A Bakry-\'Emery Almost Splitting Result With Applications to the
  Topology of Black Holes","Comm. Math. Phys., to appear","Comm. Math. Phys., 384 (2021), no. 3, 2067-2101","10.1007/s00220-021-04005-1",,"math.DG gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The almost splitting theorem of Cheeger-Colding is established in the setting
of almost nonnegative generalized $m$-Bakry-\'{E}mery Ricci curvature, in which
$m$ is positive and the associated vector field is not necessarily required to
be the gradient of a function. In this context it is shown that with a diameter
upper bound and volume lower bound the fundamental group of such manifolds is
almost abelian. Furthermore, extensions of well-known results concerning Ricci
curvature lower bounds are given for generalized $m$-Bakry-\'{E}mery Ricci
curvature. These include: the first Betti number bound of Gromov and Gallot,
Anderson's finiteness of fundamental group isomorphism types, volume
comparison, the Abresch-Gromoll inequality, and a Cheng-Yau gradient estimate.
Finally, this analysis is applied to stationary vacuum black holes in higher
dimensions to find that low temperature horizons must have limited topology,
similar to the restrictions exhibited by (extreme) horizons of zero
temperature.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 03:16:06 GMT""},{""version"":""v2"",""created"":""Sun, 28 Jun 2020 17:34:47 GMT""},{""version"":""v3"",""created"":""Sat, 16 Jan 2021 05:44:06 GMT""}]","2021-06-09"
"2006.11483","Le Yu","Le Yu, Leilei Sun, Bowen Du, Chuanren Liu, Hui Xiong, Weifeng Lv","Predicting Temporal Sets with Deep Neural Networks","9 pages, 6 figures, Proceedings of the 26th ACM SIGKDD Conference on
  Knowledge Discovery and Data Mining (KDD '2020)",,"10.1145/3394486.3403152",,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a sequence of sets, where each set contains an arbitrary number of
elements, the problem of temporal sets prediction aims to predict the elements
in the subsequent set. In practice, temporal sets prediction is much more
complex than predictive modelling of temporal events and time series, and is
still an open problem. Many possible existing methods, if adapted for the
problem of temporal sets prediction, usually follow a two-step strategy by
first projecting temporal sets into latent representations and then learning a
predictive model with the latent representations. The two-step approach often
leads to information loss and unsatisfactory prediction performance. In this
paper, we propose an integrated solution based on the deep neural networks for
temporal sets prediction. A unique perspective of our approach is to learn
element relationship by constructing set-level co-occurrence graph and then
perform graph convolutions on the dynamic relationship graphs. Moreover, we
design an attention-based module to adaptively learn the temporal dependency of
elements and sets. Finally, we provide a gated updating mechanism to find the
hidden shared patterns in different sequences and fuse both static and dynamic
information to improve the prediction performance. Experiments on real-world
data sets demonstrate that our approach can achieve competitive performances
even with a portion of the training data and can outperform existing methods
with a significant margin.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 03:29:02 GMT""},{""version"":""v2"",""created"":""Sun, 28 Jun 2020 03:00:44 GMT""},{""version"":""v3"",""created"":""Thu, 2 Jul 2020 05:43:43 GMT""},{""version"":""v4"",""created"":""Wed, 8 Jul 2020 01:58:42 GMT""}]","2020-07-09"
"2006.11484","Kirk Larsen","Kirk A. Larsen, Robert R. Lucchese, Daniel S. Slaughter, Thorsten
  Weber","Distinguishing resonance symmetries with energy-resolved photoion
  angular distributions from ion-pair formation in O$_2$ following two-photon
  absorption of a 9.3 eV femtosecond pulse","8 pages, 5 figures, 1 table","The Journal of Chemical Physics 153.2, 021103 (2020)","10.1063/5.0013485",,"physics.chem-ph physics.optics quant-ph","http://creativecommons.org/licenses/by/4.0/","  We present a combined experimental and theoretical study on the
photodissociation dynamics of ion-pair formation in O$_2$ following resonant
two-photon absorption of a 9.3 eV femtosecond pulse, where the resulting O$^+$
ions are detected using 3-D momentum imaging. Ion-pair formation states of
$^3\Sigma^-_g$ and $^3\Pi_g$ symmetry are accessed through predissociation of
optically dark continuum Rydberg states converging to the B $^2\Sigma^-_g$
ionic state, which are resonantly populated via a mixture of both
parallel-parallel and parallel-perpendicular two-photon transitions. This
mixture is evident in the angular distribution of the dissociation relative to
the light polarization, and varies with the kinetic energy release (KER) of the
fragmenting ion-pair. The KER-dependent photoion angular distribution reveals
the underlying two-photon absorption dynamics involved in the ion-pair
production mechanism and indicates the existence of two nearly degenerate
continuum resonances possessing different symmetries, which can both decay by
coupling to ion-pair states of the same total symmetry through internal
conversion.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 03:34:26 GMT""},{""version"":""v2"",""created"":""Wed, 26 Aug 2020 18:26:09 GMT""}]","2020-08-28"
"2006.11485","Tianren Zhang","Tianren Zhang, Shangqi Guo, Tian Tan, Xiaolin Hu, Feng Chen","Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement
  Learning","Accepted by NeurIPS 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Goal-conditioned hierarchical reinforcement learning (HRL) is a promising
approach for scaling up reinforcement learning (RL) techniques. However, it
often suffers from training inefficiency as the action space of the high-level,
i.e., the goal space, is often large. Searching in a large goal space poses
difficulties for both high-level subgoal generation and low-level policy
learning. In this paper, we show that this problem can be effectively
alleviated by restricting the high-level action space from the whole goal space
to a $k$-step adjacent region of the current state using an adjacency
constraint. We theoretically prove that the proposed adjacency constraint
preserves the optimal hierarchical policy in deterministic MDPs, and show that
this constraint can be practically implemented by training an adjacency network
that can discriminate between adjacent and non-adjacent subgoals. Experimental
results on discrete and continuous control tasks show that incorporating the
adjacency constraint improves the performance of state-of-the-art HRL
approaches in both deterministic and stochastic environments.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 03:34:45 GMT""},{""version"":""v2"",""created"":""Sat, 24 Oct 2020 06:07:54 GMT""},{""version"":""v3"",""created"":""Tue, 15 Dec 2020 07:37:30 GMT""},{""version"":""v4"",""created"":""Thu, 18 Mar 2021 09:48:05 GMT""}]","2021-03-19"
"2006.11486","Yang Wang","Jinjia Peng, Yang Wang, Huibing Wang, Zhao Zhang, Xianping Fu, Meng
  Wang","Unsupervised Vehicle Re-identification with Progressive Adaptation","Appearing at IJCAI 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vehicle re-identification (reID) aims at identifying vehicles across
different non-overlapping cameras views. The existing methods heavily relied on
well-labeled datasets for ideal performance, which inevitably causes fateful
drop due to the severe domain bias between the training domain and the
real-world scenes; worse still, these approaches required full annotations,
which is labor-consuming. To tackle these challenges, we propose a novel
progressive adaptation learning method for vehicle reID, named PAL, which
infers from the abundant data without annotations. For PAL, a data adaptation
module is employed for source domain, which generates the images with similar
data distribution to unlabeled target domain as ``pseudo target samples''.
These pseudo samples are combined with the unlabeled samples that are selected
by a dynamic sampling strategy to make training faster. We further proposed a
weighted label smoothing (WLS) loss, which considers the similarity between
samples with different clusters to balance the confidence of pseudo labels.
Comprehensive experimental results validate the advantages of PAL on both
VehicleID and VeRi-776 dataset.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 03:59:41 GMT""}]","2020-06-23"
"2006.11487","Duong Le Hoang","Duong H. Le, Trung-Nhan Vo, Nam Thoai","Paying more attention to snapshots of Iterative Pruning: Improving Model
  Compression via Ensemble Distillation","BMVC 2020 - Camera ready",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network pruning is one of the most dominant methods for reducing the heavy
inference cost of deep neural networks. Existing methods often iteratively
prune networks to attain high compression ratio without incurring significant
loss in performance. However, we argue that conventional methods for retraining
pruned networks (i.e., using small, fixed learning rate) are inadequate as they
completely ignore the benefits from snapshots of iterative pruning. In this
work, we show that strong ensembles can be constructed from snapshots of
iterative pruning, which achieve competitive performance and vary in network
structure. Furthermore, we present simple, general and effective pipeline that
generates strong ensembles of networks during pruning with large learning rate
restarting, and utilizes knowledge distillation with those ensembles to improve
the predictive power of compact models. In standard image classification
benchmarks such as CIFAR and Tiny-Imagenet, we advance state-of-the-art pruning
ratio of structured pruning by integrating simple l1-norm filters pruning into
our pipeline. Specifically, we reduce 75-80% of total parameters and 65-70%
MACs of numerous variants of ResNet architectures while having comparable or
better performance than that of original networks. Code associate with this
paper is made publicly available at https://github.com/lehduong/kesi.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 03:59:46 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2020 19:15:43 GMT""},{""version"":""v3"",""created"":""Fri, 14 Aug 2020 05:41:26 GMT""}]","2020-08-17"
"2006.11488","Yang Wang","Ximing Li, Yang Wang","Recovering Accurate Labeling Information from Partially Valid Data for
  Effective Multi-Label Learning","Appeared at IJCAI 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Partial Multi-label Learning (PML) aims to induce the multi-label predictor
from datasets with noisy supervision, where each training instance is
associated with several candidate labels but only partially valid. To address
the noisy issue, the existing PML methods basically recover the ground-truth
labels by leveraging the ground-truth confidence of the candidate label, \ie
the likelihood of a candidate label being a ground-truth one. However, they
neglect the information from non-candidate labels, which potentially
contributes to the ground-truth label recovery. In this paper, we propose to
recover the ground-truth labels, \ie estimating the ground-truth confidences,
from the label enrichment, composed of the relevance degrees of candidate
labels and irrelevance degrees of non-candidate labels. Upon this observation,
we further develop a novel two-stage PML method, namely
\emph{\underline{P}artial \underline{M}ulti-\underline{L}abel
\underline{L}earning with \underline{L}abel
\underline{E}nrichment-\underline{R}ecovery} (\baby), where in the first stage,
it estimates the label enrichment with unconstrained label propagation, then
jointly learns the ground-truth confidence and multi-label predictor given the
label enrichment. Experimental results validate that \baby outperforms the
state-of-the-art PML methods.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 04:13:24 GMT""}]","2020-06-23"
"2006.11489","Guojun Zhang","Zeou Hu, Kiarash Shaloudegi, Guojun Zhang, Yaoliang Yu","Federated Learning Meets Multi-objective Optimization","Accepted at IEEE Transactions on Network Science and Engineering 2022",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning has emerged as a promising, massively distributed way to
train a joint deep model over large amounts of edge devices while keeping
private user data strictly on device. In this work, motivated from ensuring
fairness among users and robustness against malicious adversaries, we formulate
federated learning as multi-objective optimization and propose a new algorithm
FedMGDA+ that is guaranteed to converge to Pareto stationary solutions.
FedMGDA+ is simple to implement, has fewer hyperparameters to tune, and
refrains from sacrificing the performance of any participating user. We
establish the convergence properties of FedMGDA+ and point out its connections
to existing approaches. Extensive experiments on a variety of datasets confirm
that FedMGDA+ compares favorably against state-of-the-art.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 04:17:13 GMT""},{""version"":""v2"",""created"":""Mon, 23 Jan 2023 23:55:16 GMT""}]","2023-01-25"
"2006.11490","Aranya Bhattacherjee Dr.","Vijay Bhatt, Pradip K. Jha, Aranya B. Bhattacherjee, Souri Banerjee","Coherent control of quantum and entanglement dynamics via periodic
  modulations in optomechanical semi-conductor resonator coupled to quantum-dot
  excitons","Comments are welcome",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We systematically study the influence of simultaneously modulating the input
laser intensity and quantum dot (QD) resonance frequecy on the mean-field
dynamics, fluctuation energy transfer and entanglement in a optomechanical
semi-conductor resonator embedded with a QD. We show that the modulation and
the hybrid system can be engineered to attain the desired mean-field values,
control the fluctuation energy transfer and the entanglement between the
various degrees of freedom. A remarkably high degree of entanglement can be
achieved by modulating only the QD frequency. The interplay between the two
modulations leads to an entanglement which lies between that generated solely
by modulating either the QD or the pump laser intensity. A transition from low
stationary to large dynamical entanglement occurs as we switch on the
modulation. This study opens up new possibilities for optimal control
strategies and can be used for data signal transfer and storage in quantum
communication platforms.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 04:17:41 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jul 2020 11:47:07 GMT""}]","2020-07-24"
"2006.11491","Toshiyuki Tanisaki","Toshiyuki Tanisaki","Differential operators on quantized flag manifolds at roots of unity III","41 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the cohomology of the sheaf of twisted differential operators on
the quantized flag manifold at a root of unity whose order is a prime power. It
follows from this and our previous results that for the De Concini-Kac type
quantized enveloping algebra, where the parameter $q$ is specialized to a root
of unity whose order is a prime power, the number of irreducible modules with a
certain specified central character coincides with the dimension of the total
cohomology group of the corresponding Springer fiber. This gives a weak version
of a conjecture of Lusztig concerning non-restricted representations of the
quantized enveloping algebra.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 04:21:21 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 04:07:03 GMT""}]","2021-08-17"
"2006.11492","Roya Firoozi","Roya Firoozi, Laura Ferranti, Xiaojing Zhang, Sebastian Nejadnik,
  Francesco Borrelli","A Distributed Multi-Robot Coordination Algorithm for Navigation in Tight
  Environments",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents a distributed method for multi-robot coordination based on
nonlinear model predictive control (NMPC) and dual decomposition. Our approach
allows the robots to coordinate in tight spaces (e.g., highway lanes, parking
lots, warehouses, canals, etc.) by using a polytopic description of each
robot's shape and formulating the collision avoidance as a dual optimization
problem. Our method accommodates heterogeneous teams of robots (i.e., robots
with different polytopic shapes and dynamic models can be part of the same
team) and can be used to avoid collisions in $n$-dimensional spaces. Starting
from a centralized implementation of the NMPC problem, we show how to exploit
the problem structure to allow the robots to cooperate (while communicating
their intentions to the neighbors) and compute collision-free paths in a
distributed way in real time. By relying on a bi-level optimization scheme, our
design decouples the optimization of the robot states and of the
collision-avoidance variables to create real time coordination strategies.
Finally, we apply our method for the autonomous navigation of a platoon of
connected vehicles on a simulation setting. We compare our design with the
centralized NMPC design to show the computational benefits of the proposed
distributed algorithm. In addition, we demonstrate our method for coordination
of a heterogeneous team of robots (with different polytopic shapes).
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 04:48:51 GMT""}]","2020-06-23"
"2006.11493","Long Peng","Long Peng, Junbo Zhao, Yong Tang, Lamine Mili, Zhuoyuan Gu, Zongsheng
  Zheng","Real-time LCC-HVDC Maximum Emergency Power Capacity Estimation Based on
  Local PMU Measurements","11 pages, 17 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The adjustable capacity of a line-commutated-converter High Voltage Direct
Current (LCC-HVDC) connected to a power system, called the LCC-HVDC maximum
emergency power capability or HVDC-MC for short, plays an important role in
determining the response of that system to a large disturbance. However, it is
a challenging task to obtain an accurate HVDC-MC due to system model
uncertainties as well as to contingencies. To address this problem, this paper
proposes to estimate the HVDC-MC using a Thevenin equivalent (TE) of the system
seen at the HVDC terminal bus of connection with the power system, whose
parameters are estimated by processing positive-sequences voltages and currents
of local synchrophasor measurements. The impacts of TE potential changes on the
impedance estimation under large disturbance have been extensively investigated
and an adaptive screening process of current measurements is developed to
reduce the error of TE impedance estimation. The uncertainties of phasor
measurements have been further taken into account by resorting to the total
least square estimation method. The limitations of the HVDC control
characteristics, the voltage-dependent current order limit, the converter
capacity, and the AC voltage on HVDC-MC estimation are also considered. The
simulations show that the proposed method can accurately track the dynamics of
the TE parameters and the real-time HVDC-MC after the large disturbances.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 04:49:42 GMT""}]","2020-06-23"
"2006.11494","Michael Yu","Michael Yu, Lu Qin, Ying Zhang, Wenjie Zhang, Xuemin Lin","AOT: Pushing the Efficiency Boundary of Main-memory Triangle Listing","Submitted to and accepted by DASFFA 2020",,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Triangle listing is an important topic significant in many practical
applications. Efficient algorithms exist for the task of triangle listing.
Recent algorithms leverage an orientation framework, which can be thought of as
mapping an undirected graph to a directed acylic graph, namely oriented graph,
with respect to any global vertex order. In this paper, we propose an adaptive
orientation technique that satisfies the orientation technique but refines it
by traversing carefully based on the out-degree of the vertices in the oriented
graph during the computation of triangles. Based on this adaptive orientation
technique, we design a new algorithm, namely aot, to enhance the edge-iterator
listing paradigm. We also make improvements to the performance of aot by
exploiting the local order within the adjacent list of the vertices.
  We show that aot is the first work which can achieve best performance in
terms of both practical performance and theoretical time complexity. Our
comprehensive experiments over $16$ real-life large graphs show a superior
performance of our \aot algorithm when compared against the state-of-the-art,
especially for massive graphs with billions of edges. Theoretically, we show
that our proposed algorithm has a time complexity of $\Theta(\sum_{ \langle u,v
\rangle \in \vec{E} } \min\{ deg^{+}(u),deg^{+}(v)\}))$, where $\vec{E}$ and
$deg^{+}(x)$ denote the set of directed edges in an oriented graph and the
out-degree of vertex $x$ respectively. As to our best knowledge, this is the
best time complexity among in-memory triangle listing algorithms.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 04:53:44 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 03:01:22 GMT""}]","2020-06-26"
"2006.11495","Manuel Baltieri Dr","Manuel Baltieri, Christopher L. Buckley, Jelle Bruineberg","Predictions in the eye of the beholder: an active inference account of
  Watt governors","Accepted at ALife 2020",,"10.1162/isal_a_00288",,"q-bio.NC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Active inference introduces a theory describing action-perception loops via
the minimisation of variational (and expected) free energy or, under
simplifying assumptions, (weighted) prediction error. Recently, active
inference has been proposed as part of a new and unifying framework in the
cognitive sciences: predictive processing. Predictive processing is often
associated with traditional computational theories of the mind, strongly
relying on internal representations presented in the form of generative models
thought to explain different functions of living and cognitive systems. In this
work, we introduce an active inference formulation of the Watt centrifugal
governor, a system often portrayed as the canonical ""anti-representational""
metaphor for cognition. We identify a generative model of a steam engine for
the governor, and derive a set of equations describing ""perception"" and
""action"" processes as a form of prediction error minimisation. In doing so, we
firstly challenge the idea of generative models as explicit internal
representations for cognitive systems, suggesting that such models serve only
as implicit descriptions for an observer. Secondly, we consider current
proposals of predictive processing as a theory of cognition, focusing on some
of its potential shortcomings and in particular on the idea that virtually any
system admits a description in terms of prediction error minimisation,
suggesting that this theory may offer limited explanatory power for cognitive
systems. Finally, as a silver lining we emphasise the instrumental role this
framework can nonetheless play as a mathematical tool for modelling cognitive
architectures interpreted in terms of Bayesian (active) inference.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 04:55:39 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 03:02:44 GMT""}]","2022-03-10"
"2006.11496","Tzonelih Hwang","Chun-Hao Chang, Yu-Chin Lu, Tzonelih Hwang","Measure-resend authenticated semi-quantum key distribution with single
  photons","10 pages, 1 figure, 1 table",,,,"quant-ph cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Yu et al. and Li et al. have proposed the measure-resend protocols of
authenticated semi-quantum key distribution (ASQKD). A new measure-resend ASQKD
protocol is proposed in this paper, which requires a lower burden of quantum
resource, needs fewer bits of the pre-shared key, and even provides better
qubit efficiency than their protocols. The security proof shows the robustness
of the proposed protocol under the collective attack.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 05:03:07 GMT""}]","2020-06-23"
"2006.11497","Lychagin Valentin","Valentin Lychagin","Euler equations for Cosserat media","12 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider Cosserat media as SO(3)-structures over a domain D in R3. Motions
of such media are given by automorphisms of the SO(3)-bundle. We present
Euler-type equations for such media and discuss their structure.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 05:11:29 GMT""}]","2020-06-23"
"2006.11498","Wei Zhong","Rui-Jie Cai, Wei Zhong, Lan Zhou and Yu-Bo Sheng","Ancilla-assisted frequency estimation under phase covariant noises with
  Greenberger-Horne-Zeilinger states","13 pages, 2 figures, Submitted to Quantum Information Processing.
  Comments are welcome","Quantum Inf Process 19, 359 (2020)","10.1007/s11128-020-02867-3",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been demonstrated that the optimal sensitivity achievable with
Greenberger-Horne-Zeilinger states is the same as that with uncorrelated probes
in the frequency estimation in the presence of uncorrelated Markovian dephasing
[S. F. Huelga, et al., Phys. Rev. Lett. 79, 3865 (1997)]. Here, we extend this
issue by examining the optimal frequency sensitivities achievable by the use of
ancilla-assisted strategy, which has been proposed recently for robust phase
estimation. We present the ultimate frequency sensitivities bounded by the
quantum Fisher information for a general case in the presence of Markovian
covariant phase noises, and the optimal measurement observables that can
saturate the theoretical sensitivity bounds. We also demonstrate the
effectiveness of the ancilla-assisted strategy for preserving frequency
sensitivities suffering from specific physically ground noises.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 05:16:57 GMT""}]","2022-03-24"
"2006.11499","Everett W. Howe","Momonari Kudo, Shushi Harashita, and Everett W. Howe","Algorithms to enumerate superspecial Howe curves of genus 4","15 pages. ANTS 2020. The previous version assumed a hypothesis that
  we verified computationally for each input prime p. Recently Jordan and
  Zaytman proved that this hypothesis holds in general, and the revised paper
  reflects this. There are other more minor edits as well","pp. 301-316 in ANTS XIV: Proceedings of the Fourteenth Algorithmic
  Number Theory Symposium (S. Galbraith, ed.), the Open Book Series 4,
  Mathematical Sciences Publishers, Berkeley, 2020","10.2140/obs.2020.4.301",,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Howe curve is a curve of genus $4$ obtained as the fiber product of two
genus-$1$ double covers of $\mathbf{P}^1$. In this paper, we present a simple
algorithm for testing isomorphism of Howe curves, and we propose two main
algorithms for finding and enumerating these curves: One involves solving
multivariate systems coming from Cartier--Manin matrices, while the other uses
Richelot isogenies of curves of genus $2$. Comparing the two algorithms by
implementation and by complexity analyses, we conclude that the latter
enumerates curves more efficiently. Using these algorithms, we show that there
exist superspecial curves of genus $4$ in characteristic $p$ for every prime
$p$ with $7 < p < 20000$.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 05:24:41 GMT""},{""version"":""v2"",""created"":""Sun, 2 Aug 2020 23:56:01 GMT""}]","2021-01-01"
"2006.11500","Lakshmi Kanta Dey Dr.","Pratikshan Mondal, Hiranmoy Garai and Lakshmi Kanta Dey","On some enriched contractions in Banach spaces","12 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce two new types of enriched contractions, viz.,
enriched $\mathcal{A}$-contraction and enriched $\mathcal{A}'$-contraction.
Then we obtain fixed points of mappings satisfying such contractions using the
fixed point property of the average operator of the mappings. Further, we study
the well-posedness and limit shadowing property of the fixed point problem
involving the contractions, and give some examples to validate the results
proved. We frame an open question related to the existence of a fixed point of
such contractions. We also show that Berinde and P\u{a}curar's recent results
on different kinds enriched contractions and some well known classical fixed
point results are particular cases of our results.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 05:48:38 GMT""}]","2020-06-23"
"2006.11501","Hou Rui","Rui Hou and Yuhui Quan and Ding Pan","Dielectric constant of supercritical water in a large
  pressure-temperature range","The trained NND model is openly available at
  https://github.com/angstrom-group/NN-Dipole-Model","Journal of Chemical Physics 153, 101103 (2020)","10.1063/5.0020811",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A huge amount of water at supercritical conditions exists in Earth's
interior, where its dielectric properties play a critical role in determining
how it stores and transports materials. However, it is very challenging to
obtain the static dielectric constant of water, $\epsilon_0$, in a wide
pressure-temperature (P-T) range as found in deep Earth either experimentally
or by first-principles simulations. Here, we introduce a neural network dipole
model, which, combined with molecular dynamics, can be used to compute P-T
dependent dielectric properties of water as accurately as first-principles
methods but much more efficiently. We found that $\epsilon_0$ may vary by one
order of magnitude in Earth's upper mantle, suggesting that the solvation
properties of water change dramatically at different depths. There is a subtle
interplay between the molecular dipole moment and the dipolar angular
correlation in governing the change of $\epsilon_0$. We also calculated the
frequency-dependent dielectric constant of water in the microwave range, which,
to the best of our knowledge, has not been calculated from first principles,
and found that temperature affects the dielectric absorption more than
pressure. Our results are of great use in many areas, e.g., modelling
water-rock interactions in geochemistry. The computational approach introduced
here can be readily applied to other molecular fluids.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 06:26:17 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 04:06:06 GMT""},{""version"":""v3"",""created"":""Sun, 16 Aug 2020 12:41:56 GMT""},{""version"":""v4"",""created"":""Tue, 18 Aug 2020 08:40:43 GMT""},{""version"":""v5"",""created"":""Mon, 14 Sep 2020 16:20:16 GMT""}]","2020-09-15"
"2006.11502","Andreas Boukas","Luigi Accardi and Andreas Boukas","von Neumann's Minimax Theorem for Continuous Quantum Games",,"Journal of Stochastic Analysis: Vol.1: No.2, Article 5, (2020)","10.31390/josa.1.2.05",,"math-ph math.FA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The concept of a classical player, corresponding to a classical random
variable, is extended to include quantum random variables in the form of self
adjoint operators on infinite dimensional Hilbert space. A quantum version of
Von Neumann's Minimax theorem for infinite dimensional (or continuous) games is
proved.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 06:33:20 GMT""}]","2020-06-23"
"2006.11503","Shao-Wen Wei","Shao-Wen Wei, Yu-Xiao Liu, Robert B. Mann","Novel dual relation and constant in Hawking-Page phase transitions","5 pages and 4 figures","Phys. Rev. D 102, 104011 (2020)","10.1103/PhysRevD.102.104011",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Universal relations and constants have important applications in
understanding a physical theory. In this article, we explore this issue for
Hawking-Page phase transitions in Schwarzschild anti-de Sitter black holes. We
find a novel exact dual relation between the minimum temperature of the
($d$+1)-dimensional black hole and the Hawking-Page phase transition
temperature in $d$ dimensions, reminiscent of the holographic principle.
Furthermore, we find that the normalized Ruppeiner scalar curvature is a
universal constant at the Hawking-Page transition point. Since the Ruppeiner
curvature can be treated as an indicator of the intensity of the interactions
amongst black hole microstructures, we conjecture that this universal constant
denotes an interaction threshold, beyond which a virtual black hole becomes a
real one. This new dual relation and universal constant are fundamental in
understanding Hawking-Page phase transitions, and might have new important
applications in the black hole physics in the near future.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 06:49:23 GMT""},{""version"":""v2"",""created"":""Mon, 9 Nov 2020 06:22:38 GMT""}]","2020-11-10"
"2006.11504","Zhigang Wu","Zhigang Wu, Shizhong Zhang and Hui Zhai","Dynamical Kosterlitz-Thouless Theory for Two-Dimensional Ultracold
  Atomic Gases","11 pages, 4 figures","Phys. Rev. A 102, 043311 (2020)","10.1103/PhysRevA.102.043311",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this letter we develop a theory for the first and second sound in a
two-dimensional atomic superfluid across the superfluid transition based on the
dynamic Koterlitz-Thouless theory. We employ a set of modified two-fluid
hydrodynamic equations which incorporate the dynamics of the quantised
vortices, rather than the conventional ones for a three-dimensional superfluid.
As far as the sound dispersion equation is concerned, the modification is
essentially equivalent to replacing the static superfluid density with a
frequency dependent one, renormalised by the frequency dependent ""dielectric
constant"" of the vortices. This theory has two direct consequences. First,
because the renormalised superfluid density at finite frequencies does not
display discontinuity across the superfluid transition, in contrast to the
static superfluid density, the sound velocities vary smoothly across the
transition. Second, the theory includes dissipation due to free vortices, and
thus naturally describes the sound-to-diffusion crossover for the second sound
in the normal phase. With only one fitting parameter, our theory gives a
perfect agreement with the experimental measurements of sound velocities across
the transition, as well as the quality factor in the vicinity of the
transition. The predictions from this theory can be further verified by future
experiments.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 06:55:19 GMT""}]","2020-10-14"
"2006.11505","Akshat Gupta","Akshat Gupta, Prasad N R","Blind Descent: A Prequel to Gradient Descent","We have discovered a new learning method which does random
  optimisation and solves the problem of initialisation for backpropagation in
  global optimisation. However, we also pose open questions that we discovered
  while performing experiments",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe an alternative learning method for neural networks, which we call
Blind Descent. By design, Blind Descent does not face problems like exploding
or vanishing gradients. In Blind Descent, gradients are not used to guide the
learning process. In this paper, we present Blind Descent as a more fundamental
learning process compared to gradient descent. We also show that gradient
descent can be seen as a specific case of the Blind Descent algorithm. We also
train two neural network architectures, a multilayer perceptron and a
convolutional neural network, using the most general Blind Descent algorithm to
demonstrate a proof of concept.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:01:25 GMT""},{""version"":""v2"",""created"":""Wed, 26 Aug 2020 14:14:29 GMT""}]","2020-08-27"
"2006.11506","Imran Mirza Mr.","Bibandhan Poudyal and Imran M. Mirza","Collective photon routing improvement in a dissipative quantum emitter
  chain strongly coupled to a chiral waveguide QED ladder","11 pages, 7 figures","Phys. Rev. Research 2, 043048 (2020)","10.1103/PhysRevResearch.2.043048",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the routing scheme of single photons in a one-dimensional periodic
chain of two-level quantum emitters (QEs) strongly coupled to two waveguides in
a ladder configuration. It is known that for a single-emitter chiral waveguide
ladder setting, photons can be redirected from one waveguide to another with a
$100\%$ probability (deterministically) provided the resonance condition is met
and spontaneous emission is completely ignored. However, when the spontaneous
emission is included the routing scheme becomes considerably imperfect. In this
paper, we present a solution to this issue by considering a chain of QEs where
in addition to the waveguide mediated interaction among emitters, a direct and
infinitely long-ranged dipole-dipole interaction (DDI) is taken into account.
We show that the collective effects arising from the strong DDI protect the
routing scheme from spontaneous emission loss. In particular, we demonstrate
that the router operation can be improved from $58\%$ to $95\%$ in a typical
dissipative chiral light-matter interface consisting of nanowires modes
strongly interacting with a linear chain of 30 quantum dots. With the recent
experimental progress in chiral quantum optics, trapped QEs evanescently
coupled to tapered nanofibers can serve as a platform for the experimental
realization of this work.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:07:17 GMT""}]","2020-10-14"
"2006.11507","Yutaka Yamaguti","Yutaka Yamaguti and Ichiro Tsuda","Functional differentiations in evolutionary reservoir computing networks","Revised manuscript. 15 figures. This article has been submitted to
  Chaos. After it is published, it will be found at
  https://aip.scitation.org/journal/cha","Chaos 31, 013137 (2021)","10.1063/5.0019116",,"nlin.AO cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an extended reservoir computer that shows the functional
differentiation of neurons. The reservoir computer is developed to enable
changing of the internal reservoir using evolutionary dynamics, and we call it
an evolutionary reservoir computer. To develop neuronal units to show
specificity, depending on the input information, the internal dynamics should
be controlled to produce contracting dynamics after expanding dynamics.
Expanding dynamics magnifies the difference of input information, while
contracting dynamics contributes to forming clusters of input information,
thereby producing multiple attractors. The simultaneous appearance of both
dynamics indicates the existence of chaos. In contrast, sequential appearance
of these dynamics during finite time intervals may induce functional
differentiations. In this paper, we show how specific neuronal units are
yielded in the evolutionary reservoir computer.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:07:44 GMT""},{""version"":""v2"",""created"":""Fri, 27 Nov 2020 12:22:22 GMT""}]","2023-05-10"
"2006.11508","Baopi Liu","Baopi Liu","Spherical-harmonic Expansion of the Modified Diffusion Equation for
  Wormlike Chain in Curvilinear Coordinates",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the wormlike polymer chains using self-consistent field theory
and take into account the Onsager excluded-volume interaction between polymer
segments. The propagator of polymer chain is one of the essential physical
quantities used to study the conformation of polymers, which satisfies the
modified diffusion equation (MDE) for wormlike chain. The propagator of
wormlike chain is not only dependent on the spatial variables, but also on the
orientation. We separate the variables of propagator by using
spherical-harmonic series and then simplify the MDE to a coupled set of
equations only depends on spatial variables in this paper. We expand the MDE by
spherical-harmonic functions in cylindrical coordinates and spherical
coordinates, respectively. We find that there are three ways to set the
orientation, no matter in cylindrical coordinates or spherical coordinates. But
for the convenience of calculation, we compare these three forms and choose the
simplest one to simplify the MDE. And we get a coupled set of equations only
depends on spatial variables.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:17:05 GMT""}]","2020-06-23"
"2006.11509","Jun Liu","Jun Liu","Molecular Characterizations of Variable Anisotropic Hardy Spaces with
  Applications to Boundedness of Calder\'on-Zygmund Operators",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $p(\cdot):\ \mathbb{R}^n\to(0,\infty]$ be a variable exponent function
satisfying the globally log-H\""{o}lder continuous condition and $A$ a general
expansive matrix on $\mathbb{R}^n$. Let $H_A^{p(\cdot)}(\mathbb{R}^n)$ be the
variable anisotropic Hardy space associated with $A$ defined via the
non-tangential grand maximal function. In this article, via the known atomic
characterization of $H_A^{p(\cdot)}(\mathbb{R}^n)$, the author establishes its
molecular characterization with the known best possible decay of molecules. As
an application, the author obtains a criterion on the boundedness of linear
operators on $H_A^{p(\cdot)}(\mathbb{R}^n)$, which is used to prove the
boundedness of anisotropic Calder\'on-Zygmund operators on
$H_A^{p(\cdot)}(\mathbb{R}^n)$. In addition, the boundedness of anisotropic
Calder\'on-Zygmund operators from $H_A^{p(\cdot)}(\mathbb{R}^n)$ to the
variable Lebesgue space $L^{p(\cdot)}(\mathbb{R}^n)$ is also presented. All
these results are new even in the classical isotropic setting.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:25:18 GMT""}]","2020-06-23"
"2006.11510","Cong Wang","Cong Wang and Witold Pedrycz and ZhiWu Li and MengChu Zhou and Shuzhi
  Sam Ge","G-image Segmentation: Similarity-preserving Fuzzy C-Means with Spatial
  Information Constraint in Wavelet Space","This paper has been withdrawn by the author since some statements are
  not right as raised by other researchers","IEEE Transactions on Fuzzy Systems, 2020","10.1109/TFUZZ.2020.3029285",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  G-images refer to image data defined on irregular graph domains. This work
elaborates a similarity-preserving Fuzzy C-Means (FCM) algorithm for G-image
segmentation and aims to develop techniques and tools for segmenting G-images.
To preserve the membership similarity between an arbitrary image pixel and its
neighbors, a Kullback-Leibler divergence term on membership partition is
introduced as a part of FCM. As a result, similarity-preserving FCM is
developed by considering spatial information of image pixels for its robustness
enhancement. Due to superior characteristics of a wavelet space, the proposed
FCM is performed in this space rather than Euclidean one used in conventional
FCM to secure its high robustness. Experiments on synthetic and real-world
G-images demonstrate that it indeed achieves higher robustness and performance
than the state-of-the-art FCM algorithms. Moreover, it requires less
computation than most of them.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:26:33 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 01:43:13 GMT""}]","2020-10-12"
"2006.11511","Abhijit Mahabal","Abhijit Mahabal, Yinrui Li, Rajat Raina, Daniel Sun, Revati Mahajan,
  Jure Leskovec","Improving Query Safety at Pinterest",,,,,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Query recommendations in search engines is a double edged sword, with
undeniable benefits but potential of harm. Identifying unsafe queries is
necessary to protect users from inappropriate query suggestions. However,
identifying these is non-trivial because of the linguistic diversity resulting
from large vocabularies, social-group-specific slang and typos, and because the
inappropriateness of a term depends on the context. Here we formulate the
problem as query-set expansion, where we are given a small and potentially
biased seed set and the aim is to identify a diverse set of semantically
related queries. We present PinSets, a system for query-set expansion, which
applies a simple yet powerful mechanism to search user sessions, expanding a
tiny seed set into thousands of related queries at nearly perfect precision,
deep into the tail, along with explanations that are easy to interpret. PinSets
owes its high quality expansion to using a hybrid of textual and behavioral
techniques (i.e., treating queries both as compositional and as black boxes).
Experiments show that, for the domain of drugs-related queries, PinSets expands
20 seed queries into 15,670 positive training examples at over 99\% precision.
The generated expansions have diverse vocabulary and correctly handles words
with ambiguous safety. PinSets decreased unsafe query suggestions at Pinterest
by 90\%.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:35:22 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 04:12:09 GMT""}]","2020-06-24"
"2006.11512","Akshay Khatri","Akshay Khatri, Pranav P and Dr. Anand Kumar M","Sarcasm Detection in Tweets with BERT and GloVe Embeddings","5 pages Submitted to ACL 2020 conference",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sarcasm is a form of communication in whichthe person states opposite of what
he actually means. It is ambiguous in nature. In this paper, we propose using
machine learning techniques with BERT and GloVe embeddings to detect sarcasm in
tweets. The dataset is preprocessed before extracting the embeddings. The
proposed model also uses the context in which the user is reacting to along
with his actual response.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:36:06 GMT""}]","2020-06-23"
"2006.11513","Haisen Zhang","Haijun Zhang, Haisen Zhang, Keping Long and George K. Karagiannidis","Deep Learning based Radio Resource Management in NOMA Networks: User
  Association, Subchannel and Power Allocation","to appear in IEEE Transactions on Network Science and Engineering",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the rapid development of future wireless communication, the combination
of NOMA technology and millimeter-wave(mmWave) technology has become a research
hotspot. The application of NOMA in mmWave heterogeneous networks can meet the
diverse needs of users in different applications and scenarios in future
communications. In this paper, we propose a machine learning framework to deal
with the user association, subchannel and power allocation problems in such a
complex scenario. We focus on maximizing the energy efficiency (EE) of the
system under the constraints of quality of service (QoS), interference
limitation, and power limitation. Specifically, user association is solved
through the Lagrange dual decomposition method, while semi-supervised learning
and deep neural network (DNN) are used for the subchannel and power allocation,
respectively. In particular, unlabeled samples are introduced to improve
approximation and generalization ability for subchannel allocation. The
simulation indicates that the proposed scheme can achieve higher EE with lower
complexity.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:49:24 GMT""}]","2020-06-23"
"2006.11514","Xuhao Wu","Xuhao Wu, Shuang Du, Renxin Xu","What if the neutron star maximum mass is beyond $\sim2.3 M_{\odot}$?","7 pages, 6 figures",,"10.1093/mnras/staa3145",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By assuming the formation of a black hole soon after the merger event of
GW170817, Shibata et al. updated the constraints on the maximum mass
($M_\textrm{max}$) of a stable neutron star within $\lesssim$ 2.3 $M_{\odot}$,
but there is no solid evidence to rule out $M_\textrm{max}>2.3~M_{\odot}$ from
the point of both microphysical and astrophysical views. In order to explain
massive pulsars, it is naturally expected that the equation of state (EOS)
would become stiffer beyond a specific density. In this paper, we consider the
possibility of EOSs with $M_\textrm{max}>2.3~M_{\odot}$, investigating the
stiffness and the transition density in a polytropic model. Two kinds of
neutron stars are considered, i.e., normal neutron stars (the density vanishes
on gravity-bound surface) and strange stars (a sharp density discontinuity on
self-bound surface). The polytropic model has only two parameter inputs in both
cases: ($\rho_{\rm t}$, $\gamma$) for gravity-bound objects, while ($\rho_{\rm
s}$, $\gamma$) for self-bound ones, with $\rho_{\rm t}$ the transition density,
$\rho_{\rm s}$ the surface density and $\gamma$ the polytropic exponent. In the
matter of $M_\textrm{max}>2.3~M_{\odot}$, it is found that the smallest
$\rho_{\rm t}$ and $\gamma$ should be $\sim 0.50~\rho_0$ and $\sim 2.65$ for
normal neutron stars, respectively, whereas for strange star, we have $\gamma >
1.40$ if $\rho_{\rm s} > 1.0~\rho_0$ and $\rho_{\rm s} < 1.58~\rho_0$ if
$\gamma <2.0$ ($\rho_0$ is the nuclear saturation density). These parametric
results could guide further research of the real EOS with any foundation of
microphysics if a pulsar mass higher than $2.3~M_{\odot}$ is measured in the
future. We also derive rough results of common neutron star radius range, which
is $9.8~\rm{km} < R_{1.4} < 13.8~\rm{km}$ for normal neutron stars and
$10.5~\rm{km} < R_{1.4} < 12.5~\rm{km}$ for strange stars.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:49:35 GMT""}]","2020-10-21"
"2006.11515","Kalin Staykov Dr.","Daniela D. Doneva, Kalin V. Staykov, Stoytcho S. Yazadjiev, Radostina
  Z. Zheleva","Multi-scalar Gauss-Bonnet gravity -- hairy black holes and scalarization",,"Phys. Rev. D 102, 064042 (2020)","10.1103/PhysRevD.102.064042",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper we consider multi-scalar extension of
Einstein-Gauss-Bonnet gravity. We focus on multi-scalar Einstein-Gauss-Bonnet
models whose target space is a three-dimensional maximally symmetric space,
namely either $\mathbb{S}^3$, $\mathbb{H}^3$ or $\mathbb{R}^3$, and in the case
when the map $\text{\it spacetime} \to \text{\it target space}$ is nontrivial.
We prove numerically the existence of black holes in this class of models for
several Gauss-Bonnet coupling functions, including the case of scalarization.
We also perform systematic study of a variety of black hole characteristics and
the space-time around them, such as the area of the horizon, the entropy and
the radius of the photon sphere. One of the most important properties of the
obtained solutions is that the scalar charge is zero and thus the scalar dipole
radiation is suppressed which leads to much weaker observational constraints
compared to the majority of modified theories possessing a scalar degree of
freedom. For one of the coupling functions we could find branches of scalarized
black holes which have a nontrivial structure -- there is non-uniqueness of the
scalarized solutions belonging to a single branch and there is a region of the
parameter space where most probably stable scalarized black holes coexist with
the stable Schwarzschild black holes. Such a phenomena can have a clear
observational signature.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:52:47 GMT""}]","2020-09-23"
"2006.11516","Wentu Song","Wentu Song, Nikita Polyanskii, Kui Cai, and Xuan He","Systematic Single-Deletion Multiple-Substitution Correcting Codes",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work by Smagloy et al. (ISIT 2020) shows that the redundancy of a
single-deletion $s$-substitution correcting code is asymptotically at least
$(s+1)\log n+o(\log n)$, where $n$ is the length of the codes. They also
provide a construction of single-deletion and single-substitution codes with
redundancy $6\log n+8$. In this paper, we propose a family of systematic
single-deletion $s$-substitution correcting codes of length $n$ with
asymptotical redundancy at most $(3s+4)\log n+o(\log n)$ and polynomial
encoding/decoding complexity, where $s\geq 2$ is a constant. Specifically, the
encoding and decoding complexity of the proposed codes are $O(n^{s+3})$ and
$O(n^{s+2})$, respectively.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:56:32 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jul 2020 01:33:59 GMT""},{""version"":""v3"",""created"":""Fri, 20 Nov 2020 22:10:59 GMT""}]","2020-11-24"
"2006.11517","Fatemeh Ahmadi Kalateh Ahmad","Y. Bisabr and F. Ahmadi","Deflation of Vacuum Energy During Inflation Due to Bulk-Brane
  Interaction","10 pages, 6 figures","JCAP 10 (2020) 050","10.1088/1475-7516/2020/10/050",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a brane world inflationary model in which inflation is driven by
dynamics of a self-interacting scalar field living in the five-dimensional
bulk. The scalar field is non-minimally coupled to matter fields on the brane
and acts as an inflaton which induces a slow-roll inflation. We show that
although the Friedmann equation is modified at early times due to effects of
the extra dimension, the slow-roll condition is the same as that of the
four-dimensional case. Due to the non-minimal coupling of matter with the bulk
scalar, there is an energy transfer between the two components. We investigate
the conditions under which the direction of this energy transfer can be from
matter onto the bulk scalar. There are at least two advantages in this case: 1)
It establishes a mechanism by which a large effective cosmological term on the
brane is deflated during the inflation period. 2) The energy flow onto the bulk
inflaton gives a more strongly damped evolution of the scalar field in the
slow-roll region for a given potential. We then show that our results are
supported by numerical estimations with quadratic and exponential potentials.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 07:58:45 GMT""}]","2020-11-11"
"2006.11518","Guan Huang","Guan Huang and Sergei Kuksin","On The Energy Transfer To High Frequencies In The Damped/Driven
  Nonlinear Schr\""odinger Equation (Extended Version)",,,,,"math.AP math-ph math.DS math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a damped/driven nonlinear Schr\""odinger equation in an $n$-cube
$K^{n}\subset\mathbb{R}^n$, $n$ is arbitrary, under Dirichlet boundary
conditions \[ u_t-\nu\Delta u+i|u|^2u=\sqrt{\nu}\eta(t,x),\quad x\in
K^{n},\quad u|_{\partial K^{n}}=0, \quad \nu>0, \] where $\eta(t,x)$ is a
random force that is white in time and smooth in space. It is known that the
Sobolev norms of solutions satisfy $ \| u(t)\|_m^2 \le C\nu^{-m}, $ uniformly
in $t\ge0$ and $\nu>0$. In this work we prove that for small $\nu>0$ and any
initial data, with large probability the Sobolev norms $\|u(t,\cdot)\|_m$ of
the solutions with $m>2$ become large at least to the order of
$\nu^{-\kappa_{n,m}}$ with $\kappa_{n,m}>0$, on time intervals of order
$\mathcal{O}(\frac{1}{\nu})$.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:07:13 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 03:37:11 GMT""}]","2020-07-02"
"2006.11519","Xingpeng Li","Arun Venkatesh Ramesh and Xingpeng Li","Enhancing System Flexibility through Corrective Demand Response in
  Security-Constrained Unit Commitment","6 pages, 4 figures",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Currently, system operators implement demand response by dispatching
controllable loads for economic reasons in day-ahead scheduling. Particularly,
demand shifting from peak hours when the cost of electricity is higher to
non-peak hours to maintain system reliability by flattening the load profile.
However, the system flexibility and economic benefits of such action in
post-contingency scenarios are not explicitly considered in short-term
operations. Hence, this paper highlights the benefits of demand response as a
corrective action for potential post-contingency emergencies in day-ahead
scheduling. A security-constrained unit commitment (SCUC) model which considers
the flexibility offered through corrective demand response (CDR) to maintain
system reliability when a line or generator outage occurs is proposed. The
proposed model was tested on IEEE 24-bus system where simulation results point
to significant total cost savings in daily operations. Moreover, the results
point to better long-term reliability of generators along with the ability to
use existing system flexibility and serve higher critical demands in base-case
when CDR is implemented.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:17:36 GMT""}]","2020-06-23"
"2006.11520","Xingpeng Li","Mingjian Tuo and Xingpeng Li","Dynamic Estimation of Power System Inertia Distribution Using
  Synchrophasor Measurements","6 pages, 10 figures",,,,"eess.SP cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Integration of intermittent renewable energy sources in modern power systems
is increasing very fast. Replacement of synchronous generators with zero-to-low
variable renewables substantially decreases the system inertia. In a large
system, inertia distribution may vary significantly, areas of low inertia are
more susceptible to frequency deviation, posing risks of load shedding and
generation trip. Therefore, it is necessary for operators to evaluate and
quantify the system inertia and its distribution in real time. This paper
proposes a novel synchronized phasor measurement units (PMUs)-based dynamic
system inertia estimation method. The proposed inertia estimation method is
derived using electrical distance and clustering algorithm, which considers the
impact of location of measurements relative to in-feed load and impact of
oscillations. The center of inertia (COI) area and area of low inertia are also
determined during the estimation. Numerical simulations are conducted on the
IEEE 24-bus system with various load profiles using Transient Security Analysis
Tools (TSAT), a core module of the DSATools, which demonstrate the efficacy of
the proposed approach.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:23:24 GMT""}]","2020-06-23"
"2006.11521","Xingpeng Li","Cunzhi Zhao and Xingpeng Li","A Novel Real-Time Energy Management Strategy for Gird-Friendly
  Microgrid: Harnessing Internal Fluctuation Internally","6 pages, 9 figures",,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Typically, a large portion of microgrid generating capacity is from variable
renewable resources that are greatly impacted by the environment and can be
intermittent as well as stochastic. This would result in uncertainty of
microgrid net-load, and negatively affect the grid reliability. A two-phase
real-time energy management strategy for networked microgrid is proposed in
this paper to address microgrid internal fluctuation internally, which enables
a microgrid to become grid-friendly. The proposed strategy is based on
coordination between the real-time dispatch (RTD) phase and the real-time
control (RTC) phase. In the RTD phase, model predictive control (MPC) is used
to optimally dispatch microgrid resources in the current time interval while
considering near future situations. The RTC phase addresses microgrid internal
net-load fluctuation with fast-acting batteries, which aims to maintain a
constant tie-line power flow between the main grid and the microgrid for the
current dispatch interval. Numerical simulations conducted on ten different
net-load scenarios can demonstrate the performance of the proposed two-phase
energy management strategy that will enable a microgrid to operate as a
controllable asset with static electricity consumption or production in an
economic dispatch interval from the perspective of the bulk grid operator.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:26:41 GMT""}]","2020-06-23"
"2006.11522","Mayra Samaniego Mrs","Mayra Samaniego, Sara Hosseinzadeh Kassani, Cristian Espana, Ralph
  Deters","Access Control Management for Computer-Aided Diagnosis Systems using
  Blockchain","5 pages, 7 figures, 1 table, 2020 IEEE International Conference on
  Smart Internet of Things (SmartIoT)",,,,"cs.CR cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computer-Aided Diagnosis (CAD) systems have emerged to support clinicians in
interpreting medical images. CAD systems are traditionally combined with
artificial intelligence (AI), computer vision, and data augmentation to
evaluate suspicious structures in medical images. This evaluation generates
vast amounts of data. Traditional CAD systems belong to a single institution
and handle data access management centrally. However, the advent of CAD systems
for research among multiple institutions demands distributed access management.
This research proposes a blockchain-based solution to enable distributed data
access management in CAD systems. This solution has been developed as a
distributed application (DApp) using Ethereum in a consortium network.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:42:20 GMT""}]","2020-06-23"
"2006.11523","Leo Liberti","Leo Liberti, Gabriele Iommazzo, Carlile Lavor, Nelson Maculan","Cycle-based formulations in Distance Geometry",,,,,"math.OC cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The distance geometry problem asks to find a realization of a given simple
edge-weighted graph in a Euclidean space of given dimension K, where the edges
are realized as straight segments of lengths equal (or as close as possible) to
the edge weights. The problem is often modelled as a mathematical programming
formulation involving decision variables that determine the position of the
vertices in the given Euclidean space. Solution algorithms are generally
constructed using local or global nonlinear optimization techniques. We present
a new modelling technique for this problem where, instead of deciding vertex
positions, formulations decide the length of the segments representing the
edges in each cycle in the graph, projected in every dimension. We propose an
exact formulation and a relaxation based on a Eulerian cycle. We then compare
computational results from protein conformation instances obtained with
stochastic global optimization techniques on the new cycle-based formulation
and on the existing edge-based formulation. While edge-based formulations take
less time to reach termination, cycle-based formulations are generally better
on solution quality measures.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:48:08 GMT""}]","2020-06-23"
"2006.11524","Saeed Amizadeh","Saeed Amizadeh, Hamid Palangi, Oleksandr Polozov, Yichen Huang,
  Kazuhito Koishida","Neuro-Symbolic Visual Reasoning: Disentangling ""Visual"" from ""Reasoning""","Published in Proceedings of the 37th International Conference on
  Machine Learning (ICML), Online, PMLR 119, 2020",,,,"cs.LG cs.AI cs.CV cs.NE cs.SC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual reasoning tasks such as visual question answering (VQA) require an
interplay of visual perception with reasoning about the question semantics
grounded in perception. However, recent advances in this area are still
primarily driven by perception improvements (e.g. scene graph generation)
rather than reasoning. Neuro-symbolic models such as Neural Module Networks
bring the benefits of compositional reasoning to VQA, but they are still
entangled with visual representation learning, and thus neural reasoning is
hard to improve and assess on its own. To address this, we propose (1) a
framework to isolate and evaluate the reasoning aspect of VQA separately from
its perception, and (2) a novel top-down calibration technique that allows the
model to answer reasoning questions even with imperfect perception. To this
end, we introduce a differentiable first-order logic formalism for VQA that
explicitly decouples question answering from visual perception. On the
challenging GQA dataset, this framework is used to perform in-depth,
disentangled comparisons between well-known VQA models leading to informative
insights regarding the participating models as well as the task.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:48:29 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 07:34:34 GMT""},{""version"":""v3"",""created"":""Tue, 25 Aug 2020 23:30:57 GMT""}]","2020-08-27"
"2006.11525","Juan Calderon Bustillo","Juan Calder\'on Bustillo, Samson H.W. Leong, Tim Dietrich, Paul D.
  Lasky","Mapping the Universe Expansion: Enabling percent-level measurements of
  the Hubble Constant with a single binary neutron-star merger detection","12 pages, 5 figures. Version accepted in The Astrophysical Journal
  Letters","The Astrophysical Journal Letters, Volume 912, Number 1 (2021)","10.3847/2041-8213/abf502","LIGO-P2000160","gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The joint observation of the gravitational-wave and electromagnetic signal
from the binary neutron-star merger GW170817 allowed for a new independent
measurement of the Hubble constant $H_0$, albeit with an uncertainty of about
15\% at 1$\sigma$. Observations of similar sources with a network of future
detectors will allow for more precise measurements of $H_0$. These, however,
are currently largely limited by the intrinsic degeneracy between the
luminosity distance and the inclination of the source in the gravitational-wave
signal. We show that the higher-order modes in gravitational waves can be used
to break this degeneracy in astrophysical parameter estimation in both the
inspiral and post-merger phases of a neutron star merger. We show that for
systems at distances similar to GW170817, this method enables percent-level
measurements of $H_0$ with a single detection. This would permit the study of
time variations and spatial anisotropies of $H_0$ with unprecedented precision.
We investigate how different network configurations affect measurements of
$H_0$, and discuss the implications in terms of science drivers for the
proposed 2.5- and third-generation gravitational-wave detectors. Finally, we
show that the precision of $H_0$ measured with these future observatories will
be solely limited by redshift measurements of electromagnetic counterparts.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:50:01 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 17:55:52 GMT""},{""version"":""v3"",""created"":""Sat, 8 May 2021 10:03:05 GMT""}]","2021-05-11"
"2006.11526","Tie Jun Wang Dr.","Yaoxiang Liu, Tie-Jun Wang, Hao Guo, Na Chen, Xuan Zhang, Haiyi Sun,
  See Leang Chin, Yuxin Leng, Ruxin Li, and Zhizhan Xu","Stable intense 1 kHz supercontinuum light generation in air",,,,,"physics.optics physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supercontinuum (SC) light source has advanced ultrafast laser spectroscopy in
condensed matter science, biology, physics, and chemistry. Compared to the
frequently used photonic crystal fibers and bulk materials, femtosecond laser
filamentation in gases is damage-immune for supercontinuum generation. A
bottleneck problem is the strong jitters from filament induced self-heating at
kHz repetition rate level. We demonstrate stable kHz supercontinuum generation
directly in air with multiple mJ level pulse energy. This is achieved by
applying an external DC electric field to the air plasma filament through the
effects of plasma wave guiding and Coulomb interaction. Both pointing and
intensity jitters of 1 kHz air filament induced SC light are reduced by more
than 2 fold. This offers the opportunities for stable intense SC generation and
other laser filament based applications in air.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:55:36 GMT""}]","2020-06-23"
"2006.11527","Mikhail Burtsev","Mikhail S. Burtsev, Yuri Kuratov, Anton Peganov, Grigory V. Sapunov","Memory Transformer",,,,,"cs.CL cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer-based models have achieved state-of-the-art results in many
natural language processing tasks. The self-attention architecture allows
transformer to combine information from all elements of a sequence into
context-aware representations. However, information about the context is stored
mostly in the same element-wise representations. This might limit the
processing of properties related to the sequence as a whole more difficult.
Adding trainable memory to selectively store local as well as global
representations of a sequence is a promising direction to improve the
Transformer model. Memory-augmented neural networks (MANNs) extend traditional
neural architectures with general-purpose memory for representations. MANNs
have demonstrated the capability to learn simple algorithms like Copy or
Reverse and can be successfully trained via backpropagation on diverse tasks
from question answering to language modeling outperforming RNNs and LSTMs of
comparable complexity. In this work, we propose and study few extensions of the
Transformer baseline (1) by adding memory tokens to store non-local
representations, (2) creating memory bottleneck for the global information, (3)
controlling memory update with dedicated layer. We evaluate these memory
augmented Transformers and demonstrate that presence of memory positively
correlates with the model performance for machine translation and language
modelling tasks. Augmentation of pre-trained masked language model with memory
tokens shows mixed results for tasks from GLUE benchmark. Visualization of
attention patterns over the memory suggest that it improves the model's ability
to process a global context.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 09:06:27 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 08:06:47 GMT""}]","2021-02-17"
"2006.11528","Jun-Jie Wei Dr.","Jun-Jie Wei, Xue-Feng Wu","Testing the Weak Equivalence Principle and Lorentz Invariance with
  Multiwavelength Polarization Observations of GRB Optical Afterglows","8 pages, 5 figures. Accepted by The European Physical Journal Plus",,,,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Violations of both the weak equivalence principle (WEP) and Lorentz
invariance can produce vacuum birefringence, which leads to an energy-dependent
rotation of the polarization vector of linearly polarized emission from a given
astrophysical source. However, the search for the birefringent effect has been
hindered by our ignorance concerning the intrinsic polarization angle in
different energy bands. Considering the contributions to the observed linear
polarization angle from both the intrinsic polarization angle and the rotation
angles induced by violations of the WEP and Lorentz invariance, and assuming
the intrinsic polarization angle is an unknown constant, we simultaneously
obtain robust bounds on possible deviations from the WEP and Lorentz
invariance, by directly fitting the multiwavelength polarimetric data of the
optical afterglows of gamma-ray burst (GRB) 020813 and GRB 021004. Here we show
that at the $3\sigma$ confidence level, the difference of the parameterized
post-Newtonian parameter $\gamma$ values characterizing the departure from the
WEP is constrained to be
$\Delta\gamma=\left(-4.5^{+10.0}_{-16.0}\right)\times10^{-24}$ and the
birefringent parameter $\eta$ quantifying the broken degree of Lorentz
invariance is limited to be
$\eta=\left(6.5^{+15.0}_{-14.0}\right)\times10^{-7}$. These are the first
simultaneous verifications of the WEP and Lorentz invariance in the photon
sector. More stringent limits can be expected as the analysis presented here is
applied to future multiwavelength polarization observations in the prompt
gamma-ray emission of GRB
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 09:10:59 GMT""}]","2020-06-23"
"2006.11529","Gencer Sumbul","Akshara Preethy Byju, Gencer Sumbul, Beg\""um Demir, Lorenzo Bruzzone","Remote Sensing Image Scene Classification with Deep Neural Networks in
  JPEG 2000 Compressed Domain","Accepted to IEEE Transactions on Geoscience and Remote Sensing",,"10.1109/TGRS.2020.3007523",,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To reduce the storage requirements, remote sensing (RS) images are usually
stored in compressed format. Existing scene classification approaches using
deep neural networks (DNNs) require to fully decompress the images, which is a
computationally demanding task in operational applications. To address this
issue, in this paper we propose a novel approach to achieve scene
classification in JPEG 2000 compressed RS images. The proposed approach
consists of two main steps: i) approximation of the finer resolution sub-bands
of reversible biorthogonal wavelet filters used in JPEG 2000; and ii)
characterization of the high-level semantic content of approximated wavelet
sub-bands and scene classification based on the learnt descriptors. This is
achieved by taking codestreams associated with the coarsest resolution wavelet
sub-band as input to approximate finer resolution sub-bands using a number of
transposed convolutional layers. Then, a series of convolutional layers models
the high-level semantic content of the approximated wavelet sub-band. Thus, the
proposed approach models the multiresolution paradigm given in the JPEG 2000
compression algorithm in an end-to-end trainable unified neural network. In the
classification stage, the proposed approach takes only the coarsest resolution
wavelet sub-bands as input, thereby reducing the time required to apply
decoding. Experimental results performed on two benchmark aerial image archives
demonstrate that the proposed approach significantly reduces the computational
time with similar classification accuracies when compared to traditional RS
scene classification approaches (which requires full image decompression).
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 09:13:38 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 17:23:15 GMT""}]","2020-12-16"
"2006.11530","Pyeongjae Park","Pyeongjae Park, Kisoo Park, Taehun Kim, Yusuke Kousaka, Ki Hoon Lee,
  T. G. Perring, Jaehong Jeong, Uwe Stuhr, Jun Akimitsu, Michel Kenzelmann, and
  Je-Geun Park","Momentum-dependent magnon lifetime in the metallic non-collinear
  triangular antiferromagnet CrB2","6 pages, 4 figures, accepted for publication in PRL",,"10.1103/PhysRevLett.125.027202",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-collinear magnetic order arises for various reasons in several magnetic
systems and exhibits interesting spin dynamics. Despite its ubiquitous
presence, little is known of how magnons, otherwise stable quasiparticles,
decay in these systems, particularly in metallic magnets. Using inelastic
neutron scattering, we examine the magnetic excitation spectra in a metallic
non-collinear antiferromagnet CrB$_{2}$, in which Cr atoms form a triangular
lattice and display incommensurate magnetic order. Our data show intrinsic
magnon damping and continuum-like excitations that cannot be explained by
linear spin wave theory. The intrinsic magnon linewidth $\Gamma(q,E_{q})$ shows
very unusual momentum dependence, which our analysis shows to originate from
the combination of two-magnon decay and the Stoner continuum. By comparing the
theoretical predictions with the experiments, we identify where in the momentum
and energy space one of the two factors becomes more dominant. Our work
constitutes a rare comprehensive study of the spin dynamics in metallic
non-collinear antiferromagnets. It reveals, for the first time, definite
experimental evidence of the higher-order effects in metallic antiferromagnets.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 09:21:52 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 06:07:10 GMT""}]","2020-08-26"
"2006.11531","Rico Zacher","Lukas Niebel and Rico Zacher","Kinetic maximal $L^2$-regularity for the (fractional) Kolmogorov
  equation","23 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the notion of kinetic maximal $L^2$-regularity with temporal
weights for the (fractional) Kolmogorov equation. In particular, we determine
the function spaces for the inhomogeneity and the initial value which
characterize the regularity of solutions to the fractional Kolmogorov equation
in terms of fractional anisotropic Sobolev spaces. It is shown that solutions
of the homogeneous (fractional) Kolmogorov equation define a semi-flow in a
suitable function space and the property of instantaneous regularization is
investigated.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 09:24:37 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 14:00:01 GMT""}]","2020-12-03"
"2006.11532","Keita Tokuda","Keita Tokuda and Naoya Fujiwara and Akihito Sudo and Yuichi Katori","Chaos may enhance expressivity in cerebellar granular layer",,"Neural Networks, Volume 136, April 2021, Pages 72-86","10.1016/j.neunet.2020.12.020",,"q-bio.NC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent evidence suggests that Golgi cells in the cerebellar granular layer
are densely connected to each other with massive gap junctions. Here, we
propose that the massive gap junctions between the Golgi cells contribute to
the representational complexity of the granular layer of the cerebellum by
inducing chaotic dynamics. We construct a model of cerebellar granular layer
with diffusion coupling through gap junctions between the Golgi cells, and
evaluate the representational capability of the network with the reservoir
computing framework. First, we show that the chaotic dynamics induced by
diffusion coupling results in complex output patterns containing a wide range
of frequency components. Second, the long non-recursive time series of the
reservoir represents the passage of time from an external input. These
properties of the reservoir enable mapping different spatial inputs into
different temporal patterns.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 09:46:28 GMT""}]","2021-01-14"
"2006.11533","Hansol Park Mr","Seung-Yeal Ha and Hansol Park","A dynamical systems approach for the shape matching of polytopes along
  rigid-body motions",,,,,"math-ph math.DS math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a dynamical systems approach for geometric matchings in an
ensemble of polytopes along rigid-body motions. Each polytope can be
characterized by a vertex set and edge or faces determined by vertices, and
polygons and simplexes correspond to a polytope. For a geometric matching, we
propose a system of dynamical system for the evolution of centroids and
rotations of polytopes to match the vertices under rigid-body motions which can
be decomposed as a composition of translation and rotations. Our proposed
dynamical system acts on the product space $({\mathbb R}^d \times SO(d))^N$.
The evolution of centroids can be described by the coupled linear second-order
dynamical system with diffusive linear couplings, whereas rotations for the
matching of vertices are described by the Lohe matrix model on $SO(d)^N$. In
particular, the Lohe matrix model has been derived from some set of physical
principles compared to previous works in which the Lohe matrix model were
employed as a system dynamics. This is a contrasted difference between earlier
works on the Lohe matrix model which has been adopted a priori for an aggregate
modeling of matrices. We also provide an analytical result leading to the
complete shape matchings for an ensemble of congruent polytopes, and several
numerical examples to illustrate analytical results visually.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 09:48:49 GMT""}]","2020-06-23"
"2006.11534","Hamid Zafar","Hamid Zafar, Mohnish Dubey, Jens Lehmann, Elena Demidova","IQA: Interactive Query Construction in Semantic Question Answering
  Systems",,"Journal of Web Semantics Volume 64, October 2020, 100586","10.1016/j.websem.2020.100586",,"cs.IR cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semantic Question Answering (SQA) systems automatically interpret user
questions expressed in a natural language in terms of semantic queries. This
process involves uncertainty, such that the resulting queries do not always
accurately match the user intent, especially for more complex and less common
questions. In this article, we aim to empower users in guiding SQA systems
towards the intended semantic queries through interaction. We introduce IQA -
an interaction scheme for SQA pipelines. This scheme facilitates seamless
integration of user feedback in the question answering process and relies on
Option Gain - a novel metric that enables efficient and intuitive user
interaction. Our evaluation shows that using the proposed scheme, even a small
number of user interactions can lead to significant improvements in the
performance of SQA systems.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:02:20 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 07:41:43 GMT""},{""version"":""v3"",""created"":""Thu, 25 Jun 2020 05:17:03 GMT""}]","2020-06-26"
"2006.11535","Nikolett N\'emet","Nikolett N\'emet, Scott Parkins, Victor Canela, Alexander Carmele","Feedback-induced instabilities and dynamics in the Jaynes-Cummings model",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the coherence and steady-state properties of the
Jaynes-Cummings model subjected to time-delayed coherent feedback in the regime
of multiple excitations. The introduced feedback qualitatively modifies the
dynamical response and steady-state quantum properties of the system by
enforcing a non-Markovian evolution. This leads to recovered collapses and
revivals as well as non-equilibrium steady states when the two-level system
(TLS) is directly driven by a laser. The latter are characterized by narrowed
spectral linewidth and diverging correlation functions that are robust against
the time delay and feedback phase choices. These effects are also demonstrated
in experimentally accessible quantities such as the power spectrum and the
second-order correlation function $g^{(2)}(\tau)$ in standard and widely
available photon-detection setups.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:07:01 GMT""}]","2020-06-23"
"2006.11536","Aravind Illa","Aravind Illa and Prasanta Kumar Ghosh","Speaker conditioned acoustic-to-articulatory inversion using x-vectors",,,,,"eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Speech production involves the movement of various articulators, including
tongue, jaw, and lips. Estimating the movement of the articulators from the
acoustics of speech is known as acoustic-to-articulatory inversion (AAI).
Recently, it has been shown that instead of training AAI in a speaker specific
manner, pooling the acoustic-articulatory data from multiple speakers is
beneficial. Further, additional conditioning with speaker specific information
by one-hot encoding at the input of AAI along with acoustic features benefits
the AAI performance in a closed-set speaker train and test condition. In this
work, we carry out an experimental study on the benefit of using x-vectors for
providing speaker specific information to condition AAI. Experiments with 30
speakers have shown that the AAI performance benefits from the use of x-vectors
in a closed set seen speaker condition. Further, x-vectors also generalizes
well for unseen speaker evaluation.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:08:06 GMT""}]","2020-06-23"
"2006.11537","Warit Asavanant","Warit Asavanant, Baramee Charoensombutamon, Shota Yokoyama, Takeru
  Ebihara, Tomohiro Nakamura, Rafael N. Alexander, Mamoru Endo, Jun-ichi
  Yoshikawa, Nicolas C. Menicucci, Hidehiro Yonezawa, and Akira Furusawa","One-hundred step measurement-based quantum computation multiplexed in
  the time domain with 25 MHz clock frequency","19 pages, 3 figures","Phys. Rev. Applied 16, 034005 (2021)","10.1103/PhysRevApplied.16.034005",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among various approaches toward quantum computation, measurement-based
quantum computation (MBQC) multiplexed in time domain is currently a promising
method for addressing the need for scalability. MBQC requires two components:
cluster states and programmable measurements. With time-domain multiplexing,
the former has been realized on an ultra-large-scale. The latter, however, has
remained unrealized, leaving the large-scale cluster states unused. In this
work, we make such a measurement system and use it to demonstrate basic quantum
operations multiplexed in the time domain with 25 MHz clock frequency. We
verify transformations of the input states and their nonclassicalities for
single-step quantum operations and also observe multi-step quantum operations
up to one hundred steps.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:12:30 GMT""}]","2021-09-06"
"2006.11538","Ionut Cosmin Duta","Ionut Cosmin Duta, Li Liu, Fan Zhu, Ling Shao","Pyramidal Convolution: Rethinking Convolutional Neural Networks for
  Visual Recognition",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work introduces pyramidal convolution (PyConv), which is capable of
processing the input at multiple filter scales. PyConv contains a pyramid of
kernels, where each level involves different types of filters with varying size
and depth, which are able to capture different levels of details in the scene.
On top of these improved recognition capabilities, PyConv is also efficient
and, with our formulation, it does not increase the computational cost and
parameters compared to standard convolution. Moreover, it is very flexible and
extensible, providing a large space of potential network architectures for
different applications. PyConv has the potential to impact nearly every
computer vision task and, in this work, we present different architectures
based on PyConv for four main tasks on visual recognition: image
classification, video action classification/recognition, object detection and
semantic image segmentation/parsing. Our approach shows significant
improvements over all these core tasks in comparison with the baselines. For
instance, on image recognition, our 50-layers network outperforms in terms of
recognition performance on ImageNet dataset its counterpart baseline ResNet
with 152 layers, while having 2.39 times less parameters, 2.52 times lower
computational complexity and more than 3 times less layers. On image
segmentation, our novel framework sets a new state-of-the-art on the
challenging ADE20K benchmark for scene parsing. Code is available at:
https://github.com/iduta/pyconv
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:19:29 GMT""}]","2020-06-23"
"2006.11539","Yijun Quan","Yijun Quan and Chang-Tsun Li","On Addressing the Impact of ISO Speed upon PRNU and Forgery Detection","The paper is accepted to IEEE Transactions on Information Forensics
  and Security with the supplementary material",,,,"cs.MM cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photo Response Non-Uniformity (PRNU) has been used as a powerful device
fingerprint for image forgery detection because image forgeries can be revealed
by finding the absence of the PRNU in the manipulated areas. The correlation
between an image's noise residual with the device's reference PRNU is often
compared with a decision threshold to check the existence of the PRNU. A PRNU
correlation predictor is usually used to determine this decision threshold
assuming the correlation is content-dependent. However, we found that not only
the correlation is content-dependent, but it also depends on the camera
sensitivity setting. \textit{Camera sensitivity}, commonly known by the name of
\textit{ISO speed}, is an important attribute in digital photography. In this
work, we will show the PRNU correlation's dependency on ISO speed. Due to such
dependency, we postulate that a correlation predictor is ISO speed-specific,
i.e. \textit{reliable correlation predictions can only be made when a
correlation predictor is trained with images of similar ISO speeds to the image
in question}. We report the experiments we conducted to validate the postulate.
It is realized that in the real-world, information about the ISO speed may not
be available in the metadata to facilitate the implementation of our postulate
in the correlation prediction process. We hence propose a method called
Content-based Inference of ISO Speeds (CINFISOS) to infer the ISO speed from
the image content.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:23:54 GMT""}]","2020-06-23"
"2006.11540","Johann Gehringer","Johann Gehringer and Xue-Mei Li","Functional limit theorems for the fractional Ornstein-Uhlenbeck process","To appear in the Journal of Theoretical Probability. arXiv admin
  note: text overlap with arXiv:1911.12600","J. of Theoretical Probaiblity 35 426-456 (2022)","10.1007/s10959-020-01044-7",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a functional limit theorem for vector-valued functionals of the
fractional Ornstein-Uhlenbeck process, providing the foundation for the
fluctuation theory of slow/fast systems driven by such a noise. Our main
contribution is on the joint convergence to a limit with both Gaussian and
non-Gaussian components. This is valid for any $L^2$ functions, whereas for
functions with stronger integrability properties the convergence is shown to
hold in the H\""older topology. As an application we prove a `rough creation'
result, i.e. the weak convergence of a family of random smooth curves to a
non-Markovian random process with rough sample paths. This includes the second
order problem and the kinetic fractional Brownian motion model.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:33:22 GMT""},{""version"":""v2"",""created"":""Sun, 4 Oct 2020 13:04:22 GMT""}]","2023-03-07"
"2006.11541","Andrea Loi","Andrea Loi, Fabio Zudda","Strictly regular and cscK metrics","8 pages, to appear in International Journal of Mathematics",,,,"math.DG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Kaehler metric $g$ with integral Kaehler form is said to be partially
regular if the partial Bergman kernel associated to mg is a positive constant
for all integer m sufficiently large. The aim of this paper is to prove that
for all n\geq 2 there exists an n-complex dimensional manifold equipped with
strictly partially regular and cscK metric g. Further, for n\geq 3, the
(constant) scalar curvature of g can be chosen to be zero, positive or
negative.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:35:33 GMT""}]","2020-06-23"
"2006.11542","Georgy Sambarov Evgenievich","Tatyana Yu. Galushina and Georgy E. Sambarov (Tomsk State University)","The dynamical evolution and the force model for asteroid (196256) 2003
  EH1",,"Planetary and Space Science 142 (2017) p.38","10.1016/j.pss.2017.04.019",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is devoted to the dynamics of asteroid (196256) 2003 EH1 that
belongs to the Amor group. It is known that the asteroid 2003 EH1 is associated
with one of the main annual meteor showers the Quadrantids. In this work we
analyze the influence of various perturbing factors on the asteroid motion. The
perturbations estimation was done by five different methods based on the
nominal orbit evolution and the size of the initial confidence region. The most
significant influences on the dynamical evolution of 2003 EH1 are gravitational
forces from the Sun, major planets and the Moon, and the relativistic effects
(RE) of the Sun. Of less importance are the Earth, the Sun and Jupiter
oblateness; gravitational perturbations from Pallas, Ceres, Vesta and Pluto;
and the RE of planets, the Moon, and Pluto. The researches of chaoticity and
evolution of asteroid 2003 EH1 were examined by integrating its motion
equations along with 500 clones. The time interval (from 1000 to 4000 years)
has been determined by integration precision estimation. We calculated the mean
exponential growth factor of nearby orbits (MEGNO) and found that MEGNO less
than two only in the interval from 1700 to 2300. After 2300 year the MEGNO
parameter increases that indicates motion instability. It shows that the orbit
may be considered as regular on the time interval of 300 years from now, and as
chaotic outside this interval. The reason, as we suppose, is frequent close
approaches of the asteroid with Jupiter and the overlap of apsidal nodal
resonances.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:38:48 GMT""}]","2020-06-23"
"2006.11543","Mpati Ramatsoku","M. Ramatsoku, P. Serra, B. M. Poggianti, A. Moretti, M. Gullieuszik,
  D. Bettoni, T. Deb, A. Franchetto, J. H. van Gorkom, Y. Jaff\'e, S. Tonnesen,
  M. A. W Verheijen, B. Vulcani, L. A. L. Andati, E. de Blok, G. I. G. J\'ozsa,
  P. Kamphuis, D. Kleiner, F. M. Maccagni, S. Makhathini, D. Cs. Moln\'ar, A.
  J. T. Ramaila, O. Smirnov, K. Thorat","GASP XXVI. HI Gas in Jellyfish Galaxies: The case of JO201 and JO206","9 pages, 8 figures, Accepted for publication in A&A",,"10.1051/0004-6361/202037759",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present HI observations of the jellyfish galaxy, JO201. This massive
galaxy (M$_{\ast} = 3.5 \times 10^{10}$ M$_\odot$) is falling along the
line-of-sight towards the centre of a rich cluster (M$_{200} \sim 1.6 \times
10^{15}$ M$_\odot$, $\sigma_{cl} \sim 982$ km/s) at a high velocity $\geq$3363
km/s. Its H$\alpha$ emission shows a $\sim$40 kpc tail confined closely to its
stellar disc and a $\sim$100 kpc tail extending further out. We find HI
emission coinciding only with the shorter clumpy H$\alpha$ tail. In total, we
measure an HI mass of M$_{\rm HI} = 1.65 \times 10^{9}$ M$_\odot$, which is
about 60% lower than expected based on its stellar mass and stellar surface
density. We compared JO201 to another jellyfish in the GASP sample, JO206 (of
similar mass but residing in a 10$\times$ less massive cluster), and find that
they are similarly HI-deficient. Of the total HI mass in JO201, about 30% lies
outside the galaxy disc in projection. This HI fraction is probably a lower
limit since most of the HI is redshifted relative to the stellar disc and could
be outside the disc. The global star formation rate (SFR) analysis of JO201
suggests that its observed SFR would be expected if it had 10$\times$ its
current HI mass. The disc is the main contributor of the high star formation
efficiency at a given HI gas density for both galaxies, but their tails also
show higher star formation efficiencies compared to the outer regions of field
galaxies. Generally, we find that JO201 and JO206 are similar based on their HI
content, stellar mass and star formation rate. This finding is unexpected
considering their different environments. A toy model comparing the ram
pressure of the ICM versus the restoring forces of these galaxies suggests that
the ram pressure strength exerted on them could be comparable if we consider
their 3D orbital velocities and radial distances relative to the clusters.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:39:17 GMT""}]","2020-08-12"
"2006.11544","Johann Gehringer","Johann Gehringer and Xue-Mei Li","Diffusive and rough homogenisation in fractional noise field","This is the revised second part of arXiv:1911.12600",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With recently developed tools, we prove a homogenisation theorem for a random
ODE with short and long-range dependent fractional noise. The effective
dynamics are not necessarily diffusions, they are given by stochastic
differential equations driven simultaneously by stochastic processes from both
the Gaussian and the non-Gaussian self-similarity universality classes. A key
lemma for this is the `lifted' joint functional central and non-central limit
theorem in the rough path topology.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:49:47 GMT""}]","2020-06-23"
"2006.11545","Haruka Suzuki","Haruka Suzuki, Priti Gupta, Hirotada Okawa and Kei-ichi Maeda","Post-Newtonian Kozai-Lidov Mechanism and its Effect on Cumulative Shift
  of Periastron Time of Binary Pulsar","22 pages, 24 figures, published by MNRAS","Monthly Notices of the Royal Astronomical Society, Volume 500,
  Issue 2, p.1645-1665 January 2021","10.1093/mnras/staa3081",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Kozai-Lidov mechanism in a hierarchical triple system in detail
by the direct integration of the first-order post Newtonian equations of
motion. We analyse a variety of models with a pulsar to evaluate the cumulative
shift of the periastron time of a binary pulsar caused by the gravitational
wave emission in a hierarchical triple system with Kozai-Lidov mechanism. We
compare our results with those by the double-averaging method. The deviation in
the eccentricity, even if small, is important in the evaluation of the emission
of the gravitational waves. We also calculate the cumulative shift of the
periastron time by using obtained osculating orbital elements. If Kozai-Lidov
oscillations occur, the cumulative shift curve will bend differently from that
of the isolated binary. If such a bending is detected through the radio
observation, it will be the first indirect observation of gravitational waves
from a triple system.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 10:55:23 GMT""},{""version"":""v2"",""created"":""Thu, 5 Nov 2020 06:06:47 GMT""}]","2020-12-15"
"2006.11546","Sharly Fleischer","Daniel Krotkov, Eli Flaxer and Sharly Fleischer","Enhanced spatial resolution of Terahertz spectroscopy via semiconductor
  photoexcitation","10 pages, 11 figures",,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We utilize the photoexcitation of a semiconductor material as a 'reflectivity
switch' for a broadband terahertz field. We show that judicious use of this
switch enables temporal characterization of the THz field with spatial
resolution significantly surpassing the diffraction limit of the terahertz and
provides desirable means for spatio-temporal terahertz spectroscopy.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:02:17 GMT""}]","2020-06-23"
"2006.11547","Pascal Kerschke","Lennart Sch\""apermeier and Christian Grimme and Pascal Kerschke","One PLOT to Show Them All: Visualization of Efficient Sets in
  Multi-Objective Landscapes","This version has been accepted for publication at the 16th
  International Conference on Parallel Problem Solving from Nature (PPSN XVI)","Proceedings of the 16th International Conference on Parallel
  Problem Solving from Nature (PPSN XVI), pp. 154 - 167, Springer (2020)","10.1007/978-3-030-58115-2_11",,"cs.NE cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visualization techniques for the decision space of continuous multi-objective
optimization problems (MOPs) are rather scarce in research. For long, all
techniques focused on global optimality and even for the few available
landscape visualizations, e.g., cost landscapes, globality is the main
criterion. In contrast, the recently proposed gradient field heatmaps (GFHs)
emphasize the location and attraction basins of local efficient sets, but
ignore the relation of sets in terms of solution quality.
  In this paper, we propose a new and hybrid visualization technique, which
combines the advantages of both approaches in order to represent local and
global optimality together within a single visualization. Therefore, we build
on the GFH approach but apply a new technique for approximating the location of
locally efficient points and using the divergence of the multi-objective
gradient vector field as a robust second-order condition. Then, the relative
dominance relationship of the determined locally efficient points is used to
visualize the complete landscape of the MOP. Augmented by information on the
basins of attraction, this Plot of Landscapes with Optimal Trade-offs (PLOT)
becomes one of the most informative multi-objective landscape visualization
techniques available.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:03:11 GMT""}]","2020-12-01"
"2006.11548","Diego Alexander Huerfano Villalba","Diego Alexander Hu\'erfano Villalba and Elizabeth Le\'on Guzm\'an","Named Entity Extraction with Finite State Transducers",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a named entity tagging system that requires minimal linguistic
knowledge and can be applied to more target languages without substantial
changes. The system is based on the ideas of the Brill's tagger which makes it
really simple. Using supervised machine learning, we construct a series of
automatons (or transducers) in order to tag a given text. The final model is
composed entirely of automatons and it requires a lineal time for tagging. It
was tested with the Spanish data set provided in the CoNLL-$2002$ attaining an
overall $F_{\beta = 1}$ measure of $60\%.$ Also, we present an algorithm for
the construction of the final transducer used to encode all the learned
contextual rules.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:09:04 GMT""}]","2020-06-23"
"2006.11549","Saptarshi Mandal","Saptarshi Mandal and Arun M Jayannavar","An introduction to Kitaev model-I","17 pages, 17 figures",,,,"cond-mat.str-el cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This pedagogical article is aimed to the beginning graduate students
interested in broad field of frustrated magnetism. We introduce and present
some of the exact results obtained in Kitaev model. The Kitaev model embodies
an unusual two spin interactions yet exactly solvable model in two dimension.
This exact solvability renders it to realize many emergent many body phenomena
such as $Z_2$ gauge field, spin liquid states, spin fractionalization,
topological order exactly. First we present the exact solution of Kitaev model
using Majorana fermionisation and elaborate in detail the $Z_2$ gauge
structure. Following this we discuss exact calculation of magnetization,
spin-spin correlation function establishing its spin-liquid character. Spin
fractionalization and de-confinement of Majorana fermion is explained in
detail. Existence of long range multi-spin correlation function and topological
degeneracy are discussed to elucidate the entangled and topological nature of
any eigenstate. Some elementary questionnaires are provided in appropriate
places for assimilation of the technical details.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:21:25 GMT""}]","2020-06-23"
"2006.11550","Alban Poth\'erat","Alban Poth\'erat, Jo\""el Sommeria and Ren\'e Moreau","Numerical simulations of an effective two-dimensional model for flows
  with a transverse magnetic field",,"J.Fluid Mech., 534, 115-143 (2005)","10.1017/S0022112005004350",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents simulations of the 2d model developed by Poth\'erat at al
(\emph{J. Fluid Mech}, 2000) for MHD flows between two planes with a strong
transverse homogeneous and steady magnetic field, accounting for moderate
inertial effects in Hartmann layers. We first show analytically how the
additional terms in the equations of motion accounting for inertia, soften
velocity gradients in the horizontal plane, and then we implement the model on
a code to carry out numerical simulations to be compared with available
experimental results. This comparison shows that the new model can give very
accurate results as long as the Hartmann layer remains laminar. Both
experimental velocity profiles and global angular momentum measurements are
closely recovered, and local and global Ekman recirculations are shown to alter
significantly the aspect of the flow as well as the global dissipation.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:23:13 GMT""}]","2020-06-23"
"2006.11551","Yuri Gornostyrev","Yu. N. Gornostyrev and M.I. Katsnelson","Origin of the vortex displacement field in twisted bilayer graphene","6 pages, 5 figures","Phys. Rev. B 102, 085428 (2020)","10.1103/PhysRevB.102.085428",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model description of patterns of atomic displacements in twisted bilayer
systems has been proposed. The model is based on the consideration of several
dislocation ensembles, employing a language that is widely used for grain
boundaries and film/substrate systems. We show that three ensembles of parallel
screw dislocations are sufficient both to describe the rotation of the layers
as a whole, and for the vortex-like displacements resulting from elastic
relaxation. The results give a clear explanation of the observed features of
the structural state such as vortices, accompanied by alternating stacking.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:23:38 GMT""}]","2020-09-02"
"2006.11552","Oleg Zaslavskii","O. B. Zaslavskii","Special case of the Ba\~{n}ados-Silk-West effect","12 pages. Matches published version","Phys. Rev. D 102, 044051 (2020)","10.1103/PhysRevD.102.044051",,"gr-qc astro-ph.HE hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If two particles collide near the rotating extremal black hole and one of
them is fine-tuned, the energy in the center of mass frame $E_{c.m.}$ can grow
unbounded. This is the so-called Ba\~{n}ados-Silk-West (BSW) effect. Recently,
another type of high energy collisions was considered in which all processes
happen in the Schwarzschild background with free falling particles. If the
Killing energy $E$ of one of particle is sufficiently small, $E_{c.m.}$ grows
unbounded. We show that, however, such a particle cannot be created in any
precedent collision with finite energies, angular momenta and masses.
Therefore, in contrast to the standard BSW effect, this one cannot be realized
if initial particles fall from infinity. If the black hole is electrically
charged, such a type of collisions is indeed possible, when a particle with
very small $E$ collides with one more particle coming from infinity. Thus the
BSW effect is achieved due to collisions of neutral particles in the background
of a charged black hole. This requires, however, at least two-step process.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:31:17 GMT""},{""version"":""v2"",""created"":""Thu, 6 Aug 2020 14:40:21 GMT""},{""version"":""v3"",""created"":""Thu, 27 Aug 2020 19:56:29 GMT""}]","2020-09-02"
"2006.11553","Panagiotis Tolias","F. Lucco Castello and P. Tolias","On the advanced integral equation theory description of dense Yukawa
  one-component plasma liquids","13 pages, 5 figures, 29 pages of supplementary material","Contrib. Plasma Phys. 61, e202000105 (2021)","10.1002/ctpp.202000105",,"cond-mat.soft physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Different advanced bridge function closures are utilized to investigate the
structural and thermodynamic properties of dense Yukawa one-component plasma
liquids within the framework of integral equation theory. The isomorph-based
empirically modified hypernetted-chain, the variational modified
hypernetted-chain, the Rogers-Young and the Ballone-Pastore-Galli-Gazzillo
approaches are compared at the level of thermodynamic properties, radial
distribution functions and bridge functions. The comparison, based on accuracy
and computational speed, concludes that the two modified hypernetted-chain
approaches are superior and singles out the isomorph-based variant as the most
promising alternative to computer simulations of structural properties of dense
Yukawa liquids. The possibility of further improvement through artificial
cross-over to exact asymptotic limits is studied.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:33:48 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jul 2020 15:32:02 GMT""}]","2021-01-21"
"2006.11554","Sergey Zagorodnyuk","Sergey M. Zagorodnyuk","On some Sobolev spaces with matrix weights and classical type Sobolev
  orthogonal polynomials","28 pages",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For every system $\{ p_n(z) \}_{n=0}^\infty$ of OPRL or OPUC, we construct
Sobolev orthogonal polynomials $y_n(z)$, with explicit integral representations
involving $p_n$. Two concrete families of Sobolev orthogonal polynomials
(depending on an arbitrary number of complex parameters) which are generalized
eigenvalues of a difference operator (in $n$) and generalized eigenvalues of a
differential operator (in $n$) are given. Applications of a general connection
between Sobolev orthogonal polynomials and orthogonal systems of functions in
the direct sum of scalar $L^2_\mu$ spaces are discussed.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:37:52 GMT""},{""version"":""v2"",""created"":""Wed, 9 Sep 2020 20:46:23 GMT""}]","2020-09-11"
"2006.11555","Syed Kabir","Syed Kabir (1 and 2), Sandhya Patidar (2), Xilin Xia (1), Qiuhua Liang
  (1), Jeffrey Neal (3) and Gareth Pender (2). ((1) School of Architecture,
  Building and Civil Engineering, Loughborough University, Loughborough, United
  Kingdom. (2) School of Energy, Geoscience, Infrastructure and Society,
  Heriot-Watt University, Edinburgh, United Kingdom. (3) School of Geographical
  Sciences, University of Bristol, Bristol, United Kingdom)","A deep convolutional neural network model for rapid prediction of
  fluvial flood inundation","45 pages, 14 figures, 7 tables","J. Hydrol. 125481 (2020)","10.1016/j.jhydrol.2020.125481",,"cs.LG eess.SP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most of the two-dimensional (2D) hydraulic/hydrodynamic models are still
computationally too demanding for real-time applications. In this paper, an
innovative modelling approach based on a deep convolutional neural network
(CNN) method is presented for rapid prediction of fluvial flood inundation. The
CNN model is trained using outputs from a 2D hydraulic model (i.e. LISFLOOD-FP)
to predict water depths. The pre-trained model is then applied to simulate the
January 2005 and December 2015 floods in Carlisle, UK. The CNN predictions are
compared favourably with the outputs produced by LISFLOOD-FP. The performance
of the CNN model is further confirmed by benchmarking against a support vector
regression (SVR) method. The results show that the CNN model outperforms SVR by
a large margin. The CNN model is highly accurate in capturing flooded cells as
indicated by several quantitative assessment matrices. The estimated error for
reproducing maximum flood depth is 0 ~ 0.2 meters for the 2005 event and 0 ~
0.5 meters for the 2015 event at over 99% of the cells covering the
computational domain. The proposed CNN method offers great potential for
real-time flood modelling/forecasting considering its simplicity, superior
performance and computational efficiency.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:37:54 GMT""},{""version"":""v2"",""created"":""Wed, 16 Sep 2020 12:17:29 GMT""}]","2020-09-17"
"2006.11556","Anton Zasedatelev Dr","A. Putintsev, A. Zasedatelev, K. E. McGhee, T. Cookson, K. Georgiou,
  D. Sannikov, D. G. Lidzey, P. G. Lagoudakis","Nano-second exciton-polariton lasing in organic microcavities",,,"10.1063/5.0019195",,"physics.app-ph cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Organic semiconductors are a promising platform for ambient polaritonics.
Several applications, such as polariton routers, and many-body condensed matter
phenomena are currently hindered due to the ultra-short polariton lifetimes in
organics. Here, we employ a single-shot dispersion imaging technique, using 4
nanosecond long non-resonant excitation pulses, to study polariton lasing in a
$\lambda/2$ planar organic microcavity filled with BODIPY-Br dye molecules. At
a power threshold density of $1.5 MW/cm^{2}$, we observe the transition to a
quasi-steady state, 1.2 ns long-lived, single-mode polariton lasing and the
concomitant superlinear increase of photoluminescence, spectral line-narrowing,
and energy blueshift
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:53:31 GMT""}]","2020-10-28"
"2006.11557","Yao Rong","Yao Rong, Zeynep Akata, Enkelejda Kasneci","Driver Intention Anticipation Based on In-Cabin and Driving Scene
  Monitoring","8 pages, 9 figures","IEEE Conference on Intelligent Transportation Systems (ITSC), 2020",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Numerous car accidents are caused by improper driving maneuvers. Serious
injuries are however avoidable if such driving maneuvers are detected
beforehand and the driver is assisted accordingly. In fact, various recent
research has focused on the automated prediction of driving maneuver based on
hand-crafted features extracted mainly from in-cabin driver videos. Since the
outside view from the traffic scene may also contain informative features for
driving maneuver prediction, we present a framework for the detection of the
drivers' intention based on both in-cabin and traffic scene videos. More
specifically, we (1) propose a Convolutional-LSTM (ConvLSTM)-based auto-encoder
to extract motion features from the out-cabin traffic, (2) train a classifier
which considers motions from both in- and outside of the cabin jointly for
maneuver intention anticipation, (3) experimentally prove that the in- and
outside image features have complementary information. Our evaluation based on
the publicly available dataset Brain4cars shows that our framework achieves a
prediction with the accuracy of 83.98% and F1-score of 84.3%.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:56:32 GMT""}]","2020-06-24"
"2006.11558","Thoudam Doren Singh","Thoudam Doren Singh, Abdullah Faiz Ur Rahman Khilji, Divyansha,
  Apoorva Vikram Singh, Surmila Thokchom and Sivaji Bandyopadhyay","Seq2Seq and Joint Learning Based Unix Command Line Prediction System","9 pages, 1 Figure",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite being an open-source operating system pioneered in the early 90s,
UNIX based platforms have not been able to garner an overwhelming reception
from amateur end users. One of the rationales for under popularity of UNIX
based systems is the steep learning curve corresponding to them due to
extensive use of command line interface instead of usual interactive graphical
user interface. In past years, the majority of insights used to explore the
concern are eminently centered around the notion of utilizing chronic log
history of the user to make the prediction of successive command. The
approaches directed at anatomization of this notion are predominantly in
accordance with Probabilistic inference models. The techniques employed in
past, however, have not been competent enough to address the predicament as
legitimately as anticipated. Instead of deploying usual mechanism of
recommendation systems, we have employed a simple yet novel approach of Seq2seq
model by leveraging continuous representations of self-curated exhaustive
Knowledge Base (KB) to enhance the embedding employed in the model. This work
describes an assistive, adaptive and dynamic way of enhancing UNIX command line
prediction systems. Experimental methods state that our model has achieved
accuracy surpassing mixture of other techniques and adaptive command line
interface mechanism as acclaimed in the past.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:57:01 GMT""}]","2020-06-23"
"2006.11559","Jan Dvorak","Jan Dvo\v{r}\'ak, Zden\v{e}k Hanz\'alek","Multi-Variant Time Constrained FlexRay Static Segment Scheduling",,,"10.1109/WFCS.2014.6837576",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The FlexRay bus is a modern standard used in the automotive industry.It
offers deterministic message transmission with zero jitter while using
time-triggered scheduling in the static segment. When several vehicle variants
(i.e. different models and their versions) share the same signal, the car
manufacturers require to schedule such signal at the same time in all vehicle
variants. This requirement simplifies the signal traceability and diagnostics
in different vehicle variants using the same platform and simplifies reuse of
components and tools.
  In this paper, we propose a first fit based heuristic algorithm which creates
the schedules for several vehicle variants at once, while transmitting a given
signal at the same time in all the schedules. The scheduling algorithm also
takes the time constraints as release dates and deadlines into account.
Finally, different algorithm versions are compared on benchmark sets and low
computational time demands are validated on large instances.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:08:00 GMT""}]","2020-06-23"
"2006.11560","Helge Spieker","Helge Spieker, Arnaud Gotlieb","Learning Objective Boundaries for Constraint Optimization Problems","The 6th International Conference on machine Learning, Optimization
  and Data science - LOD 2020","In: Nicosia G. et al. (eds) Machine Learning, Optimization, and
  Data Science. LOD 2020. Lecture Notes in Computer Science, vol 12566.
  Springer, Cham","10.1007/978-3-030-64580-9_33",,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Constraint Optimization Problems (COP) are often considered without
sufficient knowledge on the boundaries of the objective variable to optimize.
When available, tight boundaries are helpful to prune the search space or
estimate problem characteristics. Finding close boundaries, that correctly
under- and overestimate the optimum, is almost impossible without actually
solving the COP. This paper introduces Bion, a novel approach for boundary
estimation by learning from previously solved instances of the COP. Based on
supervised machine learning, Bion is problem-specific and solver-independent
and can be applied to any COP which is repeatedly solved with different data
inputs. An experimental evaluation over seven realistic COPs shows that an
estimation model can be trained to prune the objective variables' domains by
over 80%. By evaluating the estimated boundaries with various COP solvers, we
find that Bion improves the solving process for some problems, although the
effect of closer bounds is generally problem-dependent.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:09:49 GMT""}]","2022-03-23"
"2006.11561","Aviv Rosenberg","Aviv Rosenberg and Yishay Mansour","Stochastic Shortest Path with Adversarially Changing Costs",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic shortest path (SSP) is a well-known problem in planning and
control, in which an agent has to reach a goal state in minimum total expected
cost. In this paper we present the adversarial SSP model that also accounts for
adversarial changes in the costs over time, while the underlying transition
function remains unchanged. Formally, an agent interacts with an SSP
environment for $K$ episodes, the cost function changes arbitrarily between
episodes, and the transitions are unknown to the agent. We develop the first
algorithms for adversarial SSPs and prove high probability regret bounds of
$\widetilde O (\sqrt{K})$ assuming all costs are strictly positive, and
$\widetilde O (K^{3/4})$ in the general case. We are the first to consider this
natural setting of adversarial SSP and obtain sub-linear regret for it.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:10:35 GMT""},{""version"":""v2"",""created"":""Thu, 5 Nov 2020 13:19:00 GMT""},{""version"":""v3"",""created"":""Thu, 29 Apr 2021 14:15:34 GMT""},{""version"":""v4"",""created"":""Tue, 5 Apr 2022 10:29:29 GMT""}]","2022-04-06"
"2006.11564","Anastasia Vasil'eva","A.A. Vasil'eva","Linear widths of weighted Sobolev classes with conditions on the highest
  order and zero derivatives",,,"10.1134/S1061920820040135",,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper order estimates for the linear widths of some function classes
are obtained; these classes are defined by restrictions on the weighted
$L_{p_1}$-norm of the r-th derivative and the weighted $L_{p_0}$-norm of zero
derivative.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:33:17 GMT""}]","2021-02-03"
"2006.11565","Victor Zubkov","V.V. Zubkov and A.V. Zubkova","Irreversibility in classical kinetic theory: retardation of interaction
  and distribution functions","12 pages",,,,"cond-mat.stat-mech cond-mat.soft physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A kinetic equation is derived for the phase density of a system of point
particles, generating a system of integro-differential equations for
distribution functions that have a deterministic meaning. The derivation took
into account the retardation of interactions between particles. The obtained
equations describe the irreversible behavior of a system of particles without
involving any probabilistic hypotheses. The use of the retarded potentials, in
this case, corresponds to taking the field into account when the dynamics of
the many-particle system is described.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:41:06 GMT""}]","2020-06-23"
"2006.11566","Tianqi Xiang","Tianqi Xiang, Yaxin Wang, Huiwen Li, Boren Guo, Xin Zhang","A Computer Vision Based Beamforming Scheme for Millimeter Wave
  Communication in LOS Scenarios","7 pages, 10 figures","2019 IEEE 7th International Conference on Computer Science and
  Network Technology (ICCSNT), Dalian, China, 2019, pp. 401-407","10.1109/ICCSNT47585.2019.8962465",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A novel location-aware beamforming scheme for millimeter wave communication
is proposed for line of sight (LOS) and low mobility scenarios, in which
computer vision is introduced to derive the required position or spatial
angular information from the image or video captured by camera(s) co-located
with mmWave antenna array at base stations. A wireless coverage model is built
to investigate the coverage performance and influence of positioning accuracy
achieved by convolutional neural network (CNN) for image processing. In
addition, videos could be intentionally blurred, or even low-resolution videos
could be directly applied, to protect users' privacy with acceptable
positioning precision, lower computation complexity and lower camera cost. It
is proved by simulations that the beamforming scheme is practicable and the
mainstream CNN we employed is sufficient in both aspects of beam directivity
accuracy and processing speed in frame per second.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:53:25 GMT""}]","2020-06-23"
"2006.11567","Maximilian Mertin","Martin Grothaus and Maximilian Mertin","Hypocoercivity of Langevin-type dynamics on abstract smooth manifolds","46 pages, 0 figures, 2 comm. diagrams",,,,"math.PR math.FA","http://creativecommons.org/licenses/by/4.0/","  In this article we investigate hypocoercivity of Langevin-type dynamics in
nonlinear smooth geometries. The main result stating exponential decay to an
equilibrium state with explicitly computable rate of convergence is rooted in
an appealing Hilbert space strategy by Dolbeault, Mouhot and Schmeiser. This
strategy was extended in [GS14] to Kolmogorov backward evolution equations in
contrast to the dual Fokker-Planck framework. We use this mathematically
complete elaboration to investigate wide ranging classes of Langevin-type SDEs
in an abstract manifold setting, i.e. (at least) the position variables obey
certain smooth side conditions. Such equations occur e.g. as fibre lay-down
processes in industrial applications. We contribute the Lagrangian-type
formulation of such geometric Langevin dynamics in terms of (semi-)sprays and
point to the necessity of fibre bundle measure spaces to specify the model
Hilbert space.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:58:38 GMT""}]","2020-06-23"
"2006.11568","Leandro Martin Del Pezzo","Leandro M. Del Pezzo, Nicolas Frevenza and Julio D. Rossi","Quasiconvex functions on regular trees","19 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a definition of a quasiconvex function on an infinite directed
regular tree that depends on what we understood by a segment on the tree. Our
definition is based on thinking on segments as sub-trees with the root as the
midpoint of the segment. A convex set in the tree is then a subset such that it
contains every midpoint of every segment with terminal nodes in the set. Then a
quasiconvex function is a real map on the tree such that every level set is a
convex set. For this concept of quasiconvex functions on a tree, we show that
given a continuous boundary datum there exists a unique quasiconvex envelope on
the tree and we characterize the equation that this envelope satisfies. It
turns out that this equation is a mean value property that involves a median
among values of the function on successors of a given vertex. We also relate
the quasiconvex envelope of a function defined inside the tree with the
solution of an obstacle problem for this characteristic equation.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:59:40 GMT""}]","2020-06-23"
"2006.11569","Haiping Huang","Jianwen Zhou, and Haiping Huang","Weakly-correlated synapses promote dimension reduction in deep neural
  networks","21 pages, 8 figures","Phys. Rev. E 103, 012315 (2021)","10.1103/PhysRevE.103.012315",,"cs.LG cond-mat.dis-nn cond-mat.stat-mech q-bio.NC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By controlling synaptic and neural correlations, deep learning has achieved
empirical successes in improving classification performances. How synaptic
correlations affect neural correlations to produce disentangled hidden
representations remains elusive. Here we propose a simplified model of
dimension reduction, taking into account pairwise correlations among synapses,
to reveal the mechanism underlying how the synaptic correlations affect
dimension reduction. Our theory determines the synaptic-correlation scaling
form requiring only mathematical self-consistency, for both binary and
continuous synapses. The theory also predicts that weakly-correlated synapses
encourage dimension reduction compared to their orthogonal counterparts. In
addition, these synapses slow down the decorrelation process along the network
depth. These two computational roles are explained by the proposed mean-field
equation. The theoretical predictions are in excellent agreement with numerical
simulations, and the key features are also captured by a deep learning with
Hebbian rules.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:11:37 GMT""}]","2021-02-02"
"2006.11570","Liubov Tupikina","Liubov Tupikina","Continuous limits of Heterogeneous Continuous Time Random Walk model","This is the current version of the article. We are still working on
  it and plan to submit the edited version later. 2 figures, 9 pages",,,,"cond-mat.stat-mech physics.data-an stat.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous time random Walk model has been versatile analytical formalism for
studying and modeling diffusion processes in heterogeneous structures, such as
disordered or porous media.
  We are studying the continuous limits of Heterogeneous Continuous Time Random
Walk model, when a random walk is making jumps on a graph within different
time-length.
  We apply the concept of a generalized master equation to study heterogeneous
continuous-time random walks on networks.
  Depending on the interpretations of the waiting time distributions the
generalized master equation gives different forms of continuous equations.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:14:21 GMT""}]","2020-06-23"
"2006.11571","Maxim Tkachuk","M.V. Tkachuk","On fiber linear convexity","10 pages, in Ukrainian, 6 figures",,,,"math.GT math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The boundary of fiber linear convex bounded domain with smooth boundary is a
cohomological sphere.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:18:08 GMT""}]","2020-06-23"
"2006.11572","Ekaterina Vylomova","Ekaterina Vylomova, Jennifer White, Elizabeth Salesky, Sabrina J.
  Mielke, Shijie Wu, Edoardo Ponti, Rowan Hall Maudslay, Ran Zmigrod, Josef
  Valvoda, Svetlana Toldova, Francis Tyers, Elena Klyachko, Ilya Yegorov,
  Natalia Krizhanovsky, Paula Czarnowska, Irene Nikkarinen, Andrew
  Krizhanovsky, Tiago Pimentel, Lucas Torroba Hennigen, Christo Kirov, Garrett
  Nicolai, Adina Williams, Antonios Anastasopoulos, Hilaria Cruz, Eleanor
  Chodroff, Ryan Cotterell, Miikka Silfverberg, Mans Hulden","SIGMORPHON 2020 Shared Task 0: Typologically Diverse Morphological
  Inflection","39 pages, SIGMORPHON",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  A broad goal in natural language processing (NLP) is to develop a system that
has the capacity to process any natural language. Most systems, however, are
developed using data from just one language such as English. The SIGMORPHON
2020 shared task on morphological reinflection aims to investigate systems'
ability to generalize across typologically distinct languages, many of which
are low resource. Systems were developed using data from 45 languages and just
5 language families, fine-tuned with data from an additional 45 languages and
10 language families (13 in total), and evaluated on all 90 languages. A total
of 22 systems (19 neural) from 10 teams were submitted to the task. All four
winning systems were neural (two monolingual transformers and two massively
multilingual RNN-based models with gated attention). Most teams demonstrate
utility of data hallucination and augmentation, ensembles, and multilingual
training for low-resource languages. Non-neural learners and manually designed
grammars showed competitive and even superior performance on some languages
(such as Ingrian, Tajik, Tagalog, Zarma, Lingala), especially with very limited
data. Some language families (Afro-Asiatic, Niger-Congo, Turkic) were
relatively easy for most systems and achieved over 90% mean accuracy while
others were more challenging.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:24:14 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 11:17:11 GMT""}]","2020-07-15"
"2006.11573","Othmane Sebbouh","Ahmed Khaled, Othmane Sebbouh, Nicolas Loizou, Robert M. Gower, Peter
  Richt\'arik","Unified Analysis of Stochastic Gradient Methods for Composite Convex and
  Smooth Optimization",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a unified theorem for the convergence analysis of stochastic
gradient algorithms for minimizing a smooth and convex loss plus a convex
regularizer. We do this by extending the unified analysis of Gorbunov, Hanzely
\& Richt\'arik (2020) and dropping the requirement that the loss function be
strongly convex. Instead, we only rely on convexity of the loss function. Our
unified analysis applies to a host of existing algorithms such as proximal SGD,
variance reduced methods, quantization and some coordinate descent type
methods. For the variance reduced methods, we recover the best known
convergence rates as special cases. For proximal SGD, the quantization and
coordinate type methods, we uncover new state-of-the-art convergence rates. Our
analysis also includes any form of sampling and minibatching. As such, we are
able to determine the minibatch size that optimizes the total complexity of
variance reduced methods. We showcase this by obtaining a simple formula for
the optimal minibatch size of two variance reduced methods (\textit{L-SVRG} and
\textit{SAGA}). This optimal minibatch size not only improves the theoretical
total complexity of the methods but also improves their convergence in
practice, as we show in several experiments.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:40:27 GMT""}]","2020-06-23"
"2006.11574","Sumiyoshi Abe","Sumiyoshi Abe","Fokker-Planck approach to non-Gaussian normal diffusion: Hierarchical
  dynamics for diffusing diffusivity","19 pages, no figures. Title slightly changed","Phys. Rev. E 102, 042136 (2020)","10.1103/PhysRevE.102.042136",,"cond-mat.stat-mech physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A theoretical framework is developed for the phenomenon of non-Gaussian
normal diffusion that has experimentally been observed in several heterogeneous
systems. From the Fokker-Planck equation with the dynamical structure with
largely separated time scales, a set of three equations are derived for the
fast degree of freedom, the slow degree of freedom and the coupling between
these two hierarchies. It is shown that this approach consistently describes
""diffusing diffusivity"" and non-Gaussian normal diffusion.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:47:24 GMT""},{""version"":""v2"",""created"":""Wed, 28 Oct 2020 15:26:03 GMT""}]","2020-11-04"
"2006.11575","S. N Sajadi","S. H. Hendi, S. N. Sajadi, Maryam. Khademi","Physical Properties of a Regular Rotating Black Hole: Thermodynamics,
  Stability, Quasinormal Modes","19 pages, 14 figures","Phys. Rev. D 103, 064016 (2021)","10.1103/PhysRevD.103.064016",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Respecting the angular momentum conservation of torque-free systems, it is
natural to consider rotating solutions of massive objects. Besides that,
motivated by the realistic astrophysical black holes that rotate, we use the
Newman-Janis formalism to construct a regular rotating black hole. We start
with a nonlinearly charged regular static black hole in the framework of the
standard general relativity and then obtain the associated rotating solution
through such a formalism. We investigate the geometrical properties of the
metric by studying the boundary of ergosphere. We also analyze thermodynamic
properties of the solution in AdS spacetime and examine thermal stability and
possible phase transition. In addition, we perturb the black hole by using of a
real massless scalar field as a probe to investigate its dynamic stability. We
obtain an analytic expression for the real and imaginary parts of the
quasinormal frequencies. Finally, we look for a connection between the
quasinormal frequencies and the properties of the photon sphere in the eikonal
limit.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:50:37 GMT""}]","2021-03-17"
"2006.11576","Yoshikazu Mizuguchi","Kazuhisa Hoshi, Motoi Kimata, Yosuke Goto, Akira Miura, Chikao
  Moriyoshi, Yoshihiro Kuroiwa, Masanori Nagao, Yoshikazu Mizuguchi","Two-fold symmetry of in-plane magnetoresistance anisotropy in the
  superconducting states of BiCh2-based LaO0.9F0.1BiSSe single crystal","11 pages, 4 figures","J. Phys. Commun. 4, 095028(1-7) (2020)","10.1088/2399-6528/abbb58",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, two-fold symmetric in-plane anisotropy of the superconducting
properties have been observed in a single crystal of BiCh2-based (Ch: S, Se)
layered superconductor LaO0.5F0.5BiSSe having a tetragonal
(four-fold-symmetric) in-plane structure; the phenomena are very similar to
those observed in nematic superconductors. To explore the origin of the
two-fold symmetric anisotropy in the BiCh2-based system, we have investigated
the electron-doping dependence on the anisotropy by examining the in-plane
anisotropy of the magnetoresistance in the superconducting states for a single
crystal of LaO0.9F0.1BiSSe under high magnetic fields up to 15 T. We observed a
two-fold symmetry of in-plane anisotropy of magnetoresistance for
LaO0.9F0.1BiSSe. The results obtained for LaO0.9F0.1BiSSe are quite similar to
those observed for LaO0.5F0.5BiSSe, which has a higher electron doping
concentration than LaO0.9F0.1BiSSe. Our present finding suggests that the
emergence of the in-plane symmetry breaking in the superconducting state is
robust to the carrier concentration in the series of LaO1-xFxBiSSe.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:52:55 GMT""}]","2021-02-03"
"2006.11577","Stylianos E. Trevlakis","Stylianos E. Trevlakis, Alexandros-Apostolos A. Boulogeorgos, Nestor
  D. Chatzidiamantis, and George K. Karagiannidis","All-Optical Cochlear Implants",,,,,"eess.SP cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present work, we introduce a novel cochlear implant (CI) architecture,
namely all-optical CI (AOCI), which directly converts acoustic to optical
signals capable of stimulating the cochlear neurons. First, we describe the
building-blocks (BBs) of the AOCI, and explain their functionalities as well as
their interconnections. Next, we present a comprehensive system model that
incorporates the technical characteristics and constraints of each BB, the
transdermal-optical-channel particularities, i.e. optical path-loss and
external-implanted device stochastic pointing-errors, and the cochlear neurons
biological properties. Additionally, in order to prove the feasibility of the
AOCI architecture, we conduct a link-budget analysis that outputs novel
closed-form expressions for the instantaneous and average photon flux that is
emitted on the cochlear neurons. Likewise, we define three new
key-performance-indicators (KPIs), namely probability of hearing, probability
of false-hearing, and probability of neural damage. The proposed theoretical
framework is verified through respective simulations, which not only quantify
the efficiency of the proposed architecture, but also reveal an equilibrium
between the optical transmission power and the patient's safety, as well as the
AOCI BBs specifications. Finally, it is highlighted that the AOCI approach is
greener and safer than the conventional CIs.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:55:34 GMT""}]","2020-06-23"
"2006.11578","Antonio Henrique De Oliveira Fonseca","Antonio H. O. Fonseca and David van Dijk","Learning aligned embeddings for semi-supervised word translation using
  Maximum Mean Discrepancy",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Word translation is an integral part of language translation. In machine
translation, each language is considered a domain with its own word embedding.
The alignment between word embeddings allows linking semantically equivalent
words in multilingual contexts. Moreover, it offers a way to infer
cross-lingual meaning for words without a direct translation. Current methods
for word embedding alignment are either supervised, i.e. they require known
word pairs, or learn a cross-domain transformation on fixed embeddings in an
unsupervised way. Here we propose an end-to-end approach for word embedding
alignment that does not require known word pairs. Our method, termed Word
Alignment through MMD (WAM), learns embeddings that are aligned during sentence
translation training using a localized Maximum Mean Discrepancy (MMD)
constraint between the embeddings. We show that our method not only
out-performs unsupervised methods, but also supervised methods that train on
known word translations.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:57:55 GMT""}]","2020-06-23"
"2006.11579","Srikant Gollapudi","Nikhil Rai and Priyabrata Das and Srikant Gollapudi","Can an amorphous crystallize into a high entropy alloy?",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  On the premise that amorphous-HEA composites could demonstrate high toughness
and resistance to embrittlement akin to the phase separating glassy-solid
solution composites, we develop a thermodynamics based approach to identify
chemical compositions capable of undergoing the amorphous to HEA
transformation. We introduce two new parameters called phase selection value
(PSV) and molar volume dispersity parameter. Using this thermodynamic approach
seven multi-component compositions were proposed and the general guidelines for
identifying such compositions was established. The approach also reveals that
BMGs may not be as such amenable to undergo an amorphous to HEA transformation.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:58:05 GMT""}]","2020-06-23"
"2006.11580","Will Perkins","Tyler Helmuth, Matthew Jenssen, Will Perkins","Finite-size scaling, phase coexistence, and algorithms for the random
  cluster model on random graphs","This update includes new results on the slow mixing of Markov chains
  (Theorem 6)",,,,"math.PR cs.DS math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For $\Delta \ge 5$ and $q$ large as a function of $\Delta$, we give a
detailed picture of the phase transition of the random cluster model on random
$\Delta$-regular graphs. In particular, we determine the limiting distribution
of the weights of the ordered and disordered phases at criticality and prove
exponential decay of correlations and central limit theorems away from
criticality.
  Our techniques are based on using polymer models and the cluster expansion to
control deviations from the ordered and disordered ground states. These
techniques also yield efficient approximate counting and sampling algorithms
for the Potts and random cluster models on random $\Delta$-regular graphs at
all temperatures when $q$ is large. This includes the critical temperature at
which it is known the Glauber and Swendsen-Wang dynamics for the Potts model
mix slowly. We further prove new slow-mixing results for Markov chains, most
notably that the Swendsen-Wang dynamics mix exponentially slowly throughout an
open interval containing the critical temperature. This was previously only
known at the critical temperature.
  Many of our results apply more generally to $\Delta$-regular graphs
satisfying a small-set expansion condition.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:03:48 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 12:41:36 GMT""}]","2021-09-16"
"2006.11581","Yurii A. Neretin","Yury A. Neretin","Fourier transform on the Lobachevsky plane and operational calculus","11p","Functional Analysis and its Applications, 54, 4 (2020), 278-286","10.4213/faa3812, 10.1134/S001626632004005X",,"math.RT math.CA math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical Fourier transform on the line sends the operator of
multiplication by $x$ to $i\frac{d}{d\xi}$ and the operator of differentiation
$\frac{d}{d x}$ to the multiplication by $-i\xi$. For the Fourier transform on
the Lobachevsky plane we establish a similar correspondence for a certain
family of differential operators. It appears that differential operators on the
Lobachevsky plane correspond to differential-difference operators in the
Fourier-image, where shift operators act in the imaginary direction, i.e., a
direction transversal to the integration contour in the Plancherel formula.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:09:10 GMT""}]","2021-05-25"
"2006.11582","Kaushik Bhattacharya","Prathamesh Yeole, Vipul Kumar, Kaushik Bhattacharya","Wigner functions in quantum mechanics with a minimum length scale
  arising from generalized uncertainty principle","26 pages, 2 figures. The latest version contains various improvements
  and is an updated version containing new material. This version is accepted
  for publication in European Physics Journal Plus",,,,"hep-th math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we generalize the concept of Wigner function in the case of
quantum mechanics with a minimum length scale arising due to the application of
a generalized uncertainty principle (GUP). We present the phase space
formulation of such theories following GUP and show that the Weyl transform and
the Wigner function does satisfy some of their known properties in standard
quantum mechanics. We utilise the generalized Wigner function to calculate the
phase space average of the Hamiltonian of a quantum harmonic oscillator
satisfying deformed Heisenberg algebra. It is also shown that averages of
certain quantum mechanical operators in such theories may restrict the value of
the deformation parameter specifying the degree of deformation of Heisenberg
algebra. All the results presented are for pure states. The results can be
generalized for mixed states.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:11:05 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 17:04:21 GMT""}]","2021-01-28"
"2006.11583","Jiawei Zhu","Jiawei Zhu, Yujiao Song, Ling Zhao and Haifeng Li","A3T-GCN: Attention Temporal Graph Convolutional Network for Traffic
  Forecasting",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate real-time traffic forecasting is a core technological problem
against the implementation of the intelligent transportation system. However,
it remains challenging considering the complex spatial and temporal
dependencies among traffic flows. In the spatial dimension, due to the
connectivity of the road network, the traffic flows between linked roads are
closely related. In terms of the temporal factor, although there exists a
tendency among adjacent time points in general, the importance of distant past
points is not necessarily smaller than that of recent past points since traffic
flows are also affected by external factors. In this study, an attention
temporal graph convolutional network (A3T-GCN) traffic forecasting method was
proposed to simultaneously capture global temporal dynamics and spatial
correlations. The A3T-GCN model learns the short-time trend in time series by
using the gated recurrent units and learns the spatial dependence based on the
topology of the road network through the graph convolutional network. Moreover,
the attention mechanism was introduced to adjust the importance of different
time points and assemble global temporal information to improve prediction
accuracy. Experimental results in real-world datasets demonstrate the
effectiveness and robustness of proposed A3T-GCN. The source code can be
visited at https://github.com/lehaifeng/T-GCN/A3T.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:12:01 GMT""}]","2020-06-23"
"2006.11584","Max-Heinrich Laves M. Sc.","Max-Heinrich Laves, Sontje Ihler, Karl-Philipp Kortmann, Tobias
  Ortmaier","Calibration of Model Uncertainty for Dropout Variational Inference",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The model uncertainty obtained by variational Bayesian inference with Monte
Carlo dropout is prone to miscalibration. In this paper, different logit
scaling methods are extended to dropout variational inference to recalibrate
model uncertainty. Expected uncertainty calibration error (UCE) is presented as
a metric to measure miscalibration. The effectiveness of recalibration is
evaluated on CIFAR-10/100 and SVHN for recent CNN architectures. Experimental
results show that logit scaling considerably reduce miscalibration by means of
UCE. Well-calibrated uncertainty enables reliable rejection of uncertain
predictions and robust detection of out-of-distribution data.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:12:55 GMT""}]","2020-06-23"
"2006.11585","Yoav Zeevi","Yoav Zeevi, Sofi Astashenko, Yoav Benjamini","Ignored evident multiplicity harms replicability -- adjusting for it
  offers a remedy","28 pages, 2 figures, 1 table",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is a central dogma in science that a result of a study should be
replicable. Only 90 of the 190 replications attempts were successful. We
attribute a substantial part of the problem to selective inference evident in
the paper, which is the practice of selecting some of the results from the
many. 100 papers in the Reproducibility Project in Psychology were analyzed. It
was evident that the reporting of many results is common (77.7 per paper on
average). It was further found that the selection from those multiple results
is not adjusted for. We propose to account for selection using the hierarchical
false discovery rate (FDR) controlling procedure TreeBH of Bogomolov et al.
(2020), which exploits hierarchical structures to gain power. Results that were
statistically significant after adjustment were 97% of the replicable results
(31 of 32). Additionally, only 1 of the 21 non-significant results after
adjustment was replicated. Given the easy deployment of adjustment tools and
the minor loss of power involved, we argue that addressing multiplicity is an
essential missing component in experimental psychology. It should become a
required component in the arsenal of replicability enhancing methodologies in
the field.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:22:48 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 06:17:57 GMT""}]","2021-05-20"
"2006.11586","Mahmoud Daif","Mahmoud Daif, Shunsuke Kitada, Hitoshi Iyatomi","AraDIC: Arabic Document Classification using Image-Based Character
  Embeddings and Class-Balanced Loss",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classical and some deep learning techniques for Arabic text classification
often depend on complex morphological analysis, word segmentation, and
hand-crafted feature engineering. These could be eliminated by using
character-level features. We propose a novel end-to-end Arabic document
classification framework, Arabic document image-based classifier (AraDIC),
inspired by the work on image-based character embeddings. AraDIC consists of an
image-based character encoder and a classifier. They are trained in an
end-to-end fashion using the class balanced loss to deal with the long-tailed
data distribution problem. To evaluate the effectiveness of AraDIC, we created
and published two datasets, the Arabic Wikipedia title (AWT) dataset and the
Arabic poetry (AraP) dataset. To the best of our knowledge, this is the first
image-based character embedding framework addressing the problem of Arabic text
classification. We also present the first deep learning-based text classifier
widely evaluated on modern standard Arabic, colloquial Arabic and classical
Arabic. AraDIC shows performance improvement over classical and deep learning
baselines by 12.29% and 23.05% for the micro and macro F-score, respectively.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:25:06 GMT""}]","2020-06-23"
"2006.11587","Hongyi Jiang","Amitabh Basu, Hongyi Jiang","Two-halfspace closure",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a new cutting plane closure for pure integer programs called the
two-halfspace closure. It is a natural generalization of the well-known
Chv\'atal-Gomory closure. We prove that the two-halfspace closure is
polyhedral. We also study the corresponding $2$-halfpsace rank of any valid
inequality and show that it is at most the split rank of the inequality.
Moreover, while the split rank can be strictly larger than the two-halfspace
rank, the split rank is at most twice the two-halfspace rank. A key step of our
analysis shows that the split closure of a rational polyhedron can be obtained
by considering the split closures of all $k$-dimensional (rational) projections
of the polyhedron, for any fixed $k\geq 2$. This result may be of independent
interest.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:28:12 GMT""},{""version"":""v2"",""created"":""Sun, 9 May 2021 20:18:35 GMT""},{""version"":""v3"",""created"":""Tue, 17 Aug 2021 01:16:25 GMT""}]","2021-08-18"
"2006.11588","Aiguo Xu Prof. Dr.","D. J. Zhang, A. G. Xu, Y. D. Zhang and Y. J. Li","Two-fluid discrete Boltzmann model for compressible flows: based on
  Ellipsoidal Statistical Bhatnagar-Gross-Krook",,"Phys. Fluids 32, 126110 (2020)","10.1063/5.0017673",,"physics.flu-dyn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A two-fluid Discrete Boltzmann Model(DBM) for compressible flows based on
Ellipsoidal Statistical Bhatnagar-Gross-Krook(ES-BGK) is presented. The model
has flexible Prandtl number or specific heat ratio. Mathematically, the model
is composed of two coupled Discrete Boltzmann Equations(DBE). Each DBE
describes one component of the fluid. Physically, the model is equivalent to a
macroscopic fluid model based on Navier-Stokes(NS) equations, and supplemented
by a coarse-grained model for thermodynamic non-equilibrium behaviors. To
obtain a flexible Prandtl number, a coefficient is introduced in the
ellipsoidal statistical distribution function to control the viscosity. To
obtain a flexible specific heat ratio, a parameter is introduced in the energy
kinetic moments to control the extra degree of freedom. For binary mixture, the
correspondence between the macroscopic fluid model and the DBM may be
several-to-one. Five typical benchmark tests are used to verify and validate
the model. Some interesting non-equilibrium results, which are not available in
the NS model or the single-fluid DBM, are presented.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:40:11 GMT""},{""version"":""v2"",""created"":""Tue, 15 Sep 2020 14:08:19 GMT""},{""version"":""v3"",""created"":""Wed, 18 Nov 2020 03:42:52 GMT""},{""version"":""v4"",""created"":""Thu, 19 Nov 2020 23:51:51 GMT""},{""version"":""v5"",""created"":""Tue, 15 Dec 2020 00:35:27 GMT""}]","2022-03-24"
"2006.11589","Calvin Beideman","Calvin Beideman, Karthekeyan Chandrasekaran and Chao Xu","Multicritera Cuts and Size-Constrained $k$-cuts in Hypergraphs","Accepted to RANDOM 2020",,,,"cs.DS cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address counting and optimization variants of multicriteria global min-cut
and size-constrained min-$k$-cut in hypergraphs.
  1. For an $r$-rank $n$-vertex hypergraph endowed with $t$ hyperedge-cost
functions, we show that the number of multiobjective min-cuts is
$O(r2^{tr}n^{3t-1})$. In particular, this shows that the number of parametric
min-cuts in constant rank hypergraphs for a constant number of criteria is
strongly polynomial, thus resolving an open question by Aissi, Mahjoub,
McCormick, and Queyranne (Math Programming, 2015). In addition, we give
randomized algorithms to enumerate all multiobjective min-cuts and all
pareto-optimal cuts in strongly polynomial-time.
  2. We also address node-budgeted multiobjective min-cuts: For an $n$-vertex
hypergraph endowed with $t$ vertex-weight functions, we show that the number of
node-budgeted multiobjective min-cuts is $O(r2^{r}n^{t+2})$, where $r$ is the
rank of the hypergraph, and the number of node-budgeted $b$-multiobjective
min-cuts for a fixed budget-vector $b$ is $O(n^2)$.
  3. We show that min-$k$-cut in hypergraphs subject to constant lower bounds
on part sizes is solvable in polynomial-time for constant $k$, thus resolving
an open problem posed by Queyranne. Our technique also shows that the number of
optimal solutions is polynomial.
  All of our results build on the random contraction approach of Karger (SODA,
1993). Our techniques illustrate the versatility of the random contraction
approach to address counting and algorithmic problems concerning multiobjective
min-cuts and size-constrained $k$-cuts in hypergraphs.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:41:00 GMT""}]","2020-06-23"
"2006.11590","Andrey Malinin Dr.","Andrey Malinin, Sergey Chervontsev, Ivan Provilkov and Mark Gales","Regression Prior Networks",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prior Networks are a recently developed class of models which yield
interpretable measures of uncertainty and have been shown to outperform
state-of-the-art ensemble approaches on a range of tasks. They can also be used
to distill an ensemble of models via Ensemble Distribution Distillation
(EnD$^2$), such that its accuracy, calibration and uncertainty estimates are
retained within a single model. However, Prior Networks have so far been
developed only for classification tasks. This work extends Prior Networks and
EnD$^2$ to regression tasks by considering the Normal-Wishart distribution. The
properties of Regression Prior Networks are demonstrated on synthetic data,
selected UCI datasets and a monocular depth estimation task, where they yield
performance competitive with ensemble approaches.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:50:14 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 09:34:21 GMT""}]","2020-12-10"
"2006.11591","Milo Orlich","Milo Orlich","Linearization of monomial ideals","47 pages, 5 figures. Update: fixed typos and made minor changes to
  the phrasing and general structure, without new results",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a construction, called linearization, that associates to any
monomial ideal $I$ an ideal $\mathrm{Lin}(I)$ in a larger polynomial ring. The
main feature of this construction is that the new ideal $\mathrm{Lin}(I)$ has
linear quotients. In particular, since $\mathrm{Lin}(I)$ is generated in a
single degree, it follows that $\mathrm{Lin}(I)$ has a linear resolution. We
investigate some properties of this construction, such as its interplay with
classical operations on ideals, its Betti numbers, functoriality and
combinatorial interpretations. We moreover introduce an auxiliary construction,
called equification, that associates to any monomial ideal a new monomial ideal
generated in a single degree, in a polynomial ring with one more variable. We
study some of the homological and combinatorial properties of the equification,
which can be seen as a monomial analogue of the well-known homogenization
construction.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:51:21 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 17:10:30 GMT""}]","2021-03-16"
"2006.11592","Jaroslav Jaro\v{s}","Jaroslav Jaros, Takashi Kusano, Tomoyuki Tanigawa","Viewing nonoscillatory second order linear differential equations from
  the angle of Riccati equations",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We build an existence theory for nonoscillatory second order differential
equations of the form (A) $(p(t)x')' = q(t)x, $ $p(t)$ and $q(t)$ being
positive continuous functions on $[a,\infty)$, in which a crucial role is
played by a pair of the Riccati differential equations (R1) $u' = q(t) -
u^2/p(t)$, (R2) $ v' = 1/p(t) - q(t)v^2$, associated with (A). An essential
part of the theory is the construction of a pair of linearly independent
nonoscillatory solutions $x_1(t)$ and $x_2(t)$ of (A) enjoying explicit
exponential-integral representations in terms of solutions $u_1(t)$ and
$u_2(t)$ of (R1) or in terms of solutions $v_1(t)$ and $v_2(t)$ of (R2).
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:09:02 GMT""}]","2020-06-23"
"2006.11593","Yongming Li","Yongming Li, Lang Zhou, Lingyun Qin, Yuwei Zeng, Yuchuan Liu, Yan Lei,
  Pin Wang, Fan Li","Deep Double-Side Learning Ensemble Model for Few-Shot Parkinson Speech
  Recognition","15 pages, 4 figures",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diagnosis and therapeutic effect assessment of Parkinson disease based on
voice data are very important,but its few-shot learning problem is
challenging.Although deep learning is good at automatic feature extraction, it
suffers from few-shot learning problem. Therefore, the general effective method
is first conduct feature extraction based on prior knowledge, and then carry
out feature reduction for subsequent classification. However, there are two
major problems: 1) Structural information among speech features has not been
mined and new features of higher quality have not been reconstructed. 2)
Structural information between data samples has not been mined and new samples
with higher quality have not been reconstructed. To solve these two problems,
based on the existing Parkinson speech feature data set, a deep double-side
learning ensemble model is designed in this paper that can reconstruct speech
features and samples deeply and simultaneously. As to feature reconstruction,
an embedded deep stacked group sparse auto-encoder is designed in this paper to
conduct nonlinear feature transformation, so as to acquire new high-level deep
features, and then the deep features are fused with original speech features by
L1 regularization feature selection method. As to speech sample reconstruction,
a deep sample learning algorithm is designed in this paper based on iterative
mean clustering to conduct samples transformation, so as to obtain new
high-level deep samples. Finally, the bagging ensemble learning mode is adopted
to fuse the deep feature learning algorithm and the deep samples learning
algorithm together, thereby constructing a deep double-side learning ensemble
model. At the end of this paper, two representative speech datasets of
Parkinson's disease were used for verification. The experimental results show
that the proposed algorithm are effective.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:14:41 GMT""}]","2020-06-23"
"2006.11594","John Clayton Taylor","A. Andra\V{s}i, J. C. Taylor","Renormalization in an interpolating gauge in Yang-Mills theory","16 pages, 2 figures. Submitted for publication",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Coulomb gauge in QCD is the only explicitly unitary gauge. But it suffers
from energy-divergences which means that it is not rigorously well-defined. One
way to define it unambiguously is as the limit of a gauge interpolating between
the Feynman gauge and the Coulomb gauge. This interpolating gauge is
characterized by a parameter theta and the Coulomb gauge is obtained in the
limit theta tends to 0. We study the renormalization of this theta-gauge for
all values of theta. Novel features include field mixing as well as scaling,
the renormalization of the theta parameter itself, and the appearance of new
counter-term structures at two-loop order.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:22:36 GMT""}]","2020-06-23"
"2006.11595","Damien Querlioz","Bogdan Penkovsky, Marc Bocquet, Tifenn Hirtzlin, Jacques-Olivier
  Klein, Etienne Nowak, Elisa Vianello, Jean-Michel Portal and Damien Querlioz","In-Memory Resistive RAM Implementation of Binarized Neural Networks for
  Medical Applications",,,,,"eess.SP cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The advent of deep learning has considerably accelerated machine learning
development. The deployment of deep neural networks at the edge is however
limited by their high memory and energy consumption requirements. With new
memory technology available, emerging Binarized Neural Networks (BNNs) are
promising to reduce the energy impact of the forthcoming machine learning
hardware generation, enabling machine learning on the edge devices and avoiding
data transfer over the network. In this work, after presenting our
implementation employing a hybrid CMOS - hafnium oxide resistive memory
technology, we suggest strategies to apply BNNs to biomedical signals such as
electrocardiography and electroencephalography, keeping accuracy level and
reducing memory requirements. We investigate the memory-accuracy trade-off when
binarizing whole network and binarizing solely the classifier part. We also
discuss how these results translate to the edge-oriented Mobilenet~V1 neural
network on the Imagenet task. The final goal of this research is to enable
smart autonomous healthcare devices.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:27:21 GMT""}]","2020-06-23"
"2006.11596","Pham The Song","Pham The Song","On the Bogoliubov theory: Casimir effect in a single weakly interacting
  Bose gas at zero-temperature with Neumann boundary condition","Some calculations should be repaired",,,,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Developing Bogoliubov theory of weakly interacting Bose gas in uncompacted
three-dimension space, quantum fluctuation energy of one component dilute gas
of Bose-Einstein condensate (BEC) confined to two parallel plates investigated
at zero-temperature in grand canonical ensemble (GCE) with Neumann boundary
condition (BC). The Casimir force considered in comparison to the one with
Robin BC, Dirichlet BC and periodic BC.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:29:41 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 14:04:42 GMT""}]","2021-04-29"
"2006.11597","\'Akos Hajdu","\'Akos Hajdu, Naghmeh Ivaki, Imre Kocsis, Attila Klenik, L\'aszl\'o
  G\""onczy, Nuno Laranjeiro, Henrique Madeira, Andr\'as Pataricza","Using Fault Injection to Assess Blockchain Systems in Presence of Faulty
  Smart Contracts","Authors' manuscript. Published in IEEE Access 2020. The final
  publication is available at IEEE via
  http://dx.doi.org/10.1109/ACCESS.2020.3032239",,"10.1109/ACCESS.2020.3032239",,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Blockchain has become particularly popular due to its promise to support
business-critical services in very different domains (e.g., retail, supply
chains, healthcare). Blockchain systems rely on complex middleware, like
Ethereum or Hyperledger Fabric, that allow running smart contracts, which
specify business logic in cooperative applications. The presence of software
defects or faults in these contracts has notably been the cause of failures,
including severe security problems. In this paper, we use a software
implemented fault injection (SWIFI) technique to assess the behavior of
permissioned blockchain systems in the presence of faulty smart contracts. We
emulate the occurrence of general software faults (e.g., missing variable
initialization) and also blockchain-specific software faults (e.g., missing
require statement on transaction sender) in smart contracts code to observe the
impact on the overall system dependability (i.e., reliability and integrity).
We also study the effectiveness of formal verification (i.e., done by
solc-verify) and runtime protections (e.g., using the assert statement)
mechanisms in detection of injected faults. Results indicate that formal
verification as well as additional runtime protections have to complement
built-in platform checks to guarantee the proper dependability of blockchain
systems and applications. The work presented in this paper allows smart
contract developers to become aware of possible faults in smart contracts and
to understand the impact of their presence. It also provides valuable
information for middleware developers to improve the behavior (e.g., overall
fault tolerance) of their systems.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:35:55 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 07:16:51 GMT""}]","2020-10-23"
"2006.11598","Hendrik van Hees","Hendrik van Hees","Comment on ""Defining the electromagnetic potentials""","9 pages; v2: version accepted for publication in Eur. J. Phys","Eur. J. Phys. 42, 028003 (2021)","10.1088/1361-6404/abc137",,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this comment it is argued that the argument for a unique determination of
the electromagnetic potentials in classical electrodynamics in [1] is flawed.
To the contrary the ""gauge freedom"" of the electromagnetic potentials has
proven as one of the most important properties in the development of modern
physics, where local gauge invariance with its extension to non-Abelian gauge
groups is a key feature in the formulation of the Standard Model of elementary
particles in terms of a relativistic quantum field theory. [1] A. Davis, Eur.
J. Phys. 41, 045202 (2020)
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:37:51 GMT""},{""version"":""v2"",""created"":""Tue, 13 Oct 2020 07:51:38 GMT""}]","2021-01-26"
"2006.11599","Georg Enzian","Georg Enzian, John J. Price, Lars Freisem, Joshua Nunn, Jiri Janousek,
  Ben C. Buchler, Ping Koy Lam, Michael R. Vanner","Single-Phonon Addition and Subtraction to a Mechanical Thermal State",,"Phys. Rev. Lett. 126, 033601 (2021)","10.1103/PhysRevLett.126.033601",,"quant-ph cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adding or subtracting a single quantum of excitation to a thermal state of a
bosonic system has the counter-intuitive effect of approximately doubling its
mean occupation. We perform the first experimental demonstration of this effect
outside optics by implementing single-phonon addition and subtraction to a
thermal state of a mechanical oscillator via Brillouin optomechanics in an
optical whispering-gallery microresonator. Using a detection scheme that
combines single-photon counting and optical heterodyne detection, we observe
this doubling of the mechanical thermal fluctuations to a high precision. The
capabilities of this joint click-dyne detection scheme adds a significant new
dimension for optomechanical quantum science and applications.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:41:43 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 16:51:17 GMT""},{""version"":""v3"",""created"":""Fri, 22 Jan 2021 11:31:31 GMT""}]","2021-01-25"
"2006.11600","Yangyang Guo","Yangyang Guo, Zhiyong Cheng, Jiazheng Jing, Yanpeng Lin, Liqiang Nie,
  Meng Wang","Enhancing Factorization Machines with Generalized Metric Learning",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Factorization Machines (FMs) are effective in incorporating side information
to overcome the cold-start and data sparsity problems in recommender systems.
Traditional FMs adopt the inner product to model the second-order interactions
between different attributes, which are represented via feature vectors. The
problem is that the inner product violates the triangle inequality property of
feature vectors. As a result, it cannot well capture fine-grained attribute
interactions, resulting in sub-optimal performance. Recently, the Euclidean
distance is exploited in FMs to replace the inner product and has delivered
better performance. However, previous FM methods including the ones equipped
with the Euclidean distance all focus on the attribute-level interaction
modeling, ignoring the critical intrinsic feature correlations inside
attributes. Thereby, they fail to model the complex and rich interactions
exhibited in the real-world data. To tackle this problem, in this paper, we
propose a FM framework equipped with generalized metric learning techniques to
better capture these feature correlations. In particular, based on this
framework, we present a Mahalanobis distance and a deep neural network (DNN)
methods, which can effectively model the linear and non-linear correlations
between features, respectively. Besides, we design an efficient approach for
simplifying the model functions. Experiments on several benchmark datasets
demonstrate that our proposed framework outperforms several state-of-the-art
baselines by a large margin. Moreover, we collect a new large-scale dataset on
second-hand trading to justify the effectiveness of our method over cold-start
and data sparsity problems in recommender systems.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:46:22 GMT""},{""version"":""v2"",""created"":""Sat, 24 Oct 2020 03:14:38 GMT""}]","2020-10-27"
"2006.11601","Chee Seng Chan","Lixin Fan, Kam Woh Ng, Ce Ju, Tianyu Zhang, Chang Liu, Chee Seng Chan,
  Qiang Yang","Rethinking Privacy Preserving Deep Learning: How to Evaluate and Thwart
  Privacy Attacks","under review, 36 pages (updated Eq. 3 and Fig. 8)",,,,"cs.LG cs.CR cs.DC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates capabilities of Privacy-Preserving Deep Learning
(PPDL) mechanisms against various forms of privacy attacks. First, we propose
to quantitatively measure the trade-off between model accuracy and privacy
losses incurred by reconstruction, tracing and membership attacks. Second, we
formulate reconstruction attacks as solving a noisy system of linear equations,
and prove that attacks are guaranteed to be defeated if condition (2) is
unfulfilled. Third, based on theoretical analysis, a novel Secret Polarization
Network (SPN) is proposed to thwart privacy attacks, which pose serious
challenges to existing PPDL methods. Extensive experiments showed that model
accuracies are improved on average by 5-20% compared with baseline mechanisms,
in regimes where data privacy are satisfactorily protected.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:48:57 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 14:45:58 GMT""}]","2020-06-25"
"2006.11602","Eero Saksman","Kari Astala, Steffen Rohde, Eero Saksman and Terence Tao","Homogenization of iterated singular integrals with applications to
  random quasiconformal maps","56 pages",,,,"math.CV math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study homogenization of iterated randomized singular integrals and
homeomorphic solutions to the Beltrami differential equation with a random
Beltrami coefficient. More precisely, let
  $(F_j)_{j \geq 1}$ be a sequence of normalized homeomorphic solutions to the
planar Beltrami equation $\overline{\partial} F_j (z)=\mu_j(z,\omega) \partial
F_j(z),$ where the random dilatation satisfies $|\mu_j|\leq k<1$ and has
locally periodic statistics, for example of the type $$\mu_j
(z,\omega)=\phi(z)\sum_{n\in \mathbf{Z}^2}g(2^j z-n,X_{n}(\omega)), $$ where
$g(z,\omega)$ decays rapidly in $z$, the random variables $X_{n}$ are i.i.d.,
and $\phi\in C^\infty_0$. We establish the almost sure and local uniform
convergence as $j\to\infty$ of the maps $F_j$ to a deterministic quasiconformal
limit $F_\infty$.
  This result is obtained as an application of our main theorem, which deals
with homogenization of iterated randomized singular integrals. As a special
case of our theorem, let $T_1,\ldots , T_{m}$ be translation and dilation
invariant singular integrals on ${\bf R}^d, $ and consider a $d$-dimensional
version of $\mu_j$, e.g., as defined above or within a more general setting. We
then prove that there is a deterministic function $f$ such that almost surely
as $j\to\infty$, $$ \mu_j T_{m}\mu_j\ldots T_1\mu_j\to f \quad \textrm{weakly
in } L^p,\quad 1 < p < \infty\ . $$
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:51:00 GMT""}]","2020-06-23"
"2006.11603","Debasish Chaudhuri","Amir Shee, Nisha Gupta, Abhishek Chaudhuri and Debasish Chaudhuri","Semiflexible polymer in a gliding assay: reentrant transition, role of
  turnover and activity","13 pages, 14 figures; version accepted for publication in Soft Matter","Soft Matter 17, 2120 (2021)","10.1039/D0SM01181A",,"physics.bio-ph cond-mat.soft cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a model of an extensible semiflexible filament moving in two
dimensions on a motility assay of motor proteins represented explicitly as
active harmonic linkers. Their heads bind stochastically to polymer segments
within a capture radius, and extend along the filament in a directed fashion
before detaching. Both the extension and detachment rates are load-dependent
and generate an active drive on the filament. The filament undergoes a first
order phase transition from open chain to spiral conformations and shows a
reentrant behavior in both the active extension and the turnover, defined as
the ratio of attachment-detachment rates. Associated with the phase transition,
the size and shape of the polymer changes non-monotonically, and the relevant
autocorrelation functions display double-exponential decay. The corresponding
correlation times show a maximum signifying the dominance of spirals. The
orientational dynamics captures the rotation of spirals, and its correlation
time decays with activity as a power law.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:57:54 GMT""},{""version"":""v2"",""created"":""Thu, 17 Dec 2020 12:57:57 GMT""}]","2021-08-31"
"2006.12168","Luciano Canton","A. Colombi, F. Barbaro, L. Canton, M.P. Carante, A. Fontana","Modeling Nuclear Reactions for PET/MRI MultiModal Imaging: the
  innovative use of 52gMn","2 pages, to be published in the 2020 Annual Report (LNL-INFN)",,,,"physics.med-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MultiModal Imaging is an innovative technique that consists in the
combination of diagnostic exams based on different physical processes, to
obtain a unique image with more detailed clinical information. The possibility
of a simultaneous use of PET and MRI could be achieved by using a particular
radioisotope: 52gMn. The main route to produce this isotope is the reaction
52Cr(p,n)52gMn which is theoretically investigated in this study by means of
three nuclear reaction codes. An analysis of the cross sections and a
computation of the production rates and time evolution of the produced
radioisotopes are performed, to identify the optimal production parameters. The
procedure described for this reaction has a general validity and is applied
also to other reactions, such as 52Cr(d,2n)52gMn and natV(alpha,x)52gMn.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 16:34:57 GMT""}]","2020-06-23"
"2006.12298","Joao Rodrigues Dr","Jo\~ao D. Rodrigues, Himadri S. Dhar, Benjamin T. Walker, Jason M.
  Smith, Rupert F. Oulton, Florian Mintert, Robert A. Nyman","Learning the Fuzzy Phases of Small Photonic Condensates",,"Phys. Rev. Lett. 126, 150602 (2021)","10.1103/PhysRevLett.126.150602",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phase transitions, being the ultimate manifestation of collective behaviour,
are typically features of many-particle systems only. Here, we describe the
experimental observation of collective behaviour in small photonic condensates
made up of only a few photons. Moreover, a wide range of both equilibrium and
non-equilibrium regimes, including Bose-Einstein condensation or laser-like
emission are identified. However, the small photon number and the presence of
large relative fluctuations places major difficulties in identifying different
phases and phase transitions. We overcome this limitation by employing
unsupervised learning and fuzzy clustering algorithms to systematically
construct the fuzzy phase diagram of our small photonic condensate. Our results
thus demonstrate the rich and complex phase structure of even small collections
of photons, making them an ideal platform to investigate equilibrium and
non-equilibrium physics at the few particle level.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:36:55 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jul 2020 14:12:02 GMT""},{""version"":""v3"",""created"":""Tue, 23 Mar 2021 23:31:48 GMT""}]","2021-04-19"
"2006.12299","Houcine Meftahi","Houcine Meftahi","Uniqueness, Lipschitz stability and reconstruction for the inverse
  optical tomography problem",,,,,"math.AP math.FA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the inverse problem of recovering a diffusion and
absorption coefficients in steady-state optical tomography problem from the
Neumann-to-Dirichlet map. We first prove a Global uniqueness and Lipschitz
stability estimate for the absorption parameter provided that the diffusion is
known. Then, we prove a Lipschitz stability result for simultaneous recovery of
diffusion and absorption. In both cases the parameters belong to a known finite
subspace with a priori known bounds. The proofs relies on a monotonicity result
combined with the techniques of localized potentials. To numerically solve the
inverse problem, we propose a Kohn-Vogeliustype cost functional over a class of
admissible parameters subject to two boundary value problems. The reformulation
of the minimization problem via the Neumann-toDirichlet operator allows us to
obtain the optimality conditions by using the Frechet differentiability of this
operator and its inverse. The reconstruction is then performed by means of an
iterative algorithm based on a quasi-Newton method. Finally, we illustrate some
numerical results.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 17:43:38 GMT""},{""version"":""v2"",""created"":""Thu, 17 Dec 2020 21:33:06 GMT""}]","2020-12-21"
"2006.12489","Xiao Li","Xiao Li and William Fithian","Optimality of the max test for detecting sparse signals with Gaussian or
  heavier tail","30 pages, 8 figures",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A fundamental problem in high-dimensional testing is that of global null
testing: testing whether the null holds simultaneously in all of $n$
hypotheses. The max test, which uses the smallest of the $n$ marginal p-values
as its test statistic, enjoys widespread popularity for its simplicity and
robustness. However, its theoretical performance relative to other tests has
been called into question. In the Gaussian sequence version of the global
testing problem, Donoho and Jin (2004) discovered a so-called ""weak, sparse""
asymptotic regime in which the higher criticism and Berk-Jones tests achieve a
better detection boundary than the max test when all of the nonzero signal
strengths are identical. We study a more general model in which the non-null
means are drawn from a generic distribution, and show that the detection
boundary for the max test is optimal in the ""weak, sparse"" regime, provided
that the distribution's tail is no lighter than Gaussian. Further, we show
theoretically and in simulation that the modified higher criticism of Donoho
and Jin (2004) can have very low power when the distribution of non-null means
has a polynomial tail.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:50:47 GMT""}]","2020-06-24"
"2006.12490","Lorenzo Fassina PhD","Giulia Montagna, Francesco Cristofaro, Lorenzo Fassina, Giovanna
  Bruni, Lucia Cucca, Alejandro Kochen, Paola Divieti Pajevic, Beth Bragdon,
  Livia Visai, Louis Gerstenfeld","An $\textit{in vivo}$ comparison study between strontium nanoparticles
  and rhBMP2",,"Frontiers in Bioengineering and Biotechnology 2020;8:499","10.3389/fbioe.2020.00499",,"q-bio.TO q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  The osteoinductive property of strontium was repeatedly proven in the last
decades. Compelling $\textit{in vitro}$ data demonstrated that strontium
hydroxyapatite nanoparticles exert a dual action, by promoting
osteoblasts-driven matrix secretion and inhibiting osteoclasts-driven matrix
resorption. Recombinant human bone morphogenetic protein 2 (rhBMP2) is a
powerful osteoinductive biologic, used for the treatment of vertebral fractures
and critically-sized bone defects. Although effective, the use of rhBMP2 has
limitations due its recombinant morphogen nature. In this study, we examined
the comparison between two osteoinductive agents: rhBMP2 and the innovative
strontium-substituted hydroxyapatite nanoparticles. To test their
effectiveness, we independently loaded Gelfoam sponges with the two
osteoinductive agents and used the sponges as agent-carriers. Gelfoam are
FDA-approved biodegradable medical devices used as delivery system for
musculoskeletal defects. Their porous structure and spongy morphology make them
attractive in orthopedic field. The abiotic characterization of the loaded
sponges, involving ion release pattern and structure investigation, was
followed by $\textit{in vivo}$ implantation onto the periosteum of healthy mice
and comparison of the effects induced by each implant was performed. The
results demonstrated the use of sponges loaded with strontium nanoparticles as
potential bone grafts might provide better outcomes for complex fractures.
Strontium nanoparticles are a novel and effective non-biologic treatment for
bone injuries and can be used as novel powerful therapeutics for bone
regeneration.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 05:46:32 GMT""}]","2020-06-24"
"2006.12491","Rachid Marsli","Rachid Marsli and Frank J. Hall","Inclusion regions and bounds for the eigenvalues of matrices with a
  known eigenpair","10 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let ({\lambda}, v) be a known real eigenpair of a square real matrix A. In
this paper it is shown how to locate the other eigenvalues of A in terms of the
components of v. The obtained region is a union of Gershgorin discs of the
second type recently introduced by the authors in a previous paper. Two cases
are
  considered depending on whether or not some of the components of v are equal
to zero. Upper bounds are obtained, in two different ways, for the largest
eigenvalue in absolute value of A other than {\lambda}. Detailed examples are
provided. Although nonnegative irreducible matrices are somewhat emphasized,
the main results in this paper are valid for any square real matrix.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 11:09:58 GMT""}]","2020-06-24"
"2006.12492","Maxim Tkachuk","M.V. Tkachuk, S.A. Plaksa","Analog of Menchov-Trokhimchuk theorem for monogenic functions in
  three-dimensional commutative algebra","11 pages, in Ukrainian",,,,"math.CA math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this work is to weaken the conditions of monogenity for functions
that take values in one concrete three-dimensional commutative algebras over
the field of complex numbers. The monogenity of the function understood as a
combination of its continuity with the existence of a Gato derivative.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:57:38 GMT""}]","2020-06-24"
"2006.12493","Fatemeh Ghasemi","Fatemeh Ghasemi and Afshin Shafiee","An investigation into the energy transfer efficiency of a two-pigment
  photosynthetic system using a macroscopic quantum model",,,,,"physics.chem-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite several different measures of efficiency that are applicable to the
photosynthetic systems, a precise degree of efficiency of these systems is not
completely determined. Introducing an efficient model for the dynamics of
light-harvesting complexes in biological environments is a major purpose in
investigating such systems. Here, we investigate the effect of macroscopic
quantum behavior of a system of two pigments on the transport phenomena in this
system model which interacts with an oscillating environment. We use the
second-order perturbation theory to calculate the time-dependent population of
excitonic states of a two-dimensional Hamiltonian using a non-master equation
approach. Our results demonstrate that the quantum efficiency is robust with
respect to the macroscopicity parameter h solely, but the ratio of
macroscopicity over the pigment-pigment interaction energy can be considered as
a parameter that may control the energy transfer efficiency at a given time.
So, the dynamical behavior and the quantum efficiency of the supposed
photosynthetic system may be influenced by a change in the macroscopic behavior
of the system.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:59:02 GMT""}]","2020-06-24"
"2006.12494","Larry Zamick","Castaly Fan, Praveen C. Srivastava and Larry Zamick","Variation of Single-Particle Energies: Scaling Behavior for the Spectrum
  of $^{48}$Cr",,,,,"nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  We perform shell model calculations for $^{48}$Cr using GXPF1A and FPD6
interactions by varying single particle energies. We find a scaling behavior
which leads to the finding that many different sets of interactions with vastly
different single particle energies can give almost identical results for the
yrast spectrum of $^{48}$Cr
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 13:57:09 GMT""},{""version"":""v2"",""created"":""Sat, 13 Feb 2021 02:32:49 GMT""}]","2021-02-16"
"2006.12985","Wilfredo Urbina-Romero","Eduard Navas, Ebner Pineda and Wilfredo Urbina","The Boundedness of General Alternative Gaussian Singular Integrals on
  variable Lebesgue spaces with Gaussian measure","arXiv admin note: text overlap with arXiv:1911.06375",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a previous paper, we introduced a new class of Gaussian singular
integrals, that we called the general alternative Gaussian singular integrals
and study the boundedness of them on $L^p(\gamma_d)$, $ 1 < p < \infty.$ In
this paper, we study the boundedness of those operators on Gaussian variable
Lebesgue spaces under a certain additional condition of regularity on
$p(\cdot)$ following a paper by E. Dalmasso and R. Scotto.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 06:23:36 GMT""},{""version"":""v2"",""created"":""Mon, 5 Oct 2020 18:23:24 GMT""},{""version"":""v3"",""created"":""Mon, 22 Mar 2021 15:46:57 GMT""}]","2021-03-23"
"2006.12987","Shuo Chang","Shuo Chang, YiFan Zhang, Sai Huang, Yuanyuan Yao and Zhiyong Feng","Exemplar Loss for Siamese Network in Visual Tracking","The experiment results have some error. And the pdf format is not
  proper",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual tracking plays an important role in perception system, which is a
crucial part of intelligent transportation. Recently, Siamese network is a hot
topic for visual tracking to estimate moving targets' trajectory, due to its
superior accuracy and simple framework. In general, Siamese tracking
algorithms, supervised by logistic loss and triplet loss, increase the value of
inner product between exemplar template and positive sample while reduce the
value of inner product with background sample. However, the distractors from
different exemplars are not considered by mentioned loss functions, which limit
the feature models' discrimination. In this paper, a new exemplar loss
integrated with logistic loss is proposed to enhance the feature model's
discrimination by reducing inner products among exemplars. Without the bells
and whistles, the proposed algorithm outperforms the methods supervised by
logistic loss or triplet loss. Numerical results suggest that the newly
developed algorithm achieves comparable performance in public benchmarks.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:47:53 GMT""},{""version"":""v2"",""created"":""Sun, 4 Oct 2020 02:29:33 GMT""}]","2020-10-06"
"2006.12988","Max Wenqiang Xu","Quentin Dubroff, Jacob Fox, Max Wenqiang Xu","A note on the Erd\H{o}s distinct subset sums problem","Coauthor and a second proof added, 3 pages",,,,"math.CO math.NT math.PR","http://creativecommons.org/licenses/by/4.0/","  We present two short proofs giving the best known asymptotic lower bound for
the maximum element in a set of $n$ positive integers with distinct subset
sums.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:14:38 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jul 2020 15:19:07 GMT""}]","2020-07-21"
"2006.12993","Mao Fabrice Djete","Mao Fabrice Djete","Mean Field Games of Controls: on the convergence of Nash equilibria",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate a class of mean field games where the mean
field interactions are achieved through the joint (conditional) distribution of
the controlled state and the control process. The strategies are of
$open\;loop$ type, and the volatility coefficient $\sigma$ can be controlled.
Using (controlled) Fokker-Planck equations, we introduce a notion of
measure-valued solution of mean-field games of controls, and through
convergence results, prove a relation between these solutions on the one hand,
and the $\epsilon_N$--Nash equilibria on the other hand. It is shown that
$\epsilon_N$--Nash equilibria in the $N$--player games have limits as $N$ tends
to infinity, and each limit is a measure-valued solution of the mean-field
games of controls. Conversely, any measure-valued solution can be obtained as
the limit of a sequence of $\epsilon_N$--Nash equilibria in the $N$--player
games. In other words, the measure-valued solutions are the accumulating points
of $\epsilon_N$--Nash equilibria. Similarly, by considering an
$\epsilon$--strong solution of mean field games of controls which is the
classical strong solution where the optimality is obtained by admitting a small
error $\epsilon,$ we prove that the measure-valued solutions are the
accumulating points of this type of solutions when $\epsilon$ goes to zero.
Finally, existence of measure-valued solution of mean-field games of controls
are proved in the case without common noise.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:49:13 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 19:21:29 GMT""}]","2021-08-05"
"2006.12995","Soumajyoti Sarkar Mr.","Soumajyoti Sarkar, Hamidreza Alvari","Mitigating Bias in Online Microfinance Platforms: A Case Study on
  Kiva.org",,,,,"econ.EM cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the last couple of decades in the lending industry, financial
disintermediation has occurred on a global scale. Traditionally, even for small
supply of funds, banks would act as the conduit between the funds and the
borrowers. It has now been possible to overcome some of the obstacles
associated with such supply of funds with the advent of online platforms like
Kiva, Prosper, LendingClub. Kiva for example, works with Micro Finance
Institutions (MFIs) in developing countries to build Internet profiles of
borrowers with a brief biography, loan requested, loan term, and purpose. Kiva,
in particular, allows lenders to fund projects in different sectors through
group or individual funding. Traditional research studies have investigated
various factors behind lender preferences purely from the perspective of loan
attributes and only until recently have some cross-country cultural preferences
been investigated. In this paper, we investigate lender perceptions of economic
factors of the borrower countries in relation to their preferences towards
loans associated with different sectors. We find that the influence from
economic factors and loan attributes can have substantially different roles to
play for different sectors in achieving faster funding. We formally investigate
and quantify the hidden biases prevalent in different loan sectors using recent
tools from causal inference and regression models that rely on Bayesian
variable selection methods. We then extend these models to incorporate fairness
constraints based on our empirical analysis and find that such models can still
achieve near comparable results with respect to baseline regression models.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 00:22:49 GMT""}]","2020-06-24"
"2006.12996","Mao Fabrice Djete","Mao Fabrice Djete","Extended mean field control problem: a propagation of chaos result",,,,,"math.PR math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the $extended$ mean field control problem, which is a
class of McKean-Vlasov stochastic control problem where the state dynamics and
the reward functions depend upon the joint (conditional) distribution of the
controlled state and the control process. By considering an appropriate
controlled Fokker-Planck equation, we can formulate an optimization problem
over a space of measure-valued processes and, under suitable assumptions, prove
the equivalence between this optimization problem and the $extended$ mean-field
control problem. Moreover, with the help of this new optimization problem, we
establish the associated limit theory i.e. the $extended$ mean field control
problem is the limit of a large population control problem where the
interactions are achieved via the empirical distribution of state and control
processes.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 22:43:26 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 18:00:08 GMT""}]","2022-04-06"
"2006.12999","Ziming Li","Ziming Li, Julia Kiseleva, Alekh Agarwal, Maarten de Rijke, Ryen W.
  White","Optimizing Interactive Systems via Data-Driven Objectives","30 pages, 12 figures. arXiv admin note: text overlap with
  arXiv:1802.06306",,,,"cs.AI cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Effective optimization is essential for real-world interactive systems to
provide a satisfactory user experience in response to changing user behavior.
However, it is often challenging to find an objective to optimize for
interactive systems (e.g., policy learning in task-oriented dialog systems).
Generally, such objectives are manually crafted and rarely capture complex user
needs in an accurate manner. We propose an approach that infers the objective
directly from observed user interactions. These inferences can be made
regardless of prior knowledge and across different types of user behavior. We
introduce Interactive System Optimizer (ISO), a novel algorithm that uses these
inferred objectives for optimization. Our main contribution is a new general
principled approach to optimizing interactive systems using data-driven
objectives. We demonstrate the high effectiveness of ISO over several
simulations.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 20:49:14 GMT""}]","2020-06-24"
"2006.13001","Carlos Mora","Franco Fagnola, Carlos M. Mora","Basic properties of a mean field laser equation","arXiv admin note: substantial text overlap with arXiv:1803.00875","Open Systems & Information DynamicsVol. 26, No. 03, 1950015 (2019)","10.1142/S123016121950015X",,"math-ph math.FA math.MP math.PR quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the non-linear quantum master equation describing a laser under the
mean field approximation. The quantum system is formed by a single mode optical
cavity and two level atoms, which interact with reservoirs. Namely, we
establish the existence and uniqueness of the regular solution to the
non-linear operator equation under consideration, as well as we get a
probabilistic representation for this solution in terms of a mean field
stochastic Schr\""ondiger equation. To this end, we find a regular solution for
the non-autonomous linear quantum master equation in
Gorini-Kossakowski-Sudarshan-Lindblad form, and we prove the uniqueness of the
solution to the non-autonomous linear adjoint quantum master equation in
Gorini-Kossakowski-Sudarshan-Lindblad form. Moreover, we obtain rigorously the
Maxwell-Bloch equations from the mean field laser equation.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:51:44 GMT""}]","2020-06-24"
"2006.13002","Tanya Khovanova","Isha Agarwal, Matvey Borodin, Aidan Duncan, Kaylee Ji, Tanya
  Khovanova, Shane Lee, Boyan Litchev, Anshul Rastogi, Garima Rastogi, Andrew
  Zhao","From Unequal Chance to a Coin Game Dance: Variants of Penney's Game","23 pages, 4 figures, 19 tables",,,,"math.HO math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce and analyze several variations of Penney's game aimed to find a
more equitable game.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:11:27 GMT""}]","2020-06-24"
"2006.13005","Yizhao Qin","Yizhao Qin, Pengfei Yao","The linearized Kirchhoff theory for plates with incompatible prestrain","arXiv admin note: text overlap with arXiv:1503.08845,
  arXiv:1910.00404 by other authors",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we derive a linearized Kirchhoff model from three dimensional
nonlinear elastic energy of plates with incompatible prestrain as its thickness
$h$ tends to zero and its elastic energy scales like $h^{\beta}$ with
$2<\beta<4.$ The incompatible prestrain is given as a Riemannian metric $G(x')$
in the three dimensional thin plate which only depends on mid-plate of the thin
plates. The problem is studied rigorously by using a variational approach and
establishing the $\Gamma-$ limit of the non-Euclidean version of the nonlinear
elasticity functional when the gauss curvature of the mid-plate $(\Omega,
g=G_{2\times2})$ is always positive, negative or zero.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:31:36 GMT""}]","2020-06-24"
"2006.13029","George Georgescu","George Georgescu","Flat topology on prime, maximal and minimal prime spectra of quantales","arXiv admin note: text overlap with arXiv:2006.07829",,,,"math.LO math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several topologies can be defined on the prime, the maximal and the minimal
prime spectra of a commutative ring; among them, we mention the Zariski
topology, the patch topology and the flat topology. By using these topologies,
Tarizadeh and Aghajani obtained recently new characterizations of various
classes of rings: Gelfand rings, clean rings, absolutely flat rings, $mp$ -
rings,etc. The aim of this paper is to generalize some of their results to
quantales, structures that constitute a good abstractization for lattices of
ideals, filters and congruences. We shall study the flat and the patch
topologies on the prime, the maximal and the minimal prime spectra of a
coherent quantale. By using these two topologies one obtains new
characterization theorems for hyperarchimedean quantales, normal quantales,
B-normal quantales, $mp$ - quantales and $PF$ - quantales. The general results
can be applied to several concrete algebras: commutative rings, bounded
distributive lattices, MV-algebras, BL-algebras, residuated lattices,
commutative unital $l$ - groups, etc.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:32:26 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 11:27:04 GMT""}]","2020-06-26"
"2006.13079","Kostas Zoumpatianos","Haridimos Kondylakis, Niv Dayan, Kostas Zoumpatianos, Themis Palpanas","Coconut Palm: Static and Streaming Data Series Exploration Now in your
  Palm",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many modern applications produce massive streams of data series and maintain
them in indexes to be able to explore them through nearest neighbor search.
Existing data series indexes, however, are expensive to operate as they issue
many random I/Os to storage. To address this problem, we recently proposed
Coconut, a new infrastructure that organizes data series based on a new
sortable format. In this way, Coconut is able to leverage state-of-the-art
indexing techniques that rely on sorting for the first time to build, maintain
and query data series indexes using fast sequential I/Os. In this
demonstration, we present Coconut Palm, a new exploration tool that allows to
interactively combine different indexing techniques from within the Coconut
infrastructure and to thereby seamlessly explore data series from across
various scientific domains. We highlight the rich indexing design choices that
Coconut opens up, and we present a new recommender tool that allows users to
intelligently navigate them for both static and streaming data exploration
scenarios.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 02:25:34 GMT""}]","2020-06-24"
"2006.13350","Yifan Sun","Yifan Sun and Xihong Wu","Embodied Self-supervised Learning by Coordinated Sampling and Training",,,,,"eess.AS cs.LG cs.SD stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised learning can significantly improve the performance of
downstream tasks, however, the dimensions of learned representations normally
lack explicit physical meanings. In this work, we propose a novel
self-supervised approach to solve inverse problems by employing the
corresponding physical forward process so that the learned representations can
have explicit physical meanings. The proposed approach works in an
analysis-by-synthesis manner to learn an inference network by iteratively
sampling and training. At the sampling step, given observed data, the inference
network is used to approximate the intractable posterior, from which we sample
input parameters and feed them to a physical process to generate data in the
observational space; At the training step, the same network is optimized with
the sampled paired data. We prove the feasibility of the proposed method by
tackling the acoustic-to-articulatory inversion problem to infer articulatory
information from speech. Given an articulatory synthesizer, an inference model
can be trained completely from scratch with random initialization. Our
experiments demonstrate that the proposed method can converge steadily and the
network learns to control the articulatory synthesizer to speak like a human.
We also demonstrate that trained models can generalize well to unseen speakers
or even new languages, and performance can be further improved through
self-adaptation.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:05:47 GMT""},{""version"":""v2"",""created"":""Sun, 16 Jan 2022 09:33:33 GMT""}]","2022-01-19"
"2006.13713","Kostas Zoumpatianos","Haridimos Kondylakis, Niv Dayan, Kostas Zoumpatianos, Themis Palpanas","Coconut: a scalable bottom-up approach for building data series indexes","arXiv admin note: substantial text overlap with arXiv:2006.11474",,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many modern applications produce massive amounts of data series that need to
be analyzed, requiring efficient similarity search operations. However, the
state-of-the-art data series indexes that are used for this purpose do not
scale well for massive datasets in terms of performance, or storage costs. We
pinpoint the problem to the fact that existing summarizations of data series
used for indexing cannot be sorted while keeping similar data series close to
each other in the sorted order. This leads to two design problems. First,
traditional bulk-loading algorithms based on sorting cannot be used. Instead,
index construction takes place through slow top-down insertions, which create a
non-contiguous index that results in many random I/Os. Second, data series
cannot be sorted and split across nodes evenly based on their median value;
thus, most leaf nodes are in practice nearly empty. This further slows down
query speed and amplifies storage costs. To address these problems, we present
Coconut. The first innovation in Coconut is an inverted, sortable data series
summarization that organizes data series based on a z-order curve, keeping
similar series close to each other in the sorted order. As a result, Coconut is
able to use bulk-loading techniques that rely on sorting to quickly build a
contiguous index using large sequential disk I/Os. We then explore prefix-based
and median-based splitting policies for bottom-up bulk-loading, showing that
median-based splitting outperforms the state of the art, ensuring that all
nodes are densely populated. Overall, we show analytically and empirically that
Coconut dominates the state-of-the-art data series indexes in terms of
construction speed, query speed, and storage costs.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 01:52:13 GMT""}]","2020-06-25"
"2006.13809","Renato J.M. e Silva","Renato J.M. e Silva, Llohann D. Speran\c{c}a","On the completeness of dual foliations on nonnegatively curved symmetric
  spaces","6 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove Wilking's Conjecture about the completeness of dual leaves for the
case of Riemannian foliations on nonnegatively curved symmetric spaces.
Moreover, we conclude that such foliations split as a product of trivial
foliations and a foliation with a single dual leaf.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 14:22:11 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 22:32:04 GMT""}]","2020-06-30"
"2006.14051","Alexander Shamanskiy","Alexander Shamanskiy and Bernd Simeon","Mesh deformation techniques in fluid-structure interaction: robustness,
  accumulated distortion and computational efficiency",,,,,"cs.CE cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An important ingredient of any moving-mesh method for fluid-structure
interaction (FSI) problems is the mesh deformation technique (MDT) used to
adapt the computational mesh in the moving fluid domain. An ideal technique is
computationally inexpensive, can handle large mesh deformations without
inverting mesh elements and can sustain an FSI simulation for extensive periods
ot time without irreversibly distorting the mesh. Here we compare several
commonly used techniques based on the solution of elliptic partial differential
equations, including harmonic extension, bi-harmonic extension and techniques
based on the equations of linear elasticity. Moreover, we propose a novel
technique which utilizes ideas from continuation methods to efficiently solve
the equations of nonlinear elasticity and proves to be robust even when the
mesh is subject to extreme deformations. In addition to that, we study how each
technique performs when combined with the Jacobian-based local stiffening. We
evaluate each technique on a popular two-dimensional FSI benchmark reproduced
by using an isogeometric partitioned solver with strong coupling.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 18:40:12 GMT""}]","2020-06-26"
"2006.14373","Priyanka Priyanka","Priyanka and Vicky Verma","Study of lockdown/testing mitigation strategies on stochastic SIR model
  and its comparison with South Korea, Germany and New York data",,,,,"physics.soc-ph q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are currently facing a highly critical case of a world-wide pandemic. The
novel coronavirus (SARS-CoV-2, a.k.a. COVID-19) has proved to be extremely
contagious and the original outbreak from Asia has now spread to all
continents. This situation will fruitfully profit from the study in regards of
the spread of the virus, assessing effective countermeasures to weight the
impact of the adopted strategies. The standard Susceptible-Infectious-Recovered
(SIR) model is a very successful and widely used mathematical model for
predicting the spread of an epidemic. We adopt the SIR model on a random
network and extend the model to include control strategies {\em lockdown} and
{\em testing} -- two often employed mitigation strategies. The ability of these
strategies in controlling the pandemic spread is investigated by varying the
effectiveness with which they are implemented. The possibility of a second
outbreak is evaluated in detail after the mitigation strategies are withdrawn.
We notice that, in any case, a sudden interruption of such mitigation
strategies will likely induce a resurgence of a second outbreak, whose peak
will be correlated to the number of susceptible individuals. In fact, we find
that a population will remain vulnerable to the infection until the herd
immunity is achieved. We also test our model with real statistics and
information on the epidemic spread in South Korea, Germany, and New York and
find a remarkable agreement with the simulation data.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:55:16 GMT""}]","2020-06-26"
"2006.14929","Reinaldo Resende de Oliveira","Reinaldo Resende de Oliveira","On clusters and the multi-isoperimetric profile in Riemannian manifolds
  with bounded geometry","22 pages",,,,"math.DG math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a complete Riemannian manifold with bounded geometry, we prove the
existence of isoperimetric clusters and also the compactness theorem for
sequence of clusters in a larger space obtained by adding finitely many limit
manifolds at infinity. Moreover, we show that isoperimetric clusters are
bounded. We introduce and prove the Holder continuity of the
multi-isoperimetric profile which has been explored by Emanuel Milman and Joe
Neeman with a Gaussian-weighted notion of perimeter. We yield a proof of
classical existence theorem, e.g. in space forms, for isoperimetric cluster
using the results presented here. The results in this work generalize previous
works of Stefano Nardulli, Andrea Mondino, Frank Morgan, Matteo Galli and
Manuel Ritor\'e from the classical Riemannian and sub-Riemannian isoperimetric
problem to the context of Riemannian isoperimetric clusters and also Frank
Morgan and Francesco Maggi works on the clusters theory in the Euclidean
setting.
","[{""version"":""v1"",""created"":""Fri, 19 Jun 2020 19:36:22 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 19:24:09 GMT""},{""version"":""v3"",""created"":""Sun, 28 Mar 2021 12:20:54 GMT""}]","2021-03-30"
"2006.15989","Muhammad Usman","Muhammad Usman","Polarization Independent Ground State Optical Transitions in Closely
  Stacked InAs/GaAs Columnar Quantum Dots","2 pages, 2 figures, conference extended abstract",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents an analysis of the electronic and optical properties of
InAs/GaAs columnar quantum dots (QDs) by performing multi-million-atom
tight-binding simulations. The plots of the polarisation-dependent ground state
optical transition strengths predict that a nearly zero degree of polarisation
can be achieved at 1550 nm emission/absorption wavelength by engineering the
number of QD layers in a columnar QD. These results are promising for the
design of optical devices requiring polarisation insensitive optical response
such as semiconductor optical amplifiers.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 05:44:52 GMT""}]","2020-06-30"
"2006.15990","Atila Poro","Farzaneh Ahangarani Farahani, Atila Poro, Maryam Rezaee, Mehdi Sameni","Enhancement in Power Conversion Efficiency of CdS Quantum Dot Sensitized
  Solar Cells Through a Decrease in Light Reflection","12 pages, 10 figures, 1 table, sent it to Optical Materials",,,,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this research, the effect of Magnesium Fluoride (MgF2) Anti-Reflection
(AR) layer was investigated in quantum dot sensitized solar cells (QDSCs). MgF2
nanoparticles with the dominant size of 20 nm were grown by a thermal
evaporation method and a thin layer was formed on the front side of the
fluorine-doped tin oxide (FTO) substrate. In order to study the effect of the
AR layer on the efficiency of solar cells, this substrate was utilized in CdS
QDSCs. In this conventional structure of QDSC, TiO2 nanocrystals (NCs) were
applied on the FTO substrate, and then it was sensitized with CdS quantum dots
(QDs). According to the results, the QDSCs with MgF2 AR layer represented the
maximum Power Conversion Efficiency (PCE) of 3%. This efficiency was increased
by about 47% compared to the reference cell without the AR layer. The reason is
attributed to the presence of the AR layer and the reduction of incident light
reflected from the surface of the solar cell.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 04:57:30 GMT""}]","2020-06-30"
"2006.16863","Jan Dvorak","Jan Dvo\v{r}\'ak, Martin Heller, Zden\v{e}k Hanz\'alek","Makespan minimization of Time-Triggered traffic on a TTEthernet network",,,"10.1109/WFCS.2017.7991955.",,"cs.NI cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The reliability of the increasing number of modern applications and systems
strongly depends on interconnecting technology. Complex systems which usually
need to exchange, among other things, multimedia data together with
safety-related information, as in the automotive or avionic industry, for
example, make demands on both the high bandwidth and the deterministic behavior
of the communication. TTEthernet is a protocol that has been developed to face
these requirements while providing the generous bandwidth of Ethernet up to
1\,Gbit/s and enhancing its determinism by the Time-Triggered message
transmission which follows the predetermined schedule. Therefore, synthesizing
a good schedule which meets all the real-time requirements is essential for the
performance of the whole system.
  In this paper, we study the concept of creating the communication schedules
for the Time-Triggered traffic while minimizing its makespan. The aim is to
maximize the uninterrupted gap for remaining traffic classes in each
integration cycle. The provided scheduling algorithm, based on the
Resource-Constrained Project Scheduling Problem formulation and the load
balancing heuristic, obtains near-optimal (within 15\% of non-tight lower
bound) solutions in 5 minutes even for industrial sized instances. The
universality of the provided method allows easily modify or extend the problem
statement according to particular industrial demands. Finally, the studied
concept of makespan minimization is justified through the concept of scheduling
with porosity according to the worst-case delay analysis of Event-Triggered
traffic.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 12:04:40 GMT""}]","2020-07-01"
"2007.12063","Olga Krestinskaya","Olga Krestinskaya, Bhaskar Choubey, Alex Pappachen James","AM-DCGAN: Analog Memristive Hardware Accelerator for Deep Convolutional
  Generative Adversarial Networks",,,,,"cs.ET cs.NE eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative Adversarial Network (GAN) is a well known computationally complex
algorithm requiring signficiant computational resources in software
implementations including large amount of data to be trained. This makes its
implementation in edge devices with conventional microprocessor hardware a slow
and difficult task. In this paper, we propose to accelerate the computationally
intensive GAN using memristive neural networks in analog domain. We present a
fully analog hardware design of Deep Convolutional GAN (DCGAN) based on
CMOS-memristive convolutional and deconvolutional networks simulated using
180nm CMOS technology.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:37:29 GMT""}]","2020-07-24"
"2007.13487","Md. Abu Bakr Siddique","Shadman Sakib, Md. Abu Bakr Siddique, Md. Abdur Rahman","Performance Evaluation of t-SNE and MDS Dimensionality Reduction
  Techniques with KNN, ENN and SVM Classifiers","2020 IEEE Region 10 Symposium (TENSYMP), 5-7 June 2020, Dhaka,
  Bangladesh","2020 IEEE Region 10 Symposium (TENSYMP)","10.1109/TENSYMP50017.2020.9230983",,"cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The central goal of this paper is to establish two commonly available
dimensionality reduction (DR) methods i.e. t-distributed Stochastic Neighbor
Embedding (t-SNE) and Multidimensional Scaling (MDS) in Matlab and to observe
their application in several datasets. These DR techniques are applied to nine
different datasets namely CNAE9, Segmentation, Seeds, Pima Indians diabetes,
Parkinsons, Movement Libras, Mammographic Masses, Knowledge, and Ionosphere
acquired from UCI machine learning repository. By applying t-SNE and MDS
algorithms, each dataset is transformed to the half of its original dimension
by eliminating unnecessary features from the datasets. Subsequently, these
datasets with reduced dimensions are fed into three supervised classification
algorithms for classification. These classification algorithms are K Nearest
Neighbors (KNN), Extended Nearest Neighbors (ENN), and Support Vector Machine
(SVM). Again, all these algorithms are implemented in Matlab. The training and
test data ratios are maintained as ninety percent: ten percent for each
dataset. Upon accuracy observation, the efficiency for every dimensionality
technique with availed classification algorithms is analyzed and the
performance of each classifier is evaluated.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 08:13:42 GMT""}]","2020-11-19"
"2008.02629","Azqueta Gavaldon Andres Dr.","Monica Azqueta-Gavaldon, Gonzalo Azqueta-Gavaldon, Inigo
  Azqueta-Gavaldon, and Andres Azqueta-Gavaldon","Developing a real estate yield investment deviceusing granular data and
  machine learning",,,,,"q-fin.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This project aims at creating an investment device to help investors
determine which real estate units have a higher return to investment in Madrid.
To do so, we gather data from Idealista.com, a real estate web-page with
millions of real estate units across Spain, Italy and Portugal. In this
preliminary version, we present the road map on how we gather the data;
descriptive statistics of the 8,121 real estate units gathered (rental and
sale); build a return index based on the difference in prices of rental and
sale units(per neighbourhood and size) and introduce machine learning
algorithms for rental real estate price prediction.
","[{""version"":""v1"",""created"":""Sat, 20 Jun 2020 15:42:12 GMT""}]","2020-08-07"
