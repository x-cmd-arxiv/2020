"2006.07281","Juba Ziani","Emily Diana, Travis Dick, Hadi Elzayn, Michael Kearns, Aaron Roth,
  Zachary Schutzman, Saeed Sharifi-Malvajerdi, Juba Ziani","Algorithms and Learning for Fair Portfolio Design",,,,,"cs.LG cs.CE cs.GT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a variation on the classical finance problem of optimal portfolio
design. In our setting, a large population of consumers is drawn from some
distribution over risk tolerances, and each consumer must be assigned to a
portfolio of lower risk than her tolerance. The consumers may also belong to
underlying groups (for instance, of demographic properties or wealth), and the
goal is to design a small number of portfolios that are fair across groups in a
particular and natural technical sense.
  Our main results are algorithms for optimal and near-optimal portfolio design
for both social welfare and fairness objectives, both with and without
assumptions on the underlying group structure. We describe an efficient
algorithm based on an internal two-player zero-sum game that learns
near-optimal fair portfolios ex ante and show experimentally that it can be
used to obtain a small set of fair portfolios ex post as well. For the special
but natural case in which group structure coincides with risk tolerances (which
models the reality that wealthy consumers generally tolerate greater risk), we
give an efficient and optimal fair algorithm. We also provide generalization
guarantees for the underlying risk distribution that has no dependence on the
number of portfolios and illustrate the theory with simulation results.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:00:41 GMT""}]","2020-06-15"
"2006.07282","Marco Tezzele","Nicola Demo and Marco Tezzele and Gianluigi Rozza","A supervised learning approach involving active subspaces for an
  efficient genetic algorithm in high-dimensional optimization problems",,,"10.1137/20M1345219",,"math.NA cs.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present an extension of the genetic algorithm (GA) which
exploits the supervised learning technique called active subspaces (AS) to
evolve the individuals on a lower dimensional space. In many cases, GA requires
in fact more function evaluations than others optimization method to converge
to the global optimum. Thus, complex and high-dimensional functions may result
extremely demanding (from computational viewpoint) to optimize with the
standard algorithm. To address this issue, we propose to linearly map the input
parameter space of the original function onto its AS before the evolution,
performing the mutation and mate processes in a lower dimensional space. In
this contribution, we describe the novel method called ASGA, presenting
differences and similarities with the standard GA method. We test the proposed
method over n-dimensional benchmark functions -- Rosenbrock, Ackley,
Bohachevsky, Rastrigin, Schaffer N. 7, and Zakharov -- and finally we apply it
to an aeronautical shape optimization problem.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:03:49 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jan 2021 10:24:27 GMT""}]","2021-07-13"
"2006.07283","Erik Tjong Kim Sang","Shihan Wang, Marijn Schraagen, Erik Tjong Kim Sang and Mehdi Dastani","Dutch General Public Reaction on Governmental COVID-19 Measures and
  Announcements in Twitter Data","25 pages, 8 figures",,,,"cs.SI cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Public sentiment (the opinions, attitudes or feelings expressed by the
public) is a factor of interest for government, as it directly influences the
implementation of policies. Given the unprecedented nature of the COVID-19
crisis, having an up-to-date representation of public sentiment on governmental
measures and announcements is crucial. While the 'staying-at-home' policy makes
face-to-face interactions and interviews challenging, analysing real-time
Twitter data that reflects public opinion toward policy measures is a
cost-effective way to access public sentiment. In this context, we collect
streaming data using the Twitter API starting from the COVID-19 outbreak in the
Netherlands in February 2020, and track Dutch general public reactions on
governmental measures and announcements. We provide temporal analysis of tweet
frequency and public sentiment over the past seven months. We also identify
public attitudes towards two Dutch policies in case studies: one regarding
social distancing and one regarding wearing face masks. By presenting those
preliminary results, we aim to provide visibility into the social media
discussions around COVID-19 to the general public, scientists and policy
makers. The data collection and analysis will be updated and expanded over
time.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:03:58 GMT""},{""version"":""v2"",""created"":""Tue, 29 Sep 2020 10:10:35 GMT""},{""version"":""v3"",""created"":""Mon, 21 Dec 2020 19:53:55 GMT""}]","2020-12-23"
"2006.07284","Bernard Legras","Sergey Khaykin, Bernard Legras, Silvia Bucci, Pasquale Sellitto, Lars
  Isaksen, Florent Tence, Slimane Bekki, Adam Bourassa, Landon Rieger, Daniel
  Zawada, Julien Jumelet, and Sophie Godin-Beekman","The 2019/20 Australian wildfires generated a persistent smoke-charged
  vortex rising up to 35 km altitude","to appear in Communications Earth & Environment","Communications Earth and Environment, 2020","10.1038/s43247-020-00022-5",,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  The Australian bushfires around the turn of the year 2020 generated an
unprecedented perturbation of stratospheric composition, dynamical circulation
and radiative balance. Here we show from satellite observations that the
resulting planetary-scale blocking of solar radiation by the smoke is larger
than any previously documented wildfires and of the same order as the radiative
forcing produced by moderate volcanic eruptions. A striking effect of the solar
heating of an intense smoke patch was the generation of a self-maintained
anticyclonic vortex measuring 1000 km in diameter and featuring its own ozone
hole. The highly stable vortex persisted in the stratosphere for over 13 weeks,
travelled 66,000 km and lifted a confined bubble of smoke and moisture to 35 km
altitude. Its evolution was tracked by several satellite-based sensors and was
successfully resolved by the European Centre for Medium-Range Weather Forecasts
operational system, primarily based on satellite data. Because wildfires are
expected to increase in frequency and strength in a changing climate, we
suggest that extraordinary events of this type may contribute significantly to
the global stratospheric composition in the coming decades.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:07:47 GMT""},{""version"":""v2"",""created"":""Mon, 24 Aug 2020 21:04:15 GMT""}]","2020-11-26"
"2006.07285","Emine Y{\i}ld{\i}r{\i}m","Charles Paquette and Emine Yildirim","Completions of discrete cluster categories of type $\mathbb{A}$","33 pages, 11 figures",,"10.1112/tlm3.12025",,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We complete the discrete cluster categories of type $\mathbb{A}$ as defined
by Igusa and Todorov, by embedding such a discrete cluster category inside a
larger one, and then taking a certain Verdier quotient. The resulting category
is a Hom-finite Krull-Schmidt triangulated category containing the discrete
cluster category as a full subcategory. The objects and Hom-spaces in this new
category can be described geometrically, even though the category is not
$2$-Calabi-Yau and Ext-spaces are not always symmetric. We describe all
cluster-tilting subcategories. Given such a subcategory, we define a cluster
character that takes values in a ring with infinitely many indeterminates. Our
cluster character is new in that it takes into account infinite dimensional
sub-representations of infinite dimensional ones. We show that it satisfies the
multiplication formula and also the exchange formula, provided that the objects
being exchanged satisfy some local Calabi-Yau conditions.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:09:41 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 21:27:47 GMT""}]","2021-02-03"
"2006.07286","Evgenii Chzhen","Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto,
  Massimiliano Pontil","Fair Regression with Wasserstein Barycenters",,,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of learning a real-valued function that satisfies the
Demographic Parity constraint. It demands the distribution of the predicted
output to be independent of the sensitive attribute. We consider the case that
the sensitive attribute is available for prediction. We establish a connection
between fair regression and optimal transport theory, based on which we derive
a close form expression for the optimal fair predictor. Specifically, we show
that the distribution of this optimum is the Wasserstein barycenter of the
distributions induced by the standard regression function on the sensitive
groups. This result offers an intuitive interpretation of the optimal fair
prediction and suggests a simple post-processing algorithm to achieve fairness.
We establish risk and distribution-free fairness guarantees for this procedure.
Numerical experiments indicate that our method is very effective in learning
fair models, with a relative increase in error rate that is inferior to the
relative gain in fairness.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:10:41 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 13:22:01 GMT""}]","2020-06-24"
"2006.07287","Christoph Schwanda","P. Gambino, A.S. Kronfeld, M. Rotondo, C. Schwanda, F. Bernlochner, A.
  Bharucha, C. Bozzi, M. Calvi, L. Cao, G. Ciezarek, C.T.H. Davies, A.X.
  El-Khadra, S. Hashimoto, M. Jung, A. Khodjamirian, Z. Ligeti, E. Lunghi, V.
  Luth, T. Mannel, S. Meinel, G. Paz, S. Schacht, S. Simula, W. Sutcliffe, A.
  Vaquero Aviles-Casco","Challenges in Semileptonic B Decays","77 pages","Eur. Phys. J. C 80, 966 (2020)","10.1140/epjc/s10052-020-08490-x","FERMILAB-PUB-20-235-T","hep-ph hep-ex hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two of the elements of the Cabibbo-Kobayashi-Maskawa quark mixing matrix,
$|V_{ub}|$ and $|V_{cb}|$, are extracted from semileptonic B decays. The
results of the B factories, analysed in the light of the most recent
theoretical calculations, remain puzzling, because for both $|V_{ub}|$ and
$|V_{cb}|$ the exclusive and inclusive determinations are in clear tension.
Further, measurements in the $\tau$ channels at Belle, Babar, and LHCb show
discrepancies with the Standard Model predictions, pointing to a possible
violation of lepton flavor universality. LHCb and Belle II have the potential
to resolve these issues in the next few years. This article summarizes the
discussions and results obtained at the MITP workshop held on April 9--13,
2018, in Mainz, Germany, with the goal to develop a medium-term strategy of
analyses and calculations aimed at solving the puzzles. Lattice and continuum
theorists working together with experimentalists have discussed how to reshape
the semileptonic analyses in view of the much higher luminosity expected at
Belle II, searching for ways to systematically validate the theoretical
predictions in both exclusive and inclusive B decays, and to exploit the rich
possibilities at LHCb.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:11:26 GMT""},{""version"":""v2"",""created"":""Thu, 15 Oct 2020 11:40:59 GMT""}]","2020-10-26"
"2006.07288","Suraj Krishna M. S.","Fran\c{c}ois Dahmani, Suraj Krishna M S","Relative hyperbolicity of hyperbolic-by-cyclic groups","21 pages, 1 figure. v2: Incorporates referee comments",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be a torsion-free hyperbolic group and $\alpha$ an automorphism of
$G$. We show that there exists a canonical collection of subgroups that are
polynomially growing under $\alpha$, and that the mapping torus of $G$ by
$\alpha$ is hyperbolic relative to the suspensions of the maximal polynomially
growing subgroups under $\alpha$.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:11:28 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 05:24:48 GMT""}]","2021-08-25"
"2006.07289","Charles Galdies Dr","Stephen M Brincat, Charles Galdies and Kevin Hills","Carbon Star CGCS 673 identified as a Semi-regular variable star","6 pages, 3 figures, 4 tables","Research in Astronomy and Astrophysics. RAA-2020-0119","10.1088/1674-4527/20/11/177",,"astro-ph.SR astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study shows that the carbon star CGCS 673 is a semi-regular (SR)
variable star with a period of 135 d and an amplitude of 0.18 magnitudes in the
V-band. The light curve obtained by this study correlates well with the SR
classification as the photometric data obtained shows noticeable periodicity in
the light changes of CGCS 673 that is occasionally interrupted by a period of
irregular variability. The derived period and colour index obtained from our
data and those from professional databases indicate that the at-tributes of
this star fall within the parameters of the Semi-Regular class of variable
stars. Following our notification of the discovery that this star is a variable
source, CGCS 673 has received the AAVSO Unique Identifier as (AAVSO UID)
000-BMZ-492.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:11:39 GMT""}]","2020-12-02"
"2006.07290","Oscar Loaiza-Brito","Nana Cabo Bizet, Cesar Damian, Oscar Loaiza-Brito, Dami\'an Kaloni
  Mayorga Pe\~na and J.A. Monta\~nez-Barrera","Testing Swampland Conjectures with Machine Learning","30 pages, 14 Figures. (v2) References added",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider Type IIB compactifications on an isotropic torus $T^6$ threaded
by geometric and non geometric fluxes. For this particular setup we apply
supervised machine learning techniques, namely an artificial neural network
coupled to a genetic algorithm, in order to obtain more than sixty thousand
flux configurations yielding to a scalar potential with at least one critical
point. We observe that both stable AdS vacua with large moduli masses and small
vacuum energy as well as unstable dS vacua with small tachyonic mass and large
energy are absent, in accordance to the Refined de Sitter Conjecture. Moreover,
by considering a hierarchy among fluxes, we observe that perturbative solutions
with small values for the vacuum energy and moduli masses are favored, as well
as scenarios in which the lightest modulus mass is much greater than the
corresponding AdS vacuum scale. Finally we apply some results on Random Matrix
Theory to conclude that the most probable mass spectrum derived from this
string setup is that satisfying the Refined de Sitter and AdS scale
conjectures.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:12:17 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 17:10:58 GMT""}]","2020-06-30"
"2006.07291","Holger Dette","Holger Dette, Kevin Kokot","Detecting relevant differences in the covariance operators of functional
  time series -- a sup-norm approach",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose statistical inference tools for the covariance
operators of functional time series in the two sample and change point problem.
In contrast to most of the literature the focus of our approach is not testing
the null hypothesis of exact equality of the covariance operators. Instead we
propose to formulate the null hypotheses in them form that ""the distance
between the operators is small"", where we measure deviations by the sup-norm.
We provide powerful bootstrap tests for these type of hypotheses, investigate
their asymptotic properties and study their finite sample properties by means
of a simulation study.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:15:56 GMT""}]","2020-06-15"
"2006.07292","Bishwamittra Ghosh","Bishwamittra Ghosh and Daniel Neider","A Formal Language Approach to Explaining RNNs",,,,,"cs.AI cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents LEXR, a framework for explaining the decision making of
recurrent neural networks (RNNs) using a formal description language called
Linear Temporal Logic (LTL). LTL is the de facto standard for the specification
of temporal properties in the context of formal verification and features many
desirable properties that make the generated explanations easy for humans to
interpret: it is a descriptive language, it has a variable-free syntax, and it
can easily be translated into plain English. To generate explanations, LEXR
follows the principle of counterexample-guided inductive synthesis and combines
Valiant's probably approximately correct learning (PAC) with constraint
solving. We prove that LEXR's explanations satisfy the PAC guarantee (provided
the RNN can be described by LTL) and show empirically that these explanations
are more accurate and easier-to-understand than the ones generated by recent
algorithms that extract deterministic finite automata from RNNs.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:17:53 GMT""}]","2020-06-15"
"2006.07293","Isabell Piantschitsch","I. Piantschitsch, J. Terradas, M. Temmer","A new method for estimating global coronal wave properties from their
  interaction with solar coronal holes",,"A&A 641, A21 (2020)","10.1051/0004-6361/202038182",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Global coronal waves (CWs) and their interaction with coronal holes (CHs)
result, among other effects, in the formation of reflected and transmitted
waves. Observations of such events provide us with measurements of different CW
parameters, such as phase speed and intensity amplitudes. However, several of
these parameters are provided with only intermediate observational quality,
other parameters, such as the phase speed of transmitted waves, can hardly be
observed in general. We present a new method to estimate crucial CW parameters,
such as density and phase speed of reflected as well as transmitted waves, Mach
numbers and density values of the CH's interior, by using analytical
expressions in combination with basic and most accessible observational
measurements. The transmission and reflection coefficients are derived from
linear theory and subsequently used to calculate estimations for phase speeds
of incoming, reflected and transmitted waves. The obtained analytical
expressions are validated by performing numerical simulations of CWs
interacting with CHs. This new method enables to determine in a fast and
straightforward way reliable CW and CH parameters from basic observational
measurements which provides a powerful tool to better understand the observed
interaction effects between CWs and CHs.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:19:14 GMT""}]","2020-09-02"
"2006.07294","Rebecca Friesen","Rebecca Fenton Friesen, Roberta L. Klatzky, Michael A. Peshkin, J.
  Edward Colgate","Building a navigable fine texture design space",,,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Friction modulation technology enables the creation of textural effects on
flat haptic displays. However, an intuitive and manageably small design space
for construction of such haptic textures remains an unfulfilled goal for user
interface designers. In this paper, we explore perceptually relevant features
of fine texture for use in texture construction and modification. Beginning
with simple sinusoidal patterns of friction force that vary in frequency and
amplitude, we define irregularity as a third building block of a texture
pattern and show it to be a scalable feature distinct from the others using
multidimensional scaling. Additionally, subjects' verbal descriptions of this
3-dimensional design space provide insight into their intuitive interpretation
of the physical parameter changes.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:22:09 GMT""}]","2020-06-15"
"2006.07295","Duygu Vargun","Matthew Gardner, Adam Larios, Leo G. Rebholz, Duygu Vargun, Camille
  Zerfas","Continuous data assimilation applied to a velocity-vorticity formulation
  of the 2D Navier-Stokes equations","28 pages, 8 figures, 2 tables",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a continuous data assimilation (CDA) algorithm for a
velocity-vorticity formulation of the 2D Navier-Stokes equations in two cases:
nudging applied to the velocity and vorticity, and nudging applied to the
velocity only. We prove that under a typical finite element spatial
discretization and backward Euler temporal discretization, application of CDA
preserves the unconditional long-time stability property of the
velocity-vorticity method and provides optimal long-time accuracy. These
properties hold if nudging is applied only to the velocity, and if nudging is
also applied to the vorticity then the optimal long-time accuracy is achieved
more rapidly in time. Numerical tests illustrate the theory, and show its
effectiveness on an application problem of channel flow past a flat plate.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:24:04 GMT""}]","2020-06-15"
"2006.07296","Yitong Tseo","Yitong Tseo, M. I. Salkola, Ahmed Mohamed, Anuj Kumar, Freddy Abnousi","Information Extraction of Clinical Trial Eligibility Criteria","4 pages",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Clinical trials predicate subject eligibility on a diversity of criteria
ranging from patient demographics to food allergies. Trials post their
requirements as semantically complex, unstructured free-text. Formalizing trial
criteria to a computer-interpretable syntax would facilitate eligibility
determination. In this paper, we investigate an information extraction (IE)
approach for grounding criteria from trials in ClinicalTrials(dot)gov to a
shared knowledge base. We frame the problem as a novel knowledge base
population task, and implement a solution combining machine learning and
context free grammar. To our knowledge, this work is the first criteria
extraction system to apply attention-based conditional random field
architecture for named entity recognition (NER), and word2vec embedding
clustering for named entity linking (NEL). We release the resources and core
components of our system on GitHub at
https://github.com/facebookresearch/Clinical-Trial-Parser. Finally, we report
our per module and end to end performances; we conclude that our system is
competitive with Criteria2Query, which we view as the current state-of-the-art
in criteria extraction.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:25:45 GMT""},{""version"":""v2"",""created"":""Mon, 15 Jun 2020 02:37:49 GMT""},{""version"":""v3"",""created"":""Tue, 16 Jun 2020 01:44:36 GMT""},{""version"":""v4"",""created"":""Thu, 16 Jul 2020 22:36:50 GMT""},{""version"":""v5"",""created"":""Fri, 24 Jul 2020 23:48:48 GMT""},{""version"":""v6"",""created"":""Tue, 28 Jul 2020 17:50:42 GMT""}]","2020-07-29"
"2006.07297","Huan Liu","Zhaofeng Lv (1), Xiaotong Wang (1), Fanyuan Deng (1), Qi Ying (2),
  Alexander T. Archibald (3), Roderic L. Jones (3), Yan Ding (4), Ying Cheng
  (5), Mingliang Fu (4), Ying Liu (5), Hanyang Man (1), Zhigang Xue (4), Kebin
  He (1), Jiming Hao (1) and Huan Liu (1) ((1) State Key Joint Laboratory of
  ESPC, State Environmental Protection Key Laboratory of Sources and Control of
  Air Pollution Complex, International Joint Laboratory on Low Carbon Clean
  Energy Innovation, School of the Environment, Tsinghua University, China, (2)
  Zachry Department of Civil and Environmental Engineering, Texas A&M
  University, USA, (3) Centre for Atmospheric Science, Department of Chemistry,
  University of Cambridge, UK, (4) Chinese Research Academy of Environmental
  Sciences, (5) Beijing Transport Institute)","Significant reduced traffic in Beijing failed to relieve haze pollution
  during the COVID-19 lockdown: implications for haze mitigation","52 pages, 24 figures, 4 tables",,,,"physics.ao-ph physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The COVID-19 outbreak greatly limited human activities and reduced primary
emissions particularly from urban on-road vehicles, but coincided with Beijing
experiencing pandemic haze, raising the public concerns of the validity and
effectiveness of the imposed traffic policies to improve the air pollution.
Here, we explored the relationship between local vehicle emissions and the
winter haze in Beijing before and during the COVID-19 lockdown period based on
an integrated analysis framework, which combines a real-time on-road emission
inventory, in-situ air quality observations and a localized chemical transport
modeling system. We found that traffic emissions decreased substantially
affected by the pandemic, with a higher reduction for NOx (75.9%, 125.3 Mg/day)
compared to VOCs (53.1%, 52.9 Mg/day). Unexpectedly, our results show that the
imbalanced emission abatement of NOx and VOCs from vehicles led to a
significant rise of the atmospheric oxidizing capacity in urban areas, but only
resulting in modest increases in secondary aerosols due to the inadequate
precursors. However, the enhanced oxidizing capacity in the surrounding regions
greatly increased the secondary particles with relatively abundant precursors,
which is mainly responsible for Beijing haze during the lockdown period. Our
results indicate that the winter haze in Beijing was insensitive to the local
vehicular emissions reduction due to the complicated nonlinear response of the
fine particle and air pollutant emissions. We suggest mitigation policies
should focus on accelerating VOC and NH3 emissions reduction and synchronously
controlling regional sources to release the benefits on local traffic emission
control.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:25:46 GMT""}]","2020-06-15"
"2006.07298","Jan Tuziemski","Jan Tuziemski","Decoherence and information encoding in quantum reference frames","7 pages, 2 figures; v2: typos corrected",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reference frames are of special importance in physics. They are usually
considered to be idealized entities. However, in most situations, e.g. in
laboratories, physical processes are described within reference frames
constituted by physical systems. As new technological developments make it
possible to demonstrate quantum properties of complex objects an interesting
conceptual problem arises: Could one use states of quantum systems to define
reference frames? Recently such a framework has been introduced in [F.
Giacomini, E. Castro-Ruiz, and \v{C}. Brukner, Nat Commun 10, 494 (2019)]. One
of its consequences is the fact that quantum correlations depend on a physical
state of an observers reference frame. The aim of this work is to examine the
dynamical aspect of this phenomena and show that the same is true for
correlations established during an evolution of a composite systems. Therefore,
decoherence process is also relative: For some observers the reduced evolution
of subsystems is unitary, whereas for others not. I also discuss implications
of this results for modern developments of decoherence theory: Quantum
Darwinism and Spectrum Broadcast Structures.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:29:38 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 12:26:55 GMT""}]","2020-06-26"
"2006.07299","Farhan Islam","Farhan Islam, Renu Choudhary, Yong Liu, Benjamin G. Ueland, Durga
  Paudyal, Thomas Heitmann, Robert J. McQueeney, David Vaknin","Controlling Magnetic Order, Magnetic Anisotropy, and Band Topology in
  Semimetals ${\rm Sr(Mn_{0.9}Cu_{0.1})Sb_2}$ and ${\rm
  Sr(Mn_{0.9}Zn_{0.1})Sb_2}$",,"Phys. Rev. B 102, 085130 (2020)","10.1103/PhysRevB.102.085130",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neutron diffraction and magnetic susceptibility studies show that
orthorhombic single-crystals of topological semimetals ${\rm
Sr(Mn_{0.9}Cu_{0.1})Sb_2}$ and ${\rm Sr(Mn_{0.9}Zn_{0.1})Sb_2}$ undergo three
dimensional C-type antiferromagnetic (AFM) ordering of the Mn$^{2+}$ moments at
$T_N = 200\pm10$ and $210\pm12$ K, respectively, significantly lower than that
of the parent SrMnSb$_2$ with $T_N=297 \pm 3$ K. Magnetization versus applied
magnetic field (perpendicular to MnSb planes) below $T_N$ exhibits slightly
modified de Haas van Alphen oscillations for the Zn-doped crystal as compared
to that of the parent compound. By contrast, the Cu-doped system does not show
de Haas van Alphen magnetic oscillations, suggesting that either Cu
substitution for Mn changes the electronic structure of the parent compound
substantially, or that the Cu sites are strong scatterers of carriers that
significantly shorten their mean free path thus diminishing the oscillations.
Density functional theory (DFT) calculations including spin-orbit coupling
predict the C-type AFM state for the parent, Cu-, and Zn-doped systems and
identify the $a$-axis (i.e., perpendicular to the Mn layer) as the easy
magnetization direction in the parent and 12.5% of Cu or Zn substitutions. In
contrast, 25% of Cu content changes the easy magnetization to the $b$-axis
(i.e., within the Mn layer). We find that the incorporation of Cu and Zn in
SrMnSb$_2$ tunes electronic bands near the Fermi level resulting in different
band topology and semi-metallicity. The parent and Zn-doped systems have
coexistence of electron and hole pockets with opened Dirac cone around the
Y-point whereas the Cu-doped system has dominant hole pockets around the Fermi
level with a distorted Dirac cone. The tunable electronic structure may point
out possibilities of rationalizing the experimentally observed de Haas van
Alphen magnetic oscillations.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:30:53 GMT""},{""version"":""v2"",""created"":""Mon, 31 Aug 2020 02:42:38 GMT""}]","2020-09-01"
"2006.07300","Hari Teja Tatavarti","Hari Teja Tatavarti, Prashant Doshi, Layton Hayes","Recurrent Sum-Product-Max Networks for Decision Making in
  Perfectly-Observed Environments",,,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent investigations into sum-product-max networks (SPMN) that generalize
sum-product networks (SPN) offer a data-driven alternative for decision making,
which has predominantly relied on handcrafted models. SPMNs computationally
represent a probabilistic decision-making problem whose solution scales
linearly in the size of the network. However, SPMNs are not well suited for
sequential decision making over multiple time steps. In this paper, we present
recurrent SPMNs (RSPMN) that learn from and model decision-making data over
time. RSPMNs utilize a template network that is unfolded as needed depending on
the length of the data sequence. This is significant as RSPMNs not only inherit
the benefits of SPMNs in being data driven and mostly tractable, they are also
well suited for sequential problems. We establish conditions on the template
network, which guarantee that the resulting SPMN is valid, and present a
structure learning algorithm to learn a sound template network. We demonstrate
that the RSPMNs learned on a testbed of sequential decision-making data sets
generate MEUs and policies that are close to the optimal on perfectly-observed
domains. They easily improve on a recent batch-constrained reinforcement
learning method, which is important because RSPMNs offer a new model-based
approach to offline reinforcement learning.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:31:11 GMT""}]","2020-06-15"
"2006.07301","Neda Navidi","Neda Navidi, Francoi Chabo, Saga Kurandwa, Iv Lutigma, Vincent Robt,
  Gregry Szrftgr, Andea Schuh","Human and Multi-Agent collaboration in a human-MARL teaming framework",,,,,"cs.AI cs.HC cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning provides effective results with agents learning from
their observations, received rewards, and internal interactions between agents.
This study proposes a new open-source MARL framework, called COGMENT, to
efficiently leverage human and agent interactions as a source of learning. We
demonstrate these innovations by using a designed real-time environment with
unmanned aerial vehicles driven by RL agents, collaborating with a human. The
results of this study show that the proposed collaborative paradigm and the
open-source framework leads to significant reductions in both human effort and
exploration costs.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:32:42 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 21:24:19 GMT""}]","2021-03-03"
"2006.07302","Tuukka Korhonen","Tuukka Korhonen","SMS in PACE 2020","3 pages, 3 appendix pages, 0 figures. Submitted as a solver
  description of a solver in Parameterized Algorithms and Computational
  Experiments Challenge 2020",,"10.4230/LIPIcs.IPEC.2020.30",,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe SMS, our submission to the exact treedepth track of PACE 2020.
SMS computes the treedepth of a graph by branching on the small minimal
separators of the graph.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:34:24 GMT""}]","2022-02-08"
"2006.07303","Teresa Crespo","Teresa Crespo","Automatic realization of Hopf Galois structures","arXiv admin note: text overlap with arXiv:2003.01819",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider Hopf Galois structures on a separable field extension $L/K$ of
degree $p^n$, for $p$ an odd prime number, $n\geq 3$. For $p > n$, we prove
that $L/K$ has at most one abelian type of Hopf Galois structures. For a
nonabelian group $N$ of order $p^n$, with commutator subgroup of order $p$, we
prove that if $L/K$ has a Hopf Galois structure of type $N$, then it has a Hopf
Galois structure of type $A$, where $A$ is an abelian group of order $p^n$ and
having the same number of elements of order $p^m$ as $N$, for $1\leq m \leq n$.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:34:32 GMT""},{""version"":""v2"",""created"":""Tue, 29 Sep 2020 10:40:27 GMT""}]","2020-10-01"
"2006.07304","Pavel Kos","Pavel Kos, Bruno Bertini, and Toma\v{z} Prosen","Correlations in Perturbed Dual-Unitary Circuits: Efficient Path-Integral
  Formula","28 pages, 9 figures, 2 tables; v3: 32 pages, 10 figures, 2 tables;
  presentation improved, Section 3 rewritten","Phys. Rev. X 11, 011022 (2021)","10.1103/PhysRevX.11.011022",,"cond-mat.stat-mech hep-th math-ph math.MP nlin.CD quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interacting many-body systems with explicitly accessible spatio-temporal
correlation functions are extremely rare, especially in the absence of
integrability. Recently, we identified a remarkable class of such systems and
termed them dual-unitary quantum circuits. These are brick-wall type local
quantum circuits whose dynamics are unitary in both time and space. For these
systems the spatio-temporal correlation functions are non-trivial only at the
edge of the causal light cone and can be computed in terms of one-dimensional
transfer matrices. Dual-unitarity, however, requires fine-tuning and the degree
of generality of the observed dynamical features remained unclear. Here we
address this question by introducing arbitrary perturbations of the local
gates. Considering fixed perturbations, we prove that for a particular class of
unperturbed elementary dual-unitary gates the correlation functions are still
expressed in terms of one-dimensional transfer matrices. These matrices,
however, are now contracted over generic paths connecting the origin to a fixed
endpoint inside the causal light cone. The correlation function is given as a
sum over all such paths. Our statement is rigorous in the ""dilute limit"", where
only a small fraction of the gates is perturbed, and in the presence of random
longitudinal fields, but we provide theoretical arguments and stringent
numerical checks supporting its validity even in the clean case and when all
gates are perturbed. As a byproduct, in the case of random longitudinal fields
-- which turns out to be equivalent to certain classical Markov chains -- we
find four types of non-dual-unitary(and non-integrable) interacting many-body
systems where the correlation functions are exactly given by the path-sum
formula.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:36:11 GMT""},{""version"":""v2"",""created"":""Mon, 26 Oct 2020 15:07:15 GMT""}]","2021-02-11"
"2006.07305","Yanelli Nunez","Yanelli Nunez, Elizabeth A. Gibson, Eva M. Tanner, Chris Gennings,
  Brent A.Coull, Jeff A. Goldsmith, and Marianthi-Anna Kioumourtzoglou","Reflection on modern methods: Good practices for applied statistical
  learning in epidemiology","19 pages, 5 figures, 1 table. For associated code, visit
  https://github.com/yanellinunez/Commentary-to-mixture-methods-paper",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Statistical learning (SL) includes methods that extract knowledge from
complex data. SL methods beyond generalized linear models are being
increasingly implemented in public health research and epidemiology because
they can perform better in instances with complex or high-dimensional
data---settings when traditional statistical methods fail. These novel methods,
however, often include random sampling which may induce variability in results.
Best practices in data science can help to ensure robustness. As a case study,
we included four SL models that have been applied previously to analyze the
relationship between environmental mixtures and health outcomes. We ran each
model across 100 initializing values for random number generation, or ""seeds,""
and assessed variability in resulting estimation and inference. All methods
exhibited some seed-dependent variability in results. The degree of variability
differed across methods and exposure of interest. Any SL method reliant on a
random seed will exhibit some degree of seed sensitivity. We recommend that
researchers repeat their analysis with various seeds as a sensitivity analysis
when implementing these methods to enhance interpretability and robustness of
results.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:38:40 GMT""},{""version"":""v2"",""created"":""Fri, 2 Oct 2020 18:13:45 GMT""}]","2020-10-06"
"2006.07306","Mykhailo Rakov","Michael Weyrauch and Mykhailo V. Rakov","Luttinger liquid parameters from tensor network data","7 pages, 7 multi-panel figures, 1 table in Version 1","Phys. Rev. B 102, 104422 (2020)","10.1103/PhysRevB.102.104422",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the XXZ Heisenberg model in a staggered magnetic field using the
HOTRG tensor renormalization method. Built into the tensor representation of
the XXZ model is the U(1) symmetry, which is systematically maintained at each
renormalization step. We determine the phase diagram of the model from the low
lying spectrum, and from the finite size dependence of the spectrum we extract
scaling dimensions, which are compared to predictions of low energy field
theory.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:42:34 GMT""},{""version"":""v2"",""created"":""Fri, 4 Sep 2020 19:14:38 GMT""}]","2020-09-22"
"2006.07307","Rfaqat Ali","Rfaqat Ali","Revisit of generalized Kerker's conditions using composite metamaterials","7 pages, 3 Figures",,"10.1088/2040-8986/ab9d14",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Achieving zero backward scattering (ZBS) and zero forward scattering (ZFS),
i.e., the so-called the first and second Kerker's conditions respectively, by
sphere spherical particles is considered to be impossible due to the
unavailability of naturally occurring magnetic materials in the visible
frequency range. We report theoretical modeling to design composite
metamaterials that present large optical magnetic permeability in the visible
frequency range by employing Mie scattering theory and extended Maxwell Garnett
theory. We numerically show that a careful selection of constituents of a
composite metamaterial one can obtain metamaterials with sufficiently large
artificial permeability that eventually provides the Kerker's criterion to
achieve the Kereker's conditions. By taking realistic material parameters we
demonstrate that the metamaterials exhibiting ZBS and ZFS have a small
imaginary part of the refractive index than metallic structures that pave a
path to design high-performance nanophotonic devices.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:44:39 GMT""}]","2020-08-26"
"2006.07308","Prajwal Niraula","Prajwal Niraula, Julien de Wit, Benjamin V. Rackham, Elsa Ducrot,
  Artem Burdanov, Ian J. M. Crossfield, Valerie Van Grootel, Catriona Murray,
  Lionel J. Garcia, Roi Alonso, Corey Beard, Yilen Gomez Maqueo Chew, Laetitia
  Delrez, Brice-Olivier Demory, Benjamin J. Fulton, Michael Gillon, Maximilian
  N. Gunther, Andrew W. Howard, Howard Issacson, Emmanuel Jehin, Peter P.
  Pedersen, Francisco J. Pozuelos, Didier Queloz, Rafael Rebolo-Lopez, Lalitha
  Sairam, Daniel Sebastian, Samantha Thompson, Amaury H.M.J. Triaud","$\pi$ Earth: a 3.14-day Earth-sized Planet from $\textit{K2}$'s Kitchen
  Served Warm by the SPECULOOS Team",,,"10.3847/1538-3881/aba95f",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  We report on the discovery of a transiting Earth-sized (0.95$R_\oplus$)
planet around an M3.5 dwarf star at 57$\,$pc, K2-315b. The planet has a period
of $\sim$3.14 days, i.e. ${\sim}\pi$, with an instellation of
7.45$\,$S$_{\oplus}$. The detection was made using publicly available data from
$\textit{K2}$'s Campaign 15. We observed three additional transits with
SPECULOOS Southern and Northern Observatories, and a stellar spectrum from
Keck/HIRES, which allowed us to validate the planetary nature of the signal.
The confirmed planet is well suited for comparative terrestrial exoplanetology.
While exoplanets transiting ultracool dwarfs present the best opportunity for
atmospheric studies of terrestrial exoplanets with the $\textit{James Webb
Space Telescope}$, those orbiting mid-M dwarfs within 100$\,$pc such as K2-315b
will become increasingly accessible with the next generation of observatories.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:45:42 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jul 2020 13:58:07 GMT""},{""version"":""v3"",""created"":""Fri, 7 Aug 2020 15:11:43 GMT""}]","2020-09-30"
"2006.07309","Fateme Bafghi","Fateme Bafghi, Bijan Shoushtarian","Multiple-Vehicle Tracking in the Highway Using Appearance Model and
  Visual Object Tracking",,,"10.1109/MVIP49855.2020.9116905",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent decades, due to the groundbreaking improvements in machine vision,
many daily tasks are performed by computers. One of these tasks is
multiple-vehicle tracking, which is widely used in different areas such as
video surveillance and traffic monitoring. This paper focuses on introducing an
efficient novel approach with acceptable accuracy. This is achieved through an
efficient appearance and motion model based on the features extracted from each
object. For this purpose, two different approaches have been used to extract
features, i.e. features extracted from a deep neural network, and traditional
features. Then the results from these two approaches are compared with
state-of-the-art trackers. The results are obtained by executing the methods on
the UA-DETRACK benchmark. The first method led to 58.9% accuracy while the
second method caused up to 15.9%. The proposed methods can still be improved by
extracting more distinguishable features.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:46:12 GMT""}]","2020-07-07"
"2006.07310","Jonathan Dong","Jonathan Dong, Ruben Ohana, Mushegh Rafayelyan, and Florent Krzakala","Reservoir Computing meets Recurrent Kernels and Structured Transforms",,"Advances in Neural Information Processing Systems, v33, pages
  16785--16796, 2020",,,"stat.ML cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reservoir Computing is a class of simple yet efficient Recurrent Neural
Networks where internal weights are fixed at random and only a linear output
layer is trained. In the large size limit, such random neural networks have a
deep connection with kernel methods. Our contributions are threefold: a) We
rigorously establish the recurrent kernel limit of Reservoir Computing and
prove its convergence. b) We test our models on chaotic time series prediction,
a classic but challenging benchmark in Reservoir Computing, and show how the
Recurrent Kernel is competitive and computationally efficient when the number
of data points remains moderate. c) When the number of samples is too large, we
leverage the success of structured Random Features for kernel approximation by
introducing Structured Reservoir Computing. The two proposed methods, Recurrent
Kernel and Structured Reservoir Computing, turn out to be much faster and more
memory-efficient than conventional Reservoir Computing.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:46:34 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 16:11:25 GMT""}]","2021-02-18"
"2006.07311","Edward Oughton","Edward J. Oughton and Jatin Mathur","Predicting cell phone adoption metrics using satellite imagery",,,,,"cs.CY econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Approximately half of the global population does not have access to the
internet, even though digital connectivity can reduce poverty by
revolutionizing economic development opportunities. Due to a lack of data,
Mobile Network Operators and governments struggle to effectively determine if
infrastructure investments are viable, especially in greenfield areas where
demand is unknown. This leads to a lack of investment in network
infrastructure, resulting in a phenomenon commonly referred to as the `digital
divide`. In this paper we present a machine learning method that uses publicly
available satellite imagery to predict telecoms demand metrics, including cell
phone adoption and spending on mobile services, and apply the method to Malawi
and Ethiopia. Our predictive machine learning approach consistently outperforms
baseline models which use population density or nightlight luminosity, with an
improvement in data variance prediction of at least 40%. The method is a
starting point for developing more sophisticated predictive models of
infrastructure demand using machine learning and publicly available satellite
imagery. The evidence produced can help to better inform infrastructure
investment and policy decisions.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:47:45 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 08:48:52 GMT""},{""version"":""v3"",""created"":""Tue, 1 Dec 2020 09:36:19 GMT""},{""version"":""v4"",""created"":""Thu, 25 Feb 2021 18:00:14 GMT""},{""version"":""v5"",""created"":""Tue, 8 Jun 2021 20:52:14 GMT""}]","2021-06-10"
"2006.07312","Jonas Wahl","Jonas Wahl","Traces On Diagram Algebras I: Free Partition Quantum Groups, Random
  Lattice Paths And Random Walks On Trees","Comments welcome! v3: major changes in exposition",,"10.1112/jlms.12562",,"math.PR math.OA math.QA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify extremal traces on the seven direct limit algebras of noncrossing
partitions arising from the classification of free partition quantum groups of
Banica-Speicher (arXiv:0808.2628) and Weber (arXiv:1201.4723). For the
infinite-dimensional Temperley-Lieb-algebra (corresponding to the quantum group
$O^+_N$) and the Motzkin algebra ($B^+_N$), the classification of extremal
traces implies a classification result for well-known types of central random
lattice paths. For the $2$-Fuss-Catalan algebra ($H_N^+$) we solve the
classification problem by computing the \emph{minimal or exit boundary} (also
known as the \emph{absolute}) for central random walks on the Fibonacci tree,
thereby solving a probabilistic problem of independent interest, and to our
knowledge the first such result for a nonhomogeneous tree. In the course of
this article, we also discuss the branching graphs for all seven examples of
free partition quantum groups, compute those that were not already known, and
provide new formulas for the dimensions of their irreducible representations.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:48:15 GMT""},{""version"":""v2"",""created"":""Mon, 19 Oct 2020 15:53:43 GMT""},{""version"":""v3"",""created"":""Fri, 2 Jul 2021 09:15:12 GMT""}]","2022-03-14"
"2006.07313","Danny Marfatia","Danny Marfatia, Po-Yan Tseng","Gravitational wave signals of dark matter freeze-out","17 pages, 6 figures, 2 tables. Version to appear in JHEP","JHEP 2102:022 (2021)","10.1007/JHEP02(2021)022",,"hep-ph astro-ph.CO hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the stochastic background of gravitational waves which accompany the
sudden freeze-out of dark matter triggered by a cosmological first order phase
transition that endows dark matter with mass. We consider models that produce
the measured dark matter relic abundance via (1) bubble filtering, and (2)
inflation and reheating, and show that gravitational waves from these
mechanisms are detectable at future interferometers.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:51:32 GMT""},{""version"":""v2"",""created"":""Thu, 15 Oct 2020 07:22:29 GMT""},{""version"":""v3"",""created"":""Tue, 20 Oct 2020 23:32:50 GMT""},{""version"":""v4"",""created"":""Tue, 22 Dec 2020 00:14:18 GMT""}]","2021-02-03"
"2006.07314","Harshat Kumar","Harshat Kumar and Dionysios S. Kalogerias and George J. Pappas and
  Alejandro Ribeiro","Zeroth-order Deterministic Policy Gradient","18 pages, 5 figures. Fixed some minor oversights in the theoretical
  development present in the previous version of the manuscript and
  significantly revised and expanded the simulations sections, both in the main
  body and supplementary material",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deterministic Policy Gradient (DPG) removes a level of randomness from
standard randomized-action Policy Gradient (PG), and demonstrates substantial
empirical success for tackling complex dynamic problems involving Markov
decision processes. At the same time, though, DPG loses its ability to learn in
a model-free (i.e., actor-only) fashion, frequently necessitating the use of
critics in order to obtain consistent estimates of the associated policy-reward
gradient. In this work, we introduce Zeroth-order Deterministic Policy Gradient
(ZDPG), which approximates policy-reward gradients via two-point stochastic
evaluations of the $Q$-function, constructed by properly designed
low-dimensional action-space perturbations. Exploiting the idea of random
horizon rollouts for obtaining unbiased estimates of the $Q$-function, ZDPG
lifts the dependence on critics and restores true model-free policy learning,
while enjoying built-in and provable algorithmic stability. Additionally, we
present new finite sample complexity bounds for ZDPG, which improve upon
existing results by up to two orders of magnitude. Our findings are supported
by several numerical experiments, which showcase the effectiveness of ZDPG in a
practical setting, and its advantages over both PG and Baseline PG.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:52:29 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jul 2020 18:16:22 GMT""}]","2020-07-14"
"2006.07315","Jakub Marecek","Quan Zhou, Jakub Marecek, Robert N. Shorten","Fairness in Forecasting and Learning Linear Dynamical Systems",,"Proceedings of the Thirty-Fifth AAAI Conference on Artificial
  Intelligence, 2021",,,"cs.LG math.DS math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In machine learning, training data often capture the behaviour of multiple
subgroups of some underlying human population. When the amounts of training
data for the subgroups are not controlled carefully, under-representation bias
arises. We introduce two natural notions of subgroup fairness and instantaneous
fairness to address such under-representation bias in time-series forecasting
problems. In particular, we consider the subgroup-fair and instant-fair
learning of a linear dynamical system (LDS) from multiple trajectories of
varying lengths, and the associated forecasting problems. We provide globally
convergent methods for the learning problems using hierarchies of
convexifications of non-commutative polynomial optimisation problems. Our
empirical results on a biased data set motivated by insurance applications and
the well-known COMPAS data set demonstrate both the beneficial impact of
fairness considerations on statistical performance and encouraging effects of
exploiting sparsity on run time.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:53:27 GMT""},{""version"":""v2"",""created"":""Sat, 2 Jan 2021 12:28:19 GMT""}]","2022-09-07"
"2006.07316","Harry J. D. Miller","Harry J. D. Miller, M. Hamed Mohammady, Mart\'i Perarnau-Llobet,
  Giacomo Guarnieri","Thermodynamic uncertainty relation in slowly driven quantum heat engines","11 pages, 2 figures. Updated to published version with additional
  mathematical background in the supplementary material. Some additional
  results from a previous draft have now been incorporated into another
  article, see arXiv:2011.11589","Phys. Rev. Lett. 126, 210603 (2021)","10.1103/PhysRevLett.126.210603",,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermodynamic Uncertainty Relations express a trade-off between precision,
defined as the noise-to-signal ratio of a generic current, and the amount of
associated entropy production. These results have deep consequences for
autonomous heat engines operating at steady-state, imposing an upper bound for
their efficiency in terms of the power yield and its fluctuations. In the
present manuscript we analyse a different class of heat engines, namely those
which are operating in the periodic slow-driving regime. We show that an
alternative TUR is satisfied, which is less restrictive than that of
steady-state engines: it allows for engines that produce finite power, with
small power fluctuations, to operate close to the Carnot efficiency. The bound
further incorporates the effect of quantum fluctuations, which reduces engine
efficiency relative to the average power and reliability. We finally illustrate
our findings in the experimentally relevant model of a single-ion heat engine.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:55:05 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 17:08:36 GMT""},{""version"":""v3"",""created"":""Tue, 24 Nov 2020 16:46:31 GMT""},{""version"":""v4"",""created"":""Thu, 1 Jul 2021 12:07:55 GMT""}]","2021-07-02"
"2006.07317","Grigory Tarnopolsky","Igor R. Klebanov, Alexey Milekhin, Grigory Tarnopolsky, Wenli Zhao","Spontaneous Breaking of $U(1)$ Symmetry in Coupled Complex SYK Models","36 pages, 16 figures; v2: some improvements; v3: version to appear in
  JHEP",,"10.1007/JHEP11(2020)162",,"hep-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As shown in [1], two copies of the large $N$ Majorana SYK model can produce
spontaneous breaking of a $Z_2$ symmetry when they are coupled by appropriate
quartic terms. In this paper we similarly study two copies of the complex SYK
model coupled by a quartic term preserving the $U(1) \times U(1)$ symmetry. We
also present a tensor counterpart of this coupled model. When the coefficient
$\alpha$ of the quartic term lies in a certain range, the coupled large $N$
theory is nearly conformal. We calculate the scaling dimensions of fermion
bilinear operators as functions of $\alpha$. We show that the operator
$c_{1i}^\dagger c_{2i}$, which is charged under the axial $U(1)$ symmetry,
acquires a complex dimension outside of the line of fixed points. We derive the
large $N$ Dyson-Schwinger equations and show that, outside the fixed line, this
$U(1)$ symmetry is spontaneously broken at low temperatures because this
operator acquires an expectation value. We support these findings by exact
diagonalizations extrapolated to large $N$.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:55:26 GMT""},{""version"":""v2"",""created"":""Wed, 5 Aug 2020 17:36:04 GMT""},{""version"":""v3"",""created"":""Mon, 26 Oct 2020 15:25:44 GMT""}]","2020-12-30"
"2006.07318","Andrea Chiavassa","A. Chiavassa, K. Kravchenko, F. Millour, G. Schaefer, M. Schultheis,
  B. Freytag, O. Creevey, V. Hocd\'e, F. Morand, R. Ligi, S. Kraus, J. D.
  Monnier, D. Mourard, N. Nardetto, N. Anugu, J.-B. Le Bouquin, C. L. Davies,
  J. Ennis, T. Gardner, A. Labdon, C. Lanthermann, B. R. Setterholm, and T. ten
  Brummelaar","Optical interferometry and Gaia measurement uncertainties reveal the
  physics of asymptotic giant branch stars","Accepted for publication on Astronomy and Astrophysics","A&A 640, A23 (2020)","10.1051/0004-6361/202037832",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context. Asymptotic giant branch stars are cool luminous evolved stars that
are well observable across the Galaxy and populating Gaia data. They have
complex stellar surface dynamics Aims. On the AGB star CL Lac, it has been
shown that the convection-related variability accounts for a substantial part
of the Gaia DR2 parallax error. We observed this star with the MIRC-X beam
combiner installed at the CHARA interferometer to detect the presence of
stellar surface inhomogeneities. Methods. We performed the reconstruction of
aperture synthesis images from the interferometric observations at different
wavelengths. Then, we used 3D radiative hydrodynamics simulations of stellar
convection with CO5BOLD and the post-processing radiative transfer code Optim3D
to compute intensity maps in the spectral channels of MIRC-X observations.
Then, we determined the stellar radius and compared the 3D synthetic maps to
the reconstructed ones focusing on matching the intensity contrast, the
morphology of stellar surface structures, and the photocentre position at two
different spectral channels, 1.52 and 1.70 micron, simultaneously. Results. We
measured the apparent diameter of CL Lac at two wavelengths and recovered the
radius using a Gaia parallax. In addition to this, the reconstructed images are
characterised by the presence of a brighter area that largely affects the
position of the photocentre. The comparison with 3D simulation shows good
agreement with the observations both in terms of contrast and surface structure
morphology, meaning that our model is adequate for explaining the observed
inhomogenities. Conclusions. This work confirms the presence of
convection-related surface structures on an AGB star of Gaia DR2. Our result
will help us to take a step forward in exploiting Gaia measurement
uncertainties to extract the fundamental properties of AGB stars using
appropriate RHD simulations.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:55:50 GMT""}]","2020-08-05"
"2006.07319","H\'ector Ochoa de Eguileor","Hector Ochoa","Strain-induced excitonic instability in twisted bilayer graphene","6 pages + SM, 3 figures; to appear in Phys. Rev. B as Rapid
  Communication","Phys. Rev. B 102, 201107 (2020)","10.1103/PhysRevB.102.201107",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The low-energy bands of twisted bilayer graphene form Dirac cones with
approximate electron-hole symmetry at small rotation angles. These crossings
are protected by the emergent symmetries of moir\'e patterns, conferring a
topological character to the bands. Strain accumulated between layers
(heterostrain) shifts the Dirac points both in energy and momentum. The overlap
of conduction and valence bands favors an excitonic instability of the Fermi
surface close to the neutrality point. The spontaneous condensation of
electron-hole pairs breaks time reversal symmetry and the separate conservation
of charge within each valley sector. The order parameter describes interlayer
circulating currents in a Kekul\'e-like orbital magnetization density wave.
Vortices in this order parameter carry fermion numbers owing to the underlying
topology of the bands. This mechanism may explain the occurrence of insulating
states at neutrality in the most homogenous samples, where uniform strain
fields contribute both to stabilizing the relative orientation between layers
and to the formation of an excitonic gap.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:56:54 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 16:15:08 GMT""}]","2020-11-25"
"2006.07320","Gonzalo Mart\'inez Lema","G. Mart\'inez-Lema, M. Mart\'inez-Vara, M. Sorel, C. Adams, V.
  Alvarez, L. Arazi, I.J. Arnquist, C.D.R Azevedo, K. Bailey, F. Ballester,
  J.M. Benlloch-Rodr\'iguez, F.I.G.M. Borges, N. Byrnes, S. C\'arcel, J.V.
  Carri\'on, S. Cebri\'an, E. Church, C.A.N. Conde, T. Contreras, G. D\'iaz, J.
  D\'iaz, M. Diesburg, J. Escada, R. Esteve, R. Felkai, A.F.M. Fernandes,
  L.M.P. Fernandes, P. Ferrario, A.L. Ferreira, E.D.C. Freitas, J. Generowicz,
  S. Ghosh, A. Goldschmidt, J.J. G\'omez-Cadenas, D. Gonz\'alez-D\'iaz, R.
  Guenette, R.M. Guti\'errez, J. Haefner, K. Hafidi, J. Hauptman, C.A.O.
  Henriques, J.A. Hernando Morata, P. Herrero, V. Herrero, Y. Ifergan, S.
  Johnston, B.J.P. Jones, M. Kekic, L. Labarga, A. Laing, P. Lebrun, N.
  L\'opez-March, M. Losada, R.D.P. Mano, J. Mart\'in-Albo, A. Mart\'inez, A.D.
  McDonald, F. Monrabal, C.M.B. Monteiro, F.J. Mora, J. Mu\~noz Vidal, P.
  Novella, D.R. Nygren, B. Palmeiro, A. Para, J. P\'erez, M. Querol, A.B.
  Redwine, J. Renner, J. Repond, S. Riordan, L. Ripoll, Y. Rodr\'iguez
  Garc\'ia, J. Rodr\'iguez, L. Rogers, B. Romeo, C. Romo-Luque, F.P. Santos,
  J.M.F. dos Santos, A. Sim\'on, C. Sofka, T. Stiegler, J.F. Toledo, J.
  Torrent, A. Us\'on, J.F.C.A. Veloso, R. Webb, R. Weiss-Babai, J.T. White, K.
  Woodruff, N. Yahlali","Sensitivity of the NEXT experiment to Xe-124 double electron capture","23 pages, 13 figures","J. High Energ. Phys. 2021, 203 (2021)","10.1007/JHEP02(2021)203",,"hep-ex nucl-ex physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Double electron capture by proton-rich nuclei is a second-order nuclear
process analogous to double beta decay. Despite their similarities, the decay
signature is quite different, potentially providing a new channel to measure
the hypothesized neutrinoless mode of these decays. The Standard-Model-allowed
two-neutrino double electron capture ($2\nu ECEC$) has been predicted for a
number of isotopes, but only observed in $^{78}$Kr, $^{130}$Ba and, recently,
$^{124}$Xe. The sensitivity to this decay establishes a benchmark for the
ultimate experimental goal, namely the potential to discover also the
lepton-number-violating neutrinoless version of this process, $0\nu ECEC$. Here
we report on the current sensitivity of the NEXT-White detector to $^{124}$Xe
$2\nu ECEC$ and on the extrapolation to NEXT-100. Using simulated data for the
$2\nu ECEC$ signal and real data from NEXT-White operated with
$^{124}$Xe-depleted gas as background, we define an optimal event selection
that maximizes the NEXT-White sensitivity. We estimate that, for NEXT-100
operated with xenon gas isotopically enriched with 1 kg of $^{124}$Xe and for a
5-year run, a sensitivity to the $2\nu ECEC$ half-life of $6 \times 10^{22}$ y
(at 90% confidence level) or better can be reached.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:57:52 GMT""},{""version"":""v2"",""created"":""Thu, 5 Nov 2020 10:45:30 GMT""},{""version"":""v3"",""created"":""Mon, 15 Mar 2021 15:46:07 GMT""}]","2021-03-16"
"2006.07321","Antonio Enea Romano","Antonio Enea Romano","Sound speed induced production of primordial black holes",,,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study different mechanisms by which the speed of primordial curvature
perturbations can produce an enhancement of the curvature spectrum, which could
lead to the production of primordial black holes (PBH). One possibility is the
growth of the sound speed in single scalar field models, which can induce
super-horizon growth of curvature perturbations. The other is the momentum
dependent effective sound (MESS) of curvature perturbations, which can arise in
multi-fields models or modified gravity theories.
  Future gravitational waves observatories such as LISA will allow to set
constraints of the space and time dependency of the sound speed, and on the
different theoretical scenarios from which it can originate.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:59:39 GMT""}]","2020-06-15"
"2006.07322","Like Hui","Like Hui and Mikhail Belkin","Evaluation of Neural Architectures Trained with Square Loss vs
  Cross-Entropy in Classification Tasks","An extended version of the paper published at ICLR2021. Added
  material includes evaluations of Transformer architectures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern neural architectures for classification tasks are trained using the
cross-entropy loss, which is widely believed to be empirically superior to the
square loss. In this work we provide evidence indicating that this belief may
not be well-founded. We explore several major neural architectures and a range
of standard benchmark datasets for NLP, automatic speech recognition (ASR) and
computer vision tasks to show that these architectures, with the same
hyper-parameter settings as reported in the literature, perform comparably or
better when trained with the square loss, even after equalizing computational
resources. Indeed, we observe that the square loss produces better results in
the dominant majority of NLP and ASR experiments. Cross-entropy appears to have
a slight edge on computer vision tasks.
  We argue that there is little compelling empirical or theoretical evidence
indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our
experiments, performance on nearly all non-vision tasks can be improved,
sometimes significantly, by switching to the square loss. Furthermore, training
with square loss appears to be less sensitive to the randomness in
initialization. We posit that training using the square loss for classification
needs to be a part of best practices of modern deep learning on equal footing
with cross-entropy.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:00:49 GMT""},{""version"":""v2"",""created"":""Sat, 3 Oct 2020 03:34:50 GMT""},{""version"":""v3"",""created"":""Wed, 4 Nov 2020 02:40:23 GMT""},{""version"":""v4"",""created"":""Fri, 5 Mar 2021 22:40:37 GMT""},{""version"":""v5"",""created"":""Sat, 23 Oct 2021 00:36:12 GMT""}]","2021-10-26"
"2006.07323","Lyndon Hibbard","Lyndon Hibbard","Adversarial Prediction of Radiotherapy Treatment Machine Parameters","11 pages, 6 figures; This version incorporated updated networks and
  results",,,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern external beam cancer radiotherapy applies prescribed radiation doses
to tumor targets while minimally affecting nearby vulnerable organs-at-risk
(OARs). Creating a treatment plan is difficult and time-consuming with no
guarantee of optimality. Knowledge-based planning (KBP) mitigates this
uncertainty by guiding planning with probabilistic models based on populations
of prior clinical-quality plans. We have developed a KBP-inspired planning
model that predicts plans as realizations of the treatment machine parameters.
These are tuples of linear accelerator (Linac) gantry angles, multi-leaf
collimator (MLC) apertures that shape the beam, and aperture-intensity weights
that can be represented graphically in a coordinate frame isomorphic with
projections (beam's-eye views) of the patient's target anatomy. These paired
data train conditional generative adversarial networks (cGANs) that estimate
the MLC apertures and weights for a novel patient, thereby predicting a
treatment plan. The predicted plans' OAR sparing is close to that of the
clinical plans; the predicted target coverage requires refinement to match the
clinical plans' quality. Nonetheless, the predicted plans can serve as lower
bounds on plan quality, and by initializing the MLC aperture shape and weight
refinement can substantially reduce the compute times for that refinement.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:01:42 GMT""},{""version"":""v2"",""created"":""Wed, 25 Nov 2020 21:07:23 GMT""},{""version"":""v3"",""created"":""Mon, 5 Jul 2021 20:08:24 GMT""}]","2021-07-07"
"2006.07324","Luciano Ricco","L. S. Ricco, Y. Marques, J. E. Sanches, I. A. Shelykh and A. C.
  Seridonio","Interaction induced hybridization of Majorana zero-modes in a coupled
  quantum-dot hybrid-nanowire system",,"Phys. Rev. B 102, 165104 (2020)","10.1103/PhysRevB.102.165104",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the low-energy transport properties of a hybrid device composed by a
native quantum dot coupled to both ends of a topological superconducting
nanowire section hosting Majorana zero-modes. The account of the coupling
between the dot and the farthest Majorana zero-mode allows to introduce the
topological quality factor, characterizing the level of topological protection
in the system. We demonstrate that Coulomb interaction between the dot and the
topological superconducting section leads to the onset of the additional
overlap of the wavefunctions describing the Majorana zero-modes, leading to the
formation of trivial Andreev bound states even for spatially well-separated
Majoranas. This leads to the spoiling of the quality factor and introduces a
constraint for the braiding process required to perform topological quantum
computing operations.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:04:18 GMT""}]","2020-10-14"
"2006.07325","Stella Offner","Stella S. R. Offner, Josh Taylor, Carleen Markey, Hope How-Huan Chen,
  Jaime E. Pineda, Alyssa A. Goodman, Andreas Burkert, Adam Ginsburg, Spandan
  Choudhury","Turbulence, Coherence and Collapse: Three Phases for Core Evolution","26 pages, 16 figures. Accepted to MNRAS",,"10.1093/mnras/stac2734",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the formation, evolution and collapse of dense cores by tracking
structures in a magnetohydrodynamic simulation of a star-forming cloud. We
identify cores using the dendrogram algorithm and utilize machine learning
techniques, including Neural Gas prototype learning and Fuzzy $c$-means
clustering, to analyze the density and velocity dispersion profiles of cores
together with six bulk properties. We produce a 2-d visualization using a
Uniform Manifold Approximation and Projection (UMAP), which facilitates the
connection between physical properties and three partially-overlapping phases:
i) unbound turbulent structures (Phase I), ii) coherent cores that have low
turbulence (Phase II), and iii) bound cores, many of which become protostellar
(Phase III). Within Phase II we identify a population of long-lived coherent
cores that reach a quasi-equilibrium state. Most prestellar cores form in Phase
II and become protostellar after evolving into Phase III. Due to the turbulent
cloud environment, the initial core properties do not uniquely predict the
eventual evolution, i.e., core evolution is stochastic, and cores follow no one
evolutionary path. The phase lifetimes are 1.0$\pm$0.1$\times$10$^5$ yr,
1.3$\pm$0.2$\times$10$^5$ yr, and 1.8$\pm$0.3$\times$10$^5$ yr for Phase I, II,
and III, respectively. We compare our results to NH$_3$ observations of dense
cores. Known coherent cores predominantly map into Phase II, while most
turbulent pressure-confined cores map to Phase I or III. We predict that a
significant fraction of observed starless cores have unresolved coherent
regions and that $\gtrsim 20$% of observed starless cores will not form stars.
Measurements of core radial profiles, in addition to the usual bulk properties,
will enable more accurate predictions of core evolution.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:06:05 GMT""},{""version"":""v2"",""created"":""Mon, 26 Sep 2022 06:11:53 GMT""}]","2022-11-16"
"2006.07326","Sungmin Cha","Sungmin Cha, Hsiang Hsu, Taebaek Hwang, Flavio P. Calmon and Taesup
  Moon","CPR: Classifier-Projection Regularization for Continual Learning","ICLR 2021 camera ready version",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a general, yet simple patch that can be applied to existing
regularization-based continual learning methods called classifier-projection
regularization (CPR). Inspired by both recent results on neural networks with
wide local minima and information theory, CPR adds an additional regularization
term that maximizes the entropy of a classifier's output probability. We
demonstrate that this additional term can be interpreted as a projection of the
conditional probability given by a classifier's output to the uniform
distribution. By applying the Pythagorean theorem for KL divergence, we then
prove that this projection may (in theory) improve the performance of continual
learning methods. In our extensive experimental results, we apply CPR to
several state-of-the-art regularization-based continual learning methods and
benchmark performance on popular image recognition datasets. Our results
demonstrate that CPR indeed promotes a wide local minima and significantly
improves both accuracy and plasticity while simultaneously mitigating the
catastrophic forgetting of baseline continual learning methods. The codes and
scripts for this work are available at https://github.com/csm9493/CPR_CL.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:07:37 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 09:30:56 GMT""}]","2021-04-20"
"2006.07327","Xinshuo Weng","Xinshuo Weng, Yongxin Wang, Yunze Man, Kris Kitani","GNN3DMOT: Graph Neural Network for 3D Multi-Object Tracking with
  Multi-Feature Learning","CVPR 2020. My website for all my research works:
  http://www.xinshuoweng.com/",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D Multi-object tracking (MOT) is crucial to autonomous systems. Recent work
uses a standard tracking-by-detection pipeline, where feature extraction is
first performed independently for each object in order to compute an affinity
matrix. Then the affinity matrix is passed to the Hungarian algorithm for data
association. A key process of this standard pipeline is to learn discriminative
features for different objects in order to reduce confusion during data
association. In this work, we propose two techniques to improve the
discriminative feature learning for MOT: (1) instead of obtaining features for
each object independently, we propose a novel feature interaction mechanism by
introducing the Graph Neural Network. As a result, the feature of one object is
informed of the features of other objects so that the object feature can lean
towards the object with similar feature (i.e., object probably with a same ID)
and deviate from objects with dissimilar features (i.e., object probably with
different IDs), leading to a more discriminative feature for each object; (2)
instead of obtaining the feature from either 2D or 3D space in prior work, we
propose a novel joint feature extractor to learn appearance and motion features
from 2D and 3D space simultaneously. As features from different modalities
often have complementary information, the joint feature can be more
discriminate than feature from each individual modality. To ensure that the
joint feature extractor does not heavily rely on one modality, we also propose
an ensemble training paradigm. Through extensive evaluation, our proposed
method achieves state-of-the-art performance on KITTI and nuScenes 3D MOT
benchmarks. Our code will be made available at
https://github.com/xinshuoweng/GNN3DMOT
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:08:14 GMT""}]","2020-06-15"
"2006.07330","Clayton Scott","Clayton Scott and Jianxin Zhang","Learning from Label Proportions: A Mutual Contamination Framework",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning from label proportions (LLP) is a weakly supervised setting for
classification in which unlabeled training instances are grouped into bags, and
each bag is annotated with the proportion of each class occurring in that bag.
Prior work on LLP has yet to establish a consistent learning procedure, nor
does there exist a theoretically justified, general purpose training criterion.
In this work we address these two issues by posing LLP in terms of mutual
contamination models (MCMs), which have recently been applied successfully to
study various other weak supervision settings. In the process, we establish
several novel technical results for MCMs, including unbiased losses and
generalization error bounds under non-iid sampling plans. We also point out the
limitations of a common experimental setting for LLP, and propose a new one
based on our MCM framework.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:11:40 GMT""}]","2020-06-15"
"2006.07331","Donghan Yu","Donghan Yu, Yiming Yang, Ruohong Zhang, Yuexin Wu","Knowledge Embedding Based Graph Convolutional Network","WWW 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, a considerable literature has grown up around the theme of Graph
Convolutional Network (GCN). How to effectively leverage the rich structural
information in complex graphs, such as knowledge graphs with heterogeneous
types of entities and relations, is a primary open challenge in the field. Most
GCN methods are either restricted to graphs with a homogeneous type of edges
(e.g., citation links only), or focusing on representation learning for nodes
only instead of jointly propagating and updating the embeddings of both nodes
and edges for target-driven objectives. This paper addresses these limitations
by proposing a novel framework, namely the Knowledge Embedding based Graph
Convolutional Network (KE-GCN), which combines the power of GCNs in graph-based
belief propagation and the strengths of advanced knowledge embedding (a.k.a.
knowledge graph embedding) methods, and goes beyond. Our theoretical analysis
shows that KE-GCN offers an elegant unification of several well-known GCN
methods as specific cases, with a new perspective of graph convolution.
Experimental results on benchmark datasets show the advantageous performance of
KE-GCN over strong baseline methods in the tasks of knowledge graph alignment
and entity classification.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:12:51 GMT""},{""version"":""v2"",""created"":""Fri, 23 Apr 2021 15:54:15 GMT""}]","2021-04-26"
"2006.07332","Thomas Searle","Thomas Searle, Zina Ibrahim, Richard JB Dobson","Experimental Evaluation and Development of a Silver-Standard for the
  MIMIC-III Clinical Coding Dataset",,"ACL 2020","10.18653/v1/2020.bionlp-1.8",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Clinical coding is currently a labour-intensive, error-prone, but critical
administrative process whereby hospital patient episodes are manually assigned
codes by qualified staff from large, standardised taxonomic hierarchies of
codes. Automating clinical coding has a long history in NLP research and has
recently seen novel developments setting new state of the art results. A
popular dataset used in this task is MIMIC-III, a large intensive care database
that includes clinical free text notes and associated codes. We argue for the
reconsideration of the validity MIMIC-III's assigned codes that are often
treated as gold-standard, especially when MIMIC-III has not undergone secondary
validation. This work presents an open-source, reproducible experimental
methodology for assessing the validity of codes derived from EHR discharge
summaries. We exemplify the methodology with MIMIC-III discharge summaries and
show the most frequently assigned codes in MIMIC-III are under-coded up to 35%.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:15:44 GMT""}]","2023-02-28"
"2006.07333","Alan Hubbard","Jeremy R. Coyle, Nima S. Hejazi, Ivana Malenica, Rachael V. Phillips,
  Benjamin F. Arnold, Andrew Mertens, Jade Benjamin-Chung, Weixin Cai, Sonali
  Dayal, John M. Colford Jr., Alan E. Hubbard, Mark J. van der Laan","Targeting Learning: Robust Statistics for Reproducible Research","25 pages, 3 figures",,,,"stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Targeted Learning is a subfield of statistics that unifies advances in causal
inference, machine learning and statistical theory to help answer
scientifically impactful questions with statistical confidence. Targeted
Learning is driven by complex problems in data science and has been implemented
in a diversity of real-world scenarios: observational studies with missing
treatments and outcomes, personalized interventions, longitudinal settings with
time-varying treatment regimes, survival analysis, adaptive randomized trials,
mediation analysis, and networks of connected subjects. In contrast to the
(mis)application of restrictive modeling strategies that dominate the current
practice of statistics, Targeted Learning establishes a principled standard for
statistical estimation and inference (i.e., confidence intervals and p-values).
This multiply robust approach is accompanied by a guiding roadmap and a
burgeoning software ecosystem, both of which provide guidance on the
construction of estimators optimized to best answer the motivating question.
The roadmap of Targeted Learning emphasizes tailoring statistical procedures so
as to minimize their assumptions, carefully grounding them only in the
scientific knowledge available. The end result is a framework that honestly
reflects the uncertainty in both the background knowledge and the available
data in order to draw reliable conclusions from statistical analyses -
ultimately enhancing the reproducibility and rigor of scientific findings.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:17:01 GMT""}]","2020-06-15"
"2006.07334","Satyajit Saha","D. Kanjilal, S. K. Dey, S. S. Bhattacharjee, A. Bisoi, M. Das, C. C.
  Dey, S. Nag, R. Palit, S. Ray, S. Saha, J. Sethi and S. Saha","High spin states of $^{204}$At: isomeric states and shears band
  structure","This preprint has not undergone peer review or any post-submission
  improvements or corrections. The Version of Record of this article is
  published in The European Physical Journal A and is available online at
  https://doi.org/10.1140/epja/s10050-022-00809-4","Eur. Phys. J. A (2022) 58:159","10.1140/epja/s10050-022-00809-4",,"nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-spin states of neutron deficient Trans-Lead nucleus $^{204}$At were
populated up to $\sim 8\,{\rm MeV}$ excitation through the $^{12}$C +
$^{197}$Au fusion evaporation reaction. Decay of the associated levels through
prompt and delayed $\gamma$-ray emissions were studied to evaluate the
underlying nuclear structure. The level scheme, which was partly known, was
extended further. An isomeric $16^+$ level with observed lifetime $\tau=52 \pm
5\, {\rm ns}$, was established from our measurements. Attempts were made to
interpret the excited states based on multi quasiparticle and hole structures
involving $2f_{5/2}$, $1h_{9/2}$, and $1i_{13/2}$ shell model states, along
with moderate core excitation. Magnetic dipole band structure over the spin
parity range:~$16^+ - 23^+$ was confirmed and evaluated in more detail,
including the missing cross-over $E2$ transitions. Band-crossing along the
shears band was observed and compared with the evidence of similar phenomena in
the neighbouring neutron deficient $^{202}$Bi, $^{205}$Rn isotones and the
$^{203}$At isotope. Based on comparison of the measured $B(M1)/B(E2)$ values
for transitions along the band with the semiclassical model based estimates,
the shears band of $^{204}$At was established along with the level scheme.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:17:04 GMT""},{""version"":""v2"",""created"":""Fri, 12 Aug 2022 08:57:49 GMT""},{""version"":""v3"",""created"":""Thu, 1 Sep 2022 10:33:44 GMT""}]","2022-09-02"
"2006.07335","Gloria Delgado-Inglada","L. Carigi, A. Peimbert, M. Peimbert, and G. Delgado-Inglada","The ADF and the t$^2$ formalism in H II regions based on the upper mass
  limit of the IMF for the MW","19 pages, 5 figures, accepted for publication in Revista Mexicana de
  Astronomia y Astrofisica",,"10.22201/ia.01851101p.2020.56.02.06",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study in depth the abundance discrepancy problem in H II regions, this
time from a different perspective than the usual one: by studying the effect of
the upper mass limit (M$_{\rm up}$) of the initial mass function (IMF) on the
O, C, and He predicted by chemical evolution models for the Milky Way. We use
abundances determined with the direct method (DM) and with the temperature
independent method (TIM). We compare the predicted abundances at the present
time with observations of Orion, M17, and M8 to determine the M$_{\rm up}$
value of the galactic IMF. From the DM abundances, the models predict an
M$_{\rm up}$ = 25-45 M$_{\odot}$, while from the TIM, CEMs derive an M$_{\rm
up}$ = 70-110 M$_{\odot}$. Spiral galaxies with the stellar mass and star
formation rate of the MW are predicted to have an M$_{\rm up} \sim100$
M$_{\odot}$. These results support that abundances derived from the TIM are
better than those derived from the DM.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:17:32 GMT""}]","2020-09-30"
"2006.07336","George Lusztig","G. Lusztig","Strata of a disconnected reductive group","22 pages, some misprints corrected",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $D$ be a connected component of a possibly disconnected reductive group
$G$ over an algebraic closed field. We define a partition of $D$ into finitely
many Strata each of which is a union of $G^0$-conjugacy classes of fixed
dimension. In the case where $D=G^0$ this recovers a known partition.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:19:14 GMT""},{""version"":""v2"",""created"":""Sat, 26 Sep 2020 19:26:15 GMT""}]","2020-09-29"
"2006.07337","Daniel Groll","Daniel Groll, Daniel Wigger, Kevin J\""urgens, Thilo Hahn, Christian
  Schneider, Martin Kamp, Sven H\""ofling, Jacek Kasprzak, Tilmann Kuhn","Four-wave mixing dynamics of a strongly coupled quantum-dot--microcavity
  system driven by up to 20 photons",,"Phys. Rev. B 101, 245301 (2020)","10.1103/PhysRevB.101.245301",,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Jaynes-Cummings (JC) model represents one of the simplest ways in which
single qubits can interact with single photon modes, leading to profound
quantum phenomena like superpositions of light and matter states. One system,
that can be described with the JC model, is a single quantum dot embedded in a
micropillar cavity. In this joint experimental and theoretical study we
investigate such a system using four-wave mixing (FWM) micro-spectroscopy.
Special emphasis is laid on the dependence of the FWM signals on the number of
photons injected into the microcavity. By comparing simulation and experiment,
which are in excellent agreement with each other, we infer that up to ~20
photons take part in the observed FWM dynamics. Thus we verify the validity of
the JC model for the system under consideration in this non-trivial regime. We
find that the inevitable coupling between the quantum dot exciton and
longitudinal acoustic phonons of the host lattice influences the real time FWM
dynamics and has to be taken into account for a sufficient description of the
quantum dot-microcavity system. Performing additional simulations in an
idealized dissipation-less regime, we observe that the FWM signal exhibits
quasi-periodic dynamics, analog to the collapse and revival phenomenon of the
JC model. In these simulations we also see that the FWM spectrum has a triplet
structure, if a large number of photons is injected into the cavity.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:20:06 GMT""}]","2020-06-15"
"2006.07338","Naresh Dadhich","John D. Barrow and Naresh Dadhich","Maximum Force in Modified Gravity Theories","10 pages, no figures, section on power law gravity dropped, additions
  to conclusions, The paper is dedicated to the fond memory of one of the
  authors, John Barrow who passed away on 26 Sept 2020 - Naresh Dadhich,
  coauthor","Phys. Rev. D 102, 064018 (2020)","10.1103/PhysRevD.102.064018",,"gr-qc astro-ph.HE hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the existence and nature of classical maximum force bound
between two black holes with touching horizons. Besides general relativity, the
maximum force bound is independent of black hole masses only in Moffat's
theory, Brans Dicke theory (which is the same as Einstein's for vacuum) and the
higher dimensional generalization of Einstein's theory, pure Lovelock gravity
which is characterised by having single $n$th order term in Lovelock polynomial
without sum over lower orders in the action. Further if the bound is to exist
in higher dimensions and is entirely in terms of the velocity of light and the
gravitational constant, it has uniquely to be pure Lovelock gravity. In pure
Lovelock gravity, the maximum force bound exists in all $3n$-space dimensions
and has the value, $c^4/4G_n$ where $G_n$ is the corresponding gravitational
constant. The absence of mass dependence in the maximum force bound may have
relevance for the formation of naked singularities.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:23:39 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 16:21:26 GMT""},{""version"":""v3"",""created"":""Mon, 28 Sep 2020 09:32:36 GMT""}]","2020-09-30"
"2006.07339","Huiqian Luo","Chang Liu, Jianlei Shen, Jiacheng Gao, Changjiang Yi, Di Liu, Tao Xie,
  Lin Yang, Sergey Danilkin, Guochu Deng, Wenhong Wang, Shiliang Li, Youguo
  Shi, Hongming Weng, Enke Liu, and Huiqian Luo","Spin Excitations and Spin Wave Gap in the Ferromagnetic Weyl Semimetal
  Co$_3$Sn$_2$S$_2$","15 pages, 10 figures, including Supplementary Materials","Sci. China-Phys. Mech. Astron. 64, 217062 (2021)","10.1007/s11433-020-1597-6",,"cond-mat.str-el cond-mat.mtrl-sci cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a comprehensive neutron scattering study on the spin excitations in
the magnetic Weyl semimetal Co$_3$Sn$_2$S$_2$ with quasi-two-dimensional
structure. Both in-plane and out-of-plane dispersions of the spin waves are
revealed in the ferromagnetic state, similarly dispersive but damped spin
excitations persist into the paramagnetic state. The effective exchange
interactions have been estimated by a semi-classical Heisenberg model to
consistently reproduce the experimental $T_C$ and spin stiffness. However, a
full spin wave gap below $E_g=2.3$ meV is observed at $T=4$ K, much larger than
the estimated magnetic anisotropy energy ($\sim0.6$ meV), while its temperature
dependence indicates a significant contribution from the Weyl fermions. These
results suggest that Co$_3$Sn$_2$S$_2$ is a three-dimensional correlated system
with large spin stiffness, and the low-energy spin dynamics could interplay
with the topological electron states.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:24:27 GMT""},{""version"":""v2"",""created"":""Mon, 15 Jun 2020 03:06:22 GMT""}]","2020-08-25"
"2006.07340","Christopher Musco","Tam\'as Erd\'elyi and Cameron Musco and Christopher Musco","Fourier Sparse Leverage Scores and Approximate Kernel Learning",,,,,"cs.DS cs.LG math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove new explicit upper bounds on the leverage scores of Fourier sparse
functions under both the Gaussian and Laplace measures. In particular, we study
$s$-sparse functions of the form $f(x) = \sum_{j=1}^s a_j e^{i \lambda_j x}$
for coefficients $a_j \in \mathbb{C}$ and frequencies $\lambda_j \in
\mathbb{R}$. Bounding Fourier sparse leverage scores under various measures is
of pure mathematical interest in approximation theory, and our work extends
existing results for the uniform measure [Erd17,CP19a]. Practically, our bounds
are motivated by two important applications in machine learning:
  1. Kernel Approximation. They yield a new random Fourier features algorithm
for approximating Gaussian and Cauchy (rational quadratic) kernel matrices. For
low-dimensional data, our method uses a near optimal number of features, and
its runtime is polynomial in the $statistical\ dimension$ of the approximated
kernel matrix. It is the first ""oblivious sketching method"" with this property
for any kernel besides the polynomial kernel, resolving an open question of
[AKM+17,AKK+20b].
  2. Active Learning. They can be used as non-uniform sampling distributions
for robust active learning when data follows a Gaussian or Laplace
distribution. Using the framework of [AKM+19], we provide essentially optimal
results for bandlimited and multiband interpolation, and Gaussian process
regression. These results generalize existing work that only applies to
uniformly distributed data.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:25:39 GMT""},{""version"":""v2"",""created"":""Fri, 16 Oct 2020 03:37:49 GMT""},{""version"":""v3"",""created"":""Thu, 8 Jul 2021 01:55:27 GMT""}]","2021-07-09"
"2006.07341","Peter Cotton","Peter Cotton","Addressing the Herd Immunity Paradox Using Symmetry, Convexity
  Adjustments and Bond Prices",,,,,"q-bio.PE physics.soc-ph q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In constant parameter compartmental models an early onset of herd immunity is
at odds with estimates of R values from early stage growth. This paper utilizes
a result from the theory of interest rate modeling, namely a bond pricing
formula of Vasicek, and an approach inspired by a foundational result in
statistics, de Finetti's Theorem, to show how the modeling discrepancy can be
explained. Moreover the difference between predictions of classic constant
parameter epidemiological models and those with variation and stochastic
evolution can be reduced to simple ""convexity"" formulas. A novel feature of
this approach is that we do not attempt to locate a true model but only a model
that is equivalent after permutations. Convexity adjustments can also be used
for cross sectional comparisons and we derive easy to use rules of thumb for
estimating threshold infection level in one region given knowledge of threshold
infection in another.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:32:02 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 16:29:28 GMT""}]","2020-06-18"
"2006.07342","Ramin Naimi","Ramin Naimi","On intrinsically knotted and linked graphs","8 pages, 3 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a brief survey of some known results on intrinsically linked or
knotted graphs.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:32:09 GMT""}]","2020-06-15"
"2006.07343","Simeon Bird","Leah Fauber, Ming-Feng Ho, Simeon Bird, Christian R. Shelton, Roman
  Garnett, Ishita Korde","Automated Measurement of Quasar Redshift with a Gaussian Process","14 pages, 11 figures, accepted by MNRAS with some improvements and
  clarifications to discussion",,"10.1093/mnras/staa2826",,"astro-ph.GA astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop an automated technique to measure quasar redshifts in the Baryon
Oscillation Spectroscopic Survey (BOSS) of the Sloan Digital Sky Survey (SDSS).
Our technique is an extension of an earlier Gaussian process method for
detecting damped Lyman-alpha absorbers (DLAs) in quasar spectra with known
redshifts. We apply this technique to a subsample of SDSS DR12 with BAL quasars
removed and redshift larger than 2.15. We show that we are broadly competitive
to existing quasar redshift estimators, disagreeing with the PCA redshift by
more than 0.5 in only 0.38% of spectra. Our method produces a probabilistic
density function for the quasar redshift, allowing quasar redshift uncertainty
to be propagated to downstream users. We apply this method to detecting DLAs,
accounting in a Bayesian fashion for redshift uncertainty. Compared to our
earlier method with a known quasar redshift, we have a moderate decrease in our
ability to detect DLAs, predominantly in the noisiest spectra. The area under
curve drops from 0.96 to 0.91. Our code is publicly available.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:32:14 GMT""},{""version"":""v2"",""created"":""Tue, 15 Sep 2020 16:50:38 GMT""}]","2020-09-16"
"2006.07344","Alexander Kobelski","Alexander Kobelski (1), Pavel Osinenko (1) and Stefan Streif (1) ((1)
  Technische Universit\""at Chemnitz, Automatic Control and System Dynamics
  Laboratory)","A method of online traction parameter identification and mapping","Accepted for publication at the IFAC WC 2020","IFAC-PapersOnLine Volume 53, Issue 2, 2020, Pages 13933-13938","10.1016/j.ifacol.2020.12.909",,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fuel consumption of heavy-duty vehicles such as tractors, bulldozers etc. is
comparably high due to their scope of operation. The operation settings are
usually fixed and not tuned to the environmental factors, such as ground
conditions. Yet exactly the ground-to-propelling-unit properties are decisive
in energy efficiency. Optimizing the latter would require a means of
identifying those properties. This is the central matter of the current study.
More specifically, the goal is to estimate the ground conditions from the
available measurements, such as drive train signals, and to establish a map of
those. The ground condition parameters are estimated using an adaptive
unscented Kalman filter. A case study is provided with the actual and estimated
ground condition maps. Such a mapping can be seen as a crucial milestone in
optimal operation control of heavy-duty vehicles.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:33:03 GMT""},{""version"":""v2"",""created"":""Fri, 23 Apr 2021 11:27:46 GMT""}]","2021-04-26"
"2006.07345","Kashif Inayat","Shahbano, Muhammad Abdullah and Kashif Inayat","Robust Baggage Detection and Classification Based on Local
  Tri-directional Pattern",,"International Journal of Internet Technology and Secured
  Transactions (2021)",,,"cs.CV cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent decades, the automatic video surveillance system has gained
significant importance in computer vision community. The crucial objective of
surveillance is monitoring and security in public places. In the traditional
Local Binary Pattern, the feature description is somehow inaccurate, and the
feature size is large enough. Therefore, to overcome these shortcomings, our
research proposed a detection algorithm for a human with or without carrying
baggage. The Local tri-directional pattern descriptor is exhibited to extract
features of different human body parts including head, trunk, and limbs. Then
with the help of support vector machine, extracted features are trained and
evaluated. Experimental results on INRIA and MSMT17 V1 datasets show that
LtriDP outperforms several state-of-the-art feature descriptors and validate
its effectiveness.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:33:21 GMT""},{""version"":""v2"",""created"":""Mon, 15 Jun 2020 13:41:09 GMT""},{""version"":""v3"",""created"":""Mon, 1 Feb 2021 04:14:21 GMT""}]","2021-02-02"
"2006.07346","Yutong Wang","Yutong Wang and Clayton D. Scott","Weston-Watkins Hinge Loss and Ordered Partitions","38 pages, 3 figures",,,,"stat.ML cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multiclass extensions of the support vector machine (SVM) have been
formulated in a variety of ways. A recent empirical comparison of nine such
formulations [Do\v{g}an et al. 2016] recommends the variant proposed by Weston
and Watkins (WW), despite the fact that the WW-hinge loss is not calibrated
with respect to the 0-1 loss. In this work we introduce a novel discrete loss
function for multiclass classification, the ordered partition loss, and prove
that the WW-hinge loss is calibrated with respect to this loss. We also argue
that the ordered partition loss is maximally informative among discrete losses
satisfying this property. Finally, we apply our theory to justify the empirical
observation made by Do\v{g}an et al. that the WW-SVM can work well even under
massive label noise, a challenging setting for multiclass SVMs.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:34:21 GMT""}]","2020-06-15"
"2006.07347","Seyyed Mohammadreza Azimi","Seyyed Mohammadreza Azimi","Online Caching with Wireless Fronthauling and Delivery in Fog-Aided
  Networks","4 pages, 2 figures, IEEE Communications Letters","published 2020",,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fog Radio Access Network (F-RAN) exploits cached contents at edge nodes (ENs)
and fronthaul connection to the cloud for content delivery. Assuming dedicated
fronthaul links between cloud and each EN, previous works focused on analyses
of F-RANs using offline or online caching depending whether the content
popularity is time-invariant or time-variant. Extension has been done for
multicast fronthaul link connecting cloud to only two ENs and time-invariant
popularity. In contrast, the scope of this work is on the case where multicast
fronthaul link connects arbitrary number of ENs to the cloud and content
popularity is time-variant. Normalized Delivery Time (NDT) is used as a
performance measure and by investigating proactive online caching, analytical
results reveal that the power scaling of fronthaul transmission sets a limit on
the performance of F-RAN.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:35:52 GMT""}]","2020-06-15"
"2006.07348","Matheus Nora Rosa","Yiwei Xia, Emanuele Riva, Matheus I. N. Rosa, Gabriele Cazzulani,
  Alper Erturk, Francesco Braghin and Massimo Ruzzene","Experimental observation of temporal pumping in electro-mechanical
  waveguides",,"Phys. Rev. Lett. 126, 095501 (2021)","10.1103/PhysRevLett.126.095501",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We experimentally demonstrate temporal pumping of elastic waves in an
electromechanical waveguide. An aluminum beam covered by an array of
piezoelectric patches connected to shunt circuits with controllable resistances
enables the spatial and temporal control of the beam's stiffness. The spatial
modulation produces non-trivial edge states, while a smooth temporal variation
of the modulation phase drives the transfer of edge states from one boundary of
the waveguide to the other in a controllable manner. This characteristic
behavior for a topological pump is here demonstrated for the first time in a
continuous elastic waveguide. The framework presented herein opens new avenues
for the manipulation and transport of information through elastic waves, with
potential technological applications for digital delay lines and digitally
controlled waveguides. Our study also explores higher dimensional topological
physics using time as a synthetic dimension in electromechanical systems.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:37:57 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 18:10:42 GMT""}]","2021-03-10"
"2006.07349","Guto Leoni Santos Mr","Guto Leoni Santos, Patricia Takako Endo","Using Reinforcement Learning to Allocate and Manage Service Function
  Chains in Cellular Networks","9 pages, 6 figures, 2 tables",,,,"cs.NI cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  It is expected that the next generation cellular networks provide a connected
society with fully mobility to empower the socio-economic transformation.
Several other technologies will benefits of this evolution, such as Internet of
Things, smart cities, smart agriculture, vehicular networks, healthcare
applications, and so on. Each of these scenarios presents specific requirements
and demands different network configurations. To deal with this heterogeneity,
virtualization technology is key technology. Indeed, the network function
virtualization (NFV) paradigm provides flexibility for the network manager,
allocating resources according to the demand, and reduces acquisition and
operational costs. In addition, it is possible to specify an ordered set of
network virtual functions (VNFs) for a given service, which is called as
service function chain (SFC). However, besides the advantages from service
virtualization, it is expected that network performance and availability do not
be affected by its usage. In this paper, we propose the use of reinforcement
learning to deploy a SFC of cellular network service and manage the VNFs
operation. We consider that the SFC is deployed by the reinforcement learning
agent considering a scenarios with distributed data centers, where the VNFs are
deployed in virtual machines in commodity servers. The NFV management is
related to create, delete, and restart the VNFs. The main purpose is to reduce
the number of lost packets taking into account the energy consumption of the
servers. We use the Proximal Policy Optimization (PPO) algorithm to implement
the agent and preliminary results show that the agent is able to allocate the
SFC and manage the VNFs, reducing the number of lost packets.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:38:23 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 23:44:16 GMT""},{""version"":""v3"",""created"":""Tue, 20 Oct 2020 00:12:50 GMT""}]","2020-10-21"
"2006.07350","Kashif Inayat","Usama Khalid, Muhammad Abdullah and Kashif Inayat","Exploiting ML algorithms for Efficient Detection and Prevention of
  JavaScript-XSS Attacks in Android Based Hybrid Applications",,,,,"cs.CR cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The development and analysis of mobile applications in term of security have
become an active research area from many years as many apps are vulnerable to
different attacks. Especially the concept of hybrid applications has emerged in
the last three years where applications are developed in both native and web
languages because the use of web languages raises certain security risks in
hybrid mobile applications as it creates possible channels where malicious code
can be injected inside the application. WebView is an important component in
hybrid mobile applications which used to implements a sandbox mechanism to
protect the local resources of smartphone devices from un-authorized access of
JavaScript. However, the WebView application program interfaces (APIs) also
have security issues. For example, an attacker can attack the hybrid
application via JavaScript code by bypassing the sandbox security through
accessing the public methods of the applications. Cross-site scripting (XSS) is
one of the most popular malicious code injection technique for accessing the
public methods of the application through JavaScript. This research proposes a
framework for detection and prevention of XSS attacks in hybrid applications
using state-of-the-art machine learning (ML) algorithms. The detection of the
attacks have been perform by exploiting the registered Java object features.
The dataset and the sample hybrid applications have been developed using the
android studio. Then the widely used toolkit, RapidMiner, has been used for
empirical analysis. The results reveal that the ensemble based Random Forest
algorithm outperforms other algorithms and achieves both the accuracy and
F-measures as high as of 99%.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:39:26 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jul 2020 06:37:37 GMT""}]","2020-07-31"
"2006.07352","Eli Shlizerman","Jimin Kim, Eli Shlizerman","Deep Reinforcement Learning for Neural Control","Please see the associated Video at: https://youtu.be/ixsUMfb9m_U",,,,"q-bio.NC cs.AI cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel methodology for control of neural circuits based on deep
reinforcement learning. Our approach achieves aimed behavior by generating
external continuous stimulation of existing neural circuits (neuromodulation
control) or modulations of neural circuits architecture (connectome control).
Both forms of control are challenging due to nonlinear and recurrent complexity
of neural activity. To infer candidate control policies, our approach maps
neural circuits and their connectome into a grid-world like setting and infers
the actions needed to achieve aimed behavior. The actions are inferred by
adaptation of deep Q-learning methods known for their robust performance in
navigating grid-worlds. We apply our approach to the model of \textit{C.
elegans} which simulates the full somatic nervous system with muscles and body.
Our framework successfully infers neuropeptidic currents and synaptic
architectures for control of chemotaxis. Our findings are consistent with in
vivo measurements and provide additional insights into neural control of
chemotaxis. We further demonstrate the generality and scalability of our
methods by inferring chemotactic neural circuits from scratch.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:41:12 GMT""}]","2020-06-15"
"2006.07353","Gauthier Wissocq","Gauthier Wissocq and Christophe Coreixas and Jean-Fran\c{c}ois
  Boussuge","Linear stability of athermal regularized lattice Boltzmann methods","34 pages, 18 figures","Phys. Rev. E 102, 053305 (2020)","10.1103/PhysRevE.102.053305",,"physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present work is dedicated to a better understanding of the stability
properties of regularized lattice Boltzmann (LB) schemes. To this extent,
linear stability analyses of two-dimensional models are proposed: the standard
Bhatnagar-Gross-Krook (BGK) collision model, the original pre-collision
regularization and the recursive regularized model, where off-equilibrium
distributions are partially computed thanks to a recursive formula. A
systematic identification of the physical content carried by each LB mode is
done by analyzing the eigenvectors of the linear systems. Stability results are
then numerically confirmed by performing simulations of shear and acoustic
waves. This work allows drawing fair conclusions on the stability properties of
each model. In particular, recursive regularization turns out to be the most
stable model for the D2Q9 lattice, especially in the zero-viscosity limit. Two
major properties shared by every regularized model are highlighted: (1) a mode
filtering property, and (2) an incorrect, and broadly anisotropic, dissipation
rate of the modes carrying physical waves in under-resolved conditions. The
first property is the main source of increased stability, especially for the
recursive regularization. It is a direct consequence of the reconstruction of
off-equilibrium populations before each collision process, decreasing the rank
of the system of discrete equations. The second property seems to be related to
numerical errors directly induced by the equilibration of high-order moments.
In such a case, this property is likely to occur with any collision model that
follows such a stabilization methodology.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:43:04 GMT""}]","2020-11-18"
"2006.07354","Luis Renato Gon\c{c}alves Dias","Francisco Braun, Luis Renato Gon\c{c}alves Dias and Jean Venato-Santos","On global invertibility of semi-algebraic local diffeomorphisms",,"2021, Topological Methods in Nonlinear Analysis","10.12775/TMNA.2021.004",,"math.GT math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this partly expository paper we discuss conditions for the global
injectivity of $C^2$ semi-algebraic local diffeomorphisms $f:\mathbb{R}^n \to
\mathbb{R}^n$. In case $n > 2$, we consider the foliations of $\mathbb{R}^n$
defined by the level sets of each $n-2$ projections of $f$, i.e., the maps
$\mathbb{R}^n \to \mathbb{R}^{n-2}$ obtained by deleting two coordinate
functions of $f$. It is known that if the set of non-proper points of $f$ has
codimension greater than or equal to $2$ and the leaves of the above-defined
foliations are simply connected, then $f$ is bijective. In this work we relate
this simply connectedness with the notion of locally trivial fibrations. Then
some computable regularity conditions at infinity ensuring such simply
connectedness are presented. Further, we provide an equivalent statement of the
Jacobian conjecture by using fibrations. By means of examples we prove that the
results presented here are different from a previous result based on a spectral
hypothesis. Our considerations are also applied to discuss the behaviour of
some conditions when $f$ is composed with linear isomorphisms: this is relevant
due to some misunderstandings appearing in the literature.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:43:43 GMT""}]","2022-01-21"
"2006.07355","Yan Li","Ran Zhuo and Yan Li","The A Priori Estimate and Existence of the Positive Solution for A
  Nonlinear System Involving the Fractional Laplacian",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the paper, we consider the fractional elliptic system
\begin{equation*}\left\{\begin{array}{ll} (-
\Delta)^{\frac{\alpha_1}{2}}u(x)+\sum\limits^n_{i=1}b_i(x)\frac{\partial
u}{\partial x_i}+B(x)u(x)=f(x,u,v),& \mbox { in } \Omega,\\ (-
\Delta)^{\frac{\alpha_2}{2}}v(x)+\sum\limits^n_{i=1}c_i(x)\frac{\partial
v}{\partial x_i}+C(x)v(x)=g(x,u,v),& \mbox { in } \Omega,\\ u=v=0, & \mbox { in
} \mathbb{R}^n\setminus\Omega, \end{array} \right.\label{a-1.2} \end{equation*}
where $\Omega$ is a bounded domain with $C^2$ boundary in $\mathbb{R}^n$ and
$n>\max\{\alpha_1,\alpha_2\}$. We first utilize the blowing-up and re-scaling
method to derive the a priori estimate for positive solutions when
$1<\alpha_1,\alpha_2 <2$. Then for $0<\alpha_1,\alpha_2 <1$, we obtain the
regularity estimate of positive solutions. On top of this, using the
topological degree theory we prove the existence of positive solutions.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:45:27 GMT""}]","2020-06-15"
"2006.07356","Hui Jin","Hui Jin, Guido Mont\'ufar","Implicit Bias of Gradient Descent for Mean Squared Error Regression with
  Two-Layer Wide Neural Networks","97 pages, 14 figures. Added the discussion of SGD and implications to
  generalization",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate gradient descent training of wide neural networks and the
corresponding implicit bias in function space. For univariate regression, we
show that the solution of training a width-$n$ shallow ReLU network is within
$n^{- 1/2}$ of the function which fits the training data and whose difference
from the initial function has the smallest 2-norm of the second derivative
weighted by a curvature penalty that depends on the probability distribution
that is used to initialize the network parameters. We compute the curvature
penalty function explicitly for various common initialization procedures. For
instance, asymmetric initialization with a uniform distribution yields a
constant curvature penalty, and thence the solution function is the natural
cubic spline interpolation of the training data. \hj{For stochastic gradient
descent we obtain the same implicit bias result.} We obtain a similar result
for different activation functions. For multivariate regression we show an
analogous result, whereby the second derivative is replaced by the Radon
transform of a fractional Laplacian. For initialization schemes that yield a
constant penalty function, the solutions are polyharmonic splines. Moreover, we
show that the training trajectories are captured by trajectories of smoothing
splines with decreasing regularization strength.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:46:40 GMT""},{""version"":""v2"",""created"":""Sun, 25 Jul 2021 17:16:46 GMT""},{""version"":""v3"",""created"":""Wed, 4 Jan 2023 03:10:02 GMT""},{""version"":""v4"",""created"":""Sat, 22 Apr 2023 14:35:36 GMT""},{""version"":""v5"",""created"":""Sun, 28 May 2023 10:24:01 GMT""}]","2023-05-30"
"2006.07357","Rolando Garcia","Rolando Garcia, Eric Liu, Vikram Sreekanti, Bobby Yan, Anusha
  Dandamudi, Joseph E. Gonzalez, Joseph M. Hellerstein, Koushik Sen","Hindsight Logging for Model Training",,,"10.14778/3436905.3436925",,"cs.DC cs.DB cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In modern Machine Learning, model training is an iterative, experimental
process that can consume enormous computation resources and developer time. To
aid in that process, experienced model developers log and visualize program
variables during training runs. Exhaustive logging of all variables is
infeasible. Optimistic logging can be accompanied by program checkpoints; this
allows developers to add log statements post-hoc, and ""replay"" desired log
statements from checkpoint -- a process we refer to as hindsight logging.
Unfortunately, hindsight logging raises tricky problems in data management and
software engineering. Done poorly, hindsight logging can waste resources and
generate technical debt embodied in multiple variants of training code.
  In this paper, we present methodologies for efficient and effective logging
practices for model training, with a focus on techniques for hindsight logging.
Our goal is for experienced model developers to learn and adopt these
practices. To make this easier, we provide an open-source suite of tools for
Fast Low-Overhead Recovery (flor) that embodies our design across three tasks:
(i) efficient background logging in Python, (ii) adaptable periodic
checkpointing, and (iii) an instrumentation library that codifies hindsight
logging for efficient and automatic record-replay of model-training. Model
developers can use each flor tool separately as they see fit, or they can use
flor in hands-free mode, entrusting it to instrument their code end-to-end for
efficient record-replay. Our solutions leverage techniques from physiological
transaction logs and recovery in database systems. Evaluations on modern ML
benchmarks demonstrate that flor can produce fast checkpointing with small
user-specifiable overheads (e.g. 7%), and still provide hindsight log replay
times orders of magnitude faster than restarting training from scratch.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:47:32 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 05:14:53 GMT""}]","2020-12-03"
"2006.07358","Thomas Searle","Thomas Searle, Zina Ibrahim, Richard Dobson","Comparing Natural Language Processing Techniques for Alzheimer's
  Dementia Prediction in Spontaneous Speech","Submitted to INTERSPEECH 2020: Alzheimer's Dementia Recognition
  through Spontaneous Speech The ADReSS Challenge Workshop","Interspeech 2020",,,"cs.LG cs.CL cs.SD eess.AS stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Alzheimer's Dementia (AD) is an incurable, debilitating, and progressive
neurodegenerative condition that affects cognitive function. Early diagnosis is
important as therapeutics can delay progression and give those diagnosed vital
time. Developing models that analyse spontaneous speech could eventually
provide an efficient diagnostic modality for earlier diagnosis of AD. The
Alzheimer's Dementia Recognition through Spontaneous Speech task offers
acoustically pre-processed and balanced datasets for the classification and
prediction of AD and associated phenotypes through the modelling of spontaneous
speech. We exclusively analyse the supplied textual transcripts of the
spontaneous speech dataset, building and comparing performance across numerous
models for the classification of AD vs controls and the prediction of Mental
Mini State Exam scores. We rigorously train and evaluate Support Vector
Machines (SVMs), Gradient Boosting Decision Trees (GBDT), and Conditional
Random Fields (CRFs) alongside deep learning Transformer based models. We find
our top performing models to be a simple Term Frequency-Inverse Document
Frequency (TF-IDF) vectoriser as input into a SVM model and a pre-trained
Transformer based model `DistilBERT' when used as an embedding layer into
simple linear models. We demonstrate test set scores of 0.81-0.82 across
classification metrics and a RMSE of 4.58.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:51:16 GMT""},{""version"":""v2"",""created"":""Wed, 23 Sep 2020 14:21:22 GMT""}]","2023-02-28"
"2006.07359","Karuppiah Ganesan Dr","M. Suganya, K. Ganesan, P.Vijayakumar, Amirdha Sher Gill, R.Ramaseshan
  and S.Ganesamoorthy","Structural, optical and mechanical properties of Y2Ti2O7 single crystal","12 pages, 4 figures, 1 table; Accepted for publication in Scripta
  Materialia (2020)",,"10.1016/j.scriptamat.2020.06.016",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the growth of Y2Ti2O7 single crystals by optical floating zone
technique. X-ray diffraction and Raman spectroscopy studies confirm the
structural quality of the crystal. The UV-Vis optical studies reveal that the
grown crystals have a high optical transparency with an optical band gap of
3.44 eV. The hardness of Y2Ti2O7 single crystal is measured for the first time
using nanoindentation. The measured hardness, indentation and bulk modulus are
found to be 16.4$\pm$0.4, 321.1$\pm$6.9 and 243.3$\pm$5.2 GPa respectively,
which are higher than its polycrystalline counterpart and its constituent metal
oxides, Y2O3 and TiO2.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:51:18 GMT""}]","2020-06-15"
"2006.07360","Jordan Hoffmann","Jordan Hoffmann, Simon Schmitt, Simon Osindero, Karen Simonyan, Erich
  Elsen","AlgebraNets",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural networks have historically been built layerwise from the set of
functions in ${f: \mathbb{R}^n \to \mathbb{R}^m }$, i.e. with activations and
weights/parameters represented by real numbers, $\mathbb{R}$. Our work
considers a richer set of objects for activations and weights, and undertakes a
comprehensive study of alternative algebras as number representations by
studying their performance on two challenging problems: large-scale image
classification using the ImageNet dataset and language modeling using the
enwiki8 and WikiText-103 datasets. We denote this broader class of models as
AlgebraNets. Our findings indicate that the conclusions of prior work, which
explored neural networks constructed from $\mathbb{C}$ (complex numbers) and
$\mathbb{H}$ (quaternions) on smaller datasets, do not always transfer to these
challenging settings. However, our results demonstrate that there are
alternative algebras which deliver better parameter and computational
efficiency compared with $\mathbb{R}$. We consider $\mathbb{C}$, $\mathbb{H}$,
$M_{2}(\mathbb{R})$ (the set of $2\times2$ real-valued matrices),
$M_{2}(\mathbb{C})$, $M_{3}(\mathbb{R})$ and $M_{4}(\mathbb{R})$. Additionally,
we note that multiplication in these algebras has higher compute density than
real multiplication, a useful property in situations with inherently limited
parameter reuse such as auto-regressive inference and sparse neural networks.
We therefore investigate how to induce sparsity within AlgebraNets. We hope
that our strong results on large-scale, practical benchmarks will spur further
exploration of these unconventional architectures which challenge the default
choice of using real numbers for neural network weights and activations.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:51:20 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 16:10:13 GMT""}]","2020-06-17"
"2006.07361","Yin-Cong Zhi","Yin-Cong Zhi, Yin Cheng Ng, Xiaowen Dong","Gaussian Processes on Graphs via Spectral Kernel Learning","13 pages, 5 Figures",,,,"cs.LG eess.SP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a graph spectrum-based Gaussian process for prediction of signals
defined on nodes of the graph. The model is designed to capture various graph
signal structures through a highly adaptive kernel that incorporates a flexible
polynomial function in the graph spectral domain. Unlike most existing
approaches, we propose to learn such a spectral kernel, where the polynomial
setup enables learning without the need for eigen-decomposition of the graph
Laplacian. In addition, this kernel has the interpretability of graph filtering
achieved by a bespoke maximum likelihood learning algorithm that enforces the
positivity of the spectrum. We demonstrate the interpretability of the model in
synthetic experiments from which we show the various ground truth spectral
filters can be accurately recovered, and the adaptability translates to
superior performances in the prediction of real-world graph data of various
characteristics.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:51:22 GMT""},{""version"":""v2"",""created"":""Mon, 26 Oct 2020 20:42:27 GMT""},{""version"":""v3"",""created"":""Wed, 28 Oct 2020 10:57:51 GMT""}]","2020-10-29"
"2006.07362","Bapi Chatterjee","Vyacheslav Kungurtsev, Bapi Chatterjee, Dan Alistarh","Stochastic Gradient Langevin with Delayed Gradients",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic Gradient Langevin Dynamics (SGLD) ensures strong guarantees with
regards to convergence in measure for sampling log-concave posterior
distributions by adding noise to stochastic gradient iterates. Given the size
of many practical problems, parallelizing across several asynchronously running
processors is a popular strategy for reducing the end-to-end computation time
of stochastic optimization algorithms. In this paper, we are the first to
investigate the effect of asynchronous computation, in particular, the
evaluation of stochastic Langevin gradients at delayed iterates, on the
convergence in measure. For this, we exploit recent results modeling Langevin
dynamics as solving a convex optimization problem on the space of measures. We
show that the rate of convergence in measure is not significantly affected by
the error caused by the delayed gradient information used for computation,
suggesting significant potential for speedup in wall clock time. We confirm our
theoretical results with numerical experiments on some practical problems.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:51:30 GMT""}]","2020-06-15"
"2006.07363","Surya Effendy","Surya Effendy, Juhyun Song, and Martin Z. Bazant","Analysis, Design, and Generalization of Electrochemical Impedance
  Spectroscopy (EIS) Inversion Algorithms","46 pages, to be submitted to the Journal of the Electrochemical
  Society",,,,"physics.comp-ph stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a framework for analyzing and designing EIS inversion
algorithms. Our framework stems from the observation of four features common to
well-defined EIS inversion algorithms, namely (1) the representation of unknown
distributions, (2) the minimization of a metric of error to estimate parameters
arising from the chosen representation, subject to constraints on (3) the
complexity control parameters, and (4) a means for choosing optimal control
parameter values. These features must be present to overcome the ill-posed
nature of EIS inversion problems. We review three established EIS inversion
algorithms to illustrate the pervasiveness of these features, and show the
utility of the framework by resolving ambiguities concerning three more
algorithms. Our framework is then used to design the generalized EIS inversion
(gEISi) algorithm, which uses Gaussian basis function representation, modality
control parameter, and cross-validation for choosing the optimal control
parameter value. The gEISi algorithm is applicable to the generalized EIS
inversion problem, which allows for a wider range of underlying models. We also
considered the construction of credible intervals for distributions arising
from the algorithm. The algorithm is able to accurately reproduce distributions
which have been difficult to obtain using existing algorithms. It is provided
gratis on the repository https://github.com/suryaeff/gEISi.git.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:54:13 GMT""}]","2020-06-15"
"2006.07364","Ye Yuan","Ye Yuan, Kris Kitani","Residual Force Control for Agile Human Behavior Imitation and Extended
  Motion Synthesis","NeurIPS 2020. Code: https://github.com/Khrylx/RFC. Project page:
  https://www.ye-yuan.com/rfc",,,,"cs.RO cs.CV cs.GR cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning has shown great promise for synthesizing realistic
human behaviors by learning humanoid control policies from motion capture data.
However, it is still very challenging to reproduce sophisticated human skills
like ballet dance, or to stably imitate long-term human behaviors with complex
transitions. The main difficulty lies in the dynamics mismatch between the
humanoid model and real humans. That is, motions of real humans may not be
physically possible for the humanoid model. To overcome the dynamics mismatch,
we propose a novel approach, residual force control (RFC), that augments a
humanoid control policy by adding external residual forces into the action
space. During training, the RFC-based policy learns to apply residual forces to
the humanoid to compensate for the dynamics mismatch and better imitate the
reference motion. Experiments on a wide range of dynamic motions demonstrate
that our approach outperforms state-of-the-art methods in terms of convergence
speed and the quality of learned motions. Notably, we showcase a physics-based
virtual character empowered by RFC that can perform highly agile ballet dance
moves such as pirouette, arabesque and jet\'e. Furthermore, we propose a
dual-policy control framework, where a kinematic policy and an RFC-based policy
work in tandem to synthesize multi-modal infinite-horizon human motions without
any task guidance or user input. Our approach is the first humanoid control
method that successfully learns from a large-scale human motion dataset
(Human3.6M) and generates diverse long-term motions. Code and videos are
available at https://www.ye-yuan.com/rfc.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:56:16 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 17:57:12 GMT""}]","2020-10-23"
"2006.07365","Wangmei Zha","James Daniel Brandenburg, Wei Li, Lijuan Ruan, Zebo Tang, Zhangbu Xu,
  Shuai Yang, and Wangmei Zha","Acoplanarity of QED pairs accompanied by nuclear dissociation in
  ultra-peripheral heavy ion collisions",,,,,"hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the transverse momentum broadening effect for
electromagnetic production of dileptons in ultra-peripheral heavy ion
collisions accompanied by nuclear dissociation. The electromagnetic
dissociation probability of nuclei for different neutron multiplicities is
estimated, which could serve as a centrality definition (i.e. impact parameter
estimate) in ultra-peripheral collisions. In the framework of lowest-order QED,
the acoplanarity of dilepton pairs is calculated for different neutron emission
scenarios in ultra-peripheral collisions, indicating significant
impact-parameter dependence. The verification of impact-parameter dependence is
crucially important to understand the broadening effect observed in hadronic
heavy-ion collisions.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:57:35 GMT""}]","2020-06-15"
"2006.07366","Maciej Skorski","Maciej Skorski","Concentration Bounds for the Collision Estimator","Fixing minor gaps in proofs",,,,"cs.IT math.IT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a strong concentration result about the natural collision estimator,
which counts the number of collisions that occur within an iid sample. This
estimator is at the heart of algorithms used for uniformity testing and entropy
assessment.
  While the prior works were limited to only variance, we use elegant
techniques of independent interest to bounds higher moments and conclude
concentration properties. As an immediate corollary we show that the estimator
achieves high-probability guarantee on its own and there is no need for
boosting (aka median/majority trick).
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:57:48 GMT""},{""version"":""v2"",""created"":""Fri, 19 Jun 2020 17:54:34 GMT""},{""version"":""v3"",""created"":""Mon, 22 Jun 2020 16:29:20 GMT""},{""version"":""v4"",""created"":""Thu, 25 Jun 2020 17:56:16 GMT""}]","2020-06-26"
"2006.07367","Sebastian Munoz","Sebastian Munoz","Classical and weak solutions to local first-order mean field games
  through elliptic regularity","v3, 29 pages, final version","Ann. Inst. H. Poincare Anal. Non Lineaire 39 (2022), no. 1, 1-39","10.4171/AIHPC/1",,"math.AP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the regularity and well-posedness of the local, first-order
forward-backward mean field games system, assuming a polynomially growing cost
function and a Hamiltonian of quadratic growth. We consider systems and
terminal data that are strictly monotone in the density and study two different
regimes depending on whether there exists a lower bound for the running cost
function. The work relies on a transformation due to P.-L. Lions, which gives
rise to an elliptic partial differential equation with oblique boundary
conditions, that is strictly elliptic when the coupling is unbounded from
below. In this case, we prove that the solution is smooth. When the problem is
degenerate elliptic, we obtain existence and uniqueness of weak solutions
analogous to those obtained by P. Cardaliaguet and P.J. Graber for the case of
a terminal condition that is independent of the density. The weak solutions are
shown to arise as viscous limits of classical solutions to strictly elliptic
problems.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:58:14 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jul 2020 18:04:06 GMT""},{""version"":""v3"",""created"":""Wed, 23 Feb 2022 21:25:52 GMT""}]","2022-02-25"
"2006.07368","Willie Neiswanger","Willie Neiswanger, Aaditya Ramdas","Uncertainty quantification using martingales for misspecified Gaussian
  processes","Accepted as a conference paper at ALT 2021",,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address uncertainty quantification for Gaussian processes (GPs) under
misspecified priors, with an eye towards Bayesian Optimization (BO). GPs are
widely used in BO because they easily enable exploration based on posterior
uncertainty bands. However, this convenience comes at the cost of robustness: a
typical function encountered in practice is unlikely to have been drawn from
the data scientist's prior, in which case uncertainty estimates can be
misleading, and the resulting exploration can be suboptimal. We present a
frequentist approach to GP/BO uncertainty quantification. We utilize the GP
framework as a working model, but do not assume correctness of the prior. We
instead construct a confidence sequence (CS) for the unknown function using
martingale techniques. There is a necessary cost to achieving robustness: if
the prior was correct, posterior GP bands are narrower than our CS.
Nevertheless, when the prior is wrong, our CS is statistically valid and
empirically outperforms standard GP methods, in terms of both coverage and
utility for BO. Additionally, we demonstrate that powered likelihoods provide
robustness against model misspecification.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:58:59 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 11:35:13 GMT""}]","2021-03-03"
"2006.07369","Philip Boyle Smith","Philip Boyle Smith and David Tong","What Symmetries are Preserved by a Fermion Boundary State?","21 pages",,,,"hep-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Usually, a left-moving fermion in d=1+1 dimensions reflects off a boundary to
become a right-moving fermion. This means that, while overall fermion parity
$(-1)^F$ is conserved, chiral fermion parity for left- and right-movers
individually is not. Remarkably, there are boundary conditions that do preserve
chiral fermion parity, but only when the number of Majorana fermions is a
multiple of 8. In this paper we classify all such boundary states for $2N$
Majorana fermions when a $U(1)^N$ symmetry is also preserved. The fact that
chiral-parity-preserving boundary conditions only exist when $2N$ is divisible
by 8 translates to an interesting property of charge lattices. We also classify
the enhanced continuous symmetry preserved by such boundary states. The state
with the maximum such symmetry is the $SO(8)$ boundary state, first constructed
by Maldacena and Ludwig to describe the scattering of fermions off a monopole
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:59:16 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 15:01:43 GMT""}]","2021-02-26"
"2006.07372","Yu-Lin Chou","Yu-Lin Chou","Sensitive Random Variables are Dense in Every $L^{p}(\mathbb{R},
  \mathscr{B}_{\mathbb{R}}, \mathbb{P})$","Some minor improvements in the abstract and introduction that could
  otherwise be misleading. Besides the preciseness of statements, the
  definition of an $M$-sensitive random variable should include a regularity
  condition such as $\mathbb{P}$-essential boundedness. Some slight
  improvements in the proof are made accordingly. For v3: Two slight
  improvements are made in the proof, one for a remark",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that, for every $1 \leq p < +\infty$ and for every Borel probability
measure $\mathbb{P}$ over $\mathbb{R}$, every element of $L^{p}(\mathbb{R},
\mathscr{B}_{\mathbb{R}}, \mathbb{P})$ is the $L^{p}$-limit of some sequence of
bounded random variables that are Lebesgue-almost everywhere differentiable
with derivatives having norm greater than any pre-specified real number at
every point of differentiability. In general, this result provides, in some
direction, a finer description of an $L^{p}$-approximation for $L^{p}$
functions on $\mathbb{R}$.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:41:25 GMT""},{""version"":""v2"",""created"":""Sun, 19 Jul 2020 10:37:14 GMT""},{""version"":""v3"",""created"":""Tue, 21 Jul 2020 13:41:17 GMT""}]","2020-07-22"
"2006.07373","Georgios Tsekenis","Georgios Tsekenis","Jamming Criticality of Near-Crystals","main text 5 pages, 7 figures. Supplementary material included in the
  end",,"10.1209/0295-5075/ac0ffc",,"cond-mat.soft cond-mat.dis-nn cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the critical properties of minimaly-polydisperse crystals,
hexagonal in 2d and face-centered cubic in 3 dimensions, at the isostatic
jamming point. The force and gap distributions display power-law tails for
small values. The vibrational density of states (VDOS) is flat. The scaling
behavior of forces of extended floppy modes and the VDOS are universal and in
agreement with an infinite-dimensional mean-field theory and maximally
amorphous packings down to 2 dimensions. The distributions of gaps and forces
of localized floppy modes of near-crystals appear non-universal. A small
fraction of normal modes exhibit partial localization at low frequency. The
majority of normal modes is delocalized exhibiting a characteristic inverse
participation ratio scaling with frequency. The packing fraction and order at
jamming decay linearly and quadratically respectively with polydispersity down
to the maximally amorphous state.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:51:09 GMT""}]","2021-10-27"
"2006.07374","David Poland","Soner Albayrak, David Meltzer, David Poland","The Inversion Formula and 6j Symbol for 3d Fermions","63 pages, 7 figures, 1 attached Mathematica notebook","JHEP 09 (2020) 148","10.1007/JHEP09(2020)148",,"hep-th cond-mat.stat-mech cond-mat.str-el hep-lat math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we study the $6j$ symbol of the $3d$ conformal group for
fermionic operators. In particular, we study 4-point functions containing two
fermions and two scalars and also those with four fermions. By using
weight-shifting operators and harmonic analysis for the Euclidean conformal
group, we relate these spinning $6j$ symbols to the simpler $6j$ symbol for
four scalar operators. As one application we use these techniques to compute
$3d$ mean field theory (MFT) OPE coefficients for fermionic operators. We then
compute corrections to the MFT spectrum and couplings due to the inversion of a
single operator, such as the stress tensor or a low-dimension scalar. These
results are valid at finite spin and extend the perturbative large spin
analysis to include non-perturbative effects in spin.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:00 GMT""}]","2020-09-28"
"2006.07375","Kyle Lee","Kyle Lee, George Sterman","Power expansion for heavy quarkonium production at next-to-leading order
  in $\rm e^+e^-$ annihilation","44 pages, 9 figures","JHEP 09 (2020) 046","10.1007/JHEP09(2020)046","YITP-SB-20-13","hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study heavy quarkonium production associated with gluons in $\rm e^+e^-$
annihilation as an illustration of the perturbative QCD (pQCD) factorization
approach, which incorporates the first nonleading power in the energy of the
produced heavy quark pair. We show how the renormalization of the four-quark
operators that define the heavy quark pair fragmentation functions using
dimensional regularization induces ""evanescent"" operators that are absent in
four dimensions. We derive closed forms for short-distance coefficients for
quark pair production to next-to-leading order ($\alpha_s^2$) in the relevant
color singlet and octet channels. Using non-relativistic QCD (NRQCD) to
calculate the heavy quark pair fragmentation functions up to $v^4$ in the
velocity expansion, we derive analytical results for the differential energy
fraction distribution of the heavy quarkonium. Calculations for ${}^3S_1^{[1]}$
and ${}^1S_0^{[8]}$ channels agree with analogous NRQCD analytical results
available in the literature, while several color-octet calculations of energy
fraction distributions are new. We show that the remaining corrections due to
the heavy quark mass fall off rapidly in the energy of the produced state. To
explore the importance of evolution at energies much larger than the mass of
the heavy quark, we solve the renormalization group equation perturbatively to
two-loop order for the ${}^3S_1^{[1]}$ case.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:00 GMT""}]","2020-09-11"
"2006.07376","Om Sharan Salafia","Om S. Salafia and Bruno Giacomazzo","Accretion-to-jet energy conversion efficiency in GW170817","11 pages, 6 figures, reflects the A&A published version, with
  equation 1 corrected as described in the corrigendum published on A&A","A&A 660, C1 (2022)","10.1051/0004-6361/202038590e",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on previously published multi-wavelength modelling of the GRB 170817A
jet afterglow, that includes information from the VLBI centroid motion, we
construct the posterior probability density distribution on the total energy in
the bipolar jets launched by the GW170817 merger remnant. By applying a new
numerical-relativity-informed fitting formula for the accretion disk mass, we
construct the posterior probability density distribution of the GW170817
remnant disk mass. By combining the two, we estimate the accretion-to-jet
energy conversion efficiency in this system, carefully accounting for
uncertainties. The accretion-to-jet energy conversion efficiency in GW170817 is
$\eta\sim 10^{-3}$ with an uncertainty of slightly less than two orders of
magnitude. This low efficiency is in good agreement with expectations from the
$\nu\bar\nu$ mechanism, which therefore cannot be excluded by this measurement
alone. Such an efficiency also agrees with that anticipated for the
Blandford-Znajek mechanism, provided that the magnetic field in the disk right
after the merger is predominantly toroidal (which is expected as a result of
the merger dynamics).
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 23 Sep 2020 15:44:34 GMT""},{""version"":""v3"",""created"":""Fri, 25 Mar 2022 13:26:41 GMT""}]","2022-04-20"
"2006.07377","Stefano Forte","Alessandro Candido, Stefano Forte and Felix Hekhorn","Can $\overline{\rm { MS}}$ parton distributions be negative?","28 pages, 4 figures. Final version, to be published in JHEP.
  Factorization argument in sect. 2 (pag. 4-5); perturbativity argument on pag.
  17; and heavy quark discussion on pag. 25 expanded and clarified; subsection
  3.1.3 on scale dependence added; various further small clarifications and
  improvements",,"10.1007/JHEP11(2020)129","TIF-UNIMI-2020-9","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is common lore that Parton Distribution Functions (PDFs) in the
$\overline{\rm { MS}}$ factorization scheme can become negative beyond leading
order due to the collinear subtraction which is needed in order to define
partonic cross sections. We show that this is in fact not the case and
next-to-leading order (NLO) $\overline{\rm { MS}}$ PDFs are actually positive
in the perturbative regime. In order to prove this, we modify the subtraction
prescription, and perform the collinear subtraction in such a way that partonic
cross sections remain positive. This defines a factorization scheme in which
PDFs are positive. We then show that positivity of the PDFs is preserved when
transforming from this scheme to $\overline{\rm { MS}}$, provided only the
strong coupling is in the perturbative regime, such that the NLO scheme change
is smaller than the LO term.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 20 Oct 2020 06:31:07 GMT""}]","2020-12-30"
"2006.07378","Francisca Concha-Ram\'irez","Francisca Concha-Ram\'irez, Martijn J. C. Wilhelm, Simon Portegies
  Zwart, Sierk E. van Terwisga, Alvaro Hacar","Effects of stellar density on the photoevaporation of circumstellar
  discs","Accepted for publication in MNRAS. 9 pages, 4 figures",,"10.1093/mnras/staa3669",,"astro-ph.EP astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Circumstellar discs are the precursors of planetary systems and develop
shortly after their host star has formed. In their early stages these discs are
immersed in an environment rich in gas and neighbouring stars, which can be
hostile for their survival. There are several environmental processes that
affect the evolution of circumstellar discs, and external photoevaporation is
arguably one of the most important ones. Theoretical and observational evidence
point to circumstellar discs losing mass quickly when in the vicinity of
massive, bright stars. In this work we simulate circumstellar discs in
clustered environments in a range of stellar densities, where the
photoevaporation mass-loss process is resolved simultaneously with the stellar
dynamics, stellar evolution, and the viscous evolution of the discs. Our
results indicate that external photoevaporation is efficient in depleting disc
masses and that the degree of its effect is related to stellar density. We find
that a local stellar density lower than 100 stars pc$^{-2}$ is necessary for
discs massive enough to form planets to survive for \SI{2.0}{Myr}. There is an
order of magnitude difference in the disc masses in regions of projected
density 100 stars pc$^{-2}$ versus $10^4$ stars pc$^{-2}$. We compare our
results to observations of the Lupus clouds, the Orion Nebula Cluster, the
Orion Molecular Cloud-2, Taurus, and NGC 2024, and find that the trends
observed between region density and disc masses are similar to those in our
simulations.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 15:12:33 GMT""},{""version"":""v3"",""created"":""Fri, 20 Nov 2020 15:01:55 GMT""}]","2020-12-02"
"2006.07379","Amalia Madden","Junwu Huang, Amalia Madden, Davide Racco, Mario Reig","Maximal axion misalignment from a minimal model","35 pages, 9 figures, 1 table. v2: minor modifications, matches
  published version","JHEP 10 (2020) 143","10.1007/JHEP10(2020)143","IFIC/20-22","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The QCD axion is one of the best motivated dark matter candidates. The
misalignment mechanism is well known to produce an abundance of the QCD axion
consistent with dark matter for an axion decay constant of order $10^{12}$ GeV.
For a smaller decay constant, the QCD axion, with Peccei-Quinn symmetry broken
during inflation, makes up only a fraction of dark matter unless the axion
field starts oscillating very close to the top of its potential, in a scenario
called ""large-misalignment"". In this scenario, QCD axion dark matter with a
small axion decay constant is partially comprised of very dense structures. We
present a simple dynamical model realising the large-misalignment mechanism.
During inflation, the axion classically rolls down its potential approaching
its minimum. After inflation, the Universe reheats to a high temperature and a
modulus (real scalar field) changes the sign of its minimum dynamically, which
changes the sign of the mass of a vector-like fermion charged under QCD. As a
result, the minimum of the axion potential during inflation becomes the maximum
of the potential after the Universe has cooled through the QCD phase transition
and the axion starts oscillating. In this model, we can produce QCD axion dark
matter with a decay constant as low as $6\times 10^9\,{\rm GeV}$ and an axion
mass up to 1 meV. We also summarise the phenomenological implications of this
mechanism for dark matter experiments and colliders.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 30 Oct 2020 16:34:20 GMT""}]","2020-11-02"
"2006.07380","Huibert het Lam","Christopher Couzens, Huibert het Lam, Kilian Mayer and Stefan Vandoren","Anomalies of (0,4) SCFTs from F-theory","38 pages, 1 figure; v2: references added, minor corrections",,"10.1007/JHEP08(2020)060",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the macroscopics of 2d $\mathcal{N}=(0,4)$ SCFTs arising from
F-theory constructions. The class of 2d SCFTs we consider live on black strings
which are obtained by wrapping D3-branes on a curve in the base of a possibly
singular elliptically fibered Calabi-Yau threefold. In addition, we allow the
D3-branes to probe ALE or ALF spaces transversely. We compute anomaly
coefficients of these SCFTs by determining Chern-Simons terms in the 3d action
resulting from the reduction of 6d $\mathcal{N}=(1,0)$ supergravity on the
compact space surrounding the black string. Essential contributions to these
coefficients are from one-loop induced Chern-Simons terms arising from
integrating out massive Kaluza-Klein modes.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 15:34:44 GMT""}]","2020-12-02"
"2006.07381","Boris Gaensicke","Boris T. Gaensicke, Detlev Koester, Roberto Raddi, Odette Toloza, S.O.
  Kepler","SDSS J124043.01+671034.68: The partially burned remnant of a low-mass
  white dwarf that underwent thermonuclear ignition?","Accepted for publication in MNRAS",,"10.1093/mnras/staa1761",,"astro-ph.SR astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The white dwarf SDSS J124043.01+671034.68 (SDSS J1240+6710) was previously
found to have an oxygen-dominated atmosphere with significant traces of neon,
magnesium, and silicon. A possible origin via a violent late thermal pulse or
binary interactions have been suggested to explain this very unusual
photospheric composition. We report the additional detection of carbon, sodium,
and aluminium in far-ultraviolet and optical follow-up spectroscopy. No
iron-group elements are detected, with tight upper limits on iron, cobalt and
nickel, suggesting that the star underwent partial oxygen burning, but failed
to ignite silicon burning. Modelling the spectral energy distribution and
adopting the distance based on the Gaia parallax, we infer a low white dwarf
mass, M(wd)=0.41+/-0.05Msun. The large space velocity of SDSS J1240+6710,
computed from the Gaia proper motion and its radial velocity, is compatible
with a Galactic rest-frame velocity of ~250km/s in the opposite direction with
respect to the Galactic rotation, strongly supporting a binary origin of this
star. We discuss the properties of SDSS J1240+6710 in the context of the
recently identified survivors of thermonuclear supernovae, the D6 and LP 40-365
stars, and conclude that it is unlikely related to either of those two groups.
We tentatively suggest that SDSS J1240+6710 is the partially burned remnant of
a low-mass white dwarf that underwent a thermonuclear event.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:02 GMT""}]","2020-07-01"
"2006.07382","Ylva Gotberg","Y. G\""otberg, V. Korol, A. Lamberts, T. Kupfer, K. Breivik, B. Ludwig,
  M.R. Drout","Stars stripped in binaries -- the living gravitational wave sources","Submitted to ApJ",,"10.3847/1538-4357/abbda5",,"astro-ph.SR astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Binary interaction can cause stellar envelopes to be stripped, which
significantly reduces the radius of the star. The orbit of a binary composed of
a stripped star and a compact object can therefore be so tight that the
gravitational radiation the system produces reaches frequencies accessible to
the Laser Interferometer Space Antenna (LISA). Two such stripped stars in tight
orbits with white dwarfs are known so far (ZTF J2130+4420 and CD-30 11223), but
many more are expected to exist. These binaries provide important constraints
for binary evolution models and may be used as LISA verification sources. We
develop a Monte Carlo code that uses detailed evolutionary models to simulate
the Galactic population of stripped stars in tight orbits with either neutron
star or white dwarf companions. We predict 0-100 stripped star + white dwarf
binaries and 0-4 stripped star + neutron star binaries with SNR>5 after 10
years of observations with LISA. More than 90% of these binaries are expected
to show large radial velocity shifts of $\gtrsim 200$ km/s, which are
spectroscopically detectable. Photometric variability due to tidal deformation
of the stripped star is also expected and has been observed in ZTF J2130+4420
and CD-30 11223. In addition, the stripped star + neutron star binaries are
expected to be X-ray bright with $L_X \gtrsim 10^{33} - 10^{36}$ erg/s. Our
results show that stripped star binaries are promising multi-messenger sources
for the upcoming electromagnetic and gravitational wave facilities.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:02 GMT""}]","2020-12-02"
"2006.07383","At{\i}n\c{c} \c{C}a\u{g}an \c{S}eng\""ul","At{\i}n\c{c} \c{C}a\u{g}an \c{S}eng\""ul, Arthur Tsang, Ana Diaz
  Rivero, Cora Dvorkin (Harvard), Hong-Ming Zhu, Uro\v{s} Seljak (Berkeley)","Quantifying the Line-of-Sight Halo Contribution to the Dark Matter
  Convergence Power Spectrum from Strong Gravitational Lenses","24 pages, 8 figures, Matches accepted version, v3: Fixed a typo in
  Eq. C4 in the appendix. No changes in the derivations","Phys. Rev. D 102, 063502 (2020)","10.1103/PhysRevD.102.063502",,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galaxy-galaxy strong gravitational lenses have become a popular probe of dark
matter (DM) by providing a window into structure formation on the smallest
scales. In particular, the convergence power spectrum of subhalos within
lensing galaxies has been suggested as a promising observable to study DM.
However, the distances involved in strong-lensing systems are vast, and we
expect the relevant volume to contain line-of-sight (LOS) halos that are not
associated with the main lens. We develop a formalism to calculate the effect
of LOS halos as an effective convergence power spectrum. The multi-lens plane
equation couples the angular deflections of consecutive lens planes, but by
assuming that the perturbations due to the LOS halos are small, we show that
they can be projected onto the main-lens plane as effective subhalos. We test
our formalism by simulating lensing systems using the full multi-plane lens
equation and find excellent agreement. We show how the relative contribution of
LOS halos and subhalos depends on the source and lens redshift, as well as the
assumed halo and subhalo mass functions. For a fiducial system with fraction of
DM halo mass in substructure $f_{\rm sub}=0.4\%$ for subhalo masses
$[10^5-10^8]\rm{M}_{\odot}$, the interloper contribution to the power spectrum
is at least several times greater than that of subhalos for source redshifts
$z_s\gtrsim0.5$. Furthermore, it is likely that for the SLACS and BELLS lenses
the interloper contribution dominates: $f_{\rm sub}\gtrsim2\%$ ($4\%$) is
needed for subhalos to dominate in SLACS (BELLS), which is higher than current
upper bounds on $f_{\rm sub}$ for our mass range. Since the halo mass function
is better understood from first principles, the dominance of interlopers in
galaxy-galaxy lenses with high-quality imaging can be seen as a significant
advantage when translating this observable into a constraint on DM.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Tue, 15 Sep 2020 14:30:04 GMT""},{""version"":""v3"",""created"":""Wed, 23 Sep 2020 21:39:45 GMT""}]","2020-09-25"
"2006.07384","John Stott","J. P. Stott (Lancaster), R. M. Bielby, F. Cullen, J. N. Burchett, N.
  Tejos, M. Fumagalli, R. A. Crain, S. L. Morris, N. Amos, R. G. Bower and J.
  X. Prochaska","Quasar Sightline and Galaxy Evolution (QSAGE) survey -- II. Galaxy
  overdensities around UV luminous quasars at z=1-2","Published in MNRAS. This is the author accepted version. A small
  number of typos were corrected after journal proof stage","2020, MNRAS, 497, 3083","10.1093/mnras/staa2096",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate that the UV brightest quasars at z=1-2 live in overdense
environments. This is based on an analysis of deep Hubble Space Telescope WFC3
G141 grism spectroscopy of the galaxies along the lines-of-sight to UV luminous
quasars in the redshift range z=1-2. This constitutes some of the deepest grism
spectroscopy performed by WFC3, with 4 roll angles spread over a year of
observations to mitigate the effect of overlapping spectra. Of the 12 quasar
fields studied, 8 display evidence for a galaxy overdensity at the redshift of
the quasar. One of the overdensities, PG0117+213 at z=1.50, has potentially 36
spectroscopically confirmed members, consisting of 19 with secure redshifts and
17 with single-line redshifts, within a cylinder of radius ~700 kpc. Its halo
mass is estimated to be log (M/Msol)=14.7. This demonstrates that spectroscopic
and narrow-band observations around distant UV bright quasars may be an
excellent route for discovering protoclusters. Our findings agree with previous
hints from statistical observations of the quasar population and theoretical
works, as feedback regulated black hole growth predicts a correlation between
quasar luminosity and halo mass. We also present the high signal-to-noise
rest-frame optical spectral and photometric properties of the quasars
themselves.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 11:11:58 GMT""},{""version"":""v3"",""created"":""Thu, 6 Aug 2020 20:14:21 GMT""},{""version"":""v4"",""created"":""Wed, 19 Aug 2020 09:06:30 GMT""}]","2020-08-20"
"2006.07385","Robert Morgan","R. Morgan, M. Soares-Santos, J. Annis, K. Herner, A. Garcia, A.
  Palmese, A. Drlica-Wagner, R. Kessler, J. Garcia-Bellido, T. G. Bachmann N.
  Sherman, S. Allam, K. Bechtol, C. R. Bom, D. Brout, R. E. Butler, M. Butner,
  R. Cartier, H. Chen, C. Conselice, E. Cook, T. M. Davis, Z. Doctor, B. Farr,
  A. L. Figueiredo, D. A. Finley, R. J. Foley, J. Y. Galarza, M. S. S. Gill, R.
  A. Gruendl, D. E. Holz, N. Kuropatkin, C. Lidman, H. Lin, U. Malik, A. W.
  Mann, J. Marriner, J. L. Marshall, C. E. Martinez-Vazquez, N. Meza, E.
  Neilsen, C. Nicolaou, F. Olivares E., F. Paz-Chinchon, S. Points, J. Quirola,
  O. Rodriguez, M. Sako, D. Scolnic, M. Smith, F. Sobreira, D. L. Tucker, A. K.
  Vivas, M. Wiesner, M. L. Wood, B. Yanny, A. Zenteno, T. M. C. Abbott, M.
  Aguena, S. Avila, E. Bertin, S. Bhargava, D. Brooks, D. L. Burke, A. Carnero
  Rosell, M. Carrasco Kind, J. Carretero, L. N. da Costa, M. Costanzi, J. De
  Vicente, S. Desai, H. T. Diehl, P. Doel, T. F. Eifler, S. Everett, B.
  Flaugher, J. Frieman, E. Gaztanaga, D. W. Gerdes, D. Gruen, J. Gschwend, G.
  Gutierrez, W. G. Hartley, S. R. Hinton, D. L. Hollowood, K. Honscheid, D. J.
  James, K. Kuehn, O. Lahav, M. Lima, M. A. G. Maia, M. March, R. Miquel, R. L.
  C. Ogando, A. A. Plazas, A. Roodman, E. Sanchez, V. Scarpine, M. Schubnell,
  S. Serrano, I. Sevilla-Noarbe, E. Suchyta and G. Tarle","Constraints on the Physical Properties of GW190814 through Simulations
  based on DECam Follow-up Observations by the Dark Energy Survey","Published in ApJ","https://ui.adsabs.harvard.edu/abs/2020ApJ...901...83M","10.3847/1538-4357/abafaa",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On 14 August 2019, the LIGO and Virgo Collaborations detected gravitational
waves from a black hole and a 2.6 solar mass compact object, possibly the first
neutron star -- black hole (NSBH) merger. In search of an optical counterpart,
the Dark Energy Survey (DES) obtained deep imaging of the entire 90 percent
confidence level localization area with Blanco/DECam 0, 1, 2, 3, 6, and 16
nights after the merger. Objects with varying brightness were detected by the
DES Pipeline and we systematically reduced the candidate counterparts through
catalog matching, light curve properties, host-galaxy photometric redshifts,
SOAR spectroscopic follow-up observations, and machine-learning-based
photometric classification. All candidates were rejected as counterparts to the
merger. To quantify the sensitivity of our search, we applied our selection
criteria to full light curve simulations of supernovae and kilonovae as they
would appear in the DECam observations. Since the source class of the merger
was uncertain, we utilized an agnostic, three-component kilonova model based on
tidally-disrupted NS ejecta properties to quantify our detection efficiency of
a counterpart if the merger included a NS. We find that if a kilonova occurred
during this merger, configurations where the ejected matter is greater than
0.07 solar masses, has lanthanide abundance less than $10^{-8.56}$, and has a
velocity between $0.18c$ and $0.21c$ are disfavored at the $2\sigma$ level.
Furthermore, we estimate that our background reduction methods are capable of
associating gravitational wave signals with a detected electromagnetic
counterpart at the $4\sigma$ level in $95\%$ of future follow-up observations.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:03 GMT""},{""version"":""v2"",""created"":""Thu, 19 May 2022 18:41:07 GMT""}]","2022-05-23"
"2006.07386","Tim Eschmann","Tim Eschmann, Petr A. Mishchenko, Kevin O'Brien, Troels A. Bojesen,
  Yasuyuki Kato, Maria Hermanns, Yukitoshi Motome, Simon Trebst","Thermodynamic classification of three-dimensional Kitaev spin liquids","27 pages, gauge complement to classification of Majorana physics of
  3D Kitaev models in arXiv:1511.05569","Phys. Rev. B 102, 075125 (2020)","10.1103/PhysRevB.102.075125",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the field of frustrated magnetism, Kitaev models provide a unique
framework to study the phenomena of spin fractionalization and emergent lattice
gauge theories in two and three spatial dimensions. Their ground states are
quantum spin liquids, which can typically be described in terms of a Majorana
band structure and an ordering of the underlying $\mathbb{Z}_2$ gauge
structure. Here we provide a comprehensive classification of the ""gauge
physics"" of a family of elementary three-dimensional Kitaev models, discussing
how their thermodynamics and ground state order depends on the underlying
lattice geometry. Using large-scale, sign-free quantum Monte Carlo simulations
we show that the ground-state gauge order can generally be understood in terms
of the length of elementary plaquettes -- a result which extends the
applicability of Lieb's theorem to lattice geometries beyond its original
scope. At finite temperatures, the proliferation of (gapped) vison excitations
destroys the gauge order at a critical temperature scale, which we show to
correlate with the size of vison gap for the family of three-dimensional Kitaev
models. We also discuss two notable exceptions where the lattice structure
gives rise to ""gauge frustration"" or intertwines the gauge ordering with
time-reversal symmetry breaking. In a more general context, the thermodynamic
gauge transitions in such 3D Kitaev models are one of the most natural settings
for phase transitions beyond the standard Landau-Ginzburg-Wilson paradigm.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:04 GMT""}]","2020-08-20"
"2006.07387","Nashwan Sabti","Nashwan Sabti, Andrii Magalich and Anastasiia Filimonova","An Extended Analysis of Heavy Neutral Leptons during Big Bang
  Nucleosynthesis","66 pages, 17 figures, 10 tables - v3: journal version",,"10.1088/1475-7516/2020/11/056","KCL-2020-09","hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heavy Neutral Leptons (HNLs) are strongly motivated by theory due to their
capability of simultaneously explaining the observed phenomena of dark matter,
neutrino oscillations and the baryon asymmetry of the Universe. The existence
of such particles would affect the expansion history of the Universe and the
synthesis of primordial abundances of light elements. In this work we review,
revise and extend the phenomenology of HNLs during the Big Bang Nucleosynthesis
(BBN) epoch for masses up to 1 GeV. This is of great importance, as BBN is able
to provide complementary bounds to those from upcoming and proposed laboratory
experiments. To this end we have developed a high-precision Boltzmann code that
simulates BBN in the presence of HNLs and takes into account all relevant HNL
decay channels, as well as subsequent interactions of decay products
(thermalization and decay showers), dilution due to QCD phase transition,
active neutrino oscillations and corrections to the weak reaction rates. We
present robust bounds on the lifetime and mixing angles of HNLs for masses
$3\,\mathrm{MeV}\leq m_N \leq 1\,\mathrm{GeV}$ and show that BBN is able to
constrain HNL lifetimes down to $0.03 - 0.05$ s, depending on the mixing
pattern. Moreover, combining our results with current experimental searches, we
can exclude HNLs that mix purely with electron neutrinos up to ${\sim}$450 MeV
and those that mix purely with muon neutrinos up to ${\sim}$360 MeV, in both
cases for lifetimes up to at least a few tens of seconds. Finally, we compare
the BBN constraints with those obtained from Cosmic Microwave Background
observations and explore how our results will be improved by a number of
upcoming and proposed laboratory experiments.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:04 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 17:50:56 GMT""},{""version"":""v3"",""created"":""Wed, 25 Nov 2020 18:01:03 GMT""}]","2020-12-09"
"2006.07388","Lisa Dang","Lisa Dang, Sebastiano Calchi Novati, Sean Carey, Nicolas B. Cowan","Pixel Level Decorrelation in Service of the \textit{Spitzer} Microlens
  Parallax Survey","10 pages, 6 figures, revised manuscript submitted to MNRAS",,"10.1093/mnras/staa2245",,"astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Microlens parallax measurements combining space-based and ground-based
observatories can be used to study planetary demographics. In recent years, the
Spitzer Space Telescope was used as a microlens parallax satellite. Meanwhile,
\textit{Spitzer} IRAC has been employed to study short-period exoplanets and
their atmospheres. As these investigations require exquisite photometry, they
motivated the development of numerous self-calibration techniques now widely
used in the exoplanet atmosphere community. Specifically, Pixel Level
Decorrelation (PLD) was developed for starring-mode observations in uncrowded
fields. We adapt and extend PLD to make it suitable for observations obtained
as part of the \textit{Spitzer} Microlens Parallax Campaign. We apply our
method to two previously published microlensing events, OGLE-2017-BLG-1140 and
OGLE-2015-BLG-0448, and compare its performance to the state-of-the-art
pipeline used to analyses \textit{Spitzer} microlensing observation. We find
that our method yields photometry 1.5--6 times as precise as previously
published. In addition to being useful for \textit{Spitzer}, a similar approach
could improve microlensing photometry with the Nancy Grace Roman Space
Telescope.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:05 GMT""}]","2020-08-12"
"2006.07389","Xiao-Ping Wang","Jia Liu, Navin McGinnis, Carlos E.M. Wagner, Xiao-Ping Wang","Searching for the Higgsino-Bino Sector at the LHC","34 pages, 11 figures; v2: matched to the journal version","JHEP09(2020)073","10.1007/JHEP09(2020)073","EFI-20-11","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the search for electroweakinos at the 13 TeV LHC in the case of
heavy scalar superpartners. We consider both the direct production mode and the
one associated with the decay of heavy Higgs bosons, and concentrate on the
case of light Higgsinos and Binos. In this case, the direct production searches
becomes more challenging than in the light Wino scenario. In the direct
production mode, we use the current experimental searches to set the reach for
these particles at larger luminosities, and we emphasize the relevance of
considering both the neutral gauge boson and the neutral Higgs decay modes of
the second and third lightest neutralino. We show the complementarity of these
searches with the ones induced by the decay of the heavy Higgs bosons, which
are dominated by the associated production of the lightest neutralino with the
second and third lightest ones, with the latter decaying into gauge bosons. We
show that, depending on the value of $\tan\beta$, the Higgs boson decay channel
remains competitive with the direct production channel up to heavy Higgs boson
masses of about 1 TeV. Moreover, this search is not limited by the same
kinematic considerations as the ones in the direct production mode and can
cover masses up to the kinematic threshold for the decay of the heavier
electroweakinos into the lightest neutralino. This decay mode provides also an
alternative way of looking for heavy Higgs bosons in this range of masses and
hence should be a high priority for future LHC analyses.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:00:10 GMT""},{""version"":""v2"",""created"":""Mon, 17 Aug 2020 19:02:18 GMT""},{""version"":""v3"",""created"":""Thu, 20 Aug 2020 07:55:14 GMT""}]","2020-09-14"
"2006.07390","Jake Hanson","Jake R. Hanson and Sara I. Walker","Formalizing Falsification for Theories of Consciousness Across
  Computational Hierarchies","10 pages, 8 figures","Neuroscience of Consciousness, Volume 2021, Issue 2, 2021, niab014","10.1093/nc/niab014",,"cs.AI cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The scientific study of consciousness is currently undergoing a critical
transition in the form of a rapidly evolving scientific debate regarding
whether or not currently proposed theories can be assessed for their scientific
validity. At the forefront of this debate is Integrated Information Theory
(IIT), widely regarded as the preeminent theory of consciousness because of its
quantification of consciousness in terms a scalar mathematical measure called
$\Phi$ that is, in principle, measurable. Epistemological issues in the form of
the ""unfolding argument"" have provided a refutation of IIT by demonstrating how
it permits functionally identical systems to have differences in their
predicted consciousness. The implication is that IIT and any other proposed
theory based on a system's causal structure may already be falsified even in
the absence of experimental refutation. However, so far the arguments
surrounding the issue of falsification of theories of consciousness are too
abstract to readily determine the scope of their validity. Here, we make these
abstract arguments concrete by providing a simple example of functionally
equivalent machines realizable with table-top electronics that take the form of
isomorphic digital circuits with and without feedback. This allows us to
explicitly demonstrate the different levels of abstraction at which a theory of
consciousness can be assessed. Within this computational hierarchy, we show how
IIT is simultaneously falsified at the finite-state automaton (FSA) level and
unfalsifiable at the combinatorial state automaton (CSA) level. We use this
example to illustrate a more general set of criteria for theories of
consciousness: to avoid being unfalsifiable or already falsified scientific
theories of consciousness must be invariant with respect to changes that leave
the inference procedure fixed at a given level in a computational hierarchy.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:05:46 GMT""},{""version"":""v2"",""created"":""Sat, 5 Sep 2020 16:31:31 GMT""}]","2021-08-16"
"2006.07391","Dogan Timucin","Ali Eshaghian Dorche, Dogan Timucin, Krishnan Thyagarajan, Thomas
  Wunderer, Noble Johnson and David Schwartz","Advanced dispersion engineering of a III-Nitride micro-resonator for a
  blue/UV frequency comb",,,"10.1364/OE.399901",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A systematic dispersion engineering approach is presented toward designing a
III-Nitride micro-resonator for a blue/UV frequency comb. The motivation for
this endeavor is to fill the need for compact, coherent, multi-wavelength
photon sources that can be paired with, e.g., the $^{171}{\textrm{Yb}}^{+}$ ion
in a photonic integrated chip for optical sensing, time-keeping, and quantum
computing applications. The challenge is to overcome the normal material
dispersion exhibited by the otherwise ideal i.e., low-loss and
large-Kerr-coefficient) AlGaN family of materials, as this is a prerequisite
for bright-soliton Kerr comb generation. The proposed approach exploits the
avoided-crossing phenomenon in coupled waveguides to achieve strong anomalous
dispersion in a desired wavelength range. The resulting designs reveal a wide
range of dispersion response tunability, and are realizable with the current
state-of-the-art growth and fabrication methods for AlGaN semiconductors.
Numerical simulations of the spatio-temporal evolution of the intra-cavity
field under continuous-wave laser pumping indicate that such a structure is
capable of generating a broadband blue/UV bright-soliton Kerr frequency comb.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:08:42 GMT""}]","2020-10-28"
"2006.07392","Ka Wai Wong","Ka Wai Wong","Application of Mean Curvature Flow for Surface Parametrizations","5 pages, 13 figures","In ""Mean Curvature Flow"", Proceedings of the John H. Barrett
  Memorial Lectures Held at the University of Tennessee, Knoxville, May 29 -
  June 1, 2018",,,"cs.CG math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is an expository article describing the conformalized mean curvature
flow, originally introduced by Kazhdan, Solomon, and Ben-Chen. We are
interested in applying mean curvature flow to surface parametrizations. We
discuss our own implementation of their algorithm and some limitations.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:08:54 GMT""}]","2020-06-16"
"2006.07393","Karla Z. Arellano-C\'ordova","K. Z. Arellano-C\'ordova and M. Rodr\'iguez","The Te[N II]-Te[O III] temperature relation in H II regions and the
  reliability of strong-line methods","22 pages, 11 figures and 6 Tables. Accepted for publication in MNRAS",,"10.1093/mnras/staa1759",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use a sample of 154 observations of 124 H II regions that have
measurements of both Te[O III] and Te[N II], compiled from the literature, to
explore the behaviour of the Te[O III]-Te[N II] temperature relation. We
confirm that the relation depends on the degree of ionization and present a new
set of relations for two different ranges of this parameter. We study the
effects introduced by our temperature relations and four other available
relations in the calculation of oxygen and nitrogen abundances. We find that
our relations improve slightly on the results obtained with the previous ones.
We also use a sample of 26 deep, high-resolution spectra to estimate the
contribution of blending to the intensity of the temperature-sensitive line [O
III] $\lambda4363$, and we derive a relation to correct Te[O III] for this
effect. With our sample of 154 spectra, we analyse the reliability of the R, S,
O3N2, N2, ONS, and C strong-line methods by comparing the metallicity obtained
with these methods with the one implied by the direct method. We find that the
strong-line methods introduce differences that reach ~ 0.2 dex or more, and
that these differences depend on O/H, N/O, and the degree of ionization.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:09:53 GMT""}]","2020-07-29"
"2006.07394","G.R. Boroun","B.Rezaei and G.R.Boroun","Searching for top quark pair production cross section at LHeC and FCC-eh",,"EPL, 130 (2020) 51002","10.1209/0295-5075/130/51002",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The deep inelastic scattering mode of $t\overline{t}$ pair production at the
proposed LHeC and FCC-eh is considered. We present a method to extract the top
reduced cross section related to the transversal structure function
$F_{2}(x,Q^{2})$ parameterization. Numerical calculations with known kinematics
of the LHeC and FCC-eh colliders are demonstrated. The results obtained for
charm and beauty pair production are comparable with the experimental data. We
show that for a wide range of the momentum transfer into the top quark pair,
the reduced cross section is well described by center-of-mass energies.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:11:36 GMT""}]","2020-07-07"
"2006.07395","Shikha Saini","Shikha Saini, Pooja Basera, Manish Kumar, Preeti Bhumla, Saswata
  Bhattacharya","Metastability Triggered Reactivity in Clusters at Realistic Conditions:
  A Case Study of N-doped (TiO$_2$)$_n$ for Photocatalysis","36 pages, 11 figures","J. Phys. Mater. 4 015001 (2020)","10.1088/2515-7639/abc090",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here we report a strategy, by taking a prototypical model system for
photocatalysis (viz. N-doped (TiO$_2$)$_n$ clusters), to accurately determine
low energy metastable structures that can play a major role with enhanced
catalytic reactivity. Computational design of specific metastable photocatalyst
with enhanced activity is never been easy due to plenty of isomers on potential
energy surface. This requires fixing various parameters viz. (i) favorable
formation energy, (ii) low fundamental gap, (iii) low excitation energy and
(iv) high vertical electron affinity (VEA) and low vertical ionization
potential (VIP). We validate here by integrating several first principles based
methodologies that consideration of the global minimum structure alone can
severely underestimate the activity. As a first step, we have used a suite of
genetic algorithms [viz. searching clusters with conventional minimum total
energy ((GA)$_\textrm{E}$); searching clusters with specific property i.e. high
VEA ((GA)$_\textrm{P}^{\textrm{EA}}$), and low VIP
((GA)$_\textrm{P}^{\textrm{IP}}$)] to model the N-doped (TiO$_2$)$_n$ clusters.
Following this, we have identified its free energy using ab initio
thermodynamics to confirm that the metastable structures are not too far from
the global minima. By analyzing a large dataset, we find that N-substitution
((N)$_\textrm{O}$) prefers to reside at highly coordinated oxygen site to
maximize its coordination, whereas N-interstitial ((NO)$_\textrm{O}$) and
split-interstitial ((N$_2)_\textrm{O}$) favor the dangling oxygen site.
Interestingly, we notice that each types of defect (viz. substitution,
interstitials) reduce the fundamental gap and excitation energy substantially.
However, (NO)$_\textrm{O}$ and (N$_2)_\textrm{O}$ doped clusters are the
potential candidates for overall water splitting, whereas N$_\textrm{O}$ is
congenial only for oxygen evolution reaction.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:11:42 GMT""}]","2021-01-26"
"2006.07396","Aleksandr Orlov Yur'evich","Sergey M. Natanzon, Aleksandr Yu. Orlov","Hurwitz numbers from Feynman diagrams","a number of corrections",,"10.1134/S0040577920090068",,"math-ph math.MP nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain Hurwitz numbers as the number of Feynman diagrams of a certain type
divided by the order of the automorphism group of the diagram.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:15:01 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 17:59:19 GMT""}]","2020-10-28"
"2006.07397","Cristian Canton Ferrer","Brian Dolhansky, Joanna Bitton, Ben Pflaum, Jikuo Lu, Russ Howes,
  Menglin Wang, Cristian Canton Ferrer","The DeepFake Detection Challenge (DFDC) Dataset",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deepfakes are a recent off-the-shelf manipulation technique that allows
anyone to swap two identities in a single video. In addition to Deepfakes, a
variety of GAN-based face swapping methods have also been published with
accompanying code. To counter this emerging threat, we have constructed an
extremely large face swap video dataset to enable the training of detection
models, and organized the accompanying DeepFake Detection Challenge (DFDC)
Kaggle competition. Importantly, all recorded subjects agreed to participate in
and have their likenesses modified during the construction of the face-swapped
dataset. The DFDC dataset is by far the largest currently and publicly
available face swap video dataset, with over 100,000 total clips sourced from
3,426 paid actors, produced with several Deepfake, GAN-based, and non-learned
methods. In addition to describing the methods used to construct the dataset,
we provide a detailed analysis of the top submissions from the Kaggle contest.
We show although Deepfake detection is extremely difficult and still an
unsolved problem, a Deepfake detection model trained only on the DFDC can
generalize to real ""in-the-wild"" Deepfake videos, and such a model can be a
valuable analysis tool when analyzing potentially Deepfaked videos. Training,
validation and testing corpuses can be downloaded from
https://ai.facebook.com/datasets/dfdc.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:15:55 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 04:28:03 GMT""},{""version"":""v3"",""created"":""Thu, 25 Jun 2020 01:22:11 GMT""},{""version"":""v4"",""created"":""Wed, 28 Oct 2020 03:48:28 GMT""}]","2020-10-29"
"2006.07398","Arman Kabiri","Arman Kabiri, Paul Cook","Evaluating a Multi-sense Definition Generation Model for Multiple
  Languages","To be presented orally in 23rd International Conference on Text,
  Speech and Dialogue (TSD 2020)",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most prior work on definition modeling has not accounted for polysemy, or has
done so by considering definition modeling for a target word in a given
context. In contrast, in this study, we propose a context-agnostic approach to
definition modeling, based on multi-sense word embeddings, that is capable of
generating multiple definitions for a target word. In further, contrast to most
prior work, which has primarily focused on English, we evaluate our proposed
approach on fifteen different datasets covering nine languages from several
language families. To evaluate our approach we consider several variations of
BLEU. Our results demonstrate that our proposed multi-sense model outperforms a
single-sense model on all fifteen datasets.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:15:59 GMT""}]","2020-06-16"
"2006.07399","Igor Proskurin Dr","Igor Proskurin and Robert L. Stamps","Symmetry Approach to Chiral Optomagnonics in Antiferromagnetic
  Insulators","Book chapter for ""Chirality, Magnetism and Magnetoelectricity"", 33
  pages, 4 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss several aspects of chiral optomagnonics in antiferromagnetic
insulators by considering common symmetries between the electromagnetic field
and spin excitations. This approach allows us to look at optical and magnetic
materials from similar perspectives, and discuss useful analogies between them.
We show that spin waves in collinear antiferromagnets and the electromagnetic
field in vacuum are both invariant under the same eight-dimensional algebra of
symmetry transformations. By such analogy, we can extend the concept of optical
chirality to antiferromagnetic insulators, and demonstrate that the spin-wave
dynamics in these materials in the presence of a spin current is similar to
that of the light inside chiral metamaterials. Photo-excitation of magnonic
spin currents is also discussed from the symmetry point of view. It is
demonstrated that a direct magnonic spin photocurrent can be exited by
circularly polarized light, which can be considered as a magnonic analogue of
the photogalvanic effect. We also note that the Zitterbewegung process should
appear and may play a role in photo-excitation processes.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:16:09 GMT""}]","2020-06-16"
"2006.07400","Aron Vanselow","Aron Vanselow, Paul Kaufmann, Ivan Zorin, Bettina Heise, Helen M.
  Chrzanowski and Sven Ramelow","Frequency-domain optical coherence tomography with undetected
  mid-infrared photons",,,,,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mid-infrared light scatters much less than shorter wavelengths, allowing
greatly enhanced penetration depths for optical imaging techniques such as
optical coherence tomography (OCT). However, both detection and broadband
sources in the mid-IR are technologically challenging. Interfering entangled
photons in a nonlinear interferometer enables sensing with undetected photons
making mid-IR sources and detectors obsolete. Here we implement mid-infrared
frequency-domain OCT based on ultra-broadband entangled photon pairs. We
demonstrate 10 ${\mu}$m axial and 20 ${\mu}$m lateral resolution 2D and 3D
imaging of strongly scattering ceramic and paint samples. Together with $10^6$
times less noise scaled for the same amount of probe light and also vastly
reduced footprint and technical complexity this technique can outperform
conventional approaches with classical mid-IR light.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:18:38 GMT""}]","2020-06-16"
"2006.07401","C\'esar Mart\'inez","Aur\'elien Galateau, C\'esar Mart\'inez","Homoth\'eties explicites des repr\'esentations $\ell$-adiques","19 pages, in French. This second version uses new results by Gaudron
  and R\'emond on isogenies",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present classical and new results on the size of the subgroup of
homotheties of $\ell$-adic representations associated to the torsion of an
abelian variety. From these estimates, we derive uniform and explicit bounds
for the Manin-Mumford problem.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:19:07 GMT""},{""version"":""v2"",""created"":""Fri, 11 Sep 2020 12:40:27 GMT""}]","2020-09-14"
"2006.07402","Umair Mohammad","Umair Mohammad, Sameh Sorour and Mohamed Hefeida","Jointly Optimizing Dataset Size and Local Updates in Heterogeneous
  Mobile Edge Learning","7 pages, 3 figures, This paper has been submitted to the IEEE for
  possible publication",,,,"eess.SP cs.DC cs.LG","http://creativecommons.org/licenses/by/4.0/","  This paper proposes to maximize the accuracy of a distributed machine
learning (ML) model trained on learners connected via the resource-constrained
wireless edge. We jointly optimize the number of local/global updates and the
task size allocation to minimize the loss while taking into account
heterogeneous communication and computation capabilities of each learner. By
leveraging existing bounds on the difference between the training loss at any
given iteration and the theoretically optimal loss, we derive an expression for
the objective function in terms of the number of local updates. The resulting
convex program is solved to obtain the optimal number of local updates which is
used to obtain the total updates and batch sizes for each learner. The merits
of the proposed solution, which is heterogeneity aware (HA), are exhibited by
comparing its performance to the heterogeneity unaware (HU) approach.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:19:20 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jul 2020 17:30:57 GMT""},{""version"":""v3"",""created"":""Mon, 22 Feb 2021 05:17:27 GMT""}]","2021-02-23"
"2006.07403","Carey Lisse","Carey M. Lisse, Steven J. Desch, Cayman T. Unterborn, Stephen R. Kane,
  Patrick R. Young, Hilairy E. Hartnett, Natalie R. Hinkel, Sang Heon Shim,
  Eric E. Mamajek, Noam R. Izenberg","A Geologically Robust Procedure For Observing Rocky Exoplanets to Ensure
  that Detection of Atmospheric Oxygen is an Earth-Like Biosignature","27 Pages, 1 Figure, 0 Tables (accepted 09 June 2020, in press)","Astrophysical Journal Letters 2020","10.3847/2041-8213/ab9b91",,"astro-ph.EP astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the next decades, the astrobiological community will debate whether the
first observations of oxygen in an exoplanet$'$s atmosphere signifies life, so
it is critical to establish procedures now for collection and interpretation of
such data. We present a step-by-step observational strategy for using oxygen as
a robust biosignature, to prioritize exoplanet targets and design future
observations. It is premised on avoiding planets lacking subaerial weathering
of continents, which would imply geochemical cycles drastically different from
Earth$'$s, precluding use of oxygen as a biosignature. The strategy starts with
the most readily obtained data: semi-major axis and stellar luminosity to
ensure residence in the habitable zone; stellar XUV flux, to ensure an
exoplanet can retain a secondary (outgassed) atmosphere. Next, high-precision
mass and radius information should be combined with high-precision stellar
abundance data, to constrain the exoplanet$'$s water content; those
incompatible with less than 0.1 wt % H$_{2}$O can be deprioritized. Then,
reflectance photometry or low-resolution transmission spectroscopy should
confirm an optically thin atmosphere. Subsequent long-duration, high-resolution
transmission spectroscopy should search for oxygen and ensure that water vapor
and CO$_{2}$ are present only at low (10$^{2}$-10$^{4}$ ppm levels). Assuming
oxygen is found, attribution to life requires the difficult acquisition of a
detailed, multispectral light curve of the exoplanet to ensure both surface
land and water. Exoplanets failing some of these steps might be habitable, even
have observable biogenic oxygen, but should be deprioritized because oxygen
could not be attributed unambiguously to life. We show how this is the case for
the Solar System, the 55 Cnc System, and the TRAPPIST-1 System, in which only
the Earth and TRAPPIST-1e successfully pass through our procedure.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:19:26 GMT""}]","2020-07-29"
"2006.07404","Renata Rychtarikova","Kirill Lonhus, Renata Rychtarikova, Ali Ghaznavi, Dalibor Stys","Estimation of rheological parameters for unstained living cells","14 pages, 4 figures","Eur. Phys. J. Spec. Top. 230(2) (2021)","10.1140/epjs/s11734-021-00084-2",,"physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In video-records, objects moving in intracellular regions are often hardly
detectable and identifiable. In order to squeeze the information on the
intracellular flows, we propose an automatic method of reconstruction of
intracellular flow velocity fields based only on a recorded video of an
unstained cell. The basis of the method is detection of speeded-up robust
features (SURF) and assembling them into trajectories. Two components of motion
-- direct and Brownian -- are separated by an original method based on minimum
covariance estimation. The Brownian component gives a spatially resolved
diffusion coefficient. The directed component yields a velocity field, and,
after fitting the vorticity equation, estimation of the spatially distributed
effective viscosity. The method was applied to videos of a human osteoblast and
a hepatocyte. The obtained parameters are in agreement with literature data.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:20:02 GMT""},{""version"":""v2"",""created"":""Mon, 28 Sep 2020 10:23:13 GMT""},{""version"":""v3"",""created"":""Tue, 27 Oct 2020 15:02:42 GMT""},{""version"":""v4"",""created"":""Thu, 15 Apr 2021 16:19:11 GMT""}]","2022-01-13"
"2006.07405","Subhadeep Bhattacharya","Subhadeep Bhattacharya, Weikuan Yu and Fahim Tahmid Chowdhury","O(1) Communication for Distributed SGD through Two-Level Gradient
  Averaging",,,,,"cs.LG cs.DC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large neural network models present a hefty communication challenge to
distributed Stochastic Gradient Descent (SGD), with a communication complexity
of O(n) per worker for a model of n parameters. Many sparsification and
quantization techniques have been proposed to compress the gradients, some
reducing the communication complexity to O(k), where k << n. In this paper, we
introduce a strategy called two-level gradient averaging (A2SGD) to consolidate
all gradients down to merely two local averages per worker before the
computation of two global averages for an updated model. A2SGD also retains
local errors to maintain the variance for fast convergence. Our theoretical
analysis shows that A2SGD converges similarly like the default distributed SGD
algorithm. Our evaluation validates the theoretical conclusion and demonstrates
that A2SGD significantly reduces the communication traffic per worker, and
improves the overall training time of LSTM-PTB by 3.2x and 23.2x, respectively,
compared to Top-K and QSGD. To the best of our knowledge, A2SGD is the first to
achieve O(1) communication complexity per worker for distributed SGD.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:20:52 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 01:49:28 GMT""}]","2020-06-17"
"2006.07406","Adri\`a Delhom","Jose Beltr\'an Jim\'enez, Daniel de Andr\'es and Adri\`a Delhom","Anisotropic deformations in a class of projectively-invariant
  metric-affine theories of gravity","31 pages, 5 figures, 1 column",,"10.1088/1361-6382/abb923",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among the general class of metric-affine theories of gravity, there is a
special class conformed by those endowed with a projective symmetry. Perhaps
the simplest manner to realise this symmetry is by constructing the action in
terms of the symmetric part of the Ricci tensor. In these theories, the
connection can be solved algebraically in terms of a metric that relates to the
spacetime metric by means of the so-called deformation matrix that is given in
terms of the matter fields. In most phenomenological applications, this
deformation matrix is assumed to inherit the symmetries of the matter sector so
that in the presence of an isotropic energy-momentum tensor, it respects
isotropy. In this work we discuss this condition and, in particular, we show
how the deformation matrix can be anisotropic even in the presence of isotropic
sources due to the non-linear nature of the equations. Remarkably, we find that
Eddington-inspired-Born-Infeld theories do not admit anisotropic deformations,
but more general theories do. However, we find that the anisotropic branches of
solutions are generally prone to a pathological physical behaviour.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:21:58 GMT""}]","2021-04-23"
"2006.07407","Wako Ishibashi","W. Ishibashi, M. Gr\""obner","Evolution of binary black holes in AGN accretion discs: Disc-binary
  interaction and gravitational wave emission","accepted for publication in A&A","A&A 639, A108 (2020)","10.1051/0004-6361/202037799",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Binary black hole (BBH) mergers are the primary sources of gravitational wave
(GW) events detected by LIGO/Virgo. Binary black holes embedded in the
accretion discs of active galactic nuclei (AGN) are possible candidates for
such GW events. We develop an idealised analytic model for the orbital
evolution of BBHs in AGN accretion discs by combining the evolution equations
of disc-binary interaction and GW inspiral. We investigate the coupled
`disc+GW'-driven evolution of BBHs transitioning from the disc-driven regime at
large orbital separations into the GW-driven regime at small separations. In
this evolution channel, BBH mergers are accelerated by a combination of orbital
decay and orbital eccentricity growth in the disc-dominated regime. We provide
a quantification of the resulting merger timescale $\tau_\text{merger}$, and
analyse its dependence on both the accretion disc and binary orbital
parameters. By computing the evolution of the orbital eccentricity as a
function of the GW frequency, we predict that most binaries in AGN discs should
have significant residual eccentricities ($e \sim 0.01-0.1$), potentially
detectable by LISA. We further discuss the potentials and caveats of this
particular BBH-in-AGN channel in the framework of binary evolutionary paths.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:22:09 GMT""}]","2020-07-22"
"2006.07408","Daniel Fischer","A.H.N.C. De Silva, D. Atri-Schuller, S. Dubey, B.P. Acharya, K.L.
  Romans, K. Foster, O. Russ, K. Compton, C. Rischbieter, N. Douguet, K.
  Bartschat, D. Fischer","Using circular dichroism to control energy transfer in multi-photon
  ionization",,"Phys. Rev. Lett. 126, 023201 (2021)","10.1103/PhysRevLett.126.023201",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chirality causes symmetry breaks in a large variety of natural phenomena
ranging from particle physics to biochemistry. We investigate one of the
simplest conceivable chiral systems, a laser-excited, oriented, effective
one-electron Li target. Prepared in a polarized p state with |m|=1 in an
optical trap, the atoms are exposed to co- and counter-rotating circularly
polarized femtosecond laser pulses. For a field frequency near the excitation
energy of the oriented initial state, a strong circular dichroism is observed
and the photoelectron energies are significantly affected by the
helicity-dependent Autler-Townes splitting. Besides its fundamental relevance,
this system is suited to create spin-polarized electron pulses with a
reversible switch on a femtosecond timescale at an energy resolution of a few
meV.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:22:14 GMT""},{""version"":""v2"",""created"":""Mon, 26 Oct 2020 22:03:13 GMT""},{""version"":""v3"",""created"":""Tue, 12 Jan 2021 17:55:58 GMT""}]","2021-01-13"
"2006.07409","Prithviraj Ammanabrolu","Prithviraj Ammanabrolu, Ethan Tien, Matthew Hausknecht, Mark O. Riedl","How to Avoid Being Eaten by a Grue: Structured Exploration Strategies
  for Textual Worlds",,,,,"cs.AI cs.CL cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text-based games are long puzzles or quests, characterized by a sequence of
sparse and potentially deceptive rewards. They provide an ideal platform to
develop agents that perceive and act upon the world using a combinatorially
sized natural language state-action space. Standard Reinforcement Learning
agents are poorly equipped to effectively explore such spaces and often
struggle to overcome bottlenecks---states that agents are unable to pass
through simply because they do not see the right action sequence enough times
to be sufficiently reinforced. We introduce Q*BERT, an agent that learns to
build a knowledge graph of the world by answering questions, which leads to
greater sample efficiency. To overcome bottlenecks, we further introduce
MC!Q*BERT an agent that uses an knowledge-graph-based intrinsic motivation to
detect bottlenecks and a novel exploration strategy to efficiently learn a
chain of policy modules to overcome them. We present an ablation study and
results demonstrating how our method outperforms the current state-of-the-art
on nine text games, including the popular game, Zork, where, for the first
time, a learning agent gets past the bottleneck where the player is eaten by a
Grue.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:24:06 GMT""}]","2020-06-16"
"2006.07410","Sergei Nechaev","A. Valov, V. Avetisov, S. Nechaev, and G. Oshanin","Field-driven tracer diffusion through curved bottlenecks: Fine structure
  of first passage events","9 pages, 8 figures",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using scaling arguments and extensive numerical simulations, we study
dynamics of a tracer particle in a corrugated channel represented by a periodic
sequence of broad chambers and narrow funnel-like bottlenecks enclosed by a
hard-wall boundary. A tracer particle is affected by an external force pointing
along the channel, and performs an unbiased diffusion in the perpendicular
direction. We present a detailed analysis a) of the distribution function of
the height above the funnel's boundary at which the first crossing of a given
bottleneck takes place, and b) of the distribution function of the first
passage time to such an event. Our analysis reveals several new features of the
dynamical behaviour which are overlooked in the studies based on the
Fick-Jacobs approach. In particular, trajectories passing through a funnel
concentrate predominantly on its boundary, which makes first-crossing events
very sensitive to the presence of binding sites and a microscopic roughness.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:25:06 GMT""}]","2020-06-16"
"2006.07411","Meagan Carney","Meagan Carney, Holger Kantz","Sources and Sinks of Rare Trajectories in 2-Dimensional Velocity Fields
  Identified by Importance Sampling","20 pages, 10 figures",,,,"nlin.CD math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use importance sampling in a redefined way to highlight and investigate
rare events in the form of trajectories trapped inside a target coherent set.
We take a transfer operator approach to finding these sets on a reconstructed
2-dimensional flow of the atmosphere from wind velocity fields provided by the
Portable University Model of the Atmosphere. Motivated by extreme value theory,
we consider an observable $\phi(x) = -\log(d(x,\gamma))$ maximized at the
center $\gamma$ of a chosen target coherent set, where it is rare for a
particle to transition. We illustrate that importance sampling maximizing this
observable provides an enriched data set of trajectories that experience such a
rare event. Backwards reconstruction of these trajectories provides valuable
information on initial conditions and most likely paths a trajectory will take.
With this information, we are able to obtain more accurate estimates of rare
transition probabilities compared to those of standard integration techniques.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:27:40 GMT""},{""version"":""v2"",""created"":""Thu, 15 Oct 2020 11:01:08 GMT""}]","2020-10-16"
"2006.07412","Eli Shlizerman","Yang Zheng, Jinlin Xiang, Kun Su, Eli Shlizerman","BI-MAML: Balanced Incremental Approach for Meta Learning","Please see associated video at: https://youtu.be/4qlb-iG5SFo",,,,"cs.LG cs.CV cs.RO q-bio.NC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel Balanced Incremental Model Agnostic Meta Learning system
(BI-MAML) for learning multiple tasks. Our method implements a meta-update rule
to incrementally adapt its model to new tasks without forgetting old tasks.
Such a capability is not possible in current state-of-the-art MAML approaches.
These methods effectively adapt to new tasks, however, suffer from
'catastrophic forgetting' phenomena, in which new tasks that are streamed into
the model degrade the performance of the model on previously learned tasks. Our
system performs the meta-updates with only a few-shots and can successfully
accomplish them. Our key idea for achieving this is the design of balanced
learning strategy for the baseline model. The strategy sets the baseline model
to perform equally well on various tasks and incorporates time efficiency. The
balanced learning strategy enables BI-MAML to both outperform other
state-of-the-art models in terms of classification accuracy for existing tasks
and also accomplish efficient adaption to similar new tasks with less required
shots. We evaluate BI-MAML by conducting comparisons on two common benchmark
datasets with multiple number of image classification tasks. BI-MAML
performance demonstrates advantages in both accuracy and efficiency.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:28:48 GMT""}]","2020-06-16"
"2006.07413","Anton Izosimov","Quinton Aboud, Anton Izosimov","The limit point of the pentagram map and infinitesimal monodromy","10 pages, 4 figures; final version accepted to IMRN",,,,"nlin.SI math.DG math.DS math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The pentagram map takes a planar polygon $P$ to a polygon $P'$ whose vertices
are the intersection points of consecutive shortest diagonals of $P$. The orbit
of a convex polygon under this map is a sequence of polygons which converges
exponentially to a point. Furthermore, as recently proved by Glick, coordinates
of that limit point can be computed as an eigenvector of a certain operator
associated with the polygon. In the present paper we show that Glick's operator
can be interpreted as the infinitesimal monodromy of the polygon. Namely, there
exists a certain natural infinitesimal perturbation of a polygon, which is
again a polygon but in general not closed; what Glick's operator measures is
the extent to which this perturbed polygon does not close up.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:35:43 GMT""},{""version"":""v2"",""created"":""Wed, 19 Aug 2020 23:36:57 GMT""}]","2020-08-21"
"2006.07414","Nick Sterling","N. C. Sterling (University of West Georgia)","Neutron-Capture Element Abundances in Planetary Nebulae","9 pages, one figure, to appear in Proceedings of WORKPLANS II
  (Lorentz Center Workshop, Leiden, the Netherlands, December 2019), edited by
  T. Ueta, accepted for publication by Galaxies",,,,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nebular spectroscopy is a valuable tool for assessing the production of heavy
elements by slow neutron(n)-capture nucleosynthesis (the s-process). Several
transitions of n-capture elements have been identified in planetary nebulae
(PNe) in the last few years, with the aid of sensitive high-resolution
near-infrared spectrometers. Combined with optical spectroscopy, the newly
discovered near-infrared lines enable more accurate abundance determinations
than previously possible, and provide access to elements that had not
previously been studied in PNe or their progenitors. Neutron-capture elements
have also been detected in PNe in the Sagittarius Dwarf galaxy and in the
Magellanic Clouds. In this brief review, I discuss developments in
observational studies of s-process enrichments in PNe, with an emphasis on the
last five years, and note some open questions and preliminary trends.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:42:20 GMT""}]","2020-06-16"
"2006.07415","Leonard Kwuida","Blaise B. Koguep Njionou, Leonard Kwuida and Celestin Lele","Formal Concepts and Residuation on Multilattices","21 pages, 6 figures",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multilattices are generalisations of lattices introduced by Mihail Benado. He
replaced the existence of unique lower (resp. upper) bound by the existence of
maximal lower (resp. minimal upper) bound(s). A multilattice will be called
pure if it is not a lattice. Multilattices could be endowed with a residuation,
and therefore used as set of truth-values to evaluate elements in fuzzy
setting. In this paper we exhibit the smallest pure multilattice and show that
it is a sub-multilattice of any pure multilattice. We also prove that any
bounded residuated multilattice that is not a residuated lattice has at least
seven elements. We apply the ordinal sum construction to get more examples of
residuated multilattices that are not residuated lattices. We then use these
residuated multilattices to evaluate objects and attributes in formal concept
analysis setting, and describe the structure of the set of corresponding formal
concepts. More precisely, if $\mathcal{A}_i:
=(A_i,\le_i,\top_i,\odot_i,\to_i,\bot_i)$, $i=1,2$ are two complete residuated
multilattices, $G$ and $M$ two nonempty sets and $(\varphi, \psi)$ a Galois
connection between $A_1^G$ and $A_2^M$ that is compatible with the residuation,
then we show that
  \[\mathcal{C}: =\{(h,f)\in A_1^G\times A_2^M; \varphi(h)=f \text{ and }
\psi(f)=h \}\] can be endowed with a complete residuated multilattice
structure. This is a generalization of a result by Ruiz-Calvi{\~n}o and Medina
saying that if the (reduct of the) algebras $\mathcal{A}_i$, $i=1,2$ are
complete multilattices, then $\mathcal{C}$ is a complete multilattice.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:42:25 GMT""},{""version"":""v2"",""created"":""Tue, 18 Jan 2022 05:50:34 GMT""},{""version"":""v3"",""created"":""Tue, 27 Sep 2022 04:26:39 GMT""},{""version"":""v4"",""created"":""Wed, 19 Apr 2023 10:59:13 GMT""},{""version"":""v5"",""created"":""Wed, 24 May 2023 11:22:04 GMT""}]","2023-05-25"
"2006.07416","Kewen Peng","Kewen Peng, Tim Menzies","Defect Reduction Planning (using TimeLIME)","15 pages, 5 figures, 12 tables, accepted by TSE. arXiv admin note:
  substantial text overlap with arXiv:2003.06887",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Software comes in releases. An implausible change to software is something
that has never been changed in prior releases. When planning how to reduce
defects, it is better to use plausible changes, i.e., changes with some
precedence in the prior releases.
  To demonstrate these points, this paper compares several defect reduction
planning tools. LIME is a local sensitivity analysis tool that can report the
fewest changes needed to alter the classification of some code module (e.g.,
from ""defective"" to ""non-defective""). TimeLIME is a new tool, introduced in
this paper, that improves LIME by restricting its plans to just those
attributes which change the most within a project.
  In this study, we compared the performance of LIME and TimeLIME and several
other defect reduction planning algorithms. The generated plans were assessed
via (a) the similarity scores between the proposed code changes and the real
code changes made by developers; and (b) the improvement scores seen within
projects that followed the plans. For nine project trails, we found that
TimeLIME outperformed all other algorithms (in 8 out of 9 trials). Hence, we
strongly recommend using past releases as a source of knowledge for computing
fixes for new releases (using TimeLIME).
  Apart from these specific results about planning defect reductions and
TimeLIME, the more general point of this paper is that our community should be
more careful about using off-the-shelf AI tools, without first applying SE
knowledge. In this case study, it was not difficult to augment a standard AI
algorithm with SE knowledge (that past releases are a good source of knowledge
for planning defect reductions). As shown here, once that SE knowledge is
applied, this can result in dramatically better systems.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:43:02 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 10:59:54 GMT""}]","2021-02-16"
"2006.07417","Zhao Guo","Zhao Guo","Tidal Asteroseismology: Possible Evidence of Non-linear Mode Coupling in
  an Equilibrium State in Kepler Eclipsing Binary KIC 3230227","ApJ, in press",,"10.3847/1538-4357/ab911f",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Previously, a series of tidally-excited oscillations were discovered in the
eccentric eclipsing binary KIC 3230227. The pulsation amplitudes and phases
suggest the observed oscillations are prograde quadruple modes. In this paper,
we refine the analysis and extract more oscillation frequencies. We also study
the temporal variations of amplitudes and phases and show that almost all modes
have stable phases and amplitudes. We then focus on the non-orbital-harmonic
oscillations. We consider two formation mechanisms: 1) nonlinear response of
the surface convective layer, and 2) nonlinear three/multi-mode coupling.
Although the former can explain some of the observed features, we find the
latter mechanism is more probable. Assuming that these are coupled modes, the
constant amplitude/phase over four years can be explained by either an
equilibrium state in the mode coupling or modes undergoing limit cycles with
very long periods. The observed frequency detuning and the calculated damping
rates of the daughter modes favor the equilibrium-state interpretation. This is
verified by integrating the amplitude equations of three-mode coupling. We find
that the steady-state relation derived in Weinberg et al., which relates the
observed frequency detuning, phase detuning, and mode damping rates, is
approximately satisfied for one mode triplet. We also try to identify the
azimuthal number of the modes based on the observed mode amplitude ratios and
the selection rules in nonlinear three-mode coupling. We discuss further
implications of these observations on nonlinear tidal asteroseismology.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:45:00 GMT""}]","2020-07-01"
"2006.07418","Valerio Faraoni","Valerio Faraoni and Farah Atieh","Turning a Newtonian analogy for FLRW cosmology into a relativistic
  problem","12 pages","Phys. Rev. D 102, 044020 (2020)","10.1103/PhysRevD.102.044020",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Newtonian uniform ball expanding in empty space constitutes a common
heuristic analogy for FLRW cosmology. We discuss possible implementations of
the corresponding general-relativistic problem and a variety of new
cosmological analogies arising from them. We highlight essential ingredients of
the Newtonian analogy, including that the quasilocal energy is always
`Newtonian' in the sense that the magnetic part of the Weyl tensor does not
contribute to it. A symmetry of the Einstein-Friedmann equations produces
another one in the original Newtonian system.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:47:47 GMT""}]","2020-08-12"
"2006.07419","Amer AlGhadhban Dr.","Amer AlGhadhban","F4Tele: FSO for Data Center Network Management and Packet Telemetry",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The proliferation of bandwidth-hungry applications and services forces
datacenter (DC) administrators to optimize the utilization of available
resources. Precisely, the network share of management traffic has grown
significantly because DC networks are becoming more sophisticated and require a
massive amount of data for efficient debugging and troubleshooting.
Accordingly, we use free space optics communication (FSO) with wavelength
division multiplexing (WDM) technology to build a flexible yet high-performance
logical network responsible for management traffic. The FSO-WDM can provide
reconfigurable multi-terabit topology over line-of-sight (LoS) links. Due to
space and processing capacity reasons, we can not offer direct connections from
every data rack to the network management racks. Alternatively, the data racks
are grouped together as each group is serviced for a duration of time matches
its average arrival-rate. Since the data racks showed different arrival-rates,
the hotspot racks are allocated with longer service time. The evaluation
results show that F4Tele carried out high throughput close to the expensive
solution (benchmark).
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:48:50 GMT""}]","2020-06-16"
"2006.07420","Mohamed Hatifi","Mohamed Hatifi and Thomas Durt","Revealing self-gravity in a Stern-Gerlach Humpty-Dumpty experiment","Any comment is welcome !",,,,"quant-ph gr-qc","http://creativecommons.org/licenses/by/4.0/","  There is no consensus among today's physicists about how to describe the
gravitational interaction properly in a quantum framework. We propose in this
paper an experimental test aimed at revealing the existence of a non-linear
self-interaction \`a la Schrodinger-Newton (S-N). In this test, a mesoscopic
spin 1/2 microsphere is freely falling in a Humpty-Dumpty Stern-Gerlach
interferometer. After clarifying the role of the scaling of the interaction in
function of the amplitudes of the up and down spin components of the
microsphere, it is shown that self-gravity induces a measurable phase shift
between them, which paves the way to experimental tests. It is also shown that
if we consider two distinct microspheres falling in parallel, the entangling
power of the S-N interaction is exactly equal to zero.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:51:20 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 14:36:06 GMT""},{""version"":""v3"",""created"":""Tue, 7 Mar 2023 02:56:52 GMT""}]","2023-03-08"
"2006.07421","Chaofei Yang","Chaofei Yang, Lei Ding, Yiran Chen, Hai Li","Defending against GAN-based Deepfake Attacks via Transformation-aware
  Adversarial Faces",,,,,"cs.CV cs.CR eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deepfake represents a category of face-swapping attacks that leverage machine
learning models such as autoencoders or generative adversarial networks.
Although the concept of the face-swapping is not new, its recent technical
advances make fake content (e.g., images, videos) more realistic and
imperceptible to Humans. Various detection techniques for Deepfake attacks have
been explored. These methods, however, are passive measures against Deepfakes
as they are mitigation strategies after the high-quality fake content is
generated. More importantly, we would like to think ahead of the attackers with
robust defenses. This work aims to take an offensive measure to impede the
generation of high-quality fake images or videos. Specifically, we propose to
use novel transformation-aware adversarially perturbed faces as a defense
against GAN-based Deepfake attacks. Different from the naive adversarial faces,
our proposed approach leverages differentiable random image transformations
during the generation. We also propose to use an ensemble-based approach to
enhance the defense robustness against GAN-based Deepfake variants under the
black-box setting. We show that training a Deepfake model with adversarial
faces can lead to a significant degradation in the quality of synthesized
faces. This degradation is twofold. On the one hand, the quality of the
synthesized faces is reduced with more visual artifacts such that the
synthesized faces are more obviously fake or less convincing to human
observers. On the other hand, the synthesized faces can easily be detected
based on various metrics.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:51:57 GMT""}]","2020-06-16"
"2006.07422","Shihao Xie","Shihao Xie and Giovanni Russo and Richard Middleton","Scalability in nonlinear network systems affected by delays and
  disturbances","This is an authors' version of the work that is published in IEEE
  Transactions on Control of Network Systems, Volume: 8, Issue: 3, September
  2021. Changes were made to this version by the publisher prior to
  publication. The final version of record is available at
  https://ieeexplore.ieee.org/document/9353260","IEEE Transactions on Control of Network Systems, Volume: 8, Issue:
  3, 2021","10.1109/TCNS.2021.3058934",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with the study of scalability in nonlinear
heterogeneous networks affected by communication delays and disturbances. After
formalizing the notion of scalability, we give two sufficient conditions to
assess this property. Our results can be used to study leader-follower and
leaderless networks and also allow to consider the case when the desired
configuration of the system changes over time. We show how our conditions can
be turned into design guidelines to guarantee scalability and illustrate their
effectiveness via numerical examples.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:54:50 GMT""},{""version"":""v2"",""created"":""Wed, 7 Oct 2020 06:15:03 GMT""},{""version"":""v3"",""created"":""Mon, 18 Jan 2021 17:35:03 GMT""},{""version"":""v4"",""created"":""Thu, 14 Jul 2022 16:04:55 GMT""}]","2022-07-15"
"2006.07423","Dong Quan Nguyen","Dong Quan Ngoc Nguyen","On the generating polynomials for the distribution of generalized
  binomial coefficients in discrete valuation domains",,,,,"math.NT math.AC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a discrete valuation domain $V$ with maximal ideal $\mathfrak{m}$ such
that the residue field $V/\mathfrak{m}$ is finite, there exists a sequence of
polynomials $(F_n(x))_{n \ge 0}$ defined over the quotient field $K$ of $V$
that forms a basis of the $V$-module $\text{Int}(V) = \{f \in K[x] |
f(V)\subseteq V\}$. This sequence of polynomials bears many resemblances to the
classical binomial polynomials $(\binom{x}{n})_{n \ge 0}$. In this paper, we
introduce a generating polynomial to account for the distribution of the
$V$-values of the polynomials $F_n(x)$ modulo the maximal ideal $\mathfrak{m}$,
and prove a result that provides a method for counting exactly how many
$V$-values of the polynomials $(F_n(x))_{n \ge 0}$ fall into each of the
residue classes modulo $\mathfrak{m}$. Our main theorem in this paper can be
viewed as an analogue of the classical theorem of Garfield and Wilf in the
context of discrete valuation domains.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:56:01 GMT""}]","2020-06-16"
"2006.07424","Joel Friedman","Mariam Kavai, Joel Friedman, Kyle Sherman, Mingda Gong, Ioannis
  Giannakis, Samad Hajinazar, Haoyu Hu, Sarah E. Grefe, Justin Leshen, Qiu
  Yang, Satoru Nakatsuji, Aleksey N. Kolmogorov, Qimiao Si, Michael Lawler,
  Pegor Aynajian","Inhomogeneous Kondo-lattice in geometrically frustrated
  Pr$_{2}$Ir$_{2}$O$_{7}$","Nature Communications (in press)",,"10.1038/s41467-021-21698-z",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic fluctuations induced by geometric frustration of local Ir-spins
disturb the formation of long range magnetic order in the family of pyrochlore
iridates, R$_{2}$Ir$_{2}$O$_{7}$ (R = lanthanide)$^{1}$. As a consequence,
Pr$_{2}$Ir$_{2}$O$_{7}$ lies at a tuning-free antiferromagnetic-to-paramagnetic
quantum critical point and exhibits a diverse array of complex phenomena
including Kondo effect, biquadratic band structure, metallic spin-liquid (MSL),
and anomalous Hall effect$^{2-5}$. Using spectroscopic imaging with the
scanning tunneling microscope, complemented with machine learning K-means
clustering analysis, density functional theory, and theoretical modeling, we
probe the local electronic states in single crystal of Pr$_{2}$Ir$_{2}$O$_{7}$
and discover an electronic phase separation. Nanoscale regions with a
well-defined Kondo resonance are interweaved with a non-magnetic metallic phase
with Kondo-destruction. Remarkably, the spatial nanoscale patterns display a
correlation-driven fractal geometry with power-law behavior extended over two
and a half decades, consistent with being in proximity to a critical point. Our
discovery reveals a new nanoscale tuning route, viz. using a spatial variation
of the electronic potential as a means of adjusting the balance between Kondo
entanglement and geometric frustration.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:58:52 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 15:53:35 GMT""}]","2021-04-14"
"2006.07425","Shi Zong","Shi Zong, Alan Ritter, Eduard Hovy","Measuring Forecasting Skill from Text","Accepted at ACL 2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  People vary in their ability to make accurate predictions about the future.
Prior studies have shown that some individuals can predict the outcome of
future events with consistently better accuracy. This leads to a natural
question: what makes some forecasters better than others? In this paper we
explore connections between the language people use to describe their
predictions and their forecasting skill. Datasets from two different
forecasting domains are explored: (1) geopolitical forecasts from Good Judgment
Open, an online prediction forum and (2) a corpus of company earnings forecasts
made by financial analysts. We present a number of linguistic metrics which are
computed over text associated with people's predictions about the future
including: uncertainty, readability, and emotion. By studying linguistic
factors associated with predictions, we are able to shed some light on the
approach taken by skilled forecasters. Furthermore, we demonstrate that it is
possible to accurately predict forecasting skill using a model that is based
solely on language. This could potentially be useful for identifying accurate
predictions or potentially skilled forecasters earlier.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:04:10 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 16:09:30 GMT""}]","2020-06-17"
"2006.07426","Ugur Abdulla","Ugur G. Abdulla and Evan Cosgrove","Optimal Control of Singular Parabolic PDEs Modeling Multiphase
  Stefan-type Free Boundary Problems",,,,,"math.AP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimal control of the singular nonlinear parabolic PDE which is a
distributional formulation of multidimensional and multiphase Stefan-type free
boundary problem is analyzed. Approximating sequence of finite-dimensional
optimal control problems is introduced via finite differences. Existence of the
optimal control and the convergence of the sequence of discrete optimal control
problems both with respect to functional and control is proved. In particular,
convergence of the method of finite differences, and existence, uniqueness and
stability estimations are established for the singular PDE problem under
minimal regularity assumptions on the coefficients.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:06:37 GMT""}]","2020-06-16"
"2006.07427","Jorge David Castano-Yepes","Jorge David Casta\~no-Yepes, I. A. Lujan-Cabrera, C. F.
  Ramirez-Gutierrez","Comments on ""Superstatistical properties of the one-dimensional Dirac
  oscillator"" by Abdelmalek Boumali et al","Comment to the published paper Phys. A 553, 124207 (2020). The
  mathematical formalism and results are revisited. Revised version to be
  published in Phys. A",,"10.1016/j.physa.2020.125206",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this comment, we discuss the mathematical formalism used in Boumali et al.
(2020) which describes the superstatistical thermal properties of a
one-dimensional Dirac oscillator. In particular, we point out the importance of
maintaining the Legendre structure unaltered to ensure an accurate description
of the thermodynamic observables when a Tsallis-like statistical description is
assumed. Also, we remark that all the negative poles have to take into account
to calculate the Gibbs--Boltzmann partition function. Our findings show that
the divergences obtained by the authors in the Helmholtz free energy, which are
propagated to the other thermal properties, are a consequence of an incomplete
partition function. Moreover, we prove that the restrictions over the
$q$-parameter are no needed if an appropriate partition function describes the
system.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:07:20 GMT""},{""version"":""v2"",""created"":""Wed, 30 Sep 2020 18:45:39 GMT""}]","2020-10-05"
"2006.07428","Emilio Rub\'in de Celis","Mariano Chernicoff, Edel Garc\'ia, Gaston Giribet and Emilio Rub\'in
  de Celis","Thin-shell wormholes in AdS$_5$ and string dioptrics","24 pages, 6 figures",,"10.1007/JHEP10(2020)019",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider string probes in a traversable wormhole geometry that connects
two locally AdS$_5$ asymptotic regions. Holographically, this describes two
interacting copies of a 4-dimensional gauge theory. We consider string
configurations whose endpoints are located either in the same boundary or in
the two different boundaries of the wormhole. A string with both endpoints in
the same boundary is dual to a quark-antiquark pair charged under the same
gauge field, while a string extending through the wormhole describes a pair of
colored particles charged under two different gauge fields. When one considers
a quark-antiquark pair in each boundary, the system undergoes a phase
transition: While for small separation each pair of charges exhibits Coulomb
interaction, for large separation the charges in different field theories pair
up. This behavior had previously been observed in other geometric realizations
such as locally AdS$_5$ wormhole solutions with hyperbolic throats. The
geometries we consider here, in contrast, are stable thin-shell wormholes with
flat codimension-one hypersurfaces at fixed radial coordinate. They appear as
electrovacuum solutions of higher-curvature gravity theories coupled to Abelian
gauge fields. The presence of the thin-shells produces a refraction of the
string configurations in the bulk, leading to the presence of cusps in the
phase space diagram. We discuss these and other features of the phase diagram,
including the analogies and difference with other wormhole solutions considered
in related contexts.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:08:47 GMT""}]","2020-10-28"
"2006.07429","Kristopher Jensen","Kristopher T. Jensen, Ta-Chu Kao, Marco Tripodi, and Guillaume
  Hennequin","Manifold GPLVMs for discovering non-Euclidean latent structure in neural
  data",,,,,"stat.ML cs.LG q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A common problem in neuroscience is to elucidate the collective neural
representations of behaviorally important variables such as head direction,
spatial location, upcoming movements, or mental spatial transformations. Often,
these latent variables are internal constructs not directly accessible to the
experimenter. Here, we propose a new probabilistic latent variable model to
simultaneously identify the latent state and the way each neuron contributes to
its representation in an unsupervised way. In contrast to previous models which
assume Euclidean latent spaces, we embrace the fact that latent states often
belong to symmetric manifolds such as spheres, tori, or rotation groups of
various dimensions. We therefore propose the manifold Gaussian process latent
variable model (mGPLVM), where neural responses arise from (i) a shared latent
variable living on a specific manifold, and (ii) a set of non-parametric tuning
curves determining how each neuron contributes to the representation.
Cross-validated comparisons of models with different topologies can be used to
distinguish between candidate manifolds, and variational inference enables
quantification of uncertainty. We demonstrate the validity of the approach on
several synthetic datasets, as well as on calcium recordings from the ellipsoid
body of Drosophila melanogaster and extracellular recordings from the mouse
anterodorsal thalamic nucleus. These circuits are both known to encode head
direction, and mGPLVM correctly recovers the ring topology expected from neural
populations representing a single angular variable.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:08:54 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 15:06:53 GMT""}]","2020-10-22"
"2006.07430","Xuxi Yang","Xuxi Yang, Werner Duvaud, Peng Wei","Continuous Control for Searching and Planning with a Learned Model",,,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decision-making agents with planning capabilities have achieved huge success
in the challenging domain like Chess, Shogi, and Go. In an effort to generalize
the planning ability to the more general tasks where the environment dynamics
are not available to the agent, researchers proposed the MuZero algorithm that
can learn the dynamical model through the interactions with the environment. In
this paper, we provide a way and the necessary theoretical results to extend
the MuZero algorithm to more generalized environments with continuous action
space. Through numerical results on two relatively low-dimensional MuJoCo
environments, we show the proposed algorithm outperforms the soft actor-critic
(SAC) algorithm, a state-of-the-art model-free deep reinforcement learning
algorithm.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:10:41 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 03:32:50 GMT""}]","2020-06-23"
"2006.07431","Sai Swaroop Sunku","Sai S. Sunku, Alexander S. McLeod, Tobias Stauber, Hyobin Yoo, Dorri
  Halbertal, Guangxin Ni, Aaron Sternbach, Bor-Yuan Jiang, Takashi Taniguchi,
  Kenji Watanabe, Philip Kim, Michael M. Fogler, and D. N. Basov","Nano-photocurrent mapping of local electronic structure in twisted
  bilayer graphene",,"Nano Letters 20, 2958-2964 (2020)","10.1021/acs.nanolett.9b04637",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a combined nano-photocurrent and infrared nanoscopy study of
twisted bilayer graphene (TBG) enabling access to the local electronic
phenomena at length scales as short as 20 nm. We show that the photocurrent
changes sign at carrier densities tracking the local superlattice density of
states of TBG. We use this property to identify domains of varying local twist
angle by local photo-thermoelectric effect. Consistent with the photocurrent
study, infrared nano-imaging experiments reveal optical conductivity features
dominated by twist-angle dependent interband transitions. Our results provide a
fast and robust method for mapping the electronic structure of TBG and suggest
that similar methods can be broadly applied to probe electronic inhomogeneities
of moir\'e superlattices in other van der Waals heterostructures.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:12:02 GMT""}]","2020-06-16"
"2006.07432","George Kenison","George Kenison, Richard Lipton, Jo\""el Ouaknine, James Worrell","On the Skolem Problem and Prime Powers","13 pages, ISSAC 2020",,"10.1145/3373207.3404036",,"math.NT cs.CC","http://creativecommons.org/licenses/by/4.0/","  The Skolem Problem asks, given a linear recurrence sequence $(u_n)$, whether
there exists $n\in\mathbb{N}$ such that $u_n=0$. In this paper we consider the
following specialisation of the problem: given in addition $c\in\mathbb{N}$,
determine whether there exists $n\in\mathbb{N}$ of the form $n=lp^k$, with
$k,l\leq c$ and $p$ any prime number, such that $u_n=0$.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:23:03 GMT""}]","2020-06-16"
"2006.07433","Rune Christiansen","Rune Christiansen, Niklas Pfister, Martin Emil Jakobsen, Nicola Gnecco
  and Jonas Peters","A causal framework for distribution generalization","52 pages, 8 figures, 2 tables. To be published in IEEE Transactions
  on Pattern Analysis and Machine Intelligence (TPAMI)",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of predicting a response $Y$ from a set of covariates
$X$ when test and training distributions differ. Since such differences may
have causal explanations, we consider test distributions that emerge from
interventions in a structural causal model, and focus on minimizing the
worst-case risk. Causal regression models, which regress the response on its
direct causes, remain unchanged under arbitrary interventions on the
covariates, but they are not always optimal in the above sense. For example,
for linear models and bounded interventions, alternative solutions have been
shown to be minimax prediction optimal. We introduce the formal framework of
distribution generalization that allows us to analyze the above problem in
partially observed nonlinear models for both direct interventions on $X$ and
interventions that occur indirectly via exogenous variables $A$. It takes into
account that, in practice, minimax solutions need to be identified from data.
Our framework allows us to characterize under which class of interventions the
causal function is minimax optimal. We prove sufficient conditions for
distribution generalization and present corresponding impossibility results. We
propose a practical method, NILE, that achieves distribution generalization in
a nonlinear IV setting with linear extrapolation. We prove consistency and
present empirical results.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:24:02 GMT""},{""version"":""v2"",""created"":""Fri, 4 Sep 2020 20:00:08 GMT""},{""version"":""v3"",""created"":""Tue, 17 Aug 2021 19:00:01 GMT""}]","2021-08-19"
"2006.07434","Genevieve Schroeder","Genevieve Schroeder (Northwestern/CIERA), Ben Margalit, Wen-fai Fong,
  Brian D. Metzger, Peter K. G. Williams, Kerry Paterson, Kate D. Alexander,
  Tanmoy Laskar, Armaan V. Goyal, Edo Berger","A Late-time Radio Survey of Short GRBs at $z<0.5$: New Constraints on
  the Remnants of Neutron Star Mergers","21 pages, 7 figures, submitted to ApJ",,"10.3847/1538-4357/abb407",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Massive, rapidly-spinning magnetar remnants produced as a result of binary
neutron star (BNS) mergers may deposit a fraction of their energy into the
surrounding kilonova ejecta, powering a synchrotron radio signal from the
interaction of the ejecta with the circumburst medium. We present 6.0 GHz Very
Large Array (VLA) observations of nine, low-redshift short gamma-ray bursts
(SGRBs; $z<0.5$) on rest-frame timescales of $\approx2.4-13.9$ yr following the
bursts. We place $3\sigma$ limits on radio continuum emission of
$F_{\nu}\lesssim6-20\,\mu$Jy at the burst positions, or
$L_{\nu}\lesssim(0.6-8.3)\times10^{28}$erg s$^{-1}$Hz$^{-1}$. Comparing these
limits with new light curve modeling which properly incorporates relativistic
effects, we obtain limits on the energy deposited into the ejecta of
$E_{ej}\lesssim(0.6-6.7)\times 10^{52}$erg
($E_{ej}\lesssim(1.8-17.6)\times10^{52}$erg) for an ejecta mass of
$0.03\,M_{\odot}$ ($0.1\,M_{\odot}$). We present a uniform re-analysis of 27
SGRBs with $5.5-6.0$ GHz observations, and find that $\gtrsim50\%$ of SGRBs did
not form stable magnetar remnants in their mergers. Assuming SGRBs are produced
by BNS mergers drawn from the Galactic BNS population plus an additional
component of high-mass GW194025-like mergers in a fraction $f_{GW190425}$ of
cases, we place constraints on the maximum mass of a non-rotating neutron star
(NS) ($M_{TOV}$), finding $M_{TOV}\lesssim2.23\,M_{\odot}$ for
$f_{GW190425}=0.4$; this limit increases for larger values of $f_{GW190425}$.
The detection (or lack thereof) of radio remnants in untargeted surveys such as
the VLA Sky Survey (VLASS) could provide more stringent constraints on the
fraction of mergers that produce stable remnants. If $\gtrsim30-300$ radio
remnants are discovered in VLASS, this suggests that SGRBs are a biased
population of BNS mergers in terms of the stability of the remnants they
produce.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:24:47 GMT""},{""version"":""v2"",""created"":""Tue, 1 Sep 2020 20:36:09 GMT""}]","2020-10-21"
"2006.07435","Zhanhao Peng","Zhanhao Peng and Qing Zhou","An empirical Bayes Approach to stochastic blockmodels and graphons:
  shrinkage estimation and model selection",,,,,"stat.ME stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The graphon (W-graph), including the stochastic block model as a special
case, has been widely used in modeling and analyzing network data. This random
graph model is well-characterized by its graphon function, and estimation of
the graphon function has gained a lot of recent research interests. Most
existing works focus on community detection in the latent space of the model,
while adopting simple maximum likelihood or Bayesian estimates for the graphon
or connectivity parameters given the identified communities. In this work, we
propose a hierarchical Binomial model and develop a novel empirical Bayes
estimate of the connectivity matrix of a stochastic block model to approximate
the graphon function. Based on the likelihood of our hierarchical model, we
further introduce a model selection criterion for choosing the number of
communities. Numerical results on extensive simulations and two well-annotated
social networks demonstrate the superiority of our approach in terms of
estimation accuracy and model selection.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:29:45 GMT""},{""version"":""v2"",""created"":""Sun, 5 Sep 2021 09:33:34 GMT""}]","2021-09-07"
"2006.07436","Pascale Garaud","P. Garaud","Horizontal shear instabilities at low Prandtl number","Accepted for publication in the ApJ",,"10.3847/1538-4357/ab9c99",,"astro-ph.SR physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Turbulent mixing in the radiative regions of stars is usually either ignored
or crudely accounted for in most stellar evolution models. However, there is
growing theoretical and observational evidence that such mixing is present and
can affect various aspects of a star's life. In this work, we present a first
attempt at quantifying mixing by horizontal shear instabilities in stars using
Direct Numerical Simulations. The shear is driven by a body force, and rapidly
becomes unstable. At saturation, we find that several distinct dynamical
regimes exist, depending on the relative importance of stratification and
thermal diffusion (viscosity can in principle also matter, but is usually
negligible in most stellar applications). In each of the regimes identified, we
put forward a certain number of theoretically motivated scaling laws for the
turbulent vertical eddy scale, the typical turbulent diffusion coefficient, and
the typical amplitude of temperature fluctuations (among other quantities).
Based on our findings, we predict that the majority of stars should fall into
one of two categories: high P\'eclet number stratified turbulence, and low
P\'eclet number stratified turbulence. The latter is presented in detail in a
related paper by Cope et al. (2020), while the former is discussed here.
Applying our results to the best-known stellar shear layer, namely the solar
tachocline, we find that it should lie in the high P\'eclet number stratified
turbulence regime, and predict a substantial amount of vertical mixing for
temperature, momentum and composition. Taken as is, the new turbulence model
predictions are incompatible with the Spiegel & Zahn (1992) model of the solar
tachocline. However, we also show that rotation and magnetic fields are likely
to affect the turbulence, and need to be taken into account in future studies.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:30:38 GMT""}]","2020-10-07"
"2006.07437","Raymond McCulloch","Raymond McCulloch","A nondefinability result for expansions of the ordered real field by the
  Weierstrass $\wp$ function","8 pages, comments welcome",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Suppose that $\Omega$ is a complex lattice that is closed under complex
conjugation and that $I$ is a small real interval, and that $D$ is a disc in $
\mathbb{C}$. Then the restriction $\wp|_D$ is definable in the structure
$(\bar{\mathbb{R}},\wp|_I)$ if and only if the lattice $\Omega$ has complex
multiplication. This characterises lattices with complex multiplication in
terms of definability.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:31:10 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 14:25:02 GMT""}]","2020-07-07"
"2006.07438","Kiran Lekkala","Kiran Lekkala, Laurent Itti","Attentive Feature Reuse for Multi Task Meta learning",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop new algorithms for simultaneous learning of multiple tasks (e.g.,
image classification, depth estimation), and for adapting to unseen task/domain
distributions within those high-level tasks (e.g., different environments).
First, we learn common representations underlying all tasks. We then propose an
attention mechanism to dynamically specialize the network, at runtime, for each
task. Our approach is based on weighting each feature map of the backbone
network, based on its relevance to a particular task. To achieve this, we
enable the attention module to learn task representations during training,
which are used to obtain attention weights. Our method improves performance on
new, previously unseen environments, and is 1.5x faster than standard existing
meta learning methods using similar architectures. We highlight performance
improvements for Multi-Task Meta Learning of 4 tasks (image classification,
depth, vanishing point, and surface normal estimation), each over 10 to 25 test
domains/environments, a result that could not be achieved with standard meta
learning techniques like MAML.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:33:11 GMT""}]","2020-06-16"
"2006.07439","Asaf Ferber Mr","Asaf Ferber","Singularity of random symmetric matrices -- simple proof","Comments are welcome!",,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we give a simple, short, and self-contained proof for a
non-trivial upper bound on the probability that a random $\pm 1$ symmetric
matrix is singular.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:44:43 GMT""}]","2020-06-16"
"2006.07440","Sarat Chandra Varanasi","Sarat Chandra Varanasi, Neeraj Mittal, Gopal Gupta","Pointer Data Structure Synthesis from Answer Set Programming
  Specifications",,,,,"cs.LO cs.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop an inductive proof-technique to generate imperative programs for
pointer data structures from behavioural specifications expressed in the Answer
Set Programming (ASP) formalism. ASP is a non-monotonic logic based formalism
that employs negation-as-failure which helps emulate the human thought process,
allowing domain experts to model desired system behaviour succinctly. We argue
in this paper that ASP's reliance on negation-as-failure makes it a better
formalism than those based on first-order logic for writing formal
specifications. We assume the a domain expert provides the representation of
inductively defined data structures along with a specification of its
operations. Our procedures combined with our novel proof-technique reason over
the specifications and automatically generate an imperative program. Our
proof-technique leverages the idea of partial deduction to simplify logical
specifications. By algebraically simplifying logical specifications we arrive
at a residual specification which can be interpreted as an appropriate
imperative program. This work is in the realm of constructing programs that are
correct according to a given specification.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:45:35 GMT""},{""version"":""v2"",""created"":""Thu, 13 Aug 2020 03:23:33 GMT""}]","2020-08-14"
"2006.07441","Thomas Jahn","Thomas Jahn, Tino Ullrich","On the optimal constants in the two-sided Stechkin inequalities","v2: adds the continuous inequalities and acknowledgments, v3:
  corrects typos in authors' addresses and enhances acknowledgments, v4:
  introduces major rework in Section 2, minor rework in all other parts, v4:
  corrects typos",,"10.1016/j.jmaa.2021.125351",,"math.CA cs.NA math.FA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the optimal constants in the strong and the weak Stechkin
inequalities, both in their discrete and continuous variants. These
inequalities appear in the characterization of approximation spaces which arise
from sparse approximation or have applications to interpolation theory. An
elementary proof of a constant in the strong discrete Stechkin inequality given
by Bennett is provided, and we improve the constants given by Levin and
Stechkin and by Copson. Finally, the minimal constants in the weak discrete
Stechkin inequalities and both continuous Stechkin inequalities are presented.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:49:47 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 18:12:15 GMT""},{""version"":""v3"",""created"":""Wed, 22 Jul 2020 14:30:01 GMT""},{""version"":""v4"",""created"":""Thu, 4 Mar 2021 20:10:07 GMT""},{""version"":""v5"",""created"":""Wed, 30 Jun 2021 08:02:02 GMT""}]","2021-07-01"
"2006.07442","Yunhao Tang","Yunhao Tang","Self-Imitation Learning via Generalized Lower Bound Q-learning","Accepted at NeurIPS (Neural Information Processing Systems) 2020,
  Vancouver, Canada. Code is available at
  https://github.com/robintyh1/nstep-sil",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-imitation learning motivated by lower-bound Q-learning is a novel and
effective approach for off-policy learning. In this work, we propose a n-step
lower bound which generalizes the original return-based lower-bound Q-learning,
and introduce a new family of self-imitation learning algorithms. To provide a
formal motivation for the potential performance gains provided by
self-imitation learning, we show that n-step lower bound Q-learning achieves a
trade-off between fixed point bias and contraction rate, drawing close
connections to the popular uncorrected n-step Q-learning. We finally show that
n-step lower bound Q-learning is a more robust alternative to return-based
self-imitation learning and uncorrected n-step, over a wide range of continuous
control benchmark tasks.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:52:04 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 06:00:31 GMT""},{""version"":""v3"",""created"":""Sun, 14 Feb 2021 00:06:01 GMT""}]","2021-02-16"
"2006.07443","Sam Ganzfried","Sam Ganzfried","Algorithm for Computing Approximate Nash Equilibrium in Continuous Games
  with Application to Continuous Blotto",,,,,"cs.GT cs.AI cs.MA econ.TH math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Successful algorithms have been developed for computing Nash equilibrium in a
variety of finite game classes. However, solving continuous games -- in which
the pure strategy space is (potentially uncountably) infinite -- is far more
challenging. Nonetheless, many real-world domains have continuous action
spaces, e.g., where actions refer to an amount of time, money, or other
resource that is naturally modeled as being real-valued as opposed to integral.
We present a new algorithm for {approximating} Nash equilibrium strategies in
continuous games. In addition to two-player zero-sum games, our algorithm also
applies to multiplayer games and games with imperfect information. We
experiment with our algorithm on a continuous imperfect-information Blotto
game, in which two players distribute resources over multiple battlefields.
Blotto games have frequently been used to model national security scenarios and
have also been applied to electoral competition and auction theory. Experiments
show that our algorithm is able to quickly compute close approximations of Nash
equilibrium strategies for this game.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:53:18 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 06:33:21 GMT""},{""version"":""v3"",""created"":""Wed, 28 Apr 2021 00:34:42 GMT""},{""version"":""v4"",""created"":""Thu, 27 May 2021 09:15:14 GMT""},{""version"":""v5"",""created"":""Tue, 1 Jun 2021 06:46:50 GMT""}]","2021-06-02"
"2006.07444","Laura Kreidberg","Laura Kreidberg, Paul Molli\`ere, Ian J.M. Crossfield, Daniel P.
  Thorngren, Yui Kawashima, Caroline V. Morley, Bj\""orn Benneke, Thomas
  Mikal-Evans, David Berardo, Molly Kosiarek, Varoujan Gorjian, David R.
  Ciardi, Jessie L. Christiansen, Diana Dragomir, Courtney D. Dressing,
  Jonathan J. Fortney, Benjamin J. Fulton, Thomas P. Greene, Kevin K.
  Hardegree-Ullman, Andrew W. Howard, Steve B. Howell, Howard Isaacson, Jessica
  E. Krick, John H. Livingston, Joshua D. Lothringer, Farisa Y. Morales, Erik A
  Petigura, Joseph E. Rodriguez, Joshua E. Schlieder, Lauren M. Weiss","Tentative Evidence for Water Vapor in the Atmosphere of the Neptune-Size
  Exoplanet HD 106315 c","Submitted to AAS journals; 19 pages, 12 figures",,"10.3847/1538-3881/ac85be",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a transmission spectrum for the Neptune-size exoplanet HD 106315 c
from optical to infrared wavelengths based on transit observations from the
Hubble Space Telescope/Wide Field Camera 3, K2, and Spitzer. The spectrum shows
tentative evidence for a water absorption feature in the $1.1 - 1.7\mu$m
wavelength range with a small amplitude of 30 ppm (corresponding to just $0.8
\pm 0.04$ atmospheric scale heights). Based on an atmospheric retrieval
analysis, the presence of water vapor is tentatively favored with a Bayes
factor of 1.7 - 2.6 (depending on prior assumptions). The spectrum is most
consistent with either enhanced metallicity, high altitude condensates, or
both. Cloud-free solar composition atmospheres are ruled out at $>5\sigma$
confidence. We compare the spectrum to grids of cloudy and hazy forward models
and find that the spectrum is fit well by models with moderate cloud lofting or
haze formation efficiency, over a wide range of metallicities ($1 - 100\times$
solar). We combine the constraints on the envelope composition with an interior
structure model and estimate that the core mass fraction is $\gtrsim0.3$. With
a bulk composition reminiscent of that of Neptune and an orbital distance of
0.15 AU, HD 106315 c hints that planets may form out of broadly similar
material and arrive at vastly different orbits later in their evolution.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:53:53 GMT""}]","2023-05-17"
"2006.07445","Jonathan Sorenson","Eric Bach and Jonathan Sorenson","An Algorithm to Generate Random Factored Smooth Integers",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $x\ge y>0$ be integers. We present an algorithm that will generate an
integer $n\le x$ at random, with known prime factorization, such that every
prime divisor of $n$ is $\le y$. Further, asymptotically, $n$ is chosen
uniformly from among all integers $\le x$ that have no prime divisors $>y$. In
particular, if we assume the Extended Riemann Hypothesis, then with probability
$1-o(1)$, the average running time of our algorithm is $$ O\left( \frac{ (\log
x)^3 }{\log\log x} \right) $$ arithmetic operations. We also present other
running times based on differing sets of assumptions and heuristics.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:56:16 GMT""}]","2020-06-16"
"2006.07446","Hong-Cheol Choi","Kwangyeon Kim, Akshita Gupta, Hong-Cheol Choi, Inseok Hwang","Safety-guaranteed Reinforcement Learning based on Multi-class Support
  Vector Machine",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several works have addressed the problem of incorporating constraints in the
reinforcement learning (RL) framework, however majority of them can only
guarantee the satisfaction of soft constraints. In this work, we address the
problem of satisfying hard state constraints in a model-free RL setting with
the deterministic system dynamics. The proposed algorithm is developed for the
discrete state and action space and utilizes a multi-class support vector
machine (SVM) to represent the policy. The state constraints are incorporated
in the SVM optimization framework to derive an analytical solution for
determining the policy parameters. This final policy converges to a solution
which is guaranteed to satisfy the constraints. Additionally, the proposed
formulation adheres to the Q-learning framework and thus, also guarantees
convergence to the optimal solution. The algorithm is demonstrated with
multiple example problems.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:58:49 GMT""}]","2020-06-16"
"2006.07447","Eleni Vatamidou","Hansj\""org Albrecher, Martin Bladt, Eleni Vatamidou","Efficient simulation of ruin probabilities when claims are mixtures of
  heavy and light tails","18 pages, 8 figures",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the classical Cram\'er-Lundberg risk model with claim sizes that
are mixtures of phase-type and subexponential variables. Exploiting a specific
geometric compound representation, we propose control variate techniques to
efficiently simulate the ruin probability in this situation. The resulting
estimators perform well for both small and large initial capital. We quantify
the variance reduction as well as the efficiency gain of our method over
another fast standard technique based on the classical Pollaczek-Khinchine
formula. We provide a numerical example to illustrate the performance, and show
that for more time-consuming conditional Monte Carlo techniques, the new series
representation also does not compare unfavorably to the one based on the
Pollaczek- Khinchine formula.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:00:28 GMT""}]","2020-06-16"
"2006.07448","Andras Kruppa","A T Kruppa, J Kov\'acs, P Salamon, \""O Legeza","Entanglement and correlation in two-nucleon systems","20 pages, 1 figure",,"10.1088/1361-6471/abc2dd",,"nucl-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the mode entanglement and correlation of two fermionic particles.
We study the one- and two-mode entropy and a global characteristic, the
one-body entanglement entropy. We consider not only angular momentum coupled
states with single configuration but use the configuration interaction method.
With the help of the Slater decomposition, we derive analytical expressions for
the entanglement measures. We show that when the total angular momentum is zero
specific single configurations describe maximally entangled states. It turns
out that for a finite number of associated modes the one- and two-mode
entropies have identical values. In the shell model framework, we numerically
study two valence neutrons in the $sd$ shell. The one-body entanglement entropy
of the ground state is close to the maximal value and the associated modes have
the largest mutual information.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:04:17 GMT""}]","2021-02-03"
"2006.07449","Soumyottam Chatterjee","Soumyottam Chatterjee and Robert Gmyr and Gopal Pandurangan","Sleeping is Efficient: MIS in $O(1)$-rounds Node-averaged Awake
  Complexity",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Maximal Independent Set (MIS) is one of the fundamental problems in
distributed computing. The round (time) complexity of distributed MIS has
traditionally focused on the \emph{worst-case time} for all nodes to finish.
The best-known (randomized) MIS algorithms take $O(\log{n})$ worst-case rounds
on general graphs (where $n$ is the number of nodes). Motivated by the goal to
reduce \emph{total} energy consumption in energy-constrained networks such as
sensor and ad hoc wireless networks, we take an alternative approach to
measuring performance. We focus on minimizing the total (or equivalently, the
\emph{average}) time for all nodes to finish. It is not clear whether the
currently best-known algorithms yield constant-round (or even $o(\log{n})$)
node-averaged round complexity for MIS in general graphs. We posit the
\emph{sleeping model}, a generalization of the traditional model, that allows
nodes to enter either ``sleep'' or ``waking'' states at any round. While waking
state corresponds to the default state in the traditional model, in sleeping
state a node is ``offline'', i.e., it does not send or receive messages (and
messages sent to it are dropped as well) and does not incur any time,
communication, or local computation cost. Hence, in this model, only rounds in
which a node is awake are counted and we are interested in minimizing the
average as well as the worst-case number of rounds a node spends in the awake
state.
  Our main result is that we show that {\em MIS can be solved in (expected)
$O(1)$ rounds under node-averaged awake complexity measure} in the sleeping
model. In particular, we present a randomized distributed algorithm for MIS
that has expected {\em $O(1)$-rounds node-averaged awake complexity} and, with
high probability has {\em $O(\log{n})$-rounds worst-case awake complexity} and
{\em $O(\log^{3.41}n)$-rounds worst-case complexity}.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:05:01 GMT""}]","2020-06-16"
"2006.07450","Arash Fouman","Arash Fouman Ajirlou and Inna Partin-Vaisband","A Unified Learning Platform for Dynamic Frequency Scaling in Pipelined
  Processors",,,,,"cs.AR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A machine learning (ML) design framework is proposed for dynamically
adjusting clock frequency based on propagation delay of individual
instructions. A Random Forest model is trained to classify propagation delays
in real-time, utilizing current operation type, current operands, and
computation history as ML features. The trained model is implemented in Verilog
as an additional pipeline stage within a baseline processor. The modified
system is simulated at the gate-level in 45 nm CMOS technology, exhibiting a
speed-up of 68% and energy reduction of 37% with coarse-grained ML
classification. A speed-up of 95% is demonstrated with finer granularities at
additional energy costs.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:07:06 GMT""}]","2020-06-16"
"2006.07451","Kristi Morgansen","Nathan Powel and Kristi A. Morgansen","Empirical Observability Gramian for Stochastic Observability of
  Nonlinear Systems","16 pages, 11 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend observability metrics based on the empirical observability Gramian
from deterministic nonlinear systems to nonlinear stochastic systems in order
to capture the impact of process noise on observability. We demonstrate that
the empirical observability Gramian can be used to provide an equivalent
condition for a definition of stochastic observability on linear systems, and
that the Gramian can be used to extend stochastic observability to nonlinear
stochastic systems. We further demonstrate through simulation that
consideration of process noise can reveal observability in systems that would
be considered unobservable using traditional deterministic tools.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:09:26 GMT""}]","2020-06-16"
"2006.07452","Sandeep Banik","Sandeep Banik and Shaunak D. Bopardikar","Secure Route Planning Using Dynamic Games with Stopping States","8 pages, 5 figures. Technical report for the corresponding conference
  paper accepted at IEEE International Conference on Intelligent Robots and
  Systems (IROS), 2020",,,,"cs.GT cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the classic motion planning problem defined over a roadmap in
which a vehicle seeks to find an optimal path from a source to a destination in
presence of an attacker who can launch attacks on the vehicle over any edge of
the roadmap. The vehicle (defender) has the capability to switch on/off a
countermeasure that can detect and permanently disable the attack if it occurs
concurrently. We model the problem of traveling along en edge using the
framework of a simultaneous zero-sum dynamic game (edge-game) with a stopping
state played between an attacker and defender. We characterize the Nash
equiliria of an edge-game and provide closed form expressions for two actions
per player. We further provide an analytic and approximate expression on the
value of an edge-game and characterize conditions under which it grows
sub-linearly with the number of stages. We study the sensitivity of Nash
equilibrium to the (i) cost of using the countermeasure, (ii) cost of motion
and (iii) benefit of disabling the attack. The solution of an edge-game is used
to formulate and solve for the secure planning problem known as a meta-game. We
design an efficient heuristic by converting the problem to a shortest path
problem using the edge cost as the solution of corresponding edge-games. We
illustrate our findings through several insightful simulations.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:23:48 GMT""},{""version"":""v2"",""created"":""Fri, 31 Jul 2020 22:39:10 GMT""},{""version"":""v3"",""created"":""Fri, 15 Apr 2022 20:35:05 GMT""}]","2022-04-19"
"2006.07453","Sameh Sorour","Sameh Sorour, Umair Mohammad, Amr Abutuleb, Hossam Hassanein","Returning the Favor: What Wireless Networking Can Offer to AI and Edge
  Learning",,,,,"cs.DC cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning (ML) and artificial intelligence (AI) have recently made a
significant impact on improving the operations of wireless networks and
establishing intelligence at the edge. In return, rare efforts were made to
explore how adapting, optimizing, and arranging wireless networks can
contribute to implementing ML/AI at the edge. This article aims to address this
void by setting a vision on how wireless networking researchers can leverage
their expertise to return the favor to edge learning. It will review the
enabling technologies, summarize the inaugural works on this path, and shed
light on different directions to establish a comprehensive framework for mobile
edge learning (MEL).
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:25:05 GMT""}]","2020-06-16"
"2006.07454","Steven Lakin","Steven Michael Lakin, Zaid Abdo","Fast Maximum Likelihood Estimation and Supervised Classification for the
  Beta-Liouville Multinomial","30 pages, 9 figures",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The multinomial and related distributions have long been used to model
categorical, count-based data in fields ranging from bioinformatics to natural
language processing. Commonly utilized variants include the standard
multinomial and the Dirichlet multinomial distributions due to their
computational efficiency and straightforward parameter estimation process.
However, these distributions make strict assumptions about the mean, variance,
and covariance between the categorical features being modeled. If these
assumptions are not met by the data, it may result in poor parameter estimates
and loss in accuracy for downstream applications like classification. Here, we
explore efficient parameter estimation and supervised classification methods
using an alternative distribution, called the Beta-Liouville multinomial, which
relaxes some of the multinomial assumptions. We show that the Beta-Liouville
multinomial is comparable in efficiency to the Dirichlet multinomial for
Newton-Raphson maximum likelihood estimation, and that its performance on
simulated data matches or exceeds that of the multinomial and Dirichlet
multinomial distributions. Finally, we demonstrate that the Beta-Liouville
multinomial outperforms the multinomial and Dirichlet multinomial on two out of
four gold standard datasets, supporting its use in modeling data with low to
medium class overlap in a supervised classification context.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:30:12 GMT""}]","2020-06-16"
"2006.07455","Mohamed Ibrahim Nouh","Eltayeb A. Yousif, Ahmed M. A. Adam, Abaker A. Hassaballa1 and Mohamed
  I. Nouh","Conformable Fractional Isothermal Gas Spheres","15 pages, 4 figures, 2 tables",,"10.1016/j.newast.2020.101511",,"physics.comp-ph astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The isothermal gas sphere is well known as a powerful tool to model many
problems in astrophysics, physics, chemistry, and engineering. This singular
differential equation has not an exact solution and solved only by numerical
and approximate methods. In the present paper and within the framework of the
Newtonian hydrostatic equilibrium, we have developed general analytical
formulations for the fractional isothermal gas sphere. To obtain analytical
expressions for mass, radius, and density, besides the fractional isothermal
gas sphere, we used the conformable fractional calculus. Using the series
expansion method, we obtained a general recurrences relation, which allows us
to determine the series coefficients. The comparison of the series solution
with the numerical ones for the fractional parameter \alpha=1 is good for
dimensional parameters up to x=3.2, beyond this value, the series diverges. We
applied a combination of Euler-Abel and Pade techniques to accelerate the
series, therefore accelerated series converge to the numerical desired value.
We analyzed some physical parameters of a typical model of the neutron stars
such as the mass-radius relation, density, and pressure ratio for different
models. We found that the current models of the conformable neutron stars had
smaller volumes and masses than both stars in the context of modified
Rienmann-Liouville derivatives as well as the integer one.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:34:55 GMT""}]","2020-10-21"
"2006.07456","Eyal Neuman","Alessandro Micheli and Eyal Neuman","Evidence of Crowding on Russell 3000 Reconstitution Events","35 pages, 9 figures",,,,"q-fin.TR q-fin.PM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a methodology which replicates in great accuracy the FTSE Russell
indexes reconstitutions, including the quarterly rebalancings due to new
initial public offerings (IPOs). While using only data available in the CRSP US
Stock database for our index reconstruction, we demonstrate the accuracy of
this methodology by comparing it to the original Russell US indexes for the
time period between 1989 to 2019. A python package that generates the
replicated indexes is also provided.
  As an application, we use our index reconstruction protocol to compute the
permanent and temporary price impact on the Russell 3000 annual additions and
deletions, and on the quarterly additions of new IPOs . We find that the index
portfolios following the Russell 3000 index and rebalanced on an annual basis
are overall more crowded than those following the index on a quarterly basis.
This phenomenon implies that transaction costs of indexing strategies could be
significantly reduced by buying new IPOs additions in proximity to quarterly
rebalance dates.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:35:36 GMT""},{""version"":""v2"",""created"":""Thu, 22 Sep 2022 08:45:02 GMT""}]","2022-09-23"
"2006.07457","Jelena Bradic","Jing Zhou, Gerda Claeskens, Jelena Bradic","Detangling robustness in high dimensions: composite versus
  model-averaged estimation",,,,,"math.ST econ.EM stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robust methods, though ubiquitous in practice, are yet to be fully understood
in the context of regularized estimation and high dimensions. Even simple
questions become challenging very quickly. For example, classical statistical
theory identifies equivalence between model-averaged and composite quantile
estimation. However, little to nothing is known about such equivalence between
methods that encourage sparsity. This paper provides a toolbox to further study
robustness in these settings and focuses on prediction. In particular, we study
optimally weighted model-averaged as well as composite $l_1$-regularized
estimation. Optimal weights are determined by minimizing the asymptotic mean
squared error. This approach incorporates the effects of regularization,
without the assumption of perfect selection, as is often used in practice. Such
weights are then optimal for prediction quality. Through an extensive
simulation study, we show that no single method systematically outperforms
others. We find, however, that model-averaged and composite quantile estimators
often outperform least-squares methods, even in the case of Gaussian model
noise. Real data application witnesses the method's practical use through the
reconstruction of compressed audio signals.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:40:15 GMT""}]","2020-06-16"
"2006.07458","Tianyi Lin","Tianyi Lin, Chenyou Fan, Nhat Ho, Marco Cuturi and Michael I. Jordan","Projection Robust Wasserstein Distance and Riemannian Optimization","Accepted by NeurIPS 2020; The first two authors contributed equally;
  fix the confusing parts in the proof and refine the algorithms and complexity
  bounds",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Projection robust Wasserstein (PRW) distance, or Wasserstein projection
pursuit (WPP), is a robust variant of the Wasserstein distance. Recent work
suggests that this quantity is more robust than the standard Wasserstein
distance, in particular when comparing probability measures in high-dimensions.
However, it is ruled out for practical application because the optimization
model is essentially non-convex and non-smooth which makes the computation
intractable. Our contribution in this paper is to revisit the original
motivation behind WPP/PRW, but take the hard route of showing that, despite its
non-convexity and lack of nonsmoothness, and even despite some hardness results
proved by~\citet{Niles-2019-Estimation} in a minimax sense, the original
formulation for PRW/WPP \textit{can} be efficiently computed in practice using
Riemannian optimization, yielding in relevant cases better behavior than its
convex relaxation. More specifically, we provide three simple algorithms with
solid theoretical guarantee on their complexity bound (one in the appendix),
and demonstrate their effectiveness and efficiency by conducing extensive
experiments on synthetic and real data. This paper provides a first step into a
computational theory of the PRW distance and provides the links between optimal
transport and Riemannian optimization.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:40:22 GMT""},{""version"":""v10"",""created"":""Sun, 1 Jan 2023 06:17:07 GMT""},{""version"":""v2"",""created"":""Sun, 28 Jun 2020 19:49:06 GMT""},{""version"":""v3"",""created"":""Fri, 25 Sep 2020 22:49:36 GMT""},{""version"":""v4"",""created"":""Thu, 15 Oct 2020 01:06:21 GMT""},{""version"":""v5"",""created"":""Tue, 24 Nov 2020 19:02:39 GMT""},{""version"":""v6"",""created"":""Sun, 20 Dec 2020 11:21:09 GMT""},{""version"":""v7"",""created"":""Sat, 6 Feb 2021 08:53:03 GMT""},{""version"":""v8"",""created"":""Sat, 17 Jul 2021 06:26:20 GMT""},{""version"":""v9"",""created"":""Sun, 6 Nov 2022 23:45:44 GMT""}]","2023-01-03"
"2006.07459","Alexander Ritchie","Alexander Ritchie, Robert A. Vandermeulen, Clayton Scott","Consistent Estimation of Identifiable Nonparametric Mixture Models from
  Grouped Observations",,,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent research has established sufficient conditions for finite mixture
models to be identifiable from grouped observations. These conditions allow the
mixture components to be nonparametric and have substantial (or even total)
overlap. This work proposes an algorithm that consistently estimates any
identifiable mixture model from grouped observations. Our analysis leverages an
oracle inequality for weighted kernel density estimators of the distribution on
groups, together with a general result showing that consistent estimation of
the distribution on groups implies consistent estimation of mixture components.
A practical implementation is provided for paired observations, and the
approach is shown to outperform existing methods, especially when mixture
components overlap significantly.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:44:22 GMT""}]","2020-06-16"
"2006.07460","Zichao Wang","Weili Nie, Zichao Wang, Ankit B. Patel, Richard G. Baraniuk","An Improved Semi-Supervised VAE for Learning Disentangled
  Representations",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning interpretable and disentangled representations is a crucial yet
challenging task in representation learning. In this work, we focus on
semi-supervised disentanglement learning and extend work by Locatello et al.
(2019) by introducing another source of supervision that we denote as label
replacement. Specifically, during training, we replace the inferred
representation associated with a data point with its ground-truth
representation whenever it is available. Our extension is theoretically
inspired by our proposed general framework of semi-supervised disentanglement
learning in the context of VAEs which naturally motivates the supervised terms
commonly used in existing semi-supervised VAEs (but not for disentanglement
learning). Extensive experiments on synthetic and real datasets demonstrate
both quantitatively and qualitatively the ability of our extension to
significantly and consistently improve disentanglement with very limited
supervision.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:47:41 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 18:20:10 GMT""}]","2020-06-24"
"2006.07461","Khurram Javed","Khurram Javed, Martha White, Yoshua Bengio","Learning Causal Models Online","Spurious features, causal models, online learning, random search,
  non-iid",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Predictive models -- learned from observational data not covering the
complete data distribution -- can rely on spurious correlations in the data for
making predictions. These correlations make the models brittle and hinder
generalization. One solution for achieving strong generalization is to
incorporate causal structures in the models; such structures constrain learning
by ignoring correlations that contradict them. However, learning these
structures is a hard problem in itself. Moreover, it's not clear how to
incorporate the machinery of causality with online continual learning. In this
work, we take an indirect approach to discovering causal models. Instead of
searching for the true causal model directly, we propose an online algorithm
that continually detects and removes spurious features. Our algorithm works on
the idea that the correlation of a spurious feature with a target is not
constant over-time. As a result, the weight associated with that feature is
constantly changing. We show that by continually removing such features, our
method converges to solutions that have strong generalization. Moreover, our
method combined with random search can also discover non-spurious features from
raw sensory data. Finally, our work highlights that the information present in
the temporal structure of the problem -- destroyed by shuffling the data -- is
essential for detecting spurious features online.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:49:20 GMT""}]","2020-06-16"
"2006.07462","\.Inan \""Unal","\.Inan \""Unal","Generalized Quasi-Einstein Manifolds in Contact Geometry",,,"10.3390/math8091592",,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this study, we investigate generalized quasi-Einstein structure for normal
metric contact pair manifolds. Firstly, we deal with elementary properties and
examine, existence, and characterizations of generalized quasi-Einstein normal
metric contact pair manifold. Secondly, the generalized quasi-constant
curvature of normal metric contact pair manifolds are studied and it is proven
that a normal metric contact pair manifold with generalized quasi-constant
curvature is a generalized quasi-Einstein manifold. Normal metric contact pair
manifolds satisfying cyclic Ricci tensor and the Codazzi type of Ricci tensor
are considered and its shown that a generalized quasi-Einstein normal metric
contact pair manifold does not satisfy Codazzi type of Ricci tensor. Finally,
we work on normal metric contact pair manifolds satisfying certain curvature
conditions related to $ \mathcal{M}- $projective, conformal, and concircular
curvature tensors. We show that a normal metric contact pair manifold with
generalized quasi-constant curvature is locally isometric to the Hopf manifold
$ S^{2n+1}(1) \times S^1 $.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:51:30 GMT""}]","2021-02-23"
"2006.07463","Zbigniew Palmowski","Zbigniew Palmowski and Eleni Vatamidou","Phase-type approximations perturbed by a heavy-tailed component for the
  Gerber-Shiu function of risk processes with two-sided jumps",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider in this paper a risk reserve process where the claims and gains
arrive according to two independent Poisson processes. While the gain sizes are
phase-type distributed, we assume instead that the claim sizes are phase-type
perturbed by a heavy-tailed component; that is, the claim size distribution is
formally chosen to be phase-type with large probability $1-\epsilon$ and
heavy-tailed with small probability $\epsilon$. We analyze the seminal
Gerber-Shiu function coding the joint distribution of the time to ruin, the
surplus immediately before ruin, and the deficit at ruin. We derive its value
as an expansion with respect to powers of $\epsilon$ with known coefficients
and we construct approximations from the first two terms of the aforementioned
series. The main idea is based on the so-called fluid embedding that allows to
put the considered risk process into the framework of spectrally negative
Markov-additive processes and use its fluctuation theory developed in Ivanovs
and Palmowski (2012).
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:57:12 GMT""}]","2020-06-16"
"2006.07464","Morteza Ibrahimi","Vikranth Dwaracherla, Xiuyuan Lu, Morteza Ibrahimi, Ian Osband, Zheng
  Wen, Benjamin Van Roy","Hypermodels for Exploration","Published as a conference paper at ICLR 2020",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the use of hypermodels to represent epistemic uncertainty and guide
exploration. This generalizes and extends the use of ensembles to approximate
Thompson sampling. The computational cost of training an ensemble grows with
its size, and as such, prior work has typically been limited to ensembles with
tens of elements. We show that alternative hypermodels can enjoy dramatic
efficiency gains, enabling behavior that would otherwise require hundreds or
thousands of elements, and even succeed in situations where ensemble methods
fail to learn regardless of size. This allows more accurate approximation of
Thompson sampling as well as use of more sophisticated exploration schemes. In
particular, we consider an approximate form of information-directed sampling
and demonstrate performance gains relative to Thompson sampling. As
alternatives to ensembles, we consider linear and neural network hypermodels,
also known as hypernetworks. We prove that, with neural network base models, a
linear hypermodel can represent essentially any distribution over functions,
and as such, hypernetworks are no more expressive.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:59:21 GMT""}]","2020-06-16"
"2006.07471","Rosa Everson","Rosa Wallace Everson, Morgan MacLeod, Soumi De, Phillip Macias, Enrico
  Ramirez-Ruiz","Common Envelope Wind Tunnel: Range of Applicability and Self-Similarity
  in Realistic Stellar Envelopes","16 pages, 12 figures","ApJ 899 (2020) 77","10.3847/1538-4357/aba75c",,"astro-ph.SR astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Common envelope evolution, the key orbital tightening phase of the
traditional formation channel for close binaries, is a multistage process that
presents many challenges to the establishment of a fully descriptive,
predictive theoretical framework. In an approach complementary to global 3D
hydrodynamical modeling, we explore the range of applicability for a simplified
drag formalism that incorporates the results of local hydrodynamic ""wind
tunnel"" simulations into a semi-analytical framework in the treatment of the
common envelope dynamical inspiral phase using a library of realistic giant
branch stellar models across the low, intermediate, and high mass regimes. In
terms of a small number of key dimensionless parameters, we characterize a wide
range of common envelope events, revealing the broad range of applicability of
the drag formalism as well its self-similar nature across mass regimes and
ages. Limitations arising from global binary properties and local structural
quantities are discussed together with the opportunity for a general
prescriptive application for this formalism.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:05:58 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2020 17:13:06 GMT""}]","2020-08-20"
"2006.07472","Anjana Wijekoon","Anjana Wijekoon, Nirmalie Wiratunga","Learning-to-Learn Personalised Human Activity Recognition Models","17 pages",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Human Activity Recognition~(HAR) is the classification of human movement,
captured using one or more sensors either as wearables or embedded in the
environment~(e.g. depth cameras, pressure mats). State-of-the-art methods of
HAR rely on having access to a considerable amount of labelled data to train
deep architectures with many train-able parameters. This becomes prohibitive
when tasked with creating models that are sensitive to personal nuances in
human movement, explicitly present when performing exercises. In addition, it
is not possible to collect training data to cover all possible subjects in the
target population. Accordingly, learning personalised models with few data
remains an interesting challenge for HAR research. We present a meta-learning
methodology for learning to learn personalised HAR models for HAR; with the
expectation that the end-user need only provides a few labelled data but can
benefit from the rapid adaptation of a generic meta-model. We introduce two
algorithms, Personalised MAML and Personalised Relation Networks inspired by
existing Meta-Learning algorithms but optimised for learning HAR models that
are adaptable to any person in health and well-being applications. A
comparative study shows significant performance improvements against the
state-of-the-art Deep Learning algorithms and the Few-shot Meta-Learning
algorithms in multiple HAR domains.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:11:59 GMT""}]","2020-06-16"
"2006.07473","Koen Ruymbeek","Koen Ruymbeek, Karl Meerbergen, Wim Michiels","Tensor-Krylov method for computing eigenvalues of parameter-dependent
  matrices","20 pages, 5 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we extend the Residual Arnoldi method for calculating an
extreme eigenvalue (e.g. largest real part, dominant,...) to the case where the
matrices depend on parameters. The difference between this Arnoldi method and
the classical Arnoldi algorithm is that in the former the residual is added to
the subspace. We develop a Tensor-Krylov method that applies the Residual
Arnoldi method (RA) for a grid of parameter points at the same time. The
subspace contains an approximate Krylov space for all these points. Instead of
adding the residuals for all parameter values to the subspace we create a
low-rank approximation of the matrix consisting of these residuals and add only
the column space to the subspace. In order to keep the computations efficient,
it is needed to limit the dimension of the subspace and to restart once the
subspace has reached the prescribed maximal dimension. The novelty of this
approach is twofold. Firstly, we observed that a large error in the low-rank
approximations is allowed without slowing down the convergence, which implies
that we can do more iterations before restarting. Secondly, we pay particular
attention to the way the subspace is restarted, since classical restarting
techniques give a too large subspace in our case. We motivate why it is good
enough to just keep the approximation of the searched eigenvector. At the end
of the paper we extend this algorithm to shift-and-invert Residual Arnoldi
method to calculate the eigenvalue close to a shift $\sigma$ for a specific
parameter dependency. We provide theoretical results and report numerical
experiments. The Matlab code is publicly available.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:15:22 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 20:20:45 GMT""}]","2020-12-18"
"2006.07474","Lucas Mol","James D. Currie and Lucas Mol","The undirected repetition threshold and undirected pattern avoidance","arXiv admin note: substantial text overlap with arXiv:1904.10029",,,,"math.CO cs.DM cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a rational number $r$ such that $1<r\leq 2$, an undirected $r$-power is a
word of the form $xyx'$, where the word $x$ is nonempty, the word $x'$ is in
$\{x,x^R\}$, and we have $|xyx'|/|xy|=r$. The undirected repetition threshold
for $k$ letters, denoted $\mbox{URT}(k)$, is the infimum of the set of all $r$
such that undirected $r$-powers are avoidable on $k$ letters. We first
demonstrate that $\mbox{URT}(3)=\tfrac{7}{4}$. Then we show that
$\mbox{URT}(k)\geq \tfrac{k-1}{k-2}$ for all $k\geq 4$. We conjecture that
$\mbox{URT}(k)=\tfrac{k-1}{k-2}$ for all $k\geq 4$, and we confirm this
conjecture for $k\in\{4,5,\ldots,21\}.$ We then consider related problems in
pattern avoidance; in particular, we find the undirected avoidability index of
every binary pattern. This is an extended version of a paper presented at WORDS
2019, and it contains new and improved results.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:16:17 GMT""}]","2020-06-16"
"2006.07475","Niloy Sikder","Niloy Sikder, Md. Sanaullah Chowdhury, Abu Shamim Mohammad Arif, and
  Abdullah-Al Nahid","Early Blindness Detection Based on Retinal Images Using Ensemble
  Learning","6 pages, 22nd International Conference of Computer and Information
  Technology (ICCIT), 18-20 December, 2019",,"10.1109/ICCIT48885.2019.9038439",,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Diabetic retinopathy (DR) is the primary cause of vision loss among grownup
people around the world. In four out of five cases having diabetes for a
prolonged period leads to DR. If detected early, more than 90 percent of the
new DR occurrences can be prevented from turning into blindness through proper
treatment. Despite having multiple treatment procedures available that are well
capable to deal with DR, the negligence and failure of early detection cost
most of the DR patients their precious eyesight. The recent developments in the
field of Digital Image Processing (DIP) and Machine Learning (ML) have paved
the way to use machines in this regard. The contemporary technologies allow us
to develop devices capable of automatically detecting the condition of a
persons eyes based on their retinal images. However, in practice, several
factors hinder the quality of the captured images and impede the detection
outcome. In this study, a novel early blind detection method has been proposed
based on the color information extracted from retinal images using an ensemble
learning algorithm. The method has been tested on a set of retinal images
collected from people living in the rural areas of South Asia, which resulted
in a 91 percent classification accuracy.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:16:21 GMT""}]","2020-06-16"
"2006.07476","Guannan Qu","Guannan Qu, Chenkai Yu, Steven Low, Adam Wierman","Combining Model-Based and Model-Free Methods for Nonlinear Control: A
  Provably Convergent Policy Gradient Approach",,,,,"math.OC cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model-free learning-based control methods have seen great success recently.
However, such methods typically suffer from poor sample complexity and limited
convergence guarantees. This is in sharp contrast to classical model-based
control, which has a rich theory but typically requires strong modeling
assumptions. In this paper, we combine the two approaches to achieve the best
of both worlds. We consider a dynamical system with both linear and non-linear
components and develop a novel approach to use the linear model to define a
warm start for a model-free, policy gradient method. We show this hybrid
approach outperforms the model-based controller while avoiding the convergence
issues associated with model-free approaches via both numerical experiments and
theoretical analyses, in which we derive sufficient conditions on the
non-linear component such that our approach is guaranteed to converge to the
(nearly) global optimal controller.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:16:29 GMT""}]","2020-06-16"
"2006.07477","Fernando Vila","F. D. Vila, J. J. Rehr, J. J. Kas, K. Kowalski, B. Peng","Real-time coupled-cluster approach for the cumulant Green's function","This file includes both the main manuscript and the supplementary
  information","J. Chem. Theory Comput. 2020, 16, 11, 6983-6992","10.1021/acs.jctc.0c00639",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Green's function methods within many-body perturbation theory provide a
general framework for treating electronic correlations in excited states. Here
we investigate the cumulant form of the one-electron Green's function based on
the coupled-cluster equation of motion approach in an extension of our previous
study. The approach yields a non-perturbative expression for the cumulant in
terms of the solution to a set of coupled first order, non-linear differential
equations. The method thereby adds non-linear corrections to traditional
cumulant methods linear in the self energy. The approach is applied to the
core-hole Green's function and illustrated for a number of small molecular
systems. For these systems we find that the non-linear contributions lead to
significant improvements both for quasiparticle properties such as core-level
binding energies, as well as the satellites corresponding to inelastic losses
observed in photoemission spectra.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:18:26 GMT""}]","2021-04-23"
"2006.07478","Stephen Timcheck","Stephen Timcheck and Jeremy Buhler","Streaming Computations with Region-Based State on SIMD Architectures","Presented at the 13th International Workshop on Programmability and
  Architectures for Heterogeneous Multicores, 2020 (arXiv:2005.07619)",,,"MULTIPROG/2020/1","cs.DC","http://creativecommons.org/licenses/by-sa/4.0/","  Streaming computations on massive data sets are an attractive candidate for
parallelization, particularly when they exhibit independence (and hence data
parallelism) between items in the stream. However, some streaming computations
are stateful, which disrupts independence and can limit parallelism. In this
work, we consider how to extract data parallelism from streaming computations
with a common, limited form of statefulness. The stream is assumed to be
divided into variably-sized regions, and items in the same region are processed
in a common context of state. In general, the computation to be performed on a
stream is also irregular, with each item potentially undergoing different,
data-dependent processing.
  This work describes mechanisms to implement such computations efficiently on
a SIMD-parallel architecture such as a GPU. We first develop a low-level
protocol by which a data stream can be augmented with control signals that are
delivered to each stage of a computation at precise points in the stream. We
then describe an abstraction, enumeration and aggregation, by which an
application developer can specify the behavior of a streaming application with
region-based state. Finally, we study an implementation of our ideas as part of
the MERCATOR system for irregular streaming computations on GPUs, investigating
how the frequency of region boundaries in a stream impacts SIMD occupancy and
hence application performance.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:18:37 GMT""}]","2020-06-16"
"2006.07479","Troy Seberson","T. Seberson, F. Robicheaux","Stability and dynamics of optically levitated dielectric disks in a
  Gaussian standing wave beyond the harmonic approximation","9 pages, 5 figures","Phys. Rev. Research 2, 033437 (2020)","10.1103/PhysRevResearch.2.033437",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Forces and torques exerted on dielectric disks trapped in a Gaussian standing
wave are analyzed theoretically for disks of radius $2~\mu\text{m}$ with index
of refraction $n=1.45$ and $n=2.0$ as well as disks of radius 200 nm with
$n=1.45$. Calculations of the forces and torques were conducted both
analytically and numerically using a discrete-dipole approximation method.
Besides harmonic terms, third order ro-translational coupling terms in the
potential energy can be significant and a necessary consideration when
describing the dynamics of disks outside of the Rayleigh limit. The coupling
terms are a result of the finite extension of the disk coupling to both the
Gaussian and standing wave geometry of the beam. The resulting dynamics of the
degrees of freedom most affected by the coupling terms exhibit several
sidebands as evidenced in the power spectral densities. Simulations show that
for Gaussian beam waists of $1-4~\mu\text{m}$ the disk remains stably trapped.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:18:41 GMT""},{""version"":""v2"",""created"":""Wed, 19 Aug 2020 18:20:03 GMT""}]","2020-09-23"
"2006.07480","Eric Oh","Eric J. Oh and Bryan E. Shepherd and Thomas Lumley and Pamela A. Shaw","Improved Generalized Raking Estimators to Address Dependent Covariate
  and Failure-Time Outcome Error",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Biomedical studies that use electronic health records (EHR) data for
inference are often subject to bias due to measurement error. The measurement
error present in EHR data is typically complex, consisting of errors of unknown
functional form in covariates and the outcome, which can be dependent. To
address the bias resulting from such errors, generalized raking has recently
been proposed as a robust method that yields consistent estimates without the
need to model the error structure. We provide rationale for why these
previously proposed raking estimators can be expected to be inefficient in
failure-time outcome settings involving misclassification of the event
indicator. We propose raking estimators that utilize multiple imputation, to
impute either the target variables or auxiliary variables, to improve the
efficiency. We also consider outcome-dependent sampling designs and investigate
their impact on the efficiency of the raking estimators, either with or without
multiple imputation. We present an extensive numerical study to examine the
performance of the proposed estimators across various measurement error
settings. We then apply the proposed methods to our motivating setting, in
which we seek to analyze HIV outcomes in an observational cohort with
electronic health records data from the Vanderbilt Comprehensive Care Clinic.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:21:38 GMT""}]","2020-06-16"
"2006.07481","Andrea Carosso","Andrea Carosso","Novel Approaches to Renormalization Group Transformations in the
  Continuum and on the Lattice","161 pages. PhD thesis, University of Colorado Boulder",,,,"hep-lat hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This thesis is about new methods of achieving RG transformations, in both a
continuum spacetime background and on a lattice discretization thereof. The
subject is explored from the point of view of euclidean quantum field theory.
As a thesis grounded on the computational method of lattice simulation, I
emphasize the role of lattice formulations throughout the work, especially in
the first two chapters. In the first, I describe the essential aspects of
lattice theory and its symbiosis with RG. In the second, I present a new,
continuous approach to RG on the lattice, based on a numerical tool called
Gradient Flow (GF). Simulation results from quartic scalar field theory in 2
and 3 dimensions ($\phi^4_d$) and 4-dimensional 12-flavor SU(3) gauge theory
will be presented. In the third and fourth chapters, the focus becomes more
analytic. Chapter 3 is an introductory review of Functional Renormalization
Group (FRG). In chapter 4, I introduce the concept of Stochastic RG (SRG) by
working out the relationship between FRG and stochastic processes.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:22:57 GMT""}]","2020-06-16"
"2006.07482","Maria Petropoulou","M. Petropoulou, P. Beniamini, G. Vasilopoulos, D. Giannios, R. Barniol
  Duran","Deciphering the properties of the central engine in GRB collapsars","13 pages, 6 figures, accepted for publication in MNRAS",,"10.1093/mnras/staa1695",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The central engine in long gamma-ray bursts (GRBs) is thought to be a compact
object produced by the core collapse of massive stars, but its exact nature
(black hole or millisecond magnetar) is still debatable. Although the central
engine of GRB collapsars is hidden to direct observation, its properties may be
imprinted on the accompanying electromagnetic signals. We aim to decipher the
generic properties of central engines that are consistent with prompt
observations of long GRBs detected by the Burst Alert Telescope (BAT) on board
the Neil Gehrels Swift Observatory. Adopting a generic model for the central
engine, in which the engine power and activity timescale are independent of
each other, we perform Monte Carlo simulations of long GRBs produced by jets
that successfully breakout from the star. Our simulations consider the
dependence of the jet breakout timescale on the engine luminosity and the
effects of the detector's flux threshold. The two-dimensional (2D) distribution
of simulated detectable bursts in the gamma-ray luminosity versus gamma-ray
duration plane is consistent with the observed one for a range of parameter
values describing the central engine. The intrinsic 2D distribution of
simulated collapsar GRBs peaks at lower gamma-ray luminosities and longer
durations than the observed one, a prediction that can be tested in the future
with more sensitive detectors. Black-hole accretors, whose power and activity
time are set by the large-scale magnetic flux through the progenitor star and
stellar structure, respectively, are compatible with the properties of the
central engine inferred by our model.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:23:35 GMT""}]","2020-06-24"
"2006.07483","Beth Klein","Beth Klein, Simon Blouin, Diego Romani, B. Zuckerman, Carl Melis, Siyi
  Xu, P. Dufour, C. Genest-Beaulieu, A. B\'edard and M. Jura","Atmospheric Temperature Inversions and He I 5876 Core Profile Structure
  in White Dwarfs","Accepted for publication in ApJ, 16 pages, 10 figures",,"10.3847/1538-4357/ab9b24",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report distinctive core profiles in the strongest optical helium line, He
I 5876, from high-resolution high-sensitivity observations of spectral type DB
white dwarfs. By analyzing a sample of 40 stars from Keck/HIRES and VLT/UVES,
we find the core appearance to be related to the degree of hydrogen and heavy
element content in the atmosphere. New Ca K-line measurements or upper limits
are reported for about half the sample stars. He I 5876 emission cores with a
self-reversed central component are present for those stars with relatively low
hydrogen abundance, as well as relatively low atmospheric heavy element
pollution. This self-reversed structure disappears for stars with higher
degrees of pollution and/or hydrogen abundance, giving way to a single
absorption core. From our model atmospheres, we show that the self-reversed
emission cores can be explained by temperature inversions in the upper
atmosphere. We propose that the transition to a single absorption core is due
to the additional opacity from hydrogen and heavy elements that inhibits the
temperature inversions. Our current models do not exactly match the effective
temperature range of the phenomenon nor the amplitude of the self-reversed
structure, which is possibly a result of missing physics such as 3D treatment,
convective overshoot, and/or non-LTE effects. The He I 5876 line structure may
prove to be a useful new diagnostic for calibrating temperature profiles in DB
atmosphere models.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:24:51 GMT""}]","2020-09-02"
"2006.07484","Michela Paganini","Michela Paganini, Jessica Zosa Forde","dagger: A Python Framework for Reproducible Machine Learning Experiment
  Orchestration","4 pages, 3 code listings, 1 figure",,,,"cs.SE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many research directions in machine learning, particularly in deep learning,
involve complex, multi-stage experiments, commonly involving state-mutating
operations acting on models along multiple paths of execution. Although machine
learning frameworks provide clean interfaces for defining model architectures
and unbranched flows, burden is often placed on the researcher to track
experimental provenance, that is, the state tree that leads to a final model
configuration and result in a multi-stage experiment. Originally motivated by
analysis reproducibility in the context of neural network pruning research,
where multi-stage experiment pipelines are common, we present dagger, a
framework to facilitate reproducible and reusable experiment orchestration. We
describe the design principles of the framework and example usage.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:42:48 GMT""}]","2020-06-16"
"2006.07485","Andrei Pushkarev","Andrei Pushkarev","Laser-Like Waves Amplification in Straits",,,"10.1007/s10236-020-01425-w",,"physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the research of ocean surface wind waves excitation in
non-homogeneous situations, on the example of deep water strait in presence of
the constant wind, blowing perpendicular to the coastal line. The used
statistical wave model is based on Hasselmann equation with high-wavenumbers
wave-breaking dissipation, exact nonlinear four-waves interaction and ZRP wind
input term. At the first stage, the waves propagate in the wind direction in a
step-like moving front manner, which is the combination of self-similar
fetch-limited and duration-limited solutions of Hasselmann equation. The second
stage begins further, when sufficient amount of wave energy is concentrated at
the incoming waves shore line. Beginning with that time, the nonlinear wave
interactions start formation of the wave groups, propagating across and against
the wind. Despite the absence of long-wave dissipation, the system
asymptotically evolves into complicated quasi-stationary state, comprising of
the self-similar ``wind sea'' in the wind direction, and quasi-monochromatic
waves, radiated close to orthogonally with respect to the wind, while slightly
tilting counter the wind direction with the angle increasing toward the wave
turbulence origination shore line, and reaching $15^{\circ}$ close to it. The
total wave energy in the asymptotic state surpasses the wave sea energy
propagating along the wind by two times due to the presence of quasi-orthogonal
and counter the wind wave fields. The very similar turbulence structure was
previously observed experimentally, this paper presents theoretical explanation
of these results. It is suggested to name this laser-like radiation phenomenon
by Nonlinear Ocean Waves Amplifier, simplified to the abbreviation NOWA.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:44:10 GMT""}]","2021-02-03"
"2006.07486","Zihan Tan","Julia Chuzhoy, Merav Parter, Zihan Tan","On Packing Low-Diameter Spanning Trees",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Edge connectivity of a graph is one of the most fundamental graph-theoretic
concepts. The celebrated tree packing theorem of Tutte and Nash-Williams from
1961 states that every $k$-edge connected graph $G$ contains a collection
$\cal{T}$ of $\lfloor k/2 \rfloor$ edge-disjoint spanning trees, that we refer
to as a tree packing; the diameter of the tree packing $\cal{T}$ is the largest
diameter of any tree in $\cal{T}$. A desirable property of a tree packing, that
is both sufficient and necessary for leveraging the high connectivity of a
graph in distributed communication, is that its diameter is low. Yet, despite
extensive research in this area, it is still unclear how to compute a tree
packing, whose diameter is sublinear in $|V(G)|$, in a low-diameter graph $G$,
or alternatively how to show that such a packing does not exist.
  In this paper we provide first non-trivial upper and lower bounds on the
diameter of tree packing. First, we show that, for every $k$-edge connected
$n$-vertex graph $G$ of diameter $D$, there is a tree packing $\cal{T}$ of size
$\Omega(k)$, diameter $O((101k\log n)^D)$, that causes edge-congestion at most
$2$. Second, we show that for every $k$-edge connected $n$-vertex graph $G$ of
diameter $D$, the diameter of $G[p]$ is $O(k^{D(D+1)/2})$ with high
probability, where $G[p]$ is obtained by sampling each edge of $G$
independently with probability $p=\Theta(\log n/k)$. This provides a packing of
$\Omega(k/\log n)$ edge-disjoint trees of diameter at most $O(k^{(D(D+1)/2)})$
each. We then prove that these two results are nearly tight. Lastly, we show
that if every pair of vertices in a graph has $k$ edge-disjoint paths of length
at most $D$ connecting them, then there is a tree packing of size $k$, diameter
$O(D\log n)$, causing edge-congestion $O(\log n)$. We also provide several
applications of low-diameter tree packing in distributed computation.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:54:03 GMT""}]","2020-06-16"
"2006.07487","Shijing Si","Shijing Si, Chris. J. Oates, Andrew B. Duncan, Lawrence Carin,
  Fran\c{c}ois-Xavier Briol","Scalable Control Variates for Monte Carlo Methods via Stochastic
  Optimization","Accepted by MCQMC2020",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Control variates are a well-established tool to reduce the variance of Monte
Carlo estimators. However, for large-scale problems including high-dimensional
and large-sample settings, their advantages can be outweighed by a substantial
computational cost. This paper considers control variates based on Stein
operators, presenting a framework that encompasses and generalizes existing
approaches that use polynomials, kernels and neural networks. A learning
strategy based on minimising a variational objective through stochastic
optimization is proposed, leading to scalable and effective control variates.
Novel theoretical results are presented to provide insight into the variance
reduction that can be achieved, and an empirical assessment, including
applications to Bayesian inference, is provided in support.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:03:25 GMT""},{""version"":""v2"",""created"":""Wed, 21 Jul 2021 11:46:11 GMT""}]","2021-07-22"
"2006.07488","Christopher Gorham","Christopher Gorham","The 4th Industrial Revolution Effect on the Enterprise Cyber Strategy",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Fourth (4th) Industrial Revolution represents the profound advancement of
technology that will likely transform the boundaries between the digital and
physical worlds in modern society. The impact of advance technology will
disrupt almost every aspect of business and government communities alike. In
the past few years, the advancement of information technologies has opened the
door to artificial intelligence (AI), block chain technologies, robotics,
virtual reality and the possibility of quantum computing being released in the
commercial sector. The use of these innovative technologies will likely impact
society by leveraging modern technological platforms such as cloud computing
and AI. This also includes the release of 5G network technologies by Internet
Service Providers (ISP) beginning in 2019. Networks that rely upon 5G
technologies in combination with cloud computing platforms will open the door
allow greater innovations and change the nature of how work is performed in the
4th Industrial Revolution.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:04:11 GMT""}]","2020-06-16"
"2006.07489","Leonidas Spinoulas","Leonidas Spinoulas, Mohamed Hussein, David Geissb\""uhler, Joe Mathai,
  Oswin G.Almeida, Guillaume Clivaz, S\'ebastien Marcel, and Wael AbdAlmageed","Multispectral Biometrics System Framework: Application to Presentation
  Attack Detection",,,,,"cs.CV cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present a general framework for building a biometrics system
capable of capturing multispectral data from a series of sensors synchronized
with active illumination sources. The framework unifies the system design for
different biometric modalities and its realization on face, finger and iris
data is described in detail. To the best of our knowledge, the presented design
is the first to employ such a diverse set of electromagnetic spectrum bands,
ranging from visible to long-wave-infrared wavelengths, and is capable of
acquiring large volumes of data in seconds. Having performed a series of data
collections, we run a comprehensive analysis on the captured data using a
deep-learning classifier for presentation attack detection. Our study follows a
data-centric approach attempting to highlight the strengths and weaknesses of
each spectral band at distinguishing live from fake samples.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:09:35 GMT""}]","2020-06-16"
"2006.07490","Om Thakkar","Om Thakkar, Swaroop Ramaswamy, Rajiv Mathews, Fran\c{c}oise Beaufays","Understanding Unintended Memorization in Federated Learning",,,,,"cs.LG cs.CL stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recent works have shown that generative sequence models (e.g., language
models) have a tendency to memorize rare or unique sequences in the training
data. Since useful models are often trained on sensitive data, to ensure the
privacy of the training data it is critical to identify and mitigate such
unintended memorization. Federated Learning (FL) has emerged as a novel
framework for large-scale distributed learning tasks. However, it differs in
many aspects from the well-studied central learning setting where all the data
is stored at the central server. In this paper, we initiate a formal study to
understand the effect of different components of canonical FL on unintended
memorization in trained models, comparing with the central learning setting.
Our results show that several differing components of FL play an important role
in reducing unintended memorization. Specifically, we observe that the
clustering of data according to users---which happens by design in FL---has a
significant effect in reducing such memorization, and using the method of
Federated Averaging for training causes a further reduction. We also show that
training with a strong user-level differential privacy guarantee results in
models that exhibit the least amount of unintended memorization.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:10:16 GMT""}]","2020-06-16"
"2006.07491","Mohamed Yousef","Mohamed Yousef, Tom E. Bishop","OrigamiNet: Weakly-Supervised, Segmentation-Free, One-Step, Full Page
  Text Recognition by learning to unfold","Accepted to CVPR 2020",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text recognition is a major computer vision task with a big set of associated
challenges. One of those traditional challenges is the coupled nature of text
recognition and segmentation. This problem has been progressively solved over
the past decades, going from segmentation based recognition to segmentation
free approaches, which proved more accurate and much cheaper to annotate data
for. We take a step from segmentation-free single line recognition towards
segmentation-free multi-line / full page recognition. We propose a novel and
simple neural network module, termed \textbf{OrigamiNet}, that can augment any
CTC-trained, fully convolutional single line text recognizer, to convert it
into a multi-line version by providing the model with enough spatial capacity
to be able to properly collapse a 2D input signal into 1D without losing
information. Such modified networks can be trained using exactly their same
simple original procedure, and using only \textbf{unsegmented} image and text
pairs. We carry out a set of interpretability experiments that show that our
trained models learn an accurate implicit line segmentation. We achieve
state-of-the-art character error rate on both IAM \& ICDAR 2017 HTR benchmarks
for handwriting recognition, surpassing all other methods in the literature. On
IAM we even surpass single line methods that use accurate localization
information during training. Our code is available online at
\url{https://github.com/IntuitionMachines/OrigamiNet}.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:18:02 GMT""}]","2020-06-16"
"2006.07492","Ryan Comes","Suresh Thapa, Rajendra Paudel, Miles D. Blanchet, Patrick T.
  Gemperline, Ryan B. Comes","Probing Emergent Surface and Interfacial Properties in Complex Oxides
  via in situ X-ray Photoelectron Spectroscopy","31 pages, 12 figures","Journal of Materials Research, 36, 26-51, Jan 2021","10.1557/s43578-020-00070-9",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Emergent behavior at complex oxide interfaces has driven much of the research
in the oxide thin film community for the past twenty years. Interfaces have
been engineered for potential applications in spintronics, topological quantum
computing, and high-speed electronics in cases where the bulk materials would
not exhibit the desired properties. Advances in thin film growth have made the
synthesis of these interfaces possible, while surface characterization tools
such as X-ray photoelectron spectroscopy have been critical to understanding
surface and interfacial phenomena in these materials. In this review we discuss
the leading research in the oxide field over the past 5-10 years with a focus
on connecting the key results to the X-ray photoelectron spectroscopy studies
that enabled them. We describe how in situ integration of synthesis and
spectroscopy can be used to improve the film growth process and to perform
immediate experiments on specifically tailored interfacial heterostructures.
These studies can include determination of interfacial intermixing, valence
band alignment, and interfacial charge transfer. We also show how advances in
synchrotron-based spectroscopy techniques have answered questions that cannot
be addressed in a lab-based system. By further tying together synthesis and
spectroscopy through in situ techniques, we conclude by discussing future
opportunities in the field through the careful design of thin film
heterostructures that are optimized for X-ray studies.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:19:50 GMT""}]","2021-07-06"
"2006.07493","Estev\~ao Batista Do Prado","Estev\~ao B. Prado, Rafael A. Moral and Andrew C. Parnell","Bayesian Additive Regression Trees with Model Trees",,"Statistics and Computing 31, 20 (2021)","10.1007/s11222-021-09997-3",,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian Additive Regression Trees (BART) is a tree-based machine learning
method that has been successfully applied to regression and classification
problems. BART assumes regularisation priors on a set of trees that work as
weak learners and is very flexible for predicting in the presence of
non-linearity and high-order interactions. In this paper, we introduce an
extension of BART, called Model Trees BART (MOTR-BART), that considers
piecewise linear functions at node levels instead of piecewise constants. In
MOTR-BART, rather than having a unique value at node level for the prediction,
a linear predictor is estimated considering the covariates that have been used
as the split variables in the corresponding tree. In our approach, local
linearities are captured more efficiently and fewer trees are required to
achieve equal or better performance than BART. Via simulation studies and real
data applications, we compare MOTR-BART to its main competitors. R code for
MOTR-BART implementation is available at https://github.com/ebprado/MOTR-BART.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:19:58 GMT""},{""version"":""v2"",""created"":""Wed, 7 Oct 2020 10:23:36 GMT""},{""version"":""v3"",""created"":""Wed, 18 Nov 2020 18:10:16 GMT""},{""version"":""v4"",""created"":""Thu, 31 Dec 2020 00:59:41 GMT""},{""version"":""v5"",""created"":""Wed, 10 Mar 2021 16:20:03 GMT""}]","2022-06-07"
"2006.07494","Siddharth Tyagi","Siddharth Tyagi and Isaak Mayergoyz","Time-Domain Analysis of PWM Inverters",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The time-domain analysis of pulse width modulated (PWM) single-phase
inverters is presented for different load circuits. It is demonstrated that
this analysis can be reduced to the solution of linear simultaneous algebraic
equations with two diagonal matrices. Analytical solutions of such equations
are easily found which leads to the explicit expressions for the output
voltages and currents in terms of switching time-instants. This technique is
presented for second and third order circuits, however it can be used in
principle for any higher-order linear load circuit subject to pulse width
modulated voltages.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:26:32 GMT""}]","2020-06-16"
"2006.07495","Joel Lehman","Adrien Ecoffet and Jeff Clune and Joel Lehman","Open Questions in Creating Safe Open-ended AI: Tensions Between Control
  and Creativity",,,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial life originated and has long studied the topic of open-ended
evolution, which seeks the principles underlying artificial systems that
innovate continually, inspired by biological evolution. Recently, interest has
grown within the broader field of AI in a generalization of open-ended
evolution, here called open-ended search, wherein such questions of
open-endedness are explored for advancing AI, whatever the nature of the
underlying search algorithm (e.g. evolutionary or gradient-based). For example,
open-ended search might design new architectures for neural networks, new
reinforcement learning algorithms, or most ambitiously, aim at designing
artificial general intelligence. This paper proposes that open-ended evolution
and artificial life have much to contribute towards the understanding of
open-ended AI, focusing here in particular on the safety of open-ended search.
The idea is that AI systems are increasingly applied in the real world, often
producing unintended harms in the process, which motivates the growing field of
AI safety. This paper argues that open-ended AI has its own safety challenges,
in particular, whether the creativity of open-ended systems can be productively
and predictably controlled. This paper explains how unique safety problems
manifest in open-ended search, and suggests concrete contributions and research
questions to explore them. The hope is to inspire progress towards creative,
useful, and safe open-ended search algorithms.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:28:09 GMT""}]","2020-06-16"
"2006.07496","Siddharth Tyagi","Siddharth Tyagi and Isaak Mayergoyz","Optimal Time-Domain Sinusoidal Pulse Width Modulation Technique",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An optimal time-domain pulse width modulation technique is presented for
single-phase and three-phase inverters under the constraint of sinusoidally
modulated voltage pulse widths. Harmonic content in currents and voltages is
expressed as function of displacement factors, which characterize the placement
of the sinusoidally modulated voltage pulses in each sampling subinterval.
Implications of symmetries on these displacement factors for three-phase
inverters are discussed. Minimization of harmonics is stated as an optimization
problem, which is then numerically solved to reveal improvements in harmonic
performance.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:33:41 GMT""}]","2020-06-16"
"2006.07497","Zhichao Peng","Zhichao Peng, Fengyan Li","Asymptotic preserving IMEX-DG-S schemes for linear kinetic transport
  equations based on Schur complement","23 pages, 39 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a linear kinetic transport equation under a diffusive scaling,
that converges to a diffusion equation as the Knudsen number
$\varepsilon\rightarrow0$. In [3, 21], to achieve the asymptotic preserving
(AP) property and unconditional stability in the diffusive regime with
$\varepsilon\ll 1$, numerical schemes are developed based on an additional
reformulation of the even-odd or micro-macro decomposed version of the
equation. The key of the reformulation is to add a weighted diffusive term on
both sides of one equation in the decomposed system. The choice of the weight
function, however, is problem-dependent and ad-hoc, and it can affect the
performance of numerical simulations. To avoid issues related to the choice of
the weight function and still obtain the AP property and unconditional
stability in the diffusive regime, we propose in this paper a new family of AP
schemes, termed as IMEX-DG-S schemes, directly solving the micro-macro
decomposed system without any further reformulation. The main ingredients of
the IMEX-DG-S schemes include globally stiffly accurate implicit-explicit
(IMEX) Runge-Kutta (RK) temporal discretizations with a new IMEX strategy,
discontinuous Galerkin (DG) spatial discretizations, discrete ordinate methods
for the velocity space, and the application of the Schur complement to the
algebraic form of the schemes to control the overall computational cost. The AP
property of the schemes is shown formally. With an energy type stability
analysis applied to the first order scheme, and Fourier type stability analysis
applied to the first to third order schemes, we confirm the uniform stability
of the methods with respect to $\varepsilon$ and the unconditional stability in
the diffusive regime. A series of numerical examples are presented to
demonstrate the performance of the new schemes.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:37:42 GMT""}]","2020-06-16"
"2006.07498","Leonidas Spinoulas","Leonidas Spinoulas, Hengameh Mirzaalian, Mohamed Hussein, and Wael
  AbdAlmageed","Multi-Modal Fingerprint Presentation Attack Detection: Evaluation On A
  New Dataset",,,,,"cs.CV cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fingerprint presentation attack detection is becoming an increasingly
challenging problem due to the continuous advancement of attack preparation
techniques, which generate realistic-looking fake fingerprint presentations. In
this work, rather than relying on legacy fingerprint images, which are widely
used in the community, we study the usefulness of multiple recently introduced
sensing modalities. Our study covers front-illumination imaging using
short-wave-infrared, near-infrared, and laser illumination; and
back-illumination imaging using near-infrared light. Toward studying the
effectiveness of each of these unconventional sensing modalities and their
fusion for liveness detection, we conducted a comprehensive analysis using a
fully convolutional deep neural network framework. Our evaluation compares
different combination of the new sensing modalities to legacy data from one of
our collections as well as the public LivDet2015 dataset, showing the
superiority of the new sensing modalities in most cases. It also covers the
cases of known and unknown attacks and the cases of intra-dataset and
inter-dataset evaluations. Our results indicate that the power of our approach
stems from the nature of the captured data rather than the employed
classification framework, which justifies the extra cost for hardware-based (or
hybrid) solutions. We plan to publicly release one of our dataset collections.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:38:23 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 08:09:44 GMT""}]","2020-06-22"
"2006.07499","Bo-Hsiang (Andy) Tseng","Bo-Hsiang Tseng, Jianpeng Cheng, Yimai Fang, David Vandyke","A Generative Model for Joint Natural Language Understanding and
  Generation","The 58th Annual Meeting of the Association for Computational
  Linguistics, ACL2020",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Natural language understanding (NLU) and natural language generation (NLG)
are two fundamental and related tasks in building task-oriented dialogue
systems with opposite objectives: NLU tackles the transformation from natural
language to formal representations, whereas NLG does the reverse. A key to
success in either task is parallel training data which is expensive to obtain
at a large scale. In this work, we propose a generative model which couples NLU
and NLG through a shared latent variable. This approach allows us to explore
both spaces of natural language and formal representations, and facilitates
information sharing through the latent space to eventually benefit NLU and NLG.
Our model achieves state-of-the-art performance on two dialogue datasets with
both flat and tree-structured formal representations. We also show that the
model can be trained in a semi-supervised fashion by utilising unlabelled data
to boost its performance.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:38:55 GMT""}]","2020-06-16"
"2006.07500","Divyat Mahajan","Divyat Mahajan, Shruti Tople, Amit Sharma","Domain Generalization using Causal Matching","Proceedings of the 38th International Conference on Machine Learning
  (ICML), PMLR 139, 2021. (Long Talk)",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the domain generalization literature, a common objective is to learn
representations independent of the domain after conditioning on the class
label. We show that this objective is not sufficient: there exist
counter-examples where a model fails to generalize to unseen domains even after
satisfying class-conditional domain invariance. We formalize this observation
through a structural causal model and show the importance of modeling
within-class variations for generalization. Specifically, classes contain
objects that characterize specific causal features, and domains can be
interpreted as interventions on these objects that change non-causal features.
We highlight an alternative condition: inputs across domains should have the
same representation if they are derived from the same object. Based on this
objective, we propose matching-based algorithms when base objects are observed
(e.g., through data augmentation) and approximate the objective when objects
are not observed (MatchDG). Our simple matching-based algorithms are
competitive to prior work on out-of-domain accuracy for rotated MNIST,
Fashion-MNIST, PACS, and Chest-Xray datasets. Our method MatchDG also recovers
ground-truth object matches: on MNIST and Fashion-MNIST, top-10 matches from
MatchDG have over 50% overlap with ground-truth matches.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:39:35 GMT""},{""version"":""v2"",""created"":""Wed, 7 Oct 2020 16:03:08 GMT""},{""version"":""v3"",""created"":""Tue, 29 Jun 2021 09:54:44 GMT""}]","2021-06-30"
"2006.07501","Simone Colombo","Edwin Pedrozo-Pe\~nafiel and Simone Colombo and Chi Shu and Albert F.
  Adiyatullin and Zeyang Li and Enrique Mendez and Boris Braverman and Akio
  Kawasaki and Daisuke Akamatsu and Yanhong Xiao and Vladan Vuleti\'c","Entanglement-Enhanced Optical Atomic Clock","4 figures, 7 pages","Nature 588, 414 418 (2020)","10.1038/s41586-020-3006-1",,"quant-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State-of-the-art atomic clocks are based on the precise detection of the
energy difference between two atomic levels, measured as a quantum phase
accumulated in a given time interval. Optical-lattice clocks (OLCs) now operate
at or near the standard quantum limit (SQL) that arises from the quantum noise
associated with discrete measurement outcomes. While performance beyond the SQL
has been achieved in microwave clocks and other atomic sensors by engineering
quantum correlations (entanglement) between the atoms, the generation of
entanglement on an optical-clock transition and operation of such a clock
beyond the SQL represent major goals in quantum metrology that have never been
demonstrated. Here we report creation of a many-atom entangled state on an
optical transition, and demonstrate an OLC with an Allan deviation below the
SQL. We report a metrological gain of $4.4^{+0.6}_{-0.4}$ dB over the SQL using
an ensemble consisting of a few hundred 171Yb atoms, allowing us to reach a
given stability $2.8{\pm}0.3$ times faster than the same clock operated at the
SQL. Our results should be readily applicable to other systems, thus enabling
further advances in timekeeping precision and accuracy. Entanglement-enhanced
OLCs will have many scientific and technological applications, including
precision tests of the fundamental laws of physics, geodesy, or gravitational
wave detection.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:41:34 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 13:21:19 GMT""}]","2021-03-19"
"2006.07502","Siddhesh Khandelwal","Siddhesh Khandelwal, Raghav Goyal, Leonid Sigal","UniT: Unified Knowledge Transfer for Any-shot Object Detection and
  Segmentation","22 Pages, 8 Figures, 13 Tables",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Methods for object detection and segmentation rely on large scale
instance-level annotations for training, which are difficult and time-consuming
to collect. Efforts to alleviate this look at varying degrees and quality of
supervision. Weakly-supervised approaches draw on image-level labels to build
detectors/segmentors, while zero/few-shot methods assume abundant
instance-level data for a set of base classes, and none to a few examples for
novel classes. This taxonomy has largely siloed algorithmic designs. In this
work, we aim to bridge this divide by proposing an intuitive and unified
semi-supervised model that is applicable to a range of supervision: from zero
to a few instance-level samples per novel class. For base classes, our model
learns a mapping from weakly-supervised to fully-supervised
detectors/segmentors. By learning and leveraging visual and lingual
similarities between the novel and base classes, we transfer those mappings to
obtain detectors/segmentors for novel classes; refining them with a few novel
class instance-level annotated samples, if available. The overall model is
end-to-end trainable and highly flexible. Through extensive experiments on
MS-COCO and Pascal VOC benchmark datasets we show improved performance in a
variety of settings.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:45:47 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 17:38:45 GMT""},{""version"":""v3"",""created"":""Wed, 3 Mar 2021 20:34:48 GMT""}]","2021-03-05"
"2006.07503","Nicol\`o Campolongo","Nicol\`o Campolongo, Francesco Orabona","Temporal Variability in Implicit Online Learning","18 pages, 12 figures",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the setting of online learning, Implicit algorithms turn out to be highly
successful from a practical standpoint. However, the tightest regret analyses
only show marginal improvements over Online Mirror Descent. In this work, we
shed light on this behavior carrying out a careful regret analysis. We prove a
novel static regret bound that depends on the temporal variability of the
sequence of loss functions, a quantity which is often encountered when
considering dynamic competitors. We show, for example, that the regret can be
constant if the temporal variability is constant and the learning rate is tuned
appropriately, without the need of smooth losses. Moreover, we present an
adaptive algorithm that achieves this regret bound without prior knowledge of
the temporal variability and prove a matching lower bound. Finally, we validate
our theoretical findings on classification and regression datasets.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 22:50:34 GMT""},{""version"":""v2"",""created"":""Fri, 6 Nov 2020 19:59:09 GMT""}]","2020-11-10"
"2006.07504","Jesse Chan","Jesse Chan, Christina G. Taylor","Efficient computation of Jacobian matrices for entropy stable
  summation-by-parts schemes",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entropy stable schemes replicate an entropy inequality at the semi-discrete
level. These schemes rely on an algebraic summation-by-parts (SBP) structure
and a technique referred to as flux differencing. We provide simple and
efficient formulas for Jacobian matrices for the semi-discrete systems of ODEs
produced by entropy stable discretizations. These formulas are derived based on
the structure of flux differencing and derivatives of flux functions, which can
be computed using automatic differentiation (AD). Numerical results demonstrate
the efficiency and utility of these Jacobian formulas, which are then used in
the context of two-derivative explicit time-stepping schemes and implicit
time-stepping.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:01:39 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 01:20:45 GMT""},{""version"":""v3"",""created"":""Thu, 31 Dec 2020 21:57:26 GMT""}]","2021-01-05"
"2006.07505","Huan Wang","Huan Wang, Guoming Tang, Kui Wu, Jianping Wang","PLVER: Joint Stable Allocation and Content Replication for Edge-assisted
  Live Video Delivery",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The live streaming services have gained extreme popularity in recent years.
Due to the spiky traffic patterns of live videos, utilizing the distributed
edge servers to improve viewers' quality of experience (QoE) has become a
common practice nowadays. Nevertheless, current client-driven content caching
mechanism does not support caching beforehand from the cloud to the edge,
resulting in considerable cache missing in live video delivery.
State-of-the-art research generally sacrifices the liveness of delivered videos
in order to deal with the above problem. In this paper, by jointly considering
the features of live videos and edge servers, we propose PLVER, a proactive
live video push scheme to resolve the cache miss problem in live video
delivery. Specifically, PLVER first conducts a one-tomultiple stable allocation
between edge clusters and user groups, to balance the load of live traffic over
the edge servers. Then it adopts proactive video replication algorithms to
speed up the video replication among the edge servers. We conduct extensive
trace-driven evaluations, covering 0.3 million Twitch viewers and more than 300
Twitch channels. The results demonstrate that with PLVER, edge servers can
carry 28% and 82% more traffic than the auction-based replication method and
the caching on requested time method, respectively.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:04:57 GMT""}]","2020-06-16"
"2006.07506","Haoyun Wang","Haoyun Wang, Liyan Xie, Alex Cuozzo, Simon Mak, Yao Xie","Uncertainty Quantification for Inferring Hawkes Networks","16 pages including appendix, 1 figure, accepted to 2020 Neurips",,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multivariate Hawkes processes are commonly used to model streaming networked
event data in a wide variety of applications. However, it remains a challenge
to extract reliable inference from complex datasets with uncertainty
quantification. Aiming towards this, we develop a statistical inference
framework to learn causal relationships between nodes from networked data,
where the underlying directed graph implies Granger causality. We provide
uncertainty quantification for the maximum likelihood estimate of the network
multivariate Hawkes process by providing a non-asymptotic confidence set. The
main technique is based on the concentration inequalities of continuous-time
martingales. We compare our method to the previously-derived asymptotic Hawkes
process confidence interval, and demonstrate the strengths of our method in an
application to neuronal connectivity reconstruction.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:08:36 GMT""},{""version"":""v2"",""created"":""Wed, 28 Oct 2020 16:24:08 GMT""}]","2020-10-29"
"2006.07507","Keyi Chen","Keyi Chen, John Langford, Francesco Orabona","Better Parameter-free Stochastic Optimization with ODE Updates for
  Coin-Betting",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parameter-free stochastic gradient descent (PFSGD) algorithms do not require
setting learning rates while achieving optimal theoretical performance. In
practical applications, however, there remains an empirical gap between tuned
stochastic gradient descent (SGD) and PFSGD. In this paper, we close the
empirical gap with a new parameter-free algorithm based on continuous-time
Coin-Betting on truncated models. The new update is derived through the
solution of an Ordinary Differential Equation (ODE) and solved in a closed
form. We show empirically that this new parameter-free algorithm outperforms
algorithms with the ""best default"" learning rates and almost matches the
performance of finely tuned baselines without anything to tune.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:10:25 GMT""},{""version"":""v2"",""created"":""Wed, 28 Oct 2020 15:32:21 GMT""},{""version"":""v3"",""created"":""Tue, 3 May 2022 20:03:15 GMT""}]","2022-05-05"
"2006.07508","Joe Booth","Joe Booth, Vladimir Ivanov","Realistic Physics Based Character Controller","5 pages",,,,"cs.AI cs.HC cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the course of the last several years there was a strong interest in
application of modern optimal control techniques to the field of character
animation. This interest was fueled by introduction of efficient learning based
algorithms for policy optimization, growth in computation power, and game
engine improvements. It was shown that it is possible to generate natural
looking control of a character by using two ingredients. First, the simulated
agent must adhere to a motion capture dataset. And second, the character aims
to track the control input from the user. The paper aims at closing the gap
between the researchers and users by introducing an open source implementation
of physics based character control in Unity framework that has a low entry
barrier and a steep learning curve.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:13:16 GMT""}]","2020-06-16"
"2006.07509","Meng Ma","Meng K. Ma, K. A. Villegas Rosales, H. Deng, Y. J. Chung, L. N.
  Pfeiffer, K. W. West, K. W. Baldwin, R. Winkler, and M. Shayegan","Thermal and quantum melting phase diagrams for a magnetic-field-induced
  Wigner solid","Phys. Rev. Lett. (in press) (2020)","Phys. Rev. Lett. 125 036601 (2020)","10.1103/PhysRevLett.125.036601",,"cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A sufficiently large perpendicular magnetic field quenches the kinetic
(Fermi) energy of an interacting two-dimensional (2D) system of fermions,
making them susceptible to the formation of a Wigner solid (WS) phase in which
the charged carriers organize themselves in a periodic array in order to
minimize their Coulomb repulsion energy. In low-disorder 2D electron systems
confined to modulation-doped GaAs heterostructures, signatures of a
magnetic-field-induced WS appear at low temperatures and very small Landau
level filling factors ($\nu\simeq1/5$). In dilute GaAs 2D \textit{hole}
systems, on the other hand, thanks to the larger hole effective mass and the
ensuing Landau level mixing, the WS forms at relatively higher fillings
($\nu\simeq1/3$). Here we report our measurements of the fundamental
temperature vs. filling phase diagram for the 2D holes' WS-liquid
\textit{thermal melting}. Moreover, via changing the 2D hole density, we also
probe their Landau level mixing vs. filling WS-liquid \textit{quantum melting}
phase diagram. We find our data to be in good agreement with the results of
very recent calculations, although intriguing subtleties remain.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:26:56 GMT""}]","2020-07-16"
"2006.07510","Peter Clark","Sumithra Bhakthavatsalam, Kyle Richardson, Niket Tandon, Peter Clark","Do Dogs have Whiskers? A New Knowledge Base of hasPart Relations",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new knowledge-base of hasPart relationships, extracted from a
large corpus of generic statements. Complementary to other resources available,
it is the first which is all three of: accurate (90% precision), salient
(covers relationships a person may mention), and has high coverage of common
terms (approximated as within a 10 year old's vocabulary), as well as having
several times more hasPart entries than in the popular ontologies ConceptNet
and WordNet. In addition, it contains information about quantifiers, argument
modifiers, and links the entities to appropriate concepts in Wikipedia and
WordNet. The knowledge base is available at https://allenai.org/data/haspartkb
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:34:05 GMT""}]","2020-06-16"
"2006.07511","Gang Han","Gang Han","Quaternionic slice regular functions and quaternionic Laplace transforms","19 gages",,,,"math.CV","http://creativecommons.org/licenses/by-sa/4.0/","  The functions studied in the paper are quaternion-valued functions of a
quaternionic variable. It is show that the left slice regular functions and
right slice regular functions are related by a particular involution. The
relation between left slice regular functions, right slice regular functions
and intrinsic regular functions is revealed. The classical Laplace transform
can be naturally generalized to quaternions in two different ways, which
transform a quaternion-valued function of a real variable to a left or right
slice regular quaternion-valued function of a quaternionic variable. The usual
properties of the classical Laplace transforms are generalized to quaternionic
Laplace transforms.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:38:38 GMT""}]","2020-06-16"
"2006.07512","Lingjiao Chen","Lingjiao Chen, Matei Zaharia, James Zou","FrugalML: How to Use ML Prediction APIs More Accurately and Cheaply",,,,,"cs.LG cs.GT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prediction APIs offered for a fee are a fast-growing industry and an
important part of machine learning as a service. While many such services are
available, the heterogeneity in their price and performance makes it
challenging for users to decide which API or combination of APIs to use for
their own data and budget. We take a first step towards addressing this
challenge by proposing FrugalML, a principled framework that jointly learns the
strength and weakness of each API on different data, and performs an efficient
optimization to automatically identify the best sequential strategy to
adaptively use the available APIs within a budget constraint. Our theoretical
analysis shows that natural sparsity in the formulation can be leveraged to
make FrugalML efficient. We conduct systematic experiments using ML APIs from
Google, Microsoft, Amazon, IBM, Baidu and other providers for tasks including
facial emotion recognition, sentiment analysis and speech recognition. Across
various tasks, FrugalML can achieve up to 90% cost reduction while matching the
accuracy of the best single API, or up to 5% better accuracy while matching the
best API's cost.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:43:23 GMT""}]","2020-06-16"
"2006.07513","Yishu Xue","Guanyu Hu, Hou-Cheng Yang, Yishu Xue","Bayesian Group Learning for Shot Selection of Professional Basketball
  Players",,,"10.1002/sta4.324",,"stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we develop a group learning approach to analyze the underlying
heterogeneity structure of shot selection among professional basketball players
in the NBA. We propose a mixture of finite mixtures (MFM) model to capture the
heterogeneity of shot selection among different players based on Log Gaussian
Cox process (LGCP). Our proposed method can simultaneously estimate the number
of groups and group configurations. An efficient Markov Chain Monte Carlo
(MCMC) algorithm is developed for our proposed model. Simulation studies have
been conducted to demonstrate its performance. Ultimately, our proposed
learning approach is further illustrated in analyzing shot charts of several
players in the NBA's 2017-2018 regular season.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:49:08 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 19:15:09 GMT""},{""version"":""v3"",""created"":""Mon, 19 Oct 2020 23:41:30 GMT""}]","2020-10-21"
"2006.07514","Jos\'e Lu\'is da Silva Dr.","Yuri G. Kondratiev and Jos\'e L. da Silva","Green Measures for Markov Processes","12 pages","Methods Funct. Anal. Topology, 26(3), 2020, 241-248","10.31392/MFAT-npu26_3.2020.05",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study Green measures of certain classes of Markov processes.
In particular Brownian motion and processes with jump generators with different
tails. The Green measures are represented as a sum of a singular and a regular
part given in terms of the jump generator. The main technical question is to
find a bound for the regular part.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:49:44 GMT""}]","2021-01-01"
"2006.07515","Bruna Wundervald","Bruna Wundervald, Andrew Parnell and Katarina Domijan","Generalizing Gain Penalization for Feature Selection in Tree-based
  Models","13 pages, 2 figures",,,,"stat.ML cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a new approach for feature selection via gain penalization in
tree-based models. First, we show that previous methods do not perform
sufficient regularization and often exhibit sub-optimal out-of-sample
performance, especially when correlated features are present. Instead, we
develop a new gain penalization idea that exhibits a general local-global
regularization for tree-based models. The new method allows for more
flexibility in the choice of feature-specific importance weights. We validate
our method on both simulated and real data and implement itas an extension of
the popular R package ranger.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:55:52 GMT""}]","2020-06-16"
"2006.07516","Am\'ilcar Soares","Fateha Khanam Bappee, Lucas May Petry, Amilcar Soares, Stan Matwin","Analyzing the Impact of Foursquare and Streetlight Data with Human
  Demographics on Future Crime Prediction",,,,,"cs.CY cs.LG cs.SI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Finding the factors contributing to criminal activities and their
consequences is essential to improve quantitative crime research. To respond to
this concern, we examine an extensive set of features from different
perspectives and explanations. Our study aims to build data-driven models for
predicting future crime occurrences. In this paper, we propose the use of
streetlight infrastructure and Foursquare data along with demographic
characteristics for improving future crime incident prediction. We evaluate the
classification performance based on various feature combinations as well as
with the baseline model. Our proposed model was tested on each smallest
geographic region in Halifax, Canada. Our findings demonstrate the
effectiveness of integrating diverse sources of data to gain satisfactory
classification performance.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 00:11:20 GMT""}]","2020-06-16"
"2006.07517","Linda Brown Westrick","Arno Pauly and Linda Westrick and Liang Yu","Luzin's (N) and randomness reflection","25 pages",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that a computable function $f:\mathbb R\rightarrow\mathbb R$ has
Luzin's property (N) if and only if it reflects $\Pi^1_1$-randomnes, if and
only if it reflects $\Delta^1_1(\mathcal O)$-randomness, and if and only if it
reflects $\mathcal O$-Kurtz randomness, but reflecting Martin-L\""of randomness
or weak-2-randomness does not suffice. Here a function $f$ is said to reflect a
randomness notion $R$ if whenever $f(x)$ is $R$-random, then $x$ is $R$-random
as well. If additionally $f$ is known to have bounded variation, then we show
$f$ has Luzin's (N) if and only if it reflects weak-2-randomness, and if and
only if it reflects $\emptyset'$-Kurtz randomness. This links classical real
analysis with algorithmic randomness.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 00:18:00 GMT""},{""version"":""v2"",""created"":""Sat, 26 Sep 2020 01:12:09 GMT""}]","2020-09-29"
"2006.07518","Muhammad Usman Arif","Muhammad Usman Arif","Decentralized decision making and navigation strategy for tracking
  intruders in a cluttered area by a group of mobile robots","Technical Report, 55 Pages",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the current era of the industrial revolution, mobile robots are playing a
pivotal role in helping out mankind in many complex and hazardous environments
for performing tasks like search and rescue, obstacle avoidance, mining and
security surveillance, etc. A lot of navigation algorithms have been developed
in recent years but novel challenges still exist in autonomous path planning of
multiple robots to track and follow multiple intruders. This report
demonstrates a decentralized strategy of arithmetic mean based navigation
algorithm for a group of mobile robots to navigate through an unknown
environment filled with obstacles to detect and follow multiple invading
intruders. The suggested navigation strategy ensures that mobile robots safely
move right in the middle of surrounding obstacles to maintain a safe distance
and to avoid collision with obstacles and each other. The conventional method
of color recognition is used to detect dynamic intruders and calculate pixel
values using the Microsoft Kinect sensor camera. A probability of danger
algorithm is introduced to ensure that all the intruders present in the
environment are being followed by friendly robots on the bases of the minimum
distance between an intruder and its follower. The mobile robots follow
intruders movement on the bases of their pixel values. The low pixel value
means that intruder is far away and high pixel value represents that intruder
is closer to the friendly robots. All the algorithms and image processing
techniques are implemented and tested in WEBOTS simulation environment using C
programming language and the results show the success of proposed arithmetic
mean based navigation and probability of danger based intruders following
algorithms.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 00:21:11 GMT""}]","2020-06-16"
"2006.07519","Kyle Dent","Kyle Dent and Kalai Ramea","Conversational User Interfaces for Blind Knowledge Workers: A Case Study",,,,,"cs.HC cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern trends in interface design for office equipment using controls on
touch surfaces create greater obstacles for blind and visually impaired users
and contribute to an environment of dependency in work settings. We believe
that \textit{conversational user interfaces} (CUIs) offer a reasonable
alternative to touchscreen interactions enabling more access and most
importantly greater independence for blind knowledge workers. We present a case
study of our work to develop a conversational user interface for accessibility
for multifunction printers. We also describe our approach to conversational
interfaces in general, which emphasizes task-based collaborative interactions
between people and intelligent agents, and we detail the specifics of the
solution we created for multifunction printers. To guide our design, we worked
with a group of blind and visually impaired individuals starting with focus
group sessions to ascertain the challenges our target users face in their
professional lives. We followed our technology development with a user study to
assess the solution and direct our future efforts. We present our findings and
conclusions from the study.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 00:27:14 GMT""},{""version"":""v2"",""created"":""Tue, 13 Oct 2020 21:06:00 GMT""}]","2020-10-15"
"2006.07520","Qing Zhiwu","Zhiwu Qing, Xiang Wang, Yongpeng Sang, Changxin Gao, Shiwei Zhang,
  Nong Sang","Temporal Fusion Network for Temporal Action Localization:Submission to
  ActivityNet Challenge 2020 (Task E)","To appear on CVPR 2020 HACS Workshop (Rank 1st)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This technical report analyzes a temporal action localization method we used
in the HACS competition which is hosted in Activitynet Challenge 2020.The goal
of our task is to locate the start time and end time of the action in the
untrimmed video, and predict action category.Firstly, we utilize the
video-level feature information to train multiple video-level action
classification models. In this way, we can get the category of action in the
video.Secondly, we focus on generating high quality temporal proposals.For this
purpose, we apply BMN to generate a large number of proposals to obtain high
recall rates. We then refine these proposals by employing a cascade structure
network called Refine Network, which can predict position offset and new IOU
under the supervision of ground truth.To make the proposals more accurate, we
use bidirectional LSTM, Nonlocal and Transformer to capture temporal
relationships between local features of each proposal and global features of
the video data.Finally, by fusing the results of multiple models, our method
obtains 40.55% on the validation set and 40.53% on the test set in terms of
mAP, and achieves Rank 1 in this challenge.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 00:33:00 GMT""}]","2020-06-16"
"2006.07521","Harris Niavis","Harris Niavis, Nikolaos Papadis, Leandros Tassiulas","A Blockchain-based Decentralized Data Sharing Infrastructure for
  Off-grid Networking","An abridged version of this work appeared in ICBC 2020, fixed minor
  typos and layout issues",,,,"cs.DC cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Off-grid networks are recently emerging as a solution to connect the
unconnected or provide alternative services to networks of possibly untrusted
participants. The systems currently used, however, exhibit limitations due to
their centralized nature and thus prove inadequate to secure trust. Blockchain
technology can be the tool that will enable trust and transparency in such
networks. In this paper, we introduce a platform for secure and
privacy-respecting decentralized data sharing among untrusted participants in
off-grid networks. The proposed architecture realizes this goal via the
integration of existing blockchain frameworks (Hyperledger Fabric, Indy, Aries)
with an off-grid network device and a distributed file system. We evaluate the
proposed platform through experiments and show results for its throughput and
latency, which indicate its adequate performance for supporting off-grid
decentralized applications.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 00:37:56 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 16:52:08 GMT""}]","2020-07-09"
"2006.07522","Nancy Nayak","Vishnu Raj, Nancy Nayak and Sheetal Kalyani","Understanding Learning Dynamics of Binary Neural Networks via
  Information Bottleneck",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compact neural networks are essential for affordable and power efficient deep
learning solutions. Binary Neural Networks (BNNs) take compactification to the
extreme by constraining both weights and activations to two levels, $\{+1,
-1\}$. However, training BNNs are not easy due to the discontinuity in
activation functions, and the training dynamics of BNNs is not well understood.
In this paper, we present an information-theoretic perspective of BNN training.
We analyze BNNs through the Information Bottleneck principle and observe that
the training dynamics of BNNs is considerably different from that of Deep
Neural Networks (DNNs). While DNNs have a separate empirical risk minimization
and representation compression phases, our numerical experiments show that in
BNNs, both these phases are simultaneous. Since BNNs have a less expressive
capacity, they tend to find efficient hidden representations concurrently with
label fitting. Experiments in multiple datasets support these observations, and
we see a consistent behavior across different activation functions in BNNs.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 00:39:25 GMT""}]","2020-06-16"
"2006.07523","Ryo Tamura","Ryo Tamura, Koji Hukushima, Akira Matsuo, Koichi Kindo, Masashi Hase","Data-driven determination of the spin Hamiltonian parameters and their
  uncertainties: The case of the zigzag-chain compound KCu$_4$P$_3$O$_{12}$","10 pages, 8 figures",,"10.1103/PhysRevB.101.224435",,"cond-mat.mtrl-sci cond-mat.stat-mech cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a data-driven technique to estimate the spin Hamiltonian,
including uncertainty, from multiple physical quantities. Using our technique,
an effective model of KCu$_4$P$_3$O$_{12}$ is determined from the
experimentally observed magnetic susceptibility and magnetization curves with
various temperatures under high magnetic fields. An effective model, which is
the quantum Heisenberg model on a zigzag chain with eight spins having $J_1=
-8.54 \pm 0.51 \{\rm meV}$, $J_2 = -2.67 \pm 1.13 \{\rm meV}$, $J_3 = -3.90 \pm
0.15 \{\rm meV}$, and $J_4 = 6.24 \pm 0.95 \{\rm meV}$, describes these
measured results well. These uncertainties are successfully determined by the
noise estimation. The relations among the estimated magnetic interactions or
physical quantities are also discussed. The obtained effective model is useful
to predict hard-to-measure properties such as spin gap, spin configuration at
the ground state, magnetic specific heat, and magnetic entropy.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 00:47:14 GMT""}]","2020-07-15"
"2006.07524","Kouichi Hagino","K. Hagino and G.F. Bertsch","Least action and the maximum-coupling approximations in the theory of
  spontaneous fission","9 pages, 5 figures. To appear in Phys. Rev. C","Phys. Rev. C 102, 024316 (2020)","10.1103/PhysRevC.102.024316","KUNS-2819, INT-PUB-20-24","nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the dynamics of spontaneous fission in a
configuration-interaction (CI) approach. In that formalism the decay rate is
governed by an effective interaction coupling the ground-state configuration
and a fission doorway configuration, with the interaction strength determined
by inverting a high-dimensioned CI Hamiltonian matrix that may have a
block-tridiagonal structure. It is shown that the decay rate decreases
exponentially with the number of blocks at a rate determined by the largest
eigenvalue of a matrix in the block space for Hamiltonians with identical
off-diagonal blocks. The theory is greatly simplified by approximations similar
in spirit to the adiabatic and the least-action approximations in continuum
representations. Here each block is replaced by a single matrix element. While
the adiabatic reduction underestimates the coupling, a reduction based on a
maximum-coupling approximation works well in a schematic CI model.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 00:47:50 GMT""},{""version"":""v2"",""created"":""Sat, 1 Aug 2020 00:56:20 GMT""}]","2020-08-19"
"2006.07525","Riddhish Bhalodia","Riddhish Bhalodia and Ladislav Kavan and Ross Whitaker","Self-Supervised Discovery of Anatomical Shape Landmarks","Early accept at MICCAI 2020",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Statistical shape analysis is a very useful tool in a wide range of medical
and biological applications. However, it typically relies on the ability to
produce a relatively small number of features that can capture the relevant
variability in a population. State-of-the-art methods for obtaining such
anatomical features rely on either extensive preprocessing or segmentation
and/or significant tuning and post-processing. These shortcomings limit the
widespread use of shape statistics. We propose that effective shape
representations should provide sufficient information to align/register images.
Using this assumption we propose a self-supervised, neural network approach for
automatically positioning and detecting landmarks in images that can be used
for subsequent analysis. The network discovers the landmarks corresponding to
anatomical shape features that promote good image registration in the context
of a particular class of transformations. In addition, we also propose a
regularization for the proposed network which allows for a uniform distribution
of these discovered landmarks. In this paper, we present a complete framework,
which only takes a set of input images and produces landmarks that are
immediately usable for statistical shape analysis. We evaluate the performance
on a phantom dataset as well as 2D and 3D images.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 00:56:33 GMT""}]","2020-06-16"
"2006.07526","Xiang Wang","Xiang Wang, Baiteng Ma, Zhiwu Qing, Yongpeng Sang, Changxin Gao,
  Shiwei Zhang, Nong Sang","CBR-Net: Cascade Boundary Refinement Network for Action Detection:
  Submission to ActivityNet Challenge 2020 (Task 1)","ActivityNet Challenge 2020 Temporal Action Localization (Task 1)
  Champion Solution (Rank 1)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this report, we present our solution for the task of temporal action
localization (detection) (task 1) in ActivityNet Challenge 2020. The purpose of
this task is to temporally localize intervals where actions of interest occur
and predict the action categories in a long untrimmed video. Our solution
mainly includes three components: 1) feature encoding: we apply three kinds of
backbones, including TSN [7], Slowfast[3] and I3d[1], which are both pretrained
on Kinetics dataset[2]. Applying these models, we can extract snippet-level
video representations; 2) proposal generation: we choose BMN [5] as our
baseline, base on which we design a Cascade Boundary Refinement Network
(CBR-Net) to conduct proposal detection. The CBR-Net mainly contains two
modules: temporal feature encoding, which applies BiLSTM to encode long-term
temporal information; CBR module, which targets to refine the proposal
precision under different parameter settings; 3) action localization: In this
stage, we combine the video-level classification results obtained by the fine
tuning networks to predict the category of each proposal. Moreover, we also
apply to different ensemble strategies to improve the performance of the
designed solution, by which we achieve 42.788% on the testing set of
ActivityNet v1.3 dataset in terms of mean Average Precision metrics.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:05:51 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 04:22:52 GMT""}]","2020-06-25"
"2006.07527","Lijun Sun Mr","Yuankai Wu, Dingyi Zhuang, Aurelie Labbe and Lijun Sun","Inductive Graph Neural Networks for Spatiotemporal Kriging","AAAI 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time series forecasting and spatiotemporal kriging are the two most important
tasks in spatiotemporal data analysis. Recent research on graph neural networks
has made substantial progress in time series forecasting, while little
attention has been paid to the kriging problem -- recovering signals for
unsampled locations/sensors. Most existing scalable kriging methods (e.g.,
matrix/tensor completion) are transductive, and thus full retraining is
required when we have a new sensor to interpolate. In this paper, we develop an
Inductive Graph Neural Network Kriging (IGNNK) model to recover data for
unsampled sensors on a network/graph structure. To generalize the effect of
distance and reachability, we generate random subgraphs as samples and
reconstruct the corresponding adjacency matrix for each sample. By
reconstructing all signals on each sample subgraph, IGNNK can effectively learn
the spatial message passing mechanism. Empirical results on several real-world
spatiotemporal datasets demonstrate the effectiveness of our model. In
addition, we also find that the learned model can be successfully transferred
to the same type of kriging tasks on an unseen dataset. Our results show that:
1) GNN is an efficient and effective tool for spatial kriging; 2) inductive
GNNs can be trained using dynamic adjacency matrices; 3) a trained model can be
transferred to new graph structures and 4) IGNNK can be used to generate
virtual sensors.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:23:44 GMT""},{""version"":""v2"",""created"":""Sat, 19 Dec 2020 16:09:16 GMT""}]","2020-12-22"
"2006.07528","Ibrahim Saideh","Ibrahim Saideh, Daniel Finkelstein-Shapiro, Camille No\^us, T\~onu
  Pullerits, and Arne Keller","Projection based adiabatic elimination of bipartite open quantum systems","11 pages, 2 figures","Phys. Rev. A 102, 032212 (2020)","10.1103/PhysRevA.102.032212",,"quant-ph cond-mat.mes-hall physics.atom-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adiabatic elimination methods allow the reduction of the space dimension
needed to describe systems dynamics which exhibits separation of time scale.
For open quantum system, it consists in eliminating the fast part assuming it
has almost instantaneously reached its steady-state and obtaining an
approximation of the evolution of the slow part. These methods can be applied
to eliminate a linear subspace within the system Hilbert space, or
alternatively to eliminate a fast subsystems in a bipartite quantum system. In
this work, we extend an adiabatic elimination method used for removing fast
degrees of freedom within a open quantum system (Phys. Rev. A 2020, 101,042102)
to eliminate a subsystem from an open bipartite quantum system. As an
illustration, we apply our technique to a dispersively coupled two-qubit system
and in the case of the open Rabi model.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:33:47 GMT""}]","2020-09-23"
"2006.07529","Yuzhe Yang","Yuzhe Yang, Zhi Xu","Rethinking the Value of Labels for Improving Class-Imbalanced Learning","NeurIPS 2020",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-world data often exhibits long-tailed distributions with heavy class
imbalance, posing great challenges for deep recognition models. We identify a
persisting dilemma on the value of labels in the context of imbalanced
learning: on the one hand, supervision from labels typically leads to better
results than its unsupervised counterparts; on the other hand, heavily
imbalanced data naturally incurs ""label bias"" in the classifier, where the
decision boundary can be drastically altered by the majority classes. In this
work, we systematically investigate these two facets of labels. We demonstrate,
theoretically and empirically, that class-imbalanced learning can significantly
benefit in both semi-supervised and self-supervised manners. Specifically, we
confirm that (1) positively, imbalanced labels are valuable: given more
unlabeled data, the original labels can be leveraged with the extra data to
reduce label bias in a semi-supervised manner, which greatly improves the final
classifier; (2) negatively however, we argue that imbalanced labels are not
useful always: classifiers that are first pre-trained in a self-supervised
manner consistently outperform their corresponding baselines. Extensive
experiments on large-scale imbalanced datasets verify our theoretically
grounded strategies, showing superior performance over previous
state-of-the-arts. Our intriguing findings highlight the need to rethink the
usage of imbalanced labels in realistic long-tailed tasks. Code is available at
https://github.com/YyzHarry/imbalanced-semi-self.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:35:58 GMT""},{""version"":""v2"",""created"":""Sat, 26 Sep 2020 20:05:13 GMT""}]","2020-09-29"
"2006.07530","Andong Li","Andong Li, Chengshi Zheng, Renhua Peng, Cunhang Fan, Xiaodong Li","Dynamic Attention Based Generative Adversarial Network with Phase
  Post-Processing for Speech Enhancement","5 pages, 3 figures",,,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The generative adversarial networks (GANs) have facilitated the development
of speech enhancement recently. Nevertheless, the performance advantage is
still limited when compared with state-of-the-art models. In this paper, we
propose a powerful Dynamic Attention Recursive GAN called DARGAN for noise
reduction in the time-frequency domain. Different from previous works, we have
several innovations. First, recursive learning, an iterative training protocol,
is used in the generator, which consists of multiple steps. By reusing the
network in each step, the noise components are progressively reduced in a
step-wise manner. Second, the dynamic attention mechanism is deployed, which
helps to re-adjust the feature distribution in the noise reduction module.
Third, we exploit the deep Griffin-Lim algorithm as the module for phase
postprocessing, which facilitates further improvement in speech quality.
Experimental results on Voice Bank corpus show that the proposed GAN achieves
state-of-the-art performance than previous GAN- and non-GAN-based models
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:38:43 GMT""}]","2020-06-16"
"2006.07531","Sebasti\'an Reyes-Carocca","Sebasti\'an Reyes-Carocca","A family of $(p,n)$-gonal Riemann surfaces with several $(p,n)$-gonal
  groups","4 pages","Arch. Math. (Basel) 116 (2021), no. 3, 302-305","10.1007/s00013-020-01548-y",,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $p \geqslant 3$ be a prime number and let $n \geqslant 0$ be an integer
such that $p-1$ divides $n.$ In this short note we construct a family of
$(p,n)$-gonal Riemann surfaces of maximal genus $2np+(p-1)^2$ with more than
one $(p,n)$-gonal group.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:43:06 GMT""}]","2021-05-04"
"2006.07532","Tan Zhi-Xuan","Tan Zhi-Xuan, Jordyn L. Mann, Tom Silver, Joshua B. Tenenbaum, Vikash
  K. Mansinghka","Online Bayesian Goal Inference for Boundedly-Rational Planning Agents","Accepted to NeurIPS 2020. 10 pages (excl. references), 6
  figures/tables. (Supplement: 8 pages, 11 figures/tables). Code available at:
  https://github.com/ztangent/Plinf.jl",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  People routinely infer the goals of others by observing their actions over
time. Remarkably, we can do so even when those actions lead to failure,
enabling us to assist others when we detect that they might not achieve their
goals. How might we endow machines with similar capabilities? Here we present
an architecture capable of inferring an agent's goals online from both optimal
and non-optimal sequences of actions. Our architecture models agents as
boundedly-rational planners that interleave search with execution by
replanning, thereby accounting for sub-optimal behavior. These models are
specified as probabilistic programs, allowing us to represent and perform
efficient Bayesian inference over an agent's goals and internal planning
processes. To perform such inference, we develop Sequential Inverse Plan Search
(SIPS), a sequential Monte Carlo algorithm that exploits the online replanning
assumption of these models, limiting computation by incrementally extending
inferred plans as new actions are observed. We present experiments showing that
this modeling and inference architecture outperforms Bayesian inverse
reinforcement learning baselines, accurately inferring goals from both optimal
and non-optimal trajectories involving failure and back-tracking, while
generalizing across domains with compositional structure and sparse rewards.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:48:10 GMT""},{""version"":""v2"",""created"":""Sun, 25 Oct 2020 01:36:16 GMT""}]","2020-10-27"
"2006.07533","Yihao Huang","Yihao Huang, Felix Juefei-Xu, Run Wang, Qing Guo, Lei Ma, Xiaofei Xie,
  Jianwen Li, Weikai Miao, Yang Liu, Geguang Pu","FakePolisher: Making DeepFakes More Detection-Evasive by Shallow
  Reconstruction","9 pages, accepted by ACM MM 2020",,,,"cs.CV cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  At this moment, GAN-based image generation methods are still imperfect, whose
upsampling design has limitations in leaving some certain artifact patterns in
the synthesized image. Such artifact patterns can be easily exploited (by
recent methods) for difference detection of real and GAN-synthesized images.
However, the existing detection methods put much emphasis on the artifact
patterns, which can become futile if such artifact patterns were reduced.
Towards reducing the artifacts in the synthesized images, in this paper, we
devise a simple yet powerful approach termed FakePolisher that performs shallow
reconstruction of fake images through a learned linear dictionary, intending to
effectively and efficiently reduce the artifacts introduced during image
synthesis. The comprehensive evaluation on 3 state-of-the-art DeepFake
detection methods and fake images generated by 16 popular GAN-based fake image
generation techniques, demonstrates the effectiveness of our technique.Overall,
through reducing artifact patterns, our technique significantly reduces the
accuracy of the 3 state-of-the-art fake image detection methods, i.e., 47% on
average and up to 93% in the worst case.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:48:15 GMT""},{""version"":""v2"",""created"":""Fri, 14 Aug 2020 12:10:08 GMT""},{""version"":""v3"",""created"":""Mon, 17 Aug 2020 07:27:28 GMT""}]","2020-08-18"
"2006.07534","Lu Chen","Ke Wang, Lu Chen","Constraints on Multicomponent Dark Energy from Cosmological Observations","7 pages, 3 figures","Phys. Rev. D 104, 023514 (2021)","10.1103/PhysRevD.104.023514",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dark energy (DE) plays an important role in the expansion history of our
universe. But we only got limited knowledge about its nature and properties
after decades of study.In most numerical researches, DE is usually considered
as a dynamical whole. Actually, multicomponent DE models can also explain the
accelerating expansion of our universe, which is accepted theoretically but
lack of numerical researches. We try to study the multicomponent DE models from
observation by constructing $w_n$CDM models. The total energy density of DE is
separated into $n$ ($n=2,3,5$) parts equally and every part has a constant EOS
$w_i$ ($i=1,2...n$). We modify the Friedmann equation and the parameterized
post-Friedmann description of DE, then put constraints on $w_i$s from Planck
2018 TT,TE,EE$+$lowE$+$lensing, BAO data and PANTHEON samples. The
multicomponent DE models are favoured if any $w_n$CDM model is preferred by
observational data and there is no overlap between the highest and lowest
values of $w_i$s. We find the data combination supports the $w_n$CDM model when
$n$ is small and the $w_2$CDM model is slightly preferred by $\Delta
\chi^2_{\text{min}} = \Delta \text{AIC} =\Delta \text{BIC} = -2.48$ over the
CPL model, but the largest value of $w_i$ overlaps the smallest one. With
larger $n$, the maximum and minimum of $w_i$s do not overlap with each other,
but $\chi^2_{\text{min}}$ and AIC also increase. In brief, we find no obvious
evidence that DE is composed of different components.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 02:03:08 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 02:33:36 GMT""}]","2021-08-02"
"2006.07535","Michelle Cluver Dr","M.E. Cluver, T.H. Jarrett, E.N. Taylor, A.M. Hopkins, S. Brough, S.
  Casura, B.W. Holwerda, J. Liske, K.A. Pimbblet, A.H. Wright","Galaxy and Mass Assembly (GAMA): Demonstrating the power of WISE in the
  study of Galaxy Groups to $z<0.1$","Accepted for publication in ApJ",,"10.3847/1538-4357/ab9cb8",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Combining high-fidelity group characterisation from the Galaxy and Mass
Assembly (GAMA) survey and source-tailored $z<0.1$ photometry from the WISE
survey, we present a comprehensive study of the properties of ungrouped
galaxies, compared to 497 galaxy groups (4$\leq$ N$_{\rm FoF}$ $\leq$ 20) as a
function of stellar and halo mass. Ungrouped galaxies are largely unimodal in
WISE color, the result of being dominated by star-forming, late-type galaxies.
Grouped galaxies, however, show a clear bimodality in WISE color, which
correlates strongly with stellar mass and morphology. We find evidence for an
increasing early-type fraction, in stellar mass bins between
$10^{10}\lesssim$M$_{\rm stellar} \lesssim10^{11}$ M$_\odot$, with increasing
halo mass. Using ungrouped, late-type galaxies with star-forming colors
(W2$-$W3$>$3), we define a star-forming main-sequence (SFMS), which we use to
delineate systems that have moved below the sequence (""quenched"" for the
purposes of this work). We find that with increasing halo mass, the relative
number of late-type systems on the SFMS decreases, with a corresponding
increase in early-type, quenched systems at high stellar mass (M$_{\rm
stellar}>{10}^{10.5}$ M$_\odot$), consistent with mass quenching. Group
galaxies with masses M$_{\rm stellar}<{10}^{10.5}$ M$_\odot$ show evidence of
quenching consistent with environmentally-driven processes. The stellar mass
distribution of late-type, quenched galaxies suggests they may be an
intermediate population as systems transition from being star-forming and
late-type to the ""red sequence"". Finally, we use the projected area of groups
on the sky to extract groups that are (relatively) compact for their halo mass.
Although these show a marginal increase in their proportion of high mass and
early-type galaxies compared to nominal groups, a clear increase in quenched
fraction is not evident.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 02:04:58 GMT""}]","2020-07-29"
"2006.07536","Stavroula Foteinopoulou","Stavroula Foteinopoulou","Photonic crystals as metamaterials","15 pages, 4 figures","Physica B, vol. 407, pp. 4056-4061 (2012)","10.1016/j.physb.2012.01.092",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The visionary work of Veselago had inspired intensive research efforts over
the last decade, towards the realization of man-made structures with
unprecedented electromagnetic (EM) properties. These structures, known as
metamaterials, are typically periodic metallic-based resonant structures
demonstrating effective constitutive parameters beyond the possibilities of
natural material. For example they can exhibit optical magnetism or
simultaneously negative effective permeability and permittivity which implies
the existence of a negative refractive index. However, also periodic dielectric
and polar material, known as photonic crystals, can exhibit EM capabilities
beyond natural materials. This paper reviews the conditions and manifestations
of metamaterial capabilities of photonic crystal systems.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 02:16:23 GMT""}]","2020-06-16"
"2006.07537","Sergio Mundo","Sergio A. Mundo, Erin Kara, Edward M. Cackett, A.C. Fabian, J. Jiang,
  R.F. Mushotzky, M.L. Parker, C. Pinto, C.S. Reynolds, A. Zoghbi","The Origin of X-ray Emission in the Gamma-ray emitting Narrow-Line
  Seyfert 1 1H 0323+342","Accepted for publication in MNRAS. 11 pages, 9 figures; references
  added",,"10.1093/mnras/staa1744",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the results of X-ray spectral and timing analyses of the closest
gamma-ray emitting narrow-line Seyfert 1 ($\gamma$-NLS1) galaxy, 1H 0323+342.
We use observations from a recent, simultaneous XMM-Newton/NuSTAR campaign. As
in radio-quiet NLS1s, the spectrum reveals a soft excess at low energies
($\lesssim2$ keV) and reflection features such as a broad iron K emission line.
We also find evidence of a hard excess at energies above $\sim35$ keV that is
likely a consequence of jet emission. Our analysis shows that relativistic
reflection is statistically required, and using a combination of models that
includes the reflection model relxill for the broadband spectrum, we find an
inclination of $i=63^{+7}_{-5}$ degrees, which is in tension with much lower
values inferred by superluminal motion in radio observations. We also find a
flat ($q=2.2\pm0.3$) emissivity profile, implying that there is more reflected
flux than usual being emitted from the outer regions of the disk, which in turn
suggests a deviation from the thin disk model assumption. We discuss possible
reasons for this, such as reflection off of a thick accretion disk geometry.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 02:27:11 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 05:45:39 GMT""}]","2020-07-01"
"2006.07538","Michael Nosonovsky","Michael Nosonovsky and Prosun Roy","Allometric scaling law and ergodicity breaking in the vascular system",,,,,"cond-mat.soft cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Allometry or the quantitative study of the relationship of body size to
living organism physiology is an important area of biophysical scaling
research. The West-Brown-Enquist (WBE) model of fractal branching in a vascular
network explains the empirical allometric Kleiber law (the 3/4 scaling exponent
for metabolic rates as a function of animal's mass). The WBE model raises a
number of new questions, such as how to account for capillary phenomena more
accurately and what are more realistic dependencies for blood flow velocity on
the size of a capillary. We suggest a generalized formulation of the branching
model and investigate the ergodicity in the fractal vascular system. In
general, the fluid flow in such a system is not ergodic, and ergodicity
breaking is attributed to the fractal structure of the network. Consequently,
the fractal branching may be viewed as a source of ergodicity breaking in
biophysical systems, in addition to such mechanisms as aging and macromolecular
crowding. Accounting for non-ergodicity is important for a wide range of
biomedical applications where long observations of time series are impractical.
The relevance to microfluidics applications is also discussed.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 02:30:48 GMT""}]","2020-06-16"
"2006.07539","Robert Hildebrand","Benjamin Beach, Robert Hildebrand, Kimberly Ellis, Baptiste Lebreton","An Approximate Method for the Optimization of Long-Horizon Tank Blending
  and Scheduling Operations",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address a challenging tank blending and scheduling problem regarding
operations for a chemical plant. We model the problem as a nonconvex MIQCP,
then approximate this model as a MILP using a discretization-based approach. We
combine a rolling horizon approach with the discretization of individual
chemical property specifications to deal with long scheduling horizons,
time-varying quality specifications, and multiple suppliers with discrete
arrival times. This approach has been evaluated using industry-representative
data sets from the specialty chemical industry.
  We demonstrate that the proposed approach supports fast planning cycles.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 02:38:23 GMT""}]","2020-06-16"
"2006.07540","Hae Beom Lee","Jeongun Ryu and Jaewoong Shin and Hae Beom Lee and Sung Ju Hwang","MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and
  Architectures",,,,"Advances in Neural Information Processing Systems 33 (NeurIPS 2020)","cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Regularization and transfer learning are two popular techniques to enhance
generalization on unseen data, which is a fundamental problem of machine
learning. Regularization techniques are versatile, as they are task- and
architecture-agnostic, but they do not exploit a large amount of data
available. Transfer learning methods learn to transfer knowledge from one
domain to another, but may not generalize across tasks and architectures, and
may introduce new training cost for adapting to the target task. To bridge the
gap between the two, we propose a transferable perturbation, MetaPerturb, which
is meta-learned to improve generalization performance on unseen data.
MetaPerturb is implemented as a set-based lightweight network that is agnostic
to the size and the order of the input, which is shared across the layers.
Then, we propose a meta-learning framework, to jointly train the perturbation
function over heterogeneous tasks in parallel. As MetaPerturb is a set-function
trained over diverse distributions across layers and tasks, it can generalize
to heterogeneous tasks and architectures. We validate the efficacy and
generality of MetaPerturb trained on a specific source domain and architecture,
by applying it to the training of diverse neural architectures on heterogeneous
target datasets against various regularizers and fine-tuning. The results show
that the networks trained with MetaPerturb significantly outperform the
baselines on most of the tasks and architectures, with a negligible increase in
the parameter size and no hyperparameters to tune.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 02:54:59 GMT""},{""version"":""v2"",""created"":""Sun, 5 Dec 2021 13:19:40 GMT""},{""version"":""v3"",""created"":""Tue, 15 Feb 2022 13:56:01 GMT""}]","2022-02-16"
"2006.07541","Arun Sai Suggala","Arun Sai Suggala, Praneeth Netrapalli","Follow the Perturbed Leader: Optimism and Fast Parallel Algorithms for
  Smooth Minimax Games","38 pages. Under review",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of online learning and its application to solving
minimax games. For the online learning problem, Follow the Perturbed Leader
(FTPL) is a widely studied algorithm which enjoys the optimal $O(T^{1/2})$
worst-case regret guarantee for both convex and nonconvex losses. In this work,
we show that when the sequence of loss functions is predictable, a simple
modification of FTPL which incorporates optimism can achieve better regret
guarantees, while retaining the optimal worst-case regret guarantee for
unpredictable sequences. A key challenge in obtaining these tighter regret
bounds is the stochasticity and optimism in the algorithm, which requires
different analysis techniques than those commonly used in the analysis of FTPL.
The key ingredient we utilize in our analysis is the dual view of perturbation
as regularization. While our algorithm has several applications, we consider
the specific application of minimax games. For solving smooth convex-concave
games, our algorithm only requires access to a linear optimization oracle. For
Lipschitz and smooth nonconvex-nonconcave games, our algorithm requires access
to an optimization oracle which computes the perturbed best response. In both
these settings, our algorithm solves the game up to an accuracy of
$O(T^{-1/2})$ using $T$ calls to the optimization oracle. An important feature
of our algorithm is that it is highly parallelizable and requires only
$O(T^{1/2})$ iterations, with each iteration making $O(T^{1/2})$ parallel calls
to the optimization oracle.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 02:55:41 GMT""}]","2020-06-16"
"2006.07542","Cihan Okay","Cihan Okay","Commutative d-Torsion K-Theory and Its Applications","41 pages",,,,"math.AT quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Commutative $d$-torsion $K$-theory is a variant of topological $K$-theory
constructed from commuting unitary matrices of order dividing $d$. Such
matrices appear as solutions of linear constraint systems that play a role in
the study of quantum contextuality and in applications to operator-theoretic
problems motivated by quantum information theory. Using methods from stable
homotopy theory we modify commutative $d$-torsion $K$-theory into a cohomology
theory which can be used for studying operator solutions of linear constraint
systems. This provides an interesting connection between stable homotopy theory
and quantum information theory.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:13:28 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 09:31:52 GMT""},{""version"":""v3"",""created"":""Sun, 10 Oct 2021 19:58:33 GMT""}]","2021-10-12"
"2006.07543","Miaoyun Zhao","Yulai Cong, Miaoyun Zhao, Jianqiao Li, Sijia Wang, Lawrence Carin","GAN Memory with No Forgetting","NeurIPS2020",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a fundamental issue in lifelong learning, catastrophic forgetting is
directly caused by inaccessible historical data; accordingly, if the data
(information) were memorized perfectly, no forgetting should be expected.
Motivated by that, we propose a GAN memory for lifelong learning, which is
capable of remembering a stream of datasets via generative processes, with
\emph{no} forgetting. Our GAN memory is based on recognizing that one can
modulate the ""style"" of a GAN model to form perceptually-distant targeted
generation. Accordingly, we propose to do sequential style modulations atop a
well-behaved base GAN model, to form sequential targeted generative models,
while simultaneously benefiting from the transferred base knowledge. The GAN
memory -- that is motivated by lifelong learning -- is therefore itself
manifested by a form of lifelong learning, via forward transfer and modulation
of information from prior tasks. Experiments demonstrate the superiority of our
method over existing approaches and its effectiveness in alleviating
catastrophic forgetting for lifelong classification problems. Code is available
at https://github.com/MiaoyunZhao/GANmemory_LifelongLearning.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:19:54 GMT""},{""version"":""v2"",""created"":""Thu, 12 Nov 2020 05:31:26 GMT""}]","2020-11-13"
"2006.07544","Chuan-Long Xie","Chuanlong Xie, Haotian Ye, Fei Chen, Yue Liu, Rui Sun, Zhenguo Li","Risk Variance Penalization",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The key of the out-of-distribution (OOD) generalization is to generalize
invariance from training domains to target domains. The variance risk
extrapolation (V-REx) is a practical OOD method, which depends on a
domain-level regularization but lacks theoretical verifications about its
motivation and utility. This article provides theoretical insights into V-REx
by studying a variance-based regularizer. We propose Risk Variance Penalization
(RVP), which slightly changes the regularization of V-REx but addresses the
theory concerns about V-REx. We provide theoretical explanations and a
theory-inspired tuning scheme for the regularization parameter of RVP. Our
results point out that RVP discovers a robust predictor. Finally, we
experimentally show that the proposed regularizer can find an invariant
predictor under certain conditions.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:20:49 GMT""},{""version"":""v2"",""created"":""Fri, 9 Apr 2021 06:19:31 GMT""}]","2021-04-12"
"2006.07545","Tian Xu","Thomas Bartsch and Tian Xu","Strongly localized semiclassical states for nonlinear Dirac equations",,"Discrete Contin. Dyn. Syst. 41:1, 29-60 (2021)","10.3934/dcds.2020297",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study semiclassical states of the nonlinear Dirac equation \[
  -i\hbar\partial_t\psi = ic\hbar\sum_{k=1}^3\alpha_k\partial_k\psi - mc^2\beta
\psi - M(x)\psi + f(|\psi|)\psi,\quad t\in\mathbb{R},\ x\in\mathbb{R}^3, \]
where $V$ is a bounded continuous potential function and the nonlinear term
$f(|\psi|)\psi$ is superlinear, possibly of critical growth. Our main result
deals with standing wave solutions that concentrate near a critical point of
the potential. Standard methods applicable to nonlinear Schr\""odinger
equations, like Lyapunov-Schmidt reduction or penalization, do not work, not
even for the homogeneous nonlinearity $f(s)=s^p$. We develop a variational
method for the strongly indefinite functional associated to the problem.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:20:51 GMT""}]","2023-01-13"
"2006.07546","Peter Marcy","Peter W. Marcy and Curtis B. Storlie","Bayesian Calibration of Computer Models with Informative Failures",,,,"LA-UR-18-21204","stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are many practical difficulties in the calibration of computer models
to experimental data. One such complication is the fact that certain
combinations of the calibration inputs can cause the code to output data
lacking fundamental properties, or even to produce no output at all. In many
cases the researchers want or need to exclude the possibility of these
""failures"" within their analyses. We propose a Bayesian (meta-)model in which
the posterior distribution for the calibration parameters naturally excludes
regions of the input space corresponding to failed runs. That is, we define a
statistical selection model to rigorously couple the disjoint problems of
binary classification and computer model calibration. We demonstrate our
methodology using data from a carbon capture experiment in which the numerics
of the computational fluid dynamics are prone to instability.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:23:46 GMT""}]","2020-06-16"
"2006.07547","Kai Chang","Kai Chang, Stuart S. P. Parkin","Experimental formation of monolayer group-IV monochalcogenides","A Perspective for the Special Topic on Beyond Graphene: Low Symmetry
  and Anisotropic 2D Materials","J. Appl. Phys. 127, 220902 (2020)","10.1063/5.0012300",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Monolayer group-IV monochalcogenides (MX, M = Ge, Sn, Pb; X = S, Se, Te) are
a family of novel two-dimensional (2D) materials that have atomic structures
closely related to that of the staggered black phosphorus lattice. The
structure of most monolayer MX materials exhibits a broken inversion symmetry,
and many of them exhibit ferroelectricity with a reversible in-plane electric
polarization. A further consequence of the noncentrosymmetric structure is that
when coupled with strong spin-orbit coupling, many MX materials are promising
for the future applications in non-linear optics, photovoltaics, spintronics
and valleytronics. Nevertheless, because of the relatively large exfoliation
energy, the creation of monolayer MX materials is not easy, which hinders the
integration of these materials into the fast-developing field of 2D material
heterostructures. In this Perspective, we review recent developments in
experimental routes to the creation of monolayer MX, including molecular beam
epitaxy and two-step etching methods. Other approaches that could be used to
prepare monolayer MX are also discussed, such as liquid phase exfoliation and
solution phase synthesis. A quantitative comparison between these different
methods is also presented.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:24:44 GMT""}]","2020-06-16"
"2006.07548","Hamed Zamani","Helia Hashemi, Hamed Zamani, W. Bruce Croft","Guided Transformer: Leveraging Multiple External Sources for
  Representation Learning in Conversational Search","To appear in the Proceedings of ACM SIGIR 2020. 10 pages",,,,"cs.IR cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Asking clarifying questions in response to ambiguous or faceted queries has
been recognized as a useful technique for various information retrieval
systems, especially conversational search systems with limited bandwidth
interfaces. Analyzing and generating clarifying questions have been studied
recently but the accurate utilization of user responses to clarifying questions
has been relatively less explored. In this paper, we enrich the representations
learned by Transformer networks using a novel attention mechanism from external
information sources that weights each term in the conversation. We evaluate
this Guided Transformer model in a conversational search scenario that includes
clarifying questions. In our experiments, we use two separate external sources,
including the top retrieved documents and a set of different possible
clarifying questions for the query. We implement the proposed representation
learning model for two downstream tasks in conversational search; document
retrieval and next clarifying question selection. Our experiments use a public
dataset for search clarification and demonstrate significant improvements
compared to competitive baselines.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:24:53 GMT""}]","2020-06-16"
"2006.07549","Yunhao Tang","Yunhao Tang, Alp Kucukelbir","Hindsight Expectation Maximization for Goal-conditioned Reinforcement
  Learning","Accepted at International Conference on Artificial Intelligence and
  Statistics (AISTATS), 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a graphical model framework for goal-conditioned RL, with an EM
algorithm that operates on the lower bound of the RL objective. The E-step
provides a natural interpretation of how 'learning in hindsight' techniques,
such as HER, to handle extremely sparse goal-conditioned rewards. The M-step
reduces policy optimization to supervised learning updates, which greatly
stabilizes end-to-end training on high-dimensional inputs such as images. We
show that the combined algorithm, hEM significantly outperforms model-free
baselines on a wide range of goal-conditioned benchmarks with sparse rewards.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:25:31 GMT""},{""version"":""v2"",""created"":""Fri, 26 Feb 2021 15:37:26 GMT""}]","2021-03-01"
"2006.07550","Peng Xu","Liang Ding, Peng Xu, Haibo Gao, Zhikai Wang, Ruyi Zhou, Zhaopei Gong,
  and Guangjun Liu","Fault Tolerant Free Gait and Footstep Planning for Hexapod Robot Based
  on Monte-Carlo Tree",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Legged robots can pass through complex field environments by selecting gaits
and discrete footholds carefully. Traditional methods plan gait and foothold
separately and treat them as the single-step optimal process. However, such
processing causes its poor passability in a sparse foothold environment. This
paper novelly proposes a coordinative planning method for hexapod robots that
regards the planning of gait and foothold as a sequence optimization problem
with the consideration of dealing with the harshness of the environment as leg
fault. The Monte Carlo tree search algorithm(MCTS) is used to optimize the
entire sequence. Two methods, FastMCTS, and SlidingMCTS are proposed to solve
some defeats of the standard MCTS applicating in the field of legged robot
planning. The proposed planning algorithm combines the fault-tolerant gait
method to improve the passability of the algorithm. Finally, compared with
other planning methods, experiments on terrains with different densities of
footholds and artificially-designed challenging terrain are carried out to
verify our methods. All results show that the proposed method dramatically
improves the hexapod robot's ability to pass through sparse footholds
environment.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:36:55 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 04:20:58 GMT""}]","2020-06-17"
"2006.07551","Jinyuan Chang","Jinyuan Chang, Guanghui Cheng, Qiwei Yao","Testing for unit roots based on sample autocovariances",,"Biometrika 2022, Vol. 109, No. 2, 543-550","10.1093/biomet/asab034",,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new unit-root test for a stationary null hypothesis $H_0$
against a unit-root alternative $H_1$. Our approach is nonparametric as $H_0$
only assumes that the process concerned is $I(0)$ without specifying any
parametric forms. The new test is based on the fact that the sample
autocovariance function (ACVF) converges to the finite population ACVF for an
$I(0)$ process while it diverges to infinity for a process with unit-roots.
Therefore the new test rejects $H_0$ for the large values of the sample ACVF.
To address the technical challenge `how large is large', we split the sample
and establish an appropriate normal approximation for the null-distribution of
the test statistic. The substantial discriminative power of the new test
statistic is rooted from the fact that it takes finite value under $H_0$ and
diverges to infinity under $H_1$. This allows us to truncate the critical
values of the test to make it with the asymptotic power one. It also alleviates
the loss of power due to the sample-splitting. The test is implemented in a
user-friendly R-function.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:46:11 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 08:45:40 GMT""}]","2022-06-15"
"2006.07552","Wei Xiong","Soumya Sridar, Yunhao Zhao, Wei Xiong","Cyclic Re-austenitization of Copper-bearing High-Strength Low-Alloy
  Steels Fabricated by Laser Powder Bed Fusion","30 pages, 12 Figures",,"10.1016/j.matchar.2020.110437",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the first time, cyclic re-austenitization is carried out for additively
manufactured high-strength low-alloy (HSLA) steels in order to refine the
microstructure by reducing the prior austenite grain (PAG) size. In this work,
HSLA-100 steels processed using laser powder bed fusion (LPBF) technique are
subjected to several cycles of re-austenitization using quenching dilatometry.
Microstructure characterization for every cycle revealed the presence of
bainite, martensite and martensite/austenite (M/A) islands. From the analysis
of the dilatometry curves and extensive microstructure characterization, it was
found that till the 2nd cycle of re-austenitization, both PAG size and
martensite start (Ms) temperature get reduced, while the amount of bainite
transformed decreased and the retained austenite content increased.
Concomitantly, the highest microhardness along with peak nanohardness of the
constituent phases was achieved at the 2nd cycle. Conversely, from the 3rd
cycle, the microhardness, as well as the nanohardness of the constituent
phases, are found to decrease due to an increase in the PAG size. This behavior
is in contrast to the general tendency where a saturation limit is reached
after the peak refinement is achieved. It is found that retained austenite can
act as a pinning particle to obstruct the PAG boundary movement and its
fraction is found to decrease from the 3rd cycle. Hence, the increase in PAG
size after the 3rd cycle can be attributed to the destabilization of effective
pinning particles to hinder the PAG boundary movement during the
re-austenitization.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:47:18 GMT""}]","2020-06-16"
"2006.07553","Nicolas Gillis","Nicolas Nadisic, Arnaud Vandaele, Jeremy E. Cohen, Nicolas Gillis","Sparse Separable Nonnegative Matrix Factorization","20 pages, accepted in ECML 2020",,,,"cs.LG cs.CV eess.SP math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new variant of nonnegative matrix factorization (NMF), combining
separability and sparsity assumptions. Separability requires that the columns
of the first NMF factor are equal to columns of the input matrix, while
sparsity requires that the columns of the second NMF factor are sparse. We call
this variant sparse separable NMF (SSNMF), which we prove to be NP-complete, as
opposed to separable NMF which can be solved in polynomial time. The main
motivation to consider this new model is to handle underdetermined blind source
separation problems, such as multispectral image unmixing. We introduce an
algorithm to solve SSNMF, based on the successive nonnegative projection
algorithm (SNPA, an effective algorithm for separable NMF), and an exact sparse
nonnegative least squares solver. We prove that, in noiseless settings and
under mild assumptions, our algorithm recovers the true underlying sources.
This is illustrated by experiments on synthetic data sets and the unmixing of a
multispectral image.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:52:29 GMT""}]","2020-06-16"
"2006.07554","Yunhao Tang","Yunhao Tang, Krzysztof Choromanski","Online Hyper-parameter Tuning in Off-policy Learning via Evolutionary
  Strategies",,,,,"cs.LG cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Off-policy learning algorithms have been known to be sensitive to the choice
of hyper-parameters. However, unlike near on-policy algorithms for which
hyper-parameters could be optimized via e.g. meta-gradients, similar techniques
could not be straightforwardly applied to off-policy learning. In this work, we
propose a framework which entails the application of Evolutionary Strategies to
online hyper-parameter tuning in off-policy learning. Our formulation draws
close connections to meta-gradients and leverages the strengths of black-box
optimization with relatively low-dimensional search spaces. We show that our
method outperforms state-of-the-art off-policy learning baselines with static
hyper-parameters and recent prior work over a wide range of continuous control
benchmarks.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 03:54:26 GMT""}]","2020-06-16"
"2006.07555","Xavier Michalet","Xavier Michalet","Continuous and discrete phasor analysis of binned or time-gated periodic
  decays","114 pages, 18 figures, 2 tables, 38 references","AIP Advances 11 (2021) 035331","10.1063/5.0027834",,"q-bio.QM physics.ins-det physics.optics","http://creativecommons.org/licenses/by/4.0/","  Time-resolved analysis of periodically excited luminescence decays by the
phasor method in the presence of time-gating or binning is revisited.
Analytical expressions for discrete configurations of square gates are derived
and the locus of the phasors of such modified periodic single-exponential
decays is compared to the canonical uni-versal semicircle. The effects of IRF
offset, decay truncation and gate shape are also discussed. Finally, modified
expressions for the phase and modulus lifetimes are pro-vided for some simple
cases. A discussion of a modified phasor calibration approach is presented, and
illustration of the new concepts with examples from the literature conclude
this work.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 04:07:22 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jan 2021 23:20:24 GMT""}]","2021-08-04"
"2006.07556","Xingchen Wan","Binxin Ru, Xingchen Wan, Xiaowen Dong, Michael Osborne","Interpretable Neural Architecture Search via Bayesian Optimisation with
  Weisfeiler-Lehman Kernels","ICLR 2021. 9 pages, 5 figures, 1 table (23 pages, 14 figures and 3
  tables including references and appendices)",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current neural architecture search (NAS) strategies focus only on finding a
single, good, architecture. They offer little insight into why a specific
network is performing well, or how we should modify the architecture if we want
further improvements. We propose a Bayesian optimisation (BO) approach for NAS
that combines the Weisfeiler-Lehman graph kernel with a Gaussian process
surrogate. Our method optimises the architecture in a highly data-efficient
manner: it is capable of capturing the topological structures of the
architectures and is scalable to large graphs, thus making the high-dimensional
and graph-like search spaces amenable to BO. More importantly, our method
affords interpretability by discovering useful network features and their
corresponding impact on the network performance. Indeed, we demonstrate
empirically that our surrogate model is capable of identifying useful motifs
which can guide the generation of new architectures. We finally show that our
method outperforms existing NAS approaches to achieve the state of the art on
both closed- and open-domain search spaces.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 04:10:34 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 05:36:54 GMT""}]","2021-02-22"
"2006.07557","Andreas Gustavsson","Andreas Gustavsson","A nonabelian M5 brane Lagrangian in a supergravity background","30 pages",,"10.1007/JHEP10(2020)001",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a nonabelian Lagrangian that appears to have $(2,0)$
superconformal symmetry and that can be coupled to a supergravity background.
But for our construction to work, we have to break this superconformal symmetry
by imposing as a constraint on top of the Lagrangian that the fields have
vanishing Lie derivatives along a Killing direction.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 04:18:33 GMT""},{""version"":""v2"",""created"":""Sat, 20 Jun 2020 12:32:39 GMT""},{""version"":""v3"",""created"":""Sun, 6 Sep 2020 09:18:14 GMT""}]","2020-10-28"
"2006.07558","Kyle Dent","Kyle Dent","Ethical Considerations for AI Researchers",,,,,"cs.CY cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Use of artificial intelligence is growing and expanding into applications
that impact people's lives. People trust their technology without really
understanding it or its limitations. There is the potential for harm and we are
already seeing examples of that in the world. AI researchers have an obligation
to consider the impact of intelligent applications they work on. While the
ethics of AI is not clear-cut, there are guidelines we can consider to minimize
the harm we might introduce.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 04:31:42 GMT""}]","2020-06-16"
"2006.07559","J. Andrew Zhang","J. Andrew Zhang, Md Lushanur Rahman, Kai Wu, Xiaojing Huang, Y. Jay
  Guo, Shanzhi Chen, and Jinhong Yuan","Enabling Joint Communication and Radar Sensing in Mobile Networks -- A
  Survey","41 pages, 15 figures, 17 tables, journal paper. IEEE Communications
  Surveys and Tutorials (Accepted for publication, Oct. 2021)",,,,"eess.SP cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mobile network is evolving from a communication-only network towards one with
joint communication and radar/radio sensing (JCAS) capabilities, that we call
perceptive mobile network (PMN). In PMNs, JCAS integrates sensing into
communications, sharing a majority of system modules and the same transmitted
signals. The PMN is expected to provide a ubiquitous radio sensing platform and
enable a vast number of novel smart applications, whilst providing
non-compromised communications. In this paper, we present a broad picture of
the motivation, methodologies, challenges, and research opportunities of
realizing PMN, by providing a comprehensive survey for systems and technologies
developed mainly in the last ten years. Beginning by reviewing the work on
coexisting communication and radar systems, we highlight their limits on
addressing the interference problem, and then introduce the JCAS technology. We
then set up JCAS in the mobile network context and envisage its potential
applications. We continue to provide a brief review of three types of JCAS
systems, with particular attention to their differences in design philosophy.
We then introduce a framework of PMN, including the system platform and
infrastructure, three types of sensing operations, and signals usable for
sensing. Subsequently, we discuss required system modifications to enable
sensing on current communication-only infrastructure. Within the context of
PMN, we review stimulating research problems and potential solutions, organized
under nine topics: performance bounds, waveform optimization, antenna array
design, clutter suppression, sensing parameter estimation, resolution of
sensing ambiguity, pattern analysis, networked sensing under cellular topology,
and sensing-assisted communications. We conclude the paper by listing key open
research problems for the aforementioned topics and sharing some lessons that
we have learned.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 04:36:37 GMT""},{""version"":""v2"",""created"":""Fri, 11 Sep 2020 23:28:31 GMT""},{""version"":""v3"",""created"":""Sat, 16 Jan 2021 08:52:53 GMT""},{""version"":""v4"",""created"":""Thu, 21 Oct 2021 02:44:49 GMT""}]","2021-10-22"
"2006.07560","Shengyun Peng","Shengyun Peng and Yunxuan Yu and Kun Wang and Lei He","Accurate Anchor Free Tracking","10 pages, 11 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Visual object tracking is an important application of computer vision.
Recently, Siamese based trackers have achieved good accuracy. However, most of
Siamese based trackers are not efficient, as they exhaustively search potential
object locations to define anchors and then classify each anchor (i.e., a
bounding box). This paper develops the first Anchor Free Siamese Network
(AFSN). Specifically, a target object is defined by a bounding box center,
tracking offset, and object size. All three are regressed by Siamese network
with no additional classification or regional proposal, and performed once for
each frame. We also tune the stride and receptive field for Siamese network,
and further perform ablation experiments to quantitatively illustrate the
effectiveness of our AFSN. We evaluate AFSN using five most commonly used
benchmarks and compare to the best anchor-based trackers with source codes
available for each benchmark. AFSN is 3-425 times faster than these best anchor
based trackers. AFSN is also 5.97% to 12.4% more accurate in terms of all
metrics for benchmark sets OTB2015, VOT2015, VOT2016, VOT2018 and TrackingNet,
except that SiamRPN++ is 4% better than AFSN in terms of Expected Average
Overlap (EAO) on VOT2018 (but SiamRPN++ is 3.9 times slower).
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 04:42:32 GMT""}]","2020-06-16"
"2006.07561","Somak Dutta","Dongjin Li, Somak Dutta and Vivekananda Roy","Model Based Screening Embedded Bayesian Variable Selection for
  Ultra-high Dimensional Settings","54 pages including supplementary,4 figures and 6 tables",,,,"stat.ME stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a Bayesian variable selection method, called SVEN, based on a
hierarchical Gaussian linear model with priors placed on the regression
coefficients as well as on the model space. Sparsity is achieved by using
degenerate spike priors on inactive variables, whereas Gaussian slab priors are
placed on the coefficients for the important predictors making the posterior
probability of a model available in explicit form (up to a normalizing
constant). The strong model selection consistency is shown to be attained when
the number of predictors grows nearly exponentially with the sample size and
even when the norm of mean effects solely due to the unimportant variables
diverge, which is a novel attractive feature. An appealing byproduct of SVEN is
the construction of novel model weight adjusted prediction intervals. Embedding
a unique model based screening and using fast Cholesky updates, SVEN produces a
highly scalable computational framework to explore gigantic model spaces,
rapidly identify the regions of high posterior probabilities and make fast
inference and prediction. A temperature schedule guided by our model selection
consistency derivations is used to further mitigate multimodal posterior
distributions. The performance of SVEN is demonstrated through a number of
simulation experiments and a real data example from a genome wide association
study with over half a million markers.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 04:43:07 GMT""},{""version"":""v2"",""created"":""Fri, 31 Jul 2020 19:06:21 GMT""}]","2020-08-04"
"2006.07562","Mohammadi Zaki","Mohammadi Zaki, Avi Mohan, Aditya Gopalan","Explicit Best Arm Identification in Linear Bandits Using No-Regret
  Learners",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of best arm identification in linearly parameterised
multi-armed bandits. Given a set of feature vectors
$\mathcal{X}\subset\mathbb{R}^d,$ a confidence parameter $\delta$ and an
unknown vector $\theta^*,$ the goal is to identify
$\arg\max_{x\in\mathcal{X}}x^T\theta^*$, with probability at least $1-\delta,$
using noisy measurements of the form $x^T\theta^*.$ For this fixed confidence
($\delta$-PAC) setting, we propose an explicitly implementable and provably
order-optimal sample-complexity algorithm to solve this problem. Previous
approaches rely on access to minimax optimization oracles. The algorithm, which
we call the \textit{Phased Elimination Linear Exploration Game} (PELEG),
maintains a high-probability confidence ellipsoid containing $\theta^*$ in each
round and uses it to eliminate suboptimal arms in phases. PELEG achieves fast
shrinkage of this confidence ellipsoid along the most confusing (i.e., close
to, but not optimal) directions by interpreting the problem as a two player
zero-sum game, and sequentially converging to its saddle point using low-regret
learners to compute players' strategies in each round. We analyze the sample
complexity of PELEG and show that it matches, up to order, an
instance-dependent lower bound on sample complexity in the linear bandit
setting. We also provide numerical results for the proposed algorithm
consistent with its theoretical guarantees.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 05:00:01 GMT""}]","2020-06-16"
"2006.07563","Huthaifa I. Ashqar","Huthaifa I. Ashqar, Mohammed Elhenawy, and Hesham A.Rakha","Modeling bike counts in a bike-sharing system considering the effect of
  weather conditions","Published in Case Studies on Transport Policy (Volume 7, Issue 2,
  June 2019, Pages 261-268)","Case studies on transport policy 7, no. 2 (2019): 261-268","10.1016/j.cstp.2019.02.011",,"cs.CY cs.LG physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper develops a method that quantifies the effect of weather conditions
on the prediction of bike station counts in the San Francisco Bay Area Bike
Share System. The Random Forest technique was used to rank the predictors that
were then used to develop a regression model using a guided forward step-wise
regression approach. The Bayesian Information Criterion was used in the
development and comparison of the various prediction models. We demonstrated
that the proposed approach is promising to quantify the effect of various
features on a large BSS and on each station in cases of large networks with big
data. The results show that the time-of-the-day, temperature, and humidity
level (which has not been studied before) are significant count predictors. It
also shows that as weather variables are geographic location dependent and thus
should be quantified before using them in modeling. Further, findings show that
the number of available bikes at station i at time t-1 and time-of-the-day were
the most significant variables in estimating the bike counts at station i.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 05:32:32 GMT""}]","2020-06-16"
"2006.07564","Farzad Yousefian","Farzad Yousefian","Bilevel Distributed Optimization in Directed Networks",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by emerging applications in wireless sensor networks and
large-scale data processing, we consider distributed optimization over directed
networks where the agents communicate their information locally to their
neighbors to cooperatively minimize a global cost function. We introduce a new
unifying distributed constrained optimization model that is characterized as a
bilevel optimization problem. This model captures a wide range of existing
problems over directed networks including: (i) Distributed optimization with
linear constraints; (ii) Distributed unconstrained nonstrongly convex
optimization over directed networks. Employing a novel regularization-based
relaxation approach and gradient-tracking schemes, we develop an iteratively
regularized push-pull gradient algorithm. We establish the consensus and derive
new convergence rate statements for suboptimality and infeasibility of the
generated iterates for solving the bilevel model. The proposed algorithm and
the complexity analysis obtained in this work appear to be new for addressing
the bilevel model and also for the two sub-classes of problems. The numerical
performance of the proposed algorithm is presented.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 05:35:23 GMT""},{""version"":""v2"",""created"":""Tue, 29 Sep 2020 12:58:48 GMT""},{""version"":""v3"",""created"":""Fri, 19 Mar 2021 05:29:19 GMT""}]","2021-03-22"
"2006.07565","Ye Xue","Ye Xue, Xuanyu Zheng, Vincent Lau","Line-of-Sight MIMO for High Capacity Millimeter Wave Backhaul in FDD
  Systems",,,"10.23919/JCIN.2020.9130434",,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wireless backhaul is considered to be the key part of the future wireless
network with dense small cell traffic and high capacity demand. In this paper,
we focus on the design of a high spectral efficiency line-of-sight (LoS)
multiple-input multiple-output (MIMO) system for millimeter wave (mmWave)
backhaul using dual-polarized frequency division duplex (FDD). High spectral
efficiency is very challenging to achieve for the system due to various
physical impairments such as phase noise (PHN), timing offset (TO) as well as
the poor condition number of the LoS MIMO. In this paper, we propose a holistic
solution containing TO compensation, PHN estimation, precoder/decorrelator
optimization of the LoS MIMO for wireless backhaul, and the interleaving of
each part. We show that the proposed solution has robust performance with
end-to-end spectral efficiency of 60 bits/s/Hz for 8x8 MIMO.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 05:35:32 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 09:54:59 GMT""}]","2021-04-20"
"2006.07566","Grant Cairns","Christian Aebi and Grant Cairns","Lattice Equable Quadrilaterals I -- Parallelograms","Revised to incorporate changes suggested by referee",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies equable parallelograms whose vertices lie on the integer
lattice. Using Rosenberger's Theorem on generalised Markov equations, we show
that the g.c.d. of the side lengths of such parallelograms can only be 3, 4 or
5, and in each of these cases the set of parallelograms naturally forms an
infinite tree all of whose vertices have degree 4, bar the root. The paper then
focuses on what we call Pythagorean equable parallelograms. These are lattice
equable parallelograms whose complement in a circumscribing rectangle consists
of two Pythagorean triangles. We prove that for these parallelograms the
shortest side can only be 3, 4, 5, 6 or 10, and there are five infinite
families of such parallelograms, given by solutions to corresponding Pell-like
equations.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 05:42:18 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 06:51:15 GMT""}]","2021-05-03"
"2006.07567","Ligong Han","Ligong Han, Anastasis Stathopoulos, Tao Xue, Dimitris Metaxas","Unbiased Auxiliary Classifier GANs with MINE","Accepted at CVPRW-20",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Auxiliary Classifier GANs (AC-GANs) are widely used conditional generative
models and are capable of generating high-quality images. Previous work has
pointed out that AC-GAN learns a biased distribution. To remedy this, Twin
Auxiliary Classifier GAN (TAC-GAN) introduces a twin classifier to the min-max
game. However, it has been reported that using a twin auxiliary classifier may
cause instability in training. To this end, we propose an Unbiased Auxiliary
GANs (UAC-GAN) that utilizes the Mutual Information Neural Estimator (MINE) to
estimate the mutual information between the generated data distribution and
labels. To further improve the performance, we also propose a novel
projection-based statistics network architecture for MINE. Experimental results
on three datasets, including Mixture of Gaussian (MoG), MNIST and CIFAR10
datasets, show that our UAC-GAN performs better than AC-GAN and TAC-GAN. Code
can be found on the project website.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 05:51:51 GMT""}]","2020-06-16"
"2006.07568","Xin-Long Luo","Xin-long Luo and Yi-yan Yao","Primal-dual path-following methods and the trust-region updating
  strategy for linear programming with noisy data","arXiv admin note: text overlap with arXiv:2006.02634",,,,"math.OC cs.LG cs.NA math.DS math.NA","http://creativecommons.org/licenses/by/4.0/","  In this article, we consider the primal-dual path-following method and the
trust-region updating strategy for the standard linear programming problem. For
the rank-deficient problem with the small noisy data, we also give the
preprocessing method based on the QR decomposition with column pivoting. Then,
we prove the global convergence of the new method when the initial point is
strictly primal-dual feasible. Finally, for some rank-deficient problems with
or without the small noisy data from the NETLIB collection, we compare it with
other two popular interior-point methods, i.e. the subroutine pathfollow.m and
the built-in subroutine linprog.m of the MATLAB environment. Numerical results
show that the new method is more robust than the other two methods for the
rank-deficient problem with the small noise data.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:01:53 GMT""},{""version"":""v2"",""created"":""Sun, 3 Jan 2021 06:17:13 GMT""},{""version"":""v3"",""created"":""Mon, 18 Jan 2021 12:23:31 GMT""},{""version"":""v4"",""created"":""Mon, 22 Feb 2021 12:23:44 GMT""}]","2021-02-23"
"2006.07569","Chenkai Yu","Chenkai Yu, Guanya Shi, Soon-Jo Chung, Yisong Yue, Adam Wierman","The Power of Predictions in Online Control",,,,,"math.OC cs.SY eess.SY math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the impact of predictions in online Linear Quadratic Regulator
control with both stochastic and adversarial disturbances in the dynamics. In
both settings, we characterize the optimal policy and derive tight bounds on
the minimum cost and dynamic regret. Perhaps surprisingly, our analysis shows
that the conventional greedy MPC approach is a near-optimal policy in both
stochastic and adversarial settings. Specifically, for length-$T$ problems, MPC
requires only $O(\log T)$ predictions to reach $O(1)$ dynamic regret, which
matches (up to lower-order terms) our lower bound on the required prediction
horizon for constant regret.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:03:46 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jul 2020 21:02:39 GMT""},{""version"":""v3"",""created"":""Sat, 7 Nov 2020 16:28:31 GMT""},{""version"":""v4"",""created"":""Fri, 8 Jan 2021 06:48:22 GMT""}]","2021-01-11"
"2006.07570","Muhammed Amir","Sushant G. Ghosh, Muhammed Amir, Sunil D. Maharaj","Ergosphere and shadow of a rotating regular black hole","22 pages, 11 figures, 2 tables, accepted for publication in NPB",,"10.1016/j.nuclphysb.2020.115088",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spacetime singularities in classical general relativity predicted by the
celebrated singularity theorems are formed at the end of gravitational
collapse. Quantum gravity is the expected theory to resolve the singularity
problem, but we are now far from it. Therefore attention has shifted to models
of regular black holes free from the singularities. A spherically symmetric
regular toy model was obtained by Dymnikova (1992) which we demonstrate as an
exact solution of Einstein's field equations coupled to nonlinear
electrodynamics for a Lagrangian with parameter $b$ related to magnetic charge.
We construct rotating counterpart of this solution which encompasses the Kerr
black hole as a special case when charge is switched off ($b=0$). Event Horizon
Telescope has released the first image of supermassive black hole M87$^*$,
revealing the structure near black hole horizon. The rotating regular black
hole's shadow may be useful to determine strong field regime. We investigate
ergosphere and black hole shadow of rotating regular black hole to infer that
their sizes are sensitive to charge $b$ and have a richer chaotic structure. In
particular, rotating regular black hole possess larger size, but less distorted
shadows when compared with Kerr black holes. We find one to one correspondence
between ergosphere and shadow of the black hole.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:05:20 GMT""}]","2020-07-15"
"2006.07571","Masahiro Fujisawa","Masahiro Fujisawa, Takeshi Teshima, Issei Sato, Masashi Sugiyama","$\gamma$-ABC: Outlier-Robust Approximate Bayesian Computation Based on a
  Robust Divergence Estimator","The 24th International Conference on Artificial Intelligence and
  Statistics (AISTATS 2021); 48 pages, 22 figures",,,,"stat.ML cs.LG stat.CO stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Approximate Bayesian computation (ABC) is a likelihood-free inference method
that has been employed in various applications. However, ABC can be sensitive
to outliers if a data discrepancy measure is chosen inappropriately. In this
paper, we propose to use a nearest-neighbor-based $\gamma$-divergence estimator
as a data discrepancy measure. We show that our estimator possesses a suitable
theoretical robustness property called the redescending property. In addition,
our estimator enjoys various desirable properties such as high flexibility,
asymptotic unbiasedness, almost sure convergence, and linear-time computational
complexity. Through experiments, we demonstrate that our method achieves
significantly higher robustness than existing discrepancy measures.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:09:27 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 08:06:41 GMT""},{""version"":""v3"",""created"":""Fri, 5 Mar 2021 05:16:43 GMT""}]","2021-03-08"
"2006.07572","Mitsunori Araki","Mitsunori Araki, Shuro Takano, Nobuhiko Kuze, Yoshiaki Minami,
  Takahiro Oyama, Kazuhisa Kamegai, Yoshihiro Sumiyoshi, and Koichi Tsukiyama","Observations and Analysis of Absorption Lines including J = K Rotational
  Levels of CH3CN: The Envelope of Sagittarius B2(M)",,,"10.1093/mnras/staa1754",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Molecules in diffuse and translucent clouds experience cooling as a result of
radiation and less excitation from collisions. However, a rotation around a
molecular axis of acetonitrile, CH3CN, cannot be cooled by radiation, causing
rotational populations to concentrate at the J = K levels. We aim to search for
absorption lines of CH3CN having J = K level concentrations in diffuse and
translucent clouds. The JK = 43-33 transition at 73.6 GHz was investigated
toward Sgr B2(M) in the Galactic Center region and other sources, using the
Nobeyama 45 m telescope. Based on the detected absorption lines toward Sgr
B2(M), a radiation temperature of 2.8 +/- 0.5 K, kinetic temperature of 88 +/-
29 K, and column density of (1.35 +/- 0.14) x 10^14 cm-2 were derived for this
molecule, revealing extremely concentrated J = K levels due to the lower
excitation temperature and the higher kinetic temperature. The absorption lines
occurred at a velocity of 64 km s-1. The results confirm that CH3CN with J = K
level concentrations exists in the envelope of Sgr B2(M).
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:12:12 GMT""}]","2020-08-19"
"2006.07573","Xavier Marjou","Xavier Marjou","GIPFA: Generating IPA Pronunciation from Audio","10 pages, 2 figures, 7 tables","Proceedings of the eLex 2021 conference, page 588",,,"cs.CL cs.SD eess.AS","http://creativecommons.org/licenses/by-sa/4.0/","  Transcribing spoken audio samples into the International Phonetic Alphabet
(IPA) has long been reserved for experts. In this study, we examine the use of
an Artificial Neural Network (ANN) model to automatically extract the IPA
phonemic pronunciation of a word based on its audio pronunciation, hence its
name Generating IPA Pronunciation From Audio (GIPFA). Based on the French
Wikimedia dictionary, we trained our model which then correctly predicted 75%
of the IPA pronunciations tested. Interestingly, by studying inference errors,
the model made it possible to highlight possible errors in the dataset as well
as to identify the closest phonemes in French.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:14:11 GMT""},{""version"":""v2"",""created"":""Tue, 21 Sep 2021 19:53:39 GMT""}]","2021-09-23"
"2006.07574","Slava Rychkov","Vyacheslav S. Rychkov","Splitting of Volterra Integral Operators with Degenerate Kernels","21 pages","Trudy Mat. Inst. Steklova, vol.214 (1997) 267-285; Translated in
  Proc. Steklov Inst. Math., vol.214 (1996) 260-278",,,"math.CA math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Volterra integral operators with non-sign-definite degenerate kernels
$A(x,t)= \sum_{k=0}^n A_k(x,t)$, $A_k(x,t)= a_k (x) t^k$, are studied acting
from one weighted $L_2$ space on $(0,+\infty)$ to another. Imposing an integral
doubling condition on one of the weights, it is shown that the operator with
the kernel $A(x,t)$ is bounded if and only $n+1$ operators with kernels
$A_k(x,t)$ are all bounded. We apply this result to describe spaces of
pointwise multipliers in weighted Sobolev spaces on $(0,+\infty)$.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:25:11 GMT""}]","2020-06-16"
"2006.07575","Romain Couillet","Xiaoyi Mai and Romain Couillet","Consistent Semi-Supervised Graph Regularization for High Dimensional
  Data",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semi-supervised Laplacian regularization, a standard graph-based approach for
learning from both labelled and unlabelled data, was recently demonstrated to
have an insignificant high dimensional learning efficiency with respect to
unlabelled data (Mai and Couillet 2018), causing it to be outperformed by its
unsupervised counterpart, spectral clustering, given sufficient unlabelled
data. Following a detailed discussion on the origin of this inconsistency
problem, a novel regularization approach involving centering operation is
proposed as solution, supported by both theoretical analysis and empirical
results.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:42:12 GMT""}]","2020-06-16"
"2006.07576","Sixue Gong Miss","Sixue Gong, Xiaoming Liu, and Anil K. Jain","Mitigating Face Recognition Bias via Group Adaptive Classifier",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Face recognition is known to exhibit bias - subjects in a certain demographic
group can be better recognized than other groups. This work aims to learn a
fair face representation, where faces of every group could be more equally
represented. Our proposed group adaptive classifier mitigates bias by using
adaptive convolution kernels and attention mechanisms on faces based on their
demographic attributes. The adaptive module comprises kernel masks and
channel-wise attention maps for each demographic group so as to activate
different facial regions for identification, leading to more discriminative
features pertinent to their demographics. Our introduced automated adaptation
strategy determines whether to apply adaptation to a certain layer by
iteratively computing the dissimilarity among demographic-adaptive parameters.
A new de-biasing loss function is proposed to mitigate the gap of average
intra-class distance between demographic groups. Experiments on face benchmarks
(RFW, LFW, IJB-A, and IJB-C) show that our work is able to mitigate face
recognition bias across demographic groups while maintaining the competitive
accuracy.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:43:37 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 04:18:39 GMT""}]","2020-12-02"
"2006.07577","Yoshiki Toba","Yoshiki Toba, Tomotsugu Goto, Nagisa Oi, Ting-Wen Wang, Seong Jin Kim,
  Simon C.-C. Ho, Denis Burgarella, Tetsuya Hashimoto, Bau-Ching Hsieh,
  Ting-Chi Huang, Ho Seong Hwang, Hiroyuki Ikeda, Helen K. Kim, Seongjae Kim,
  Dongseob Lee, Matthew A. Malkan, Hideo Matsuhara, Takamitsu Miyaji, Rieko
  Momose, Youichi Ohyama, Shinki Oyabu, Chris Pearson, Daryl Joe D. Santos,
  Hyunjin Shim, Toshinobu Takagi, Yoshihiro Ueda, Yousuke Utsumi, Takehiko Wada","Search for Optically Dark Infrared Galaxies without Counterparts of
  Subaru Hyper Suprime-Cam in the AKARI North Ecliptic Pole Wide Survey Field","17 pages, 13 figures, and 2 tables, accepted for publication in ApJ",,"10.3847/1538-4357/ab9cb7",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the physical properties of AKARI sources without optical
counterparts in optical images from the Hyper Suprime-Cam (HSC) on the Subaru
telescope. Using the AKARI infrared (IR) source catalog and HSC optical
catalog, we select 583 objects that do not have HSC counterparts in the AKARI
North Ecliptic Pole (NEP) wide survey field ($\sim 5$ deg$^{2}$). Because the
HSC limiting magnitude is deep ($g_{\rm AB}$ $\sim 28.6$), these are good
candidates for extremely red star-forming galaxies (SFGs) and/or active
galactic nuclei (AGNs), possibly at high redshifts. We compile multi-wavelength
data out to 500 $\mu$m and use it for Spectral Energy Distribution (SED)
fitting with CIGALE to investigate the physical properties of AKARI galaxies
without optical counterparts. We also compare their physical quantities with
AKARI mid-IR selected galaxies with HSC counterparts. The estimated redshifts
of AKARI objects without HSC counterparts range up to $z\sim 4$, significantly
higher than that of AKARI objects with HSC counterparts. We find that: (i) 3.6
$-$ 4.5 $\mu$m color, (ii) AGN luminosity, (iii) stellar mass, (iv) star
formation rate, and (v) $V$-band dust attenuation in the interstellar medium of
AKARI objects without HSC counterparts are systematically larger than those of
AKARI objects with counterparts. These results suggest that our sample includes
luminous, heavily dust-obscured SFGs/AGNs at $z\sim 1-4$ that are missed by
previous optical surveys, providing very interesting targets for the coming
James Webb Space Telescope era.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:46:35 GMT""}]","2020-08-19"
"2006.07578","Jorge Pe\~na Queralta","Jorge Pe\~na Queralta and Tomi Westerlund","Blockchain for Mobile Edge Computing: Consensus Mechanisms and
  Scalability",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mobile edge computing (MEC) and next-generation mobile networks are set to
disrupt the way intelligent and autonomous systems are interconnected. This
will have an effect on a wide range of domains, from the Internet of Things to
autonomous mobile robots. The integration of such a variety of MEC services in
a inherently distributed architecture requires a robust system for managing
hardware resources, balancing the network load and securing the distributed
applications. Blockchain technology has emerged a solution for managing MEC
services, with consensus protocols and data integrity checks that enable
transparent and efficient distributed decision-making. In addition to
transparency, the benefits from a security point of view are evident.
Nonetheless, blockchain technology faces significant challenges in terms of
scalability. In this chapter, we review existing consensus protocols and
scalability techniques in both well-established and next-generation blockchain
architectures. From this, we evaluate the most suitable solutions for managing
MEC services and discuss the benefits and drawbacks of the available
alternatives.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:47:17 GMT""}]","2020-06-16"
"2006.07579","He Yin","He Yin, Peter Seiler, Murat Arcak","Stability Analysis using Quadratic Constraints for Systems with Neural
  Network Controllers","8 pages, submitted to IEEE TAC",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A method is presented to analyze the stability of feedback systems with
neural network controllers. Two stability theorems are given to prove
asymptotic stability and to compute an ellipsoidal inner-approximation to the
region of attraction (ROA). The first theorem addresses linear time-invariant
systems, and merges Lyapunov theory with local (sector) quadratic constraints
to bound the nonlinear activation functions in the neural network. The second
theorem allows the system to include perturbations such as unmodeled dynamics,
slope-restricted nonlinearities, and time delay, using integral quadratic
constraint (IQCs) to capture their input/output behavior. This in turn allows
for off-by-one IQCs to refine the description of activation functions by
capturing their slope restrictions. Both results rely on semidefinite
programming to approximate the ROA. The method is illustrated on systems with
neural networks trained to stabilize a nonlinear inverted pendulum as well as
vehicle lateral dynamics with actuator uncertainty.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:52:58 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 21:39:06 GMT""}]","2021-01-28"
"2006.07580","Ankita Likhyani Mrs","Ankita Likhyani and Vinayak Gupta and Srijith P. K. and Deepak P. and
  Srikanta Bedathur","Modeling Implicit Communities using Spatio-Temporal Point Processes from
  Geo-tagged Event Traces","17 pages",,,,"cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  The location check-ins of users through various location-based services such
as Foursquare, Twitter, and Facebook Places, etc., generate large traces of
geo-tagged events. These event-traces often manifest in hidden (possibly
overlapping) communities of users with similar interests. Inferring these
implicit communities is crucial for forming user profiles for improvements in
recommendation and prediction tasks. Given only time-stamped geo-tagged traces
of users, can we find out these implicit communities, and characteristics of
the underlying influence network? Can we use this network to improve the next
location prediction task? In this paper, we focus on the problem of community
detection as well as capturing the underlying diffusion process and propose a
model COLAB based on Spatio-temporal point processes in continuous time but
discrete space of locations that simultaneously models the implicit communities
of users based on their check-in activities, without making use of their social
network connections. COLAB captures the semantic features of the location,
user-to-user influence along with spatial and temporal preferences of users. To
learn the latent community of users and model parameters, we propose an
algorithm based on stochastic variational inference. To the best of our
knowledge, this is the first attempt at jointly modeling the diffusion process
with activity-driven implicit communities. We demonstrate COLAB achieves up to
27% improvements in location prediction task over recent deep point-process
based methods on geo-tagged event traces collected from Foursquare check-ins.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 06:55:47 GMT""}]","2020-06-16"
"2006.07581","Ming Gong","Linjun Shou, Shining Bo, Feixiang Cheng, Ming Gong, Jian Pei, Daxin
  Jiang","Mining Implicit Relevance Feedback from User Behavior for Web Question
  Answering","Accepted by KDD 2020",,"10.1145/3394486.3403343",,"cs.IR cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training and refreshing a web-scale Question Answering (QA) system for a
multi-lingual commercial search engine often requires a huge amount of training
examples. One principled idea is to mine implicit relevance feedback from user
behavior recorded in search engine logs. All previous works on mining implicit
relevance feedback target at relevance of web documents rather than passages.
Due to several unique characteristics of QA tasks, the existing user behavior
models for web documents cannot be applied to infer passage relevance. In this
paper, we make the first study to explore the correlation between user behavior
and passage relevance, and propose a novel approach for mining training data
for Web QA. We conduct extensive experiments on four test datasets and the
results show our approach significantly improves the accuracy of passage
ranking without extra human labeled data. In practice, this work has proved
effective to substantially reduce the human labeling cost for the QA service in
a global commercial search engine, especially for languages with low resources.
Our techniques have been deployed in multi-language services.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 07:02:08 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 01:10:48 GMT""}]","2020-06-17"
"2006.07582","Nathan Hannon","Nathan Hannon","Spaces of Random Plane Triangulations and the Density of States","23 pages, 2 figures",,,,"math.OA math-ph math.FA math.MG math.MP math.SP","http://creativecommons.org/licenses/by-sa/4.0/","  Tiling spaces are constructed using a metric in which two tilings of
$\mathbb{R}^n$ are close if and only if, after a small translation, they agree
on a large ball around the origin. We construct analogous spaces to study
random triangulations of the plane. We construct a continuous space which is a
foliated space equipped with a transverse measure, and a discrete space which
is a transversal of that space. Measures on these triangulations can be
constructed as limits of measures on spheres.
  We consider von Neumann algebras associated with these spaces. Under certain
conditions, we show that the von Neumann algebra associated with the discrete
space is a hyperfinite type $II_1$ factor. We also show that the density of
states of certain operators is well-behaved with respect to the convergence of
measures, and in particular can be computed by approximating it on spheres,
where eigenvalues can be directly computed. Additionally, we prove a connection
between jumps of the integrated density of states and compactly supported
eigenfunctions analogous to arXiv:0709.2836.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 07:15:43 GMT""},{""version"":""v2"",""created"":""Sun, 26 Jul 2020 23:34:08 GMT""},{""version"":""v3"",""created"":""Mon, 3 Aug 2020 02:38:54 GMT""}]","2020-08-04"
"2006.07583","Beatriz Otero","B. Otero, O. Rojas, F. Moya, J. Castillo","Alternating direction implicit time integrations for finite difference
  acoustic wave propagation: Parallelization and convergence","20 pages, 5 figures","Computers and Fluids 205 (2020) 104584","10.1016/j.compfluid.2020.104584",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work studies the parallelization and empirical convergence of two finite
difference acoustic wave propagation methods on 2-D rectangular grids, that use
the same alternating direction implicit (ADI) time integration. This ADI
integration is based on a second-order implicit Crank-Nicolson temporal
discretization that is factored out by a Peaceman-Rachford decomposition of the
time and space equation terms. In space, these methods highly diverge and apply
different fourth-order accurate differentiation techniques. The first method
uses compact finite differences (CFD) on nodal meshes that requires solving
tridiagonal linear systems along each grid line, while the second one employs
staggered-grid mimetic finite differences (MFD). For each method, we implement
three parallel versions: (i) a multithreaded code in Octave, (ii) a C++ code
that exploits OpenMP loop parallelization, and (iii) a CUDA kernel for a NVIDIA
GTX 960 Maxwell card. In these implementations, the main source of parallelism
is the simultaneous ADI updating of each wave field matrix, either column-wise
or row-wise, according to the differentiation direction. In our numerical
applications, the highest performances are displayed by the CFD and MFD CUDA
codes that achieve speedups of 7.21x and 15.81x, respectively, relative to
their C++ sequential counterparts with optimal compilation flags. Our test
cases also allow to assess the numerical convergence and accuracy of both
methods. In a problem with exact harmonic solution, both methods exhibit
convergence rates close to 4 and the MDF accuracy is practically higher.
Alternatively, both convergences decay to second order on smooth problems with
severe gradients at boundaries, and the MDF rates degrade in highly-resolved
grids leading to larger inaccuracies. This transition of empirical convergences
agrees with the nominal truncation errors in space and time.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 07:25:32 GMT""}]","2020-06-16"
"2006.07584","Zhiyun Lu","Zhiyun Lu, Eugene Ie, Fei Sha","Mean-Field Approximation to Gaussian-Softmax Integral with Application
  to Uncertainty Estimation",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many methods have been proposed to quantify the predictive uncertainty
associated with the outputs of deep neural networks. Among them, ensemble
methods often lead to state-of-the-art results, though they require
modifications to the training procedures and are computationally costly for
both training and inference. In this paper, we propose a new single-model based
approach. The main idea is inspired by the observation that we can ""simulate""
an ensemble of models by drawing from a Gaussian distribution, with a form
similar to those from the asymptotic normality theory, infinitesimal Jackknife,
Laplacian approximation to Bayesian neural networks, and trajectories in
stochastic gradient descents. However, instead of using each model in the
""ensemble"" to predict and then aggregating their predictions, we integrate the
Gaussian distribution and the softmax outputs of the neural networks. We use a
mean-field approximation formula to compute this analytically intractable
integral. The proposed approach has several appealing properties: it functions
as an ensemble without requiring multiple models, and it enables closed-form
approximate inference using only the first and second moments of the Gaussian.
Empirically, the proposed approach performs competitively when compared to
state-of-the-art methods, including deep ensembles, temperature scaling,
dropout and Bayesian NNs, on standard uncertainty estimation tasks. It also
outperforms many methods on out-of-distribution detection.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 07:32:38 GMT""},{""version"":""v2"",""created"":""Sun, 9 May 2021 05:31:11 GMT""}]","2021-05-11"
"2006.07585","Tao He","Tao He, Lianli Gao, Jingkuan Song, Jianfei Cai, Yuan-Fang Li","Learning from the Scene and Borrowing from the Rich: Tackling the Long
  Tail in Scene Graph Generation",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the huge progress in scene graph generation in recent years, its
long-tail distribution in object relationships remains a challenging and
pestering issue. Existing methods largely rely on either external knowledge or
statistical bias information to alleviate this problem. In this paper, we
tackle this issue from another two aspects: (1) scene-object interaction aiming
at learning specific knowledge from a scene via an additive attention
mechanism; and (2) long-tail knowledge transfer which tries to transfer the
rich knowledge learned from the head into the tail. Extensive experiments on
the benchmark dataset Visual Genome on three tasks demonstrate that our method
outperforms current state-of-the-art competitors.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 07:43:40 GMT""}]","2020-06-16"
"2006.07586","Carlos Alberto Plata Ramos","Carlos A. Plata, Emanuele Pigani, Sandro Azaele, Violeta
  Calleja-Solanas, Mar\'ia J. Palazzi, Albert Sol\'e-Ribalta, Sandro Meloni,
  Javier Borge-Holthoefer, Samir Suweis","Neutral Theory for competing attention in social networks",,"Phys. Rev. Research 3, 013070 (2021)","10.1103/PhysRevResearch.3.013070",,"physics.soc-ph cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We used an ecological approach based on a neutral model to study the
competition for attention in an online social network. This novel approach
allow us to analyze some ecological patterns that has also an insightful
meaning in the context of information ecosystem. Specifically, we focus on the
study of patterns related with the persistence of a meme within the network and
the capacity of the system to sustain coexisting memes. Not only are we able of
doing such analysis in an approximated continuum limit, but also we get exact
results of the finite-size discrete system.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:12:19 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 11:31:31 GMT""}]","2021-06-15"
"2006.07587","Man M. Ho","Man M. Ho, Lu Zhang, Alexander Raake, Jinjia Zhou","Semantic-driven Colorization","Code is available at
  https://minhmanho.github.io/semantic-driven_colorization/",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent colorization works implicitly predict the semantic information while
learning to colorize black-and-white images. Consequently, the generated color
is easier to be overflowed, and the semantic faults are invisible. As a human
experience in colorization, our brains first detect and recognize the objects
in the photo, then imagine their plausible colors based on many similar objects
we have seen in real life, and finally colorize them, as described in the
teaser. In this study, we simulate that human-like action to let our network
first learn to understand the photo, then colorize it. Thus, our work can
provide plausible colors at a semantic level. Plus, the semantic information of
the learned model becomes understandable and able to interact. Additionally, we
also prove that Instance Normalization is also a missing ingredient for
colorization, then re-design the inference flow of U-Net to have two streams of
data, providing an appropriate way of normalizing the feature maps from the
black-and-white image and its semantic map. As a result, our network can
provide plausible colors competitive to the typical colorization works for
specific objects.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:13:30 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 11:32:24 GMT""},{""version"":""v3"",""created"":""Sat, 14 Aug 2021 13:19:14 GMT""}]","2021-08-17"
"2006.07588","Ali Pourmiri","Catherine Greenhill, Bernard Mans, and Ali Pourmiri","Balanced Allocation on Hypergraphs",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a variation of balls-into-bins which randomly allocates $m$ balls
into $n$ bins. Following Godfrey's model (SODA, 2008), we assume that each ball
$t$, $1\le t\le m$, comes with a hypergraph
$\mathcal{H}^{(t)}=\{B_1,B_2,\ldots,B_{s_t}\}$, and each edge
$B\in\mathcal{H}^{(t)}$ contains at least a logarithmic number of bins. Given
$d\ge 2$, our $d$-choice algorithm chooses an edge $B\in \mathcal{H}^{(t)}$,
uniformly at random, and then chooses a set $D$ of $d$ random bins from the
selected edge $B$. The ball is allocated to a least-loaded bin from $D$, with
ties are broken randomly. We prove that if the hypergraphs
$\mathcal{H}^{(1)},\ldots, \mathcal{H}^{(m)}$ satisfy a \emph{balancedness}
condition and have low \emph{pair visibility}, then after allocating
$m=\Theta(n)$ balls, the maximum number of balls at any bin, called the
\emph{maximum load}, is at most $\log_d\log n+O(1)$, with high probability. The
balancedness condition enforces that bins appear almost uniformly within the
hyperedges of $\mathcal{H}^{(t)}$, $1\le t\le m$, while the pair visibility
condition measures how frequently a pair of bins is chosen during the
allocation of balls. Moreover, we establish a lower bound for the maximum load
attained by the balanced allocation for a sequence of hypergraphs in terms of
pair visibility, showing the relevance of the visibility parameter to the
maximum load. In Godfrey's model, each ball is forced to probe all bins in a
randomly selected hyperedge and the ball is then allocated in a least-loaded
bin. Godfrey showed that if each $\mathcal{H}^{(t)}$, $1\le t\le m$, is
balanced and $m=O(n)$, then the maximum load is at most one, with high
probability. However, we apply the power of $d$ choices paradigm, and only
query the load information of $d$ random bins per ball, while achieving very
slow growth in the maximum load.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:22:05 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 06:32:23 GMT""},{""version"":""v3"",""created"":""Sat, 3 Sep 2022 11:03:29 GMT""}]","2022-09-07"
"2006.07589","Minseon Kim","Minseon Kim, Jihoon Tack, Sung Ju Hwang","Adversarial Self-Supervised Contrastive Learning","NeurIPS 2020. Code: https://github.com/Kim-Minseon/RoCL",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing adversarial learning approaches mostly use class labels to generate
adversarial samples that lead to incorrect predictions, which are then used to
augment the training of the model for improved robustness. While some recent
works propose semi-supervised adversarial learning methods that utilize
unlabeled data, they still require class labels. However, do we really need
class labels at all, for adversarially robust training of deep neural networks?
In this paper, we propose a novel adversarial attack for unlabeled data, which
makes the model confuse the instance-level identities of the perturbed data
samples. Further, we present a self-supervised contrastive learning framework
to adversarially train a robust neural network without labeled data, which aims
to maximize the similarity between a random augmentation of a data sample and
its instance-wise adversarial perturbation. We validate our method, Robust
Contrastive Learning (RoCL), on multiple benchmark datasets, on which it
obtains comparable robust accuracy over state-of-the-art supervised adversarial
learning methods, and significantly improved robustness against the black box
and unseen types of attacks. Moreover, with further joint fine-tuning with
supervised adversarial loss, RoCL obtains even higher robust accuracy over
using self-supervised learning alone. Notably, RoCL also demonstrate impressive
results in robust transfer learning.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:24:33 GMT""},{""version"":""v2"",""created"":""Mon, 26 Oct 2020 14:04:48 GMT""}]","2020-10-27"
"2006.07590","Harshavardhan Kamarthi","Siddharth Nishtala, Harshavardhan Kamarthi, Divy Thakkar, Dhyanesh
  Narayanan, Anirudh Grama, Aparna Hegde, Ramesh Padmanabhan, Neha Madhiwalla,
  Suresh Chaudhary, Balaraman Ravindran, Milind Tambe","Missed calls, Automated Calls and Health Support: Using AI to improve
  maternal health outcomes by increasing program engagement",,,,,"cs.CY cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  India accounts for 11% of maternal deaths globally where a woman dies in
childbirth every fifteen minutes. Lack of access to preventive care information
is a significant problem contributing to high maternal morbidity and mortality
numbers, especially in low-income households. We work with ARMMAN, a non-profit
based in India, to further the use of call-based information programs by
early-on identifying women who might not engage on these programs that are
proven to affect health parameters positively.We analyzed anonymized
call-records of over 300,000 women registered in an awareness program created
by ARMMAN that uses cellphone calls to regularly disseminate health related
information. We built robust deep learning based models to predict short term
and long term dropout risk from call logs and beneficiaries' demographic
information. Our model performs 13% better than competitive baselines for
short-term forecasting and 7% better for long term forecasting. We also discuss
the applicability of this method in the real world through a pilot validation
that uses our method to perform targeted interventions.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:32:41 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 13:23:33 GMT""},{""version"":""v3"",""created"":""Mon, 6 Jul 2020 23:17:36 GMT""}]","2020-07-08"
"2006.07591","Marian Apostol","Bogdan Felix Apostol","Bath's law, correlations and magnitude distributions","20 pages, Figure",,,,"physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The empirical Bath's law is derived from the magnitude-difference statistical
distribution of earthquake pairs. The pair distribution related to earthquake
correlations is presented. The single-event distribution of dynamically
correlated earthquakes is derived, by means of the geometric-growth model of
energy accumulation in the focal region. The dynamical correlations may
account, at least partially, for the roll-off effect in the Gutenberg-Richter
distributions. The seismic activity which accompanies a main shock, including
both the aftershocks and the foreshocks, can be viewed as fluctuations in
magnitude. The extension of the magnitude difference to negative values leads
to a vanishing mean value of the fluctuations and to the standard deviation as
a measure of these fluctuations. It is suggested that the standard deviation of
the magnitude difference is the average difference in magnitude between the
main shock and its largest aftershock (foreshock), thus providing an insight
into the nature and the origin of the Bath's law. It is shown that
moderate-magnitude doublets may be viewed as Bath partners. Deterministic
time-magnitude correlations of the accompanying seismic activity are also
presented.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:37:41 GMT""}]","2020-06-16"
"2006.07592","Quan Zhao","Quan Zhao and Weiqing Ren","A Finite Element Method for Electrowetting on Dielectric",,,"10.1016/j.jcp.2020.109998",,"physics.comp-ph cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of electrowetting on dielectric (EWoD). The system
involves the dynamics of a conducting droplet, which is immersed in another
dielectric fluid, on a dielectric substrate under an applied voltage. The fluid
dynamics is modeled by the two-phase incompressible Navier-Stokes equations
with the standard interface conditions, the Navier slip condition on the
substrate, and a contact angle condition which relates the dynamic contact
angle and the contact line velocity, as well as the kinematic condition for the
evolution of the interface. The electric force acting on the fluid interface is
modeled by Maxwell's equations in the domain occupied by the dielectric fluid
and the dielectric substrate. We develop a numerical method for the model based
on its weak form. This method combines the finite element method for the
Navier-Stokes equations on a fixed bulk mesh with a parametric finite element
method for the dynamics of the fluid interface, and the boundary integral
method for the electric force along the fluid interface. Numerical examples are
presented to demonstrate the accuracy and convergence of the numerical method,
the effect of various physical parameters on the interface profile, and other
interesting phenomena such as the transportation of droplet driven by the
applied non-uniform electric potential difference.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:40:00 GMT""}]","2021-03-17"
"2006.07593","Vu Nguyen","Vu Nguyen and Tam Le and Makoto Yamada and Michael A Osborne","Optimal Transport Kernels for Sequential and Parallel Neural
  Architecture Search","23 pages, camera ready ICML2021",,,,"cs.LG cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural architecture search (NAS) automates the design of deep neural
networks. One of the main challenges in searching complex and non-continuous
architectures is to compare the similarity of networks that the conventional
Euclidean metric may fail to capture. Optimal transport (OT) is resilient to
such complex structure by considering the minimal cost for transporting a
network into another. However, the OT is generally not negative definite which
may limit its ability to build the positive-definite kernels required in many
kernel-dependent frameworks. Building upon tree-Wasserstein (TW), which is a
negative definite variant of OT, we develop a novel discrepancy for neural
architectures, and demonstrate it within a Gaussian process surrogate model for
the sequential NAS settings. Furthermore, we derive a novel parallel NAS, using
quality k-determinantal point process on the GP posterior, to select diverse
and high-performing architectures from a discrete set of candidates.
Empirically, we demonstrate that our TW-based approaches outperform other
baselines in both sequential and parallel NAS.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:44:41 GMT""},{""version"":""v2"",""created"":""Sat, 31 Oct 2020 21:39:48 GMT""},{""version"":""v3"",""created"":""Thu, 10 Jun 2021 06:55:22 GMT""}]","2021-06-11"
"2006.07594","Isha Mudahar Dr.","Amrish Sharma, Sandeep Kaur, Hitesh Sharma, Neha Kapila, V. K. Jindal,
  Vladimir Bubanja and Isha Mudahar","Effect of Twist Angle on Structural, Electronic and Magnetic Properties
  of Carbon Nano Hybrids: A DFT Study","Submitted to International Journal of Quantum Chemistry",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Density functional calculations of hybrids consisting of a single wall carbon
nanotube and a graphene nanoribbon have been performed. We consider the
dependence of the structural, electronic and magnetic properties of the hybrids
on the twist angle between their subunits. We calculated the binding energies,
pyramidalization angles, Mulliken charge, and HOMO-LUMO gaps as functions of
the twist angle. We find that, owing to the asymmetrical spin density
distributions of their subunits, the hybrids have finite magnetic moments.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:54:42 GMT""}]","2020-06-16"
"2006.07595","Liliya V. El'nikova","L.V. Elnikova, A.N. Ozerin, V.G. Shevchenko, P.M. Nedorezova, A.T.
  Ponomarenko, V.V. Skoi, A.I. Kuklin","Spatial structure and aggregation of carbon allotrope nanofillers in
  isotactic polypropylene composites studied by small-angle neutron scattering","20 pages, 13 figures",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the aggregation of carbon allotrope nanofillers in the matrix of
isotactic polypropylene with direct small-angle neutron scattering
measurements. With the ATSAS software, we analyzed the data and determined the
fractal shape, dimension, and sizes of nanofiller aggregation in the bulk of
isotactic polypropylene over the range of the scattering angles. We estimated
the volume distributions and aggregation of different types of carbon
nanofillers at different concentrations: nanographite, graphene nanoplatelets
(GNP), single-walled carbon nanotubes (SWCNT), multi-wall carbon nanotubes
(MWCNT), binary fillers MWCNT/GNP and fullerenes. We reconstructed the shape of
nanoscale aggregates of all nanofillers and found that the systems are
polydisperse; nanofillers associate in the volume of iPP as fractal dense
aggregates with rugged surface, their sizes exceeding original dimensions of
nanofillers several times.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:56:47 GMT""}]","2020-06-16"
"2006.07596","Shulin Lyu","Shulin Lyu and Yang Chen","Gaussian unitary ensemble with two jump discontinuities, PDEs and the
  coupled Painlev\'{e} II and IV systems","21 pages",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Hankel determinant generated by the Gaussian weight with two
jump discontinuities. Utilizing the results of [C. Min and Y. Chen, Math. Meth.
Appl. Sci. {\bf 42} (2019), 301--321] where a second order PDE was deduced for
the log derivative of the Hankel determinant by using the ladder operators
adapted to orthogonal polynomials, we derive the coupled Painlev\'{e} IV system
which was established in [X. Wu and S. Xu, arXiv: 2002.11240v2] by a study of
the Riemann-Hilbert problem for orthogonal polynomials. Under double scaling,
we show that, as $n\rightarrow\infty$, the log derivative of the Hankel
determinant in the scaled variables tends to the Hamiltonian of a coupled
Painlev\'{e} II system and it satisfies a second order PDE. In addition, we
obtain the asymptotics for the recurrence coefficients of orthogonal
polynomials, which are connected with the solutions of the coupled Painlev\'{e}
II system.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 09:13:30 GMT""}]","2020-06-16"
"2006.07597","Zhiyuan Chen","Zhiyuan Chen, Annan Li, Shilu Jiang, Yunhong Wang","Attribute-aware Identity-hard Triplet Loss for Video-based Person
  Re-identification",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video-based person re-identification (Re-ID) is an important computer vision
task. The batch-hard triplet loss frequently used in video-based person Re-ID
suffers from the Distance Variance among Different Positives (DVDP) problem. In
this paper, we address this issue by introducing a new metric learning method
called Attribute-aware Identity-hard Triplet Loss (AITL), which reduces the
intra-class variation among positive samples via calculating attribute
distance. To achieve a complete model of video-based person Re-ID, a multi-task
framework with Attribute-driven Spatio-Temporal Attention (ASTA) mechanism is
also proposed. Extensive experiments on MARS and DukeMTMC-VID datasets shows
that both the AITL and ASTA are very effective. Enhanced by them, even a simple
light-weighted video-based person Re-ID baseline can outperform existing
state-of-the-art approaches. The codes has been published on
https://github.com/yuange250/Video-based-person-ReID-with-Attribute-information.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 09:15:38 GMT""}]","2020-06-16"
"2006.07598","Jan-Willem van Wingerden","J. W. van Wingerden, P. A. Fleming, T. G\""o\c{c}men, I. Eguinoa, B. M.
  Doekemeijer, K. Dykes, M. Lawson, E. Simley, J. King, D. Astrain, M. Iribas,
  C. L. Bottasso, J. Meyers, S. Raach, K. K\""olle, G. Giebel","Expert Elicitation on Wind Farm Control",,,"10.1088/1742-6596/1618/2/022025",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wind farm control is an active and growing field of research in which the
control actions of individual turbines in a farm are coordinated, accounting
for inter-turbine aerodynamic interaction, to improve the overall performance
of the wind farm and to reduce costs. The primary objectives of wind farm
control include increasing power production, reducing turbine loads, and
providing electricity grid support services. Additional objectives include
improving reliability or reducing external impacts to the environment and
communities. In 2019, a European research project (FarmConners) was started
with the main goal of providing an overview of the state-of-the-art in wind
farm control, identifying consensus of research findings, data sets, and best
practices, providing a summary of the main research challenges, and
establishing a roadmap on how to address these challenges. Complementary to the
FarmConners project, an IEA Wind Topical Expert Meeting (TEM) and two rounds of
surveys among experts were performed. From these events we can clearly identify
an interest in more public validation campaigns. Additionally, a deeper
understanding of the mechanical loads and the uncertainties concerning the
effectiveness of wind farm control are considered two major research gaps.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 09:29:00 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 11:55:05 GMT""}]","2020-12-30"
"2006.07599","Richard Paris","M. Ali, M. Ghayasuddin and R.B. Paris","Generalized Beta-type integral operators","9 pages, 0 figures",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This research note deals with the evaluation of some generalized beta-type
integral operators involving the multi-index Mittag-Leffler function
$E_{\epsilon_{i}),(\omega_{i})}(z)$. Further, we derive a new family of
beta-type integrals involving the product of a multi-index Mittag-Leffler
function and a generating function of two variables. Some concluding remarks
regarding our present investigation are briefly discussed in the last section.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 09:50:20 GMT""}]","2020-06-16"
"2006.07600","Jos\'e Luis Bravo Trinidad","A. \'Alvarez, J.L. Bravo, C. Christopher, P. Marde\v{s}i\'c","Infinitesimal Center Problem on zero cycles and the composition
  conjecture","14 pages, 1 figure",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the analogue of the classical infinitesimal center problem in the
plane, but for zero cycles. We define the displacement function in this context
and prove that it is identically zero if and only if the deformation has a
composition factor. That is, we prove that here the composition conjecture is
true, in contrast with the tangential center problem on zero cycles. Finally,
we give examples of applications of our results.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 09:54:27 GMT""}]","2020-06-16"
"2006.07601","Mariia Dobko","Mariia Dobko, Ostap Viniavskyi, Oles Dobosevych","NoPeopleAllowed: The Three-Step Approach to Weakly Supervised Semantic
  Segmentation","This short-paper was submitted to Learning from Imperfect Data
  workshop at CVPR 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel approach to weakly supervised semantic segmentation, which
consists of three consecutive steps. The first two steps extract high-quality
pseudo masks from image-level annotated data, which are then used to train a
segmentation model on the third step. The presented approach also addresses two
problems in the data: class imbalance and missing labels. Using only
image-level annotations as supervision, our method is capable of segmenting
various classes and complex objects. It achieves 37.34 mean IoU on the test
set, placing 3rd at the LID Challenge in the task of weakly supervised semantic
segmentation.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 09:56:18 GMT""}]","2020-06-16"
"2006.07602","Maryam Soleymaninia","Mahdi Delpasand, S. Mohammad Moosavi Nejad and Maryam Soleymaninia","$\Lambda_c^+$ fragmentation functions from pQCD approach and the Suzuki
  model","13 pages, 7 figures and 2 Tables, Accepted for publication in
  physical Review D","Phys. Rev. D 101, 114022 (2020)","10.1103/PhysRevD.101.114022",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Through data analysis, we present new sets of nonperturbative fragmentation
functions (FFs) for $\Lambda_c^+$ baryon both at leading and next-to-leading
order (NLO) and, for the first time, at next-to-next-to-leading order (NNLO) in
the minimal subtraction factorization scheme with five massless quarks. The FFs
are determined by fitting all available data of inclusive single $\Lambda_c^+$
baryon production in $e^+e^-$ annihilation taken by the OPAL Collaboration at
CERN LEP1 and Belle Collaboration at KEKB. We also estimate the uncertainties
in the $\Lambda_c^+$ FFs as well as in the corresponding observables. In a
completely different approach based on the Suzuki model, we will theoretically
calculate the $\Lambda_c^+$ FF from charm quark and present our result at
leading order perturbative QCD framework. A comparison confirms a good
consistency between both approaches. We will also apply the $\Lambda_c^+$ FFs
to make theoretical predictions for the energy distribution of $\Lambda_c^+$
produced through the top quark decay, to be measured at the CERN LHC.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:02:29 GMT""}]","2020-07-01"
"2006.07603","Shenghao Yang","Yanyan Dong and Shenghao Yang","On Optimal Finite-length Binary Codes of Four Codewords for Binary
  Symmetric Channels","accepted by ISITA 2020",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finite-length binary codes of four codewords are studied for memoryless
binary symmetric channels (BSCs) with the maximum likelihood decoding. For any
block-length, best linear codes of four codewords have been explicitly
characterized, but whether linear codes are better than nonlinear codes or not
is unknown in general. In this paper, we show that for any block-length, there
exists an optimal code of four codewords that is either linear or in a subset
of nonlinear codes, called Class-I codes. Based on the analysis of Class-I
codes, we derive sufficient conditions such that linear codes are optimal. For
block-length less than or equal to 8, our analytical results show that linear
codes are optimal. For block-length up to 300, numerical evaluations show that
linear codes are optimal.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:03:13 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 04:27:17 GMT""}]","2020-07-07"
"2006.07604","Cheng Zhang","Cheng Zhang","Dynamic gesture retrieval: searching videos by human pose sequence","The problem proposed in this article should be classified as ""gesture
  retrieval"" or ""gesture detection"", and there are already better algorithms to
  deal with the proposed problem, for example Dynamic Time Warping (DTW) based
  methods. The solution in this work gives little contribution to the field, so
  I decided to withdraw it",,,,"cs.CV cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The number of static human poses is limited, it is hard to retrieve the exact
videos using one single pose as the clue. However, with a pose sequence or a
dynamic gesture as the keyword, retrieving specific videos becomes more
feasible. We propose a novel method for querying videos containing a designated
sequence of human poses, whereas previous works only designate a single static
pose. The proposed method takes continuous 3d human poses from keyword gesture
video and video candidates, then converts each pose in individual frames into
bone direction descriptors, which describe the direction of each natural
connection in articulated pose. A temporal pyramid sliding window is then
applied to find matches between designated gesture and video candidates, which
ensures that same gestures with different duration can be matched.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:11:22 GMT""},{""version"":""v2"",""created"":""Tue, 27 Apr 2021 03:53:15 GMT""}]","2021-04-28"
"2006.07605","Amilcar Bedoya-Pinto","Amilcar Bedoya-Pinto, Jing-Rong Ji, Avanindra Pandeya, Pierluigi
  Gargiani, Manuel Valvidares, Paolo Sessi, Florin Radu, Kai Chang and Stuart
  Parkin","Intrinsic 2D-XY ferromagnetism in a van der Waals monolayer",,"Science, Vol 374, Issue 6567, pp. 616-620 (2021)","10.1126/science.abd5146",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Long before the recent fascination with two-dimensional materials, the
critical behaviour and universality scaling of phase transitions in
low-dimensional systems has been a topic of great interest. Particularly
intriguing is the case of long-range magnetic order in two dimensions, once
considered to be excluded in systems with continuous symmetry by the
Hohenberg-Mermin-Wagner theorem. While an out-of-plane anisotropy has been
shown to stabilize 2D magnetic order, this proof has remained elusive for a 2D
magnet with in-plane rotational symmetry. Here, we construct a nearly ideal
easy-plane system, a CrCl3 monolayer grown on Graphene/6H-SiC (0001), and
unambiguously demonstrate robust in-plane ferromagnetic ordering with a
critical scaling behaviour characteristic of a 2D-XY system. These observations
suggest the first realization of a finite-size Berezinskii-Kosterlitz-Thouless
(BKT) phase transition in a large-area, quasi-freestanding, van der Waals
monolayer magnet with a XY universality class; and further constitute an ideal
platform to study exotic phenomena like superfluid spin transport or 2D
topological in-plane spin textures -- such as merons.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:21:59 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 17:07:38 GMT""}]","2021-12-21"
"2006.07606","Tianren Wang","Tianren Wang, Teng Zhang, Brian Lovell","Faces \`a la Carte: Text-to-Face Generation via Attribute
  Disentanglement","8 pages, 4 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text-to-Face (TTF) synthesis is a challenging task with great potential for
diverse computer vision applications. Compared to Text-to-Image (TTI) synthesis
tasks, the textual description of faces can be much more complicated and
detailed due to the variety of facial attributes and the parsing of high
dimensional abstract natural language. In this paper, we propose a Text-to-Face
model that not only produces images in high resolution (1024x1024) with
text-to-image consistency, but also outputs multiple diverse faces to cover a
wide range of unspecified facial features in a natural way. By fine-tuning the
multi-label classifier and image encoder, our model obtains the vectors and
image embeddings which are used to transform the input noise vector sampled
from the normal distribution. Afterwards, the transformed noise vector is fed
into a pre-trained high-resolution image generator to produce a set of faces
with the desired facial attributes. We refer to our model as TTF-HD.
Experimental results show that TTF-HD generates high-quality faces with
state-of-the-art performance.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:24:31 GMT""},{""version"":""v2"",""created"":""Fri, 18 Sep 2020 07:21:45 GMT""}]","2020-09-21"
"2006.07607","Ziming Liu","Ziming Liu and Guangyu Gao and Lin Sun and Zhiyuan Fang","HRDNet: High-resolution Detection Network for Small Objects",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Small object detection is challenging because small objects do not contain
detailed information and may even disappear in the deep network. Usually,
feeding high-resolution images into a network can alleviate this issue.
However, simply enlarging the resolution will cause more problems, such as
that, it aggravates the large variant of object scale and introduces unbearable
computation cost. To keep the benefits of high-resolution images without
bringing up new problems, we proposed the High-Resolution Detection Network
(HRDNet). HRDNet takes multiple resolution inputs using multi-depth backbones.
To fully take advantage of multiple features, we proposed Multi-Depth Image
Pyramid Network (MD-IPN) and Multi-Scale Feature Pyramid Network (MS-FPN) in
HRDNet. MD-IPN maintains multiple position information using multiple depth
backbones. Specifically, high-resolution input will be fed into a shallow
network to reserve more positional information and reducing the computational
cost while low-resolution input will be fed into a deep network to extract more
semantics. By extracting various features from high to low resolutions, the
MD-IPN is able to improve the performance of small object detection as well as
maintaining the performance of middle and large objects. MS-FPN is proposed to
align and fuse multi-scale feature groups generated by MD-IPN to reduce the
information imbalance between these multi-scale multi-level features. Extensive
experiments and ablation studies are conducted on the standard benchmark
dataset MS COCO2017, Pascal VOC2007/2012 and a typical small object dataset,
VisDrone 2019. Notably, our proposed HRDNet achieves the state-of-the-art on
these datasets and it performs better on small objects.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:25:35 GMT""}]","2020-06-16"
"2006.07608","Maria Alessandra Ragusa Full Professor","M. I. Abbas, M.A. Ragusa","Solvability of Langevin equations with two Hadamard fractional
  derivatives via Mittag-Leffler functions",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we discuss the solvability of Langevin equations with two
Hadamard fractional derivatives. The method of this discussion is to study the
solutions of the equivalent Volterra integral equation in terms of Mittag-
Leffler functions. The existence and uniqueness results are established by
using Schauder fixed point theorem and Banach fixed point theorem respectively.
An example is given to illustrate the main results.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:28:55 GMT""}]","2020-06-16"
"2006.07609","Ziming Liu","Ziming Liu and Guangyu Gao and A. K. Qin and Jinyang Li","DTG-Net: Differentiated Teachers Guided Self-Supervised Video Action
  Recognition",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State-of-the-art video action recognition models with complex network
architecture have archived significant improvements, but these models heavily
depend on large-scale well-labeled datasets. To reduce such dependency, we
propose a self-supervised teacher-student architecture, i.e., the
Differentiated Teachers Guided self-supervised Network (DTG-Net). In DTG-Net,
except for reducing labeled data dependency by self-supervised learning (SSL),
pre-trained action related models are used as teacher guidance providing prior
knowledge to alleviate the demand for a large number of unlabeled videos in
SSL. Specifically, leveraging the years of effort in action-related tasks,
e.g., image classification, image-based action recognition, the DTG-Net learns
the self-supervised video representation under various teacher guidance, i.e.,
those well-trained models of action-related tasks. Meanwhile, the DTG-Net is
optimized in the way of contrastive self-supervised learning. When two image
sequences are randomly sampled from the same video or different videos as the
positive or negative pairs, respectively, they are then sent to the teacher and
student networks for feature embedding. After that, the contrastive feature
consistency is defined between features embedding of each pair, i.e.,
consistent for positive pair and inconsistent for negative pairs. Meanwhile, to
reflect various teacher tasks' different guidance, we also explore different
weighted guidance on teacher tasks. Finally, the DTG-Net is evaluated in two
ways: (i) the self-supervised DTG-Net to pre-train the supervised action
recognition models with only unlabeled videos; (ii) the supervised DTG-Net to
be jointly trained with the supervised action networks in an end-to-end way.
Its performance is better than most pre-training methods but also has excellent
competitiveness compared to supervised action recognition methods.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:40:31 GMT""}]","2020-06-16"
"2006.07610","Serhii Favorov","S.Yu.Favorov","Uniqueness Theorems for Fourier Quasicrystals and Temperate
  Distributions with Discrete Support","9 pages 15 references",,,,"math.FA math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  It is proved that if some points of the supports of two Fourier quasicrystals
approach each other while tending to infinity and the same is true for the
masses at these points, then these quasicrystals coincide. A similar statement
is obtained for a certain class of discrete temperate distributions.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:42:01 GMT""},{""version"":""v2"",""created"":""Sun, 21 Feb 2021 18:55:10 GMT""}]","2021-02-23"
"2006.07611","Jieyuan Cui","Jieyuan Cui, Yang Liu, Yunzhou Deng, Chen Lin, Zhishan Fang, Chensheng
  Xiang, Peng Bai, Kai Du, Xiaobing Zuo, Kaichuan Wen, Shaolong Gong, Haiping
  He, Zhizhen Ye, Yunan Gao, He Tian, Baodan Zhao, Jianpu Wang and Yizheng Jin","Efficient light-emitting diodes based on oriented perovskite
  nanoplatelets","52 pages, 23 figures",,,,"physics.app-ph cond-mat.mtrl-sci physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solution-processed planar perovskite light-emitting diodes (LEDs) promise
high-performance and cost-effective electroluminescent (EL) devices ideal for
large-area display and lighting applications. Exploiting emission layers with
high ratios of horizontal transition dipole moments (TDMs) is expected to boost
photon outcoupling of planar LEDs. However, LEDs based on anisotropic
perovskite nanoemitters remains to be inefficient (external quantum efficiency,
EQE <5%), due to the difficulties of simultaneously controlling the
orientations of TDMs, achieving high photoluminescence quantum yields (PLQYs)
and realizing charge balance in the films of the assembled nanostructures. Here
we demonstrate efficient EL from an in-situ grown continuous perovskite film
comprising of a monolayer of face-on oriented nanoplatelets. The ratio of
horizontal TDMs of the perovskite nanoplatelet films is ~84%, substantially
higher than that of isotropic emitters (67%). The nanoplatelet film shows a
high PLQY of ~75%. These merits enable LEDs with a peak EQE of 23.6%,
representing the most efficient perovskite LEDs.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:42:18 GMT""},{""version"":""v2"",""created"":""Thu, 23 Sep 2021 01:41:19 GMT""}]","2021-09-24"
"2006.07612","Yu Fu","Yu Fu, Min-Chun Hong, Xin Zhan","On Chen's biharmonic conjecture for hypersurfaces in $\mathbb R^5$","23 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A longstanding conjecture on biharmonic submanifolds, proposed by Chen in
1991, is that {\it any biharmonic submanifold in a Euclidean space is minimal}.
In the case of a hypersurface $M^n$ in $\mathbb R^{n+1}$, Chen's conjecture was
settled in the case of $n=2$ by Chen and Jiang around 1987 independently.
Hasanis and Vlachos in 1995 settled Chen's conjecture for a hypersurface with
$n=3$. However, the general Chen's conjecture on a hypersurface $M^n$ remains
open for $n> 3$. In this paper, we settle Chen's conjecture for hypersurfaces
in $\mathbb R^{5}$ for $n=4$.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:49:45 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 04:30:34 GMT""},{""version"":""v3"",""created"":""Wed, 22 Jul 2020 04:59:56 GMT""}]","2020-07-23"
"2006.07613","Abhibhav Garg","Abhibhav Garg, Nitin Saxena","Special-case Algorithms for Blackbox Radical Membership, Nullstellensatz
  and Transcendence Degree",,,,,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radical membership testing, and the special case of Hilbert's Nullstellensatz
(HN), is a fundamental computational algebra problem. It is NP-hard; and has a
famous PSPACE algorithm due to effective Nullstellensatz bounds. We identify a
useful case of these problems where practical algorithms, and improved bounds,
could be given, when the transcendence degree $r$ of the input polynomials is
smaller than the number of variables $n$. If $d$ is the degree bound on the
input polynomials, then we solve radical membership (even if input polynomials
are blackboxes) in around $d^r$ time. The prior best was $> d^n$ time (always,
$d^n\ge d^r$). Also, we significantly improve effective Nullstellensatz
degree-bound, when $r\ll n$. Structurally, our proof shows that these problems
reduce to the case of $r+1$ polynomials of transcendence degree $\ge r$. This
input instance (corresponding to none or a unique annihilator) is at the core
of HN's hardness. Our proof methods invoke basic algebraic-geometry.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:50:04 GMT""}]","2020-06-16"
"2006.07614","D\'ora Tarczay-Neh\'ez","T. Szklen\'ar, A. B\'odi, D. Tarczay-Neh\'ez, K. Vida, G. Marton, Gy.
  Mez\H{o}, A. Forr\'o, R. Szab\'o","Image-based Classification of Variable Stars: First Results from Optical
  Gravitational Lensing Experiment Data","Accepted in ApJL, 11pages, 5 figures, 8 tables",,"10.3847/2041-8213/ab9ca4",,"astro-ph.SR astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, machine learning methods presented a viable solution for automated
classification of image-based data in various research fields and business
applications. Scientists require a fast and reliable solution to be able to
handle the always growing enormous amount of data in astronomy. However, so far
astronomers have been mainly classifying variable star light curves based on
various pre-computed statistics and light curve parameters. In this work we use
an image-based Convolutional Neural Network to classify the different types of
variable stars. We used images of phase-folded light curves from the OGLE-III
survey for training, validating and testing and used OGLE-IV survey as an
independent data set for testing. After the training phase, our neural network
was able to classify the different types between 80 and 99%, and 77-98%
accuracy for OGLE-III and OGLE-IV, respectively.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:51:42 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 10:01:59 GMT""},{""version"":""v3"",""created"":""Sun, 5 Jul 2020 11:04:46 GMT""}]","2020-07-07"
"2006.07615","Iwo Bialynicki-Birula","Iwo Bialynicki-Birula and Zofia Bialynicka-Birula","Comment on ""Nondispersive analytical solutions to the Dirac equation""","Critical comment 2 figures In this version Eq.(1) is corrected",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In our Comment we question the validity of the claim made by the authors of
\cite{cc} that their solutions of the Dirac equation in an external {\em
time-dependent} electromagnetic field describe beams of electrons. In every
time-dependent field, no matter how weak, which has {\em infinite} time
duration, there is a continuous electron-positron pair creation and
annihilation. Without the proper accounting for these processes, the
mathematical solutions of the Dirac equation are not directly applicable to
realistic physical situations. In particular, the time evolution of the average
values $\langle x\rangle$ and $\langle y\rangle$ does not describe the electron
trajectory but the motion of some combination of the electron and positron
charge distributions with pathological properties (zitterbewegung).
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 10:58:02 GMT""},{""version"":""v2"",""created"":""Sun, 21 Jun 2020 13:53:22 GMT""},{""version"":""v3"",""created"":""Thu, 25 Jun 2020 15:18:44 GMT""}]","2020-06-26"
"2006.07616","Sayyed-Ahmad Naghavi-Nozad","Sayyed Ahmad Naghavi Nozad and Maryam Amir Haeri and Gianluigi Folino","SDCOR: Scalable Density-based Clustering for Local Outlier Detection in
  Massive-Scale Datasets","Highlights are shortened each to about 85 characters","Nozad, Sayyed Ahmad Naghavi, Maryam Amir Haeri, and Gianluigi
  Folino. ""SDCOR: Scalable density-based clustering for local outlier detection
  in massive-scale datasets."" Knowledge-Based Systems (2021): 107256","10.1016/j.knosys.2021.107256",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a batch-wise density-based clustering approach for local
outlier detection in massive-scale datasets. Unlike the well-known traditional
algorithms, which assume that all the data is memory-resident, our proposed
method is scalable and processes the input data chunk-by-chunk within the
confines of a limited memory buffer. A temporary clustering model is built at
the first phase; then, it is gradually updated by analyzing consecutive memory
loads of points. Subsequently, at the end of scalable clustering, the
approximate structure of the original clusters is obtained. Finally, by another
scan of the entire dataset and using a suitable criterion, an outlying score is
assigned to each object called SDCOR (Scalable Density-based Clustering
Outlierness Ratio). Evaluations on real-life and synthetic datasets demonstrate
that the proposed method has a low linear time complexity and is more effective
and efficient compared to best-known conventional density-based methods, which
need to load all data into the memory; and also, to some fast distance-based
methods, which can perform on data resident in the disk.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 11:07:37 GMT""},{""version"":""v10"",""created"":""Mon, 21 Jun 2021 21:09:07 GMT""},{""version"":""v11"",""created"":""Mon, 5 Jul 2021 15:02:24 GMT""},{""version"":""v2"",""created"":""Sat, 27 Jun 2020 05:32:54 GMT""},{""version"":""v3"",""created"":""Thu, 24 Sep 2020 08:35:06 GMT""},{""version"":""v4"",""created"":""Sun, 27 Sep 2020 11:12:12 GMT""},{""version"":""v5"",""created"":""Fri, 9 Oct 2020 08:10:24 GMT""},{""version"":""v6"",""created"":""Mon, 26 Oct 2020 19:22:13 GMT""},{""version"":""v7"",""created"":""Sat, 27 Mar 2021 08:51:34 GMT""},{""version"":""v8"",""created"":""Mon, 12 Apr 2021 17:56:44 GMT""},{""version"":""v9"",""created"":""Mon, 26 Apr 2021 11:50:30 GMT""}]","2021-07-06"
"2006.07617","Hisato Komatsu","Hisato Komatsu","A model of magnetic friction with the infinite-range interaction","10 pages, 7 figures; accepted for publication in Phys. Rev. E","Phys. Rev. E 102, 062131 (2020)","10.1103/PhysRevE.102.062131",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate a model of magnetic friction with the infinite-range
interaction by mean field analysis and a numerical simulation, and compare its
behavior with that of the short-range model that we considered previously
[H.~Komatsu, Phys.\ Rev.\ E.\ \textbf{100}, 052130 (2019)]. This infinite-range
model always obeys the Stokes law when the temperature is higher than the
critical value, $T_c$, whereas it shows a crossover or transition from the
Dieterich--Ruina law to the Stokes law when the temperature is lower than
$T_c$. Considering that the short-range model in our previous study shows a
crossover or transition irrespective of whether the temperature is above or
below the equilibrium transition temperature, the behavior in the
high-temperature state is the major difference between these two models.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 11:10:26 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 04:13:08 GMT""}]","2021-01-04"
"2006.07618","Ali AlSoufi Dr.","Abdulkarim Katbi, Jaflah AlAmmari, Ali AlSoufi","The Demand Side of Open Government Data: A Case Study of Kingdom of
  Bahrain","18 pages, 6 figures, 7 tables, Journal","International Journal of Managing Information Technology (IJMIT),
  VOlume 12, Number 2, May 2020","10.5121/ijmit.2020.12203",,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Governments around the world have realized the importance of Open Government
Data (OGD) as a new paradigm shift in government that focuses on making
governments more service-oriented, transparent, and competent. However, as with
many countries, the situation of the OGD initiative in the Kingdom of Bahrain
is not promising as reflected by a number of assessments that measure the
implementation and progress of OGD worldwide. The current research aims at
investing in the local situation regarding consuming and reusing OGD in the
Kingdom of Bahrain. Specifically, this research assesses the level of citizen
awareness towards OGD, determines citizens requirements of OGD, and identifies
the key challenges and obstacles in using/reusing OGD. A questionnaire was
developed to investigate the demand side of OGD. The findings show that serious
and responsible efforts from the publishers of OGD, namely: Government
Organizations are believed to be a necessity in order to progress the
implementation process of the OGD initiative in the Kingdom of Bahrain.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 11:15:50 GMT""}]","2020-06-16"
"2006.07619","Kieran Leschinski","Kieran Leschinski (1), Jo\~ao Alves (1) ((1) Department of
  Astropyhsics, University of Vienna, Austria)","The Future of IMF studies with the ELT and MICADO I: The local Universe
  as a resolved IMF laboratory","13 pages, 8 figures, 3 tables","A&A 639, A120 (2020)","10.1051/0004-6361/202038145",,"astro-ph.GA astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aims. In this work we aim to estimate the lowest stellar mass that MICADO at
the ELT will be able to reliably detect given a stellar density and distance.
We also show that instrumental effects that will play a critical role, and
report the number of young clusters that will be accessible for IMF studies in
the local Universe with the ELT.
  Methods. We used SimCADO, the instrument simulator package for the MICADO
camera, to generate observations of 56 dense stellar regions with densities
similar to the cores of young stellar clusters. We placed the cluster fields at
distances between 8 kpc and 5 Mpc from the Earth, implying core densities from
10^2 to 10^5 stars arcsec^-2, and determined the lowest reliably observable
mass for each stellar field through point-spread function (PSF) fitting
photometry.
  Results. Our results show that stellar densities of <10^3 stars arcsec^-2
will be easily resolvable by MICADO. The lowest reliably observable mass in the
Large Magellanic Cloud will be around 0.1 Msun for clusters with densities
<10^3 stars arcsec^-2. MICADO will be able to access the stellar content of the
cores of all dense young stellar clusters in the Magellanic Clouds, allowing
the peak and shape of the IMF to be studied in great detail outside the Milky
Way. At a distance of 2 Mpc, all stars with M > 2 Msun will be resolved in
fields of <10^4 stars arcsec^-2 , allowing the high-mass end of the IMF to be
studied in all galaxies out to and including NGC300.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 11:24:14 GMT""}]","2020-07-22"
"2006.07620","Helmer Koppelman","Helmer H. Koppelman, Roy O.Y. Bos, Amina Helmi","A massive mess: When a large dwarf and a Milky Way-like galaxy merge","6 pages, 5 figures, submitted. Movie of Fig.4 available at
  https://www.astro.rug.nl/~ahelmi/MassiveMess/","A&A 642, L18 (2020)","10.1051/0004-6361/202038652",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Circa 10 billion years ago the Milky Way merged with a massive satellite,
Gaia-Enceladus. To gain insight into the properties of its debris we analyse in
detail the suite of simulations from Villalobos & Helmi (2008), which includes
an experiment that produces a good match to the kinematics of nearby halo stars
inferred from Gaia data. We compare the kinematic distributions of stellar
particles in the simulations and study the distribution of debris in orbital
angular momentum, eccentricity and energy, and its relation to the mass-loss
history of the simulated satellite. We confirm that Gaia-Enceladus probably
fell in on a retrograde, 30$^\circ$ inclination orbit. We find that while 75%
of the debris in our preferred simulation has large eccentricity ($> 0.8$),
roughly 9% has eccentricity smaller than 0.6. Star particles lost early have
large retrograde motions, and a subset of these have low eccentricity. Such
stars would be expected to have lower metallicities as they stem from the
outskirts of the satellite, and hence naively they could be confused with
debris associated with a separate system. These considerations seem to apply to
some of the stars from the postulated Sequoia galaxy. When a massive discy
galaxy merges, it leaves behind debris with a complex phase-space structure, a
large range of orbital properties, and a range of chemical abundances.
Observationally, this results in substructures with very different properties,
which can be misinterpreted as implying independent progeny. Detailed chemical
abundances of large samples of stars and tailored hydrodynamical simulations
are critical to resolving such conundrums.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 11:27:04 GMT""}]","2020-10-28"
"2006.07621","Janusz Grabowski","Katarzyna Grabowska, Janusz Grabowski, Marek Kus and Giuseppe Marmo","Information geometry on groupoids: the case of singular metrics","15 pages",,"10.1142/S1230161220500158",,"math.DG cs.IT math-ph math.IT math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use the general setting for contrast (potential) functions in statistical
and information geometry provided by Lie groupoids and Lie algebroids. The
contrast functions are defined on Lie groupoids and give rise to two-forms and
three-forms on the corresponding Lie algebroid. We study the case when the
two-form is degenerate and show how in sufficiently regular cases one reduces
it to a pseudometric structures. Transversal Levi-Civita connections for
Riemannian foliations are generalized to the Lie groupoid/Lie algebroid case.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 11:28:26 GMT""}]","2021-02-03"
"2006.07622","Yu Zhang","Qiao Xiao and Yu Zhang","Distant Transfer Learning via Deep Random Walk",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transfer learning, which is to improve the learning performance in the target
domain by leveraging useful knowledge from the source domain, often requires
that those two domains are very close, which limits its application scope.
Recently, distant transfer learning has been studied to transfer knowledge
between two distant or even totally unrelated domains via auxiliary domains
that are usually unlabeled as a bridge in the spirit of human transitive
inference that it is possible to connect two completely unrelated concepts
together through gradual knowledge transfer. In this paper, we study distant
transfer learning by proposing a DeEp Random Walk basEd distaNt Transfer
(DERWENT) method. Different from existing distant transfer learning models that
implicitly identify the path of knowledge transfer between the source and
target instances through auxiliary instances, the proposed DERWENT model can
explicitly learn such paths via the deep random walk technique. Specifically,
based on sequences identified by the random walk technique on a data graph
where source and target data have no direct edges, the proposed DERWENT model
enforces adjacent data points in a squence to be similar, makes the ending data
point be represented by other data points in the same sequence, and considers
weighted training losses of source data. Empirical studies on several benchmark
datasets demonstrate that the proposed DERWENT algorithm yields the
state-of-the-art performance.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 11:31:24 GMT""}]","2020-06-16"
"2006.07623","C. S. Rajan","Plawan Das and C. S. Rajan","A uniform bound for inertially equivalent, pure $\ell$-adic
  representations: an extension of Faltings' theorem","The proof of the main theorem contains a gap, and cannot be fixed",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a notion of inertial equivalence for integral $\ell$-adic
representation of the Galois group of a global field. We show that the
collection of continuous, semisimple, pure $\ell$-adic representations of the
absolute Galois group of a global field lifting a fixed absolutely irreducible
residual representation and with given inertial type outside a fixed finite set
of places is uniformly bounded independent of the inertial type.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 11:33:20 GMT""},{""version"":""v2"",""created"":""Mon, 10 Aug 2020 11:36:45 GMT""},{""version"":""v3"",""created"":""Fri, 12 Mar 2021 08:22:10 GMT""},{""version"":""v4"",""created"":""Wed, 9 Jun 2021 11:25:00 GMT""}]","2021-06-10"
"2006.07624","Davide Giraudo","Herold Dehling, Davide Giraudo, Olimjon Sharipov","Convergence of the empirical two-sample $U$-statistics with
  $\beta$-mixing data",,,,,"math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the empirical two-sample $U$-statistic with strictly
$\beta$-mixing strictly stationary data and inverstigate its convergence in
Skorohod spaces. We then provide an application of such convergence.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 11:52:44 GMT""}]","2020-06-16"
"2006.07625","Zhou Rui","Ya-Qian Li, Meng-Kun Jia, Zhou Rui","Revisiting nonfactorizable contributions to factorization-forbidden
  decays of $B$ mesons to charmonium","11 pages, 1 figure, 4 tables","Chinese Physics C 44, No. 11 (2020) 113104","10.1088/1674-1137/abae50",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the large rates of $B\rightarrow (\chi_{c0}, \chi_{c2}, h_c)K$
decays observed by the $BABAR$ and Belle collaborations, we investigate the
nonfactorizable contributions to these factorization-forbidden decays, which
can occur through a gluon exchange between the $c\bar c$ system and the
spectator quark. Our numerical results demonstrate that the spectator
contributions are capable of producing a large branching ratio consistent with
the experiments. As a by-product, we also study the Cabibbo-suppressed decays,
such as $B\rightarrow (\chi_{c0}, \chi_{c2}, h_c)\pi$ and the U-spin-related
$B_s$ decay, which have so far received less theoretical and experimental
attention. The calculated branching ratios reach the order of $10^{-6}$, which
in within the scope of the Belle-II and LHCb experiments. Further, the
$CP$-asymmetry parameters are also calculated for these decays. The obtained
results are compared with the available experimental data and numbers from
other predictions. We also investigate the sources of theoretical uncertainties
in our calculation.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 11:59:51 GMT""},{""version"":""v2"",""created"":""Sun, 30 Aug 2020 07:26:24 GMT""}]","2020-09-01"
"2006.07626","Daniel M. Pellegrino","Daniel Pellegrino and Janiely Silva","Macphail's Theorem revisited",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 1947, M. S. Macphail constructed a series in $\ell_{1}$ that converges
unconditionally but does not converge absolutely. According to the literature,
this result helped Dvoretzky and Rogers to finally answer a long standing
problem of Banach Space Theory, by showing that in all infinite-dimensional
Banach spaces, there exists an unconditionally summable sequence that fails to
be absolutely summable. More precisely, the Dvoretzky--Rogers Theorem asserts
that in every infinite-dimensional Banach space $E$ there exists an
unconditionally convergent series ${\textstyle\sum}x^{(j)}$ such that
${\textstyle\sum}\Vert x^{(j)}\Vert^{^{2-\varepsilon}}=\infty$ for all
$\varepsilon>0.$ Their proof is non-constructive and Macphail's result for
$E=\ell_{1}$ provides a constructive proof just for $\varepsilon\geq1.$ In this
note we revisit Machphail's paper and present two alternative constructions
that work for all $\varepsilon>0.$
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 12:05:56 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 22:15:20 GMT""}]","2020-12-03"
"2006.07627","Jalim Singh","Jalim Singh, Mahammad Mustakim, and A. V. Anil Kumar","Super-Arrhenius diffusion in a binary colloidal mixture at low volume
  fraction: an effect of depletion interaction due to an asymmetric barrier","13 pages, 18 figures","J. Phys.: Condens. Matter 33, 125101 (2021)","10.1088/1361-648X/abd428",,"cond-mat.soft cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report results from the molecular dynamics simulations of a binary
colloidal mixture subjected to an external potential barrier along one of the
spatial directions at low volume fraction, {\phi} = 0.2. The variations in the
asymmetry of the external potential barrier do not change the dynamics of the
smaller particles, showing Arrhenius diffusion. However, the dynamics of the
larger particles shows a crossover from sub-Arrhenius to super-Arrhenius
diffusion with the asymmetry in the external potential at the low temperatures
and low volume fraction. Super-Arrhenius diffusion is generally observed in the
high density systems where the transient cages are present due to dense
packing, e.g., supercooled liquids, jammed systems, diffusion through porous
membranes, dynamics within the cellular environment, etc. This model can be
applied to study the molecular transport across cell membranes, nano-, and
micro-channels which are characterized by spatially asymmetric potentials.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 12:11:07 GMT""},{""version"":""v2"",""created"":""Sun, 24 Jan 2021 07:49:50 GMT""}]","2021-01-26"
"2006.07628","Sepehr Assadi","Sepehr Assadi, Shay Solomon","When Algorithms for Maximal Independent Set and Maximal Matching Run in
  Sublinear-Time",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Maximal independent set (MIS), maximal matching (MM), and
$(\Delta+1)$-coloring in graphs of maximum degree $\Delta$ are among the most
prominent algorithmic graph theory problems. They are all solvable by a simple
linear-time greedy algorithm and up until very recently this constituted the
state-of-the-art. In SODA 2019, Assadi, Chen, and Khanna gave a randomized
algorithm for $(\Delta+1)$-coloring that runs in $\widetilde{O}(n\sqrt{n})$
time, which even for moderately dense graphs is sublinear in the input size.
The work of Assadi et al. however contained a spoiler for MIS and MM: neither
problems provably admits a sublinear-time algorithm in general graphs. In this
work, we dig deeper into the possibility of achieving sublinear-time algorithms
for MIS and MM.
  The neighborhood independence number of a graph $G$, denoted by $\beta(G)$,
is the size of the largest independent set in the neighborhood of any vertex.
We identify $\beta(G)$ as the ``right'' parameter to measure the runtime of MIS
and MM algorithms: Although graphs of bounded neighborhood independence may be
very dense (clique is one example), we prove that carefully chosen variants of
greedy algorithms for MIS and MM run in $O(n\beta(G))$ and
$O(n\log{n}\cdot\beta(G))$ time respectively on any $n$-vertex graph $G$. We
complement this positive result by observing that a simple extension of the
lower bound of Assadi et.al. implies that $\Omega(n\beta(G))$ time is also
necessary for any algorithm to either problem for all values of $\beta(G)$ from
$1$ to $\Theta(n)$. We note that our algorithm for MIS is deterministic while
for MM we use randomization which we prove is unavoidable: any deterministic
algorithm for MM requires $\Omega(n^2)$ time even for $\beta(G) = 2$.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 12:12:31 GMT""}]","2020-06-16"
"2006.07629","Ahmed Jellal","Bouchaib Lemaalem, Abdelhadi Belouad, Miloud Mekkaoui, Ahmed Jellal","Confinement in Gapped Graphene with Magnetic Flux","15 pages, 8 figures",,,,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the propagation of electrons in a circular quantum dot of gapped
graphene subject to the magnetic flux $\phi$. We present analytical expressions
for the eigenstates, scattering coefficients, scattering efficiency and radial
component of the reflected current. We identify different scattering regimes as
a function of the physical parameters such as the incident electronic energy,
potential barrier, radius of quantum dot, gap and $\phi$. We choose two values
of the flux $\phi=1/2, 3/2$ and show that for low energy of the incident
electron, the scattering resonances appear and the far-field scattered current
presents distinct preferred scattering directions.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 12:17:30 GMT""}]","2020-06-16"
"2006.07630","Emilien Dupont","Emilien Dupont, Miguel Angel Bautista, Alex Colburn, Aditya Sankar,
  Carlos Guestrin, Josh Susskind, Qi Shan","Equivariant Neural Rendering","Add link to code",,,,"cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a framework for learning neural scene representations directly
from images, without 3D supervision. Our key insight is that 3D structure can
be imposed by ensuring that the learned representation transforms like a real
3D scene. Specifically, we introduce a loss which enforces equivariance of the
scene representation with respect to 3D transformations. Our formulation allows
us to infer and render scenes in real time while achieving comparable results
to models requiring minutes for inference. In addition, we introduce two
challenging new datasets for scene representation and neural rendering,
including scenes with complex lighting and backgrounds. Through experiments, we
show that our model achieves compelling results on these datasets as well as on
standard ShapeNet benchmarks.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 12:25:07 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 11:28:31 GMT""}]","2020-12-22"
"2006.07631","Helmut Meusinger","H. Meusinger, C. Rudolf, B. Stecklum, M. Hoeft, R. Mauersberger, and
  D. Apai","The galaxy population within the virial radius of the Perseus cluster","Accepted for publication in A&A","A&A 640, A30 (2020)","10.1051/0004-6361/202037574",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the galaxy population in a field of the Perseus cluster that
roughly covers the virial radius of the cluster. The galaxies were selected on
Schmidt CCD images in B and H alpha in combination with SDSS images. We present
a catalogue of 1294 galaxies. Morphological information was obtained for 90% of
the galaxies from the `eyeball' inspection, partly supported by the surface
brightness profile analysis. Redshifts were taken from SDSS, literature
sources, and own spectroscopic observations and are available for 24% of the
catalogues galaxies. The galaxy catalogue is used to derive cluster properties,
such as radial profiles, indications of sub-structure, virial mass, and viral
radius and to study the cluster galaxy population with regard to morphological
types and peculiarities, star formation rates and active galactic nuclei. In
addition to the statistical approach, we present brief individual descriptions
of 18 cluster galaxies with conspicuous morphological peculiarities. (Abstract
modified to match the arXiv format.)
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 12:32:24 GMT""}]","2020-08-12"
"2006.07632","Shinichiro Kobayashi","Shinichiro Kobayashi","An upper bound for higher order eigenvalues of symmetric graphs","12 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we derive an upper bound for higher order eigenvalues of the
normalized Laplace operator associated with a symmetric finite graph in terms
of lower order eigenvalues.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 12:47:38 GMT""}]","2020-06-16"
"2006.07633","Ying Wang","Ying Wang, Rongxin Wu, Chao Wang, Ming Wen, Yepang Liu, Shing-Chi
  Cheung, Hai Yu, Chang Xu, Zhiliang Zhu","Will Dependency Conflicts Affect My Program's Semantics?",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Java projects are often built on top of various third-party libraries. If
multiple versions of a library exist on the classpath, JVM will only load one
version and shadow the others, which we refer to as dependency conflicts. This
would give rise to semantic conflict (SC) issues, if the library APIs
referenced by a project have identical method signatures but inconsistent
semantics across the loaded and shadowed versions of libraries. SC issues are
difficult for developers to diagnose in practice, since understanding them
typically requires domain knowledge. Although adapting the existing test
generation technique for dependency conflict issues, Riddle, to detect SC
issues is feasible, its effectiveness is greatly compromised. This is mainly
because Riddle randomly generates test inputs, while the SC issues typically
require specific arguments in the tests to be exposed. To address that, we
conducted an empirical study of 75 real SC issues to understand the
characteristics of such specific arguments in the test cases that can capture
the SC issues. Inspired by our empirical findings, we propose an automated
testing technique Sensor, which synthesizes test cases using ingredients from
the project under test to trigger inconsistent behaviors of the APIs with the
same signatures in conflicting library versions. Our evaluation results show
that \textsc{Sensor} is effective and useful: it achieved a $Precision$ of
0.803 and a $Recall$ of 0.760 on open-source projects and a $Precision$ of
0.821 on industrial projects; it detected 150 semantic conflict issues in 29
projects, 81.8\% of which had been confirmed as real bugs.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 12:49:44 GMT""}]","2020-06-16"
"2006.07634","Qing Guo","Hua Qi and Qing Guo and Felix Juefei-Xu and Xiaofei Xie and Lei Ma and
  Wei Feng and Yang Liu and Jianjun Zhao","DeepRhythm: Exposing DeepFakes with Attentional Visual Heartbeat Rhythms","11 pages, 7 figures; This paper has been accepted to ACM-MM 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the GAN-based face image and video generation techniques, widely known as
DeepFakes, have become more and more matured and realistic, there comes a
pressing and urgent demand for effective DeepFakes detectors. Motivated by the
fact that remote visual photoplethysmography (PPG) is made possible by
monitoring the minuscule periodic changes of skin color due to blood pumping
through the face, we conjecture that normal heartbeat rhythms found in the real
face videos will be disrupted or even entirely broken in a DeepFake video,
making it a potentially powerful indicator for DeepFake detection. In this
work, we propose DeepRhythm, a DeepFake detection technique that exposes
DeepFakes by monitoring the heartbeat rhythms. DeepRhythm utilizes
dual-spatial-temporal attention to adapt to dynamically changing face and fake
types. Extensive experiments on FaceForensics++ and DFDC-preview datasets have
confirmed our conjecture and demonstrated not only the effectiveness, but also
the generalization capability of \emph{DeepRhythm} over different datasets by
various DeepFakes generation techniques and multifarious challenging
degradations.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 12:56:46 GMT""},{""version"":""v2"",""created"":""Wed, 26 Aug 2020 06:45:10 GMT""}]","2020-08-27"
"2006.07635","Bernhard Hientzsch","Yajie Yu, Bernhard Hientzsch, Narayan Ganesan","Backward Deep BSDE Methods and Applications to Nonlinear Problems","25 pages",,,,"q-fin.CP q-fin.MF q-fin.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a backward deep BSDE method applied to Forward
Backward Stochastic Differential Equations (FBSDE) with given terminal
condition at maturity that time-steps the BSDE backwards. We present an
application of this method to a nonlinear pricing problem - the differential
rates problem. To time-step the BSDE backward, one needs to solve a nonlinear
problem. For the differential rates problem, we derive an exact solution of
this time-step problem and a Taylor-based approximation. Previously backward
deep BSDE methods only treated zero or linear generators. While a Taylor
approach for nonlinear generators was previously mentioned, it had not been
implemented or applied, while we apply our method to nonlinear generators and
derive details and present results. Likewise, previously backward deep BSDE
methods were presented for fixed initial risk factor values $X_0$ only, while
we present a version with random $X_0$ and a version that learns portfolio
values at intermediate times as well. The method is able to solve nonlinear
FBSDE problems in high dimensions.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 13:01:48 GMT""}]","2020-06-16"
"2006.07636","Maria Alessandra Ragusa Full Professor","M. A. Ragusa, A. Tachikawa","Energy estimates of harmonic maps between Riemannian manifolds",,,,,"math.AP math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Omega \subset {R}^n,$ $n \geq 3,$ be a bounded open set,
$x=(x_1,x_2,\ldots,x_n)$ a generic point which belongs to $\Omega,$ $u \colon
\Omega \to {R}^N ,$ $N>1,$ and $ Du=(D_\alpha u^i)$, $D_\alpha =
\partial/\partial x_\alpha, $ $\alpha =1,\ldots,n,\,$ $i=1,\ldots,N .\,$
  Main goal is the study of regularity of the minima of nondifferentiable
functionals $$ {\cal F} \,=\, \int_\Omega F(x,u,Du) dx. $$ having the integrand
function different shapes of smoothness. The method is based on the use some
majorizations for the functional, rather than the well known Euler equation
associated to it.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 13:09:25 GMT""}]","2020-06-16"
"2006.07637","Luka Chkhetiani","Luka Chkhetiani, Levan Bejanidze","SE-MelGAN -- Speaker Agnostic Rapid Speech Enhancement","4 pages, 1 image, 1 table, 1 page for references",,,,"eess.AS cs.CL cs.SD","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recent advancement in Generative Adversarial Networks in speech synthesis
domain[3],[2] have shown, that it's possible to train GANs [8] in a reliable
manner for high quality coherent waveform generation from mel-spectograms. We
propose that it is possible to transfer the MelGAN's [3] robustness in learning
speech features to speech enhancement and noise reduction domain without any
model modification tasks. Our proposed method generalizes over multi-speaker
speech dataset and is able to robustly handle unseen background noises during
the inference. Also, we show that by increasing the batch size for this
particular approach not only yields better speech results, but generalizes over
multi-speaker dataset easily and leads to faster convergence. Additionally, it
outperforms previous state of the art GAN approach for speech enhancement SEGAN
[5] in two domains: 1. quality ; 2. speed. Proposed method runs at more than
100x faster than realtime on GPU and more than 2x faster than real time on CPU
without any hardware optimization tasks, right at the speed of MelGAN [3].
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 13:26:37 GMT""}]","2020-06-16"
"2006.07638","R\'obinson J. Acosta Diaz","R. Acosta Diaz, C.H. Monken, A. Jorio, Marcelo F. Santos","Effective Hamiltonian for Stokes--anti-Stokes pair generation with pump
  and probe polarized modes","9 pages, 3 figures","Phys. Rev. B 102, 134304 (2020)","10.1103/PhysRevB.102.134304",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the correlated Stokes--anti-Stokes scattering (SAS) an incident photon
interacts with a Raman-active material, creating a Stokes photon and exciting a
quantum vibrational mode in the medium, which is posteriorly annihilated on
contact with a second incident photon, producing in turn an anti-Stokes photon.
This can be accomplished by real and virtual processes. In real process the
quantum mode shared between the Stokes and anti-Stokes events is a real
particle, whereas in virtual processes the pair formation is mediated by the
exchange of virtual particles. Here, we introduce a Hamiltonian to describe the
pair production in SAS scattering, for both types of process, when stimulated
by two orthogonally polarized laser pulses in a pump-and-probe configuration.
We also model the effect of the natural decay of the vibration created in the
Stokes event and compute the probability of producing SAS pairs. Additionally,
we follow the dynamics of the vibration by considering the Stokes and
anti-Stokes fields as external reservoirs, obtaining thus a master equation for
the reduced density matrix for the vibrational population. Finally, we compare
our theoretical results with recently published experimental data.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 13:30:15 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 20:15:27 GMT""}]","2020-10-26"
"2006.07639","Chris Nixon","C. J. Nixon, J. E. Pringle, E. R. Coughlin, A. Swan, J. Farihi","Emission from elliptical streams of dusty debris around white dwarfs","31 pages, 5 figures, submitted to New Astronomy",,,,"astro-ph.SR astro-ph.EP astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  White dwarfs are routinely observed to have polluted atmospheres, and
sometimes significant infrared excesses, that indicate ongoing accretion of
circumstellar dust and rocky debris. Typically this debris is assumed to be in
the form of a (circular) disc, and to originate from asteroids that passed
close enough to the white dwarf to be pulled apart by tides. However,
theoretical considerations suggest that the circularisation of the debris,
which initially occupies highly eccentric orbits, is very slow. We therefore
hypothesise that the observations may be readily explained by the debris
remaining on highly eccentric orbits, and we explore the properties of such
debris. For the generic case of an asteroid originating at several au from the
white dwarf, we find that all of the tidal debris is always bound to the white
dwarf and that the orbital energy distribution of the debris is narrow enough
that it executes similar elliptical orbits with only a narrow spread. Assuming
that the tidal field of the white dwarf is sufficient to minimise the effects
of self-gravity and collisions within the debris, we estimate the time over
which the debris spreads into a single elliptical ring, and we generate toy
spectra and lightcurves from the initial disruption to late times when the
debris distribution is essentially time steady. Finally we speculate on the
connection between these simple considerations and the observed properties of
these systems, and on additional physical processes that may change this simple
picture.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 13:50:23 GMT""}]","2020-06-16"
"2006.07640","Shifeng Xiong Doc","Chunya Li, Daijun Chen, and Shifeng Xiong","Linear screening for high-dimensional computer experiments",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose a linear variable screening method for computer
experiments when the number of input variables is larger than the number of
runs. This method uses a linear model to model the nonlinear data, and screens
the important variables by existing screening methods for linear models. When
the underlying simulator is nearly sparse, we prove that the linear screening
method is asymptotically valid under mild conditions. To improve the screening
accuracy, we also provide a two-stage procedure that uses different basis
functions in the linear model. The proposed methods are very simple and easy to
implement. Numerical results indicate that our methods outperform existing
model-free screening methods.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 13:55:20 GMT""}]","2020-06-16"
"2006.07641","Richard Forbes","Mohammad M. Allam, Richard G. Forbes, and Marwan S. Mousa","Applying the field emission orthodoxy test to Murphy-Good plots","26 typescript pages, 3 figures",,,,"physics.app-ph cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In field electron emission (FE) studies, it is important to check and analyse
the quality and validity of results experimentally obtained from samples, using
suitably plotted current-voltage [I(V)] measurements. For the traditional
plotting method, the Fowler-Nordheim (FN) plot, there exists a so-called
""orthodoxy test"" that can be applied to the FN plot, in order to check whether
the FE device/system generating the results is ""ideal"". If it is not ideal,
then emitter characterization parameters deduced from the FN plot are likely to
be spurious. A new form of FE I(V) data plot, the so-called ""Murphy-Good (MG)
plot"" has recently been introduced (R.G. Forbes, Roy. Soc. Open Sci. 6 (2019)
190912. This aims to improve the precision with which
characterization-parameter values (particularly values of formal emission area)
can be extracted from FE I(V) data. The present paper compares this new
plotting form with the older FN and Millikan-Lauritsen (ML) forms, and makes an
independent assessment of the consistency with which slope (and hence
scaled-field) estimates can be extracted from a MG plot. It is shown that, by
using a revised formula for the extraction of scaled-field values, the existing
orthodoxy test can be applied to Murphy-Good plots. The development is reported
of a prototype web tool that can apply the orthodoxy test to all three forms of
FE data plot (ML, MG and FN).
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:03:53 GMT""}]","2020-06-16"
"2006.07642","Andrew McRae","Andrew McRae and Justin Romberg and Mark Davenport","Sample complexity and effective dimension for regression on manifolds",,,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the theory of regression on a manifold using reproducing kernel
Hilbert space methods. Manifold models arise in a wide variety of modern
machine learning problems, and our goal is to help understand the effectiveness
of various implicit and explicit dimensionality-reduction methods that exploit
manifold structure. Our first key contribution is to establish a novel
nonasymptotic version of the Weyl law from differential geometry. From this we
are able to show that certain spaces of smooth functions on a manifold are
effectively finite-dimensional, with a complexity that scales according to the
manifold dimension rather than any ambient data dimension. Finally, we show
that given (potentially noisy) function values taken uniformly at random over a
manifold, a kernel regression estimator (derived from the spectral
decomposition of the manifold) yields minimax-optimal error bounds that are
controlled by the effective dimension.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:09:55 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 13:58:59 GMT""},{""version"":""v3"",""created"":""Fri, 16 Oct 2020 14:58:46 GMT""}]","2020-10-19"
"2006.07643","Dmitrii Pirozhkov","Dmitrii Pirozhkov","Admissible subcategories of del Pezzo surfaces","53 pages, 4 figures; improved version of author's PhD thesis",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study admissible subcategories of derived categories of coherent sheaves
on del Pezzo surfaces and rational elliptic surfaces. Using a relation between
admissible subcategories and anticanonical divisors we prove the following
results. First, we classify all admissible subcategories of the projective
plane by showing that each is generated by a subcollection of a full
exceptional collection. Second, we show that the derived categories of del
Pezzo surfaces do not contain any phantom subcategories. This provides first
examples of varieties of dimension larger than one that have some nontrivial
admissible subcategories, but provably do not contain phantoms. We also prove
that any admissible subcategory supported set-theoretically on a smooth
(-1)-curve in a surface is generated by some twist of the structure sheaf of
that curve.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:10:00 GMT""}]","2020-06-16"
"2006.07644","Lin Bai","Lin Bai, Yecheng Lyu and Xinming Huang","RoadNet-RT: High Throughput CNN Architecture and SoC Design for
  Real-Time Road Segmentation",,"in IEEE Transactions on Circuits and Systems I: Regular Papers,
  vol. 68, no. 2, pp. 704-714, Feb. 2021",,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, convolutional neural network has gained popularity in many
engineering applications especially for computer vision. In order to achieve
better performance, often more complex structures and advanced operations are
incorporated into the neural networks, which results very long inference time.
For time-critical tasks such as autonomous driving and virtual reality,
real-time processing is fundamental. In order to reach real-time process speed,
a light-weight, high-throughput CNN architecture namely RoadNet-RT is proposed
for road segmentation in this paper. It achieves 90.33% MaxF score on test set
of KITTI road segmentation task and 8 ms per frame when running on GTX 1080
GPU. Comparing to the state-of-the-art network, RoadNet-RT speeds up the
inference time by a factor of 20 at the cost of only 6.2% accuracy loss. For
hardware design optimization, several techniques such as depthwise separable
convolution and non-uniformed kernel size convolution are customized designed
to further reduce the processing time. The proposed CNN architecture has been
successfully implemented on an FPGA ZCU102 MPSoC platform that achieves the
computation capability of 83.05 GOPS. The system throughput reaches 327.9
frames per second with image size 1216x176.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:12:23 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 13:59:45 GMT""}]","2021-05-18"
"2006.07645","Olivia Beckwith","Scott Ahlgren, Olivia Beckwith, Martin Raum","Scarcity of congruences for the partition function","Minor revisions made to a few of the proofs. To appear in American
  Journal of Mathematics",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The arithmetic properties of the ordinary partition function $p(n)$ have been
the topic of intensive study for the past century. Ramanujan proved that there
are linear congruences of the form $p(\ell n+\beta)\equiv 0\pmod\ell$ for the
primes $\ell=5, 7, 11$, and it is known that there are no others of this form.
On the other hand, for every prime $\ell\geq 5$ there are infinitely many
examples of congruences of the form $p(\ell Q^m n+\beta)\equiv 0\pmod\ell$
where $Q\geq 5$ is prime and $m\geq 3$. This leaves open the question of the
existence of such congruences when $m=1$ or $m=2$ (no examples in these cases
are known). We prove in a precise sense that such congruences, if they exist,
are exceedingly scarce. Our methods involve a careful study of modular forms of
half integral weight on the full modular group which are related to the
partition function. Among many other tools, we use work of Radu which describes
expansions of such modular forms along square classes at cusps of the modular
curve $X(\ell Q)$, Galois representations and the arithmetic large sieve.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:24:12 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jun 2022 15:17:42 GMT""},{""version"":""v3"",""created"":""Mon, 5 Dec 2022 03:04:00 GMT""}]","2022-12-06"
"2006.07646","el Houcein el Abdalaoui","el Houcein el Abdalaoui and Mahesh Nerurkar","Sarnak's M\""obius disjointness for dynamical systems with singular
  spectrum and dissection of M\""obius flow","23 pages. We present an unpublished theorem of Veech which is closely
  related to our main result with complete proof. The notion of Quasi-factor
  plays a key role",,,,"math.DS math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that Sarnak's M\""{o}bius orthogonality conjecture is fulfilled
for the compact metric dynamical systems for which every invariant measure has
singular spectra. This is accomplished by first establishing a special case of
Chowla conjecture which gives a correlation between the M\""{o}bius function and
its square. Then a computation of W. Veech, followed by an argument using the
notion of `affinity between measures', (or the so-called `Hellinger method'),
completes the proof. We further present an unpublished theorem of Veech which
is closely related to our main result. This theorem asserts, if for any
probability measure in the closure of the Cesaro averages of the Dirac measure
on the shift of the M\""{o}bius function, the first projection is in the
orthocomplement of its Pinsker algebra then Sarnak M\""{o}bius disjointness
conjecture holds. Among other consequences, we obtain a simple proof of
Matom{\""a}ki-Radziwi{\l}l-Tao's theorem and Matom{\""a}ki-Radziwi{\l}l's theorem
on the correlations of order two of the Liouville function.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:24:27 GMT""}]","2020-06-16"
"2006.07647","Ivan Smirnov","Ivan Smirnov, Florian Lemmerich, Markus Strohmaier","Quota-based debiasing can decrease representation of already
  underrepresented groups",,,,,"cs.CY cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many important decisions in societies such as school admissions, hiring, or
elections are based on the selection of top-ranking individuals from a larger
pool of candidates. This process is often subject to biases, which typically
manifest as an under-representation of certain groups among the selected or
accepted individuals. The most common approach to this issue is debiasing, for
example via the introduction of quotas that ensure proportional representation
of groups with respect to a certain, often binary attribute. Cases include
quotas for women on corporate boards or ethnic quotas in elections. This,
however, has the potential to induce changes in representation with respect to
other attributes. For the case of two correlated binary attributes we show that
quota-based debiasing based on a single attribute can worsen the representation
of already underrepresented groups and decrease overall fairness of selection.
We use several data sets from a broad range of domains from recidivism risk
assessments to scientific citations to assess this effect in real-world
settings. Our results demonstrate the importance of including all relevant
attributes in debiasing procedures and that more efforts need to be put into
eliminating the root causes of inequalities as purely numerical solutions such
as quota-based debiasing might lead to unintended consequences.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:26:42 GMT""}]","2020-06-16"
"2006.07648","B{\l}a\.zej Miasojedow","Maryia Shpak, B{\l}a\.zej Miasojedow, Wojciech Rejchel","Structure learning for CTBN's via penalized maximum likelihood methods",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The continuous-time Bayesian networks (CTBNs) represent a class of stochastic
processes, which can be used to model complex phenomena, for instance, they can
describe interactions occurring in living processes, in social science models
or in medicine. The literature on this topic is usually focused on the case
when the dependence structure of a system is known and we are to determine
conditional transition intensities (parameters of the network). In the paper,
we study the structure learning problem, which is a more challenging task and
the existing research on this topic is limited. The approach, which we propose,
is based on a penalized likelihood method. We prove that our algorithm, under
mild regularity conditions, recognizes the dependence structure of the graph
with high probability. We also investigate the properties of the procedure in
numerical studies to demonstrate its effectiveness.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:28:19 GMT""}]","2020-06-16"
"2006.07649","Sai Prathyusha Malla","Sai Prathyusha Malla, Dennis Stello, Daniel Huber, Benjamin T. Montet,
  Timothy R. Bedding, Mads Fredslund Andersen, Frank Grundahl, Jens
  Jessen-Hansen, Daniel R. Hey, Pere L. Palle, Licai Deng, Chunguang Zhang,
  Xiaodian Chen, James Lloyd, Victoria Antoci","Asteroseismic masses of four evolved planet-hosting stars using SONG and
  TESS: resolving the retired A-star mass controversy","13 pages, 12 figures, Accepted for publication in the Main Journal of
  MNRAS","MNRAS 496 2020 5423-5435","10.1093/mnras/staa1793",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of planet occurrence as a function of stellar mass is important for
a better understanding of planet formation. Estimating stellar mass, especially
in the red giant regime, is difficult. In particular, stellar masses of a
sample of evolved planet-hosting stars based on spectroscopy and grid-based
modelling have been put to question over the past decade with claims they were
overestimated. Although efforts have been made in the past to reconcile this
dispute using asteroseismology, results were inconclusive. In an attempt to
resolve this controversy, we study four more evolved planet-hosting stars in
this paper using asteroseismology, and we revisit previous results to make an
informed study of the whole ensemble in a self-consistent way. For the four new
stars, we measure their masses by locating their characteristic oscillation
frequency, $\mathrm{\nu}_{\mathrm{max}}$, from their radial velocity time
series observed by SONG. For two stars, we are also able to measure the large
frequency separation, $\mathrm{\Delta\nu}$, helped by extended SONG single-site
and dual-site observations and new TESS observations. We establish the
robustness of the $\mathrm{\nu}_{\mathrm{max}}$-only-based results by
determining the stellar mass from $\mathrm{\Delta\nu}$, and from both
$\mathrm{\Delta\nu}$ and $\mathrm{\nu}_{\mathrm{max}}$. We then compare the
seismic masses of the full ensemble of 16 stars with the spectroscopic masses
from three different literature sources. We find an offset between the seismic
and spectroscopic mass scales that is mass-dependent, suggesting that the
previously claimed overestimation of spectroscopic masses only affects stars
more massive than about 1.6 M$_\mathrm{\odot}$.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:35:27 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 15:06:37 GMT""},{""version"":""v3"",""created"":""Mon, 22 Jun 2020 12:22:37 GMT""}]","2020-07-30"
"2006.07650","Ercan Kilicarslan","Suat Dengiz, Ercan Kilicarslan, Ivan Kol\'a\v{r}, Anupam Mazumdar","Impulsive waves in ghost free infinite derivative gravity in anti-de
  Sitter spacetime","9 pages, 5 figures, minor corrections and references added, Published
  in Phys.Rev. D","Phys. Rev. D 102, 044016 (2020)","10.1103/PhysRevD.102.044016",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study exact impulsive gravitational waves propagating in anti-de Sitter
spacetime in the context of the ghost free infinite derivative gravity. We show
that the source-free theory does not admit any AdS wave solutions other than
that of Einstein's general relativity. The situation is significantly different
in the presence of sources. We construct impulsive-wave solutions of the
infinite derivative gravity generated by massless particles and linear sources
in four and three dimensions. The singularities corresponding to distributional
curvature at the locations of the sources get smeared by the non-localities.
The obtained solutions are regular everywhere. They reduce to the corresponding
solutions of general relativity in the infrared regime and in the local limit.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:47:42 GMT""},{""version"":""v2"",""created"":""Mon, 10 Aug 2020 11:25:55 GMT""}]","2020-08-12"
"2006.07651","Eduard Feireisl","Eduard Feireisl","(S)-convergence and approximation of oscillatory solutions in fluid
  dynamics",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new concept of (S)-convergence applicable to numerical methods
as well as other consistent approximations of the Euler system in gas dynamics.
(S)-convergence, based on averaging in the spirit of Strong Law of Large
Numbers, reflects the asymptotic properties of a given approximate sequence
better than the standard description via Young measures. Similarity with the
tools of ergodic theory is discussed.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:48:26 GMT""}]","2020-06-16"
"2006.07652","Grigoris Panotopoulos","Grigoris Panotopoulos, Daniele Vernieri and Il\'idio Lopes","Quark stars with isotropic matter in Ho\v{r}ava gravity and
  Einstein-{\ae}ther theory","10 pages, 6 figures, to appear in EPJ C","Eur. Phys. J. C (2020) 80:537","10.1140/epjc/s10052-020-8105-5",,"gr-qc astro-ph.HE hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study non-rotating and isotropic strange quark stars in Lorentz-violating
theories of gravity, and in particular in Ho\v{r}ava gravity and
Einstein-{\ae}ther theory. For quark matter we adopt both linear and non-linear
equations of state, corresponding to the MIT bag model and colour flavour
locked state, respectively. The new structure equations describing hydrostatic
equilibrium generalize the usual Tolman-Oppenheimer-Volkoff (TOV) equations of
Einstein's general relativity. A dimensionless parameter $\nu$ measures the
deviation from the standard TOV equations, which are recovered in the limit
$\nu \rightarrow 0$. We compute the mass, the radius as well as the compactness
of the stars, and we show graphically the impact of the parameter $\nu$ on the
mass-to-radius profiles for different equations of state describing quark
matter. The energy conditions and stability criteria are also considered, and
they are all found to be fulfilled.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:53:44 GMT""}]","2020-06-22"
"2006.07653","Francesco Mainardi","Francesco Mainardi, Armando Consiglio","The Pioneers of the Mittag-Leffler Functions in Dielectrical and
  Mechanical Relaxation Processes","13 pages, 9 figures. arXiv admin note: text overlap with
  arXiv:1305.0161","WSEAS Transactions on Mathematics Vol 19 (2020), pp. 289--300","10.37394/23206.2020.19.29",,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We start with a short survey of the basic properties of the Mittag-Leffler
functions. Then we focus on the key role of these functions to explain the
after-effects and relaxation phenomena occurring in dielectrics and in
viscoelastic bodies. For this purpose we recall the main aspects that were
formerly discussed by two pioneers in the years 1930's-1940's whom we have
identified with Harold T. Davis and Bernhard Gross.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:54:10 GMT""}]","2020-06-16"
"2006.07654","Zhenning Cai","Zhenning Cai, Jianfeng Lu, Siyao Yang","Numerical analysis for inchworm Monte Carlo method: Sign problem and
  error growth","58 pages, 8 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the numerical analysis of the inchworm Monte Carlo method, which
is proposed recently to tackle the numerical sign problem for open quantum
systems. We focus on the growth of the numerical error with respect to the
simulation time, for which the inchworm Monte Carlo method shows a flatter
curve than the direct application of Monte Carlo method to the classical Dyson
series. To better understand the underlying mechanism of the inchworm Monte
Carlo method, we distinguish two types of exponential error growth, which are
known as the numerical sign problem and the error amplification. The former is
due to the fast growth of variance in the stochastic method, which can be
observed from the Dyson series, and the latter comes from the evolution of the
numerical solution. Our analysis demonstrates that the technique of partial
resummation can be considered as a tool to balance these two types of error,
and the inchwormMonte Carlo method is a successful case where the numerical
sign problem is effectively suppressed by such means. We first demonstrate our
idea in the context of ordinary differential equations, and then provide
complete analysis for the inchworm Monte Carlo method. Several numerical
experiments are carried out to verify our theoretical results.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:58:41 GMT""},{""version"":""v2"",""created"":""Sun, 5 Dec 2021 23:40:09 GMT""}]","2021-12-07"
"2006.07655","David Kohns Mr","David Kohns and Tibor Szendrei","Horseshoe Prior Bayesian Quantile Regression",,,,,"econ.EM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper extends the horseshoe prior of Carvalho et al. (2010) to Bayesian
quantile regression (HS-BQR) and provides a fast sampling algorithm for
computation in high dimensions. The performance of the proposed HS-BQR is
evaluated on Monte Carlo simulations and a high dimensional Growth-at-Risk
(GaR) forecasting application for the U.S. The Monte Carlo design considers
several sparsity and error structures. Compared to alternative shrinkage
priors, the proposed HS-BQR yields better (or at worst similar) performance in
coefficient bias and forecast error. The HS-BQR is particularly potent in
sparse designs and in estimating extreme quantiles. As expected, the
simulations also highlight that identifying quantile specific location and
scale effects for individual regressors in dense DGPs requires substantial
data. In the GaR application, we forecast tail risks as well as complete
forecast densities using the McCracken and Ng (2020) database. Quantile
specific and density calibration score functions show that the HS-BQR provides
the best performance, especially at short and medium run horizons. The ability
to produce well calibrated density forecasts and accurate downside risk
measures in large data contexts makes the HS-BQR a promising tool for
nowcasting applications and recession modelling.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:07:52 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2021 22:31:54 GMT""}]","2021-03-22"
"2006.07656","Weida Wu","Paul M. Sass, Jinwoong Kim, David Vanderbilt, Jiaqiang Yan, Weida Wu","Robust A-type order and spin-flop transition on the surface of the
  antiferromagnetic topological insulator MnBi$_2$Te$_4$","11 pages, 4 figures","Physical Review Letters 125, 037201 (2020)","10.1103/PhysRevLett.125.037201",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here we present microscopic evidence of the persistence of uniaxial A-type
antiferromagnetic order to the surface layers of MnBi$_2$Te$_4$ single crystals
using magnetic force microscopy. Our results reveal termination-dependent
magnetic contrast across both surface step edges and domain walls, which can be
screened by thin layers of soft magnetism. The robust surface A-type order is
further corroborated by the observation of termination-dependent surface
spin-flop transitions, which have been theoretically proposed decades ago. Our
results not only provide key ingredients for understanding the electronic
properties of the antiferromagnetic topological insulator MnBi$_2$Te$_4$, but
also open a new paradigm for exploring intrinsic surface metamagnetic
transitions in natural antiferromagnets.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:11:50 GMT""}]","2020-07-15"
"2006.07657","Doina Bucur","Doina Bucur","Top influencers can be identified universally by combining classical
  centralities","14 pages, 10 figures, 4 supplementary figures",,"10.1038/s41598-020-77536-7",,"cs.SI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Information flow, opinion, and epidemics spread over structured networks.
When using individual node centrality indicators to predict which nodes will be
among the top influencers or spreaders in a large network, no single centrality
has consistently good ranking power. We show that statistical classifiers using
two or more centralities as input are instead consistently predictive over many
diverse, static real-world topologies. Certain pairs of centralities cooperate
particularly well in statistically drawing the boundary between the top
spreaders and the rest: local centralities measuring the size of a node's
neighbourhood benefit from the addition of a global centrality such as the
eigenvector centrality, closeness, or the core number. This is, intuitively,
because a local centrality may rank highly some nodes which are located in
dense, but peripheral regions of the network---a situation in which an
additional global centrality indicator can help by prioritising nodes located
more centrally. The nodes selected as superspreaders will usually jointly
maximise the values of both centralities. As a result of the interplay between
centrality indicators, training classifiers with seven classical indicators
leads to a nearly maximum average precision function (0.995) across the
networks in this study.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:12:28 GMT""},{""version"":""v2"",""created"":""Tue, 4 Aug 2020 12:33:44 GMT""}]","2020-11-30"
"2006.07658","Thorsten Hohage","Martin Halla and Thorsten Hohage","On the well-posedness of the damped time-harmonic Galbrun equation and
  the equations of stellar oscillations","21 pages",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the time-harmonic Galbrun equation describing the propagation of
sound in the presence of a steady background flow. With additional rotational
and gravitational terms these equations are also fundamental in helio- and
asteroseismology as a model for stellar oscillations. For a simple damping
model we prove well-posedness of these equations, i.e. uniqueness, existence,
and stability of solutions under mild conditions on the parameters (essentially
subsonic flows). The main tool of our analysis is a generalized Helmholtz
decomposition.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:17:40 GMT""}]","2020-06-16"
"2006.07659","Marianna Korsos","M. B. Korsos, P. Romano, H. Morgan, Y. Ye, R. Erdelyi, F. Zuccarello","Differences in periodic magnetic helicity injection behaviour between
  flaring and non-flaring Active Regions: Case Study",,,"10.3847/2041-8213/ab9d7a",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The evolution of magnetic helicity has a close relationship with solar
eruptions and is of interest as a predictive diagnostic. In this case study, we
analyse the evolution of the normalised emergence, shearing and total magnetic
helicity components in the case of three flaring and three non-flaring active
regions (ARs) using SHARPs (Spaceweather Helioseismic Magnetic Imager Active
Region Patches) vector magnetic field data. The evolution of the three magnetic
helicity components is analysed with wavelet transforms, revealing significant
common periodicities of the normalised emergence, shearing and total helicity
fluxes before flares in the flaring ARs. The three non-flaring ARs do not show
such common periodic behaviour. This case study suggests that the presence of
significant periodicities in the power spectrum of magnetic helicity components
could serve as a valuable precursor for flares.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:18:26 GMT""}]","2020-07-15"
"2006.07660","Dario Pavllo","Dario Pavllo, Graham Spinks, Thomas Hofmann, Marie-Francine Moens,
  Aurelien Lucchi","Convolutional Generation of Textured 3D Meshes","NeurIPS 2020, Oral presentation. Code at
  https://github.com/dariopavllo/convmesh",,,,"cs.CV cs.GR cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While recent generative models for 2D images achieve impressive visual
results, they clearly lack the ability to perform 3D reasoning. This heavily
restricts the degree of control over generated objects as well as the possible
applications of such models. In this work, we bridge this gap by leveraging
recent advances in differentiable rendering. We design a framework that can
generate triangle meshes and associated high-resolution texture maps, using
only 2D supervision from single-view natural images. A key contribution of our
work is the encoding of the mesh and texture as 2D representations, which are
semantically aligned and can be easily modeled by a 2D convolutional GAN. We
demonstrate the efficacy of our method on Pascal3D+ Cars and CUB, both in an
unconditional setting and in settings where the model is conditioned on class
labels, attributes, and text. Finally, we propose an evaluation methodology
that assesses the mesh and texture quality separately.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:23:29 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 10:21:45 GMT""}]","2020-10-26"
"2006.07661","Ilinka Dimitrova","Ilinka Dimitrova, J\""org Koppitz","On Relative Ranks of the Semigroup of Orientation-preserving
  Transformations on Infinite Chains",,,"10.1142/S1793557121501461",,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we determine the relative rank of the semigroup OP(X) of all
orientation-preserving transformations on infinite chains modulo the semigroup
O(X) of all order-preserving transformations.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:24:52 GMT""},{""version"":""v2"",""created"":""Wed, 26 Aug 2020 12:29:09 GMT""}]","2021-11-25"
"2006.07662","Venkata Medicherla Prof","Ananya Sahoo, Maheswari Mohanta, S. K. Parida and V. R. R. Medicherla","Structural properties of Fe-Ni/Cu/Fe-Ni trilayers on Si (100)","6 pages, 4 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the structural properties of
Fe$_{1-x}$Ni$_x$/Cu/Fe$_{1-x}$Ni$_x$ ( $x=0.5$, non Invar and $x=0.36$, Invar)
trilayers deposited on Si~(100)~at room temperature using dc magnetron
sputtering technique in ultra high vacuum conditions taking high purity Fe, Ni
and Cu metals with Cu layer thickness 4, 6 and 8 nm for each alloy composition.
The structure of the alloy films of the trilayers was investigated using x-ray
diffraction and the thickness \& roughness of the layers were obtained by x-ray
reflectivity measurement. Both the as prepared and annealed trilayers exhibit
layered structure. The as deposited Fe-Ni alloy in non Invar trilayer exhibits
only fcc structure whereas in Invar alloy it exhibits a mixed fcc and bcc
phases. Interestingly after annealing at 425$^0$C in ultra high vacuum, the
Invar alloy completely transformed to fcc structure for all Cu thicknesses. In
both Invar and non Invar trilayers, the Bragg reflections corresponding to
Fe-Ni alloy layers become sharp after annealing. The induced structural
transformation in Invar trilayer is explained using enhanced diffusion of Fe
and Ni atoms at high temperatures.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:28:17 GMT""}]","2020-06-16"
"2006.07663","Gyuhyeong Goh","Gyuhyeong Goh, Jisang Yu","Bayesian causal inference with some invalid instrumental variables",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In observational studies, instrumental variables estimation is greatly
utilized to identify causal effects. One of the key conditions for the
instrumental variables estimator to be consistent is the exclusion restriction,
which indicates that instruments affect the outcome of interest only via the
exposure variable of interest. We propose a likelihood-free Bayesian approach
to make consistent inferences about the causal effect when there are some
invalid instruments in a way that they violate the exclusion restriction
condition. Asymptotic properties of the proposed Bayes estimator, including
consistency and normality, are established. A simulation study demonstrates
that the proposed Bayesian method produces consistent point estimators and
valid credible intervals with correct coverage rates for Gaussian and
non-Gaussian data with some invalid instruments. We also demonstrate the
proposed method through the real data application.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:35:06 GMT""}]","2020-06-16"
"2006.07664","Longlong Feng","Longlong Feng and Xu Wang","Automate Obstructive Sleep Apnea Diagnosis Using Convolutional Neural
  Networks","10 pages, 3 figures, AMMCS-2019 International Conference",,,,"cs.LG eess.SP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identifying sleep problem severity from overnight polysomnography (PSG)
recordings plays an important role in diagnosing and treating sleep disorders
such as the Obstructive Sleep Apnea (OSA). This analysis traditionally is done
by specialists manually through visual inspections, which can be tedious,
time-consuming, and is prone to subjective errors. One of the solutions is to
use Convolutional Neural Networks (CNN) where the convolutional and pooling
layers behave as feature extractors and some fully-connected (FCN) layers are
used for making final predictions for the OSA severity. In this paper, a CNN
architecture with 1D convolutional and FCN layers for classification is
presented. The PSG data for this project are from the Cleveland Children's
Sleep and Health Study database and classification results confirm the
effectiveness of the proposed CNN method. The proposed 1D CNN model achieves
excellent classification results without manually preprocesssing PSG signals
such as feature extraction and feature reduction.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:35:18 GMT""}]","2020-06-16"
"2006.07665","Yansong Tang","Yansong Tang, Zanlin Ni, Jiahuan Zhou, Danyang Zhang, Jiwen Lu, Ying
  Wu, Jie Zhou","Uncertainty-aware Score Distribution Learning for Action Quality
  Assessment","CVPR2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Assessing action quality from videos has attracted growing attention in
recent years. Most existing approaches usually tackle this problem based on
regression algorithms, which ignore the intrinsic ambiguity in the score labels
caused by multiple judges or their subjective appraisals. To address this
issue, we propose an uncertainty-aware score distribution learning (USDL)
approach for action quality assessment (AQA). Specifically, we regard an action
as an instance associated with a score distribution, which describes the
probability of different evaluated scores. Moreover, under the circumstance
where fine-grained score labels are available (e.g., difficulty degree of an
action or multiple scores from different judges), we further devise a
multi-path uncertainty-aware score distributions learning (MUSDL) method to
explore the disentangled components of a score. We conduct experiments on three
AQA datasets containing various Olympic actions and surgical activities, where
our approaches set new state-of-the-arts under the Spearman's Rank Correlation.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:41:29 GMT""}]","2020-06-16"
"2006.07666","Elena Fantino Dr","D. de la Torre Sangr\`a and E. Fantino and R. Flores and O. Calvente
  Lozano and C. Garc\'ia Estelrich","An Automatic Tree Search Algorithm for the Tisserand Graph",,"Alexandria Engineering Journal, Volume 60, Issue 1, 2021, Pages
  1027-1041, ISSN 1110-0168","10.1016/j.aej.2020.10.028",,"astro-ph.EP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Tisserand graph (TG) is a graphical tool commonly employed in the
preliminary design of gravity-assisted trajectories. The TG is a
two-dimensional map showing essential orbital information regarding the
Keplerian orbits resulting from the close passage by one or more massive
bodies, given the magnitude of the hyperbolic excess speed ($v_{\infty}$) and
the minimum allowed pericenter height for each passage. Contours of constant
$v_{\infty}$ populate the TG. Intersections between contours allow to link
consecutive flybys and build sequences of encounters en route to a selected
destination. When the number of perturbing bodies is large and many
$v_{\infty}$ levels are considered, the identification of all the possible
sequences of encounters through the visual inspection of the TG becomes a
laborious task. Besides, if the sequences are used as input for a numerical
code for trajectory design and optimization, an automated examination of the TG
is desirable. This contribution describes an automatic technique to explore the
TG and find all the encounter paths. The technique is based on a tree search
method, and the intersections between contours are found using the regula-falsi
scheme. The method is validated through comparisons with solutions available in
the open literature. Examples are given of application to interplanetary
mission scenarios, including the coupling with a trajectory optimizer.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:44:22 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 10:09:39 GMT""}]","2021-04-02"
"2006.07667","Valerio Ficcadenti","Valerio Ficcadenti, Roy Cerqueti, Marcel Ausloos, Gurjeet Dhesi","Words ranking and Hirsch index for identifying the core of the hapaxes
  in political texts",,,"10.1016/j.joi.2020.101054",,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper deals with a quantitative analysis of the content of official
political speeches. We study a set of about one thousand talks pronounced by
the US Presidents, ranging from Washington to Trump. In particular, we search
for the relevance of the rare words, i.e. those said only once in each speech
-- the so-called hapaxes. We implement a rank-size procedure of Zipf-Mandelbrot
type for discussing the hapaxes' frequencies regularity over the overall set of
speeches. Starting from the obtained rank-size law, we define and detect the
core of the hapaxes set by means of a procedure based on an Hirsch index
variant. We discuss the resulting list of words in the light of the overall US
Presidents' speeches. We further show that this core of hapaxes itself can be
well fitted through a Zipf-Mandelbrot law and that contains elements producing
deviations at the low ranks between scatter plots and fitted curve -- the
so-called king and vice-roy effect. Some socio-political insights are derived
from the obtained findings about the US Presidents messages.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:48:15 GMT""}]","2020-06-16"
"2006.07668","Lei Deng","Lei Deng, Fang Liu, Yijin Zhang, Wing Shing Wong","Delay-Constrained Topology-Transparent Distributed Scheduling for MANETs",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transparent topology is common in many mobile ad hoc networks (MANETs) such
as vehicle ad hoc networks (VANETs), unmanned aerial vehicle (UAV) ad hoc
networks, and wireless sensor networks due to their decentralization and
mobility nature. There are many existing works on distributed scheduling scheme
design for topology-transparent MANETs. Most of them focus on
delay-unconstrained settings. However, with the proliferation of real-time
applications over wireless communications, it becomes more and more important
to support delay-constrained traffic in MANETs. In such applications, each
packet has a given hard deadline: if it is not delivered before its deadline,
its validity will expire and it will be removed from the system. This feature
is fundamentally different from the traditional delay-unconstrained one. In
this paper, we for the first time investigate distributed scheduling schemes
for a topology-transparent MANET to support delay-constrained traffic. We
analyze and compare probabilistic ALOHA scheme and deterministic sequence
schemes, including the conventional time division multiple access (TDMA), the
Galois field (GF) sequence scheme proposed in \cite{chlamtac1994making}, and
the combination sequence scheme that we propose for a special type of sparse
network topology.We use both theoretical analysis and empirical simulations to
compare all these schemes and summarize the conditions under which different
individual schemes perform best.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:52:06 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 10:58:50 GMT""},{""version"":""v3"",""created"":""Sat, 27 Jun 2020 13:36:27 GMT""},{""version"":""v4"",""created"":""Sun, 8 Nov 2020 08:51:23 GMT""},{""version"":""v5"",""created"":""Tue, 10 Nov 2020 08:04:22 GMT""},{""version"":""v6"",""created"":""Fri, 25 Dec 2020 08:14:09 GMT""}]","2020-12-29"
"2006.08357","Zhen Dong","Zhen Dong, Dequan Wang, Qijing Huang, Yizhao Gao, Yaohui Cai, Tian Li,
  Bichen Wu, Kurt Keutzer, John Wawrzynek","CoDeNet: Efficient Deployment of Input-Adaptive Object Detection on
  Embedded FPGAs","Github repo: https://github.com/DequanWang/CoDeNet arXiv:2002.08357
  is the preliminary version of this paper","FPGA 2021",,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deploying deep learning models on embedded systems has been challenging due
to limited computing resources. The majority of existing work focuses on
accelerating image classification, while other fundamental vision problems,
such as object detection, have not been adequately addressed. Compared with
image classification, detection problems are more sensitive to the spatial
variance of objects, and therefore, require specialized convolutions to
aggregate spatial information. To address this need, recent work introduces
dynamic deformable convolution to augment regular convolutions. However, this
will lead to inefficient memory accesses of inputs with existing hardware. In
this work, we harness the flexibility of FPGAs to develop a novel object
detection pipeline with deformable convolutions. We show the speed-accuracy
tradeoffs for a set of algorithm modifications including irregular-access
versus limited-range and fixed-shape. We then Co-Design a Network CoDeNet with
the modified deformable convolution and quantize it to 4-bit weights and 8-bit
activations. With our high-efficiency implementation, our solution reaches 26.9
frames per second with a tiny model size of 0.76 MB while achieving 61.7 AP50
on the standard object detection dataset, Pascal VOC. With our higher accuracy
implementation, our model gets to 67.1 AP50 on Pascal VOC with only 2.9 MB of
parameters-20.9x smaller but 10% more accurate than Tiny-YOLO.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 17:56:47 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 22:35:57 GMT""}]","2021-01-27"
"2006.08375","Oleksandr Kliushnichenko","S.P. Lukyanets, I.S. Gandzha, and O.V. Kliushnichenko","Modeling and Controlling the Spread of Epidemic with Various Social and
  Economic Scenarios","14 pages, 6 figures, 5 tables","Chaos Soliton Frac. (2021), v. 148, 111046","10.1016/j.chaos.2021.111046",,"physics.soc-ph econ.GN q-bio.PE q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  We propose a dynamical model for describing the spread of epidemics. This
model is an extension of the SIQR (susceptible-infected-quarantined-recovered)
and SIRP (susceptible-infected-recovered-pathogen) models used earlier to
describe various scenarios of epidemic spreading. As compared to the basic SIR
model, our model takes into account two possible routes of contagion
transmission: direct from the infected compartment to the susceptible
compartment and indirect via some intermediate medium or fomites. Transmission
rates are estimated in terms of average distances between the individuals in
selected social environments and characteristic time spans for which the
individuals stay in each of these environments. We also introduce a collective
economic resource associated with the average amount of money or income per
individual to describe the socioeconomic interplay between the spreading
process and the resource available to infected individuals. The
epidemic-resource coupling is supposed to be of activation type, with the
recovery rate governed by the Arrhenius-like law. Our model brings an advantage
of building various control strategies to mitigate the effect of epidemic and
can be applied, in particular, to modeling the spread of COVID-19.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:52:58 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 13:12:10 GMT""}]","2022-12-08"
"2006.08601","Samuel Lerman","Samuel Lerman, Chenliang Xu, Charles Venuto, Henry Kautz","Explaining Local, Global, And Higher-Order Interactions In Deep Learning","Presented at ICCV, 2021","Proceedings of the IEEE/CVF International Conference on Computer
  Vision (ICCV), 2021, pp. 1224-1233",,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a simple yet highly generalizable method for explaining
interacting parts within a neural network's reasoning process. First, we design
an algorithm based on cross derivatives for computing statistical interaction
effects between individual features, which is generalized to both 2-way and
higher-order (3-way or more) interactions. We present results side by side with
a weight-based attribution technique, corroborating that cross derivatives are
a superior metric for both 2-way and higher-order interaction detection.
Moreover, we extend the use of cross derivatives as an explanatory device in
neural networks to the computer vision setting by expanding Grad-CAM, a popular
gradient-based explanatory tool for CNNs, to the higher order. While Grad-CAM
can only explain the importance of individual objects in images, our method,
which we call Taylor-CAM, can explain a neural network's relational reasoning
across multiple objects. We show the success of our explanations both
qualitatively and quantitatively, including with a user study. We will release
all code as a tool package to facilitate explainable deep learning.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:13:27 GMT""},{""version"":""v2"",""created"":""Wed, 4 Nov 2020 17:06:53 GMT""},{""version"":""v3"",""created"":""Sun, 25 Jul 2021 17:14:43 GMT""},{""version"":""v4"",""created"":""Fri, 24 Sep 2021 16:11:47 GMT""}]","2021-10-12"
"2006.08602","Alex Wong","Alex Wong, Safa Cicek, Stefano Soatto","Targeted Adversarial Perturbations for Monocular Depth Prediction",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the effect of adversarial perturbations on the task of monocular
depth prediction. Specifically, we explore the ability of small, imperceptible
additive perturbations to selectively alter the perceived geometry of the
scene. We show that such perturbations can not only globally re-scale the
predicted distances from the camera, but also alter the prediction to match a
different target scene. We also show that, when given semantic or instance
information, perturbations can fool the network to alter the depth of specific
categories or instances in the scene, and even remove them while preserving the
rest of the scene. To understand the effect of targeted perturbations, we
conduct experiments on state-of-the-art monocular depth prediction methods. Our
experiments reveal vulnerabilities in monocular depth prediction networks, and
shed light on the biases and context learned by them.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:29:43 GMT""},{""version"":""v2"",""created"":""Tue, 8 Dec 2020 22:28:46 GMT""}]","2020-12-10"
"2006.08603","Mohammad Athar SAJJAD","M. Sajjad Athar and Jorge G. Morfin","Neutrino (Antineutrino)-Nucleus Interactions in the Shallow- and
  Deep-Inelastic Scattering Regions","110 pages, 58 figures, Invited Review Article in Journal of Physics
  G: Nuclear and Particle Physics - IOPscience (Accepted for Publication)",,,,"hep-ph hep-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In $\nu/\bar{\nu}$-N/A interactions SIS is technically defined in terms of
the four-momentum transfer to the hadronic system as non-resonant meson
production with $Q^2 \lessapprox 1~GeV^2$. This non-resonant meson production
intermixes with resonant meson production in a regime of similar effective
hadronic mass W of the interaction. As $Q^2$ grows and surpasses this $\approx
1~GeV^2$ limit, non-resonant interactions begin to take place with quarks
within the nucleon indicating the start of DIS region. SIS and DIS regions have
received varying degrees of attention from the community. While the theoretical
/ phenomenological study of $\nu$-nucleon and $\nu$-nucleus DIS scattering is
advanced, such studies of a large portion of the SIS region, particularly the
SIS to DIS transition region, have hardly begun. Experimentally, the SIS and
the DIS regions for $\nu$-nucleon scattering have minimal results and only in
the experimental study of the $\nu$-nucleus DIS region are there significant
results for some nuclei. Since current and future neutrino oscillation
experiments have contributions from both higher W SIS and DIS kinematic regions
and these regions are in need of both considerable theoretical and experimental
study, this review will concentrate on these SIS to DIS transition and DIS
kinematic regions surveying our knowledge and the current challenges.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 09:19:00 GMT""}]","2020-06-17"
"2006.08768","Tatiana Valentine Guy","Eli\v{s}ka Zugarov\'a and Tatiana V. Guy","Similarity-based transfer learning of decision policies",,,,,"cs.LG cs.AI cs.SY eess.SY stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A problem of learning decision policy from past experience is considered.
Using the Fully Probabilistic Design (FPD) formalism, we propose a new general
approach for finding a stochastic policy from the past data.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 16:39:54 GMT""}]","2020-06-17"
"2006.08841","Sajad Mousavi","Sajad Mousavi, Fatemeh Afghah, Fatemeh Khadem, U. Rajendra Acharya","ECG Language Processing (ELP): a New Technique to Analyze ECG Signals",,,,,"eess.SP q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A language is constructed of a finite/infinite set of sentences composing of
words. Similar to natural languages, Electrocardiogram (ECG) signal, the most
common noninvasive tool to study the functionality of the heart and diagnose
several abnormal arrhythmias, is made up of sequences of three or four distinct
waves including the P-wave, QRS complex, T-wave and U-wave. An ECG signal may
contain several different varieties of each wave (e.g., the QRS complex can
have various appearances). For this reason, the ECG signal is a sequence of
heartbeats similar to sentences in natural languages) and each heartbeat is
composed of a set of waves (similar to words in a sentence) of different
morphologies. Analogous to natural language processing (NLP) which is used to
help computers understand and interpret the human's natural language, it is
possible to develop methods inspired by NLP to aid computers to gain a deeper
understanding of Electrocardiogram signals. In this work, our goal is to
propose a novel ECG analysis technique, \textit{ECG language processing (ELP)},
focusing on empowering computers to understand ECG signals in a way physicians
do. We evaluated the proposed method on two tasks including the classification
of heartbeats and the detection of atrial fibrillation in the ECG signals.
Experimental results on three databases (i.e., PhysionNet's MIT-BIH, MIT-BIH
AFIB and PhysioNet Challenge 2017 AFIB Dataset databases) reveal that the
proposed method is a general idea that can be applied to a variety of
biomedical applications and is able to achieve remarkable performance.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:42:05 GMT""}]","2020-06-17"
"2006.09169","Ashok Singal","Ashok K. Singal","A discontinuity in the electromagnetic field of a uniformly accelerated
  charge","10 pages, 5 figures","J._Phys._Commun. 4, 095023 (2020)","10.1088/2399-6528/abb9c7",,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The electric field of a uniformly accelerated charge shows a plane of
discontinuity, where the field extending only on one side of the plane,
terminates abruptly on the plane with a finite value. This indicates a non-zero
divergence of the electric field in a source-free region, implying a violation
of Gauss law. In order to make the field compliant with Maxwell's equations
everywhere, an additional field component, proportional to a $\delta$-function
at the plane of discontinuity, is required. Such a ""$\delta$-field"" might be
the electromagnetic field of the charge, moving with a uniform velocity
approaching $c$, the speed of light, prior to the imposition of acceleration at
infinity. However, some attempts to derive this $\delta$-field for such a case,
have not been entirely successful. Some of the claims of the derivation involve
elaborate calculations with some not-so-obvious mathematical approximations.
Since the result to be derived is already known from the constraint of its
compliance with Maxwell's equations, and the derivation involves the familiar
text-book expressions for the field of a uniformly moving charge, one would
expect an easy, simple approach, to lead to the correct result. Here, starting
from the electromagnetic field of a uniformly accelerated charge in the
instantaneous rest frame, in terms of the position and motion of the charge at
the retarded time, we derive this $\delta$-field, consistent with Maxwell's
equations, in a fairly simple manner. This is followed by a calculation of the
energy in the $\delta$-field, in an analytical manner without making any
approximation, where we show that this energy is exactly the one that would be
lost by the charge because of the radiation reaction on the charge,
proportional to its rate of change of acceleration, that was imposed on it at a
distant past.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 12:45:44 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 08:50:17 GMT""},{""version"":""v3"",""created"":""Mon, 29 Jun 2020 11:40:44 GMT""},{""version"":""v4"",""created"":""Thu, 8 Oct 2020 15:40:59 GMT""}]","2020-10-09"
"2006.09172","Alireza Amani","A. Pourbagher and Alireza Amani","Thermodynamics of the viscous $f(T, B)$ gravity in the new agegraphic
  dark energy model","18 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:1908.11595",,"10.1142/S0217732320501667",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we first obtain the energy density by the approach of the new
agegraphic dark energy model, and then the $f(T,B)$ gravity model is studied as
an alternative to the dark energy in a viscous fluid by flat-FRW background, in
which $T$ and $B$ are torsion scalar and boundary term. The Friedmann equations
will obtain in the framework of modified teleparallel gravity by tetrad
components. We consider that the universe dominates with components such as
matter and dark energy by an interacting model. The Hubble parameter is
parameterized by the power-law for the scale factor, and then we fit the
corresponding Hubble parameter with observational data constraints. The
variation of the equation of state (EoS) for dark energy is plotted as a
function of the redshift parameter, and the accelerated expansion of the
universe is explored. In what follows, the stability of the model is also
studied on the base of the sound speed parameter. Finally, the generalized
second law of thermodynamics is investigated by entropies of inside and on the
boundary of the apparent horizon in thermodynamics equilibrium.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 05:40:30 GMT""}]","2020-06-17"
"2006.09173","Marly Gotti","Marly Gotti","Atomicity and Factorization of Puiseux Monoids","108 pages. arXiv admin note: text overlap with arXiv:1908.09227",,,,"math.AC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A Puiseux monoid is an additive submonoid of the nonnegative cone of rational
numbers. Although Puiseux monoids are torsion-free rank-one monoids, their
atomic structure is rich and highly complex. For this reason, they have been
important objects to construct crucial examples in commutative algebra and
factorization theory. In 1974 Anne Grams used a Puiseux monoid to construct the
first example of an atomic domain not satisfying the ACCP, disproving Cohn's
conjecture that every atomic domain satisfies the ACCP. Even recently, Jim
Coykendall and Felix Gotti have used Puiseux monoids to construct the first
atomic monoids with monoid algebras (over a field) that are not atomic,
answering a question posed by Robert Gilmer back in the 1980s.
  This dissertation is focused on the investigation of the atomic structure and
factorization theory of Puiseux monoids. Here we established various sufficient
conditions for a Puiseux monoid to be atomic (or satisfy the ACCP). We do the
same for two of the most important atomic properties: the finite-factorization
property and the bounded-factorization property. Then we compare these four
atomic properties in the context of Puiseux monoids. This leads us to construct
and study several classes of Puiseux monoids with distinct atomic structure.
Our investigation provides sufficient evidence to believe that the class of
Puiseux monoids is the simplest class with enough complexity to find monoids
satisfying almost every fundamental atomic behavior.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 04:59:40 GMT""}]","2020-06-17"
"2006.09177","Daniel C. Mayer","Daniel C. Mayer","Schur sigma-groups with abelian quotient invariants (9,3)","9 pages, 2 tables",,,,"math.GR math.NT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  By the construction of suitable non-metabelian Schur sigma-groups S of type
(9,3) with log order lo(S) = 21 and nilpotency class cl(S) = 9, evidence is
provided of a new class of imaginary quadratic fields K with 3-class group
Cl(3,K) ~ C(9) * C(3) and punctured principalization type kappa ~ (1,4,4;4)
whose 3-class field tower consists of precisely three stages. In contrast,
previous examples of three-stage towers were associated with kappa in {
(1,1,2;2), (1,1,2;3), (1,1,4;2), (1,2,3;1) }, lo(S) = 9 and cl(S) = 5.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 19:22:18 GMT""}]","2020-06-17"
"2006.09178","Jingjing Bu","Jingjing Bu, Afshin Mesbahi, Mehran Mesbahi","Policy Gradient-based Algorithms for Continuous-time Linear Quadratic
  Control","arXiv admin note: substantial text overlap with arXiv:1907.08921",,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the continuous-time Linear-Quadratic-Regulator (LQR) problem in
terms of optimizing a real-valued matrix function over the set of feedback
gains. The results developed are in parallel to those in Bu et al. [1] for
discrete-time LTI systems. In this direction, we characterize several
analytical properties (smoothness, coerciveness, quadratic growth) that are
crucial in the analysis of gradient-based algorithms. We also point out
similarities and distinctive features of the continuous time setup in
comparison with its discrete time analogue. First, we examine three types of
well-posed flows direct policy update for LQR: gradient flow, natural gradient
flow and the quasi-Newton flow. The coercive property of the corresponding cost
function suggests that these flows admit unique solutions while the gradient
dominated property indicates that the underling Lyapunov functionals decay at
an exponential rate; quadratic growth on the other hand guarantees that the
trajectories of these flows are exponentially stable in the sense of Lyapunov.
We then discuss the forward Euler discretization of these flows, realized as
gradient descent, natural gradient descent and quasi-Newton iteration. We
present stepsize criteria for gradient descent and natural gradient descent,
guaranteeing that both algorithms converge linearly to the global optima. An
optimal stepsize for the quasi-Newton iteration is also proposed, guaranteeing
a $Q$-quadratic convergence rate--and in the meantime--recovering the
Kleinman-Newton iteration. Lastly, we examine LQR state feedback synthesis with
a sparsity pattern. In this case, we develop the necessary formalism and
insights for projected gradient descent, allowing us to guarantee a sublinear
rate of convergence to a first-order stationary point.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 23:23:50 GMT""}]","2020-06-17"
"2006.09180","Alejandro Gangui","Alejandro Gangui, Juan Antonio Belmonte","The development of a utopian city? Comparing land- and skyscapes in
  Santa Cruz de Tenerife and San Cristobal de la Laguna","PDF document including 1 table and 3 figures. arXiv admin note:
  substantial text overlap with arXiv:2003.12410","Mediterranean Archaeology and Archaeometry 18: 53-57, 2018",,,"physics.hist-ph astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the peculiar planning of the city of San Cristobal de La Laguna,
in the Canary Island of Tenerife (Spain), when compared to the nearby and
essentially contemporary Santa Cruz de Tenerife, which served as a maritime
port of the former city. For this we review our previous study of the exact
spatial orientation of twenty-one historic Christian churches currently
existing in the old part of La Laguna, which we compare with the analysis of
six similar buildings located in Santa Cruz, and presented here for the first
time. In both cities, we take the spatial orientation of historic churches as
good indicators of the original layout of the respective urban lattices.
Although we find a clear orientation pattern for La Laguna, which singles out
an absolute-value astronomical declination slightly below 20 degrees, pointing
to a preferred date close to the July 25th feast-day of San Cristobal de Licia,
in the case of Santa Cruz this trend is not followed. On the contrary, the
pattern we find for Santa Cruz, within the uncertainties due to the low
statistics, and apart from one equinoctial and one solstitial oriented
churches, is consistent with an orographic orientation within the canonic
limits of sunrise. This result highlights the uniqueness of the city of La
Laguna, and supports the idea suggesting its deliberate planning in the early
16th century.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:19:57 GMT""}]","2020-06-17"
"2006.09818","Nathaniel Barlow","Steven J. Weinstein, Morgan S. Holland, Kelly E. Rogers, Nathaniel S.
  Barlow","Analytic solution of the SEIR epidemic model via asymptotic approximant","original version had substantial text overlap with arXiv:2004.07833;
  this is now less so",,"10.1016/j.physd.2020.132633",,"q-bio.PE physics.soc-ph","http://creativecommons.org/licenses/by-sa/4.0/","  An analytic solution is obtained to the SEIR Epidemic Model. The solution is
created by constructing a single second-order nonlinear differential equation
in $\ln S$ and analytically continuing its divergent power series solution such
that it matches the correct long-time exponential damping of the epidemic
model. This is achieved through an asymptotic approximant (Barlow et. al, 2017,
Q. Jl Mech. Appl. Math, 70 (1), 21-48) in the form of a modified symmetric
Pad\'e approximant that incorporates this damping. The utility of the
analytical form is demonstrated through its application to the COVID-19
pandemic.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 20:18:44 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 01:52:51 GMT""}]","2020-07-01"
"2006.09846","Muji Gunarto","Muji Gunarto and Ratih Hurriyati","Creating Experience value to build student satisfaction in higher
  education","11 page. Dinasti International Journal of Education Management and
  Social Science (February 2020)",,"10.31933/dijemss.v1i3.166",,"physics.ed-ph cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Higher education products or services received by students are experiential
values. The purpose of this study is how to create the values of student
experience so that student satisfaction arises. Higher education should now
focus on students by creating strong ties with students and alumni. This
research was conducted with a survey confirmatory approach. The survey was
conducted at 32 universities in South Sumatra Province, Indonesia with a total
sample of 357 students. The sampling technique used was stratified random
sampling and data analysis using structural equation modeling (SEM) analysis.
The results showed that the values of experience in HE were formed through
increased cocreation in HE, where students were directly involved in various
campus activities. High co-creation shows that there is a stronger attachment
of students to HE and a higher value of student experience. Co-creation does
not directly affect student satisfaction, but it does indirectly affect
experience value. If the value of experience is higher, student satisfaction
will also be higher.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 15:29:41 GMT""}]","2020-06-18"
"2006.09974","Sorina Lazanu","Ionel Lazanu, Sorina Lazanu and Mihaela P\^arvu","About detecting very low mass black holes in LAr detectors","substantially improved version","JCAP 10 (2020) 046","10.1088/1475-7516/2020/10/046",,"hep-ph astro-ph.IM physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nature of dark matter is still an open problem. The simplest assumption
is that gravity is the only force coupled certainly to dark matter and thus the
micro black holes could be a viable candidate. We investigated the possibility
of direct detection of micro black holes with masses around and upward the
Planck scale (10$^{-5}$ g), ensuring classical gravitational treatment of these
objects in the next generation of huge LAr detectors. We show that the signals
(ionization and scintillation) produced in LAr enable the discrimination
between micro black holes or other particles. It is expected that the
trajectories of these micro black holes will appear as crossing the whole
active medium, in any direction, producing uniform ionization and scintillation
on all the path.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:43:58 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 05:54:17 GMT""}]","2020-10-23"
"2006.10161","Kolahal Bhattacharya","Kolahal Bhattacharya","Can magnetic field be used to reduce cosmic charged particles background
  to low energy particle detectors?","14 pages, 17 figures, 6 tables",,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The possibility to reduce the background due to cosmic ray charged particles
by the use of magnetic field in the ground based low energy particle detectors
is explored. The degree of reduction of cosmic rays as a function of the
magnetic field strength and its depth is quantified.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 14:46:47 GMT""}]","2020-06-19"
"2006.10488","Abhishek Pandey","Abhishek Pandey, Sudhakar V. Nuti, Pratha Sah, Chad R. Wells, Alison
  P. Galvani, Jeffrey P. Townsend","The effect of extended closure of red-light areas on COVID-19
  transmission in India",,,,,"physics.soc-ph q-bio.PE","http://creativecommons.org/licenses/by-sa/4.0/","  The novel coronavirus disease (COVID-19) pandemic has resulted in over
200,000 cases in India. Thus far, India has implemented lockdown measures to
curb disease transmission. However, commercial sex work in red-light areas
(RLAs) has potential to lead to COVID-19 resurgence after lockdown. We
developed a model of COVID-19 transmission in RLAs, evaluating the impact of
extended RLA closure compared with RLA reopening on cases, hospitalizations,
and mortality rates within the RLAs of five major Indian cities, within the
cities, and across India. Closure lowered transmission at all scales. More than
90% of cumulative cases and deaths among RLA residents of Kolkata, Pune, and
Nagpur could be averted by the time the epidemic would peak under a re-opening
scenario. Across India, extended closure of RLAs would benefit the population
at large, delaying the peak of COVID-19 cases by 8 to 23 days, and avert 32% to
60.2% of cumulative cases and 43% to 67.6% of cumulative deaths at the peak of
the epidemic. Extended closure of RLAs until better prevention and treatment
strategies are developed would benefit public health in India.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 18:22:19 GMT""}]","2020-06-19"
"2006.11161","Aman Chadha Mr.","Aman Chadha, John Britto, and M. Mani Roja","iSeeBetter: Spatio-temporal video super-resolution using recurrent
  generative back-projection networks","11 pages, 6 figures, 4 tables, Project Page:
  https://iseebetter.amanchadha.com/","Springer Journal of Computational Visual Media, Tsinghua
  University Press, 6(3):307-317, 2020","10.1007/s41095-020-0175-7",,"cs.CV cs.AI cs.LG cs.MM eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, learning-based models have enhanced the performance of single-image
super-resolution (SISR). However, applying SISR successively to each video
frame leads to a lack of temporal coherency. Convolutional neural networks
(CNNs) outperform traditional approaches in terms of image quality metrics such
as peak signal to noise ratio (PSNR) and structural similarity (SSIM). However,
generative adversarial networks (GANs) offer a competitive advantage by being
able to mitigate the issue of a lack of finer texture details, usually seen
with CNNs when super-resolving at large upscaling factors. We present
iSeeBetter, a novel GAN-based spatio-temporal approach to video
super-resolution (VSR) that renders temporally consistent super-resolution
videos. iSeeBetter extracts spatial and temporal information from the current
and neighboring frames using the concept of recurrent back-projection networks
as its generator. Furthermore, to improve the ""naturality"" of the
super-resolved image while eliminating artifacts seen with traditional
algorithms, we utilize the discriminator from super-resolution generative
adversarial network (SRGAN). Although mean squared error (MSE) as a primary
loss-minimization objective improves PSNR/SSIM, these metrics may not capture
fine details in the image resulting in misrepresentation of perceptual quality.
To address this, we use a four-fold (MSE, perceptual, adversarial, and
total-variation (TV)) loss function. Our results demonstrate that iSeeBetter
offers superior VSR fidelity and surpasses state-of-the-art performance.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:36:30 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 20:34:00 GMT""},{""version"":""v3"",""created"":""Sat, 29 Aug 2020 21:38:05 GMT""},{""version"":""v4"",""created"":""Wed, 30 Sep 2020 00:45:38 GMT""}]","2020-10-01"
"2006.11252","Pinaki Patra","Kalpana Biswas, Jyoti Prasad Saha, Pinaki Patra","Generalized Lewis-Riesenfeld invariance for dynamical effective mass in
  jammed granullar media under a potential well in non-commutative space","Serious flaw in Physical interpretation of the result is reported by
  the anonymous referees. Authors are in complete agreement of the flaws",,,,"physics.gen-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consideration of the asteroid belt (Kuiper belt) as a jammed-granular media
establishes a bridge between condensed matter physics and astrophysics. It
opens up an experimental possibility to determine the deformation parameters
for noncommutative space-time. Dynamics of the Kuiper belt can be simplified as
dynamics of a dynamical effective mass for a jammed granular media under a
gravitational well. Alongside, if one considers the space-time to be
noncommutative, then an experimental model for the determination of the
deformation parameters for noncommutative space-time can be done.
  The construction of eigenfunctions and invariance for this model is in
general a tricky problem. We have utilized the Lewis-Riesenfeld invariant
method to determine the invariance for this time-dependent quantum system. In
this article, we have shown that a class of generalized time-dependent
Lewis-Riesenfeld invariant operators exist for the system with dynamical
effective mass in jammed granular media under a potential well in
noncommutative space. To keep the discussion fairly general, we have considered
both position-position and momentum-momentum noncommutativity. Since, up to a
time-dependent phase-factor, the eigenfunctions of the invariant operator will
satisfy the time-dependent Schr\""{o}dinger equation for the time-dependent
Hamiltonian of the system, the construction of the invariant operator fairly
solve the problem mathematically, the results of which can be utilized to
demonstrate an experiment.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 13:47:11 GMT""},{""version"":""v2"",""created"":""Mon, 24 Apr 2023 20:45:21 GMT""}]","2023-04-26"
"2006.11392","Huazhu Fu","Deng-Ping Fan, Ge-Peng Ji, Tao Zhou, Geng Chen, Huazhu Fu, Jianbing
  Shen, Ling Shao","PraNet: Parallel Reverse Attention Network for Polyp Segmentation","Accepted to MICCAI 2020",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Colonoscopy is an effective technique for detecting colorectal polyps, which
are highly related to colorectal cancer. In clinical practice, segmenting
polyps from colonoscopy images is of great importance since it provides
valuable information for diagnosis and surgery. However, accurate polyp
segmentation is a challenging task, for two major reasons: (i) the same type of
polyps has a diversity of size, color and texture; and (ii) the boundary
between a polyp and its surrounding mucosa is not sharp. To address these
challenges, we propose a parallel reverse attention network (PraNet) for
accurate polyp segmentation in colonoscopy images. Specifically, we first
aggregate the features in high-level layers using a parallel partial decoder
(PPD). Based on the combined feature, we then generate a global map as the
initial guidance area for the following components. In addition, we mine the
boundary cues using a reverse attention (RA) module, which is able to establish
the relationship between areas and boundary cues. Thanks to the recurrent
cooperation mechanism between areas and boundaries, our PraNet is capable of
calibrating any misaligned predictions, improving the segmentation accuracy.
Quantitative and qualitative evaluations on five challenging datasets across
six metrics show that our PraNet improves the segmentation accuracy
significantly, and presents a number of advantages in terms of
generalizability, and real-time segmentation efficiency.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 08:13:43 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 16:39:51 GMT""},{""version"":""v3"",""created"":""Tue, 30 Jun 2020 10:30:19 GMT""},{""version"":""v4"",""created"":""Fri, 3 Jul 2020 13:14:44 GMT""}]","2020-07-06"
"2006.11403","Soroush Vosoughi Dr","Lili Wang, Ruibo Liu, and Soroush Vosoughi","Salienteye: Maximizing Engagement While Maintaining Artistic Style on
  Instagram Using Deep Neural Networks","Proceedings of the 2020 International Conference on Multimedia
  Retrieval. 2020",,"10.1145/3372278.3390736",,"cs.CV cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Instagram has become a great venue for amateur and professional photographers
alike to showcase their work. It has, in other words, democratized photography.
Generally, photographers take thousands of photos in a session, from which they
pick a few to showcase their work on Instagram. Photographers trying to build a
reputation on Instagram have to strike a balance between maximizing their
followers' engagement with their photos, while also maintaining their artistic
style. We used transfer learning to adapt Xception, which is a model for object
recognition trained on the ImageNet dataset, to the task of engagement
prediction and utilized Gram matrices generated from VGG19, another object
recognition model trained on ImageNet, for the task of style similarity
measurement on photos posted on Instagram. Our models can be trained on
individual Instagram accounts to create personalized engagement prediction and
style similarity models. Once trained on their accounts, users can have new
photos sorted based on predicted engagement and style similarity to their
previous work, thus enabling them to upload photos that not only have the
potential to maximize engagement from their followers but also maintain their
style of photography. We trained and validated our models on several Instagram
accounts, showing it to be adept at both tasks, also outperforming several
baseline models and human annotators.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 01:58:02 GMT""}]","2020-06-23"
"2006.12254","Michael Pinsker","Manuel Bodirsky, Antoine Mottet, Miroslav Ol\v{s}\'ak, Jakub
  Opr\v{s}al, Michael Pinsker, Ross Willard","\omega-categorical structures avoiding height 1 identities","24 pages. arXiv admin note: text overlap with arXiv:1901.04237",,"10.1090/tran/8179",,"math.LO cs.LO math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The algebraic dichotomy conjecture for Constraint Satisfaction Problems
(CSPs) of reducts of (infinite) finitely bounded homogeneous structures states
that such CSPs are polynomial-time tractable if the model-complete core of the
template has a pseudo-Siggers polymorphism, and NP-complete otherwise.
  One of the important questions related to the dichotomy conjecture is
whether, similarly to the case of finite structures, the condition of having a
pseudo-Siggers polymorphism can be replaced by the condition of having
polymorphisms satisfying a fixed set of identities of height 1, i.e.,
identities which do not contain any nesting of functional symbols. We provide a
negative answer to this question by constructing for each non-trivial set of
height 1 identities a structure within the range of the conjecture whose
polymorphisms do not satisfy these identities, but whose CSP is tractable
nevertheless.
  An equivalent formulation of the dichotomy conjecture characterizes
tractability of the CSP via the local satisfaction of non-trivial height 1
identities by polymorphisms of the structure. We show that local satisfaction
and global satisfaction of non-trivial height 1 identities differ for
$\omega$-categorical structures with less than doubly exponential orbit growth,
thereby resolving one of the main open problems in the algebraic theory of such
structures.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 09:08:28 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jan 2021 10:40:18 GMT""}]","2021-01-12"
"2006.13140","Zohreh Kaheh","Zohreh Kaheh, Reza Baradaran Kazemzadeh, Ellips Masehian, Ali
  Husseinzadeh Kashan","A Mathematical Negotiation Mechanism for Distributed Procurement
  Problems and a Hybrid Algorithm for its Solution","26 pages, 6 figures",,"10.24200/J65.2018.20035",,"cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a mathematical negotiation mechanism is designed to minimize
the negotiators' costs in a distributed procurement problem at two echelons of
an automotive supply chain. The buyer's costs are procurement cost and shortage
penalty in a one-period contract. On the other hand, the suppliers intend to
solve a multi-period, multi-product production planning to minimize their
costs. Such a mechanism provides an alignment among suppliers' production
planning and order allocation, also supports the partnership with the valued
suppliers by taking suppliers' capacities into account. Such a circumstance has
been modeled via bi-level programming, in which the buyer acts as a leader, and
the suppliers individually appear as followers in the lower level. To solve
this nonlinear bi-level programming model, a hybrid algorithm by combining the
particle swarm optimization (PSO) algorithm with a heuristic algorithm based on
A search is proposed. The heuristic A algorithm is embedded to solve the
mixed-integer nonlinear programming (MINLP) sub-problems for each supplier
according to the received variable values determined by PSO system particles
(buyer's request for quotations (RFQs)). The computational analyses have shown
that the proposed hybrid algorithm called PSO-A outperforms PSO-SA and
PSO-Greedy algorithms.
","[{""version"":""v1"",""created"":""Fri, 12 Jun 2020 21:05:16 GMT""},{""version"":""v2"",""created"":""Wed, 23 Sep 2020 16:01:37 GMT""},{""version"":""v3"",""created"":""Sat, 18 Dec 2021 00:27:35 GMT""}]","2021-12-21"
"2006.13688","Hsin-Chieh Liao","Hsin-Chieh Liao","Signed Countings of Type B and D Permutations and $t,q$-Euler numbers","Author's MSc thesis. It is an extension of arXiv:1708.05518, some new
  results and conjectures are added",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A classical result states that the parity balance of the number of excedances
of all permutations (derangements, respectively) of length $n$ is the Euler
number. In 2010, Josuat-Verg\`{e}s gives a $q$-analogue with $q$ representing
the number of crossings. We extend this result to the permutations
(derangements, respectively) of type B and D. It turns out that the signed
countings are related to the derivative polynomials of $\tan$ and $\sec$.
  Springer numbers defined by Springer can be regarded as an analogue of Euler
numbers defined on every Coxeter group. In 1992 Arnol'd showed that the
Springer numbers of classical types A, B, D count various combinatorial
objects, called snakes. In 1999 Hoffman found that derivative polynomials of
$\sec x$ and $\tan x$ and their subtraction evaluated at certain values count
exactly the number of snakes of certain types. Then Josuat-Verg\`{e}s studied
the $(t,q)$-analogs of derivative polynomials $Q_n(t,q)$, $R_n(t,q)$ and showed
that as setting $q=1$ the polynomials are enumerators of snakes with respect to
the number of sign-changing. Our second result is to find combinatorial
interpretations of $Q_n(t,q)$ and $R_n(t,q)$ as enumerators of the snakes,
although the outcome is somewhat messy.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 05:15:02 GMT""}]","2020-06-25"
"2006.13691","Valay Agarawal","Valay Agarawal and Anish Chakraborty and Rahul Maitra","Stability analysis of a double similarity transformed coupled cluster
  theory","The main manuscript file contains 8 pages and 6 figures",,,,"cond-mat.stat-mech nlin.CD physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we have analysed the time series associated with the iterative
scheme of a double similarity transformed Coupled Cluster theory. The coupled
iterative scheme to solve the ground state Schr{\""o}dinger equation is cast as
a multivariate time-discrete map, the solutions show the universal Feigenbaum
dynamics. Using recurrence analysis, it is shown that the dynamics of the
iterative process is dictated by a small subgroup of cluster operators, mostly
those involving chemically active orbitals, whereas all other cluster operators
with smaller amplitudes are enslaved. Using Synergetics, we will indicate how
the master-slave dynamics can suitably be exploited to develop a novel
coupled-cluster algorithm in a much-reduced dimension.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 13:08:12 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jul 2020 10:35:10 GMT""}]","2020-07-29"
"2006.16915","Hanshuang Tong","Hanshuang Tong, Zhen Wang, Yun Zhou, Shiwei Tong, Wenyuan Han, Qi Liu","HGKT: Introducing Hierarchical Exercise Graph for Knowledge Tracing","10 pages, 11 figures, accepted by SIGIR 2022",,,,"cs.CY cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge tracing (KT) which aims at predicting learner's knowledge mastery
plays an important role in the computer-aided educational system. In recent
years, many deep learning models have been applied to tackle the KT task, which
have shown promising results. However, limitations still exist. Most existing
methods simplify the exercising records as knowledge sequences, which fail to
explore rich information that existed in exercises. Besides, the existing
diagnosis results of knowledge tracing are not convincing enough since they
neglect prior relations between exercises. To solve the above problems, we
propose a hierarchical graph knowledge tracing model called HGKT to explore the
latent hierarchical relations between exercises. Specifically, we introduce the
concept of problem schema to construct a hierarchical exercise graph that could
model the exercise learning dependencies. Moreover, we employ two attention
mechanisms to highlight the important historical states of learners. In the
testing stage, we present a K&S diagnosis matrix that could trace the
transition of mastery of knowledge and problem schema, which can be more easily
applied to different applications. Extensive experiments show the effectiveness
and interpretability of our proposed models.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 07:09:52 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jul 2020 02:43:10 GMT""},{""version"":""v3"",""created"":""Fri, 23 Oct 2020 13:49:28 GMT""},{""version"":""v4"",""created"":""Mon, 8 Feb 2021 12:24:39 GMT""},{""version"":""v5"",""created"":""Wed, 21 Apr 2021 12:22:56 GMT""},{""version"":""v6"",""created"":""Mon, 29 Aug 2022 14:59:42 GMT""}]","2022-08-30"
"2012.00843","Qing-Long Liu","Qing-Long Liu","Pseudo-mass parameterized alchemical equation: a generalisation of the
  molecular Schr\""odinger equation","12 pages",,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a pseudo-mass parameterized Schr\""odinger-like alchemical
equation which contains nuclear charges as variables, treating nuclear charges,
nuclear coordinates and electronic coordinates on the equal footing. The
eigenfunctions of the alchemical equation are the wave functions of nuclear
charges, just like conventional wave functions are of coordinates. A
mathematical definition of alchemical function space is given to hold the
''nuclear charge wave function''. The geometric phase of alchemical dynamics
and alchemical phase space are also derived. For hydrogen-like ion, the
alchemical equation can be simplified into a strong repulsive inverse square
potential equation, which refers to the quantum anomaly and keeps conformal
invariance in non-relativistic quantum mechanics. An extension of the
Hellmann-Feynman theorem, which applies to the non-stationary state in
time-dependent clamped-nuclear-charge alchemical dynamics, is also proved.
","[{""version"":""v1"",""created"":""Sat, 13 Jun 2020 02:06:48 GMT""}]","2020-12-03"
