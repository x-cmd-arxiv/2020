"2006.14509","Jonathan Simone","Jonathan Simone","Using rational homology circles to construct rational homology balls","Added Theorem 1.2, added to exposition, and fixed typos","Topology and its Applications, Vol. 291 (2021)","10.1016/j.topol.2021.107626",,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by Akbulut-Larson's construction of Brieskorn spheres bounding
rational homology 4-balls, we explore plumbed 3-manifolds that bound rational
homology circles and use them to construct infinite families of rational
homology 3-spheres that bound rational homology 4-balls. Some of these rational
homology 3-spheres are new examples of integer homology 3-spheres that bound
rational homology 4-balls, but do not bound integer homology 4-balls. In
particular, we find infinite families of torus bundles over the circle that
bound rational homology circles, provide a simple method for constructing more
general plumbed 3-manifolds that bound rational homology circles, and show
that, for example, $-1$-surgery along any unknotting number one knot $K$ with a
positive crossing that can be switched to unknot $K$ bounds a rational homology
4-ball.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:00:34 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 15:48:45 GMT""},{""version"":""v3"",""created"":""Wed, 4 Nov 2020 18:51:08 GMT""}]","2023-06-09"
"2006.14510","Jakub Marecek","Daniel J. Egger, Claudio Gambella, Jakub Marecek, Scott McFaddin,
  Martin Mevissen, Rudy Raymond, Andrea Simonetto, Stefan Woerner, Elena
  Yndurain","Quantum Computing for Finance: State of the Art and Future Prospects","24 pages","IEEE Transactions on Quantum Engineering, vol. 1, pp. 1-24, 2020,
  Art no. 3101724","10.1109/TQE.2020.3030314",,"quant-ph q-fin.ST","http://creativecommons.org/licenses/by-sa/4.0/","  This article outlines our point of view regarding the applicability,
state-of-the-art, and potential of quantum computing for problems in finance.
We provide an introduction to quantum computing as well as a survey on problem
classes in finance that are computationally challenging classically and for
which quantum computing algorithms are promising. In the main part, we describe
in detail quantum algorithms for specific applications arising in financial
services, such as those involving simulation, optimization, and machine
learning problems. In addition, we include demonstrations of quantum algorithms
on IBM Quantum back-ends and discuss the potential benefits of quantum
algorithms for problems in financial services. We conclude with a summary of
technical challenges and future prospects.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:02:05 GMT""},{""version"":""v2"",""created"":""Thu, 6 Aug 2020 18:10:06 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jan 2021 10:34:36 GMT""}]","2021-01-29"
"2006.14511","Tao Yang","Tao Yang","Model-Independent Perspectives on Coupled Dark Energy and the Swampland","7 pages, 2 figures. The PRD version","Phys. Rev. D 102, 083511 (2020)","10.1103/PhysRevD.102.083511",,"astro-ph.CO gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a general model-independent approach to study the coupled dark
energy and the string Swampland criteria. We show how the dark sector
interaction is degenerated with the equation of state of dark energy in the
context of the expansion of the Universe. With priors for either of them, the
dynamics of dark energy and the dark sector interactions can be reconstructed
together with the bounds of the Swampland criteria. Combining cosmic
chronometers, baryon acoustic oscillation (BAO), and Type Ia supernovae our
results suggest a mild $1 \sigma$ significance of dark sector interactions at
low redshift for the coupled quintessence. The Lyman-$\alpha$ BAO at $z=2.34$
leads a $2 \sigma$ signal of nonzero interactions at high redshift. The
implications for coupled quintessence are discussed.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:04:44 GMT""},{""version"":""v2"",""created"":""Fri, 9 Oct 2020 03:10:57 GMT""}]","2020-10-14"
"2006.14512","Kaizhao Liang","Kaizhao Liang, Jacky Y. Zhang, Boxin Wang, Zhuolin Yang, Oluwasanmi
  Koyejo, Bo Li","Uncovering the Connections Between Adversarial Transferability and
  Knowledge Transferability","Accepted to ICML 2021",,,,"cs.LG cs.AI cs.CV stat.ML","http://creativecommons.org/publicdomain/zero/1.0/","  Knowledge transferability, or transfer learning, has been widely adopted to
allow a pre-trained model in the source domain to be effectively adapted to
downstream tasks in the target domain. It is thus important to explore and
understand the factors affecting knowledge transferability. In this paper, as
the first work, we analyze and demonstrate the connections between knowledge
transferability and another important phenomenon--adversarial transferability,
\emph{i.e.}, adversarial examples generated against one model can be
transferred to attack other models. Our theoretical studies show that
adversarial transferability indicates knowledge transferability and vice versa.
Moreover, based on the theoretical insights, we propose two practical
adversarial transferability metrics to characterize this process, serving as
bidirectional indicators between adversarial and knowledge transferability. We
conduct extensive experiments for different scenarios on diverse datasets,
showing a positive correlation between adversarial transferability and
knowledge transferability. Our findings will shed light on future research
about effective knowledge transfer learning and adversarial transferability
analyses.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:04:47 GMT""},{""version"":""v2"",""created"":""Sat, 12 Jun 2021 19:42:53 GMT""},{""version"":""v3"",""created"":""Tue, 15 Jun 2021 17:14:16 GMT""},{""version"":""v4"",""created"":""Thu, 8 Jul 2021 19:17:09 GMT""}]","2021-07-12"
"2006.14513","Jiejun Hu","Jiejun Hu, Martin Reed, Mays Al-Naday, Nikolaos Thomos","Blockchain-Aided Flow Insertion and Verification in Software Defined
  Networks","9 pages, 6 figures, published in Global Internet of Things Summit
  2020",,"10.1109/GIOTS49054.2020.9119638",,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Internet of Things (IoT) connected by Software Defined Networking (SDN)
promises to bring great benefits to cyber-physical systems. However, the
increased attack surface offered by the growing number of connected vulnerable
devices and complex nature of SDN control plane applications could overturn the
huge benefits of such a system. This paper addresses the vulnerability of some
unspecified security flaw in the SDN control plane application (such as a
zero-day software vulnerability) which can be exploited to insert malicious
flow rules in the switch that do not match network policies. Specifically, we
propose a blockchain-as-a-service (BaaS) based framework that supports switch
flow verification and insertion; and additionally provides straightforward
deployment of blockchain technology within an existing SDN infrastructure.
While use of an external BaaS brings straightforward deployment, it obscures
knowledge of the blockchain agents who are responsible for flow conformance
testing through a smart blockchain contract, leading to potential exploitation.
Thus, we design a strategy to prevent the blockchain agents from acting
arbitrarily, as this would result in what is termed a ""moral hazard"". We
achieve this by developing a novel mathematical model of the fair reward scheme
based on game theory. To understand the performance of our system, we evaluate
our model using a Matlab based simulation framework. The simulation results
demonstrate that the proposed algorithm balances the needs of the blockchain
agents to maximise the overall social welfare, i.e. the sum of profits across
all parties.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:06:19 GMT""}]","2020-06-26"
"2006.14514","Sotirios Sabanis","Attila Lovas, Iosif Lytras, Mikl\'os R\'asonyi, Sotirios Sabanis","Taming neural networks with TUSLA: Non-convex learning via adaptive
  stochastic gradient Langevin algorithms",,,,,"cs.LG math.OC math.PR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial neural networks (ANNs) are typically highly nonlinear systems
which are finely tuned via the optimization of their associated, non-convex
loss functions. In many cases, the gradient of any such loss function has
superlinear growth, making the use of the widely-accepted (stochastic) gradient
descent methods, which are based on Euler numerical schemes, problematic. We
offer a new learning algorithm based on an appropriately constructed variant of
the popular stochastic gradient Langevin dynamics (SGLD), which is called tamed
unadjusted stochastic Langevin algorithm (TUSLA). We also provide a
nonasymptotic analysis of the new algorithm's convergence properties in the
context of non-convex learning problems with the use of ANNs. Thus, we provide
finite-time guarantees for TUSLA to find approximate minimizers of both
empirical and population risks. The roots of the TUSLA algorithm are based on
the taming technology for diffusion processes with superlinear coefficients as
developed in \citet{tamed-euler, SabanisAoAP} and for MCMC algorithms in
\citet{tula}. Numerical experiments are presented which confirm the theoretical
findings and illustrate the need for the use of the new algorithm in comparison
to vanilla SGLD within the framework of ANNs.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:06:22 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 17:54:27 GMT""},{""version"":""v3"",""created"":""Thu, 23 Dec 2021 18:55:58 GMT""},{""version"":""v4"",""created"":""Sun, 15 Jan 2023 14:09:14 GMT""}]","2023-01-18"
"2006.14515","Micha\""el Zamo","Naty Citlali Cabrera-Guti\'errez, Hadrien God\'e, Jean-Christophe
  Jouhaud, Mohamed Chafik Bakkay, Valentin Kivachuk Burd\'a, Florian Dupuy,
  Maud-Alix Mader, Olivier Mestre, Guillaume Oller, Mathieu Serrurier,
  Micha\""el Zamo","Surrogate Models for Rainfall Nowcasting","17 pages, 8 figures",,,,"physics.comp-ph physics.ao-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Nowcasting (or short-term weather forecasting) is particularly important in
the case of extreme events as it helps prevent human losses. Many of our
activities, however, also depend on the weather. Therefore, nowcasting has
shown to be useful in many different domains. Currently, immediate rainfall
forecasts in France are calculated using the Arome-NWC model developed by
M\'et\'eo-France, which is a complex physical model. Arome-NWC forecasts are
stored with a 15 minute time interval. A higher time resolution is, however,
desirable for other meteorological applications. Complex model calculations,
such as Arome-NWC, can be very expensive and time consuming. A surrogate model
aims at producing results which are very close to the ones obtained using a
complex model, but with largely reduced calculation times. Building a surrogate
model requires only a few calculations with the real model. Once the surrogate
model is built, further calculations can be quickly realized. In this study, we
propose to build surrogate models for immediate rainfall forecasts with two
different approaches: combining Proper Orthogonal Decomposition (POD) and
Kriging, or combining POD and Random Forest (RF). We show that results obtained
with our surrogate models are not only close to the ones obtained by Arome-NWC,
but they also have a higher time resolution (1 minute) with a reduced
calculation time.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:06:37 GMT""}]","2020-06-26"
"2006.14516","Kirsten von Bergmann","Gustav Bihlmayer, Jonas Sassmannshausen, Andr\'e Kubetzka, Stefan
  Bl\""ugel, Kirsten von Bergmann, Roland Wiesendanger","Plumbene on a magnetic substrate: a combined STM and DFT study","5 pages, 5 figures","Physical Review Letters 124, 126401 (2020)","10.1103/PhysRevLett.124.126401",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As heavy analog of graphene, plumbene is a two-dimensional material with
strong spin-orbit coupling effects. Using scanning tunneling microscopy (STM),
we observe that Pb forms a flat honeycomb lattice on an Fe monolayer on
Ir(111). In contrast, without the Fe layer, a c(2x4) structure of Pb on Ir(111)
is found. We use density functional theory (DFT) calculations to rationalize
these findings and analyze the impact of the hybridization on the plumbene band
structure. In the unoccupied states the splitting of the Dirac cone by
spin-orbit interaction is clearly observed while in the occupied states of the
freestanding plumbene we find a band inversion that leads to the formation of a
topologically non-trivial gap. Exchange splitting as mediated by the strong
hybridization with the Fe layer drives a quantum spin Hall to quantum anomalous
Hall state transition.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:07:34 GMT""}]","2020-06-26"
"2006.14517","Graham Cox","Thomas John Baird, Paul Cornwell, Graham Cox, Christopher Jones and
  Robert Marangell","Generalized Maslov indices for non-Hamiltonian systems","50 pages, 9 figures; comments welcome! Applications in Sections 4 &5
  have been significantly improved in v2",,,,"math.DS math.AT math.CA math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the definition of the Maslov index to a broad class of
non-Hamiltonian dynamical systems. To do this, we introduce a family of
topological spaces--which we call Maslov-Arnold spaces--that share key
topological features with the Lagrangian Grassmannian, and hence admit a
similar index theory. This family contains the Lagrangian Grassmannian, and
much more. We construct a family of examples, called hyperplane Maslov-Arnold
spaces, that are dense in the Grassmannian, and hence are much larger than the
Lagrangian Grassmannian (which is a submanifold of positive codimension). The
resulting index is then used to study eigenvalue problems for non-symmetric
reaction-diffusion systems. A highlight of our analysis is a topological
interpretation of the Turing instability: the bifurcation that occurs as one
increases the ratio of diffusion coefficients corresponds to a change in the
generalized Maslov index.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:08:52 GMT""},{""version"":""v2"",""created"":""Mon, 20 Sep 2021 23:55:04 GMT""}]","2021-09-22"
"2006.14518","Joseph Chow","Theodoros P. Pantelidis, Joseph Y. J. Chow, Oded Cats","Mobility operator service capacity sharing contract design to risk-pool
  against network disruptions",,,,,"cs.GT cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose a new mechanism to design risk-pooling contracts between operators
to facilitate horizontal cooperation to mitigate those costs and improve
service resilience during disruptions. We formulate a novel two-stage
stochastic multicommodity flow model to determine the cost savings of a
coalition under different disruption scenarios and solve it using L-shaped
method along with sample average approximation. Computational tests of the
L-shaped method against deterministic equivalent method with sample average
approximation are conducted for network instances with up to 64 nodes, 10 OD
pairs, and 1024 scenarios. The results demonstrate that the solution algorithm
only becomes computationally effective for larger size instances (above 128
nodes) and that SAA maintains a close approximation. The proposed model is
applied to a regional multi-operator network in the Randstad area of the
Netherlands, for four operators, 40 origin-destination pairs, and over 1400
links where disruption data is available. Using the proposed method, we
identify stable cost allocations among four operating agencies that could yield
a 66% improvement in overall network performance over not having any
risk-pooling contract in place. Furthermore, the model allows policymakers to
evaluate the sensitivity of any one operator's bargaining power to different
network structures and disruption scenario distributions, as we illustrate for
the HTM operator in Randstad.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:10:02 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 14:50:11 GMT""},{""version"":""v3"",""created"":""Mon, 1 May 2023 17:33:06 GMT""}]","2023-05-02"
"2006.14519","Haji M. Furqan Madni","Abdullateef Almohamad, Anas M. Tahir, Ayman Al-Kababji, Haji M.
  Furqan, Tamer Khattab, Mazen O. Hasna, and Huseyin Arslan","Smart and Secure Wireless Communications via Reflecting Intelligent
  Surfaces: A Short Survey","Accepted for publication in IEEE Open Journal of ComSoc",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the emergence of the internet of things (IoT) technology, wireless
connectivity should be more ubiquitous than ever. In fact, the availability of
wireless connection everywhere comes with security threats that, unfortunately,
cannot be handled by conventional cryptographic solutions alone, especially in
heterogeneous and decentralized future wireless networks. In general, physical
layer security (PLS) helps in bridging this gap by taking advantage of the
fading propagation channel. Moreover, the adoption of reconfigurable
intelligent surfaces (RIS) in wireless networks makes the PLS techniques more
efficient by involving the channel into the design loop. In this paper, we
conduct a comprehensive literature review on the RIS-assisted PLS for future
wireless communications. We start by introducing the basic concepts of RISs and
their different applications in wireless communication networks and the most
common PLS performance metrics. Then, we focus on the review and classification
of RIS-assisted PLS applications, exhibiting multiple scenarios, system models,
objectives, and methodologies. In fact, most of the works in this field
formulate an optimization problem to maximize the secrecy rate (SR) or secrecy
capacity (SC) at a legitimate user by jointly optimizing the beamformer at the
transmitter and the RIS's coefficients, while the differences are in the
adopted methodology to optimally/sub-optimally approach the solution. We
finalize this survey by presenting some insightful recommendations and
suggesting open problems for future research extensions.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:10:28 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 06:48:54 GMT""},{""version"":""v3"",""created"":""Mon, 31 Aug 2020 12:56:29 GMT""},{""version"":""v4"",""created"":""Thu, 10 Sep 2020 11:11:52 GMT""}]","2020-09-11"
"2006.14520","Alfonso Zamora","Carlos Florentino, Azizeh Nozad, Jaime Silva and Alfonso Zamora","On Hodge polynomials of Singular Character Varieties","To appear in the Proceedings of the Special Session on Complex
  Geometry of the ISAAC conference, Aveiro, Portugal (2019)",,,,"math.AG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathcal{X}_{\Gamma}G:=\mathrm{Hom}(\Gamma,G)/\!/G$ be the $G$-character
variety of $\Gamma$, where $G$ is a complex reductive group and $\Gamma$ a
finitely presented group. We introduce new techniques for computing
Hodge-Deligne and Serre polynomials of $\mathcal{X}_{\Gamma}G$, and present
some applications, focusing on the cases when $\Gamma$ is a free or free
abelian group. Detailed constructions and proofs of the main results will
appear elsewhere.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:12:09 GMT""}]","2020-06-26"
"2006.14521","Mukul Sholapurkar","Itay M. Bloch, Andrea Caputo, Rouven Essig, Diego Redigolo, Mukul
  Sholapurkar, Tomer Volansky","Exploring New Physics with O(keV) Electron Recoils in Direct Detection
  Experiments","v2: various corrections, clarifications, and additions. 50 pages, 9
  pages references, 25 figures",,"10.1007/JHEP01(2021)178",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the recent XENON1T results, we explore various new physics
models that can be discovered through searches for electron recoils in
O(keV)-threshold direct-detection experiments. First, we consider the
absorption of light bosons, either as dark matter relics or being produced
directly in the Sun. In the latter case, we find that keV mass bosons produced
in the Sun provide an adequate fit to the data but are excluded by stellar
cooling constraints. We address this tension by introducing a novel
Chameleon-like axion model, which can explain the excess while evading the
stellar bounds. We find that absorption of bosonic dark matter provides a
viable explanation for the excess only if the dark matter is a dark photon or
an axion. In the latter case, photophobic axion couplings are necessary to
avoid X-ray constraints. Second, we analyze models of dark matter-electron
scattering to determine which models might explain the excess. Standard
scattering of dark matter with electrons is generically in conflict with data
from lower-threshold experiments. Momentum-dependent interactions with a heavy
mediator can fit the data with dark matter mass heavier than a GeV but are
generically in tension with collider constraints. Next, we consider dark matter
consisting of two (or more) states that have a small mass splitting. The
exothermic (down)scattering of the heavier state to the lighter state can fit
the data for keV mass splittings. Finally, we consider a subcomponent of dark
matter that is accelerated by scattering off cosmic rays, finding that dark
matter interacting though an O(100 keV)-mass mediator can fit the data. The
cross sections required in this scenario are, however, typically challenged by
complementary probes of the light mediator. Throughout our study, we implement
an unbinned Monte Carlo analysis and use an improved energy reconstruction of
the XENON1T events.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:17:07 GMT""},{""version"":""v2"",""created"":""Tue, 8 Sep 2020 22:54:57 GMT""}]","2021-05-12"
"2006.14522","R\'uben Sousa","R\'uben Sousa, Manuel Guerra, Semyon Yakubovich","Product formulas and convolutions for two-dimensional Laplace-Beltrami
  operators: beyond the trivial case","33 pages",,,,"math.AP math.CA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the notion of a family of convolution operators associated with
a given elliptic partial differential operator. Such a convolution structure is
shown to exist for a general class of Laplace-Beltrami operators on
two-dimensional manifolds endowed with cone-like metrics. This structure gives
rise to a convolution semigroup representation for the Markovian semigroup
generated by the Laplace-Beltrami operator.
  In the particular case of the operator $\mathcal{L} = \partial_x^2 + {1 \over
2x} \partial_x + {1 \over x} \partial_\theta^2$ on $\mathbb{R}^+ \times
\mathbb{T}$, we deduce the existence of a convolution structure for a
two-dimensional integral transform whose kernel and inversion formula can be
written in closed form in terms of confluent hypergeometric functions. The
results of this paper can be interpreted as a natural extension of the theory
of one-dimensional generalized convolutions to the framework of multiparameter
eigenvalue problems.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:20:27 GMT""}]","2020-06-26"
"2006.14523","Dr Arun K. Pati","Brij Mohan and Arun Kumar Pati","Reverse Quantum Speed Limit: How Slow Quantum Battery can Discharge?","Accepted in Phys. Rev.A (2021)","Phys. Rev. A 104, 042209 (2021)","10.1103/PhysRevA.104.042209",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the notion of reverse quantum speed limit for arbitrary quantum
evolution which answers a fundamental question: ``how slow a quantum system can
evolve in time?"" Using the geometrical approach to quantum mechanics, the
reverse speed limit follows from the fact that the gauge invariant length of
the reference section is always greater than the Fubini-Study distance on the
projective Hilbert space of the quantum system. We illustrate the reverse speed
limit for two-level quantum systems with an external driving Hamiltonian and
show that our results hold well. We find several examples where our bound is
tight. We also find one practical application of the reverse speed limit in
discharging process of quantum batteries which answers the question: ``how slow
quantum batteries can discharge?"" Our result provides a lower bound on the
average discharging power of quantum batteries.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:21:23 GMT""},{""version"":""v2"",""created"":""Mon, 27 Sep 2021 14:16:09 GMT""}]","2022-12-07"
"2006.14524","Sauro Succi","Hakan Ba\c{s}a\u{g}ao\u{g}lu, Sauro Succi, Danielle Wyrick, Justin
  Blount","Particle Shape Influences Settling and Sorting Behavior in Microfluidic
  Domains","22 pages, 18 figures","Scientific reports, 2018, 8.1: 1-11","10.1038/s41598-018-26786-7",,"physics.comp-ph cond-mat.soft physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new numerical model to simulate settling trajectories of
discretized individual or a mixture of particles of different geometrical
shapes in a quiescent fluid and their flow trajectories in a flowing fluid.
Simulations unveiled diverse particle settling trajectories as a function of
their geometrical shape and density. The effects of the surface concavity of a
boomerang particle and aspect ratio of a rectangular particle on the
periodicity and amplitude of oscillations in their settling trajectories were
numerically captured. Use of surrogate circular particles for settling or
flowing of a mixture of non-circular particles were shown to miscalculate
particle velocities by a factor of 0.9-2.2 and inaccurately determine the
particles' trajectories. In a microfluidic chamber with particles of different
shapes and sizes, simulations showed that steady vortices do not necessarily
always control particle entrapments, nor do larger particles get selectively
and consistently entrapped in steady vortices. Strikingly, a change in the
shape of large particles from circular to elliptical resulted in stronger
entrapments of smaller circular particles, but enhanced outflows of larger
particles, which could be an alternative microfluidics-based method for sorting
and separation of particles of different sizes and shapes.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:21:31 GMT""}]","2020-06-26"
"2006.14525","Alden Walker","Jennifer Taback and Alden Walker","Conjugation Curvature in Solvable Baumslag-Solitar Groups","50 pages, 3 figures",,,,"math.GR math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For an element in $BS(1,n) = \langle t,a | tat^{-1} = a^n \rangle$ written in
the normal form $t^{-u}a^vt^w$ with $u,w \geq 0$ and $v \in \mathbb{Z}$, we
exhibit a geodesic word representing the element and give a formula for its
word length with respect to the generating set $\{t,a\}$. Using this word
length formula, we prove that there are sets of elements of positive density of
positive, negative and zero conjugation curvature, as defined by Bar Natan,
Duchin and Kropholler.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:22:07 GMT""}]","2020-06-26"
"2006.14526","Nathan Brooks","Nathan A. Brooks, Simon T. Powers and James M. Borg","A mechanism to promote social behaviour in household load balancing","8 pages, 5 figures",,"10.1162/isal_a_00290",,"cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reducing the peak energy consumption of households is essential for the
effective use of renewable energy sources, in order to ensure that as much
household demand as possible can be met by renewable sources. This entails
spreading out the use of high-powered appliances such as dishwashers and
washing machines throughout the day. Traditional approaches to this problem
have relied on differential pricing set by a centralised utility company. But
this mechanism has not been effective in promoting widespread shifting of
appliance usage. Here we consider an alternative decentralised mechanism, where
agents receive an initial allocation of time-slots to use their appliances and
can then exchange these with other agents. If agents are willing to be more
flexible in the exchanges they accept, then overall satisfaction, in terms of
the percentage of agents time-slot preferences that are satisfied, will
increase. This requires a mechanism that can incentivise agents to be more
flexible. Building on previous work, we show that a mechanism incorporating
social capital - the tracking of favours given and received - can incentivise
agents to act flexibly and give favours by accepting exchanges that do not
immediately benefit them. We demonstrate that a mechanism that tracks favours
increases the overall satisfaction of agents, and crucially allows social
agents that give favours to outcompete selfish agents that do not under
payoff-biased social learning. Thus, even completely self-interested agents are
expected to learn to produce socially beneficial outcomes.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:23:02 GMT""}]","2022-04-07"
"2006.14527","Pierre Ille","Abderrahim Boussairi, Brahim Chergui, Pierre Ille and Mohamed Zaidi","Critical 3-hypergraphs (detailed version)","28 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a 3-hypergraph $H$, a subset $M$ of $V(H)$ is a module of $H$ if for
each $e\in E(H)$ such that $e\cap M\neq\emptyset$ and $e\setminus
M\neq\emptyset$, there exists $m\in M$ such that $e\cap M=\{m\}$ and for every
$n\in M$, we have $(e\setminus\{m\})\cup\{n\}\in E(H)$. For example,
$\emptyset$, $V(H)$ and $\{v\}$, where $v\in V(H)$, are modules of $H$, called
trivial. A 3-hypergraph is prime if all its modules are trivial. Furthermore, a
prime 3-hypergraph is critical if all its induced subhypergraphs, obtained by
removing one vertex, are not prime. We characterize the critical 3-hypergraphs.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:23:47 GMT""}]","2020-06-26"
"2006.14528","Ellis Solaiman","B. Awaji, E. Solaiman, A. Albshri","Blockchain-Based Applications in Higher Education: A Systematic Mapping
  Study",,,,,"cs.CY cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The utilisation of blockchain has moved beyond digital currency to other
fields such as health, the Internet of Things, and education. In this paper, we
present a systematic mapping study to collect and analyse relevant research on
blockchain technology related to the higher education field. The paper
concentrates on two main themes. First, it examines state of the art in
blockchain-based applications that have been developed for educational
purposes. Second, it summarises the challenges and research gaps that need to
be addressed in future studies.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:24:28 GMT""}]","2020-06-26"
"2006.14529","Sanjib Kumar Agarwalla","Anil Kumar, Amina Khatun, Sanjib Kumar Agarwalla, Amol Dighe","From oscillation dip to oscillation valley in atmospheric neutrino
  experiments","27 pages, 11 figures, 5 tables, comments are welcome. Matches with
  the published version",,"10.1140/epjc/s10052-021-08946-8","IP/BBSR/2020-3, TIFR/TH/20-19","hep-ph hep-ex physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Atmospheric neutrino experiments can show the ""oscillation dip"" feature in
data, due to their sensitivity over a large $L/E$ range. In experiments that
can distinguish between neutrinos and antineutrinos, like INO, oscillation dips
can be observed in both these channels separately. We present the
dip-identification algorithm employing a data-driven approach -- one that uses
the asymmetry in the upward-going and downward-going events, binned in the
reconstructed $L/E$ of muons -- to demonstrate the dip, which would confirm the
oscillation hypothesis. We further propose, for the first time, the
identification of an ""oscillation valley"" in the reconstructed
($E_\mu$,$\,\cos\theta_\mu$) plane, feasible for detectors like ICAL having
excellent muon energy and direction resolutions. We illustrate how this
two-dimensional valley would offer a clear visual representation and test of
the $L/E$ dependence, the alignment of the valley quantifying the atmospheric
mass-squared difference. Owing to the charge identification capability of the
ICAL detector at INO, we always present our results using $\mu^{-}$ and
$\mu^{+}$ events separately. Taking into account the statistical fluctuations
and systematic errors, and varying oscillation parameters over their currently
allowed ranges, we estimate the precision to which atmospheric neutrino
oscillation parameters would be determined with the 10-year simulated data at
ICAL using our procedure.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:25:43 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 20:59:22 GMT""}]","2021-03-10"
"2006.14530","Caleb Marshall","C. Marshall, P. Morfouace, N. de S\'er\'eville and R. Longland","Bayesian Analysis of the $^{70}$Zn$(d, ^3\!\text{He}) ^{69}$Cu Transfer
  Reaction","15 pages, 7 figures, accepted to Phys. Rev. C","Phys. Rev. C 102, 024609 (2020)","10.1103/PhysRevC.102.024609",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transfer reactions provide information about the single-particle nature of
nuclear levels. In particular, the differential cross sections from these
measurements are sensitive to the angular momentum of the transferred particle
and the spectroscopic factor of the populated level. However, the process of
extracting these properties is subject to uncertainties, both from experimental
and theoretical sources. By integrating the distorted wave Born approximation
into a Bayesian model, we propagate these uncertainties through to the
spectroscopic factors and orbital angular momentum values. We use previously
reported data of the proton pickup reaction $^{70}$Zn$(d, ^3\!\text{He})
^{69}$Cu as an example. By accounting for uncertainties in the experimental
data, optical model parameters, and reaction mechanism, we find that the
extracted spectroscopic factors for low lying states of $^{69}$Cu are subject
to large, asymmetric uncertainties ranging from $35 \%$ to $108 \%$.
Additionally, Bayesian model comparison is employed to assign probabilities to
each of the allowed angular momentum transfers. This method confirms the
assignments for many states, but suggests that the data for a state lying at
$3.70$ MeV is better characterized by an $\ell = 3$ transfer, rather than the
previously reported $\ell = 2$.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:25:47 GMT""}]","2020-08-19"
"2006.14531","Michael Cosacchi","M. Cosacchi, J. Wiercinski, T. Seidelmann, M. Cygorek, A. Vagov, D. E.
  Reiter, V. M. Axt","On-demand generation of higher-order Fock states in quantum-dot--cavity
  systems","12 pages, 8 figures","Phys. Rev. Research 2, 033489 (2020)","10.1103/PhysRevResearch.2.033489",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The on-demand preparation of higher-order Fock states is of fundamental
importance in quantum information sciences. We propose and compare different
protocols to generate higher-order Fock states in solid state
quantum-dot--cavity systems. The protocols make use of a series of laser pulses
to excite the quantum dot exciton and off-resonant pulses to control the
detuning between dot and cavity. Our theoretical studies include dot and cavity
loss processes as well as the pure-dephasing type coupling to longitudinal
acoustic phonons in a numerically complete fashion. By going beyond the
two-level approximation for quantum dots, we study the impact of a finite
exchange splitting, the impact of a higher energetic exciton state, and an
excitation with linearly polarized laser pulses leading to detrimental
occupations of the biexciton state. We predict that under realistic conditions,
a protocol which keeps the cavity at resonance with the quantum dot until the
desired target state is reached is able to deliver fidelities to the Fock state
$| 5\rangle$ well above $40\,\%$.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:26:57 GMT""},{""version"":""v2"",""created"":""Mon, 28 Sep 2020 10:15:28 GMT""}]","2020-09-30"
"2006.14532","Julio Perez","J. C. P\'erez-Pedraza (1), E. D\'iaz-Bautista (2), A. Raya (1 and 3)
  and D. Valenzuela (4) ((1) Instituto de F\'isica y Matem\'aticas, Universidad
  Michoacana de San Nicol\'as de Hidalgo, (2) Departamento de Formaci\'on
  B\'asica Disciplinaria, Unidad Profesional Interdisciplinaria de Ingenier\'ia
  Campus Hidalgo del Instituto Polit\'ecnico Nacional, (3) Centro de Ciencias
  Exactas, Universidad del B\'io-B\'io, (4) Instituto de F\'isica, Pontificia
  Universidad Cat\'olica de Chile)","Critical behavior for point monopole and dipole electric impurities in
  uniformily and uniaxially strained graphene","9 pages, 5 figures, accepted in Phys. Rev.B","Phys. Rev. B 102, 045131 (2020)","10.1103/PhysRevB.102.045131",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the problem of bound states in graphene under the influence of
point electric monopole and dipole impurity potentials extended to the case in
which the membrane of this material is uniformly and uniaxially strained, which
leads to a redefinition of the charge and dipole moment, respectively. By
considering an anisotropic Fermi velocity, we analytically solve the resulting
Dirac equation for each potential. We observe that the effect of the anisotropy
is to promote or inhibit the critical behavior known to occur for each kind of
impurity, depending on the direction along which strain is applied: both the
atomic collapse, for the monopole impurity, and the emergence of cascades of
infinitely many bound states with a universal Efimov-like scaling, for the
dipole impurity, are phenomena that occur under less or more restrictive
conditions due to strain.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:29:55 GMT""}]","2020-08-20"
"2006.14533","Charles S. do Amaral","Charles S. do Amaral, A. P. F. Atman, Bernardo N. B. de Lima","On the monotonicity of the critical time in the Constrained-degree
  percolation model",,,"10.1016/j.physa.2020.125291",,"math-ph cond-mat.stat-mech math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Constrained-degree percolation model was introduced in [B.N.B. de Lima,
R. Sanchis, D.C. dos Santos, V. Sidoravicius, and R. Teodoro, Stoch. Process.
Appl. (2020)], where it was proven that this model has a non-trivial phase
transition on a square lattice. We study the Constrained-degree percolation
model on the $d$-dimensional hypercubic lattice ($\mathbb{Z}^d$) and, via
numerical simulations, found evidence that the critical time $t_{c}^{d}(k)$ is
monotonous not increasing in the constrained $k$ if $d=3,4$, like it is when
$d=2$. We verify that the lowest constrained value $k$ such that the system
exhibits a phase transition is $k=3$ and that the correlation critical exponent
$\nu$ for the Constrained-degree percolation model and ordinary Bernoulli
percolation are the same.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:30:46 GMT""},{""version"":""v2"",""created"":""Sat, 19 Sep 2020 13:12:27 GMT""}]","2020-09-22"
"2006.14534","Alden Walker","Jennifer Taback and Alden Walker","A new proof of the growth rate of the solvable Baumslag-Solitar groups","18 pages, 6 figures",,,,"math.GR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We exhibit a regular language of geodesics for a large set of elements of
$BS(1,n)$ and show that the growth rate of this language is the growth rate of
the group. This provides a straightforward calculation of the growth rate of
$BS(1,n)$, which was initially computed by Collins, Edjvet and Gill in [5]. Our
methods are based on those we develop in [8] to show that $BS(1,n)$ has a
positive density of elements of positive, negative and zero conjugation
curvature, as introduced by Bar-Natan, Duchin and Kropholler in [1].
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:31:09 GMT""}]","2020-06-26"
"2006.14535","Aleksey Lunkin","A. V. Lunkin, A. Yu. Kitaev, and M. V. Feigel'man","Perturbed Sachdev-Ye-Kitaev model: a polaron in the hyperbolic plane","12 pages","Phys. Rev. Lett. 125, 196602 (2020)","10.1103/PhysRevLett.125.196602",,"cond-mat.str-el hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the SYK$_4$ model with a weak SYK$_2$ term of magnitude $\Gamma$
beyond the simplest perturbative limit considered previously. For intermediate
values of the perturbation strength, $J/N \ll \Gamma \ll J/\sqrt{N}$,
fluctuations of the Schwarzian mode are suppressed, and the SYK$_4$ mean-field
solution remains valid beyond the timescale $t_0 \sim N/J$ up to $t_* \sim
J/\Gamma^2$. Out-of-time-order correlation function displays at short time
intervals exponential growth with maximal Lyapunov exponent $2\pi T$, but its
prefactor scales as $T$ at low temperatures $T \leq \Gamma$.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:32:24 GMT""},{""version"":""v2"",""created"":""Sun, 5 Jul 2020 08:57:38 GMT""},{""version"":""v3"",""created"":""Tue, 3 Nov 2020 15:42:25 GMT""}]","2020-11-11"
"2006.14536","Cihang Xie","Cihang Xie, Mingxing Tan, Boqing Gong, Alan Yuille, Quoc V. Le","Smooth Adversarial Training","tech report",,,,"cs.LG cs.CV cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is commonly believed that networks cannot be both accurate and robust,
that gaining robustness means losing accuracy. It is also generally believed
that, unless making networks larger, network architectural elements would
otherwise matter little in improving adversarial robustness. Here we present
evidence to challenge these common beliefs by a careful study about adversarial
training. Our key observation is that the widely-used ReLU activation function
significantly weakens adversarial training due to its non-smooth nature. Hence
we propose smooth adversarial training (SAT), in which we replace ReLU with its
smooth approximations to strengthen adversarial training. The purpose of smooth
activation functions in SAT is to allow it to find harder adversarial examples
and compute better gradient updates during adversarial training.
  Compared to standard adversarial training, SAT improves adversarial
robustness for ""free"", i.e., no drop in accuracy and no increase in
computational cost. For example, without introducing additional computations,
SAT significantly enhances ResNet-50's robustness from 33.0% to 42.3%, while
also improving accuracy by 0.9% on ImageNet. SAT also works well with larger
networks: it helps EfficientNet-L1 to achieve 82.2% accuracy and 58.6%
robustness on ImageNet, outperforming the previous state-of-the-art defense by
9.5% for accuracy and 11.6% for robustness. Models are available at
https://github.com/cihangxie/SmoothAdversarialTraining.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:34:39 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jul 2021 00:56:58 GMT""}]","2021-07-13"
"2006.14537","Andrea Ferrario","Andrea Ferrario, James Rankin","Auditory streaming emerges from fast excitation and slow delayed
  inhibition","Supplementary Material is at the end of the file",,,,"math.DS q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the auditory streaming paradigm alternating sequences of pure tones can be
perceived as a single galloping rhythm (integration) or as two sequences with
separated low and high tones (segregation). Although studied for decades, the
neural mechanisms underlining this perceptual grouping of sound remains a
mystery. With the aim of identifying a plausible minimal neural circuit that
captures this phenomenon, we propose a firing rate model with two periodically
forced neural populations coupled by fast direct excitation and slow delayed
inhibition. By analyzing the model in a non-smooth, slow-fast regime we
analytically prove the existence of a rich repertoire of dynamical states and
of their parameter dependent transitions. We impose plausible parameter
restrictions and link all states with perceptual interpretations. Regions of
stimulus parameters occupied by states linked with each percept matches those
found in behavioral experiments. Our model suggests that slow inhibition masks
the perception of subsequent tones during segregation (forward masking), while
fast excitation enables integration for large pitch differences between the two
tones.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:35:58 GMT""},{""version"":""v2"",""created"":""Fri, 20 Nov 2020 12:06:59 GMT""}]","2020-11-23"
"2006.14538","Hossein Shahabadi Farahani","Hossein Shahabadi Farahani, Alireza Fatehi, Mahdi Aliyari Shoorehdeli","Between-Domain Instance Transition Via the Process of Gibbs Sampling in
  RBM",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a new idea for Transfer Learning (TL) based on
Gibbs Sampling. Gibbs sampling is an algorithm in which instances are likely to
transfer to a new state with a higher possibility with respect to a probability
distribution. We find that such an algorithm can be employed to transfer
instances between domains. Restricted Boltzmann Machine (RBM) is an energy
based model that is very feasible for being trained to represent a data
distribution and also for performing Gibbs sampling. We used RBM to capture
data distribution of the source domain and use it in order to cast target
instances into new data with a distribution similar to the distribution of
source data. Using datasets that are commonly used for evaluation of TL
methods, we show that our method can successfully enhance target classification
by a considerable ratio. Additionally, the proposed method has the advantage
over common DA methods that it needs no target data during the process of
training of models.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:36:27 GMT""}]","2020-06-26"
"2006.14539","Bailin Deng","Wenqing Ouyang and Yue Peng and Yuxin Yao and Juyong Zhang and Bailin
  Deng","Anderson Acceleration for Nonconvex ADMM Based on Douglas-Rachford
  Splitting","To be published in Computer Graphis Forum and presented at
  Eurographics Symposium on Geometry Processing 2020",,,,"math.OC cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The alternating direction multiplier method (ADMM) is widely used in computer
graphics for solving optimization problems that can be nonsmooth and nonconvex.
It converges quickly to an approximate solution, but can take a long time to
converge to a solution of high-accuracy. Previously, Anderson acceleration has
been applied to ADMM, by treating it as a fixed-point iteration for the
concatenation of the dual variables and a subset of the primal variables. In
this paper, we note that the equivalence between ADMM and Douglas-Rachford
splitting reveals that ADMM is in fact a fixed-point iteration in a
lower-dimensional space. By applying Anderson acceleration to such
lower-dimensional fixed-point iteration, we obtain a more effective approach
for accelerating ADMM. We analyze the convergence of the proposed acceleration
method on nonconvex problems, and verify its effectiveness on a variety of
computer graphics problems including geometry processing and physical
simulation.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:37:32 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 09:18:20 GMT""}]","2020-06-29"
"2006.14541","Felipe Yukihide Yasumura","Thiago Castilho de Mello, Felipe Yukihide Yasumura","Relatively free algebras of finite rank",,"In: Polynomial Identities in Algebras. Springer INdAM Series, vol
  44, 2021","10.1007/978-3-030-63111-6_8",,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathbb{K}$ be a field of characteristic zero and $B=B_0+B_1$ a finite
dimensional associative superalgebra. In this paper we investigate the
polynomial identities of the relatively free algebras of finite rank of the
variety $\mathfrak V$ defined by the Grassmann envelope of $B$. We also
consider the $k$-th Grassmann Envelope of $B$, $G^{(k)}(B)$, constructed with
the $k$-generated Grassmann algebra, instead of the infinite dimensional
Grassmann algebra. We specialize our studies for the algebra $UT_2(G)$ and
$UT_2(G^{(k)})$, which can be seen as the Grassmann envelope and $k$-th
Grassmann envelope, respectively, of the superalgebra $UT_2(\mathbb{K}[u])$,
where $u^2=1$.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:38:56 GMT""}]","2022-08-09"
"2006.14542","James Leng","James Leng","Moser's Method and Conservative Extensions of Diffeomorphisms","24 pages",,,,"math.CA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper shall be concerned with three main results. After a brief
recollection of basic symplectic geometry, we prove using Moser's homotopy
method a special case of the Strong Darboux Theorem found, for instance, in
Theorem 21.1.6 of [Hor]. Next, we'll prove two conservative extension results
for a diffeomorphism on a circle. One uses Moser's homotopy method but loses a
degree of regularity. The other uses the method of generating functions as
found in [BCW] and [BGV]. Finally, we'll prove a conservative extension result
for a ""diffeomorphism"" defined on the boundary of $(0, 1)^2$ and use the
techniques developed there and by [M] to prove an ambient Dacarogna-Moser
Theorem.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:39:25 GMT""},{""version"":""v2"",""created"":""Sun, 28 Jun 2020 20:01:17 GMT""}]","2020-06-30"
"2006.14543","Alexander M\""uller-Hermes","Alexander M\""uller-Hermes","Decomposable Pauli diagonal maps and Tensor Squares of Qubit Maps","63 pages, 4 figures, 3 tables. Matlab code to verify one of the main
  results is included as auxiliary material. Comments are welcome!",,"10.1063/5.0049533",,"quant-ph math-ph math.FA math.MP math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is a well-known result due to E. St{\o}rmer that every positive qubit map
is decomposable into a sum of a completely positive map and a completely
copositive map. Here, we generalize this result to tensor squares of qubit
maps. Specifically, we show that any positive tensor product of a qubit map
with itself is decomposable. This solves a recent conjecture by S. Fillipov and
K. Magadov. We contrast this result with examples of non-decomposable positive
maps arising as the tensor product of two distinct qubit maps or as the tensor
square of a decomposable map from a qubit to a ququart. To show our main
result, we reduce the problem to Pauli diagonal maps. We then characterize the
cone of decomposable ququart Pauli diagonal maps by determining all 252
extremal rays of ququart Pauli diagonal maps that are both completely positive
and completely copositive. These extremal rays split into three disjoint orbits
under a natural symmetry group, and two of these orbits contain only
entanglement breaking maps. Finally, we develop a general combinatorial method
to determine the extremal rays of Pauli diagonal maps that are both completely
positive and completely copositive between multi-qubit systems using the
ordered spectra of their Choi matrices. Classifying these extremal rays beyond
ququarts is left as an open problem.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:39:32 GMT""}]","2021-09-15"
"2006.14545","Scott Lawrence","Thomas D. Cohen, Scott Lawrence, Yukari Yamauchi","The thermodynamics of large-N QCD and the nature of metastable phases","12 pages, 3 figures; version for PRC","Phys. Rev. C 102, 065206 (2020)","10.1103/PhysRevC.102.065206",,"hep-ph hep-th nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the limit of a large number of colors (N), both Yang-Mills and quantum
chromodynamics are expected to have a first-order phase transition separating a
confined hadronic phase and a deconfined plasma phase. One aspect of this
separation is that at large N, one can unambiguously identify a plasma regime
that is strongly coupled. The existence of a first-order transition suggests
that the hadronic phase can be superheated and the plasma phase supercooled.
The supercooled deconfined plasma present at large N, if it exists, has the
remarkable property that it has negative absolute pressure -- i.e. a pressure
below that of the vacuum. For energy densities of order unity in a 1/N
expansion but beyond the endpoint of the hadronic superheated phase, a
description of homogeneous matter composed of ordinary hadrons with masses of
order unity in a 1/N expansion can exist, and acts as though it has a
temperature of $T_H$ in order unity. However, the connection between the
canonical and microcanonical descriptions breaks down and the system cannot
fully equilibrate as $N \rightarrow \infty$. Rather, in a hadronic description,
energy is pushed to hadrons with masses that are arbitrarily large. The
thermodynamic limit of large volumes becomes subtle for such systems: the
energy density is no longer intensive. These conclusions follow provided that
standard large N scaling rules hold, the system at large N undergoes a generic
first-order phase transition between the hadronic and plasma phases and that
the mesons and glueballs follow a Hagedorn-type spectrum.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:41:52 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 17:24:25 GMT""}]","2021-01-07"
"2006.14546","Shubham Kanodia","Shubham Kanodia, Caleb I. Canas, Gudmundur Stefansson, Joe P. Ninan,
  Leslie Hebb, Andrea S.J. Lin, Helen Baran, Marissa Maney, Ryan C. Terrien,7
  Suvrath Mahadevan, William D. Cochran, Michael Endl, Jiayin Dong, Chad F.
  Bender, Scott A. Diddams, Eric B. Ford, Connor Fredrick, Samuel Halverson,
  Fred Hearty, Andrew J. Metcalf, Andrew Monson, Lawrence W. Ramsey, Paul
  Robertson, Arpita Roy, Christian Schwab, and Jason T. Wright","TOI-1728b: The Habitable-zone Planet Finder confirms a warm super
  Neptune orbiting an M dwarf host","21 pages, 12 figures, 4 tables: Accepted for publication",,"10.3847/1538-4357/aba0a2",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We confirm the planetary nature of TOI-1728b using a combination of
ground-based photometry, near-infrared Doppler velocimetry and spectroscopy
with the Habitable-zone Planet Finder.TOI-1728 is an old, inactive M0 star with
\teff{} $= 3980^{+31}_{-32}$ K, which hosts a transiting super Neptune at an
orbital period of $\sim$ 3.49 days. Joint fitting of the radial velocities and
TESS and ground-based transits yields a planetary radius of
$5.05_{-0.17}^{+0.16}$ R$_{\oplus}$, mass $26.78_{-5.13}^{+5.43}$ M$_{\oplus}$
and eccentricity $0.057_{-0.039}^{+0.054}$. We estimate the stellar properties,
and perform a search for He 10830 \AA absorption during the transit of this
planet and claim a null detection with an upper limit of 1.1$\%$ with 90\%
confidence. A deeper level of He 10830 \AA ~ absorption has been detected in
the planet atmosphere of GJ 3470b, a comparable gaseous planet. TOI-1728b is
the largest super Neptune -- the intermediate subclass of planets between
Neptune and the more massive gas-giant planets -- discovered around an M dwarf.
With its relatively large mass and radius, TOI-1728 represents a valuable
datapoint in the M-dwarf exoplanet mass-radius diagram, bridging the gap
between the lighter Neptune-sized planets and the heavier Jovian planets known
to orbit M-dwarfs. With a low bulk density of $1.14_{-0.24}^{+0.26}$ g/cm$^3$,
and orbiting a bright host star (J $\sim 9.6$, V $\sim 12.4$), TOI-1728b is
also a promising candidate for transmission spectroscopy both from the ground
and from space, which can be used to constrain planet formation and
evolutionary models.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:44:37 GMT""}]","2020-08-19"
"2006.14547","Armin Hadzic","Armin Hadzic, Gordon Christie, Jeffrey Freeman, Amber Dismer, Stevan
  Bullard, Ashley Greiner, Nathan Jacobs, Ryan Mukherjee","Estimating Displaced Populations from Overhead","Fixed typo in abstract",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a deep learning approach to perform fine-grained population
estimation for displacement camps using high-resolution overhead imagery. We
train and evaluate our approach on drone imagery cross-referenced with
population data for refugee camps in Cox's Bazar, Bangladesh in 2018 and 2019.
Our proposed approach achieves 7.02% mean absolute percent error on sequestered
camp imagery. We believe our experiments with real-world displacement camp data
constitute an important step towards the development of tools that enable the
humanitarian community to effectively and rapidly respond to the global
displacement crisis.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:45:11 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 17:41:21 GMT""}]","2020-12-22"
"2006.14548","Greg Yang","Greg Yang","Tensor Programs II: Neural Tangent Kernel for Any Architecture","11 pages of main text. 60 pages total. August 2020: Fixed ""BP-like""
  definition",,,,"stat.ML cond-mat.dis-nn cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that a randomly initialized neural network of *any architecture* has
its Tangent Kernel (NTK) converge to a deterministic limit, as the network
widths tend to infinity. We demonstrate how to calculate this limit. In prior
literature, the heuristic study of neural network gradients often assumes every
weight matrix used in forward propagation is independent from its transpose
used in backpropagation (Schoenholz et al. 2017). This is known as the
*gradient independence assumption (GIA)*. We identify a commonly satisfied
condition, which we call *Simple GIA Check*, such that the NTK limit
calculation based on GIA is correct. Conversely, when Simple GIA Check fails,
we show GIA can result in wrong answers. Our material here presents the NTK
results of Yang (2019a) in a friendly manner and showcases the *tensor
programs* technique for understanding wide neural networks. We provide
reference implementations of infinite-width NTKs of recurrent neural network,
transformer, and batch normalization at https://github.com/thegregyang/NTK4A.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:45:23 GMT""},{""version"":""v2"",""created"":""Sun, 28 Jun 2020 19:42:48 GMT""},{""version"":""v3"",""created"":""Tue, 18 Aug 2020 14:07:55 GMT""},{""version"":""v4"",""created"":""Mon, 30 Nov 2020 03:30:09 GMT""}]","2020-12-01"
"2006.14549","K\'aroly Nagy","K\'aroly Nagy","The existence and unicity of numerical solution of initial value
  problems by Walsh polynomials approach",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chen and Hsiao gave the numerical solution of initial value problems of
systems of linear differential equations with constant coefficients by Walsh
polynomials approach. This result was improved by G\'at and Toledo for initial
value problems of differential equations with variable coefficients on the
interval $[0,1[$ and initial value $\xi=0$. In the present paper we discuss the
general case while $\xi$ can take any arbitrary value in the interval $[0,1[$.
We show the existence and uniform convergence of the numerical solution, as
well.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:46:09 GMT""}]","2020-06-26"
"2006.14550","Roberto Henschel","Andrea Hornakova, Roberto Henschel, Bodo Rosenhahn, Paul Swoboda","Lifted Disjoint Paths with Application in Multiple Object Tracking","ICML 2020, Codebase available at
  https://github.com/AndreaHor/LifT_Solver",,,,"cs.CV cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an extension to the disjoint paths problem in which additional
\emph{lifted} edges are introduced to provide path connectivity priors. We call
the resulting optimization problem the lifted disjoint paths problem. We show
that this problem is NP-hard by reduction from integer multicommodity flow and
3-SAT. To enable practical global optimization, we propose several classes of
linear inequalities that produce a high-quality LP-relaxation. Additionally, we
propose efficient cutting plane algorithms for separating the proposed linear
inequalities. The lifted disjoint path problem is a natural model for multiple
object tracking and allows an elegant mathematical formulation for long range
temporal interactions. Lifted edges help to prevent id switches and to
re-identify persons. Our lifted disjoint paths tracker achieves nearly optimal
assignments with respect to input detections. As a consequence, it leads on all
three main benchmarks of the MOT challenge, improving significantly over
state-of-the-art.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:49:08 GMT""}]","2020-06-26"
"2006.14551","Thomas Beckers","Thomas Beckers and Sandra Hirche","Prediction with Approximated Gaussian Process Dynamical Models","This article has been accepted for publication by IEEE",,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The modeling and simulation of dynamical systems is a necessary step for many
control approaches. Using classical, parameter-based techniques for modeling of
modern systems, e.g., soft robotics or human-robot interaction, is often
challenging or even infeasible due to the complexity of the system dynamics. In
contrast, data-driven approaches need only a minimum of prior knowledge and
scale with the complexity of the system. In particular, Gaussian process
dynamical models (GPDMs) provide very promising results for the modeling of
complex dynamics. However, the control properties of these GP models are just
sparsely researched, which leads to a ""blackbox"" treatment in modeling and
control scenarios. In addition, the sampling of GPDMs for prediction purpose
respecting their non-parametric nature results in non-Markovian dynamics making
the theoretical analysis challenging. In this article, we present approximated
GPDMs which are Markov and analyze their control theoretical properties. Among
others, the approximated error is analyzed and conditions for boundedness of
the trajectories are provided. The outcomes are illustrated with numerical
examples that show the power of the approximated models while the the
computational time is significantly reduced.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:51:17 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 15:38:25 GMT""}]","2021-12-01"
"2006.14552","Giulio Ermanno Pibiri","Giulio Ermanno Pibiri and Rossano Venturini","Practical Trade-Offs for the Prefix-Sum Problem","Accepted by ""Software: Practice and Experience"", 2020","Softw. Pract. Exp. 51(5): 921-949 (2021)","10.1002/spe.2918",,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given an integer array A, the prefix-sum problem is to answer sum(i) queries
that return the sum of the elements in A[0..i], knowing that the integers in A
can be changed. It is a classic problem in data structure design with a wide
range of applications in computing from coding to databases. In this work, we
propose and compare several and practical solutions to this problem, showing
that new trade-offs between the performance of queries and updates can be
achieved on modern hardware.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:52:10 GMT""},{""version"":""v2"",""created"":""Sat, 27 Jun 2020 08:18:03 GMT""},{""version"":""v3"",""created"":""Tue, 6 Oct 2020 19:54:27 GMT""}]","2022-02-08"
"2006.14553","Danielle Gonzalez","Danielle Gonzalez, Michael Rath, Mehdi Mirakhorli","Did You Remember to Test Your Tokens?","In 17th International Conference on Mining Software Repositories
  (MSR) 2020, Technical Track, Virtual. 11 pages",,"10.1145/3379597.3387471",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Authentication is a critical security feature for confirming the identity of
a system's users, typically implemented with help from frameworks like Spring
Security. It is a complex feature which should be robustly tested at all stages
of development. Unit testing is an effective technique for fine-grained
verification of feature behaviors that is not widely-used to test
authentication. Part of the problem is that resources to help developers unit
test security features are limited. Most security testing guides recommend test
cases in a ""black box"" or penetration testing perspective. These resources are
not easily applicable to developers writing new unit tests, or who want a
security-focused perspective on coverage.
  In this paper, we address these issues by applying a grounded theory-based
approach to identify common (unit) test cases for token authentication through
analysis of 481 JUnit tests exercising Spring Security-based authentication
implementations from 53 open source Java projects. The outcome of this study is
a developer-friendly unit testing guide organized as a catalog of 53 test cases
for token authentication, representing unique combinations of 17 scenarios, 40
conditions, and 30 expected outcomes learned from the data set in our analysis.
We supplement the test guide with common test smells to avoid. To verify the
accuracy and usefulness of our testing guide, we sought feedback from selected
developers, some of whom authored unit tests in our dataset.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:52:33 GMT""}]","2020-06-26"
"2006.14554","Benjamin Coleman","Benjamin Coleman, Gaurav Gupta, John Chen, Anshumali Shrivastava","STORM: Foundations of End-to-End Empirical Risk Minimization on the Edge",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Empirical risk minimization is perhaps the most influential idea in
statistical learning, with applications to nearly all scientific and technical
domains in the form of regression and classification models. To analyze massive
streaming datasets in distributed computing environments, practitioners
increasingly prefer to deploy regression models on edge rather than in the
cloud. By keeping data on edge devices, we minimize the energy, communication,
and data security risk associated with the model. Although it is equally
advantageous to train models at the edge, a common assumption is that the model
was originally trained in the cloud, since training typically requires
substantial computation and memory. To this end, we propose STORM, an online
sketch for empirical risk minimization. STORM compresses a data stream into a
tiny array of integer counters. This sketch is sufficient to estimate a variety
of surrogate losses over the original dataset. We provide rigorous theoretical
analysis and show that STORM can estimate a carefully chosen surrogate loss for
the least-squares objective. In an exhaustive experimental comparison for
linear regression models on real-world datasets, we find that STORM allows
accurate regression models to be trained.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:56:23 GMT""}]","2020-06-26"
"2006.14555","Adamantia Kosma","Adamantia Kosma (1), Philipp R\""u{\ss}mann (2), Stefan Bl\""ugel (2),
  and Phivos Mavropoulos (1) ((1) Section of Condensed Matter Physics,
  Department of Physics, National and Kapodistrian University of Athens,
  Panepistimioupolis Athens, Greece, (2) Peter Gr\""unberg Institut and
  Institute for Advanced Simulation, Forschungszentrum J\""ulich and JARA,
  J\""ulich, Germany)","Strong Spin-Orbit Torque effect on magnetic defects due to topological
  surface state electrons in Bi$_{2}$Te$_{3}$",,"Phys. Rev. B 102, 144424 (2020)","10.1103/PhysRevB.102.144424",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the spin-orbit torque exerted on the magnetic moments of the
transition-metal impurities Cr, Mn, Fe and Co, embedded in the surface of the
topological insulator Bi$_{2}$Te$ _{3} $, in response to an electric field and
a consequent electrical current flow in the surface. The multiple scattering
problem of electrons off impurity atoms is solved by first-principles
calculations within the full-potential relativistic Korringa-Kohn-Rostoker
(KKR) Green function method, while the spin-orbit torque calculations are
carried out by combining the KKR method with the semiclassical Boltzmann
transport equation. We analyze the correlation of the spin-orbit torque to the
spin accumulation and spin flux in the defects. We compare the torque on
different magnetic impurities and unveil the effect of resonant scattering. In
addition, we calculate the resistivity and the Joule heat as a function of the
torque in these systems. We predict that the Mn/Bi$_{2}$Te$_{3}$ is optimal
among the studied systems.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:57:37 GMT""}]","2020-10-21"
"2006.14556","Dumindu Tissera","Nadarasar Bahavan, Navaratnarajah Suman, Sulhi Cader, Ruwinda
  Ranganayake, Damitha Seneviratne, Vinu Maddumage, Gershom Seneviratne,
  Yasinha Supun, Isuru Wijesiri, Suchitha Dehigaspitiya, Dumindu Tissera,
  Chamira Edussooriya","Anomaly Detection using Deep Reconstruction and Forecasting for
  Autonomous Systems","Runners Up - IEEE Signal Processing Cup 2020",,,,"cs.LG cs.CV eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose self-supervised deep algorithms to detect anomalies in
heterogeneous autonomous systems using frontal camera video and IMU readings.
Given that the video and IMU data are not synchronized, each of them are
analyzed separately. The vision-based system, which utilizes a conditional GAN,
analyzes immediate-past three frames and attempts to predict the next frame.
The frame is classified as either an anomalous case or a normal case based on
the degree of difference estimated using the prediction error and a threshold.
The IMU-based system utilizes two approaches to classify the timestamps; the
first being an LSTM autoencoder which reconstructs three consecutive IMU
vectors and the second being an LSTM forecaster which is utilized to predict
the next vector using the previous three IMU vectors. Based on the
reconstruction error, the prediction error, and a threshold, the timestamp is
classified as either an anomalous case or a normal case. The composition of
algorithms won runners up at the IEEE Signal Processing Cup anomaly detection
challenge 2020. In the competition dataset of camera frames consisting of both
normal and anomalous cases, we achieve a test accuracy of 94% and an F1-score
of 0.95. Furthermore, we achieve an accuracy of 100% on a test set containing
normal IMU data, and an F1-score of 0.98 on the test set of abnormal IMU data.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:00:01 GMT""}]","2020-06-26"
"2006.14557","Deepak Ojha","Deepak Ojha and Thomas D K\""uhne","""On-the-fly"" calculation of the Vibrational Sum-frequency Generation
  Spectrum at the Air-water Interface","5 pages, 3 figures",,,,"physics.chem-ph cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present work, we provide an electronic structure based method for the
""on-the-fly"" determination of vibrational sum frequency generation (v-SFG)
spectra. The predictive power of this scheme is demonstrated at the air-water
interface. While the instantaneous fluctuations in dipole moment are obtained
using the maximally localized Wannier functions, the fluctuations in
polarizability are approximated to be proportional to the second moment of
Wannier functions. The spectrum henceforth obtained captures the signatures of
hydrogen bond stretching, bending, as well as low-frequency librational modes.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:01:46 GMT""}]","2020-06-26"
"2006.14558","Fulin Chen","Fulin Chen, Naihuan Jing, Fei Kong and Shaobin Tan","On quantum toroidal algebra of type $A_1$",,"J. Pure Applied Algebra (2022), no.1, 108614","10.1016/j.jpaa.2021.106814",,"math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we introduce a new quantum algebra which specializes to the
$2$-toroidal Lie algebra of type $A_1$.
  We prove that this quantum toroidal algebra has a natural triangular
decomposition, a (topological) Hopf algebra structure and a vertex operator
realization.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:02:11 GMT""}]","2021-07-02"
"2006.14559","Dmitry Chelkak","Dmitry Chelkak","Ising model and s-embeddings of planar graphs","70 pages, 10 figures. Changes in this version: assumption Exp-Fat
  clarified, Section 2.7 (discussion of the non-flat setup) extended + minor
  changes throughout the text",,,,"math-ph math.CV math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the notion of s-embeddings $\mathcal{S}=\mathcal{S}_\mathcal{X}$
of planar graphs carrying a nearest-neighbor Ising model. The construction of
$\mathcal{S}_\mathcal{X}$ is based upon a choice of a global complex-valued
solution $\mathcal{X}$ of the propagation equation for Kadanoff-Ceva fermions.
Each choice of $\mathcal{X}$ provides an interpretation of all other fermionic
observables as s-holomorphic functions on $\mathcal{S}_\mathcal{X}$. We set up
a general framework for the analysis of such functions on s-embeddings
$\mathcal{S}^\delta$ with $\delta\to 0$. Throughout this analysis, a key role
is played by the functions $\mathcal{Q}^\delta$ associated with
$\mathcal{S}^\delta$, the so-called origami maps in the bipartite dimer model
terminology. In particular, we give an interpretation of the mean curvature of
the limit of discrete surfaces $(\mathcal{S}^\delta;\mathcal{Q}^\delta)$ viewed
in the Minkowski space $\mathbb R^{2,1}$ as the mass in the Dirac equation
describing the continuous limit of the model.
  We then focus on the simplest situation when $\mathcal{S}^\delta$ have
uniformly bounded lengths/angles and $\mathcal{Q}^\delta=O(\delta)$; as a
particular case this includes all critical Ising models on doubly periodic
graphs via their canonical s-embeddings. In this setup we prove RSW-type
crossing estimates for the random cluster representation of the model and the
convergence of basic fermionic observables. The proof relies upon a new
strategy as compared to the already existing literature, it also provides a
quantitative estimate on the speed of convergence.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:02:29 GMT""},{""version"":""v2"",""created"":""Fri, 11 Sep 2020 17:35:36 GMT""},{""version"":""v3"",""created"":""Mon, 3 May 2021 14:42:54 GMT""},{""version"":""v4"",""created"":""Sat, 9 Apr 2022 18:58:50 GMT""},{""version"":""v5"",""created"":""Mon, 7 Nov 2022 10:51:19 GMT""}]","2022-11-08"
"2006.14560","Jeremy Bernstein","Jeremy Bernstein, Jiawei Zhao, Markus Meister, Ming-Yu Liu, Anima
  Anandkumar, Yisong Yue","Learning compositional functions via multiplicative weight updates",,,,,"cs.NE cs.LG cs.NA math.NA stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compositionality is a basic structural feature of both biological and
artificial neural networks. Learning compositional functions via gradient
descent incurs well known problems like vanishing and exploding gradients,
making careful learning rate tuning essential for real-world applications. This
paper proves that multiplicative weight updates satisfy a descent lemma
tailored to compositional functions. Based on this lemma, we derive Madam -- a
multiplicative version of the Adam optimiser -- and show that it can train
state of the art neural network architectures without learning rate tuning. We
further show that Madam is easily adapted to train natively compressed neural
networks by representing their weights in a logarithmic number system. We
conclude by drawing connections between multiplicative weight updates and
recent findings about synapses in biology.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:05:19 GMT""},{""version"":""v2"",""created"":""Fri, 8 Jan 2021 17:34:41 GMT""}]","2021-01-11"
"2006.14561","Line Roald","Line A. Roald, Kaarthik Sundar, Anatoly Zlotnik, Sidhant Misra,
  G\""oran Andersson","An Uncertainty Management Framework for Integrated Gas-Electric Energy
  Systems",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many parts of the world, electric power systems have seen a significant
shift towards generation from renewable energy and natural gas. Because of
their ability to flexibly adjust power generation in real time, gas-fired power
plants are frequently seen as the perfect partner for variable renewable
generation. However, this reliance on gas generation increases interdependence
and propagates uncertainty between power grids and gas pipelines, and brings
coordination and uncertainty management challenges. To address these issues, we
propose an uncertainty management framework for uncertain, but bounded gas
consumption by gas-fired power plants. The admissible ranges are computed based
on a joint optimization problem for the combined gas and electricity networks,
which involves chance-constrained scheduling for the electric grid and a novel
robust optimization formulation for the natural gas network. This formulation
ensures feasibility of the integrated system with a high probability, while
providing a tractable numerical formulation. A key advance with respect to
existing methods is that our method is based on a physically accurate,
validated model for transient gas pipeline flows. Our case study benchmarks our
proposed formulation against methods that ignore how reserve activation impacts
the fuel use of gas power plants, and only consider predetermined gas
consumption. The results demonstrate the importance of considering uncertainty
to avoid operating constraint violations and curtailment of gas to the
generators.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:05:22 GMT""}]","2020-06-26"
"2006.14562","Melvyn B. Nathanson","Melvyn B. Nathanson","A new class of minimal asymptotic bases","10 pages; minor improvements and corrections","Combinatorial and Additive Number Theory V, Springer, New York,
  2022",,,"math.NT math.CO","http://creativecommons.org/licenses/by/4.0/","  A set $A$ of nonnegative integers is an asymptotic basis of order $h$ if
every sufficiently large integer can be represented as the sum of $h$ not
necessarily distinct elements of $A$. The asymptotic basis $A$ is minimal if
removing any element of $A$ destroys every representation of infinitely many
integers, and so $A\setminus \{a\}$ is not an asymptotic basis of order $h$ for
all $a\in A$. In this paper, a new class of minimal asymptotic bases is
constructed.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:06:28 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 13:11:34 GMT""}]","2022-12-14"
"2006.14563","Yongqiang Dou","Yongqiang Dou, Haocheng Yang, Maolin Yang, Yanyan Xu and Dengfeng Ke","Dynamically Mitigating Data Discrepancy with Balanced Focal Loss for
  Replay Attack Detection","The 25th International Conference on Pattern Recognition (ICPR2020)",,"10.1109/ICPR48806.2021.9412749",,"cs.CV cs.LG eess.AS stat.ML","http://creativecommons.org/licenses/by/4.0/","  It becomes urgent to design effective anti-spoofing algorithms for vulnerable
automatic speaker verification systems due to the advancement of high-quality
playback devices. Current studies mainly treat anti-spoofing as a binary
classification problem between bonafide and spoofed utterances, while lack of
indistinguishable samples makes it difficult to train a robust spoofing
detector. In this paper, we argue that for anti-spoofing, it needs more
attention for indistinguishable samples over easily-classified ones in the
modeling process, to make correct discrimination a top priority. Therefore, to
mitigate the data discrepancy between training and inference, we propose D3M,
to leverage a balanced focal loss function as the training objective to
dynamically scale the loss based on the traits of the sample itself. Besides,
in the experiments, we select three kinds of features that contain both
magnitude-based and phase-based information to form complementary and
informative features. Experimental results on the ASVspoof2019 dataset
demonstrate the superiority of the proposed methods by comparison between our
systems and top-performing ones. Systems trained with the balanced focal loss
perform significantly better than conventional cross-entropy loss. With
complementary features, our fusion system with only three kinds of features
outperforms other systems containing five or more complex single models by
22.5% for min-tDCF and 7% for EER, achieving a min-tDCF and an EER of 0.0124
and 0.55% respectively. Furthermore, we present and discuss the evaluation
results on real replay data apart from the simulated ASVspoof2019 data,
indicating that research for anti-spoofing still has a long way to go. Source
code, analysis data, and other details are publicly available at
https://github.com/asvspoof/D3M.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:06:47 GMT""},{""version"":""v2"",""created"":""Mon, 16 Jan 2023 19:44:13 GMT""},{""version"":""v3"",""created"":""Wed, 18 Jan 2023 04:17:47 GMT""}]","2023-01-19"
"2006.14564","Jo\~ao Manuel da Silva Santos","J. M. da Silva Santos, J. de la Cruz Rodr\'iguez, S. M. White, J.
  Leenaarts, G. J. M. Vissers, V. H. Hansteen","ALMA observations of transient heating in a solar active region","revised; accepted in Astronomy & Astrophysics","A&A 643, A41 (2020)","10.1051/0004-6361/202038755",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We aim to investigate the temperature enhancements and formation heights of
impulsive heating phenomena in solar active-regions such as Ellerman bombs
(EBs), ultraviolet bursts (UVBs), and flaring active-region fibrils (FAFs)
using interferometric observations in the millimeter (mm) continuum provided by
the Atacama Large Millimeter/submillimeter Array (ALMA). We examined 3 mm
signatures of heating events identified in Solar Dynamics Observatory (SDO)
observations of an active region and compared the results with synthetic
spectra from a 3D radiative magnetohydrodynamic simulation. We estimated the
contribution from the corona to the mm brightness using differential emission
measure analysis. We report the null detection of EBs in the 3 mm continuum at
$\sim1.2$"" spatial resolution, which is evidence that they are sub-canopy
events that do not significantly contribute to heating the upper chromosphere.
In contrast, we find the active region to be populated with multiple compact,
bright, flickering mm bursts -- reminiscent of UVBs. The high brightness
temperatures of up to $\sim14200$ K in some events have a significant
contribution (up to $\sim$7%) from the corona. We also detect FAF-like events
in the 3 mm continuum that show rapid motions of $>10000\,$K plasma launched
with high plane-of-sky velocities ($37-340\rm\,km\,s^{-1}$) from bright
kernels. The mm FAFs are the brightest class of warm canopy fibrils that
connect magnetic regions of opposite polarities. The simulation confirms that
ALMA should be able to detect the mm counterparts of UVBs and small flares and
thus provide a complementary diagnostic for localized heating in the solar
chromosphere.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:09:01 GMT""},{""version"":""v2"",""created"":""Tue, 1 Sep 2020 14:01:05 GMT""}]","2020-11-04"
"2006.14565","Karol Szymula","Karol P. Szymula, Fabio Pasqualetti, Ann M. Graybiel, Theresa M.
  Desrochers, and Danielle S. Bassett","Habit learning supported by efficiently controlled network dynamics in
  naive macaque monkeys","Main Text: 17 pages and 6 figures; Supplement Text: 9 pages and 8
  figures",,,,"q-bio.NC cs.IT math.IT math.OC q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Primates display a marked ability to learn habits in uncertain and dynamic
environments. The associated perceptions and actions of such habits engage
distributed neural circuits. Yet, precisely how such circuits support the
computations necessary for habit learning remain far from understood. Here we
construct a formal theory of network energetics to account for how changes in
brain state produce changes in sequential behavior. We exercise the theory in
the context of multi-unit recordings spanning the caudate nucleus, prefrontal
cortex, and frontal eyefields of female macaque monkeys engaged in 60-180
sessions of a free scan task that induces motor habits. The theory relies on
the determination of effective connectivity between recording channels, and on
the stipulation that a brain state is taken to be the trial-specific firing
rate across those channels. The theory then predicts how much energy will be
required to transition from one state into another, given the constraint that
activity can spread solely through effective connections. Consistent with the
theory's predictions, we observed smaller energy requirements for transitions
between more similar and more complex trial saccade patterns, and for sessions
characterized by less entropic selection of saccade patterns. Using a virtual
lesioning approach, we demonstrate the resilience of the observed relationships
between minimum control energy and behavior to significant disruptions in the
inferred effective connectivity. Our theoretically principled approach to the
study of habit learning paves the way for future efforts examining how behavior
arises from changing patterns of activity in distributed neural circuitry.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:09:07 GMT""}]","2020-06-26"
"2006.14566","Saad Nadeem","Saad Nadeem, Travis Hollmann and Allen Tannenbaum","Multimarginal Wasserstein Barycenter for Stain Normalization and
  Augmentation","To appear in MICCAI 2020",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variations in hematoxylin and eosin (H&E) stained images (due to clinical lab
protocols, scanners, etc) directly impact the quality and accuracy of clinical
diagnosis, and hence it is important to control for these variations for a
reliable diagnosis. In this work, we present a new approach based on the
multimarginal Wasserstein barycenter to normalize and augment H&E stained
images given one or more references. Specifically, we provide a mathematically
robust way of naturally incorporating additional images as intermediate
references to drive stain normalization and augmentation simultaneously. The
presented approach showed superior results quantitatively and qualitatively as
compared to state-of-the-art methods for stain normalization. We further
validated our stain normalization and augmentations in the nuclei segmentation
task on a publicly available dataset, achieving state-of-the-art results
against competing approaches.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:09:40 GMT""}]","2020-06-26"
"2006.14567","Tatjana Chavdarova","Tatjana Chavdarova, Matteo Pagliardini, Sebastian U. Stich, Francois
  Fleuret, Martin Jaggi","Taming GANs with Lookahead-Minmax",,"ICLR 2021",,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative Adversarial Networks are notoriously challenging to train. The
underlying minmax optimization is highly susceptible to the variance of the
stochastic gradient and the rotational component of the associated game vector
field. To tackle these challenges, we propose the Lookahead algorithm for
minmax optimization, originally developed for single objective minimization
only. The backtracking step of our Lookahead-minmax naturally handles the
rotational game dynamics, a property which was identified to be key for
enabling gradient ascent descent methods to converge on challenging examples
often analyzed in the literature. Moreover, it implicitly handles high variance
without using large mini-batches, known to be essential for reaching state of
the art performance. Experimental results on MNIST, SVHN, CIFAR-10, and
ImageNet demonstrate a clear advantage of combining Lookahead-minmax with Adam
or extragradient, in terms of performance and improved stability, for
negligible memory and computational cost. Using 30-fold fewer parameters and
16-fold smaller minibatches we outperform the reported performance of the
class-dependent BigGAN on CIFAR-10 by obtaining FID of 12.19 without using the
class labels, bringing state-of-the-art GAN training within reach of common
computational resources.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:13:23 GMT""},{""version"":""v2"",""created"":""Mon, 26 Oct 2020 21:59:07 GMT""},{""version"":""v3"",""created"":""Wed, 23 Jun 2021 17:54:03 GMT""}]","2021-06-24"
"2006.14568","Oleksii Matsedonskyi","Ranny Budnik, Hyungjin Kim, Oleksii Matsedonskyi, Gilad Perez, Yotam
  Soreq","Probing the relaxed relaxion and Higgs-portal with S1 & S2","8 pages, 5 figures; new bounds on relaxion parameter space are added","Phys. Rev. D 104, 015012 (2021)","10.1103/PhysRevD.104.015012",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the recent \XeT excess in context of solar scalar, specifically in
the framework of Higgs-portal and the relaxion model. We show that $m_\phi =
1.9\,\keV$ and $g_{\phi e}=2.4\times 10^{-14}$ can explain the observed excess
in science run 1 (SR1) analysis in the 1-7 keV range. When translated into the
scalar-Higgs mixing angle, the corresponding mixing angle $\sin\theta =
10^{-8}$ is intriguingly close to the maximum value of mixing angle for the
technical naturalness of the scalar mass. Unlike the solar axion model, the
excess favors a massive scalar field because of its softer spectrum. In the
minimal scenarios we consider, the best fit parameters are in tension with
stellar cooling bounds. We discuss a possibility that a large density of red
giant stars may trigger a phase transition, resulting in a local scalar mass
increase suppressing the stellar cooling. For the particular case of minimal
relaxion scenarios, we find that such type of chameleon effects is
automatically present but they can not ease the cooling bounds. They are
however capable of triggering a catastrophic phase transition in the entire
universe. Following this observation we derive a new set of bounds on the
relaxed-relaxion parameter space.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:14:47 GMT""},{""version"":""v2"",""created"":""Sun, 30 Aug 2020 19:41:10 GMT""}]","2021-07-14"
"2006.14569","Renaud Boussarie","Renaud Boussarie and Yacine Mehtar-Tani","A novel formulation of the unintegrated gluon distribution for DIS","6 pages, 3 figures",,"10.1016/j.physletb.2022.137125",,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a semi-classical description of the inclusive gluon induced Deep
Inelastic Scattering cross section in a way that accounts for the leading
powers in both the Regge and Bjorken limits. Our approach thus allows a
systematic matching of small and moderate $x_{\rm Bj}$ regimes of gluon proton
structure functions. We find a new unintegrated gluon distribution with an
explicit dependence on the longitudinal momentum fraction $x$ which entirely
spans both the dipole operator and the gluonic Parton Distribution Function.
Computing this gauge invariant gluon operator on the lattice could allow to
probe the energy dependence of the saturation scale from first principles.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:15:16 GMT""}]","2022-04-27"
"2006.14570","Yacine Ali-Ha\""imoud","Yacine Ali-Ha\""imoud, Tristan L. Smith and Chiara M. F. Mingarelli","Fisher formalism for anisotropic gravitational-wave background searches
  with pulsar timing arrays","Version accepted for publication in PRD after minor changes.
  Follow-up paper on applications: arXiv:2010.13958","Phys. Rev. D 102, 122005 (2020)","10.1103/PhysRevD.102.122005",,"gr-qc astro-ph.IM physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pulsar timing arrays (PTAs) are currently the only experiments directly
sensitive to gravitational waves with decade-long periods. Within the next five
to ten years, PTAs are expected to detect the stochastic gravitational-wave
background (SGWB) collectively sourced by inspiralling supermassive black hole
binaries. It is expected that this background is mostly isotropic, and current
searches focus on the monopole part of the SGWB. Looking ahead, anisotropies in
the SGWB may provide a trove of additional information both on known and
unknown astrophysical and cosmological sources. In this paper, we build a
simple yet realistic Fisher formalism for anisotropic SGWB searches with PTAs.
Our formalism is able to accommodate realistic properties of PTAs, and allows
simple and accurate forecasts. We illustrate our approach with an idealized PTA
consisting of identical, isotropically distributed pulsars. In a companion
paper, we apply our formalism to current PTAs and show that it can be a
powerful tool to guide and optimize real data analysis.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:16:20 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 19:43:22 GMT""}]","2021-01-04"
"2006.14571","Kyriakos Axiotis","Kyriakos Axiotis and Maxim Sviridenko","Sparse Convex Optimization via Adaptively Regularized Hard Thresholding","Accepted to ICML 2020",,,,"cs.LG cs.DS stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of Sparse Convex Optimization is to optimize a convex function $f$
under a sparsity constraint $s\leq s^*\gamma$, where $s^*$ is the target number
of non-zero entries in a feasible solution (sparsity) and $\gamma\geq 1$ is an
approximation factor. There has been a lot of work to analyze the sparsity
guarantees of various algorithms (LASSO, Orthogonal Matching Pursuit (OMP),
Iterative Hard Thresholding (IHT)) in terms of the Restricted Condition Number
$\kappa$. The best known algorithms guarantee to find an approximate solution
of value $f(x^*)+\epsilon$ with the sparsity bound of $\gamma =
O\left(\kappa\min\left\{\log \frac{f(x^0)-f(x^*)}{\epsilon},
\kappa\right\}\right)$, where $x^*$ is the target solution. We present a new
Adaptively Regularized Hard Thresholding (ARHT) algorithm that makes
significant progress on this problem by bringing the bound down to
$\gamma=O(\kappa)$, which has been shown to be tight for a general class of
algorithms including LASSO, OMP, and IHT. This is achieved without significant
sacrifice in the runtime efficiency compared to the fastest known algorithms.
We also provide a new analysis of OMP with Replacement (OMPR) for general $f$,
under the condition $s > s^* \frac{\kappa^2}{4}$, which yields Compressed
Sensing bounds under the Restricted Isometry Property (RIP). When compared to
other Compressed Sensing approaches, it has the advantage of providing a strong
tradeoff between the RIP condition and the solution sparsity, while working for
any general function $f$ that meets the RIP condition.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:16:21 GMT""}]","2020-06-26"
"2006.14572","Kieran Leschinski","Kieran Leschinski (1), Eric Gendron (2) ((1) University of Vienna, (2)
  Observatoire de Paris)","AnisoCADO: a python package for analytically generating adaptive optics
  point spread functions for the Extremely Large Telescope","4 pages, 1 figure, 1 table",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  AnisoCADO is a Python package for generating images of the point spread
function (PSF) for the european extremely large telescope (ELT). The code
allows the user to set many of the most important atmospheric and observational
parameters that influence the shape and strehl ratio of the resulting PSF,
including but not limited to: the atmospheric turbulence profile, the guide
star position for a single conjugate adaptive optics (SCAO) solution,
differential telescope pupil transmission, etc. Documentation can be found at
https://anisocado.readthedocs.io/en/latest/
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:17:39 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 18:27:31 GMT""}]","2020-07-02"
"2006.14573","Michael Zevin","Michael Zevin, Mario Spera, Christopher P. L. Berry, Vicky Kalogera","Exploring the Lower Mass Gap and Unequal Mass Regime in Compact Binary
  Evolution","19 pages (9 pages main text + 8 pages appendices/references), 6
  figures, 1 table, published in ApJL","The Astrophysical Journal Letters 899, L1 (2020)","10.3847/2041-8213/aba74e",,"astro-ph.HE astro-ph.SR gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On August 14, 2019, the LIGO and Virgo detectors observed GW190814, a
gravitational-wave signal originating from the merger of a $\simeq 23 M_\odot$
black hole with a $\simeq 2.6 M_\odot$ compact object. GW190814's
compact-binary source is atypical both in its highly asymmetric masses and in
its lower-mass component lying between the heaviest known neutron star and
lightest known black hole in a compact-object binary. If formed through
isolated binary evolution, the mass of the secondary is indicative of its mass
at birth. We examine the formation of such systems through isolated binary
evolution across a suite of assumptions encapsulating many physical
uncertainties in massive-star binary evolution. We update how mass loss is
implemented for the neutronization process during the collapse of the
proto-compact object to eliminate artificial gaps in the mass spectrum at the
transition between neutron stars and black holes. We find it challenging for
population modeling to match the empirical rate of GW190814-like systems whilst
simultaneously being consistent with the rates of other compact binary
populations inferred by gravitational-wave observations. Nonetheless, the
formation of GW190814-like systems at any measurable rate requires a supernova
engine model that acts on longer timescales such that the proto-compact object
can undergo substantial accretion immediately prior to explosion, hinting that
if GW190814 is the result of massive-star binary evolution, the mass gap
between neutron stars and black holes may be narrower or nonexistent.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:18:10 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 17:57:49 GMT""},{""version"":""v3"",""created"":""Thu, 6 Aug 2020 15:19:44 GMT""}]","2020-08-07"
"2006.14574","Anderson Barbosa A. L. R. Barbosa","F. A. F. Santana, J. M. da Silva, T. C. Vasconcelos, J. G. G. S.
  Ramos, and A. L. R. Barbosa","Spin Hall angle fluctuations in a disorder device","Accepted for publication as a Rapid Communication in Physical Review
  B","Phys. Rev. B 102, 041107(R) (2020)","10.1103/PhysRevB.102.041107",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate a disorderly mesoscopic device that supports spin-orbit
interaction. The systemis connected to four semi-infinite leads embedded in the
Landauer-Buttiker setup for quantumtransport and, according to our analysis,
exhibits spin Hall angle fluctuations. We show analyticallyand numerically the
fingerprint of the universal fluctuation of the polarization mediated by
theconversion of charge current into spin current. Our investigation shows the
complete compatibilityof our analytical and numerical results with the most
recent experiments. Furthermore, we shownonzero and universal features of spin
Hall effect in Rashba 2DEG with disorder. All the resultsshow the relevance of
microscopic parameters for electronic transport with charge-spin conversionand,
in many cases, inevitably lead to universal numbers.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:19:02 GMT""}]","2020-07-07"
"2006.14575","Subhas Khajanchi Dr.","Subhas Khajanchi, Kankan Sarkar","Forecasting the daily and cumulative number of cases for the COVID-19
  pandemic in India","18 Pages, 7 Figures",,"10.1063/5.0016240",,"q-bio.PE physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  The ongoing novel coronavirus epidemic has been announced a pandemic by the
World Health Organization on March 11, 2020, and the Govt. of India has
declared a nationwide lockdown from March 25, 2020, to prevent community
transmission of COVID-19. Due to absence of specific antivirals or vaccine,
mathematical modeling play an important role to better understand the disease
dynamics and designing strategies to control rapidly spreading infectious
diseases. In our study, we developed a new compartmental model that explains
the transmission dynamics of COVID-19. We calibrated our proposed model with
daily COVID-19 data for the four Indian provinces, namely Jharkhand, Gujarat,
Andhra Pradesh, and Chandigarh. We study the qualitative properties of the
model including feasible equilibria and their stability with respect to the
basic reproduction number $\mathcal{R}_0$. The disease-free equilibrium becomes
stable and the endemic equilibrium becomes unstable when the recovery rate of
infected individuals increased but if the disease transmission rate remains
higher then the endemic equilibrium always remain stable. For the estimated
model parameters, $\mathcal{R}_0 >1$ for all the four provinces, which suggests
the significant outbreak of COVID-19. Short-time prediction shows the
increasing trend of daily and cumulative cases of COVID-19 for the four
provinces of India.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:20:34 GMT""}]","2020-08-26"
"2006.14576","Yi Shi","Yi Shi, Kemal Davaslioglu, Yalin E. Sagduyu","Over-the-Air Membership Inference Attacks as Privacy Threats for Deep
  Learning-based Wireless Signal Classifiers",,,,,"eess.SP cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents how to leak private information from a wireless signal
classifier by launching an over-the-air membership inference attack (MIA). As
machine learning (ML) algorithms are used to process wireless signals to make
decisions such as PHY-layer authentication, the training data characteristics
(e.g., device-level information) and the environment conditions (e.g., channel
information) under which the data is collected may leak to the ML model. As a
privacy threat, the adversary can use this leaked information to exploit
vulnerabilities of the ML model following an adversarial ML approach. In this
paper, the MIA is launched against a deep learning-based classifier that uses
waveform, device, and channel characteristics (power and phase shifts) in the
received signals for RF fingerprinting. By observing the spectrum, the
adversary builds first a surrogate classifier and then an inference model to
determine whether a signal of interest has been used in the training data of
the receiver (e.g., a service provider). The signal of interest can then be
associated with particular device and channel characteristics to launch
subsequent attacks. The probability of attack success is high (more than 88%
depending on waveform and channel conditions) in identifying signals of
interest (and potentially the device and channel information) used to build a
target classifier. These results show that wireless signal classifiers are
vulnerable to privacy threats due to the over-the-air information leakage of
their ML models
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:23:32 GMT""}]","2020-06-26"
"2006.14577","Lei Feng","Lei Zu, Guan-Wen Yuan, Lei Feng, Yi-Zhong Fan","Mirror Dark Matter and Electronic Recoil Events in XENON1T","5 pages, 3 figures","Nuclear Physics B 965 (2021) 115369","10.1016/j.nuclphysb.2021.115369",,"hep-ph astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the XENON1T experiment has reported the possible detection of an
excess in the electronic recoil spectrum. Such an excess may indicate the
presence of new physics. In this work, we suggest that the scattering of mirror
electrons with ordinary electrons through photon$-$mirror photon kinetic mixing
with parameter $\epsilon \sim 10^{-12}(n_{\rm e'}/0.2{\rm
cm^{-3}})^{-1/2}({v_{\rm c}^0/5\times 10^{9}~{\rm cm~s^{-1}}})^{1/2}$ may
account for the excess electronic recoil events in XENON1T, where $n_{\rm e'}$
is the density of mirror electron and $v_{\rm c}^0$ is the cutoff velocity of
the mirror electron arriving at the earth. Interestingly, this parameter to
interpret the excess of XENON1T electronic recoil spectrum are consistent with
the constrains of Darkside50.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:24:07 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jul 2020 03:48:06 GMT""},{""version"":""v3"",""created"":""Mon, 16 Aug 2021 03:35:30 GMT""}]","2021-08-17"
"2006.14578","Haojian Li","Haojian Li, Marius Junge and Nicholas LaRacuente","Graph H\""ormander Systems",,,,,"math-ph math.DG math.FA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper extends the Bakry-\'{E}mery theorem connecting the Ricci curvature
and log-Sobolev inequalities to the matrix-valued setting. Using tools from
noncommuative geometry, it is shown that for a right invariant second order
differential operator on a compact Lie group, a lower bound for a matrix-valued
modified log-Sobolev inequality is equivalent to a uniform lower bound for all
finite dimensional representations. Using combinatorial tools, we obtain
computable lower bounds for matrix-valued log-Sobolev inequalities of
graph-H\""ormander systems using combinatorial methods.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:24:18 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 17:12:44 GMT""},{""version"":""v3"",""created"":""Mon, 29 Jun 2020 18:06:14 GMT""}]","2020-07-01"
"2006.14579","George Fisher","J. Todd Hoeksema, William P. Abbett, David J. Bercik, Mark C. M.
  Cheung, Marc L. DeRosa, George H. Fisher, Keiji Hayashi, Maria D. Kazachenko,
  Yang Liu, Erkka Lumme, Benjamin J. Lynch, Xudong Sun, and Brian T. Welsch","The Coronal Global Evolutionary Model: Using HMI Vector Magnetogram and
  Doppler Data to Determine Coronal Magnetic Field Evolution","19 pages, 8 figures","Astrophysical Journal Supplement Series 250:28 (15pp), 2020
  October","10.3847/1538-4365/abb3fb",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Coronal Global Evolutionary Model (CGEM) provides data-driven simulations
of the magnetic field in the solar corona to better understand the build-up of
magnetic energy that leads to eruptive events. The CGEM project has developed
six capabilities. CGEM modules (1) prepare time series of full-disk vector
magnetic field observations to (2) derive the changing electric field in the
solar photosphere over active-region scales. This local electric field is (3)
incorporated into a surface flux transport model that reconstructs a global
electric field that evolves magnetic flux in a consistent way. These electric
fields drive a (4) 3D spherical magneto-frictional (SMF) model, either at
high-resolution over a restricted range of solid angle or at lower resolution
over a global domain, to determine the magnetic field and current density in
the low corona. An SMF-generated initial field above an active region and the
evolving electric field at the photosphere are used to drive (5) detailed
magneto-hydrodynamic (MHD) simulations of active regions in the low corona. SMF
or MHD solutions are then used to compute emissivity proxies that can be
compared with coronal observations. Finally, a lower-resolution SMF magnetic
field is used to initialize (6) a global MHD model that is driven by an SMF
electric-field time series to simulate the outer corona and heliosphere,
ultimately connecting Sun to Earth. As a demonstration, this report features
results of CGEM applied to observations of the evolution of NOAA Active Region
11158 in February 2011.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:26:02 GMT""},{""version"":""v2"",""created"":""Fri, 2 Oct 2020 23:27:04 GMT""}]","2020-10-06"
"2006.14580","Emily Wenger","Emily Wenger, Josephine Passananti, Arjun Bhagoji, Yuanshun Yao,
  Haitao Zheng, Ben Y. Zhao","Backdoor Attacks Against Deep Learning Systems in the Physical World","Accepted to the 2021 Conference on Computer Vision and Pattern
  Recognition (CVPR 2021); 14 pages",,,,"cs.CV cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Backdoor attacks embed hidden malicious behaviors into deep learning models,
which only activate and cause misclassifications on model inputs containing a
specific trigger. Existing works on backdoor attacks and defenses, however,
mostly focus on digital attacks that use digitally generated patterns as
triggers. A critical question remains unanswered: can backdoor attacks succeed
using physical objects as triggers, thus making them a credible threat against
deep learning systems in the real world? We conduct a detailed empirical study
to explore this question for facial recognition, a critical deep learning task.
Using seven physical objects as triggers, we collect a custom dataset of 3205
images of ten volunteers and use it to study the feasibility of physical
backdoor attacks under a variety of real-world conditions. Our study reveals
two key findings. First, physical backdoor attacks can be highly successful if
they are carefully configured to overcome the constraints imposed by physical
objects. In particular, the placement of successful triggers is largely
constrained by the target model's dependence on key facial features. Second,
four of today's state-of-the-art defenses against (digital) backdoors are
ineffective against physical backdoors, because the use of physical objects
breaks core assumptions used to construct these defenses. Our study confirms
that (physical) backdoor attacks are not a hypothetical phenomenon but rather
pose a serious real-world threat to critical classification tasks. We need new
and more robust defenses against backdoors in the physical world.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:26:20 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 22:12:56 GMT""},{""version"":""v3"",""created"":""Wed, 14 Apr 2021 16:41:55 GMT""},{""version"":""v4"",""created"":""Tue, 7 Sep 2021 17:42:01 GMT""}]","2021-09-08"
"2006.14581","Oleg Kovalenko","Vladyslav Babenko, Vira Babenko and Oleg Kovalenko","Korneichuk-Stechkin Lemma, Ostrowski and Landau inequalities, and
  optimal recovery problems for $L$-space Valued Functions",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove an analogue of the Korneichuk--Stechkin lemma for functions with
values in $L$-spaces. As applications, we obtain sharp Ostrowski type
inequalities and solve problems of optimal recovery of identity and
convexifying operators, as well as the problem of integral recovery, on the
classes of $L$-space valued functions with given majorant of modulus of
continuity. The recovery is done based on $n$ mean values of the functions over
some intervals. Moreover, on the classes of functions with given majorant of
modulus of continuity of their Hukuhara type derivative, we solve the problem
of optimal recovery of the function and the Hukuhara type derivative. The
recovery is done based on $n$ values of the function. We also obtain some sharp
Landau type inequalities and solve an analogue of the Stechkin problem about
approximation of unbounded operators by bounded ones and the problem of optimal
recovery of an unbounded operator on a class of elements, known with error.
Consideration of $L$-space valued functions gives a unified approach to
solution of the mentioned above extremal problems for the classes of multi- and
fuzzy-valued functions as well as for the classes of functions with values in
Banach spaces, in particular random processes, and many other classes of
functions.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:28:54 GMT""}]","2020-06-26"
"2006.14582","Xianhang Li","Xianhang Li, Yali Wang, Zhipeng Zhou, Yu Qiao","SmallBigNet: Integrating Core and Contextual Views for Video
  Classification","CVPR2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Temporal convolution has been widely used for video classification. However,
it is performed on spatio-temporal contexts in a limited view, which often
weakens its capacity of learning video representation. To alleviate this
problem, we propose a concise and novel SmallBig network, with the cooperation
of small and big views. For the current time step, the small view branch is
used to learn the core semantics, while the big view branch is used to capture
the contextual semantics. Unlike traditional temporal convolution, the big view
branch can provide the small view branch with the most activated video features
from a broader 3D receptive field. Via aggregating such big-view contexts, the
small view branch can learn more robust and discriminative spatio-temporal
representations for video classification. Furthermore, we propose to share
convolution in the small and big view branch, which improves model compactness
as well as alleviates overfitting. As a result, our SmallBigNet achieves a
comparable model size like 2D CNNs, while boosting accuracy like 3D CNNs. We
conduct extensive experiments on the large-scale video benchmarks, e.g.,
Kinetics400, Something-Something V1 and V2. Our SmallBig network outperforms a
number of recent state-of-the-art approaches, in terms of accuracy and/or
efficiency. The codes and models will be available on
https://github.com/xhl-video/SmallBigNet.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:29:57 GMT""}]","2020-06-26"
"2006.14583","Dongge Han","Dongge Han, Michael Wooldridge, Alex Rogers, Olga Ohrimenko, Sebastian
  Tschiatschek","Replication-Robust Payoff-Allocation for Machine Learning Data Markets","Published in IEEE Transactions on Artificial Intelligence",,"10.1109/TAI.2022.3195686",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Submodular functions have been a powerful mathematical model for a wide range
of real-world applications. Recently, submodular functions are becoming
increasingly important in machine learning (ML) for modelling notions such as
information and redundancy among entities such as data and features. Among
these applications, a key question is payoff allocation, i.e., how to evaluate
the importance of each entity towards the collective objective? To this end,
classic solution concepts from cooperative game theory offer principled
approaches to payoff allocation. However, despite the extensive body of
game-theoretic literature, payoff allocation in submodular games are relatively
under-researched. In particular, an important notion that arises in the
emerging submodular applications is redundancy, which may occur from various
sources such as abundant data or malicious manipulations where a player
replicates its resource and act under multiple identities. Though many
game-theoretic solution concepts can be directly used in submodular games,
naively applying them for payoff allocation in these settings may incur
robustness issues against replication. In this paper, we systematically study
the replication manipulation in submodular games and investigate replication
robustness, a metric that quantitatively measures the robustness of solution
concepts against replication. Using this metric, we present conditions which
theoretically characterise the robustness of semivalues, a wide family of
solution concepts including the Shapley and Banzhaf value. Moreover, we
empirically validate our theoretical results on an emerging submodular ML
application, i.e., the ML data market.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:30:12 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 14:29:08 GMT""},{""version"":""v3"",""created"":""Thu, 22 Apr 2021 21:03:42 GMT""},{""version"":""v4"",""created"":""Sun, 15 May 2022 15:49:37 GMT""},{""version"":""v5"",""created"":""Fri, 26 Aug 2022 15:04:44 GMT""},{""version"":""v6"",""created"":""Tue, 15 Nov 2022 22:34:28 GMT""}]","2022-11-17"
"2006.14584","Vahdat Abdelzad","Vahdat Abdelzad, Krzysztof Czarnecki, Rick Salay","The Effect of Optimization Methods on the Robustness of
  Out-of-Distribution Detection Approaches","13 pages, 4 figures, 15 tables",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) have become the de facto learning mechanism in
different domains. Their tendency to perform unreliably on out-of-distribution
(OOD) inputs hinders their adoption in critical domains. Several approaches
have been proposed for detecting OOD inputs. However, existing approaches still
lack robustness. In this paper, we shed light on the robustness of OOD
detection (OODD) approaches by revealing the important role of optimization
methods. We show that OODD approaches are sensitive to the type of optimization
method used during training deep models. Optimization methods can provide
different solutions to a non-convex problem and so these solutions may or may
not satisfy the assumptions (e.g., distributions of deep features) made by OODD
approaches. Furthermore, we propose a robustness score that takes into account
the role of optimization methods. This provides a sound way to compare OODD
approaches. In addition to comparing several OODD approaches using our proposed
robustness score, we demonstrate that some optimization methods provide better
solutions for OODD approaches.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:32:22 GMT""}]","2020-06-26"
"2006.14585","Lev Tovstopyat-Nelip","Lev Tovstopyat-Nelip","Quasipositive surfaces and decomposable Lagrangians","Comments welcome",,,,"math.GT math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that a quasipositive surface with disconnected boundary induces a map
between the knot Floer homology groups of its boundary components preserving
the transverse invariant. As an application, we show that this invariant can be
used to obstruct decomposable Lagrangian cobordisms of arbitrary genus within
Weinstein cobordisms. The construction of our maps rely on the
comultiplicativity of the transverse invariant. Along the way, we also recover
various naturality statements for the invariant under contact +1 surgery.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:32:28 GMT""}]","2020-06-26"
"2006.14586","C. Ian Short","C. Ian Short","In situ exo-planet transit lightcurve modelling with the Chroma+ suite","Eleven pages (""manuscript format"") with one figure",,,,"astro-ph.SR astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have added to the Chroma+ suite of stellar atmosphere and spectrum
modelling codes the ability to synthesize the exo-planet transit lightcurve for
planets of arbitrary size up to 10% of the host stellar radius, and arbitrary
planetary and stellar mass and orbital radius (thus determining orbital
velocity) and arbitrary orbital inclination. The lightcurves are computed in
situ, integrated with the radiative transfer solution for the radiation field
emerging from the stellar surface, and there is no limb-darkening
parameterization. The lightcurves are computed for the Johnson-Bessel
photometric system UBVRIHJK. We describe our method of computing the transit
path, and the reduction in flux caused by occultation, and compare our
lightcurve to an analytic solution with a four-parameter limb-darkening
parameterization for the case of an edge-on transit of the Sun by Earth. This
capability has been added to all ports and variations, including the Python
port, ChromaStarPy, and the version that interpolates among the fully
line-blanketed ATLAS9 surface intensity distributions, ChromaStarAtlas. All
codes may be accessed at www.ap.smu.ca/OpenStars and at GitHub
(github.com/sevenian3).
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:32:44 GMT""}]","2020-06-26"
"2006.14587","Sambaran Banerjee Dr.","Sambaran Banerjee","LISA sources from young massive and open stellar clusters","13 pages, 3 figures, 1 table. Extended descriptions, discussions, and
  bibliography; results unaltered. Accepted for publication in Phys. Rev. D","Phys. Rev. D 102, 103002 (2020)","10.1103/PhysRevD.102.103002",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I study the potential role of young massive (YMCs) and open star clusters
(OCs) in assembling stellar-mass binary black holes (BBHs) which would be
detectable as persistent gravitational-wave (GW) sources by the forthcoming
LISA mission. The energetic dynamical interactions inside star clusters make
them factories of assembling BBHs and other types of double-compact binaries
that undergo general-relativistic (GR) inspiral and merger. The initial phase
of such inspirals would, typically, sweep through the LISA GW band. Here, such
LISA sources are studied from a set of evolutionary models of star clusters
with masses ranging over $10^4M_\odot-10^5M_\odot$ that represent YMCs and
intermediate-aged OCs in metal-rich and metal-poor environments of the Local
Universe. These models are evolved with long-term, direct, relativistic
many-body computations incorporating state-of-the-art stellar-evolutionary and
remnant-formation models. Based on models of Local Universe constructed with
such model clusters, it is shown that YMCs and intermediate-aged OCs would
yield several 10s to 100s of LISA BBH sources at the current cosmic epoch with
GW frequency within $10^{-3}{\rm~Hz} - 10^{-1}{\rm~Hz}$ and
signal-to-noise-ratio (S/N) $>5$, assuming a mission lifetime of 5 or 10 years.
Such LISA BBHs would have a bimodal distribution in total mass, be generally
eccentric ($\lesssim0.7$), and typically have similar component masses although
mass-asymmetric systems are possible. Intrinsically, there would be 1000s of
present-day, LISA-detectable BBHs from YMCs and OCs. That way, YMCs and OCs
would provide a significant and the dominant contribution to the stellar-mass
BBH population detectable by LISA. A small fraction, $<5$%, of these BBHs would
undergo GR inspiral to make it to LIGO-Virgo GW frequency band and merge,
within the mission timespan; $<15$% would do so within twice the timespan.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:34:21 GMT""},{""version"":""v2"",""created"":""Tue, 29 Sep 2020 13:49:29 GMT""}]","2020-11-11"
"2006.14588","Andr\'as D\'er Dr.","Andras Buzas, Elmar K. Wolff, Mihaly G. Benedict, Pal Ormos and Andras
  Der","Biological Microscopy with Undetected Photons","This article has been accepted for publication in IEEE Access, but
  has not been fully edited","Published in: IEEE Access ( Volume: 8 ) Page(s): 107539 - 107548
  Date of Publication: 08 June 2020 Electronic ISSN: 2169-3536 DOI:
  10.1109/ACCESS.2020.3000740 Publisher: IEEE","10.1109/ACCESS.2020.3000740",,"physics.app-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  Novel imaging techniques utilizing nondegenerate, correlated photon pairs
sparked intense interest during the last couple of years among scientists of
the quantum optics community and beyond. It is a key property of such ""ghost
imaging"" or ""quantum interference"" methods that they use those photons of the
correlated pairs for imaging that never interacted with the sample, allowing
detection in a spectral range different from that of the illumination of the
object. Extensive applications of these techniques in spectroscopy and
microscopy are envisioned, however, their limited spatial resolution to date
has not yet supported real-life microscopic investigations of tiny biological
objects. Here we report a modification of the method based on quantum
interference by using a seeding laser and confocal scanning, that allows the
improvement of the resolution of imaging with undetected photons by more than
an order of magnitude, and we also present examples of application in the
microscopy of biological samples.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:34:29 GMT""}]","2020-06-26"
"2006.14589","Ziv Ran","Ziv Ran","Incident rational curves",,"European J. Math.(2020)","10.1007/s40879-020-00407-y",,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study families of rational curves on an algebraic variety satisfying
incidence conditions. We prove an analogue of bend-and-break: that is, we show
that under suitable conditions, such a family must contain reducibles. In the
case of curves in $\P^n$ incident to certain complete intersections, we prove
the family is irreducible.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:35:00 GMT""}]","2020-06-26"
"2006.14590","Farinaldo Queiroz","Manfred Lindner, Yann Mambrini, Tessio B. de Melo, Farinaldo S.
  Queiroz","XENON1T Anomaly: A Light $Z^\prime$","6 pages, 1 figure",,"10.1016/j.physletb.2020.135972","IIP-2020","hep-ph astro-ph.HE hep-ex hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have witnessed the beginning of an era where dark matter and neutrino
detectors can probe similar new physics phenomena. Motivated by the low-energy
electron recoil spectrum observed by the dark matter experiment, XENON1T, at
Gran Sasso laboratory, we interpret the observed signal not in terms of a dark
matter particle, but rather in the context of a new light $Z^\prime$ gauge
boson. We discuss how such a light $Z^\prime$ rises in a Two Higgs Doublet
Model augmented by an abelian gauge symmetry where neutrino masses and the
flavor problem are addressed, in agreement with neutrino-electron scattering
data.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:35:41 GMT""}]","2020-12-02"
"2006.14591","Constantin Philippenko","Constantin Philippenko and Aymeric Dieuleveut","Bidirectional compression in heterogeneous settings for distributed or
  federated learning with partial participation: tight convergence guarantees","54 pages, 4 theorems, 1 algorithm, code source on GitHub",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a framework - Artemis - to tackle the problem of learning in a
distributed or federated setting with communication constraints and device
partial participation. Several workers (randomly sampled) perform the
optimization process using a central server to aggregate their computations. To
alleviate the communication cost, Artemis allows to compress the information
sent in both directions (from the workers to the server and conversely)
combined with a memory mechanism. It improves on existing algorithms that only
consider unidirectional compression (to the server), or use very strong
assumptions on the compression operator, and often do not take into account
devices partial participation. We provide fast rates of convergence (linear up
to a threshold) under weak assumptions on the stochastic gradients (noise's
variance bounded only at optimal point) in non-i.i.d. setting, highlight the
impact of memory for unidirectional and bidirectional compression, analyze
Polyak-Ruppert averaging. We use convergence in distribution to obtain a lower
bound of the asymptotic variance that highlights practical limits of
compression. We propose two approaches to tackle the challenging case of
devices partial participation and provide experimental results to demonstrate
the validity of our analysis.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:37:45 GMT""},{""version"":""v2"",""created"":""Thu, 5 Nov 2020 10:39:53 GMT""},{""version"":""v3"",""created"":""Mon, 8 Mar 2021 15:03:32 GMT""},{""version"":""v4"",""created"":""Sun, 19 Jun 2022 15:40:37 GMT""}]","2022-06-22"
"2006.14592","Guojun Zhang","Guojun Zhang, Kaiwen Wu, Pascal Poupart and Yaoliang Yu","Newton-type Methods for Minimax Optimization","code update",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Differential games, in particular two-player sequential zero-sum games
(a.k.a. minimax optimization), have been an important modeling tool in applied
science and received renewed interest in machine learning due to many recent
applications, such as adversarial training, generative models and reinforcement
learning. However, existing theory mostly focuses on convex-concave functions
with few exceptions. In this work, we propose two novel Newton-type algorithms
for nonconvex-nonconcave minimax optimization. We prove their local convergence
at strict local minimax points, which are surrogates of global solutions. We
argue that our Newton-type algorithms nicely complement existing ones in that
(a) they converge faster to strict local minimax points; (b) they are much more
effective when the problem is ill-conditioned; (c) their computational
complexity remains similar. We verify the effectiveness of our Newton-type
algorithms through experiments on training GANs which are intrinsically
nonconvex and ill-conditioned. Our code is available at
https://github.com/watml/min-max-2nd-order.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:38:00 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 01:54:34 GMT""},{""version"":""v3"",""created"":""Sat, 18 Feb 2023 23:10:02 GMT""}]","2023-02-21"
"2006.14593","Soumen Roy","Saptarshi Sinha, Deep Nath, and Soumen Roy","Topology dependent payoffs can lead to escape from prisoner's dilemma","Replaced by the version accepted to European Physical Journal B","The European Physical Journal B, 94, 80 (2021)","10.1140/epjb/s10051-021-00087-x",,"physics.soc-ph cs.SI q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The maintenance of cooperation in the presence of spatial restrictions has
been studied extensively. It is well-established that the underlying graph
topology can significantly influence the outcome of games on graphs.
Maintenance of cooperation could be difficult, especially in the absence of
spatial restrictions. The evolution of cooperation would naturally depend on
payoffs. However, payoffs are generally considered to be invariant in a given
game. A natural yet unexplored question is whether the topology of the
underlying structures on which the games are played, possesses no role
whatsoever in the determination of payoffs. Herein, we introduce the notion of
cooperator graphs and defector graphs as well as a new form of game payoff,
which is weakly dependent on the underlying network topology. These concepts
are inspired by the well-known microbial phenomenon of quorum sensing. We
demonstrate that even with such a weak dependence, the fundamental game
dynamics and indeed the very nature of the game may be altered. Such changes in
the nature of a game have been well-reported in theoretical and experimental
studies.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:39:39 GMT""},{""version"":""v2"",""created"":""Sat, 13 Mar 2021 03:22:27 GMT""}]","2021-10-27"
"2006.14594","Cody Schimming","Cody D. Schimming and Jorge Vi\~nals","Anisotropic disclination cores in nematic liquid crystals modelled by a
  self consistent molecular field theory",,"Phys. Rev. E 102, 010701 (2020)","10.1103/PhysRevE.102.010701",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Disclination configurations of a nematic liquid crystal are studied within a
self-consistent molecular field theory. The theory is based on a tensor order
parameter, and can accommodate anisotropic elastic energies without the known
divergences in the Landau-de Gennes formulation. Our results agree with the
asymptotic results of Dzyaloshinsky for the Frank-Oseen energy and far from the
defect core, but reveal biaxial order at intermediate distances from the core,
crossing over to uniaxial, but isotropic configurations as the core is
approached. The elastic terms considered in our energy allow for separate
control of surface tension, anchoring, and elasticity contrast, and are used to
analyze recent results for lyotropic chromonic liquid crystals. The latter
display unusually large defect cores (on the order of tens of microns) which
can be used for a quantitative comparison with the theory. Both $\pm 1/2$
disclination configurations are well reproduced by our calculations. Elastic
anisotropy is also shown to lead to qualitative changes in the disclination
polarization, a quantity that is proportional to the active stress in models of
active matter.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:40:35 GMT""}]","2020-08-05"
"2006.14595","Piotr Surowka","Carlos Hoyos, Ruben Lier, Francisco Pe\~na-Benitez, Piotr Sur\'owka","Quantum Hall effective action for anisotropic Dirac semi-metal","6 pages + supplementary material, 1 figure","Phys. Rev. B 102, 081303 (2020)","10.1103/PhysRevB.102.081303",,"cond-mat.str-el hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a study of Hall transport in semi-Dirac critical phases. The
construction is based on a covariant formulation of relativistic systems with
spatial anisotropy. Geometric data together with external electromagnetic
fields is used to devise an expansion procedure that leads to a low-energy
effective action consistent with the discrete $PT$ symmetry that we impose. We
use the action to discuss terms contributing to the Hall transport and extract
the coefficients. We also discuss the associated scaling symmetry.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:41:10 GMT""}]","2020-09-02"
"2006.14596","Arsenii Titov","Mikael Chala and Arsenii Titov","One-loop running of dimension-six Higgs-neutrino operators and
  implications of a large neutrino dipole moment","27 pages, 7 figures, 2 tables, 1 matrix; Feynman diagrams made nicer;
  typos corrected; matches version published in JHEP","JHEP 09 (2020) 188","10.1007/JHEP09(2020)188",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the one-loop running of the dimension-six CP-even Higgs operators
in the Standard Model effective field theory involving the right-handed
component of the would-be Dirac neutrinos. We discuss the implications of a
large Dirac neutrino magnetic dipole moment. In particular, we demonstrate that
a neutrino magnetic moment explaining the recent XENON1T excess induces Higgs
and $Z$ invisible decays with branching ratios in the range $[10^{-18},
10^{-12}]$. These numbers are unfortunately beyond the reach of current and
near future facilities.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:41:35 GMT""},{""version"":""v2"",""created"":""Wed, 30 Sep 2020 21:59:43 GMT""}]","2020-10-02"
"2006.14597","Julian Rey","Guillermo Ballesteros, Juli\'an Rey, Marco Taoso and Alfredo Urbano","Stochastic inflationary dynamics beyond slow-roll and consequences for
  primordial black hole formation","30 pages, 9 figures. v3: minor changes, version accepted for
  publication in JCAP. v2: identical to v1",,"10.1088/1475-7516/2020/08/043",,"astro-ph.CO gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the impact of quantum diffusion on inflationary dynamics during
an ultra-slow-roll phase, which can be of particular significance for the
formation of primordial black holes. We show, by means of a fully analytical
approach, that the power spectrum of comoving curvature perturbations computed
in stochastic inflation matches precisely, at the linear level, the result
obtained by solving the Mukhanov-Sasaki equation, even in the presence of an
ultra-slow-roll phase. We confirm this result numerically in a model in which
the inflaton has a polynomial potential and is coupled quadratically to the
Ricci scalar. En route, we assess the role that quantum noise plays in the
presence of an ultra-slow-roll phase, and clarify the issue of the
quantum-to-classical transition in this scenario.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:41:52 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 06:49:43 GMT""},{""version"":""v3"",""created"":""Wed, 19 Aug 2020 07:48:35 GMT""}]","2020-09-02"
"2006.14598","Jia Liu","Christina Gao, Jia Liu, Lian-Tao Wang, Xiao-Ping Wang, Wei Xue,
  Yi-Ming Zhong","Re-examining the Solar Axion Explanation for the XENON1T Excess","8 pages, 4 figures; v2: new physics discussion improved; v3: version
  accepted for publication in PRL; v4: screening length revised","Phys. Rev. Lett. 125, 131806 (2020)","10.1103/PhysRevLett.125.131806","EFI-20-13","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The XENON1T collaboration has observed an excess in electronic recoil events
below $5~\mathrm{keV}$ over the known background, which could originate from
beyond-the-Standard-Model physics. The solar axion is a well-motivated model
that has been proposed to explain the excess, though it has tension with
astrophysical observations. The axions traveled from the Sun can be absorbed by
the electrons in the xenon atoms via the axion-electron coupling. Meanwhile,
they can also scatter with the atoms through the inverse Primakoff process via
the axion-photon coupling, which emits a photon and mimics the electronic
recoil signals. We found that the latter process cannot be neglected. After
including the $\rm{keV}$ photon produced via inverse Primakoff in the
detection, the tension with the astrophysical constraints can be significantly
reduced. We also explore scenarios involving additional new physics to further
alleviate the tension with the astrophysical bounds.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:42:32 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 20:24:44 GMT""},{""version"":""v3"",""created"":""Tue, 1 Sep 2020 14:52:19 GMT""},{""version"":""v4"",""created"":""Thu, 24 Dec 2020 03:13:30 GMT""}]","2020-12-25"
"2006.14599","Wei Hu","Wei Hu, Lechao Xiao, Ben Adlam, Jeffrey Pennington","The Surprising Simplicity of the Early-Time Learning Dynamics of Neural
  Networks",,,,,"cs.LG cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern neural networks are often regarded as complex black-box functions
whose behavior is difficult to understand owing to their nonlinear dependence
on the data and the nonconvexity in their loss landscapes. In this work, we
show that these common perceptions can be completely false in the early phase
of learning. In particular, we formally prove that, for a class of well-behaved
input distributions, the early-time learning dynamics of a two-layer
fully-connected neural network can be mimicked by training a simple linear
model on the inputs. We additionally argue that this surprising simplicity can
persist in networks with more layers and with convolutional architecture, which
we verify empirically. Key to our analysis is to bound the spectral norm of the
difference between the Neural Tangent Kernel (NTK) at initialization and an
affine transform of the data kernel; however, unlike many previous results
utilizing the NTK, we do not require the network to have disproportionately
large width, and the network is allowed to escape the kernel regime later in
training.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:42:49 GMT""}]","2020-06-26"
"2006.14600","Lorenzo Luzi","Lorenzo Luzi, Randall Balestriero, Richard G. Baraniuk","Ensembles of Generative Adversarial Networks for Disconnected Data",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most current computer vision datasets are composed of disconnected sets, such
as images from different classes. We prove that distributions of this type of
data cannot be represented with a continuous generative network without error.
They can be represented in two ways: With an ensemble of networks or with a
single network with truncated latent space. We show that ensembles are more
desirable than truncated distributions in practice. We construct a regularized
optimization problem that establishes the relationship between a single
continuous GAN, an ensemble of GANs, conditional GANs, and Gaussian Mixture
GANs. This regularization can be computed efficiently, and we show empirically
that our framework has a performance sweet spot which can be found with
hyperparameter tuning. This ensemble framework allows better performance than a
single continuous GAN or cGAN while maintaining fewer total parameters.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:44:40 GMT""}]","2020-06-26"
"2006.14601","Elias Roland Most","Elias R. Most, L. Jens Papenfort, Lukas R. Weih, Luciano Rezzolla","A lower bound on the maximum mass if the secondary in GW190814 was once
  a rapidly spinning neutron star","6 pages, 3 figures, Improved presentation and added new figure;
  results remain unchanged. Accepted by MNRAS Lett",,"10.1093/mnrasl/slaa168",,"astro-ph.HE gr-qc nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent detection of GW190814 featured the merger of a binary with a
primary having a mass of $\sim 23\,M_{\odot}$ and a secondary with a mass of
$\sim 2.6\,M_{\odot}$. While the primary was most likely a black hole, the
secondary could be interpreted as either the lightest black hole or the most
massive neutron star ever observed, but also as the indication of a novel class
of exotic compact objects. We here argue that the secondary in GW190814 needs
not be an ab-initio black hole nor an exotic object; rather, based on our
current understanding of the nuclear-matter equation of state, it can be a
rapidly rotating neutron star that collapsed to a rotating black hole at some
point before merger. Using universal relations connecting the masses and spins
of uniformly rotating neutron stars, we estimate the spin, $0.49 \lesssim \chi
\lesssim 0.68$, of the secondary -- a quantity not constrained so far by the
detection -- and a novel strict lower bound on the maximum mass, $M_{\rm TOV} >
2.08^{+0.04}_{-0.04}\, \,M_{\odot}$, of nonrotating neutron stars, consistent
with recent observations of a very massive pulsar. The new lower bound also
remains valid even in the less likely scenario in which the secondary neutron
star never collapsed to a black hole.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:44:41 GMT""},{""version"":""v2"",""created"":""Mon, 21 Sep 2020 17:10:34 GMT""}]","2020-09-30"
"2006.14602","Mohamed Sulman","Mohamed Sulman, Truong Nguyen, Ronald Haynes, Weizhang Huang","Domain Decomposition Parabolic Monge-Amp\`ere Approach for Fast
  Generation of Adaptive Moving Meshes",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A fast method is presented for adaptive moving mesh generation in
multi-dimensions using a domain decomposition parabolic Monge-Amp\`ere
approach. The domain decomposition procedure employed here is non-iterative and
involves splitting the computational domain into overlapping subdomains. An
adaptive mesh on each subdomain is then computed as the image of the solution
of the $L^2$ optimal mass transfer problem using a parabolic Monge-Amp\`ere
method. The domain decomposition approach allows straightforward implementation
for the parallel computation of adaptive meshes which helps to reduce
computational time significantly. Results are presented to show the numerical
convergence of the domain decomposition solution to the single domain solution.
Several numerical experiments are given to demonstrate the performance and
efficiency of the proposed method. The numerical results indicate that the
domain decomposition parabolic Monge-Amp\`ere method is more efficient than the
standard implementation of the parabolic Monge-Amp\`ere method on the whole
domain, in particular when computing adaptive meshes in three spatial
dimensions.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:45:21 GMT""}]","2020-06-26"
"2006.14603","Tommaso Boccali","Tommaso Boccali, Stefano Dal Pra, Daniele Spiga, Diego Ciangottini,
  Stefano Zani, Concezio Bozzi, Alessandro De Salvo, Andrea Valassi, Francesco
  Noferini, Luca dell Agnello, Federico Stagni, Alessandra Doria, Daniele
  Bonacorsi","Extension of the INFN Tier-1 on a HPC system","13 pages",,"10.1051/epjconf/202024509009",,"physics.comp-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The INFN Tier-1 located at CNAF in Bologna (Italy) is a center of the WLCG
e-Infrastructure, supporting the 4 major LHC collaborations and more than 30
other INFN-related experiments. After multiple tests towards elastic expansion
of CNAF compute power via Cloud resources (provided by Azure, Aruba and in the
framework of the HNSciCloud project), and building on the experience gained
with the production quality extension of the Tier-1 farm on remote owned sites,
the CNAF team, in collaboration with experts from the ALICE, ATLAS, CMS, and
LHCb experiments, has been working to put in production a solution of an
integrated HTC+HPC system with the PRACE CINECA center, located nearby Bologna.
Such extension will be implemented on the Marconi A2 partition, equipped with
Intel Knights Landing (KNL) processors. A number of technical challenges were
faced and solved in order to successfully run on low RAM nodes, as well as to
overcome the closed environment (network, access, software distribution, ... )
that HPC systems deploy with respect to standard GRID sites. We show
preliminary results from a large scale integration effort, using resources
secured via the successful PRACE grant N. 2018194658, for 30 million KNL core
hours.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:45:44 GMT""}]","2021-02-03"
"2006.14604","Ryan Jacobs","Dane Morgan and Ryan Jacobs","Opportunities and Challenges for Machine Learning in Materials Science",,"Annual Reviews of Materials Research, vol. 50, 2020","10.1146/annurev-matsci-070218-010015",,"cond-mat.mtrl-sci physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advances in machine learning have impacted myriad areas of materials science,
ranging from the discovery of novel materials to the improvement of molecular
simulations, with likely many more important developments to come. Given the
rapid changes in this field, it is challenging to understand both the breadth
of opportunities as well as best practices for their use. In this review, we
address aspects of both problems by providing an overview of the areas where
machine learning has recently had significant impact in materials science, and
then provide a more detailed discussion on determining the accuracy and domain
of applicability of some common types of machine learning models. Finally, we
discuss some opportunities and challenges for the materials community to fully
utilize the capabilities of machine learning.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:46:57 GMT""}]","2020-06-26"
"2006.14605","Wendelin Werner","Jason Miller, Scott Sheffield, Wendelin Werner","Non-simple conformal loop ensembles on Liouville quantum gravity and the
  law of CLE percolation interfaces","Dedicated to the memory of Harry Kesten. To appear in Probab. Theory
  Rel. Fields, 30 pages, 18 figures",,,,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the structure of the Liouville quantum gravity (LQG) surfaces that
are cut out as one explores a conformal loop-ensemble CLE$_{\kappa'}$ for
$\kappa'$ in $(4,8)$ that is drawn on an independent $\gamma$-LQG surface for
$\gamma^2=16/\kappa'$. The results are similar in flavor to the ones from our
paper dealing with CLE$_{\kappa}$ for $\kappa$ in $(8/3,4)$, where the loops of
the CLE are disjoint and simple. In particular, we encode the combined
structure of the LQG surface and the CLE$_{\kappa'}$ in terms of stable
growth-fragmentation trees or their variants, which also appear in the
asymptotic study of peeling processes on decorated planar maps.
  This has consequences for questions that do a priori not involve LQG
surfaces: Our previous paper ""CLE percolations"" described the law of interfaces
obtained when coloring the loops of a CLE$_{\kappa'}$ independently into two
colors with respective probabilities $p$ and $1-p$. This description was
complete up to one missing parameter $\rho$. The results of the present paper
about CLE on LQG allow us to determine its value in terms of $p$ and $\kappa'$.
It shows in particular that CLE$_{\kappa'}$ and CLE$_{16/\kappa'}$ are related
via a continuum analog of the Edwards-Sokal coupling between FK$_q$ percolation
and the $q$-state Potts model (which makes sense even for non-integer $q$
between $1$ and $4$) if and only if $q=4\cos^2(4\pi /\kappa')$. This provides
further evidence for the long-standing belief that CLE$_{\kappa'}$ and
CLE$_{16/\kappa'}$ represent the scaling limits of FK$_q$ percolation and the
$q$-Potts model when $q$ and $\kappa'$ are related in this way. Another
consequence of the formula for $\rho(p,\kappa')$ is the value of half-plane arm
exponents for such divide-and-color models (a.k.a. fuzzy Potts models) that
turn out to take a somewhat different form than the usual critical exponents
for two-dimensional models.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:47:08 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 09:54:03 GMT""}]","2021-05-31"
"2006.14606","Haoxiang Wang","Haoxiang Wang, Ruoyu Sun, Bo Li","Global Convergence and Generalization Bound of Gradient-Based
  Meta-Learning with Deep Neural Nets","Under review. Code available at
  https://github.com/AI-secure/Meta-Neural-Kernel",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gradient-based meta-learning (GBML) with deep neural nets (DNNs) has become a
popular approach for few-shot learning. However, due to the non-convexity of
DNNs and the bi-level optimization in GBML, the theoretical properties of GBML
with DNNs remain largely unknown. In this paper, we first aim to answer the
following question: Does GBML with DNNs have global convergence guarantees? We
provide a positive answer to this question by proving that GBML with
over-parameterized DNNs is guaranteed to converge to global optima at a linear
rate. The second question we aim to address is: How does GBML achieve fast
adaption to new tasks with prior experience on past tasks? To answer it, we
theoretically show that GBML is equivalent to a functional gradient descent
operation that explicitly propagates experience from the past tasks to new
ones, and then we prove a generalization error bound of GBML with
over-parameterized DNNs.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:48:14 GMT""},{""version"":""v2"",""created"":""Mon, 16 Nov 2020 05:28:00 GMT""}]","2020-11-17"
"2006.14607","Athena Stacy","Christopher F. McKee, Athena Stacy, Pak Shing Li","Magnetic Fields in the Formation of the First Stars. I. Theory vs.
  Simulation","28 pages, 4 figures, submitted to MNRAS",,"10.1093/mnras/staa1903",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While magnetic fields are important in contemporary star formation, their
role in primordial star formation is unknown. Magnetic fields of order 10^-16 G
are produced by the Biermann battery due to the curved shocks and turbulence
associated with the infall of gas into the dark matter minihalos that are the
sites of formation of the first stars. These fields are rapidly amplified by a
small-scale dynamo until they saturate at or near equipartition with the
turbulence in the central region of the gas. Analytic results are given for the
outcome of the dynamo, including the effect of compression in the collapsing
gas. The mass-to-flux ratio in this gas is 2-3 times the critical value,
comparable to that in contemporary star formation. Predictions of the outcomes
of simulations using smooth particle hydrodynamics (SPH) and grid-based
adaptive mesh refinement (AMR) are given. Because the numerical viscosity and
resistivity for the standard resolution of 64 cells per Jeans length are
several orders of magnitude greater than the physical values, dynamically
significant magnetic fields affect a much smaller fraction of the mass in
simulations than in reality. An appendix gives an analytic treatment of
free-fall collapse, including that in a constant density background. Another
appendix presents a new method of estimating the numerical viscosity; results
are given for both SPH and grid-based codes.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:49:16 GMT""}]","2020-07-15"
"2006.14608","Artur Souza","Artur Souza, Luigi Nardi, Leonardo B. Oliveira, Kunle Olukotun, Marius
  Lindauer, Frank Hutter","Bayesian Optimization with a Prior for the Optimum",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While Bayesian Optimization (BO) is a very popular method for optimizing
expensive black-box functions, it fails to leverage the experience of domain
experts. This causes BO to waste function evaluations on bad design choices
(e.g., machine learning hyperparameters) that the expert already knows to work
poorly. To address this issue, we introduce Bayesian Optimization with a Prior
for the Optimum (BOPrO). BOPrO allows users to inject their knowledge into the
optimization process in the form of priors about which parts of the input space
will yield the best performance, rather than BO's standard priors over
functions, which are much less intuitive for users. BOPrO then combines these
priors with BO's standard probabilistic model to form a pseudo-posterior used
to select which points to evaluate next. We show that BOPrO is around 6.67x
faster than state-of-the-art methods on a common suite of benchmarks, and
achieves a new state-of-the-art performance on a real-world hardware design
application. We also show that BOPrO converges faster even if the priors for
the optimum are not entirely accurate and that it robustly recovers from
misleading priors.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:49:24 GMT""},{""version"":""v2"",""created"":""Wed, 7 Oct 2020 18:40:00 GMT""},{""version"":""v3"",""created"":""Tue, 23 Feb 2021 18:53:59 GMT""},{""version"":""v4"",""created"":""Mon, 19 Apr 2021 14:29:46 GMT""}]","2021-04-20"
"2006.14609","Konstantinos Pelechrinis","Konstantinos Pelechrinis, Wayne Winston","The Hot Hand in Actual Game Situations",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Streaks of success have always fascinated people and a lot of research has
been conducted to identify whether the ""hot hand"" effect is real. While sports
have provided an appropriate platform for studying this phenomenon, the
majority of existing literature examines scenarios in a vacuum with results
that might or might not be applicable in the wild. In this report, we build on
the existing literature and develop an appropriate framework to quantify the
extend to which success can come in streaks -- beyond the stroke of chance --
in a natural environment. Considering actual basketball game situations, our
results provide strong statistical evidence that the hot hand exists in this
setting. Even though our results are based on a sports setting, we believe that
our study provides a path towards thinking of the hot hand outside of
laboratory-like, controlled environment. This is crucial if we want to use
similar results to enhance our decision making and better understand short and
long term outcomes of repeated decisions.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:49:48 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 19:47:46 GMT""},{""version"":""v3"",""created"":""Mon, 19 Jul 2021 19:13:25 GMT""}]","2021-07-21"
"2006.14610","Yuval Atzmon","Yuval Atzmon, Felix Kreuk, Uri Shalit, Gal Chechik","A causal view of compositional zero-shot recognition","(1) Accepted to NeurIPS 2020 (Spotlight) (2) Project page is at
  https://github.com/nv-research-israel/causal_comp (3) A video of our
  spotlight talk is at https://www.youtube.com/watch?v=IUAmwBylvyc",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  People easily recognize new visual categories that are new combinations of
known components. This compositional generalization capacity is critical for
learning in real-world domains like vision and language because the long tail
of new combinations dominates the distribution. Unfortunately, learning systems
struggle with compositional generalization because they often build on features
that are correlated with class labels even if they are not ""essential"" for the
class. This leads to consistent misclassification of samples from a new
distribution, like new combinations of known components.
  Here we describe an approach for compositional generalization that builds on
causal ideas. First, we describe compositional zero-shot learning from a causal
perspective, and propose to view zero-shot inference as finding ""which
intervention caused the image?"". Second, we present a causal-inspired embedding
model that learns disentangled representations of elementary components of
visual objects from correlated (confounded) training data. We evaluate this
approach on two datasets for predicting new combinations of attribute-object
pairs: A well-controlled synthesized images dataset and a real-world dataset
which consists of fine-grained types of shoes. We show improvements compared to
strong baselines.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:51:22 GMT""},{""version"":""v2"",""created"":""Sun, 1 Nov 2020 17:26:29 GMT""}]","2020-11-03"
"2006.14611","Zhenfeng Xue","Zhenfeng Xue, Weijie Mao, Liang Zheng","Learning to simulate complex scenes","13 pages, 13 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data simulation engines like Unity are becoming an increasingly important
data source that allows us to acquire ground truth labels conveniently.
Moreover, we can flexibly edit the content of an image in the engine, such as
objects (position, orientation) and environments (illumination, occlusion).
When using simulated data as training sets, its editable content can be
leveraged to mimic the distribution of real-world data, and thus reduce the
content difference between the synthetic and real domains. This paper explores
content adaptation in the context of semantic segmentation, where the complex
street scenes are fully synthesized using 19 classes of virtual objects from a
first person driver perspective and controlled by 23 attributes. To optimize
the attribute values and obtain a training set of similar content to real-world
data, we propose a scalable discretization-and-relaxation (SDR) approach. Under
a reinforcement learning framework, we formulate attribute optimization as a
random-to-optimized mapping problem using a neural network. Our method has
three characteristics. 1) Instead of editing attributes of individual objects,
we focus on global attributes that have large influence on the scene structure,
such as object density and illumination. 2) Attributes are quantized to
discrete values, so as to reduce search space and training complexity. 3)
Correlated attributes are jointly optimized in a group, so as to avoid
meaningless scene structures and find better convergence points. Experiment
shows our system can generate reasonable and useful scenes, from which we
obtain promising real-world segmentation accuracy compared with existing
synthetic training sets.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:51:34 GMT""}]","2020-06-26"
"2006.14612","Fernando Mac\'ias","Uwe Wolter, Fernando Mac\'ias, Adrian Rutle","Multilevel Typed Graph Transformations","In the proceedings of the 13th International Conference on Graph
  Transformation (ICGT 2020)",,"10.1007/978-3-030-51372-6_10",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multilevel modeling extends traditional modeling techniques with a
potentially unlimited number of abstraction levels. Multilevel models can be
formally represented by multilevel typed graphs whose manipulation and
transformation are carried out by multilevel typed graph transformation rules.
These rules are cospans of three graphs and two inclusion graph homomorphisms
where the three graphs are multilevel typed over a common typing chain. In this
paper, we show that typed graph transformations can be appropriately
generalized to multilevel typed graph transformations improving preciseness,
flexibility and reusability of transformation rules. We identify type
compatibility conditions, for rules and their matches, formulated as equations
and inequations, respectively, between composed partial typing morphisms. These
conditions are crucial presuppositions for the application of a rule for a
match---based on a pushout and a final pullback complement construction for the
underlying graphs in the category Graph---to always provide a well-defined
canonical result in the multilevel typed setting. Moreover, to formalize and
analyze multilevel typing as well as to prove the necessary results, in a
systematic way, we introduce the category Chain of typing chains and typing
chain morphisms.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:55:17 GMT""}]","2020-06-26"
"2006.14613","Allan Jabri","Allan Jabri, Andrew Owens, Alexei A. Efros","Space-Time Correspondence as a Contrastive Random Walk","NeurIPS 2020 camera ready version -- Code at
  github.com/ajabri/videowalk",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a simple self-supervised approach for learning a
representation for visual correspondence from raw video. We cast correspondence
as prediction of links in a space-time graph constructed from video. In this
graph, the nodes are patches sampled from each frame, and nodes adjacent in
time can share a directed edge. We learn a representation in which pairwise
similarity defines transition probability of a random walk, so that long-range
correspondence is computed as a walk along the graph. We optimize the
representation to place high probability along paths of similarity. Targets for
learning are formed without supervision, by cycle-consistency: the objective is
to maximize the likelihood of returning to the initial node when walking along
a graph constructed from a palindrome of frames. Thus, a single path-level
constraint implicitly supervises chains of intermediate comparisons. When used
as a similarity metric without adaptation, the learned representation
outperforms the self-supervised state-of-the-art on label propagation tasks
involving objects, semantic parts, and pose. Moreover, we demonstrate that a
technique we call edge dropout, as well as self-supervised adaptation at
test-time, further improve transfer for object-centric correspondence.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:56:05 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 18:59:03 GMT""}]","2020-12-04"
"2006.14614","Amir Asadi","Amir R. Asadi, Emmanuel Abbe","Maximum Multiscale Entropy and Neural Network Regularization","27 pages, 2 figures",,,,"cs.LG cs.IT math.IT nlin.AO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A well-known result across information theory, machine learning, and
statistical physics shows that the maximum entropy distribution under a mean
constraint has an exponential form called the Gibbs-Boltzmann distribution.
This is used for instance in density estimation or to achieve excess risk
bounds derived from single-scale entropy regularizers (Xu-Raginsky '17). This
paper investigates a generalization of these results to a multiscale setting.
We present different ways of generalizing the maximum entropy result by
incorporating the notion of scale. For different entropies and arbitrary scale
transformations, it is shown that the distribution maximizing a multiscale
entropy is characterized by a procedure which has an analogy to the
renormalization group procedure in statistical physics. For the case of
decimation transformation, it is further shown that this distribution is
Gaussian whenever the optimal single-scale distribution is Gaussian. This is
then applied to neural networks, and it is shown that in a teacher-student
scenario, the multiscale Gibbs posterior can achieve a smaller excess risk than
the single-scale Gibbs posterior.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:56:11 GMT""}]","2020-06-26"
"2006.14615","Kamal Gupta","Kamal Gupta, Justin Lazarow, Alessandro Achille, Larry Davis, Vijay
  Mahadevan, Abhinav Shrivastava","LayoutTransformer: Layout Generation and Completion with Self-attention","To appear at ICCV 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of scene layout generation for diverse domains such as
images, mobile applications, documents, and 3D objects. Most complex scenes,
natural or human-designed, can be expressed as a meaningful arrangement of
simpler compositional graphical primitives. Generating a new layout or
extending an existing layout requires understanding the relationships between
these primitives. To do this, we propose LayoutTransformer, a novel framework
that leverages self-attention to learn contextual relationships between layout
elements and generate novel layouts in a given domain. Our framework allows us
to generate a new layout either from an empty set or from an initial seed set
of primitives, and can easily scale to support an arbitrary of primitives per
layout. Furthermore, our analyses show that the model is able to automatically
capture the semantic properties of the primitives. We propose simple
improvements in both representation of layout primitives, as well as training
methods to demonstrate competitive performance in very diverse data domains
such as object bounding boxes in natural images(COCO bounding box), documents
(PubLayNet), mobile applications (RICO dataset) as well as 3D shapes
(Part-Net). Code and other materials will be made available at
https://kampta.github.io/layout.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:56:34 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 16:44:42 GMT""}]","2021-10-01"
"2006.14616","Ameesh Makadia","Jake Levinson, Carlos Esteves, Kefan Chen, Noah Snavely, Angjoo
  Kanazawa, Afshin Rostamizadeh, Ameesh Makadia","An Analysis of SVD for Deep Rotation Estimation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Symmetric orthogonalization via SVD, and closely related procedures, are
well-known techniques for projecting matrices onto $O(n)$ or $SO(n)$. These
tools have long been used for applications in computer vision, for example
optimal 3D alignment problems solved by orthogonal Procrustes, rotation
averaging, or Essential matrix decomposition. Despite its utility in different
settings, SVD orthogonalization as a procedure for producing rotation matrices
is typically overlooked in deep learning models, where the preferences tend
toward classic representations like unit quaternions, Euler angles, and
axis-angle, or more recently-introduced methods. Despite the importance of 3D
rotations in computer vision and robotics, a single universally effective
representation is still missing. Here, we explore the viability of SVD
orthogonalization for 3D rotations in neural networks. We present a theoretical
analysis that shows SVD is the natural choice for projecting onto the rotation
group. Our extensive quantitative analysis shows simply replacing existing
representations with the SVD orthogonalization procedure obtains state of the
art performance in many deep learning applications covering both supervised and
unsupervised training.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:58:28 GMT""}]","2020-06-26"
"2006.14617","Yongcheng Zhou","George Borleske and Y. C. Zhou","Enriched Gradient Recovery for Interface Solutions of the
  Poisson-Boltzmann Equation",,,"10.1016/j.jcp.2020.109725",,"physics.comp-ph cs.NA math.NA q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate calculation of electrostatic potential and gradient on the molecular
surface is highly desirable for the continuum and hybrid modeling of large
scale deformation of biomolecules in solvent. In this article a new numerical
method is proposed to calculate these quantities on the dielectric interface
from the numerical solutions of the Poisson-Boltzmann equation. Our method
reconstructs a potential field locally in the least square sense on the
polynomial basis enriched with Green's functions, the latter characterize the
Coulomb potential induced by charges near the position of reconstruction. This
enrichment resembles the decomposition of electrostatic potential into singular
Coulomb component and the regular reaction field in the Generalized Born
methods. Numerical experiments demonstrate that the enrichment recovery
produces drastically more accurate and stable potential gradients on molecular
surfaces compared to classical recovery techniques.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:58:58 GMT""}]","2020-08-26"
"2006.14618","Yue Cao","Yue Cao, Zhenda Xie, Bin Liu, Yutong Lin, Zheng Zhang, Han Hu","Parametric Instance Classification for Unsupervised Visual Feature
  Learning",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents parametric instance classification (PIC) for unsupervised
visual feature learning. Unlike the state-of-the-art approaches which do
instance discrimination in a dual-branch non-parametric fashion, PIC directly
performs a one-branch parametric instance classification, revealing a simple
framework similar to supervised classification and without the need to address
the information leakage issue. We show that the simple PIC framework can be as
effective as the state-of-the-art approaches, i.e. SimCLR and MoCo v2, by
adapting several common component settings used in the state-of-the-art
approaches. We also propose two novel techniques to further improve
effectiveness and practicality of PIC: 1) a sliding-window data scheduler,
instead of the previous epoch-based data scheduler, which addresses the
extremely infrequent instance visiting issue in PIC and improves the
effectiveness; 2) a negative sampling and weight update correction approach to
reduce the training time and GPU memory consumption, which also enables
application of PIC to almost unlimited training images. We hope that the PIC
framework can serve as a simple baseline to facilitate future study.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:59:13 GMT""}]","2020-06-26"
"2006.14619","Johannes Bausch","Johannes Bausch","Recurrent Quantum Neural Networks","22 pages","Advances in Neural Information Processing Systems 33 (NeurIPS
  2020)",,,"cs.LG quant-ph stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recurrent neural networks are the foundation of many sequence-to-sequence
models in machine learning, such as machine translation and speech synthesis.
In contrast, applied quantum computing is in its infancy. Nevertheless there
already exist quantum machine learning models such as variational quantum
eigensolvers which have been used successfully e.g. in the context of energy
minimization tasks. In this work we construct a quantum recurrent neural
network (QRNN) with demonstrable performance on non-trivial tasks such as
sequence learning and integer digit classification. The QRNN cell is built from
parametrized quantum neurons, which, in conjunction with amplitude
amplification, create a nonlinear activation of polynomials of its inputs and
cell state, and allow the extraction of a probability distribution over
predicted classes at each step. To study the model's performance, we provide an
implementation in pytorch, which allows the relatively efficient optimization
of parametrized quantum circuits with thousands of parameters. We establish a
QRNN training setup by benchmarking optimization hyperparameters, and analyse
suitable network topologies for simple memorisation and sequence prediction
tasks from Elman's seminal paper (1990) on temporal structure learning. We then
proceed to evaluate the QRNN on MNIST classification, both by feeding the QRNN
each image pixel-by-pixel; and by utilising modern data augmentation as
preprocessing step. Finally, we analyse to what extent the unitary nature of
the network counteracts the vanishing gradient problem that plagues many
existing quantum classifiers and classical RNNs.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:59:44 GMT""}]","2020-10-01"
"2006.14620","Monica Jinwoo Kang","Elliott Gesteau and Monica Jinwoo Kang","Holographic baby universes: an observable story","35 pages, 4 figures, minor corrections and clarifications added",,,"CALT-TH-2020-029","hep-th gr-qc math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We formulate the baby universe construction rigorously by giving a primordial
role to the algebra of observables of quantum gravity rather than the Hilbert
space. Utilizing diffeomorphism invariance, we study baby universe creation and
annihilation via change in topology. We then construct the algebra of boundary
observables for holographic theories and show that it enhances to contain an
'extra' Abelian tensor factor to describe the bulk in the quantum regime; via
the gravitational path integral we realize this extra tensor factor, at the
level of the Hilbert space, in the context of the GNS representation. We
reformulate the necessary assumptions for the ""baby universe hypothesis"" using
the GNS representation. When the baby universe hypothesis is satisfied, we
demonstrate that the ""miraculous cancellations"" in the corresponding
gravitational path integral have a natural explanation in terms of the
character theory of Abelian $C^\ast$-algebras. We find the necessary and
sufficient mathematical condition for the baby universe hypothesis to hold, and
transcribe it into sufficient physical conditions. We find that they are
incompatible with a baby universe formation that is influenced by any bulk
process from the AdS/CFT correspondence. We illustrate our construction by
applying it to two settings, which leads to a re-interpretion of some
topological models of gravity, and to draw an analogy with the topological
vacua of gauge theory.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:59:59 GMT""},{""version"":""v2"",""created"":""Tue, 4 Aug 2020 18:11:54 GMT""}]","2020-08-06"
"2006.14624","Alexios P. Polychronakos","Alexios P. Polychronakos","Exchange interactions, Yang-Baxter relations and transparent particles","13 pages, 1 figure","Nucl.Phys.B 961 (2020) 115243","10.1016/j.nuclphysb.2020.115243",,"hep-th cond-mat.str-el math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a class of particle models in one dimension involving exchange
interactions that have scattering properties satisfying the Yang-Baxter
consistency condition. A subclass of these models exhibits reflectionless
scattering, in which particles are ""transparent"" to each other, generalizing a
property hitherto only known for the exchange Calogero model. The
thermodynamics of these systems can be derived using the asymptotic
Bethe-ansatz method.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:00 GMT""}]","2022-02-10"
"2006.14625","John Regan","John A. Regan (Maynooth University, Ireland), Zolt\'an Haiman
  (Columbia), John H. Wise (Georgia Tech), Brian W. O'Shea (Michigan State) and
  Michael L. Norman (UCSD)","Massive Star Formation in Metal-Enriched Haloes at High Redshift","11 pages. Accepted for publication in the Open Journal of
  Astrophysics","Open Journal of Astrophysics Vol. 3 2020 August 24, 2020","10.21105/astro.2006.14625",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The formation of supermassive stars has generally been studied under the
assumption of rapid accretion of pristine metal-free gas. Recently it was
found, however, that gas enriched to metallicities up to $Z \sim 10^{-3}$
Z$_{\odot}$ can also facilitate supermassive star formation, as long as the
total mass infall rate onto the protostar remains sufficiently high. We extend
the analysis further by examining how the abundance of supermassive star
candidate haloes would be affected if all haloes with super-critical infall
rates, regardless of metallicity were included. We investigate this scenario by
identifying all atomic cooling haloes in the Renaissance simulations with
central mass infall rates exceeding a fixed threshold. We find that among these
haloes with central mass infall rates above 0.1 M$_{\odot}$ yr$^{-1}$
approximately two-thirds of these haloes have metallicities of $Z > 10^{-3}$
Z$_{\odot}$. If metal mixing within these haloes is inefficient early in their
assembly and pockets of metal-poor gas can remain then the number of haloes
hosting supermassive stars can be increased by at least a factor of four.
Additionally the centres of these high infall-rate haloes provide ideal
environments in which to grow pre-existing black holes. Further research into
the (supermassive) star formation dynamics of rapidly collapsing haloes, with
inhomogeneous metal distributions, is required to gain more insight into both
supermassive star formation in early galaxies as well as early black hole
growth.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 20 Aug 2020 16:21:51 GMT""}]","2020-09-16"
"2006.14626","Monica Gallegos-Garcia","Monica Gallegos-Garcia, Blakesley Burkhart, Anna Rosen, Jill P.
  Naiman, Enrico Ramirez-Ruiz","Winds in Star Clusters Drive Kolmogorov Turbulence","12 pages, 5 figures, Accepted for publication in ApJL",,"10.3847/2041-8213/ababae",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intermediate and massive stars drive fast and powerful isotropic winds that
interact with the winds of nearby stars in star clusters and the surrounding
interstellar medium (ISM). Wind-ISM collisions generate astrospheres around
these stars that contain hot $T\sim 10^7$ K gas that adiabatically expands. As
individual bubbles expand and collide they become unstable, potentially driving
turbulence in star clusters. In this paper we use hydrodynamic simulations to
model a densely populated young star cluster within a homogeneous cloud to
study stellar wind collisions with the surrounding ISM. We model a
mass-segregated cluster of 20 B-type young main sequence stars with masses
ranging from 3--17 $M_{\odot}$. We evolve the winds for $\sim$11 kyrs and show
that wind-ISM collisions and over-lapping wind-blown bubbles around B-stars
mixes the hot gas and ISM material generating Kolmogorov-like turbulence on
small scales early in its evolution. We discuss how turbulence driven by
stellar winds may impact the subsequent generation of star formation in the
cluster
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 16:17:00 GMT""}]","2021-11-08"
"2006.14627","Wouter Waalewijn","Avanish Basdew-Sharma, Franz Herzog, Solange Schrijnder van Velzen,
  Wouter J. Waalewijn","One-loop Jet Functions by Geometric Subtraction","29 pages, 8 figures, for accompanying Mathematica package see
  https://bitbucket.org/GOJet/gojet",,"10.1007/JHEP10(2020)118","Nikhef 20-009","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In factorization formulae for cross sections of scattering processes,
final-state jets are described by jet functions, which are a crucial ingredient
in the resummation of large logarithms. We present an approach to calculate
generic one-loop jet functions, by using the geometric subtraction scheme. This
method leads to local counterterms generated from a slicing procedure; and
whose analytic integration is particularly simple. The poles are obtained
analytically, up to an integration over the azimuthal angle for the
observable-dependent soft counterterm. The poles depend only on the soft limit
of the observable, characterized by a power law, and the finite term is written
as a numerical integral. We illustrate our method by reproducing the known
expressions for the jet function for angularities, the jet shape, and jets
defined through a cone or $k_T$ algorithm. As a new result, we obtain the
one-loop jet function for an angularity measurement in $e^+e^-$ collisions,
that accounts for the formally power-suppressed but potentially large effect of
recoil. An implementation of our approach is made available as the GOJet
Mathematica package accompanying this paper.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:00 GMT""}]","2020-12-02"
"2006.14628","Elisa Maggio","Elisa Maggio, Luca Buoninfante, Anupam Mazumdar, Paolo Pani","How does a dark compact object ringdown?","11+7 pages, 8 figures. v2: minor revisions to match the version to
  appear in PRD","Phys. Rev. D 102, 064053 (2020)","10.1103/PhysRevD.102.064053",,"gr-qc astro-ph.HE hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A generic feature of nearly out-of-equilibrium dissipative systems is that
they resonate through a set of quasinormal modes. Black holes - the absorbing
objects par excellence - are no exception. When formed in a merger, black holes
vibrate in a process called ""ringdown"", which leaves the gravitational-wave
footprint of the event horizon. In some models of quantum gravity which attempt
to solve the information-loss paradox and the singularities of General
Relativity, black holes are replaced by regular, horizonless objects with a
tiny effective reflectivity. Motivated by these scenarios, here we develop a
generic framework to the study of the ringdown of a compact object with various
shades of darkness. By extending the black-hole membrane paradigm, we map the
interior of any compact object in terms of the bulk and shear viscosities of a
fictitious fluid located at the surface, with the black-hole limit being a
single point in a three-dimensional parameter space. We unveil some remarkable
features of the ringdown and some universal properties of the light ring in
this framework. We also identify the region of the parameter space which can be
probed by current and future gravitational-wave detectors. A general feature is
the appearance of mode doublets which are degenerate only in the black-hole
limit. We argue that the merger event GW150914 already imposes a strong lower
bound on the compactness of the merger remnant of approximately 99% of the
black-hole compactness. This places model-independent constraints on black-hole
alternatives such as diffuse ""fuzzballs"" and nonlocal stars.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 9 Sep 2020 21:29:00 GMT""}]","2020-09-23"
"2006.14629","Juan Rojo","Rabah Abdul Khalek, Jacob J. Ethier, Juan Rojo, Gijs van Weelden","nNNPDF2.0: Quark Flavor Separation in Nuclei from LHC Data","65 pages, 26 figures. The nNNPDF2.0 sets are available from
  http://nnpdf.mi.infn.it/for-users/nuclear-pdfs/",,"10.1007/JHEP09(2020)183","Nikhef/2020-006","hep-ph hep-ex nucl-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  We present a model-independent determination of the nuclear parton
distribution functions (nPDFs) using machine learning methods and Monte Carlo
techniques based on the NNPDF framework. The neutral-current deep-inelastic
nuclear structure functions used in our previous analysis, nNNPDF1.0, are
complemented by inclusive and charm-tagged cross-sections from charged-current
scattering. Furthermore, we include all available measurements of W and Z
leptonic rapidity distributions in proton-lead collisions from ATLAS and CMS at
$\sqrt{s}=5.02$ TeV and 8.16 TeV. The resulting nPDF determination, nNNPDF2.0,
achieves a good description of all datasets. In addition to quantifying the
nuclear modifications affecting individual quarks and antiquarks, we examine
the implications for strangeness, assess the role that the momentum and valence
sum rules play in nPDF extractions, and present predictions for representative
phenomenological applications. Our results, made available via the LHAPDF
library, highlight the potential of high-energy collider measurements to probe
nuclear dynamics in a robust manner.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:01 GMT""}]","2020-10-28"
"2006.14630","Teymoor Saifollahi","Teymoor Saifollahi (1), Ignacio Trujillo (2 and 3), Michael A. Beasley
  (2 and 3), Reynier F. Peletier (1), Johan H. Knapen (2 and 3) ((1) Kapteyn
  Astronomical Institute, (2) Instituto de Astrof\'isica de Canarias, (3)
  Departamento de Astrof\'isica, Universidad de La Laguna)","The number of globular clusters around the iconic UDG DF44 is as
  expected for dwarf galaxies","16 pages, 13 figures, accepted for publication in MNRAS, minor
  changes on the text to match the accepted version",,"10.1093/mnras/staa3016",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a growing consensus that the vast majority of ultra-diffuse galaxies
(UDGs) are dwarf galaxies. However, there remain a few UDGs that seem to be
special in terms of their globular cluster (GC) systems. In particular,
according to some authors, certain UDGs exhibit large GC populations when
compared to expectations from their stellar (or total) mass. Among these
special UDGs, DF44 in the Coma cluster is one of the better-known examples.
DF44 has been claimed to have a relatively high number of GCs,
$N_{GC}=74^{+18}_{-18}$, for a stellar mass of only $3\times 10^8$ $M_{ \odot
}$ which would indicate a much larger dark halo mass than dwarfs of similar
stellar mass. In this paper we revisit this number and, contrary to previous
results, find $N_{GC}=21^{+7}_{-9}$ assuming that the distribution of the GCs
follows the same geometry as the galaxy. If we assume that the GCs around DF44
are distributed in a (projected) circularly symmetric way and, if we use a less
strict criterion for the selection of the GCs, we find $N_{GC}=18^{+23}_{-12}$.
Making use of the $M_{\rm GC} - M_{\rm halo}$ relation, this number of GCs
suggests a dark matter halo mass of $M_{halo}=1.1^{+0.4}_{-0.5} \times 10^{11}
M_{\odot}$, a value which is consistent with the expected total mass for DF44
based on its velocity dispersion, $\sigma=33^{+3}_{-3}$ km s$^{-1}$. We
conclude that the number of GCs around DF44 is as expected for regular dwarf
galaxies of similar stellar mass and DF44 is not extraordinary in this respect.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 15:09:05 GMT""},{""version"":""v3"",""created"":""Mon, 28 Sep 2020 12:08:06 GMT""},{""version"":""v4"",""created"":""Tue, 29 Sep 2020 18:36:53 GMT""}]","2020-10-09"
"2006.14631","Junghwan Lee","Sunghoon Jung, Junghwan Lee, Martin Perell\'o, Junping Tian, Marcel
  Vos","Higgs, top and electro-weak precision measurements at future $e^+ e^-$
  colliders; a combined effective field theory analysis with renormalization
  mixing","66 pages, 13 figures",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a combined analysis of the potential of a future
electron-positron collider to constrain the Higgs, top and electro-weak (EW)
sectors of the Standard Model Effective Field Theory (SMEFT). The leading
contributions of operators involving top quarks arise mostly at one-loop
suppressed order and can be captured by the renormalization group mixing with
Higgs operators. We perform global fits with an extended basis of 29
parameters, including both Higgs and top operators, to the projections for the
Higgs, top and electro-weak precision measurements at the International Linear
Collider (ILC). The determination of the Higgs boson couplings in the 250 GeV
stage of the ILC is initially severely degraded by the additional top-quark
degrees of freedom, but can be nearly completely recovered by the inclusion of
precise measurements of top-quark EW couplings at the LHC. The physical Higgs
couplings are relatively robust, as the top mass is larger than the energy
scale of EW processes. The effect of the top operators on the bounds on the
Wilson coefficients is much more pronounced and may limit our ability to
identify the source of deviations from the Standard Model. Robust global bounds
on all Wilson coefficients are only obtained when the 500 GeV stage of the ILC
is included.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:02 GMT""}]","2020-06-29"
"2006.14632","Giacomo Fragione","Giacomo Fragione, Rosalba Perna, Abraham Loeb","Calibrating the binary black hole population in nuclear star clusters
  through tidal disruption events","13 pages, 7 figures, 1 table, accepted by MNRAS",,"10.1093/mnras/staa3493",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the sensitivity of gravitational wave (GW) instruments improves and new
networks start operating, hundreds of merging stellar-mass black holes (SBHs)
and intermediate-mass black holes (IMBHs) are expected to be observed in the
next few years. The origin and distribution of SBH and IMBH binaries in various
dynamical environments is a fundamental scientific question in GW astronomy. In
this paper, we discuss ways tidal disruption events (TDEs) may provide a unique
electromagnetic window into the assembly and merger of binary SBHs and IMBHs in
nuclear star clusters (NSCs). We discuss how the host NSC mass and density and
the slope of the black-hole mass function set the orbital properties and the
masses of the binaries that undergo a TDE. For typical NSC properties, we
predict a TDE rate of $\sim 10^{-6}$--$10^{-7}\ {\rm yr}^{-1}$ per galaxy. The
lightcurve of TDEs in NSCs could be interrupted and modulated by the companion
black hole on the orbital period of the binary. These should be readily
detectable by optical transient surveys such as the Zwicky Transient Facility
and LSST.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Thu, 5 Nov 2020 21:18:07 GMT""}]","2020-11-18"
"2006.14633","Marianne Girard","M. Girard, C. A. Mason, A. Fontana, M. Dessauges-Zavadsky, T.
  Morishita, R. Amor\'in, D. B. Fisher, T. Jones, D. Schaerer, K. B. Schmidt,
  T. Treu, and B. Vulcani","The KMOS Lens-Amplified Spectroscopic Survey (KLASS): Kinematics and
  clumpiness of low-mass galaxies at cosmic noon","19 pages, 9 figures. Accepted for publication in MNRAS",,"10.1093/mnras/staa1907",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present results from the KMOS Lens-Amplified Spectroscopic Survey (KLASS),
an ESO Very Large Telescope (VLT) large program using gravitational lensing to
study the spatially resolved kinematics of 44 star-forming galaxies at
0.6<z<2.3 with a stellar mass of 8.1<log(M$_\star$/M$_{\odot}$)<11.0. These
galaxies are located behind six galaxy clusters selected from the HST Grism
Lens-Amplified Survey from Space (GLASS). We find that the majority of the
galaxies show a rotating disk, but most of the rotation-dominated galaxies only
have a low $\upsilon_{rot}/\sigma_0$ ratio (median of
$\upsilon_{rot}/\sigma_0\sim2.5$). We explore the Tully-Fisher relation by
adopting the circular velocity,
$V_{circ}=(\upsilon_{rot}^2+3.4\sigma_0^2)^{1/2}$, to account for pressure
support. We find that our sample follows a Tully-Fisher relation with a
positive zero-point offset of +0.18 dex compared to the local relation,
consistent with more gas-rich galaxies that still have to convert most of their
gas into stars. We find a strong correlation between the velocity dispersion
and stellar mass in the KLASS sample. When combining our data to other surveys
from the literature, we also see an increase of the velocity dispersion with
stellar mass at all redshift. We obtain an increase of
$\upsilon_{rot}/\sigma_0$ with stellar mass at 0.5<z<1.0. This could indicate
that massive galaxies settle into regular rotating disks before the low-mass
galaxies. For higher redshift (z>1), we find a weak increase or flat trend. We
investigate the relation between the rest-frame UV clumpiness of galaxies and
their global kinematic properties. We find no clear trend between the
clumpiness and the velocity dispersion and $\upsilon_{rot}/\sigma_0$. This
could suggest that the kinematic properties of galaxies evolve after the clumps
formed in the galaxy disk or that the clumps can form in different physical
conditions.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:02 GMT""}]","2020-07-15"
"2006.14634","Dorin Weissman","Jacob Sonnenschein and Dorin Weissman","On the quantization of folded strings in non-critical dimensions","v1: 60 pages, v2: typos corrected, references added, v3: minor
  revisions, version to be published in JHEP","JHEP 12 (2020) 120","10.1007/JHEP12(2020)120",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classical rotating closed string are folded strings. At the folding points
the scalar curvature associated with the induced metric diverges. As a
consequence one cannot properly quantize the fluctuations around the classical
solution since there is no complete set of normalizable eigenmodes. Furthermore
in the non-critical effective string action of Polchinski and Strominger, there
is a divergence associated with the folds. We overcome this obstacle by putting
a massive particle at each folding point which can be used as a regulator.
Using this method we compute the spectrum of quantum fluctuations around the
rotating string and the intercept of the leading Regge trajectory. The results
we find are that the intercepts are $a=1$ and $a=2$ for the open and closed
string respectively, independent of the target space dimension. We argue that
in generic theories with an effective string description, one can expect
corrections from finite masses associated with either the endpoints of an open
string or the folding points on a closed string. We compute explicitly the
corrections in the presence of these masses.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:04 GMT""},{""version"":""v2"",""created"":""Mon, 17 Aug 2020 02:58:19 GMT""},{""version"":""v3"",""created"":""Wed, 11 Nov 2020 03:29:58 GMT""}]","2020-12-22"
"2006.14635","Davide Napoletano","Enrico Bothmann, Davide Napoletano","Automated evaluation of electroweak Sudakov logarithms in Sherpa","17 pages, 4 figures",,"10.1140/epjc/s10052-020-08596-2",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an automated implementation for the calculation of one-loop double
and single Sudakov logarithms stemming from electroweak radiative corrections
within the Sherpa event generation framework, based on the derivation in[1]. At
high energies, these logarithms constitute the leading contributions to the
full NLO electroweak corrections. As examples, we show applications for
relevant processes at both the LHC and future hadron colliders, namely on-shell
W boson pair production, EW-induced dijet production and electron-positron
production in association with four jets, providing the first estimate of EW
corrections at this multiplicity.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:04 GMT""}]","2020-12-02"
"2006.14636","Marc Huertas-Company","M. Huertas-Company, Y. Guo, O. Ginzburg, C.T. Lee, N. Mandelker, M.
  Metter, J.R. Primack, A. Dekel, D. Ceverino, S.M. Faber, D.C. Koo, A.
  Koekemoer, G. Snyder, M. Giavalisco, H. Zhang","Stellar Masses of Giant Clumps in CANDELS and Simulated Galaxies Using
  Machine Learning","Accepted for publication in MNRAS - This is the final version",,"10.1093/mnras/staa2777",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A significant fraction of high redshift star-forming disc galaxies are known
to host giant clumps, whose nature and role in galaxy evolution are yet to be
understood. In this work we first present a new method based on neural networks
to detect clumps in galaxy images. We use this method to detect clumps in the
rest-frame optical and UV images of a complete sample of $\sim1500$ star
forming galaxies at $1<z<3$ in the CANDELS survey as well as in images from the
VELA zoom-in cosmological simulations. We show that observational effects have
a dramatic impact on the derived clump properties leading to an overestimation
of the clump mass up to a factor of 10, which highlights the importance of fair
comparisons between observations and simulations and the limitations of current
HST data to study the resolved structure of distant galaxies. After correcting
for these effects with a mixture density network, we estimate that the clump
stellar mass function follows a power-law down to the completeness limit
($10^{7}$ solar masses) with the majority of the clumps being less massive than
$10^9$ solar masses. This is in better agreement with recent gravitational
lensing based measurements. The simulations explored in this work overall
reproduce the shape of the observed clump stellar mass function and clumpy
fractions when confronted under the same conditions, although they tend to lie
in the lower limit of the confidence intervals of the observations. This
agreement suggests that most of the observed clumps are formed in-situ.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:09 GMT""},{""version"":""v2"",""created"":""Tue, 8 Sep 2020 14:51:28 GMT""}]","2020-09-30"
"2006.14637","Avijit Das","Avijit Das, Abhishek Dhar, Ion Santra, Urbashi Satpathi and Supurna
  Sinha","Quantum Brownian Motion: Drude and Ohmic Baths as Continuum Limits of
  the Rubin Model","11 pages, 10 figures","Phys. Rev. E 102, 062130 (2020)","10.1103/PhysRevE.102.062130",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The motion of a free quantum particle in a thermal environment is usually
described by the quantum Langevin equation, where the effect of the bath is
encoded through a dissipative and a noise term, related to each other via the
fluctuation dissipation theorem. The quantum Langevin equation can be derived
starting from a microscopic model of the thermal bath as an infinite collection
of harmonic oscillators prepared in an initial equilibrium state. The spectral
properties of the bath oscillators and their coupling to the particle determine
the specific form of the dissipation and noise. Here we investigate in detail
the well-known Rubin bath model, which consists of a one-dimensional harmonic
chain with the boundary bath particle coupled to the Brownian particle. We show
how in the limit of infinite bath bandwidth, we get the Drude model and a
second limit of infinite system-bath coupling gives the Ohmic model. A detailed
analysis of relevant correlation functions, such as the mean squared
displacement, velocity auto-correlation functions, and the response function
are presented, with the aim of understanding of the various temporal regimes.
In particular, we discuss the quantum to classical crossover time scales where
the mean square displacement changes from a $\sim \ln t$ to a $\sim t$
dependence. We relate our study to recent work using linear response theory to
understand quantum Brownian motion.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:13 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 09:26:40 GMT""}]","2020-12-16"
"2006.14638","Bertrand Lemasle","B. Lemasle, M. Hanke, J. Storm, G. Bono, and E. K. Grebel","Atmospheric parameters of Cepheids from flux ratios with ATHOS: I. The
  temperature scale","16 pages, 13 figures, accepted in A&A","A&A 641, A71 (2020)","10.1051/0004-6361/202038277",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context: The effective temperature is a key parameter governing the
properties of a star. For stellar chemistry, it has the strongest impact on the
accuracy of the abundances derived. Since Cepheids are pulsating stars,
determining their effective temperature is more complicated that in the case of
non-variable stars. Aims: We want to provide a new temperature scale for
classical Cepheids, with a high precision and full control of the systematics.
Methods: Using a data-driven machine learning technique employing observed
spectra, and taking great care to accurately phase single-epoch observations,
we have tied flux ratios to (label) temperatures derived using the infrared
surface brightness method. Results: We identified 143 flux ratios that allow us
to determine the effective temperature with a precision of a few K and an
accuracy better than 150 K, which is in line with the most accurate temperature
measures available to date. The method does not require a normalization of the
input spectra and provides homogeneous temperatures for low- and
high-resolution spectra, even at the lowest signal-to-noise ratios. Due to the
lack of a dataset of sufficient sample size for Small Magellanic Cloud
Cepheids, the temperature scale does not extend to Cepheids with [Fe/H] < -0.6
dex but nevertheless provides an exquisite, homogeneous means of characterizing
Galactic and Large Magellanic Cloud Cepheids. Conclusions: The temperature
scale will be extremely useful in the context of spectroscopic surveys for
Milky Way archaeology with the WEAVE and 4MOST spectrographs. It paves the way
for highly accurate and precise metallicity estimates, which will allow us to
assess the possible metallicity dependence of Cepheids' period-luminosity
relations and, in turn, to improve our measurement of the Hubble constant H0.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:14 GMT""}]","2020-09-16"
"2006.14639","Aritra Ghosh","Aritra Ghosh, C. Megan Urry, Zhengdong Wang, Kevin Schawinski, Dennis
  Turp and Meredith C. Powell","Galaxy Morphology Network: A Convolutional Neural Network Used to Study
  Morphology and Quenching in $\sim 100,000$ SDSS and $\sim 20,000$ CANDELS
  Galaxies","23 pages, 12 figures; Accepted for publication in The Astrophysical
  Journal; Public Data Release at
  http://www.astro.yale.edu/aghosh/gamornet.html","The Astrophysical Journal, 895(2), 112 (2020)","10.3847/1538-4357/ab8a47",,"astro-ph.GA astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine morphology-separated color-mass diagrams to study the quenching of
star formation in $\sim 100,000$ ($z\sim0$) Sloan Digital Sky Survey (SDSS) and
$\sim 20,000$ ($z\sim1$) Cosmic Assembly Near-Infrared Deep Extragalactic
Legacy Survey (CANDELS) galaxies. To classify galaxies morphologically, we
developed Galaxy Morphology Network (GaMorNet), a convolutional neural network
that classifies galaxies according to their bulge-to-total light ratio.
GaMorNet does not need a large training set of real data and can be applied to
data sets with a range of signal-to-noise ratios and spatial resolutions.
GaMorNet's source code as well as the trained models are made public as part of
this work ( http://www.astro.yale.edu/aghosh/gamornet.html ). We first trained
GaMorNet on simulations of galaxies with a bulge and a disk component and then
transfer learned using $\sim25\%$ of each data set to achieve misclassification
rates of $\lesssim5\%$. The misclassified sample of galaxies is dominated by
small galaxies with low signal-to-noise ratios. Using the GaMorNet
classifications, we find that bulge- and disk-dominated galaxies have distinct
color-mass diagrams, in agreement with previous studies. For both SDSS and
CANDELS galaxies, disk-dominated galaxies peak in the blue cloud, across a
broad range of masses, consistent with the slow exhaustion of star-forming gas
with no rapid quenching. A small population of red disks is found at high mass
($\sim14\%$ of disks at $z\sim0$ and $2\%$ of disks at $z \sim 1$). In
contrast, bulge-dominated galaxies are mostly red, with much smaller numbers
down toward the blue cloud, suggesting rapid quenching and fast evolution
across the green valley. This inferred difference in quenching mechanism is in
agreement with previous studies that used other morphology classification
techniques on much smaller samples at $z\sim0$ and $z\sim1$.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:00:21 GMT""}]","2020-06-29"
"2006.14640","Madhumita Sarkar","Madhumita Sarkar and K. Sengupta","Dynamical Transition for a class of integrable models coupled to a bath","12 pages,15 figures","Phys. Rev. B 102, 235154 (2020)","10.1103/PhysRevB.102.235154",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dynamics of correlation functions of a class of $d-$dimensional
integrable models coupled linearly to a fermionic or bosonic bath in the
presence of a periodic drive with a square pulse protocol. It is well known
that in the absence of the bath, these models exhibit a dynamical phase
transition; all correlators decay to their steady state values as
$n_0^{-(d+1)/2}$[$n_0^{-d/2}]$ above [below] a critical frequency $\omega_c$,
where $n_0$ is the number of drive cycles. We find that the presence of a
linearly coupled fermionic bath which maintains integrability of the system
preserves this transition. We provide a semi-analytic expression for the
evolution operator for this system and use it to provide a phase diagram
showing the different dynamical regimes as a function of the system-bath
coupling strength and the bath parameters. In contrast, when such models are
coupled to a bosonic bath which breaks integrability of the model, we find
exponential decay of the correlators to their steady state. Our numerical
analysis shows that this exponential decay sets in above a critical number of
drive cycles $n_c$ which depends on the system-bath coupling strength and the
amplitude of perturbation. Below $n_c$, the system retains the power-law
behavior identical to that for the closed integrable models and the dynamical
transition survives. We discuss the applicability of our results for
interacting fermion systems and discuss experiments which can test our theory.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:01:03 GMT""}]","2021-02-05"
"2006.14641","Kyrylo Snizhko","Kyrylo Snizhko, Nihal Rao, Parveen Kumar, and Yuval Gefen","Weak-measurement-induced phases and dephasing: broken symmetry of the
  geometric phase","22 pages, 15 figures. Comments are welcome","Phys. Rev. Research 3, 043045 (2021)","10.1103/PhysRevResearch.3.043045",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coherent steering of a quantum state, induced by a sequence of weak
measurements, has become an active area of theoretical and experimental study.
For a closed steered trajectory, the underlying phase factors involve both
geometrical and dynamical terms. Furthermore, considering the reversal of the
order of the measurement sequence, such a phase comprises a symmetric and an
antisymmetric term. Superseding common wisdom, we show that the symmetric and
the antisymmetric components do not correspond to the dynamical and geometrical
parts respectively. Addressing a broad class of measurement protocols, we
further investigate the dependence of the induced phases on the measurement
parameters (e.g., the measurement strength). We find transitions between
different topologically distinct sectors, defined by integer-valued winding
numbers, and show that the transitions are accompanied by diverging dephasing.
We propose experimental protocols to observe these effects.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:03:55 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 21:03:20 GMT""},{""version"":""v3"",""created"":""Wed, 20 Oct 2021 18:03:52 GMT""}]","2021-10-22"
"2006.14642","Gregory Simonian","Gregory V. A. Simonian (1 and 2), Marc H. Pinsonneault (2), Donald M.
  Terndrup (2), Jennifer L. van Saders (3 and 4 and 5) ((1) Concord University,
  (2) The Ohio State University, (3) University of Hawaii, (4) Observatories of
  the Carnegie Institution for Science, (5) Princeton University)","Rotation of Kepler field dwarfs and sub giants: Spectroscopic $v \sin I$
  from APOGEE","30 pages, 15 figures, Accepted in The Astrophysical Journal. For a
  video summarizing the main results of the paper, see
  https://youtu.be/G2Zr_PkLO0U",,"10.3847/1538-4357/ab9a43",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use 5,337 spectroscopic $v \sin i$ measurements of Kepler dwarfs and
subgiants from the APOGEE survey to study stellar rotation trends. We find a
detection threshold of 10 km/s, which allows us to explore the spindown of
intermediate-mass stars leaving the main sequence, merger products, young
stars, and tidally-synchronized binaries. We see a clear distinction between
blue stragglers and the field turnoff in $\alpha$-rich stars, with a sharp
rapid rotation cutoff for blue stragglers consistent with the Kraft break. We
also find rapid rotation and RV variability in a sample of red straggler stars,
considerably cooler than the giant branch, lending credence to the hypothesis
that these are active, tidally-synchronized binaries. We see clear evidence for
a transition between rapid and slow rotation on the subgiant branch in the
domain predicted by modern angular momentum evolution models. We find
substantial agreement between the spectroscopic and photometric properties of
KIC targets added by Huber et al (2014) based on 2MASS photometry. For the
unevolved lower main sequence, we see the same concentration toward rapid
rotation in photometric binaries as that observed in rotation period data, but
at an enhanced rate. We attribute this difference to unresolved near-equal
luminosity spectroscopic binaries with velocity displacements on the order of
the APOGEE resolution. Among cool unevolved stars we find an excess rapid
rotator fraction of 4% caused by pipeline issues with photometric binaries.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:04:42 GMT""}]","2020-08-05"
"2006.14643","Sarbani Basu","Sarbani Basu and Saskia Hekker","Unveiling the Structure and Dynamics of Red Giants with Asteroseismology","Accepted for publication in Frontiers in Astronomy and Space Sciences",,"10.3389/fspas.2020.00044",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Kepler mission observed many thousands of red giants. The long time
series, some as long as the mission itself, have allowed us to study red giants
with unprecedented detail. Given that red giants are intrinsically luminous,
and hence can be observed from very large distances, knowing the properties of
red giants, in particular ages, is of immense value for studies of the
formation and evolution of the Galaxy, an endeavor known as ""Galactic
archaeology"". In this article we review what we have learned about red giants
using asteroseismic data. We start with the properties of the power spectrum
and move on to internal structure and dynamics of these stars; we also touch
upon unsolved issues in red-giant asteroseismology and the prospects of making
further progress in understanding these stars.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:05:18 GMT""}]","2020-06-29"
"2006.14644","Vibhor Singh","Vibhor Singh, Vishesh Devgan, Ishu Anand","Determining Image similarity with Quasi-Euclidean Metric",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Image similarity is a core concept in Image Analysis due to its extensive
application in computer vision, image processing, and pattern recognition. The
objective of our study is to evaluate Quasi-Euclidean metric as an image
similarity measure and analyze how it fares against the existing standard ways
like SSIM and Euclidean metric. In this paper, we analyzed the similarity
between two images from our own novice dataset and assessed its performance
against the Euclidean distance metric and SSIM. We also present experimental
results along with evidence indicating that our proposed implementation when
applied to our novice dataset, furnished different results than standard
metrics in terms of effectiveness and accuracy. In some cases, our methodology
projected remarkable performance and it is also interesting to note that our
implementation proves to be a step ahead in recognizing similarity when
compared to
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:12:21 GMT""}]","2020-06-29"
"2006.14645","Sebastian Heedt","Francesco Borsoi, Kun Zuo, Sasa Gazibegovic, Roy L. M. Op het Veld,
  Erik P. A. M. Bakkers, Leo P. Kouwenhoven, Sebastian Heedt","Transmission phase read-out of a large quantum dot in a nanowire
  interferometer","to be published in Nature Communications","Nat. Commun. 11, 3666 (2020)","10.1038/s41467-020-17461-5",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detecting the transmission phase of a quantum dot via interferometry can
reveal the symmetry of the orbitals and details of electron transport.
Crucially, interferometry will enable the read-out of topological qubits based
on one-dimensional nanowires. However, measuring the transmission phase of a
quantum dot in a nanowire has not yet been established. Here, we exploit recent
breakthroughs in the growth of one-dimensional networks and demonstrate
interferometric read-out in a nanowire-based architecture. In our two-path
interferometer, we define a quantum dot in one branch and use the other path as
a reference arm. We observe Fano resonances stemming from the interference
between electrons that travel through the reference arm and undergo resonant
tunnelling in the quantum dot. Between consecutive Fano peaks, the transmission
phase exhibits phase lapses that are affected by the presence of multiple
trajectories in the interferometer. These results provide critical insights for
the design of future topological qubits.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:12:51 GMT""}]","2020-07-29"
"2006.14646","Ankan Banerjee","Ankan Banerjee, Manojit Ghosh and Pinaki Pal","Transitions in overstable rotating magnetoconvection","To be appeared in the Physical Review E",,"10.1103/PhysRevE.102.013107",,"physics.flu-dyn nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical Rayleigh-B\'{e}nard convection (RBC) system is known to exhibit
either subcritical or supercritical transition to convection in the presence or
absence of rotation and/or magnetic field. However, the simultaneous exhibition
of subcritical and supercritical branches of convection in plane layer RBC
depending on the initial conditions, has not been reported so far. Here, we
report the phenomenon of simultaneous occurrence of subcritical and
supercritical branches of convection in overstable RBC of electrically
conducting low Prandtl number fluids (liquid metals) in the presence of an
external uniform horizontal magnetic field and rotation about the vertical
axis. Extensive three dimensional (3D) direct numerical simulations (DNS) and
low dimensional modeling of the system, performed in the ranges $750 \leq
\mathrm{Ta} \leq 3000$ and $0 < \mathrm{Q} \leq 1000$ of the Taylor number
($\mathrm{Ta}$, strength of the Coriolis force) and the Chandrasekhar number
($\mathrm{Q}$, strength of the Lorenz force) respectively, establish the
phenomenon convincingly. Detailed bifurcation analysis of a simple three
dimensional model derived from the DNS data reveals that a supercritical Hopf
bifurcation and a subcritical pitchfork bifurcation of the conduction state are
responsible for this. The effect of Prandtl number on these transitions is also
explored in detail.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:13:40 GMT""}]","2020-08-26"
"2006.14647","Raghwinder Singh Grewal","Raghwinder Singh Grewal, Mauricio Pulido, Gour Pati, Renu Tripathi","Magnetometry using sodium fluorescence with synchronous modulation of
  two-photon resonant light fields",,,,,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a new technique for generating magnetic resonance with synchronous
modulation of two-photon resonant light fields. Magnetic resonances in
fluorescence from a sodium cell are measured to demonstrate suitability of this
technique for remote magnetometry. A strong magnetic resonance with its dip
corresponding to the Larmor frequency is produced in the presence of a
transverse magnetic field. An additional resonance at 3\{Omega_L} is observed,
which can be used to determine the magnetic field orientation. We have
developed a theoretical model based on the density matrix equations to verify
our experimental observations. An average magnetic field sensitivity of 41
\mathbf{pT}/\sqrt{\mathbf{Hz}} is measured using light duty cycles ranging from
35% to 10%. We have discussed possible changes that can be made to improve the
sensitivity of this scheme further.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:20:23 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jul 2020 13:29:43 GMT""}]","2020-07-29"
"2006.14648","Allen Moy","Allen Moy and Gordan Savin","Euler-Poincar\'{e} formulae for positive depth Bernstein projectors","36 pages, 2 figures",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Work of Bezrukavnikov-Kazhdan-Varshavsky uses an equivariant system of
trivial idempotents of Moy-Prasad groups to obtain an Euler-Poincar\'{e}
formula for the r-depth Bernstein projector. Barbasch-Ciubotaru-Moy use
depth-zero cuspidal representations of parahoric subgroups to decompose the
Euler-Poincar\'{e} presentation of the depth-zero projector. For positive depth
$r$, we establish a decomposition of the Euler-Poincar\'{e} presentation of the
r-depth Bernstein projector based on a notion of associate classes of cuspidal
pairs for Moy-Prasad quotients. We apply these new Euler-Poincar\'{e}
presentations to the obtain decompositions of the resolutions of
Schneider-Stuhler and Bestvina-Savin.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:22:33 GMT""}]","2020-06-29"
"2006.14649","Anna Melnik","A. M. Melnik, A. K. Dambis","Distance scale for high-luminosity stars in OB associations and in field
  with Gaia DR2. Spurious systematic motions","15 pages, 5 figures, accepted for publication in Astrophysics and
  Space Science",,"10.1007/s10509-020-03827-0",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculated the median parallaxes for 47 OB associations including at least
10 stars with known Gaia DR2 parallaxes. A comparison between trigonometric and
photometric parallaxes of OB associations reveals a zero-point offset of
delta_pi=-0.11 +\- 0.04 mas indicating that Gaia DR2 parallaxes are, on
average, underestimated and the distances derived from them are overestimated.
The correction of delta_pi=-0.11 mas is consistent with the estimate that
Arenou et al. (2018) obtained for bright stars. An analysis of parallaxes of OB
associations and high-luminosity field stars confirms our previous conclusion
(Dambis et al. 2001) that the distance scale for OB stars established by Blaha
and Humphreys (1989) must be reduced by 10--20%. Spurious systematic motions of
10--20 km s-1 at the distances of 2--3 kpc from the Sun are found to arise from
the use of the uncorrected Gaia DR2 parallaxes.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:22:54 GMT""}]","2020-07-15"
"2006.14650","Yi-Kuan Chiang","Yi-Kuan Chiang, Ryu Makiya, Brice M\'enard, Eiichiro Komatsu","The Cosmic Thermal History Probed by Sunyaev-Zeldovich Effect Tomography","22 pages, 11 figures. Accepted for publication in ApJ",,"10.3847/1538-4357/abb403",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cosmic thermal history, quantified by the evolution of the mean thermal
energy density in the universe, is driven by the growth of structures as
baryons get shock heated in collapsing dark matter halos. This process can be
probed by redshift-dependent amplitudes of the thermal Sunyaev-Zeldovich (SZ)
effect background. To do so, we cross-correlate eight sky intensity maps in the
$\it{Planck}$ and Infrared Astronomical Satellite missions with two million
spectroscopic redshift references in the Sloan Digital Sky Surveys. This
delivers snapshot spectra for the far-infrared to microwave background light as
a function of redshift up to $z\sim3$. We decompose them into the SZ and
thermal dust components. Our SZ measurements directly constrain $\langle
bP_{\rm e} \rangle$, the halo bias-weighted mean electron pressure, up to
$z\sim 1$. This is the highest redshift achieved to date, with uncorrelated
redshift bins thanks to the spectroscopic references. We detect a threefold
increase in the density-weighted mean electron temperature $\bar{T}_{\rm{e}}$
from $7\times 10^5~{\rm K}$ at $z=1$ to $2\times 10^6~{\rm K}$ today. Over
$z=1$-$0$, we witness the build-up of nearly $70\%$ of the present-day mean
thermal energy density $\rho_{\rm{th}}$, with the corresponding density
parameter $\Omega_{\rm th}$ reaching $1.5 \times10^{-8}$. We find the mass bias
parameter of $\it{Planck}$'s universal pressure profile of $B=1.27$ (or
$1-b=1/B=0.79$), consistent with the magnitude of non-thermal pressure in gas
motion and turbulence from mass assembly. We estimate the redshift-integrated
mean Compton parameter $y\sim1.2\times10^{-6}$, which will be tested by future
spectral distortion experiments. More than half of which originates from the
large-scale structure at $z<1$, which we detect directly.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:23:35 GMT""},{""version"":""v2"",""created"":""Thu, 24 Sep 2020 22:48:39 GMT""}]","2020-10-21"
"2006.14651","Samyadeep Basu","Samyadeep Basu, Philip Pope, Soheil Feizi","Influence Functions in Deep Learning Are Fragile","ICLR 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Influence functions approximate the effect of training samples in test-time
predictions and have a wide variety of applications in machine learning
interpretability and uncertainty estimation. A commonly-used (first-order)
influence function can be implemented efficiently as a post-hoc method
requiring access only to the gradients and Hessian of the model. For linear
models, influence functions are well-defined due to the convexity of the
underlying loss function and are generally accurate even across difficult
settings where model changes are fairly large such as estimating group
influences. Influence functions, however, are not well-understood in the
context of deep learning with non-convex loss functions. In this paper, we
provide a comprehensive and large-scale empirical study of successes and
failures of influence functions in neural network models trained on datasets
such as Iris, MNIST, CIFAR-10 and ImageNet. Through our extensive experiments,
we show that the network architecture, its depth and width, as well as the
extent of model parameterization and regularization techniques have strong
effects in the accuracy of influence functions. In particular, we find that (i)
influence estimates are fairly accurate for shallow networks, while for deeper
networks the estimates are often erroneous; (ii) for certain network
architectures and datasets, training with weight-decay regularization is
important to get high-quality influence estimates; and (iii) the accuracy of
influence estimates can vary significantly depending on the examined test
points. These results suggest that in general influence functions in deep
learning are fragile and call for developing improved influence estimation
methods to mitigate these issues in non-convex setups.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:25:59 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 23:45:14 GMT""}]","2021-02-12"
"2006.14652","Ojas Parekh","Ojas Parekh, Cynthia A. Phillips, Conrad D. James, James B. Aimone","Constant-Depth and Subcubic-Size Threshold Circuits for Matrix
  Multiplication","Appears in the proceedings of the ACM Symposium on Parallelism in
  Algorithms and Architectures (SPAA), 2018",,"10.1145/3210377.3210410",,"cs.DS cs.DC cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Boolean circuits of McCulloch-Pitts threshold gates are a classic model of
neural computation studied heavily in the late 20th century as a model of
general computation. Recent advances in large-scale neural computing hardware
has made their practical implementation a near-term possibility. We describe a
theoretical approach for multiplying two $N$ by $N$ matrices that integrates
threshold gate logic with conventional fast matrix multiplication algorithms,
that perform $O(N^\omega)$ arithmetic operations for a positive constant
$\omega < 3$. Our approach converts such a fast matrix multiplication algorithm
into a constant-depth threshold circuit with approximately $O(N^\omega)$ gates.
Prior to our work, it was not known whether the $\Theta(N^3)$-gate barrier for
matrix multiplication was surmountable by constant-depth threshold circuits.
  Dense matrix multiplication is a core operation in convolutional neural
network training. Performing this work on a neural architecture instead of
off-loading it to a GPU may be an appealing option.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:28:10 GMT""}]","2020-06-29"
"2006.14653","Pengyu Qian","Yash Kanoria, Seungki Min, Pengyu Qian","The Competition for Partners in Matching Markets",,,,,"cs.GT econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the competition for partners in two-sided matching markets with
heterogeneous agent preferences, with a focus on how the equilibrium outcomes
depend on the connectivity in the market. We model random partially connected
markets, with each agent having an average degree $d$ in a random (undirected)
graph, and a uniformly random preference ranking over their neighbors in the
graph. We formally characterize stable matchings in large markets random with
small imbalance and find a threshold in the connectivity $d$ at $\log^2 n$
(where $n$ is the number of agents on one side of the market) which separates a
``weak competition'' regime, where agents on both sides of the market do
equally well, from a ``strong competition'' regime, where agents on the short
(long) side of the market enjoy a significant advantage (disadvantage).
Numerical simulations confirm and sharpen our theoretical predictions, and
demonstrate robustness to our assumptions. We leverage our characterizations in
two ways: First, we derive prescriptive insights into how to design the
connectivity of the market to trade off optimally between the average agent
welfare achieved and the number of agents who remain unmatched in the market.
For most market primitives, we find that the optimal connectivity should lie in
the weak competition regime or at the threshold between the regimes. Second,
our analysis uncovers a new conceptual principle governing whether the short
side enjoys a significant advantage in a given matching market, which can
moreover be applied as a diagnostic tool given only basic summary statistics
for the market. Counterfactual analyses using data on centralized high school
admissions in a major USA city show the practical value of both our design
insights and our diagnostic principle.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:28:30 GMT""},{""version"":""v2"",""created"":""Wed, 11 Jan 2023 00:36:41 GMT""}]","2023-01-12"
"2006.14654","Ahmed Arif","Di ""Chelsea"" Sun, Vaishnavi Melkote, Ahmed Sabbir Arif","Exploratory Study of Young Children's Social Media Needs and
  Requirements",,"Extended Abstracts of the 19th ACM International Conference on
  Interaction Design and Children (IDC 2020)","10.1145/3397617.3397836",,"cs.HC cs.SI","http://creativecommons.org/licenses/by/4.0/","  As social media are becoming increasingly popular among young children, it is
important to explore this population's needs and requirements from these
platforms. As a first step to this, we conducted an exploratory design workshop
with children aged between ten and eleven years to find out about their social
media needs and requirements. Through an analysis of the paper prototypes
solicited from the workshop, here we discuss the social media features that are
the most desired by this population.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:31:51 GMT""}]","2020-12-15"
"2006.14655","Tianlong Chen","Yi Wang, Jingyang Zhou, Tianlong Chen, Sijia Liu, Shiyu Chang,
  Chandrajit Bajaj, Zhangyang Wang","Can 3D Adversarial Logos Cloak Humans?",,,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the trend of adversarial attacks, researchers attempt to fool trained
object detectors in 2D scenes. Among many of them, an intriguing new form of
attack with potential real-world usage is to append adversarial patches (e.g.
logos) to images. Nevertheless, much less have we known about adversarial
attacks from 3D rendering views, which is essential for the attack to be
persistently strong in the physical world. This paper presents a new 3D
adversarial logo attack: we construct an arbitrary shape logo from a 2D texture
image and map this image into a 3D adversarial logo via a texture mapping
called logo transformation. The resulting 3D adversarial logo is then viewed as
an adversarial texture enabling easy manipulation of its shape and position.
This greatly extends the versatility of adversarial training for computer
graphics synthesized imagery. Contrary to the traditional adversarial patch,
this new form of attack is mapped into the 3D object world and back-propagates
to the 2D image domain through differentiable rendering. In addition, and
unlike existing adversarial patches, our new 3D adversarial logo is shown to
fool state-of-the-art deep object detectors robustly under model rotations,
leading to one step further for realistic attacks in the physical world. Our
codes are available at https://github.com/TAMU-VITA/3D_Adversarial_Logo.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:34:33 GMT""},{""version"":""v2"",""created"":""Fri, 27 Nov 2020 07:18:55 GMT""}]","2020-11-30"
"2006.14656","Riddhi Mehta","Riddhi Mehta, Maxim Barkov, Lorenzo Sironi and Maxim Lyutikov","Tilting Instability of Magnetically Confined Spheromaks","20 pages, 10 figures, accepted for publication in Journal of Plasma
  Physics","J. Plasma Phys. 86 (2020) 905860407","10.1017/S0022377820000768",,"physics.plasm-ph astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the tilting instability of a magnetically confined spheromak
using 3D MHD and relativistic PIC calculations with an application to
astrophysical plasmas, specifically those occurring in magnetar magnetospheres.
The instability is driven by the counter alignment of the spheromak's intrinsic
magnetic dipole with the external magnetic field. Initially the spheromak
rotates - tilts - trying to lower its magnetic potential energy. As a result a
current sheet forms between the internal magnetic field of a spheromak and the
confining field. Magnetic reconnection sets in; this leads to the annihilation
of the newly counter-aligned magnetic flux of the spheromak. This occurs on few
Alfv\'en time scales. In the case of higher order (second order) spheromak, the
internal core is first pushed out of the envelope, resulting in formation of
two nearly independent tilting spheromaks. Thus, the magnetically twisted outer
shell cannot stabilize the inner core. During dissipation, helicity of the
initial spheromak is carried away by torsional Alfv\'en waves, violating the
assumptions of the Taylor relaxation theorem. In applications to magnetars'
giant flares, fast development of tilting instabilities, and no stabilization
of the higher order spheromaks, make it unlikely that trapped spheromaks are
responsible for the tail emission lasting hundreds of seconds.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:44:55 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 15:53:53 GMT""}]","2020-08-26"
"2006.14657","Mona Ghassemi","Maryam Mesgarpour Tousi, Mona Ghassemi","Influence of Temperature and Frequency on Electric Field Reduction
  Method via a Nonlinear Field Dependent Conductivity Layer Combined with
  Protruding Substrate for Power Electronics Modules",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As shown in our previous studies, geometrical field grading techniques such
as stacked and protruding substrate designs cannot well mitigate high electric
stress issue within power electronics modules. However, it was shown that a
combination of protruding substrate design and applying a nonlinear
field-dependent conductivity layer could address the issue. Electric field (E)
simulations were carried out according to IEC 61287-1 for the partial discharge
test measurement step, where a 50/60 Hz AC voltage was applied. However,
dielectrics, including ceramic substrate and silicone gel, in power devices
undergo high temperatures up to a few hundred degrees and frequencies up to 1
MHz. Thus, E values obtained with electrical parameters of the mentioned
dielectrics for room temperature and under 50/60 Hz may not be valid for high
temperatures and frequencies mentioned above. In this paper, we address this
technical gap through developing a finite element method (FEM) E calculation
model developed in COMSOL Multiphysics where E calculations are carried out for
different temperatures up to 250 C and frequencies up to 1 MHz. Using the
model, the influence of temperature and frequency on our proposed electric
field mitigation technique mentioned above is evaluated.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:45:25 GMT""}]","2020-06-29"
"2006.14658","Stefano Zippilli","Giacomo Serafini, Stefano Zippilli, Irene Marzoli","Optomechanical Stirling heat engine driven by feedback-controlled light","11 pages, 14 figures","Phys. Rev. A 102, 053502 (2020)","10.1103/PhysRevA.102.053502",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose and analyze a microscopic Stirling heat engine based on an
optomechanical system. The working fluid is a single vibrational mode of a
mechanical resonator, which interacts by radiation pressure with a
feedback-controlled optical cavity. The cavity light is used to engineer the
thermal reservoirs and to steer the resonator through a thermodynamic cycle. In
particular, the feedback is used to properly modulate the light fluctuations
inside the cavity and hence to realize efficient thermodynamic transformations
with realistic optomechanical devices.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:47:40 GMT""},{""version"":""v2"",""created"":""Tue, 3 Nov 2020 17:39:07 GMT""}]","2020-11-11"
"2006.14659","Jaafar Elmirghani","Amal A. Alahmadi, T. E. H. El-Gorashi, and Jaafar M. H. Elmirghani","Energy Efficient Processing Allocation in Opportunistic
  Cloud-Fog-Vehicular Edge Cloud Architectures",,,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates distributed processing in Vehicular Edge Cloud
(VECs), where a group of vehicles in a car park, at a charging station or at a
road traffic intersection, cluster and form a temporary vehicular cloud by
combining their computational resources in the cluster. We investigated the
problem of energy efficient processing task allocation in VEC by developing a
Mixed Integer Linear Programming (MILP) model to minimize power consumption by
optimizing the allocation of different processing tasks to the available
network resources, cloud resources, fog resources and vehicular processing
nodes resources. Three dimensions of processing allocation were investigated.
The first dimension compared centralized processing (in the central cloud) to
distributed processing (in the multi-layer fog nodes). The second dimension
introduced opportunistic processing in the vehicular nodes with low and high
vehicular node density. The third dimension considered non-splittable tasks
(single allocation) versus splittable tasks (distributed allocation),
representing real-time versus non real-time applications respectively. The
results revealed that a power savings up to 70% can be achieved by allocating
processing to the vehicles. However, many factors have an impact on the power
saving such the vehicle processing capacities, vehicles density, workload size,
and the number of generated tasks. It was observed that the power saving is
improved by exploiting the flexibility offered by task splitting among the
available vehicles.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:52:29 GMT""}]","2020-06-29"
"2006.14660","Angela Dai","Angela Dai, Yawar Siddiqui, Justus Thies, Julien Valentin, Matthias
  Nie{\ss}ner","SPSG: Self-Supervised Photometric Scene Generation from RGB-D Scans","Video: https://youtu.be/1cj962m9zqo",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present SPSG, a novel approach to generate high-quality, colored 3D models
of scenes from RGB-D scan observations by learning to infer unobserved scene
geometry and color in a self-supervised fashion. Our self-supervised approach
learns to jointly inpaint geometry and color by correlating an incomplete RGB-D
scan with a more complete version of that scan. Notably, rather than relying on
3D reconstruction losses to inform our 3D geometry and color reconstruction, we
propose adversarial and perceptual losses operating on 2D renderings in order
to achieve high-resolution, high-quality colored reconstructions of scenes.
This exploits the high-resolution, self-consistent signal from individual raw
RGB-D frames, in contrast to fused 3D reconstructions of the frames which
exhibit inconsistencies from view-dependent effects, such as color balancing or
pose inconsistencies. Thus, by informing our 3D scene generation directly
through 2D signal, we produce high-quality colored reconstructions of 3D
scenes, outperforming state of the art on both synthetic and real data.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:58:23 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 15:15:45 GMT""}]","2021-04-29"
"2006.14661","Svitlana Mayboroda","G. David and S. Mayboroda","Harmonic measure is absolutely continuous with respect to the Hausdorff
  measure on all low-dimensional uniformly rectifiable sets",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It was recently shown that the harmonic measure is absolutely continuous with
respect to the Hausdorff measure on a domain with an $n-1$ dimensional
uniformly rectifiable boundary, in the presence of now well understood
additional topological constraints. The topological restrictions, while mild,
are necessary, as the counterexamples of C. Bishop and P. Jones show, and no
analogues of these results have been available for higher co-dimensional sets.
  In the present paper we show that for any $d<n-1$ and for any domain with a
$d$-dimensional uniformly rectifiable boundary the elliptic measure of an
appropriate degenerate elliptic operator is absolutely continuous with respect
to the Hausdorff measure of the boundary. There are no topological or
dimensional restrictions contrary to the aforementioned results.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 18:59:32 GMT""}]","2020-06-29"
"2006.14662","Abhishek Gupta","Abhishek Gupta (1 and 2), Camylle Lanteigne (1 and 3), Victoria Heath
  (1 and 4), Marianna Bergamaschi Ganapini (1 and 5), Erick Galinkin (1 and 6),
  Allison Cohen (1 and 7), Tania De Gasperis (1 and 8), Mo Akif (1 and 3),
  Renjie Butalid (1) ((1) Montreal AI Ethics Institute, (2) Microsoft, (3)
  McGill University, (4) Creative Commons, (5) Union College, (6) Rapid7, (7)
  AI Global, (8) OCAD University)","The State of AI Ethics Report (June 2020)","128 pages",,,,"cs.CY cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  These past few months have been especially challenging, and the deployment of
technology in ways hitherto untested at an unrivalled pace has left the
internet and technology watchers aghast. Artificial intelligence has become the
byword for technological progress and is being used in everything from helping
us combat the COVID-19 pandemic to nudging our attention in different
directions as we all spend increasingly larger amounts of time online. It has
never been more important that we keep a sharp eye out on the development of
this field and how it is shaping our society and interactions with each other.
With this inaugural edition of the State of AI Ethics we hope to bring forward
the most important developments that caught our attention at the Montreal AI
Ethics Institute this past quarter. Our goal is to help you navigate this
ever-evolving field swiftly and allow you and your organization to make
informed decisions. This pulse-check for the state of discourse, research, and
development is geared towards researchers and practitioners alike who are
making decisions on behalf of their organizations in considering the societal
impacts of AI-enabled solutions. We cover a wide set of areas in this report
spanning Agency and Responsibility, Security and Risk, Disinformation, Jobs and
Labor, the Future of AI Ethics, and more. Our staff has worked tirelessly over
the past quarter surfacing signal from the noise so that you are equipped with
the right tools and knowledge to confidently tread this complex yet
consequential domain.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:00:41 GMT""}]","2020-06-29"
"2006.14663","Samantha Brunker","Samantha W. Brunker, John J. Salzer, Steven Janowiecki, Rose A. Finn,
  George Helou","Properties of the KISS Green Pea Galaxies","21 pages, 12 figures. Accepted for publication in the Astrophysical
  Journal",,"10.3847/1538-4357/ab9ec0",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Green Peas are a class of extreme star-forming galaxies at intermediate
redshifts, originally discovered via color-selection using multi-filter,
wide-field survey imaging data (Cardamone et al. 2009). They are commonly
thought of as being analogs of high-redshift Ly$\alpha$-emitting galaxies. The
defining characteristic of Green Pea galaxies is a high-excitation nebular
spectrum with very large equivalent width lines, leading to the recognition
that Green Pea-like galaxies can also be identified in samples of emission-line
galaxies. Here we compare the properties a sample of [O III]-selected
star-forming galaxies (z = 0.29-0.41) from the KPNO International Spectroscopic
Survey (KISS) with the color-selected Green Peas. We find that the KISS [O
III]-selected galaxies overlap with the parameter space defined by the
color-selected Green Peas; the two samples appear to be drawn from the same
population of objects. We compare the KISS Green Peas with the full
H$\alpha$-selected KISS star-forming galaxy sample (z $<$ 0.1) and find that
they are extreme systems. Many appear to be young systems at their observed
look-back times (3-4 Gyr), with more than 90% of their rest-frame B-band
luminosity coming from the starburst population. We compute the volume density
of the KISSR Green Peas at z = 0.29-0.41 and find that they are extremely rare
objects. We don't see galaxies as extreme as the KISSR Green Peas in the local
Universe, although we recognize several lower-luminosity systems at z $<$ 0.1.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:03:55 GMT""}]","2020-08-05"
"2006.14664","Eoin Mackall","Eoin Mackall","Universal additive Chern classes and a GRR-type theorem","14 Pages. To appear in Journal of Algebra",,,,"math.AG math.KT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a functor, from the category of schemes to the category of
graded rings, that is an initial object for having a theory of Chern classes
with an additive first Chern class. For any scheme $X$, the graded ring that
our functor associates to $X$ is related to the associated graded ring of the
$\gamma$-filtration on the Grothendieck ring of finite rank locally free
sheaves on $X$ via a Grothendieck-Riemann-Roch type theorem.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:14:23 GMT""}]","2020-06-29"
"2006.14665","Yang Sun","Yang Sun, Yong-Xin Yao, Manh Cuong Nguyen, Cai-Zhuang Wang, Kai-Ming
  Ho and Vladimir Antropov","Spatial decomposition of magnetic anisotropy in magnets: application for
  doped Fe16N2",,"Phys. Rev. B 102, 134429 (2020)","10.1103/PhysRevB.102.134429",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a scheme of decomposition of the total relativistic energy in
solids to intra- and interatomic contributions. The method is based on a
variation of the speed of light from its value in relativistic theory to
infinity (a non-relativistic limit). As an illustration of the method, we
tested such decomposition in the case of a spin-orbit interaction variation for
decomposition of the magnetic anisotropy energy (MAE) in CoPt. We further
studied the {\alpha}''-Fe16N2 magnet doped by Bi, Sb, Co and Pt atoms. It has
been found that the addition of Pt atoms can enhance the MAE by as large as
five times while Bi and Sb substitutions double the total MAE. Using the
proposed technique we demonstrate the spatial distribution of these
enhancements. Our studies also suggest that Sb, Pt and Co substitutions could
be synthesized by experiments.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:14:50 GMT""},{""version"":""v2"",""created"":""Thu, 5 Nov 2020 04:05:44 GMT""}]","2020-11-06"
"2006.14666","Pranav Sharma","Pranav Sharma","LPar -- A Distributed Multi Agent platform for building Polyglot, Omni
  Channel and Industrial grade Natural Language Interfaces",,,,,"cs.CL cs.CY cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of serving and delighting customers in a personal and near human
like manner is very high on automation agendas of most Enterprises. Last few
years, have seen huge progress in Natural Language Processing domain which has
led to deployments of conversational agents in many enterprises. Most of the
current industrial deployments tend to use Monolithic Single Agent designs that
model the entire knowledge and skill of the Domain. While this approach is one
of the fastest to market, the monolithic design makes it very hard to scale
beyond a point. There are also challenges in seamlessly leveraging many tools
offered by sub fields of Natural Language Processing and Information Retrieval
in a single solution. The sub fields that can be leveraged to provide relevant
information are, Question and Answer system, Abstractive Summarization,
Semantic Search, Knowledge Graph etc. Current deployments also tend to be very
dependent on the underlying Conversational AI platform (open source or
commercial) , which is a challenge as this is a fast evolving space and no one
platform can be considered future proof even in medium term of 3-4 years.
Lately,there is also work done to build multi agent solutions that tend to
leverage a concept of master agent. While this has shown promise, this approach
still makes the master agent in itself difficult to scale. To address these
challenges, we introduce LPar, a distributed multi agent platform for large
scale industrial deployment of polyglot, diverse and inter-operable agents. The
asynchronous design of LPar supports dynamically expandable domain. We also
introduce multiple strategies available in the LPar system to elect the most
suitable agent to service a customer query.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:20:07 GMT""}]","2020-06-29"
"2006.14667","Clement de Chaisemartin","Cl\'ement de Chaisemartin and Xavier D'Haultf{\oe}uille","Empirical MSE Minimization to Estimate a Scalar Parameter",,,,,"math.ST econ.EM stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the estimation of a scalar parameter, when two estimators are
available. The first is always consistent. The second is inconsistent in
general, but has a smaller asymptotic variance than the first, and may be
consistent if an assumption is satisfied. We propose to use the weighted sum of
the two estimators with the lowest estimated mean-squared error (MSE). We show
that this third estimator dominates the other two from a minimax-regret
perspective: the maximum asymptotic-MSE-gain one may incur by using this
estimator rather than one of the other estimators is larger than the maximum
asymptotic-MSE-loss.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:20:37 GMT""}]","2020-06-29"
"2006.14668","Rudolf Rosa","Rudolf Rosa, Ond\v{r}ej Du\v{s}ek, Tom Kocmi, David Mare\v{c}ek,
  Tom\'a\v{s} Musil, Patr\'icia Schmidtov\'a, Dominik Jurko, Ond\v{r}ej Bojar,
  Daniel Hrbek, David Ko\v{s}\v{t}\'ak, Martina Kinsk\'a, Josef Dole\v{z}al and
  Kl\'ara Voseck\'a","THEaiTRE: Artificial Intelligence to Write a Theatre Play","accepted to AI4Narratives2020","Proc. AI4Narratives (2020) 9-13",,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present THEaiTRE, a starting project aimed at automatic generation of
theatre play scripts. This paper reviews related work and drafts an approach we
intend to follow. We plan to adopt generative neural language models and
hierarchical generation approaches, supported by summarization and machine
translation methods, and complemented with a human-in-the-loop approach.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:24:57 GMT""}]","2021-10-26"
"2006.14669","Chunmei Wang","Dan Li and Chunmei Wang","A simplified primal-dual weak Galerkin finite element method for
  Fokker-Planck type equations","23 pages, 17 tables",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A simplified primal-dual weak Galerkin (S-PDWG) finite element method is
designed for the Fokker-Planck type equation with non-smooth diffusion tensor
and drift vector. The discrete system resulting from S-PDWG method has
significantly fewer degrees of freedom compared with the one resulting from the
PDWG method proposed by Wang-Wang \cite{WW-fp-2018}. Furthermore, the condition
number of the S-PDWG method is smaller than the PDWG method \cite{WW-fp-2018}
due to the introduction of a new stabilizer, which provides a potential for
designing fast algorithms. Optimal order error estimates for the S-PDWG
approximation are established in the $L^2$ norm. A series of numerical results
are demonstrated to validate the effectiveness of the S-PDWG method.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:26:26 GMT""}]","2020-06-29"
"2006.14670","Patrick Tribbett","Patrick D. Tribbett, Tyler D. Robinson, Tommi T. Koskinen","Titan in Transit: Ultraviolet Occultation Observations Reveal a Complex
  Atmospheric Structure","18 pages, 11 figures, submitted to AAS journals; comments and
  feedback welcome",,,,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transit spectroscopy is a key tool for exoplanet atmospheric
characterization. However, transit spectrum observations can be limited by
aerosol extinction when gas opacities are weak. The ultraviolet wavelength
range contains a variety of strong molecular and atomic features, potentially
enabling gas species detection even when atmospheric hazes are present. To
understand the interplay between aerosol extinction and ultraviolet molecular
opacities, we investigate transmission through the atmosphere of Saturn's moon
Titan during an occultation observed with the Ultraviolet Imaging Spectrometer
(UVIS) aboard NASA's Cassini orbiter. We analyze the derived ultraviolet
transit spectrum of Titan using atmospheric retrieval models that both include
and exclude treatments for hazes. Our retrieved atmospheric properties, namely
the gas column densities, are consistent with previous studies analyzing UVIS
occultation data. Using the Bayesian Information Criterion, we demonstrate that
haze parameterizations were unnecessary to fit the data despite apparent
opacity due to multiple detached haze layers in the underlying occultation
data. Our work indicates that continued characterization of exoplanets in the
ultraviolet wavelength regime can provide novel atmospheric constraints even if
transit spectra are dominated by haze extinction at longer wavelengths.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:26:32 GMT""}]","2020-06-29"
"2006.14671","Constantin Shramov","Constantin Shramov","Finite groups acting on Severi-Brauer surfaces","19 pages",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify finite groups that can act by automorphisms and birational
automorphisms on non-trivial Severi-Brauer surfaces over fields of
characteristic zero.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:35:09 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2020 08:09:22 GMT""},{""version"":""v3"",""created"":""Thu, 17 Dec 2020 12:01:02 GMT""}]","2020-12-18"
"2006.14672","Thomas Purcell","Florian Knoop and Thomas A. R. Purcell and Matthias Scheffler and
  Christian Carbogno","Anharmonicity Measure for Materials","17 figures, 2 tables, and 12 pages","Phys. Rev. Materials 4, 083809 (2020)","10.1103/PhysRevMaterials.4.083809",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Theoretical frameworks used to qualitatively and quantitatively describe
nuclear dynamics in solids are often based on the harmonic approximation.
However, this approximation is known to become inaccurate or to break down
completely in many modern functional materials. Interestingly, there is no
reliable measure to quantify anharmonicity so far. Thus, a systematic
classification of materials in terms of anharmonicity and a benchmark of
methodologies that may be appropriate for different strengths of anharmonicity
is currently impossible. In this work, we derive and discuss a statistical
measure that reliably classifies compounds across temperature regimes and
material classes by their ""degree of anharmonicity"". This enables us to
distinguish ""harmonic"" materials, for which anharmonic effects constitute a
small perturbation on top of the harmonic approximation, from strongly
""anharmonic"" materials, for which anharmonic effects become significant or even
dominant and the treatment of anharmonicity in terms of perturbation theory is
more than questionable. We show that the analysis of this measure in real and
reciprocal space is able to shed light on the underlying microscopic
mechanisms, even at conditions close to, e.g., phase transitions or defect
formation. Eventually, we demonstrate that the developed approach is
computationally efficient and enables rapid high-throughput searches by
scanning over a set of several hundred binary solids. The results show that
strong anharmonic effects beyond the perturbative limit are not only active in
complex materials or close to phase transitions, but already at moderate
temperatures in simple binary compounds.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:39:34 GMT""},{""version"":""v2"",""created"":""Mon, 10 Aug 2020 18:09:35 GMT""}]","2020-09-02"
"2006.14673","Hugo Oliveira","Hugo Oliveira, Caio Silva, Gabriel L. S. Machado, Keiller Nogueira,
  Jefersson A. dos Santos","Fully Convolutional Open Set Segmentation","Submitted to the Machine Learning Journal",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In semantic segmentation knowing about all existing classes is essential to
yield effective results with the majority of existing approaches. However,
these methods trained in a Closed Set of classes fail when new classes are
found in the test phase. It means that they are not suitable for Open Set
scenarios, which are very common in real-world computer vision and remote
sensing applications. In this paper, we discuss the limitations of Closed Set
segmentation and propose two fully convolutional approaches to effectively
address Open Set semantic segmentation: OpenFCN and OpenPCS. OpenFCN is based
on the well-known OpenMax algorithm, configuring a new application of this
approach in segmentation settings. OpenPCS is a fully novel approach based on
feature-space from DNN activations that serve as features for computing PCA and
multi-variate gaussian likelihood in a lower dimensional space. Experiments
were conducted on the well-known Vaihingen and Potsdam segmentation datasets.
OpenFCN showed little-to-no improvement when compared to the simpler and much
more time efficient SoftMax thresholding, while being between some orders of
magnitude slower. OpenPCS achieved promising results in almost all experiments
by overcoming both OpenFCN and SoftMax thresholding. OpenPCS is also a
reasonable compromise between the runtime performances of the extremely fast
SoftMax thresholding and the extremely slow OpenFCN, being close able to run
close to real-time. Experiments also indicate that OpenPCS is effective, robust
and suitable for Open Set segmentation, being able to improve the recognition
of unknown class pixels without reducing the accuracy on the known class
pixels.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:40:20 GMT""}]","2020-06-29"
"2006.14674","Ru-Yu Lai","Christian Klingenberg, Ru-Yu Lai, Qin Li","Reconstruction of the emission coefficient in the nonlinear radiative
  transfer equation","16 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate an inverse problem for the radiative transfer
equation that is coupled with a heat equation in a nonscattering medium in
$\mathbb{R}^n$, $n\geq 2$. The two equations are coupled through a nonlinear
blackbody emission term that is proportional to the fourth power of the
temperature. By measuring the radiation intensity on the surface of the
blackbody, we prove that the emission property of the system can be uniquely
reconstructed. In particular, we design a reconstruction procedure that uses
merely one set of experiment setup to fully recover the emission parameter.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:42:08 GMT""},{""version"":""v2"",""created"":""Fri, 9 Oct 2020 15:54:26 GMT""}]","2020-10-12"
"2006.14675","William Foreman","W. Castiglioni, W. Foreman, I. Lepetic, B. R. Littlejohn, M. Malaker,
  A. Mastbaum","Benefits of MeV-scale reconstruction capabilities in large liquid argon
  time projection chambers",,,"10.1103/PhysRevD.102.092010",,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using truth-level Monte Carlo simulations of particle interactions in a large
volume of liquid argon, we demonstrate physics capabilities enabled by
reconstruction of topologically compact and isolated low-energy features, or
`blips,' in large liquid argon time projection chamber (LArTPC) events. These
features are mostly produced by electron products of photon interactions
depositing ionization energy. The blip identification capability of the LArTPC
is enabled by its unique combination of size, position resolution precision,
and low energy thresholds. We show that consideration of reconstructed blips in
LArTPC physics analyses can result in substantial improvements in calorimetry
for neutrino and new physics interactions and for final-state particles ranging
in energy from the MeV to the GeV scale. Blip activity analysis is also shown
to enable discrimination between interaction channels and final-state particle
types. In addition to demonstrating these gains in calorimetry and
discrimination, some limitations of blip reconstruction capabilities and
physics outcomes are also discussed.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:50:50 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 16:59:10 GMT""}]","2020-12-30"
"2006.14676","Clara Shaw","Clara L. Shaw and David A. Kennedy","What the reproductive number R_0 can and cannot tell us about COVID-19
  dynamics","25 pages, 2 figures",,,,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The reproductive number R_0 (and its value after initial disease emergence R)
has long been used to predict the likelihood of pathogen invasion, to gauge the
potential severity of an epidemic, and to set policy around interventions.
However, often ignored complexities have generated confusion around use of the
metric. This is particularly apparent with the emergent pandemic virus
SARS-CoV-2, the causative agent of COVID-19. We address some of these
misconceptions, namely, how R changes over time, varies over space, and relates
to epidemic size by referencing the mathematical definition of R and examples
from the current pandemic. We hope that a better appreciation of the uses,
nuances, and limitations of R facilitates a better understanding of epidemic
spread, epidemic severity, and the effects of interventions in the context of
SARS-CoV-2.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:52:34 GMT""}]","2020-06-29"
"2006.14677","Yuxin Chen","Akash Kumar, Adish Singla, Yisong Yue, Yuxin Chen","Average-case Complexity of Teaching Convex Polytopes via Halfspace
  Queries",,,,,"cs.LG cs.CG math.CO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the task of locating a target region among those induced by
intersections of $n$ halfspaces in $\mathbb{R}^d$. This generic task connects
to fundamental machine learning problems, such as training a perceptron and
learning a $\phi$-separable dichotomy. We investigate the average teaching
complexity of the task, i.e., the minimal number of samples (halfspace queries)
required by a teacher to help a version-space learner in locating a randomly
selected target. As our main result, we show that the average-case teaching
complexity is $\Theta(d)$, which is in sharp contrast to the worst-case
teaching complexity of $\Theta(n)$. If instead, we consider the average-case
learning complexity, the bounds have a dependency on $n$ as $\Theta(n)$ for
\tt{i.i.d.} queries and $\Theta(d \log(n))$ for actively chosen queries by the
learner. Our proof techniques are based on novel insights from computational
geometry, which allow us to count the number of convex polytopes and faces in a
Euclidean space depending on the arrangement of halfspaces. Our insights allow
us to establish a tight bound on the average-case complexity for
$\phi$-separable dichotomies, which generalizes the known $\mathcal{O}(d)$
bound on the average number of ""extreme patterns"" in the classical
computational geometry literature (Cover, 1965).
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:59:24 GMT""},{""version"":""v2"",""created"":""Sun, 25 Oct 2020 23:58:40 GMT""}]","2020-10-27"
"2006.14678","Jie Chen","Jie Chen, Aritra K. Mukhopadhyay, Peter Schmelcher","Asymptotic population imbalance of an ultracold bosonic ensemble in a
  driven double-well","13 pages, 5 figures","Phys. Rev. A 102, 033302 (2020)","10.1103/PhysRevA.102.033302",,"quant-ph cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate that an ultracold many-body bosonic ensemble confined in an
one-dimensional (1D) double well potential exhibits a population imbalance
between the two wells at large timescales, when the depth of the wells are
modulated by a time-dependent driving force. The specific form of the driving
force is shown to break spatial parity and time-reversal symmetries, which
leads to such an asymptotic population imbalance (API). The value of the API
can be flexibly controlled by changing the phase of the driving force and the
total number of particles. While the API is highly sensitive to the initial
state in the few-particle regime, this dependence on the initial state is lost
as we approach the classical limit of large particle numbers. We perform a
Floquet analysis in the few-particle regime and an analysis based on a driven
classical non-rigid pendulum in the many-particle regime. Although the obtained
API values in the many-particle regime agree very well with that obtained in
the classical limit, we show that there exists a significant disagreement in
the corresponding real-time population imbalance due to quantum correlations.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:01:02 GMT""}]","2020-09-09"
"2006.14679","Basavesh Ammanaghatta Shivakumar","Paul M. Berges, Basavesh Ammanaghatta Shivakumar, Timothy Graziano,
  Ryan Gerdes and Z. Berkay Celik","On the Feasibility of Exploiting Traffic Collision Avoidance System
  Vulnerabilities",,,,,"eess.SP cs.CY cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traffic Collision Avoidance Systems (TCAS) are safety-critical systems
required on most commercial aircrafts in service today. However, TCAS was not
designed to account for malicious actors. While in the past it may have been
infeasible for an attacker to craft radio signals to mimic TCAS signals,
attackers today have access to open-source digital signal processing software,
like GNU Radio, and inexpensive software defined radios (SDR) that enable the
transmission of spurious TCAS messages. In this paper, methods, both
qualitative and quantitative, for analyzing TCAS from an adversarial
perspective are presented. To demonstrate the feasibility of inducing near
mid-air collisions between current day TCAS-equipped aircraft, an experimental
Phantom Aircraft generator is developed using GNU Radio and an SDR against a
realistic threat model.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:03:17 GMT""}]","2020-06-29"
"2006.14680","Andrew Larkoski","Andrew J. Larkoski","Improving the Understanding of Jet Grooming in Perturbation Theory","12 pages, 5 figures; v2: JHEP version, fixed typos and added
  discussion for $\beta >0$ and non-perturbative power corrections",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Jet grooming has emerged as a necessary and powerful tool in a precision jet
physics program. In this paper, we present three results on jet grooming in
perturbation theory, focusing on heavy jet mass in $e^+e^-\to$ hadrons
collisions, groomed with the modified mass drop tagger. First, we calculate the
analytic cross section at leading-order. Second, using the leading-order result
and numerical results through next-to-next-to-leading order, we show that cusps
in the distribution on the interior of phase space at leading-order are
softened at higher orders. Finally, using analytic and numerical results, we
show that terms that violate the assumptions of the factorization theorem for
groomed jet mass are numerically much smaller than expected from power
counting. These results provide important information regarding the convergence
of perturbation theory for groomed jet observables and reliable estimates for
residual uncertainties in a precision calculation.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:15:42 GMT""},{""version"":""v2"",""created"":""Fri, 14 Aug 2020 20:27:07 GMT""}]","2020-08-18"
"2006.14681","Nan Li","Yu-Chen Ding, Nan Li, Chun-Cheng Wei and Yu-Feng Zhou","The high energy window of probing dark matter with cosmic-ray
  antideuterium and antihelium","22 pages, 12 figures; to appear on Chin. Phys. C",,"10.1088/1674-1137/abf13a",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cosmic-ray (CR) anti-nuclei are often considered as important observables for
dark matter (DM) indirect detections at low kinetic energies below GeV per
nucleon. Since the primary CR fluxes drop quickly towards high energies, the
secondary anti-nuclei in CR are expected to be significantly suppressed in high
energy regions ($\gtrsim 100$ GeV per nucleon). If DM particles are heavy, the
annihilation productions of DM can be highly boosted, thus the fluxes of
anti-nuclei produced by DM annihilations may exceed the secondary background at
high energies, which opens a high energy window for DM indirect detections. We
investigate the possibility of detecting heavy DM particles which annihilate
into high energy anti-nuclei. We use Monte-Carlo generators $\texttt{PYTHIA}$,
$\texttt{EPOS-LHC}$ and $\texttt{DPMJET}$ and the coalescence model to simulate
the production of anti-nuclei, and constrain the DM annihilation cross sections
by using the AMS-02 and HAWC antiproton data and the HESS galactic center
gamma-ray data. We find that the conclusion depends on the choice of DM density
profiles. For the ""Cored"" type profile with a DM particle mass $\gtrsim 10$
TeV, the contributions from DM annihilations can exceed the secondary
background in high energy regions, which opens the high energy window. While
for the ""Cuspy"" type profile, the excess disappears.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:19:17 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 12:47:07 GMT""}]","2021-07-07"
"2006.14682","Elias Roussos","Elias Roussos and Peter Kollmann","The radiation belts of Jupiter and Saturn","24 pages, 4 figures",,"10.1002/9781119815624.ch32",,"astro-ph.EP physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The era of outer planet orbiters (Galileo, Juno and Cassini) is advancing our
understanding of how the radiation belts of Jupiter and Saturn are structured,
form and evolve well beyond what had been possible during the age of flyby
missions and ground-based observations. The nearly two decades-long datasets of
these missions, in the context of detailed and long-term observations of
Earth's radiation belts, highlight which of the processes that accelerate
particles to relativistic kinetic energies and limit their flux intensity can
be considered more universal, and thus key for most extraterrestrial
magnetospheres, and which reflect the unique aspects of each planet and its
magnetospheric system. In this chapter we focus on the in-situ radiation belt
observations in the context of theory, simulations and relevant measurements by
Earth-based observatories. We describe both the average state and the time
variations of Jupiter's and Saturn's radiation belts and associate them with
specific physical processes.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:20:39 GMT""}]","2021-09-15"
"2006.14683","Itzik Malkiel","Itzik Malkiel, Lior Wolf","MTAdam: Automatic Balancing of Multiple Training Loss Terms",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When training neural models, it is common to combine multiple loss terms. The
balancing of these terms requires considerable human effort and is
computationally demanding. Moreover, the optimal trade-off between the loss
term can change as training progresses, especially for adversarial terms. In
this work, we generalize the Adam optimization algorithm to handle multiple
loss terms. The guiding principle is that for every layer, the gradient
magnitude of the terms should be balanced. To this end, the Multi-Term Adam
(MTAdam) computes the derivative of each loss term separately, infers the first
and second moments per parameter and loss term, and calculates a first moment
for the magnitude per layer of the gradients arising from each loss. This
magnitude is used to continuously balance the gradients across all layers, in a
manner that both varies from one layer to the next and dynamically changes over
time. Our results show that training with the new method leads to fast recovery
from suboptimal initial loss weighting and to training outcomes that match
conventional training with the prescribed hyperparameters of each method.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:27:27 GMT""}]","2020-06-29"
"2006.14684","Lars Gjesteby","Adam Michaleas, Lars A. Gjesteby, Michael Snyder, David Chavez, Meagan
  Ash, Matthew A. Melton, Damon G. Lamb, Sara N. Burke, Kevin J. Otto, Lee
  Kamentsky, Webster Guan, Kwanghun Chung, Laura J. Brattain","Active Learning Pipeline for Brain Mapping in a High Performance
  Computing Environment","6 pages, 5 figures, submitted to IEEE HPEC 2020 proceedings",,,,"eess.IV q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describes a scalable active learning pipeline prototype for
large-scale brain mapping that leverages high performance computing power. It
enables high-throughput evaluation of algorithm results, which, after human
review, are used for iterative machine learning model training. Image
processing and machine learning are performed in a batch layer. Benchmark
testing of image processing using pMATLAB shows that a 100$\times$ increase in
throughput (10,000%) can be achieved while total processing time only increases
by 9% on Xeon-G6 CPUs and by 22% on Xeon-E5 CPUs, indicating robust
scalability. The images and algorithm results are provided through a serving
layer to a browser-based user interface for interactive review. This pipeline
has the potential to greatly reduce the manual annotation burden and improve
the overall performance of machine learning-based brain mapping.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:27:33 GMT""}]","2020-06-29"
"2006.14685","Yongcheng Zhou","Y. C. Zhou and David Argudo and Frank Marcoline and Michael Grabe","A Computational Model of Protein Induced Membrane Morphology with
  Geodesic Curvature Driven Protein-Membrane Interface",,,,,"cond-mat.soft q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuum or hybrid modeling of bilayer membrane morphological dynamics
induced by embedded proteins necessitates the identification of
protein-membrane interfaces and coupling of deformations of two surfaces. In
this article we developed (i) a minimal total geodesic curvature model to
describe these interfaces, and (ii) a numerical one-one mapping between two
surface through a conformal mapping of each surface to the common middle
annulus. Our work provides the first computational tractable approach for
determining the interfaces between bilayer and embedded proteins. The one-one
mapping allows a convenient coupling of the morphology of two surfaces. We
integrated these two new developments into the energetic model of
protein-membrane interactions, and developed the full set of numerical methods
for the coupled system. Numerical examples are presented to demonstrate (1) the
efficiency and robustness of our methods in locating the curves with minimal
total geodesic curvature on highly complicated protein surfaces, (2) the
usefulness of these interfaces as interior boundaries for membrane deformation,
and (3) the rich morphology of bilayer surfaces for different protein-membrane
interfaces.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:32:36 GMT""}]","2020-06-29"
"2006.14686","Francesco Marino","P. Vezio, A. Chowdhury, M. Bonaldi, A. Borrielli, F. Marino, B.
  Morana, G. A. Prodi, P.M. Sarro, E. Serra and F. Marin","Quantum motion of a squeezed mechanical oscillator attained via a
  optomechanical experiment",,"Phys. Rev. A 102, 053505 (2020)","10.1103/PhysRevA.102.053505",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We experimentally investigate a mechanical squeezed state realized in a
parametrically-modulated membrane resonator embedded in an optical cavity. We
demonstrate that a quantum characteristic of the squeezed dynamics can be
revealed and quantified even in a moderately warm oscillator, through the
analysis of motional sidebands. We provide a theoretical framework for
quantitatively interpreting the observations and present an extended comparison
with the experiment. A notable result is that the spectral shape of each
motional sideband provides a clear signature of a quantum mechanical squeezed
state without the necessity of absolute calibrations, in particular in the
regime where residual fluctuations in the squeezed quadrature are reduced below
the zero-point level.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:34:44 GMT""}]","2020-11-11"
"2006.14687","Ricardo Ruviaro","Liliane A. Maia, Gilberto S. Pina and Ricardo Ruviaro","Pohozaev manifold constraint for solving nonlinear Schr\""odinger
  equations with potentials vanishing at infinity",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existence of a positive solution for a class of nonlinear Schr\""odinger
equations with potentials which decay to zero at infinity, with an appropriate
rate, approaching zero mass type limit scalar field equations, is established
via a new composition of two translated and dilated solitons and its projection
on the so called Pohozaev manifold.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:35:19 GMT""}]","2020-06-29"
"2006.14688","Nicole Reindl Dr.","N. Reindl, V. Schaffenroth, M. M. Miller Bertolami, S. Geier, N. L.
  Finch, M. A. Barstow, S. L. Casewell, and S. Taubenberger","An in-depth reanalysis of the alleged type Ia supernova progenitor
  Henize 2-428","14 pages, published in A&A,
  https://www.aanda.org/articles/aa/abs/2020/06/aa38117-20/aa38117-20.html",,"10.1051/0004-6361/202038117",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nucleus of the planetary nebula Hen2-428 is a short orbital-period
(4.2h), double-lined spectroscopic binary, whose status as a potential
supernova type Ia progenitor has raised some controversy in the literature.
With the aim of resolving this debate, we carried out an in-depth reanalysis of
the system. Our approach combines a refined wavelength calibration, thorough
line-identifications, improved radial-velocity measurements, non-LTE spectral
modeling, as well as multi-band light-curve fitting. Our results are then
discussed in view of state-of-the-art stellar evolutionary models.
  Besides systematic zero-point shifts in the wavelength calibration of the
OSIRIS spectra which were also used in the previous analysis of the system, we
found that the spectra are contaminated with diffuse interstellar bands. Our
Voigt-profile radial velocity fitting method, which considers the additional
absorption of these diffuse interstellar bands, reveals significantly lower
masses ($M_1=0.66\pm0.11M_\odot$ and $M_2=0.42\pm0.07M_\odot$) than previously
reported and a mass ratio that is clearly below unity. Our spectral and light
curve analyses lead to consistent results, however, we find higher effective
temperatures and smaller radii than previously reported. Moreover, we find that
the red-excess that was reported before to prove to be a mere artifact of an
outdated reddening law that was applied.
  Our work shows that blends of HeII 5412A with diffuse interstellar bands have
led to an overestimation of the previously reported dynamical masses of
Hen2-428. The merging event of Hen2-428 will not be recognised as a supernova
type Ia, but most likely leads to the formation of a H-deficient star. We
suggest that the system was formed via a first stable mass transfer episode,
followed by common envelope evolution, and it is now composed of a post-early
AGB star and a reheated He-core white dwarf.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:35:36 GMT""}]","2020-06-29"
"2006.14689","Shruti Subramanian","Shruti Subramanian (1 and 2), Quinn T. Campbell (1 and 3), Simon Moser
  (4 and 5), Jonas Kiemle (6), Philipp Zimmermann (6), Paul Seifert (6 and 7),
  Florian Sigger (6), Deeksha Sharma (8), Hala Al-Sadeg (1), Michael Labella
  III (9), Dacen Waters (10), Randall M. Feenstra (10), Roland J. Koch (4),
  Chris Jozwiak (4), Aaron Bostwick (4), Eli Rotenberg (4), Ismaila Dabo (1),
  Alexander Holleitner (6), Thomas E. Beechem (11), Ursula Wurstbauer (6 and
  12) and Joshua A. Robinson (1,2,13 and 14) ((1) Department of Materials
  Science and Engineering, The Pennsylvania State University. (2) Center for
  2-Dimensional and Layered Materials, The Pennsylvania State University. (3)
  Center for Computing Research, Sandia National Laboratories. (4) Advanced
  Light Source, E. O. Lawrence Berkeley National Laboratory. (5) Physikalisches
  Institut and W\""urzburg-Dresden Cluster of Excellence ct.qmat, Universit\""at
  W\""urzburg. (6) Walter Schottky Institut and Physik Department, Technische
  Universit\""at M\""unchen. (7) ICFO - Institut de Ciencies Fotoniques, The
  Barcelona Institute of Science and Technology. (8) Department of Mechanical
  Engineering, The Pennsylvania State University. (9) Nanofabrication Facility,
  The Pennsylvania State University. (10) Department of Physics, Carnegie
  Mellon University. (11) Center for Integrated Nanotechnologies, Sandia
  National Laboratories. (12) Institute of Physics, University of Munster. (13)
  2-Dimensional Crystal Consortium, The Pennsylvania State University. (14)
  Center for Atomically Thin Multifunctional Coatings, The Pennsylvania State
  University.)","Photo-physics and electronic structure of lateral graphene/MoS2 and
  metal/MoS2 junctions",,,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Integration of semiconducting transition metal dichalcogenides (TMDs) into
functional optoelectronic circuitries requires an understanding of the charge
transfer across the interface between the TMD and the contacting material.
Here, we use spatially resolved photocurrent microscopy to demonstrate
electronic uniformity at the epitaxial graphene/molybdenum disulfide (EG/MoS2)
interface. A 10x larger photocurrent is extracted at the EG/MoS2 interface when
compared to metal (Ti/Au) /MoS2 interface. This is supported by semi-local
density-functional theory (DFT), which predicts the Schottky barrier at the
EG/MoS2 interface to be ~2x lower than Ti/MoS2. We provide a direct
visualization of a 2D material Schottky barrier through combination of angle
resolved photoemission spectroscopy with spatial resolution selected to be ~300
nm (nano-ARPES) and DFT calculations. A bending of ~500 meV over a length scale
of ~2-3 micrometer in the valence band maximum of MoS2 is observed via
nano-ARPES. We explicate a correlation between experimental demonstration and
theoretical predictions of barriers at graphene/TMD interfaces. Spatially
resolved photocurrent mapping allows for directly visualizing the uniformity of
built-in electric fields at heterostructure interfaces, providing a guide for
microscopic engineering of charge transport across heterointerfaces. This
simple probe-based technique also speaks directly to the 2D synthesis community
to elucidate electronic uniformity at domain boundaries alongside morphological
uniformity over large areas.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:40:03 GMT""}]","2020-06-29"
"2006.14690","Haneya Qureshi","Haneya Naeem Qureshi and Ali Imran","Towards Designing Systems with Large Number of Antennas for Range
  Extension in Ground-to-Air Communications","Published in IEEE PIMRC 2018","Published in IEEE PIMRC 2018",,,"eess.SP cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Providing broadband connectivity to airborne systems using ground based
cellular networks is a promising solution as it offers several advantages over
satellite-based solutions. However, limited range of terrestrial base stations
is a key challenge in full realization of this approach. This paper addresses
this problem by proposing a mathematical framework for range extension
leveraging large number of antennas at the base station. In contrast to prior
works where range is not considered as a design parameter, we model the signal
to noise ratio as a function of both number of antennas as well as the range in
line-of-sight ground-to-air systems. This allows us to derive analytical
expressions to determine the number of antennas required to increase range in
different frequency bands and tracking and non tracking scenarios.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:40:58 GMT""}]","2020-06-29"
"2006.14691","Ilya Chugunov","Ilya Chugunov and Avideh Zakhor","Duodepth: Static Gesture Recognition Via Dual Depth Sensors","26th International Conference on Image Processing","2019 IEEE International Conference on Image Processing (ICIP),
  Taipei, Taiwan, 2019, pp. 3467-3471","10.1109/ICIP.2019.8803665",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Static gesture recognition is an effective non-verbal communication channel
between a user and their devices; however many modern methods are sensitive to
the relative pose of the user's hands with respect to the capture device, as
parts of the gesture can become occluded. We present two methodologies for
gesture recognition via synchronized recording from two depth cameras to
alleviate this occlusion problem. One is a more classic approach using
iterative closest point registration to accurately fuse point clouds and a
single PointNet architecture for classification, and the other is a dual
Point-Net architecture for classification without registration. On a manually
collected data-set of 20,100 point clouds we show a 39.2% reduction in
misclassification for the fused point cloud method, and 53.4% for the dual
PointNet, when compared to a standard single camera pipeline.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:41:47 GMT""}]","2020-06-29"
"2006.14692","Mauricio Tapia","Mauricio Tapia, Paolo Persi, Miguel Roth, Davide Elia","An infrared study of the high-mass, multi-stage star-forming region
  IRAS~12272-6240","14 pages, 13 figures, Accepted by MNRAS",,"10.1093/mnras/staa1772",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  IRAS 12272-6240 is a complex star forming region with a compact massive dense
clump and several associated masers, located at a well-determined distance of
$d=9.3$ kpc from the Sun. For this study, we obtained sub-arcsec broad- and
narrow-band near-IR imaging and low-resolution spectroscopy with the
Baade/Magellan telescope and its camera PANIC. Mosaics of size $2 \times 2$
square arcmin in the $JHK_s$ bands and with narrow-band filters centred in the
2.12 $\mu$m H$_2$ and 2.17 $\mu$m Br$\gamma$ lines were analysed in combination
with HI-GAL/{\sl Herschel} and archive IRAC/{\sl Spitzer} and {\sl WISE}
observations. We found that the compact dense clump houses two Class~I YSOs
that probably form a 21 kAU-wide binary system. Its combined 1 to 1200 $\mu$m
SED is consistent with an O9V central star with a $10^{-2} M_\odot$ disc and a
$1.3 \times 10^4 M_\odot$ dust envelope. Its total luminosity is $8.5 \times
10^4 L_\odot$. A series of shocked H$_2$ emission knots are found in its close
vicinity, confirming the presence of outflows. IRAS 12272-6240 is at the centre
of an embedded cluster with a mean age of 1 Myr and 2.6 pc in size that
contains more than 150 stars. At its nucleus, we found a more compact and
considerably younger sub-cluster containing the YSOs. We also identified and
classified the O-type central stars of two dusty radio/IR HII regions flanking
the protostars. Our results confirm that these elements form a single giant
young complex where massive star formation processes started some 1 million
years ago and is still active.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:43:56 GMT""}]","2020-06-29"
"2006.14693","Istvan Fehervari","Istvan Fehervari and Ives Macedo","Adaptive additive classification-based loss for deep metric learning",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent works have shown that deep metric learning algorithms can benefit from
weak supervision from another input modality. This additional modality can be
incorporated directly into the popular triplet-based loss function as
distances. Also recently, classification loss and proxy-based metric learning
have been observed to lead to faster convergence as well as better retrieval
results, all the while without requiring complex and costly sampling
strategies. In this paper we propose an extension to the existing adaptive
margin for classification-based deep metric learning. Our extension introduces
a separate margin for each negative proxy per sample. These margins are
computed during training from precomputed distances of the classes in the other
modality. Our results set a new state-of-the-art on both on the Amazon fashion
retrieval dataset as well as on the public DeepFashion dataset. This was
observed with both fastText- and BERT-based embeddings for the additional
textual modality. Our results were achieved with faster convergence and lower
code complexity than the prior state-of-the-art.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:45:22 GMT""}]","2020-06-29"
"2006.14694","M\'aria Csernoch","M\'aria Csernoch","From webtables to datatables","22 pages, 34 Formulae & 21 Colour Figures","Proceedings of the EuSpRIG 2019 Conference ""Spreadsheet Risk
  Management"", Browns, Covent Garden, London, pp127-148, ISBN:
  978-1-905404-56-8",,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Webtables -- tables and table-like structures on webpages -- are excellent
sources for teaching spreadsheeting, in commercial and professional
organisations by utilizing and developing knowledge-transfer items, presenting
and handling various real-world problems and solutions, discussing and
debugging, and in general, developing and utilizing computational thinking
skills. In the present paper the conversion process of one of the LOL Boards
(League of Legends, Riot Games Inc. 2019) is detailed. After presenting the
algorithm of the conversion, two solutions are offered -- one in a word
processor, the other purely in a spreadsheet application -- leaving space for
discussions, inventing other solutions and combining them.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:49:44 GMT""}]","2020-06-29"
"2006.14695","Henry Liu","Henry Liu","Quasimaps and stable pairs","51 pages, journal version","Forum of Mathematics, Sigma 9 (2021) e32","10.1017/fms.2021.25",,"math.AG hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove an equivalence between the Bryan--Steinberg theory of $\pi$-stable
pairs on $Y = \mathcal{A}_{m-1} \times \mathbb{C}$ and the theory of quasimaps
to $X = \mathrm{Hilb}(\mathcal{A}_{m-1})$, in the form of an equality of
K-theoretic equivariant vertices. In particular, the combinatorics of both
vertices are described explicitly via box counting. Then we apply the
equivalence to study the implications for sheaf-counting theories on $Y$
arising from 3d mirror symmetry for quasimaps to $X$, including the
Donaldson--Thomas crepant resolution conjecture.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:55:40 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 17:17:03 GMT""}]","2021-07-01"
"2006.14696","Jonathan Wahl","Jonathan Wahl","Complex surface singularities with rational homology disk smoothings","27 pages, to be published in Proceedings of the N\'{e}methi60
  Conference",,,,"math.AG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A cyclic quotient singularity of type $p^2/pq-1$ ($0<q<p, (p,q)=1$) has a
smoothing whose Milnor fibre is a $\mathbb Q$HD, or rational homology disk
(i.e., the Milnor number is $0$) ([9], 5.9.1). In the 1980's, we discovered
additional examples of such singularities: three triply-infinite and six
singly-infinite families, all weighted homogeneous. Later work of Stipsicz,
Szab\'{o}, Bhupal, and the author ([7], [1]) proved that these were the only
weighted homogeneous examples. In his UNC PhD thesis (unpublished but available
at [2]), our student Jacob Fowler completed the analytic classification of
these singularities, and counted the number of smoothings in each case, except
for types $\mathcal W$, $\mathcal N$, and $\mathcal M$. In this paper, we
describe his results, and settle these remaining cases; there is a unique
$\mathbb Q$HD smoothing component except in the cases of an obvious symmetry of
the resolution dual graph. The method involves study of configurations of
rational curves on projective rational surfaces.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:58:59 GMT""}]","2020-06-29"
"2006.14697","Kai Liu","MacCallum Robertson, Christopher J. Agostino, Gong Chen, Sang Pyo
  Kang, Arantzazu Mascaraque, Enrique Garcia Michel, Changyeon Won, Yizheng Wu,
  Andreas K. Schmid, and Kai Liu","In-plane N\'eel wall chirality and orientation of interfacial
  Dzyaloshinskii-Moriya vector in magnetic films","19 pages, 5 figures","Phys. Rev. B 102, 024417 (2020)","10.1103/PhysRevB.102.024417",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interfacial Dzyaloshinskii-Moriya interaction (DMI) is of great interest
as it can stabilize chiral spin structures in thin films. Experiments verifying
the orientation of the interfacial DMI vector remain rare, in part due to the
difficulty of separating vector components of DMI. In this study, Fe/Ni
bilayers and Co/Ni multilayers were deposited epitaxially onto Cu(001) and
Pt(111) substrates, respectively. By tailoring the effective anisotropy, spin
reorientation transitions (SRTs) are employed to probe the orientation of the
DMI vector by measuring the spin structure of domain walls on both sides of the
SRTs. The interfacial DMI is found to be sufficiently strong to stabilize
chiral N\'eel walls in the out-of-plane magnetized regimes, while achiral
N\'eel walls are observed in the in-plane magnetized regimes. These findings
experimentally confirm that the out-of-plane component of the DMI vector is
insignificant in these fcc(001) and fcc(111) oriented interfaces, even in the
presence of atomic steps.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:00:26 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 18:05:31 GMT""}]","2020-07-16"
"2006.14699","Saypraseuth Mounsaveng","Saypraseuth Mounsaveng, Issam Laradji, Ismail Ben Ayed, David Vazquez,
  Marco Pedersoli","Learning Data Augmentation with Online Bilevel Optimization for Image
  Classification",,,,,"cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data augmentation is a key practice in machine learning for improving
generalization performance. However, finding the best data augmentation
hyperparameters requires domain knowledge or a computationally demanding
search. We address this issue by proposing an efficient approach to
automatically train a network that learns an effective distribution of
transformations to improve its generalization. Using bilevel optimization, we
directly optimize the data augmentation parameters using a validation set. This
framework can be used as a general solution to learn the optimal data
augmentation jointly with an end task model like a classifier. Results show
that our joint training method produces an image classification accuracy that
is comparable to or better than carefully hand-crafted data augmentation. Yet,
it does not need an expensive external validation loop on the data augmentation
hyperparameters.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:01:52 GMT""},{""version"":""v2"",""created"":""Tue, 10 Nov 2020 16:11:57 GMT""}]","2020-11-11"
"2006.14701","William H. Jaco","Birch Bryant, William Jaco and J. Hyam Rubinstein","Efficient triangulations and boundary slopes","21 pages, 6 figures; revised and improved version of an earlier paper
  arXiv:1108.2936, Annular efficient triangulations of 3-manifolds",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a compact, irreducible, $\partial$-irreducible, an-annular bounded
3-manifold $M\ne\mathbb{B}^3$, then any triangulation $\mathcal{T}$ of $M$ can
be modified to an ideal triangulation $\mathcal{T}^*$ of $\stackrel{\circ}{M}$.
We use the inverse relationship of crushing a triangulation along a normal
surface and that of inflating an ideal triangulation to introduce and study
boundary-efficient triangulations and end-efficient ideal triangulations. We
prove that the topological conditions necessary for a compact 3-manifold $M$
admitting an annular-efficient triangulation are sufficient to modify any
triangulation of $M$ to a boundary-efficient triangulation which is also
annular-efficient. From the proof we have for any ideal triangulation $T^*$ and
any inflation $\mathcal{T}_{\Lambda}$, there is a bijective correspondence
between the closed normal surfaces in $\mathcal{T}^*$ and the closed normal
surfaces in $\mathcal{T}_{\Lambda}$ with corresponding normal surfaces being
homeomorphic. It follows that for an ideal triangulation $\mathcal{T}^*$ that
is $0$-efficient, $1$-efficient, or end-efficient, then any inflation
$\mathcal{T}_{\Lambda}$ of $\mathcal{T}^*$ is $0$-efficient, $1$-efficient, or
$\partial$-efficient, respectively. There are algorithms to decide if a given
triangulation or ideal triangulation of a $3$-manifold is one of these
efficient triangulations. Finally, it is shown that for an annular-efficient
triangulation, there are only a finite number of boundary slopes for normal
surfaces of a bounded Euler characteristic; hence, in a compact, orientable,
irreducible, $\partial$-irreducible, and an-annular $3$-manifold, there are
only finitely many boundary slopes for incompressible and
$\partial$-incompressible surfaces of a bounded Euler characteristic.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:06:52 GMT""}]","2020-06-29"
"2006.14702","Hongxu Yang","Hongxu Yang, Caifeng Shan, Alexander F. Kolen, Peter H. N. de With","Deep Q-Network-Driven Catheter Segmentation in 3D US by Hybrid
  Constrained Semi-Supervised Learning and Dual-UNet","Accepted by MICCAI 2020",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Catheter segmentation in 3D ultrasound is important for computer-assisted
cardiac intervention. However, a large amount of labeled images are required to
train a successful deep convolutional neural network (CNN) to segment the
catheter, which is expensive and time-consuming. In this paper, we propose a
novel catheter segmentation approach, which requests fewer annotations than the
supervised learning method, but nevertheless achieves better performance. Our
scheme considers a deep Q learning as the pre-localization step, which avoids
voxel-level annotation and which can efficiently localize the target catheter.
With the detected catheter, patch-based Dual-UNet is applied to segment the
catheter in 3D volumetric data. To train the Dual-UNet with limited labeled
images and leverage information of unlabeled images, we propose a novel
semi-supervised scheme, which exploits unlabeled images based on hybrid
constraints from predictions. Experiments show the proposed scheme achieves a
higher performance than state-of-the-art semi-supervised methods, while it
demonstrates that our method is able to learn from large-scale unlabeled
images.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:10:04 GMT""}]","2020-06-29"
"2006.14703","Bryan Gillis","Bryan R. Gillis, Tim Schrabback, Ole Marggraf, Rachel Mandelbaum,
  Richard Massey, Jason Rhodes, Andy Taylor","Validation of PSF Models for HST and Other Space-Based Observations","26 pages, 12 figures, code included. Accepted for publication by
  MNRAS",,"10.1093/mnras/staa1818","Monthly Notices of the Royal Astronomical Society, 0035-8711,
  staa1818","astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Forthcoming space-based observations will require high-quality point-spread
function (PSF) models for weak gravitational lensing measurements. One approach
to generating these models is using a wavefront model based on the known
telescope optics. We present an empirical framework for validating such models
to confirm that they match the actual PSF to within requirements by comparing
the models to the observed light distributions of isolated stars. We apply this
framework to Tiny Tim, the standard tool for generating model PSFs for the
Hubble Space Telescope (HST), testing its models against images taken by HST's
Advanced Camera for Surveys in the Wide Field Channel. We show that Tiny Tim's
models, in the default configuration, differ significantly from the observed
PSFs, most notably in their sizes. We find that the quality of Tiny Tim PSFs
can be improved through fitting the full set of Zernike polynomial coefficients
which characterise the optics, to the point where the practical significance of
the difference between model and observed PSFs is negligible for most use
cases, resulting in additive and multiplicative biases both of order
approximately 4e-4. We also show that most of this improvement can be retained
through using an updated set of Zernike coefficients, which we provide.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:12:22 GMT""}]","2020-06-29"
"2006.14704","Norton G. de Almeida Dr.","Rog\'erio J. de Assis, Jos\'e S. Sales, Jefferson A. R. da Cunha, and
  Norton G. de Almeida","Universal two-level quantum Otto machine under a squeezed reservoir",,,"10.1103/PhysRevE.102.052131",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study an Otto heat machine whose working substance is a single two-level
system interacting with a cold thermal reservoir and with a squeezed hot
thermal reservoir. By adjusting the squeezing or the adiabaticity parameter
(the probability of transition) we show that our two-level system can function
as a universal heat machine, either producing net work by consuming heat or
consuming work that is used to cool or heat environments. Using our model we
study the performance of these machine in the finite-time regime of the
isentropic strokes, which is a regime that contributes to make them useful from
a practical point of view.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:14:56 GMT""}]","2020-12-30"
"2006.14705","Kaiqiang Lin","Kai-Qiang Lin, Chin Shen Ong, Sebastian Bange, Paulo E. Faria Junior,
  Bo Peng, Jonas D. Ziegler, Jonas Zipfel, Christian B\""auml, Nicola Paradiso,
  Kenji Watanabe, Takashi Taniguchi, Christoph Strunk, Bartomeu Monserrat,
  Jaroslav Fabian, Alexey Chernikov, Diana Y. Qiu, Steven G. Louie, John M.
  Lupton","Bright excitons with negative-mass electrons",,"Nature Communications 12, 5500 (2021)","10.1038/s41467-021-25499-2",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bound electron-hole excitonic states are generally not expected to form with
charges of negative effective mass. We identify such excitons in a single layer
of the semiconductor WSe2, where they give rise to narrow-band upconverted
photoluminescence in the UV, at an energy of 1.66 eV above the first band-edge
excitonic transition. Negative band curvature and strong electron-phonon
coupling result in a cascaded phonon progression with equidistant peaks in the
photoluminescence spectrum, resolvable to ninth order. Ab initio GW-BSE
calculations with full electron-hole correlations unmask and explain the
admixture of upper conduction-band states to this complex many-body excitation:
an optically bright, bound exciton in resonance with the semiconductor
continuum. This exciton is responsible for atomic-like quantum-interference
phenomena such as electromagnetically induced transparency. Since band
curvature can be tuned by pressure or strain, synthesis of exotic
quasiparticles such as flat-band excitons with infinite reduced mass becomes
feasible.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:17:16 GMT""}]","2021-09-20"
"2006.14706","Peter Bartholomew","Peter Bartholomew","Will Dynamic Arrays finally change the way Models are built?","11 Pages, 5 Figures, Numerous Spreadsheet Formulae","Proceedings of the EuSpRIG 2019 Conference ""Spreadsheet Risk
  Management"", Browns, Covent Garden, London, pp149-160, ISBN:
  978-1-905404-56-8",,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spreadsheets offer a supremely successful and intuitive means of processing
and exchanging numerical content. Its intuitive ad-hoc nature makes it hugely
popular for use in diverse areas including business and engineering, yet these
very same characteristics make it extraordinarily error-prone; many would
question whether it is suitable for serious analysis or modelling tasks. A
previous EuSpRIG paper examined the role of Names in increasing solution
transparency and providing a readable notation to forge links with the problem
domain. Extensive use was made of CSE array formulas, but it is acknowledged
that their use makes spreadsheet development a distinctly cumbersome task.
Since that time, the new dynamic arrays have been introduced and array
calculation is now the default mode of operation for Excel. This paper examines
the thesis that their adoption within a more professional development
environment could replace traditional techniques where solution integrity is
important. A major advantage of fully dynamic models is that they require less
manual intervention to keep them updated and so have the potential to reduce
the attendant errors and risk.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:18:41 GMT""}]","2020-06-29"
"2006.14707","Semih Cant\""urk","Semih Cant\""urk, Aman Singh, Patrick St-Amant, Jason Behrmann","Machine-Learning Driven Drug Repurposing for COVID-19","Submitted to NeurIPS 2020. 11 pages, 3 figures, 5 tables, 12 pages of
  appendices",,,,"cs.LG q-bio.QM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The integration of machine learning methods into bioinformatics provides
particular benefits in identifying how therapeutics effective in one context
might have utility in an unknown clinical context or against a novel pathology.
We aim to discover the underlying associations between viral proteins and
antiviral therapeutics that are effective against them by employing neural
network models. Using the National Center for Biotechnology Information virus
protein database and the DrugVirus database, which provides a comprehensive
report of broad-spectrum antiviral agents (BSAAs) and viruses they inhibit, we
trained ANN models with virus protein sequences as inputs and antiviral agents
deemed safe-in-humans as outputs. Model training excluded SARS-CoV-2 proteins
and included only Phases II, III, IV and Approved level drugs. Using sequences
for SARS-CoV-2 (the coronavirus that causes COVID-19) as inputs to the trained
models produces outputs of tentative safe-in-human antiviral candidates for
treating COVID-19. Our results suggest multiple drug candidates, some of which
complement recent findings from noteworthy clinical studies. Our in-silico
approach to drug repurposing has promise in identifying new drug candidates and
treatments for other viruses.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:18:53 GMT""}]","2020-06-29"
"2006.14708","Jiayuan Mao","Yikai Li, Jiayuan Mao, Xiuming Zhang, William T. Freeman, Joshua B.
  Tenenbaum, Jiajun Wu","Perspective Plane Program Induction from a Single Image","CVPR 2020. First two authors contributed equally. Project page:
  http://p3i.csail.mit.edu/",,,,"cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the inverse graphics problem of inferring a holistic representation
for natural images. Given an input image, our goal is to induce a
neuro-symbolic, program-like representation that jointly models camera poses,
object locations, and global scene structures. Such high-level, holistic scene
representations further facilitate low-level image manipulation tasks such as
inpainting. We formulate this problem as jointly finding the camera pose and
scene structure that best describe the input image. The benefits of such joint
inference are two-fold: scene regularity serves as a new cue for perspective
correction, and in turn, correct perspective correction leads to a simplified
scene structure, similar to how the correct shape leads to the most regular
texture in shape from texture. Our proposed framework, Perspective Plane
Program Induction (P3I), combines search-based and gradient-based algorithms to
efficiently solve the problem. P3I outperforms a set of baselines on a
collection of Internet images, across tasks including camera pose estimation,
global structure inference, and down-stream image manipulation tasks.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:18:58 GMT""}]","2020-06-29"
"2006.14709","Sebastian Goldt","Sebastian Goldt, Bruno Loureiro, Galen Reeves, Florent Krzakala, Marc
  M\'ezard, Lenka Zdeborov\'a","The Gaussian equivalence of generative models for learning with shallow
  neural networks","The accompanying code for this paper is available at
  https://github.com/sgoldt/gaussian-equiv-2layer","Proceedings of the 2nd Mathematical and Scientific Machine
  Learning Conference, PMLR 145:426-471 (2021)",,,"stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the impact of data structure on the computational tractability
of learning is a key challenge for the theory of neural networks. Many
theoretical works do not explicitly model training data, or assume that inputs
are drawn component-wise independently from some simple probability
distribution. Here, we go beyond this simple paradigm by studying the
performance of neural networks trained on data drawn from pre-trained
generative models. This is possible due to a Gaussian equivalence stating that
the key metrics of interest, such as the training and test errors, can be fully
captured by an appropriately chosen Gaussian model. We provide three strands of
rigorous, analytical and numerical evidence corroborating this equivalence.
First, we establish rigorous conditions for the Gaussian equivalence to hold in
the case of single-layer generative models, as well as deterministic rates for
convergence in distribution. Second, we leverage this equivalence to derive a
closed set of equations describing the generalisation performance of two widely
studied machine learning problems: two-layer neural networks trained using
one-pass stochastic gradient descent, and full-batch pre-learned features or
kernel methods. Finally, we perform experiments demonstrating how our theory
applies to deep, pre-trained generative models. These results open a viable
path to the theoretical study of machine learning models with realistic data.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:20:09 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 09:56:34 GMT""},{""version"":""v3"",""created"":""Fri, 21 May 2021 13:21:00 GMT""}]","2022-05-23"
"2006.14710","XiaoLin Kang","D. Babusci, M. Berlowski, C. Bloise, F. Bossi, P. Branchini, A.
  Budano, B. Cao, F. Ceradini, P. Ciambrone, F. Curciarello, E. Czerwi\'nski,
  G. D'Agostini, E. Dan\`e, V. De Leo, E. De Lucia, A. De Santis, P. De Simone,
  A. Di Cicco, A. Di Domenico, D. Domenici, A. D'Uffizi, A. Fantini, P.
  Fermani, S. Fiore, A. Gajos, P. Gauzzi, S. Giovannella, E. Graziani, V. L.
  Ivanov, T. Johansson, X. Kang, D. Kisielewska-Kami\'nska, E. A. Kozyrev, W.
  Krzemien, A. Kupsc, P. A. Lukin, G. Mandaglio, M. Martini, R. Messi, S.
  Miscetti, D. Moricciani, P. Moskal, S. Parzych, A. Passeri, V. Patera, E.
  Perez del Rio, P. Santangelo, M. Schioppa, A. Selce, M. Silarski, F. Sirghi,
  E. P. Solodov, L. Tortora, G. Venanzoni, W. Wi\'slicki, M. Wolke","Upper limit on the $\eta\to\pi^{+}\pi^{-}$ branching fraction with the
  KLOE experiment","11 pages, 3 figures","J. High Energ. Phys. 2020, 47 (2020)","10.1007/JHEP10(2020)047",,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on an integrated luminosity of 1.61 fb$^{-1}$ $e^+e^-$ collision data
collected with the KLOE detector at DA$\Phi$NE, the Frascati $\phi$-factory, a
search for the $P$- and $CP$-violating decay $\eta\to\pi^{+}\pi^{-}$ has been
performed. Radiative $\phi\to\eta\gamma$ decay is exploited to access the
$\eta$ mesons. No signal is observed in the $\pi^{+}\pi^{-}$ invariant mass
spectrum, and the upper limit on the branching fraction at 90\% confidence
level is determined to be ${\mathcal
B}(\eta\to\pi^{+}\pi^{-})<4.9\times10^{-6}$, which is approximately three times
smaller than the previous KLOE result. From the combination of these two
measurements we get ${\mathcal B}(\eta\to\pi^{+}\pi^{-}) < 4.4\times10^{-6}$ at
90\% confidence level.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:21:23 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 04:04:16 GMT""}]","2021-03-02"
"2006.14711","Gabriel Leit\~ao","Gabriel Leit\~ao, Juan Colonna, Edwin Monteiro, Elaine Oliveira,
  Raimundo Barreto","New Metrics for Learning Evaluation in Digital Education Platforms","12 pages, 6 figures, 12 tables",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Technology applied in education can provide great benefits and overcome
challenges by facilitating access to learning objects anywhere and anytime.
However, technology alone is not enough, since it requires suitable planning
and learning methodologies. Using technology can be problematic, especially in
determining whether learning has occurred or not. Futhermore, if learning has
not occured, technology can make it difficult to determine how to mitigate this
lack of learning. This paper presents a set of new metrics for measuring
student's acquired understanding of a content in technology-based education
platforms. Some metrics were taken from the literature ""as is"", some were
modified slighty, while others were added. The hypothesis is that we should not
only focus on traditional scoring, because it only counts the number of
hits/errors and does not consider any other aspect of learning. We applied all
metrics to an assessment conducted in a high school class in which we show
specific cases, along with metrics, where very useful information can be
obtained from by combining several metrics. We conclude that the proposed
metrics are promising for measuring student's acquired understanding of a
content, as well as for teachers to measure student's weaknesses.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:25:44 GMT""},{""version"":""v2"",""created"":""Thu, 22 Sep 2022 18:54:54 GMT""}]","2022-09-26"
"2006.14712","Amy Glazier","Amy L. Glazier, Ward S. Howard, Hank Corbett, Nicholas M. Law, Jeffrey
  K. Ratzloff, Octavi Fors, and Daniel del Ser","Evryscope and K2 Constraints on TRAPPIST-1 Superflare Occurrence and
  Planetary Habitability","12 pages, 9 figures. Accepted to The Astrophysical Journal, in press",,"10.3847/1538-4357/aba4a6",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nearby ultracool dwarf TRAPPIST-1 possesses several Earth-sized
terrestrial planets, three of which have equilibrium temperatures that may
support liquid surface water, making it a compelling target for exoplanet
characterization. TRAPPIST-1 is an active star with frequent flaring, with
implications for the habitability of its planets. Superflares (stellar flares
whose energy exceeds 10^33 erg) can completely destroy the atmospheres of a
cool star's planets, allowing ultraviolet radiation and high-energy particles
to bombard their surfaces. However, ultracool dwarfs emit little ultraviolet
flux when quiescent, raising the possibility of frequent flares being necessary
for prebiotic chemistry that requires ultraviolet light. We combine Evryscope
and Kepler observations to characterize the high-energy flare rate of
TRAPPIST-1. The Evryscope is an array of 22 small telescopes imaging the entire
Southern sky in g' every two minutes. Evryscope observations, spanning 170
nights over 2 years, complement the 80-day continuous short-cadence K2
observations by sampling TRAPPIST-1's long-term flare activity. We update
TRAPPIST-1's superflare rate, finding a cumulative rate of 4.2 (+1.9 -0.2)
superflares per year. We calculate the flare rate necessary to deplete ozone in
the habitable-zone planets' atmospheres, and find that TRAPPIST-1's flare rate
is insufficient to deplete ozone if present on its planets. In addition, we
calculate the flare rate needed to provide enough ultraviolet flux to power
prebiotic chemistry. We find TRAPPIST-1's flare rate is likely insufficient to
catalyze some of the Earthlike chemical pathways thought to lead to RNA
synthesis, and flux due to flares in the biologically relevant UV-B band is
orders of magnitude less for any TRAPPIST-1 planet than has been experienced by
Earth at any time in its history.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:31:28 GMT""},{""version"":""v2"",""created"":""Mon, 17 Aug 2020 18:58:24 GMT""}]","2020-09-02"
"2006.14713","Guoqing Chang","Daniel S. Sanchez, Guoqing Chang, Ilya Belopolski, Hong Lu, Jia-Xin
  Yin, Nasser Alidoust, Xitong Xu, Tyler A. Cochran, Xiao Zhang, Yi Bian,
  Songtian S. Zhang, Yi-Yuan Liu, Jie Ma, Guang Bian, Hsin Lin, Su-Yang Xu,
  Shuang Jia, and M. Zahid Hasan","Observation of Weyl fermions in a magnetic non-centrosymmetric crystal","To appear in Nature Communications (2020)","Nature Communications 11, 3356 (2020)","10.1038/s41467-020-16879-1",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Characterized by the absence of inversion symmetry, non-centrosymmetric
materials are of great interest because they exhibit ferroelectricity, second
harmonic generation, emergent Weyl fermions, and other fascinating phenomena.
It is expected that if time-reversal symmetry is also broken, additional
magneto-electric effects can emerge from the interplay between magnetism and
electronic order. Here we report topological conducting properties in the
non-centrosymmetric magnet PrAlGe. By photoemission spectroscopy, we observe an
arc parametrizing surface-localized states---a topological arc. Using the
bulk-boundary correspondence, we conclude that these arcs correspond to
projected topological charges of $\pm{1}$ in the surface Brillouin zone,
demonstrating the presence of magnetic Weyl quasiparticles in bulk. We further
observe a large anomalous Hall response, arising from diverging bulk Berry
curvature fields associated with the magnetic Weyl band structure. Our results
demonstrate a topological phase with robust electronic surface states and
anomalous transport in a non-centrosymmetric magnet for the first time,
providing a novel material platform to study the interplay between magnetic
order, band topology and transport.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:39:19 GMT""}]","2020-07-06"
"2006.14714","Valerie Jacobson","Valerie Jacobson, Dave Diercks, Bobby To, Andriy Zakutayev, Geoff
  Brennecka","Thin Film Growth Effects on Electrical Conductivity in Entropy
  Stabilized Oxides",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entropy stabilization has garnered significant attention as a new approach to
designing novel materials. Much of the work in this area has focused on bulk
ceramic processing, leaving entropy-stabilized thin films relatively
underexplored. Following an extensive multi-variable investigation of
polycrystalline (Mg$_{0.2}$Co$_{0.2}$Ni$_{0.2}$Cu$_{0.2}$Zn$_{0.2}$)O thin
films deposited via pulsed laser deposition (PLD), it is shown here that
substrate temperature and deposition pressure have strong and repeatable
effects on film texture and lattice parameter. Further analysis shows that
films deposited at lower temperatures and under lower oxygen chamber pressure
are $\sim$40x more electrically conductive than otherwise identical films grown
at higher temperature and pressure. This electronic conductivity is
hypothesized to be the result of polaron hopping mediated by transition metal
valence changes which compensate for oxygen off-stoichiometry.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:42:20 GMT""}]","2020-06-29"
"2006.14715","Amirreza Mahbod","Amirreza Mahbod, Gerald Schaefer, Chunliang Wang, Rupert Ecker, Georg
  Dorffner, Isabella Ellinger","Investigating and Exploiting Image Resolution for Transfer
  Learning-based Skin Lesion Classification","Accepted for the 25th International Conference on Pattern Recognition
  (ICPR 2020)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Skin cancer is among the most common cancer types. Dermoscopic image analysis
improves the diagnostic accuracy for detection of malignant melanoma and other
pigmented skin lesions when compared to unaided visual inspection. Hence,
computer-based methods to support medical experts in the diagnostic procedure
are of great interest. Fine-tuning pre-trained convolutional neural networks
(CNNs) has been shown to work well for skin lesion classification. Pre-trained
CNNs are usually trained with natural images of a fixed image size which is
typically significantly smaller than captured skin lesion images and
consequently dermoscopic images are downsampled for fine-tuning. However,
useful medical information may be lost during this transformation. In this
paper, we explore the effect of input image size on skin lesion classification
performance of fine-tuned CNNs. For this, we resize dermoscopic images to
different resolutions, ranging from 64x64 to 768x768 pixels and investigate the
resulting classification performance of three well-established CNNs, namely
DenseNet-121, ResNet-18, and ResNet-50. Our results show that using very small
images (of size 64x64 pixels) degrades the classification performance, while
images of size 128x128 pixels and above support good performance with larger
image sizes leading to slightly improved classification. We further propose a
novel fusion approach based on a three-level ensemble strategy that exploits
multiple fine-tuned networks trained with dermoscopic images at various sizes.
When applied on the ISIC 2017 skin lesion classification challenge, our fusion
approach yields an area under the receiver operating characteristic curve of
89.2% and 96.6% for melanoma classification and seborrheic keratosis
classification, respectively, outperforming state-of-the-art algorithms.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:51:24 GMT""}]","2020-06-29"
"2006.14716","Madeline Locus Dawsey","Madeline Locus Dawsey and Dermot McCarthy","Generalized Paley graphs and their complete subgraphs of orders three
  and four",,"Res. Math. Sci. 8: 18 (2021)",,,"math.NT math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $k \geq 2$ be an integer. Let $q$ be a prime power such that $q \equiv 1
\pmod {k}$ if $q$ is even, or, $q \equiv 1 \pmod {2k}$ if $q$ is odd. The
generalized Paley graph of order $q$, $G_k(q)$, is the graph with vertex set
$\mathbb{F}_q$ where $ab$ is an edge if and only if ${a-b}$ is a $k$-th power
residue. We provide a formula, in terms of finite field hypergeometric
functions, for the number of complete subgraphs of order four contained in
$G_k(q)$, $\mathcal{K}_4(G_k(q))$, which holds for all $k$. This generalizes
the results of Evans, Pulham and Sheehan on the original ($k$=2) Paley graph.
We also provide a formula, in terms of Jacobi sums, for the number of complete
subgraphs of order three contained in $G_k(q)$, $\mathcal{K}_3(G_k(q))$. In
both cases we give explicit determinations of these formulae for small $k$. We
show that zero values of $\mathcal{K}_4(G_k(q))$ (resp.
$\mathcal{K}_3(G_k(q))$) yield lower bounds for the multicolor diagonal Ramsey
numbers $R_k(4)=R(4,4,\cdots,4)$ (resp. $R_k(3)$). We state explicitly these
lower bounds for small $k$ and compare to known bounds. We also examine the
relationship between both $\mathcal{K}_4(G_k(q))$ and $\mathcal{K}_3(G_k(q))$,
when $q$ is prime, and Fourier coefficients of modular forms.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:13:43 GMT""}]","2022-06-22"
"2006.14717","Alessandro De Stefani","Giulio Caviglia, Alessandro De Stefani","A Cayley-Bacharach theorem for points in $\mathbb{P}^n$","12 pages, 1 figure. Minor modifications, citations added,
  acknowledged a result which was known in the literature",,"10.1112/blms.12492",,"math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a Cayley-Bacharach-type theorem for points in projective space
$\mathbb{P}^n$ that lie on a complete intersection of $n$ hypersurfaces. This
is made possible by new bounds on the growth of the Hilbert function of almost
complete intersections.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:17:00 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 14:16:22 GMT""}]","2021-09-17"
"2006.14718","Ramina Ghods","Ramina Ghods, Arundhati Banerjee, Jeff Schneider","Asynchronous Multi Agent Active Search","Preprint under review",,,,"cs.LG cs.RO eess.SP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active search refers to the problem of efficiently locating targets in an
unknown environment by actively making data-collection decisions, and has many
applications including detecting gas leaks, radiation sources or human
survivors of disasters using aerial and/or ground robots (agents). Existing
active search methods are in general only amenable to a single agent, or if
they extend to multi agent they require a central control system to coordinate
the actions of all agents. However, such control systems are often impractical
in robotics applications. In this paper, we propose two distinct active search
algorithms called SPATS (Sparse Parallel Asynchronous Thompson Sampling) and
LATSI (LAplace Thompson Sampling with Information gain) that allow for multiple
agents to independently make data-collection decisions without a central
coordinator. Throughout we consider that targets are sparsely located around
the environment in keeping with compressive sensing assumptions and its
applicability in real world scenarios. Additionally, while most common search
algorithms assume that agents can sense the entire environment (e.g.
compressive sensing) or sense point-wise (e.g. Bayesian Optimization) at all
times, we make a realistic assumption that each agent can only sense a
contiguous region of space at a time. We provide simulation results as well as
theoretical analysis to demonstrate the efficacy of our proposed algorithms.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:17:20 GMT""}]","2020-06-29"
"2006.14719","Michael Walker","Michael R. Walker II and Joseph A. O'Sullivan","Iterative Algorithms for Joint Scatter and Attenuation Estimation From
  Broken Ray Transform Data","13 pages, 5 figures",,"10.1109/TCI.2021.3066798",,"eess.IV eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The single-scatter approximation is fundamental in many tomographic imaging
problems including x-ray scatter imaging and optical scatter imaging for
certain media. In all cases, noisy measurements are affected by both local
scatter events and nonlocal attenuation. Prior works focus on reconstructing
one of two images: scatter density or total attenuation. However, both images
are media specific and useful for object identification.
  Nonlocal effects of the attenuation image on the data are summarized by the
broken ray transform (BRT). While analytic inversion formulas exist, poor
conditioning of the inverse problem is only exacerbated by noisy measurements
and sampling errors. This has motivated interest in the related star transforms
incorporating BRT measurements from multiple source-detector pairs. However,
all analytic methods operate on the log of the data. For media comprising
regions with no scatter a new approach is required.
  We are the first to present a joint estimation algorithm based on Poisson
data models for a single-scatter measurement geometry. Monotonic reduction of
the log-likelihood function is guaranteed for our iterative algorithm while
alternating image updates. We also present a fast algorithm for computing the
discrete BRT forward operator. Our generalized approach can incorporate both
transmission and scatter measurements from multiple source-detector pairs.
Transmission measurements resolve low-frequency ambiguity in the joint image
estimation problem, while multiple scatter measurements resolve the attenuation
image. The benefits of joint estimation, over single-image estimation, vary
with problem scaling. Our results quantify these benefits and should inform
design of future acquisition systems.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:20:18 GMT""},{""version"":""v2"",""created"":""Tue, 20 Apr 2021 02:19:54 GMT""}]","2021-04-21"
"2006.14720","Juan Galvis","J. Galvis and H. M. Versieux","A porous media fracture model based on homogenization theory",,,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A novel regularized fracture model for crack propagation in porous media is
proposed. Our model is obtained through homogenization theory and formal
asymptotic expansions. We start with a regularized quasi-static fracture model
posed in a periodically perforated domain obtained by periodic extension of a
re-scaled unit cell with a hole. This setup allows us to write two separated
minimality conditions for the primary (displacement) and secondary variables
plus a balance of energy relation. Then we apply the usual asymptotic expansion
matching to deduce limit relations when the re-scaling parameter of the unit
cells vanishes. By introducing cell problems solutions and a homogenized tensor
we can recast the obtained relations into a novel model for crack propagation
in porous media. The proposed model can be interpreted as a regularized
quasi-static fracture model for porous media. This model yields two separated
(homogenized) minimality conditions for the primary and secondary variables and
a balance of homogenized energy relation.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:27:29 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 18:47:46 GMT""}]","2021-10-07"
"2006.14721","Savin Shynu Varghese","S. S. Varghese, K. S. Obenberger, G. B. Taylor and J. Dowell","Testing the Radiation Pattern of Meteor Radio Afterglow","17 pages, 8 figures",,"10.1029/2019JA026922",,"astro-ph.EP astro-ph.IM physics.plasm-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radio emission from meteors or meteor radio afterglows (MRAs) were first
detected using the all-sky imaging capabilities of the first station of the
Long Wavelength Array (LWA1). In this work, we use the recently commissioned
LWA Sevilleta (LWA-SV) station along with the LWA1 to carry out co-ordinated
observations. The combined all-sky observations with LWA1 and LWA-SV have
co-observed 32 MRAs and 21 transmitter reflections from meteors (meteor scatter
events) which are believed to be specular reflections from overdense trails.
The flux density of the events observed by each station were measured from the
all-sky images. Triangulating the angular direction of events from each station
gave the physical location and the distance of the event to each station. The
luminosity of the events in each station were calculated using the flux
distance relation for an isotropic source. The luminosity distribution for MRAs
and meteor scatter events observed by each station shows a clear distinction
between these two types of events as the ratio of luminosities are closer to
unity for MRAs than the meteor scatter events. Furthermore, we find that MRAs
follow an isotropic radiation pattern. This suggests, either a complete
incoherent emission mechanism or an incoherent addition of coherently emitting
small regions within the meteor trail.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:28:12 GMT""}]","2020-06-29"
"2006.14722","Satyam Mohla Mr.","Satyam Mohla, Anshul Nasery and Biplab Banerjee","Teaching CNNs to mimic Human Visual Cognitive Process & regularise
  Texture-Shape bias","Submitted at ICASSP 2022; 5 Pages; LaTex;",,,,"cs.CV cs.AI cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experiments in computer vision demonstrate texture bias as the primary
reason for supreme results in models employing Convolutional Neural Networks
(CNNs), conflicting with early works claiming that these networks identify
objects using shape. It is believed that the cost function forces the CNN to
take a greedy approach and develop a proclivity for local information like
texture to increase accuracy, thus failing to explore any global statistics. We
propose CognitiveCNN, a new intuitive architecture, inspired from feature
integration theory in psychology to utilise human interpretable feature like
shape, texture, edges etc. to reconstruct, and classify the image. We define
novel metrics to quantify the ""relevance"" of ""abstract information"" present in
these modalities using attention maps. We further introduce a regularisation
method which ensures that each modality like shape, texture etc. gets
proportionate influence in a given task, as it does for reconstruction; and
perform experiments to show the resulting boost in accuracy and robustness,
besides imparting explainability to these CNNs for achieving superior
performance in object recognition.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:32:54 GMT""},{""version"":""v2"",""created"":""Mon, 10 Jan 2022 00:43:26 GMT""}]","2022-01-11"
"2006.14723","Yoshikazu Yamagishi","Yoshikazu Yamagishi, Takamichi Sushida, Jean-Fran\c{c}ois Sadoc","Area convergence of Voronoi cells on spiral lattices","11 figures",,"10.1088/1361-6544/abe733",,"math.DS math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that the area of Voronoi cells for a generalized Archimedean
spiral lattice converges under some scale normalization, if the angle parameter
is badly approximable.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:49:04 GMT""}]","2021-07-07"
"2006.14724","Johann Haber","Johann Haber, Andreas Kaldun, Samuel W. Teitelbaum, Alfred Q.R. Baron,
  Philip H. Bucksbaum, Matthias Fuchs, Jerome B. Hastings, Ichiro Inoue, Yuichi
  Inubushi, Dietrich Krebs, Taito Osaka, Robin Santra, Sharon Shwartz, Kenji
  Tamasaku, David A. Reis","Nonlinear resonant X-ray Raman scattering","6 pages, 4 figures",,,,"physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the observation of a novel nonlinear effect in the hard x-ray
range. Upon illuminating Fe and Cu metal foils with intense x-ray pulses tuned
near their respective K edges, photons at nearly twice the incoming photon
energy are emitted. The signal rises quadratically with the incoming intensity,
consistent with two-photon excitation. The spectrum of emitted high-energy
photons comprises multiple Raman lines that disperse with the incident photon
energy. Upon reaching the double K-shell ionization threshold, the signal
strength undergoes a marked rise. Above this threshold, the lines cease
dispersing, turning into orescence lines with energies much greater than
obtainable by single electron transitions, and additional Raman lines appear.
We attribute these processes to electron-correlation mediated multielectron
transitions involving double-core hole excitation and various two-electron
de-excitation processes to a final state involving one or more L and M
core-holes.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:50:24 GMT""}]","2020-06-29"
"2006.14725","Romit Maulik","Romit Maulik, Bethany Lusch, Prasanna Balaprakash","Non-autoregressive time-series methods for stable parametric
  reduced-order models",,,,,"physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advection-dominated dynamical systems, characterized by partial differential
equations, are found in applications ranging from weather forecasting to
engineering design where accuracy and robustness are crucial. There has been
significant interest in the use of techniques borrowed from machine learning to
reduce the computational expense and/or improve the accuracy of predictions for
these systems. These rely on the identification of a basis that reduces the
dimensionality of the problem and the subsequent use of time series and
sequential learning methods to forecast the evolution of the reduced state.
Often, however, machine-learned predictions after reduced-basis projection are
plagued by issues of stability stemming from incomplete capture of multiscale
processes as well as due to error growth for long forecast durations. To
address these issues, we have developed a \emph{non-autoregressive} time series
approach for predicting linear reduced-basis time histories of forward models.
In particular, we demonstrate that non-autoregressive counterparts of
sequential learning methods such as long short-term memory (LSTM) considerably
improve the stability of machine-learned reduced-order models. We evaluate our
approach on the inviscid shallow water equations and show that a
non-autoregressive variant of the standard LSTM approach that is bidirectional
in the PCA components obtains the best accuracy for recreating the nonlinear
dynamics of partial observations. Moreover---and critical for many applications
of these surrogates---inference times are reduced by three orders of magnitude
using our approach, compared with both the equation-based Galerkin projection
method and the standard LSTM approach.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:54:28 GMT""}]","2020-06-29"
"2006.14726","Stefan Zellmann","Stefan Zellmann","Augmenting Image Warping-Based Remote Volume Rendering with Ray Tracing",,,,,"cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an image warping-based remote rendering technique for volumes that
decouples the rendering and display phases. Our work builds on prior work that
samples the volume on the client using ray casting and reconstructs a z-value
based on some heuristic. The color and depth buffer are then sent to the client
that reuses this depth image as a stand-in for subsequent frames by warping it
according to the current camera position until new data was received from the
server. We augment that method by implementing the client renderer using ray
tracing. By representing the pixel contributions as spheres, this allows us to
effectively vary their footprint based on the distance to the viewer, which we
find to give better results than point-based rasterization when applied to
volumetric data sets.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:56:45 GMT""}]","2020-06-29"
"2006.14727","Polina Zablotskaia","Polina Zablotskaia, Edoardo A. Dominici, Leonid Sigal, Andreas M.
  Lehrmann","Unsupervised Video Decomposition using Spatio-temporal Iterative
  Inference",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised multi-object scene decomposition is a fast-emerging problem in
representation learning. Despite significant progress in static scenes, such
models are unable to leverage important dynamic cues present in video. We
propose a novel spatio-temporal iterative inference framework that is powerful
enough to jointly model complex multi-object representations and explicit
temporal dependencies between latent variables across frames. This is achieved
by leveraging 2D-LSTM, temporally conditioned inference and generation within
the iterative amortized inference for posterior refinement. Our method improves
the overall quality of decompositions, encodes information about the objects'
dynamics, and can be used to predict trajectories of each object separately.
Additionally, we show that our model has a high accuracy even without color
information. We demonstrate the decomposition, segmentation, and prediction
capabilities of our model and show that it outperforms the state-of-the-art on
several benchmark datasets, one of which was curated for this work and will be
made publicly available.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:57:17 GMT""}]","2020-06-29"
"2006.14728","Vasilis Niaouris","Jennifer F. Lilieholm, Vasilis Niaouris, Alexander Kato, Kai-Mei C. Fu
  and Boris B. Blinov","Photon-mediated entanglement scheme between a ZnO semiconductor defect
  and a trapped Yb ion",,,"10.1063/5.0019892",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an optical scheme to generate an entangled state between a trapped
ion and a solid state donor qubit through which-path erasure of identical
photons emitted from the two systems. The proposed scheme leverages the similar
transition frequencies between In donor bound excitons in ZnO and the
$^2P_{1/2}$ to $^2S_{1/2}$ transition in Yb$^+$. The lifetime of the relevant
ionic state is longer than that of the ZnO system by a factor of 6, leading to
a mismatch in the temporal profiles of emitted photons. A detuned
cavity-assisted Raman scheme weakly excites the donor with a shaped laser pulse
to generate photons with 0.99 temporal overlap to the Yb$^+$ emission and
partially shift the emission of the defect toward the Yb$^+$ transition. The
remaining photon shift is accomplished via the dc Stark effect. We show that an
entanglement rate of 21 kHz and entanglement fidelity of 94 % can be attained
using a weak excitation scheme with reasonable parameters.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 22:58:54 GMT""},{""version"":""v2"",""created"":""Wed, 2 Sep 2020 17:01:12 GMT""}]","2020-10-28"
"2006.14729","Laura Classen","Laura Classen, Andrey V. Chubukov, Carsten Honerkamp, Michael M.
  Scherer","Competing orders at higher-order Van Hove points","11+10 pages, 9+4 figures","Phys. Rev. B 102, 125141 (2020)","10.1103/PhysRevB.102.125141",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Van Hove points are special points in the energy dispersion, where the
density of states exhibits analytic singularities. When a Van Hove point is
close to the Fermi level, tendencies towards density wave orders, Pomeranchuk
orders, and superconductivity can all be enhanced, often in more than one
channel, leading to a competition between different orders and unconventional
ground states. Here we consider the effects from higher-order Van Hove points,
around which the dispersion is flatter than near a conventional Van Hove point,
and the density of states has a power-law divergence. We argue that such points
are present in intercalated graphene and other materials. We use an effective
low-energy model for electrons near higher-order Van Hove points and analyze
the competition between different ordering tendencies using an unbiased
renormalization group approach. For purely repulsive interactions, we find that
two key competitors are ferromagnetism and chiral superconductivity. For a
small attractive exchange interaction, we find a new type of spin Pomeranchuk
order, in which the spin order parameter winds around the Fermi surface. The
supermetal state, predicted for a single higher-order Van Hove point, is an
unstable fixed point in our case.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 23:12:16 GMT""}]","2020-09-30"
"2006.14730","Michael Mazur","Michael Mazur, Petr Pokorny, Peter Brown, Robert J. Weryk, Denis Vida,
  Carsten Schult, Gunter Stober, Anamika Agrawal","Precision measurements of radar transverse scattering speeds from meteor
  phase characteristics","Accepted for publication to Radio Science on 2020-06-23",,"10.1029/2019RS006987",,"astro-ph.EP astro-ph.IM eess.SP","http://creativecommons.org/licenses/by/4.0/","  We describe an improved technique for using the backscattered phase from
meteor radar echo measurements just prior to the specular point ($t_{0}$) to
calculate meteor speeds and their uncertainty. Our method, which builds on
earlier work of Cervera et al (1997), scans possible speeds in the Fresnel
distance - time domain with a dynamic, sliding window and derives a best-speed
estimate from the resultant speed distribution. We test the performance of our
method, called pre-$t_{0}$ speeds by sliding-slopes technique (PSSST), on
transverse scattered meteor echoes observed by the Middle Atmosphere Alomar
Radar System (MAARSY) and the Canadian Meteor Orbit Radar (CMOR), and compare
the results to time-of-flight and Fresnel transform speed estimates. Our novel
technique is shown to produce good results when compared to both model and
speed measurements using other techniques. We show that our speed precision is
$\pm$5$\%$ at speeds less than 40 km/s and we find that more than 90$\%$ of all
CMOR multi-station echoes have PSSST solutions. For CMOR data, PSSST is robust
against the selection of critical phase value and poor phase unwrapping. Pick
errors of up to $\pm$6 pulses for meteor speeds less than about 50 km/s produce
errors of less than $\pm$5$\%$ of the meteoroid speed. In addition, the width
of the PSSST speed Kernel density estimate (KDE) is used as a natural measure
of uncertainty that captures both noise and $t_0$ pick uncertainties.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 23:27:58 GMT""}]","2020-12-02"
"2006.14731","Savin Shynu Varghese","S. S. Varghese, K. S. Obenberger, J. Dowell, and G. B. Taylor","Detection of a Low-frequency Cosmic Radio Transient Using Two LWA
  Stations","15 pages, 9 figures","The Astrophysical Journal, 874:151 (12pp), 2019 April 1,
  https://iopscience.iop.org/article/10.3847/1538-4357/ab07c6","10.3847/1538-4357/ab07c6",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the detection of a potential cosmic radio transient source using
the two stations of the Long Wavelength Array. The transient was detected on 18
October 2017 08:47 UTC near the celestial equator while reducing 10,240 hours
of archival all-sky images from the LWA1 and LWA-SV stations. The detected
transient at 34 MHz has a duration of 15 - 20 seconds and a flux density of 842
+/- 116 Jy at LWA1 and 830 +/- 92 Jy at LWA-SV. The transient source has not
repeated, and its nature is not well understood. The Pan-STARRS optical
telescope has detected a supernova that occurred on the edge of the position
error circle of the transient on the same day.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 23:30:19 GMT""}]","2020-06-29"
"2006.14732","Tatiana Komarova","Tatiana Komarova and Denis Nekipelov","Identification and Formal Privacy Guarantees","69 pages, 2 figures, 1 table",,,,"econ.EM stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Empirical economic research crucially relies on highly sensitive individual
datasets. At the same time, increasing availability of public individual-level
data makes it possible for adversaries to potentially de-identify anonymized
records in sensitive research datasets. Most commonly accepted formal
definition of an individual non-disclosure guarantee is referred to as
differential privacy. It restricts the interaction of researchers with the data
by allowing them to issue queries to the data. The differential privacy
mechanism then replaces the actual outcome of the query with a randomised
outcome.
  The impact of differential privacy on the identification of empirical
economic models and on the performance of estimators in nonlinear empirical
Econometric models has not been sufficiently studied. Since privacy protection
mechanisms are inherently finite-sample procedures, we define the notion of
identifiability of the parameter of interest under differential privacy as a
property of the limit of experiments. It is naturally characterized by the
concepts from the random sets theory.
  We show that particular instances of regression discontinuity design may be
problematic for inference with differential privacy as parameters turn out to
be neither point nor partially identified. The set of differentially private
estimators converges weakly to a random set. Our analysis suggests that many
other estimators that rely on nuisance parameters may have similar properties
with the requirement of differential privacy. We show that identification
becomes possible if the target parameter can be deterministically located
within the random set. In that case, a full exploration of the random set of
the weak limits of differentially private estimators can allow the data curator
to select a sequence of instances of differentially private estimators
converging to the target parameter in probability.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 23:36:45 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 22:24:27 GMT""}]","2021-05-05"
"2006.14733","Debajyoti Mondal","Debajyoti Mondal, N. Parthiban, V. Kavitha, Indra Rajasingh","APX-Hardness and Approximation for the k-Burning Number Problem",,,,,"cs.CC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider an information diffusion process on a graph $G$ that starts with
$k>0$ burnt vertices, and at each subsequent step, burns the neighbors of the
currently burnt vertices, as well as $k$ other unburnt vertices. The
\emph{$k$-burning number} of $G$ is the minimum number of steps $b_k(G)$ such
that all the vertices can be burned within $b_k(G)$ steps. Note that the last
step may have smaller than $k$ unburnt vertices available, where all of them
are burned. The $1$-burning number coincides with the well-known burning number
problem, which was proposed to model the spread of social contagion. The
generalization to $k$-burning number allows us to examine different worst-case
contagion scenarios by varying the spread factor $k$.
  In this paper we prove that computing $k$-burning number is APX-hard, for any
fixed constant $k$. We then give an $O((n+m)\log n)$-time 3-approximation
algorithm for computing $k$-burning number, for any $k\ge 1$, where $n$ and $m$
are the number of vertices and edges, respectively. Finally, we show that even
if the burning sources are given as an input, computing a burning sequence
itself is an NP-hard problem.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 23:41:13 GMT""},{""version"":""v2"",""created"":""Sun, 17 Jan 2021 05:07:11 GMT""}]","2021-01-19"
"2006.14734","Nilabja Guha","Nilabja Guha and Anindya Roy","Stochastic Approximation Algorithm for Estimating Mixing Distribution
  for Dependent Observations",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Estimating the mixing density of a mixture distribution remains an
interesting problem in statistics literature. Using a stochastic approximation
method, Newton and Zhang (1999) introduced a fast recursive algorithm for
estimating the mixing density of a mixture. Under suitably chosen weights the
stochastic approximation estimator converges to the true solution. In Tokdar
et. al. (2009) the consistency of this recursive estimation method was
established. However, the proof of consistency of the resulting estimator used
independence among observations as an assumption. Here, we extend the
investigation of performance of Newton's algorithm to several dependent
scenarios. We prove that the original algorithm under certain conditions
remains consistent even when the observations are arising from a weakly
dependent stationary process with the target mixture as the marginal density.
We show consistency under a decay condition on the dependence among
observations when the dependence is characterized by a quantity similar to
mutual information between the observations.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:00:12 GMT""},{""version"":""v2"",""created"":""Sat, 31 Jul 2021 22:54:45 GMT""},{""version"":""v3"",""created"":""Sat, 22 Jan 2022 14:52:44 GMT""},{""version"":""v4"",""created"":""Sat, 26 Mar 2022 23:39:49 GMT""}]","2022-03-29"
"2006.14735","Vladimir Dzuba","V. A. Dzuba, Saleh O. Allehabi, V. V. Flambaum, Jiguang Li and S.
  Schiller","Time keeping and searching for new physics using metastable states of
  Cu, Ag and Au","10 pages, 2 figures","Phys. Rev. A 103, 022822 (2021)","10.1103/PhysRevA.103.022822",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the prospects of using the electric quadrupole transitions from the
ground states of Cu, Ag and Au to the metastable state $^2{\rm D}_{5/2}$ as
clock transitions in optical lattice clocks. We calculate lifetimes, transition
rates, systematic shifts, and demonstrate that the fractional uncertainty of
the clocks can be similar to what is achieved in the best current optical
clocks. The use of these proposed clocks for the search of new physics, such as
time variation of the fine structure constant, search for low-mass scalar dark
matter, violation of Local Position Invariance and violation of Lorenz
Invariance is discussed.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:21:58 GMT""}]","2021-02-24"
"2006.14736","Sarthak Parikh","Sarah Hoback and Sarthak Parikh","Towards Feynman rules for conformal blocks","59 pages + appendices, several figures",,"10.1007/JHEP01(2021)005",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We conjecture a simple set of ""Feynman rules"" for constructing $n$-point
global conformal blocks in any channel in $d$ spacetime dimensions, for
external and exchanged scalar operators for arbitrary $n$ and $d$. The vertex
factors are given in terms of Lauricella hypergeometric functions of one, two
or three variables, and the Feynman rules furnish an explicit power-series
expansion in powers of cross-ratios. These rules are conjectured based on
previously known results in the literature, which include four-, five- and
six-point examples as well as the $n$-point comb channel blocks. We prove these
rules for all previously known cases, as well as for a seven-point block in a
new topology and the even-point blocks in the ""OPE channel."" The proof relies
on holographic methods, notably the Feynman rules for Mellin amplitudes of
tree-level AdS diagrams in a scalar effective field theory, and is easily
applicable to any particular choice of a conformal block.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:26:46 GMT""}]","2021-02-03"
"2006.14737","Nokuthaba Sibanda","Doaa Ayad and Nokuthaba Sibanda","Monitoring of process and risk-adjusted medical outcomes using a
  multi-stage MEWMA chart","17 pages, 3 figures Submitted to Statistical Methods in Medical
  Research",,,,"stat.ME stat.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most statistical process control programmes in healthcare focus on
surveillance of outcomes at the final stage of a procedure, such as mortality
or failure rates. Such an approach ignores the multi-stage nature of these
procedures, in which a patient progresses through several stages prior to the
final stage. In this paper, we develop a multi-stage control chart based on a
multivariate exponentially weighted moving average (EWMA) test statistic
derived from score equations. This allows simultaneous monitoring of all
intermediate and final stage outcomes of a healthcare process, with adjustment
for underlying patient risk factors and dependence between outcome variables.
Use of the EWMA test statistics allows quick detection of small gradual changes
in any part of the process. Three advantages of the approach are: better
understanding of how outcomes at different stages relate to each other,
explicit monitoring of upstream stage outcomes may help curtail trends that
lead to poorer end-stage outcomes and understanding the impact of each stage
can help determine the most effective allocation of quality improvement
resources. Simulations are performed to test the control charts under various
types of hypothesised shifts, and the results are summarised using
out-of-control average run lengths.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:31:04 GMT""}]","2020-06-29"
"2006.14738","Sepehr Ataei","Sepehr Ataei, Dr. Javad Alirezaie, Dr. Paul Babyn","Cascaded Convolutional Neural Networks with Perceptual Loss for Low Dose
  CT Denoising",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low Dose CT Denoising research aims to reduce the risks of radiation exposure
to patients. Recently researchers have used deep learning to denoise low dose
CT images with promising results. However, approaches that use
mean-squared-error (MSE) tend to over smooth the image resulting in loss of
fine structural details in low contrast regions of the image. These regions are
often crucial for diagnosis and must be preserved in order for Low dose CT to
be used effectively in practice. In this work we use a cascade of two neural
networks, the first of which aims to reconstruct normal dose CT from low dose
CT by minimizing perceptual loss, and the second which predicts the difference
between the ground truth and prediction from the perceptual loss network. We
show that our method outperforms related works and more effectively
reconstructs fine structural details in low contrast regions of the image.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:35:26 GMT""}]","2020-06-29"
"2006.14739","Elena Bratkovskaya","V. Kireyeu, I. Grishmanovskii, V. Kolesnikov, V. Voronyuk, and E.
  Bratkovskaya","Hadron production in elementary nucleon-nucleon reactions from low to
  ultra-relativistic energies","18 pages, 17 figures; extended version to be published in the
  European Physical Journal A",,,,"hep-ph hep-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the hadron production in $p+p$, $p+n$ and $n+n$ reactions within the
microscopic Parton-Hadron-Dynamics (PHSD) transport approach in comparison to
PYTHIA 8.2. We discuss the details of the ""PHSD tune"" of the Lund string model
(realized by event generators FRITIOF and PYTHIA) in the vacuum (as in $N+N$
collisions) as well as its in-medium modifications relevant for heavy-ion
collisions where a hot and dense matter is produced. We compare the results of
PHSD and PYTHIA 8.2 (default version) for the excitation function of hadron
multiplicities as well as differential rapidity $y$, transverse momentum $p_T$
and $x_F$ distributions in $p+p$, $p+n$ and $n+n$ reactions with the existing
experimental data in the energy range $\sqrt{s_{NN}} = 2.7 - 7000$ GeV. We
discuss the production mechanisms of hadrons and the role of final state
interactions (FSI) due to the hadronic rescattering. We also show the influence
of the possible quark-gluon plasma (QGP) formation on hadronic observables in
$p+p$ collisions at LHC energies. We stress the importance of developing a
reliable event generator for elementary reactions from low to
ultra-relativistic energies in view of actual and upcoming heavy-ion
experiments.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:44:52 GMT""},{""version"":""v2"",""created"":""Tue, 25 Aug 2020 00:23:47 GMT""}]","2020-08-26"
"2006.14740","Seung Gyo Jeong","Seung Gyo Jeong, Gyeongtak Han, Sehwan Song, Taewon Min, Ahmed Yousef
  Mohamed, Sungkyun Park, Jaekwang Lee, Hu Young Jeong, Young-Min Kim,
  Deok-Yong Cho, and Woo Seok Choi","Propagation control of octahedral tilt in SrRuO3 via artificial
  heterostructuring","27 pages, 4 figures, 6 supplementary figures","published in 2020","10.1002/advs.202001643",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bonding geometry engineering of metal-oxygen octahedra is a facile way of
tailoring various functional properties of transition metal oxides. Several
approaches, including epitaxial strain, thickness, and stoichiometry control,
have been proposed to efficiently tune the rotation and tilting of the
octahedra, but these approaches are inevitably accompanied by unnecessary
structural modifications such as changes in thin-film lattice parameters. In
this study, we propose a method to selectively engineer the octahedral bonding
geometries, while maintaining other parameters that might implicitly influence
the functional properties. A concept of octahedral tilt propagation engineering
has been developed using atomically designed SrRuO3/SrTiO3 superlattices. In
particular, the propagation of RuO6 octahedral tilting within the SrRuO3 layers
having identical thicknesses was systematically controlled by varying the
thickness of adjacent SrTiO3 layers. This led to a substantial modification in
the electromagnetic properties of the SrRuO3 layer, significantly enhancing the
magnetic moment of Ru. Our approach provides a method to selectively manipulate
the bonding geometry of strongly correlated oxides, thereby enabling a better
understanding and greater controllability of their functional properties.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:55:32 GMT""}]","2020-06-29"
"2006.14741","John Baez","John C. Baez","Getting to the Bottom of Noether's Theorem","37 pages",,,,"math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the assumptions behind Noether's theorem connecting symmetries and
conservation laws. To compare classical and quantum versions of this theorem,
we take an algebraic approach. In both classical and quantum mechanics,
observables are naturally elements of a Jordan algebra, while generators of
one-parameter groups of transformations are naturally elements of a Lie
algebra. Noether's theorem holds whenever we can map observables to generators
in such a way that each observable generates a one-parameter group that
preserves itself. In ordinary complex quantum mechanics this mapping is
multiplication by $\sqrt{-1}$. In the more general framework of unital
JB-algebras, Alfsen and Shultz call such a mapping a ""dynamical
correspondence"", and show its presence allows us to identify the unital
JB-algebra with the self-adjoint part of a complex C*-algebra. However, to
prove their result, they impose a second, more obscure, condition on the
dynamical correspondence. We show this expresses a relation between quantum and
statistical mechanics, closely connected to the principle that ""inverse
temperature is imaginary time"".
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:56:17 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jul 2020 21:38:47 GMT""},{""version"":""v3"",""created"":""Sat, 28 Nov 2020 23:52:58 GMT""},{""version"":""v4"",""created"":""Mon, 14 Feb 2022 17:56:32 GMT""}]","2022-02-15"
"2006.14742","Timothy Trudgian","Michael J. Mossinghoff and Timothy S. Trudgian","The size of oscillations in the Goldbach conjecture","11 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $R(n) = \sum_{a+b=n} \Lambda(a)\Lambda(b)$, where $\Lambda(\cdot)$ is the
von Mangoldt function. The function $R(n)$ is often studied in connection with
Goldbach's conjecture. On the Riemann hypothesis (RH) it is known that
$\sum_{n\leq x} R(n) = x^2/2 - 4x^{3/2} G(x) + O(x^{1+\epsilon})$, where
$G(x)=\Re \sum_{\gamma>0} \frac{x^{i\gamma}}{(\frac{1}{2} +
i\gamma)(\frac{3}{2} + i\gamma)}$ and the sum is over the ordinates of the
nontrivial zeros of the Riemann zeta function in the upper half-plane. We prove
(on RH) that each of the inequalities $G(x) < -0.02093$ and $G(x)> 0.02092$
hold infinitely often, and establish improved bounds under an assumption of
linearly independence for zeros of the zeta function. We also show that the
bounds we obtain are very close to optimal.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:56:47 GMT""}]","2020-06-29"
"2006.14743","Chiang-Mei Chen","Chiang-Mei Chen, James M. Nester, Walter Vogel","Felix Klein's ""Uber die Integralform der Erhaltungss\""atze und die
  Theorie der r\""aumlich-geschlossenen Welt"": an English translation","30 pages",,,,"physics.hist-ph gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an English translation of a third 1918 paper by Felix Klein which
follows up on his earlier work.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:58:32 GMT""}]","2020-06-29"
"2006.14744","Liqun Chen","Liqun Chen, Zhe Gan, Yu Cheng, Linjie Li, Lawrence Carin, Jingjing Liu","Graph Optimal Transport for Cross-Domain Alignment",,"ICML 2020",,,"cs.CL cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cross-domain alignment between two sets of entities (e.g., objects in an
image, words in a sentence) is fundamental to both computer vision and natural
language processing. Existing methods mainly focus on designing advanced
attention mechanisms to simulate soft alignment, with no training signals to
explicitly encourage alignment. The learned attention matrices are also dense
and lacks interpretability. We propose Graph Optimal Transport (GOT), a
principled framework that germinates from recent advances in Optimal Transport
(OT). In GOT, cross-domain alignment is formulated as a graph matching problem,
by representing entities into a dynamically-constructed graph. Two types of OT
distances are considered: (i) Wasserstein distance (WD) for node (entity)
matching; and (ii) Gromov-Wasserstein distance (GWD) for edge (structure)
matching. Both WD and GWD can be incorporated into existing neural network
models, effectively acting as a drop-in regularizer. The inferred transport
plan also yields sparse and self-normalized alignment, enhancing the
interpretability of the learned model. Experiments show consistent
outperformance of GOT over baselines across a wide range of tasks, including
image-text retrieval, visual question answering, image captioning, machine
translation, and text summarization.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:14:23 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 15:58:36 GMT""},{""version"":""v3"",""created"":""Fri, 24 Jul 2020 20:04:49 GMT""}]","2020-07-28"
"2006.14745","Laura Domin\'e","Laura Domin\'e, Pierre C\^ote de Soux, Fran\c{c}ois Drielsma, Dae Heun
  Koh, Ran Itay, Qing Lin, Kazuhiro Terao, Ka Vang Tsang, Tracy L. Usher","Point Proposal Network for Reconstructing 3D Particle Endpoints with
  Sub-Pixel Precision in Liquid Argon Time Projection Chambers",,"Phys. Rev. D 104, 032004 (2021)","10.1103/PhysRevD.104.032004",,"hep-ex cs.CV physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Liquid Argon Time Projection Chambers (LArTPC) are particle imaging detectors
recording 2D or 3D images of trajectories of charged particles. Identifying
points of interest in these images, namely the initial and terminal points of
track-like particle trajectories such as muons and protons, and the initial
points of electromagnetic shower-like particle trajectories such as electrons
and gamma rays, is a crucial step of identifying and analyzing these particles
and impacts the inference of physics signals such as neutrino interaction. The
Point Proposal Network is designed to discover these specific points of
interest. The algorithm predicts with a sub-voxel precision their spatial
location, and also determines the category of the identified points of
interest. Using as a benchmark the PILArNet public LArTPC data sample in which
the voxel resolution is 3mm/voxel, our algorithm successfully predicted 96.8%
and 97.8% of 3D points within a distance of 3 and 10~voxels from the provided
true point locations respectively. For the predicted 3D points within 3 voxels
of the closest true point locations, the median distance is found to be 0.25
voxels, achieving the sub-voxel level precision. In addition, we report our
analysis of the mistakes where our algorithm prediction differs from the
provided true point positions by more than 10~voxels. Among 50 mistakes
visually scanned, 25 were due to the definition of true position location, 15
were legitimate mistakes where a physicist cannot visually disagree with the
algorithm's prediction, and 10 were genuine mistakes that we wish to improve in
the future. Further, using these predicted points, we demonstrate a simple
algorithm to cluster 3D voxels into individual track-like particle trajectories
with a clustering efficiency, purity, and Adjusted Rand Index of 96%, 93%, and
91% respectively.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:18:43 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 17:47:41 GMT""},{""version"":""v3"",""created"":""Fri, 10 Jul 2020 15:30:44 GMT""}]","2021-08-25"
"2006.14746","Sergio R. Coria","Sergio R. Coria, Leonardo Marcos-Santiago, Christian A. Cruz-Melendez,
  Juan M. Jimenez-Canseco","Towards an automated repository for indexing, analysis and
  characterization of municipal e-government websites in Mexico",,,,,"cs.CY cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article addresses a problem in the electronic government discipline with
special interest in Mexico: the need for a concentrated and updated information
source about municipal e-government websites. One reason for this is the lack
of a complete and updated database containing the electronic addresses (web
domain names) of the municipal governments having a website. Due to diverse
causes, not all the Mexican municipalities have one, and a number of those
having it do not present information corresponding to the current governments
but, instead, to other previous ones. The scarce official lists of municipal
websites are not updated with the sufficient frequency, and manually
determining which municipalities have an operating and valid website in a given
moment is a time-consuming process. Besides, website contents do not always
comply with legal requirements and are considerably heterogeneous. In turn, the
evolution development level of municipal websites is valuable information that
can be harnessed for diverse theoretical and practical purposes in the public
administration field. Obtaining all these pieces of information requires
website content analysis. Therefore, this article investigates the need for and
the feasibility to automate implementation and updating of a digital repository
to perform diverse analyses of these websites. Its technological feasibility is
addressed by means of a literature review about web scraping and by proposing a
preliminary manual methodology. This takes into account known, proven,
techniques and software tools for web crawling and scraping. No new techniques
for crawling or scraping are proposed because the existing ones satisfy the
current needs. Finally, software requirements are specified in order to
automate the creation, updating, indexing, and analyses of the repository.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:20:20 GMT""}]","2020-06-29"
"2006.14747","El\'ias Castellanos Dr.","Jasel Berra-Montiel, El\'ias Castellanos, Alberto Molgado and Jonathan
  Trinidad-Garc\'ia","Superfluids in Polymer Quantum Mechanics","14 pages","Modern Physics Letters A Vol. 36, No. 07, 2150045 (2021)","10.1142/S0217732321500450",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we analyze the corrections obtained on a homogeneous
one-dimensional Bose gas within the high densities limit by means of the
polymer quantization scheme. Thus, starting from the Bogoliubov formalism, we
analyze the ground expectation value of the polymer momentum operator in terms
of semiclassical states, in order to obtain an analytic expression for the
ground state energy of the N-body system, which allows us to solve the
pathological behavior commonly associated with the one-dimensional
Bose-Einstein condensation through the introduction of finite size effects
characterized by the contribution of the polymer corrections. We also discuss
the speed of sound in our polymer version of the Bose gas and the corresponding
relative shift induced by the introduction of a minimum length parameter.
Finally, by considering the idea that the Bose-Einstein condensation phenomenon
is closely related to that of superfluidity, we investigate the emergent
superfluid behavior in our polymer model by implementing an appropriate
Landau's criterion. In this case, we are able to consequently analyze the
changes in the critical velocity which defines the limit between the
superfluid-condensate regions, thus deducing that the polymer length acts as a
kind of pseudo-potential which induces a dissipationless flow associated with
the superfluid phase even in the absence of self-interactions.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:31:29 GMT""}]","2021-03-12"
"2006.14748","Akhilan Boopathy","Akhilan Boopathy, Sijia Liu, Gaoyuan Zhang, Cynthia Liu, Pin-Yu Chen,
  Shiyu Chang, Luca Daniel","Proper Network Interpretability Helps Adversarial Robustness in
  Classification","22 pages, 9 figures, Published at ICML 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent works have empirically shown that there exist adversarial examples
that can be hidden from neural network interpretability (namely, making network
interpretation maps visually similar), or interpretability is itself
susceptible to adversarial attacks. In this paper, we theoretically show that
with a proper measurement of interpretation, it is actually difficult to
prevent prediction-evasion adversarial attacks from causing interpretation
discrepancy, as confirmed by experiments on MNIST, CIFAR-10 and Restricted
ImageNet. Spurred by that, we develop an interpretability-aware defensive
scheme built only on promoting robust interpretation (without the need for
resorting to adversarial loss minimization). We show that our defense achieves
both robust classification and robust interpretation, outperforming
state-of-the-art adversarial training methods against attacks of large
perturbation in particular.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:31:31 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 18:56:05 GMT""}]","2020-10-23"
"2006.14749","Oscar De Lima","Oscar de Lima, Sean Franklin, Shreshtha Basu, Blake Karwoski, Annet
  George","Deepfake Detection using Spatiotemporal Convolutional Networks",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Better generative models and larger datasets have led to more realistic fake
videos that can fool the human eye but produce temporal and spatial artifacts
that deep learning approaches can detect. Most current Deepfake detection
methods only use individual video frames and therefore fail to learn from
temporal information. We created a benchmark of the performance of
spatiotemporal convolutional methods using the Celeb-DF dataset. Our methods
outperformed state-of-the-art frame-based detection methods. Code for our paper
is publicly available at https://github.com/oidelima/Deepfake-Detection.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:32:31 GMT""}]","2020-06-29"
"2006.14750","Andrew Hines","Labhaoise Ni Fhaolain and Andrew Hines","Could regulating the creators deliver trustworthy AI?","To be published in The Second Workshop on Implementing Machine
  Ethics, Dublin, Ireland, 30 June 2020",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Is a new regulated profession, such as Artificial Intelligence (AI) Architect
who is responsible and accountable for AI outputs necessary to ensure
trustworthy AI? AI is becoming all pervasive and is often deployed in everyday
technologies, devices and services without our knowledge. There is heightened
awareness of AI in recent years which has brought with it fear. This fear is
compounded by the inability to point to a trustworthy source of AI, however
even the term ""trustworthy AI"" itself is troublesome. Some consider trustworthy
AI to be that which complies with relevant laws, while others point to the
requirement to comply with ethics and standards (whether in addition to or in
isolation of the law). This immediately raises questions of whose ethics and
which standards should be applied and whether these are sufficient to produce
trustworthy AI in any event.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:32:53 GMT""}]","2020-06-29"
"2006.14751","Ruda Zhang","Ruda Zhang","Newton retraction as approximate geodesics on submanifolds","9 pages, 2 figures, 1 table",,,,"math.NA cs.NA math.DG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Efficient approximation of geodesics is crucial for practical algorithms on
manifolds. Here we introduce a class of retractions on submanifolds, induced by
a foliation of the ambient manifold. They match the projective retraction to
the third order and thus match the exponential map to the second order. In
particular, we show that Newton retraction (NR) is always stabler than the
popular approach known as oblique projection or orthographic retraction: per
Kantorovich-type convergence theorems, the superlinear convergence regions of
NR include those of the latter. We also show that NR always has a lower
computational cost. The preferable properties of NR are useful for
optimization, sampling, and many other statistical problems on manifolds.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:41:48 GMT""}]","2020-06-29"
"2006.14752","Shashank Reddy Vadyala","Shashank Reddy Vadyala, Sai Nethra Betgeri, Eric A. Sherer, Amod
  Amritphale","Prediction of the Number of COVID-19 Confirmed Cases Based on
  K-Means-LSTM",,,,,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  COVID-19 is a pandemic disease that began to rapidly spread in the US with
the first case detected on January 19, 2020, in Washington State. March 9,
2020, and then increased rapidly with total cases of 25,739 as of April 20,
2020. The Covid-19 pandemic is so unnerving that it is difficult to understand
how any person is affected by the virus. Although most people with coronavirus
81%, according to the U.S. Centers for Disease Control and Prevention (CDC),
will have little to mild symptoms, others may rely on a ventilator to breathe
or not at all. SEIR models have broad applicability in predicting the outcome
of the population with a variety of diseases. However, many researchers use
these models without validating the necessary hypotheses. Far too many
researchers often ""overfit"" the data by using too many predictor variables and
small sample sizes to create models. Models thus developed are unlikely to
stand validity check on a separate group of population and regions. The
researcher remains unaware that overfitting has occurred, without attempting
such validation. In the paper, we present a combination algorithm that combines
similar days features selection based on the region using Xgboost, K Means, and
long short-term memory (LSTM) neural networks to construct a prediction model
(i.e., K-Means-LSTM) for short-term COVID-19 cases forecasting in Louisana
state USA. The weighted k-means algorithm based on extreme gradient boosting is
used to evaluate the similarity between the forecasts and past days. The
results show that the method with K-Means-LSTM has a higher accuracy with an
RMSE of 601.20 whereas the SEIR model with an RMSE of 3615.83.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:42:07 GMT""}]","2020-06-30"
"2006.14753","Luc Gossart","Luc Gossart","Flat traces for a random partially hyperbolic map",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a $\mathbb R/\mathbb Z$ extension of an Anosov diffemorphism of a
compact Riemannian manifold by a random function $\tau$ and show that the flat
traces of the transfer operator, reduced with respect to frequency in the
fibers, converge in law towards Gaussians, up to an Ehrenfest time that
decreases with the regularity of $\tau$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:49:48 GMT""}]","2020-06-29"
"2006.14754","Si Wu","Si Wu, Yinghao Zhu, Haoshi Gao, Yinguo Xiao, Junchao Xia, Pengfei
  Zhou, Defang Ouyang, Zhen Li, Zhenqiang Chen, Zikang Tang, Hai-Feng Li","Super-Necking Crystal Growth and Structural and Magnetic Properties of
  SrTb$_2$O$_4$ Single Crystals","19 pages, 13 figures","ACS Omega, 2020, 5, 16584--16594","10.1021/acsomega.0c01360",,"cond-mat.mtrl-sci cond-mat.str-el physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on single-crystal growths of the SrTb$_2$O$_4$ compound by a
super-necking technique with a laser-floating-zone furnace and study the
stoichiometry, growth mode, and structural and magnetic properties by scanning
electronic microscopy, neutron Laue, X-ray powder diffraction, and the physical
property measurement system. We optimized the growth parameters, mainly the
growth speed, atmosphere, and the addition of a Tb$_4$O$_7$ raw material.
Neutron Laue diffraction displays the characteristic feature of a single
crystal. Our study reveals an atomic ratio of Sr:Tb $ = 0.97(2){:}2.00(1)$ and
a possible layer by layer crystal growth mode. Our X-ray powder diffraction
study determines the crystal structure, lattice constants and atomic positions.
The paramagnetic (PM) Curie--Weiss (CW) temperature $\theta_{\texttt{CW}} =$
5.00(4) K, and the effective PM moment $M^{\texttt{eff}}_{\texttt{mea}} =$
10.97(1) $\mu_\texttt{B}$ per Tb$^{3+}$ ion. The data of magnetization versus
temperature can be divided into three regimes, showing a coexistence of
antiferromagnetic and ferromagnetic interactions. This probably leads to the
magnetic frustration in the SrTb$_2$O$_4$ compound. The magnetization at 2 K
and 14 T originates from both the Tb1 and Tb2 sites and is strongly frustrated
with an expected saturation field at $\sim$41.5 T, displaying an intricate
phase diagram with three ranges.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:49:49 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 13:04:21 GMT""}]","2020-07-15"
"2006.14755","Yinjun Wu","Yinjun Wu, Edgar Dobriban, Susan B. Davidson","DeltaGrad: Rapid retraining of machine learning models",,"published in ICML 2020",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning models are not static and may need to be retrained on
slightly changed datasets, for instance, with the addition or deletion of a set
of data points. This has many applications, including privacy, robustness, bias
reduction, and uncertainty quantifcation. However, it is expensive to retrain
models from scratch. To address this problem, we propose the DeltaGrad
algorithm for rapid retraining machine learning models based on information
cached during the training phase. We provide both theoretical and empirical
support for the effectiveness of DeltaGrad, and show that it compares favorably
to the state of the art.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:59:55 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 21:18:21 GMT""}]","2020-07-02"
"2006.14756","Michael Coughlin","Michael W. Coughlin, Tim Dietrich, Sarah Antier, Mouza Almualla,
  Shreya Anand, Mattia Bulla, Francois Foucart, Nidhal Guessoum, Kenta
  Hotokezaka, Vishwesh Kumar, Geert Raaijmakers and Samaya Nissanke","Implications of the search for optical counterparts during the second
  part of the Advanced LIGO's and Advanced Virgo's third observing run: lessons
  learned for future follow-up observations",,,"10.1093/mnras/staa1925",,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Joint multi-messenger observations with gravitational waves and
electromagnetic data offer new insights into the astrophysical studies of
compact objects. The third Advanced LIGO and Advanced Virgo observing run began
on April 1, 2019; during the eleven months of observation, there have been 14
compact binary systems candidates for which at least one component is
potentially a neutron star. Although intensive follow-up campaigns involving
tens of ground and space-based observatories searched for counterparts, no
electromagnetic counterpart has been detected. Following on a previous study of
the first six months of the campaign, we present in this paper the next five
months of the campaign from October 2019 to March 2020. We highlight two
neutron star - black hole candidates (S191205ah, S200105ae), two binary neutron
star candidates (S191213g and S200213t) and a binary merger with a possible
neutron star and a ""MassGap"" component, S200115j. Assuming that the
gravitational-wave candidates are of astrophysical origin and their location
was covered by optical telescopes, we derive possible constraints on the matter
ejected during the events based on the non-detection of counterparts. We find
that the follow-up observations during the second half of the third observing
run did not meet the necessary sensitivity to constrain the source properties
of the potential gravitational-wave candidate. Consequently, we suggest that
different strategies have to be used to allow a better usage of the available
telescope time. We examine different choices for follow-up surveys to optimize
sky localization coverage vs.\ observational depth to understand the likelihood
of counterpart detection.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 02:05:06 GMT""}]","2020-07-15"
"2006.14757","Chao Min","Chao Min and Yang Chen","Painlev\'{e} V and the Hankel Determinant for a Singularly Perturbed
  Jacobi Weight","28 pages","Nuclear Physics B 961 (2020) 115221 (25 pages)","10.1016/j.nuclphysb.2020.115221",,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Hankel determinant generated by a singularly perturbed Jacobi
weight $$
w(x,t):=(1-x^2)^\alpha\mathrm{e}^{-\frac{t}{x^{2}}},\;\;\;\;\;\;x\in[-1,1],\;\;\alpha>0,\;\;t\geq
0. $$ If $t=0$, it is reduced to the classical symmetric Jacobi weight. For
$t>0$, the factor $\mathrm{e}^{-\frac{t}{x^{2}}}$ induces an infinitely strong
zero at the origin. This Hankel determinant is related to the Wigner time-delay
distribution in chaotic cavities.
  In the finite $n$ dimensional case, we obtain two auxiliary quantities
$R_n(t)$ and $r_n(t)$ by using the ladder operator approach. We show that the
Hankel determinant has an integral representation in terms of $R_n(t)$, where
$R_n(t)$ is closely related to a particular Painlev\'{e} V transcendent.
Furthermore, we derive a second-order nonlinear differential equation and also
a second-order difference equation for the logarithmic derivative of the Hankel
determinant. This quantity can be expressed in terms of the Jimbo-Miwa-Okamoto
$\sigma$-function of a particular Painlev\'{e} V. Then we consider the
asymptotics of the Hankel determinant under a suitable double scaling, i.e.
$n\rightarrow\infty$ and $t\rightarrow 0$ such that $s=2n^2 t$ is fixed. Based
on previous results by using the Coulomb fluid method, we obtain the large $s$
and small $s$ asymptotic behaviors of the scaled Hankel determinant, including
the constant term in the asymptotic expansion.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 02:21:15 GMT""}]","2020-10-27"
"2006.14758","Yi Fang","Daohan Lu, Yi Fang","Meta Deformation Network: Meta Functionals for Shape Correspondence",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new technique named ""Meta Deformation Network"" for 3D shape
matching via deformation, in which a deep neural network maps a reference shape
onto the parameters of a second neural network whose task is to give the
correspondence between a learned template and query shape via deformation. We
categorize the second neural network as a meta-function, or a function
generated by another function, as its parameters are dynamically given by the
first network on a per-input basis. This leads to a straightforward overall
architecture and faster execution speeds, without loss in the quality of the
deformation of the template. We show in our experiments that Meta Deformation
Network leads to improvements on the MPI-FAUST Inter Challenge over designs
that utilized a conventional decoder design that has non-dynamic parameters.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 02:28:51 GMT""}]","2020-06-29"
"2006.14759","Chol-Hui Yun","Chang Il Rim, Jong Gyong Kim, Chol-Hui Yun","Existence and convergence theorems for monotone generalized
  alpa-nonexpansive mappings in uniformly convex partially ordered hyperbolic
  metric spaces and its application",,,,,"math.FA cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we generalize the existence result in [14] and prove
convergence theorems of the iterative scheme in [12, 16] for monotone
generalized alpa-nonexpansive mappings in uniformly convex partially ordered
hyperbolic metric spaces. And we also give a numerical example to show that
this scheme converges faster than the scheme in [14] and apply the result to
the integral equation.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 02:29:38 GMT""}]","2020-06-29"
"2006.14760","Anschel Schaffer-Cohen","Anschel Schaffer-Cohen","Graphs of curves and arcs quasi-isometric to big mapping class groups","33 pages, 8 figures; version accepted for publication in Groups,
  Geometry, and Dynamics. Added a corollary about coarsely bounded
  presentations, a consequence of hyperbolicity",,,,"math.GT math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following the work of Rosendal and Mann and Rafi, we try to answer the
following question: when is the mapping class group of an infinite-type surface
quasi-isometric to a graph whose vertices are curves on that surface? With the
assumption of tameness as defined by Mann and Rafi, we describe a necessary and
sufficient condition, called translatability, for a geometrically nontrivial
big mapping class group to admit such a quasi-isometry. In addition, we show
that the mapping class group of the plane minus a Cantor set is quasi-isometric
to the loop graph defined by Bavard, which we believe represents the first
example of a mapping class group known to be non-elementary hyperbolic.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 02:45:07 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jul 2020 19:25:54 GMT""},{""version"":""v3"",""created"":""Fri, 5 Aug 2022 17:51:51 GMT""}]","2022-08-08"
"2006.14761","Pengfei Guo","Pengfei Guo, Puyang Wang, Jinyuan Zhou, Vishal M. Patel, Shanshan
  Jiang","Lesion Mask-based Simultaneous Synthesis of Anatomic and MolecularMR
  Images using a GAN","MICCAI 2020",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data-driven automatic approaches have demonstrated their great potential in
resolving various clinical diagnostic dilemmas for patients with malignant
gliomas in neuro-oncology with the help of conventional and advanced molecular
MR images. However, the lack of sufficient annotated MRI data has vastly
impeded the development of such automatic methods. Conventional data
augmentation approaches, including flipping, scaling, rotation, and distortion
are not capable of generating data with diverse image content. In this paper,
we propose a method, called synthesis of anatomic and molecular MR images
network (SAMR), which can simultaneously synthesize data from arbitrary
manipulated lesion information on multiple anatomic and molecular MRI
sequences, including T1-weighted (T1w), gadolinium enhanced T1w (Gd-T1w),
T2-weighted (T2w), fluid-attenuated inversion recovery (FLAIR), and amide
proton transfer-weighted (APTw). The proposed framework consists of a
stretch-out up-sampling module, a brain atlas encoder, a segmentation
consistency module, and multi-scale label-wise discriminators. Extensive
experiments on real clinical data demonstrate that the proposed model can
perform significantly better than the state-of-the-art synthesis methods.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 02:50:09 GMT""},{""version"":""v2"",""created"":""Sun, 5 Jul 2020 21:34:12 GMT""},{""version"":""v3"",""created"":""Wed, 26 Aug 2020 19:03:46 GMT""}]","2020-08-28"
"2006.14762","Julius Susanto","Julius Susanto, Farhad Shahnia","Optimal Capacity of a Battery Energy Storage System based on Solar
  Variability Index to Smooth out Power Fluctuations in PV-Diesel Microgrids",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Battery energy storage systems can be integrated with photovoltaic
(PV)-diesel microgrids, as an enabling technology to increase the penetration
of PV systems and aid microgrid stability by smoothing out the power
fluctuations of the PV systems. The aim of this paper is to derive correlations
between the optimal capacity of the smoothing batteries and variabilities in
daily solar irradiance. Two commonly used smoothing techniques of moving
average and ramp rate control are applied on a real solar irradiance dataset
with a 1-minute resolution for a full calendar year across 11 sites in
Australia. The paper then presents the developed empirical model, based on
linear regressions, to estimate the optimal capacity of the batteries without
requiring the use of detailed simulation studies. The performance of the
developed technique is validated by numerical simulation studies in MATLAB. The
study demonstrates that the empirical model provided reasonably accurate
estimates when using the moving average smoothing technique, but had limited
accuracy under the ramp rate control technique.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 02:51:13 GMT""}]","2020-06-29"
"2006.14763","Zakaria Mhammedi","Zakaria Mhammedi, Benjamin Guedj, Robert C. Williamson","PAC-Bayesian Bound for the Conditional Value at Risk",,"NeurIPS 2020",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conditional Value at Risk (CVaR) is a family of ""coherent risk measures""
which generalize the traditional mathematical expectation. Widely used in
mathematical finance, it is garnering increasing interest in machine learning,
e.g., as an alternate approach to regularization, and as a means for ensuring
fairness. This paper presents a generalization bound for learning algorithms
that minimize the CVaR of the empirical loss. The bound is of PAC-Bayesian type
and is guaranteed to be small when the empirical CVaR is small. We achieve this
by reducing the problem of estimating CVaR to that of merely estimating an
expectation. This then enables us, as a by-product, to obtain concentration
inequalities for CVaR even when the random variable in question is unbounded.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 02:55:24 GMT""}]","2020-11-17"
"2006.14764","Andre Oliveira","Andre P. Oliveira","Khintchine's Theorem with rationals coming from neighborhoods in
  different places","v1: 24 pages; v2: minor clarifications in the introduction and
  acknowledgements extended; v3: referee comments included",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Duffin--Schaeffer Conjecture answers a question on how well one can
approximate irrationals by rational numbers in reduced form (an imposed
condition) where the accuracy of the approximation depends on the rational
number. It can be viewed as an analogue to Khintchine's Theorem with the added
restriction of only allowing rationals in reduced form. Other conditions such
as numerator or denominator a prime, a square-free integer, or an element of a
particular arithmetic progression, etc. have also been imposed and analogues of
Khintchine's Theorem studied. We prove versions of Khintchine's Theorem where
the rational numbers are sourced from a ball in some completion of $\mathbb{Q}$
(i.e. Euclidean or $p$-adic), while the approximations are carried out in a
distinct second completion. Finally, by using a mass transference principle for
Hausdorff measures, we are able to extend our results to their corresponding
analogues with Haar measures replaced by Hausdorff measures, thereby
establishing an analogue of Jarn\'ik's Theorem.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 02:59:59 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 20:26:28 GMT""},{""version"":""v3"",""created"":""Tue, 18 Aug 2020 19:13:02 GMT""},{""version"":""v4"",""created"":""Wed, 31 Mar 2021 14:22:07 GMT""}]","2021-04-01"
"2006.14765","Tingmin Wu","Tingmin Wu, Wanlun Ma, Sheng Wen, Xin Xia, Cecile Paris, Surya Nepal,
  Yang Xiang","Analysis of Trending Topics and Text-based Channels of Information
  Delivery in Cybersecurity","13 pages (main content) + 4 pages (references and appendix)",,,,"cs.CR cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computer users are generally faced with difficulties in making correct
security decisions. While an increasingly fewer number of people are trying or
willing to take formal security training, online sources including news,
security blogs, and websites are continuously making security knowledge more
accessible. Analysis of cybersecurity texts can provide insights into the
trending topics and identify current security issues as well as how cyber
attacks evolve over time. These in turn can support researchers and
practitioners in predicting and preparing for these attacks. Comparing
different sources may facilitate the learning process for normal users by
persisting the security knowledge gained from different cybersecurity context.
Prior studies neither systematically analysed the wide-range of digital sources
nor provided any standardisation in analysing the trending topics from recent
security texts. Although LDA has been widely adopted in topic generation, its
generated topics cannot cover the cybersecurity concepts completely and
considerably overlap. To address this issue, we propose a semi-automated
classification method to generate comprehensive security categories instead of
LDA-generated topics. We further compare the identified 16 security categories
across different sources based on their popularity and impact. We have revealed
several surprising findings. (1) The impact reflected from cyber-security texts
strongly correlates with the monetary loss caused by cybercrimes. (2) For most
categories, security blogs share the largest popularity and largest
absolute/relative impact over time. (3) Websites deliver security information
without caring about timeliness much, where one third of the articles do not
specify the date and the rest have a time lag in posting emerging security
issues.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:00:04 GMT""}]","2020-06-29"
"2006.14766","Jake Bobowski","Jake S. Bobowski, Saimoom Ferdous and Thomas Johnson","Calibrated Single-Contact Voltage Sensor for High-Voltage Monitoring
  Applications","12 pages, 13 figures","IEEE Transactions on Instrumentation and Measurement, vol. 64, no.
  4, pp. 923-934, April 2015","10.1109/TIM.2014.2360804",,"physics.ins-det physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A single-contact voltage sensor designed for accurate measurements of ac
voltages across a pair of conductors is described. The sensor design is
motivated by remote monitoring applications where accurate voltage measurement
of high-voltage transmission lines is required. The body of the sensor is
electrically and mechanically attached to a single conductor: either the
neutral or high-voltage conductor. A capacitive sensing plate attached to the
sensor creates a capacitive voltage divider using the stray capacitance to the
non-contacted line. A very high-impedance buffer is used to measure the voltage
across the divider output and estimate the line voltage. An important part of
the work includes a method of calibrating the sensor such that blind voltage
measurements can be made without knowing the exact geometry of the conductors.
Other important aspects of the design include a two-stage voltage divider for
retaining accuracy and increasing the voltage range of the sensor. The work is
supported by extensive numerical simulation models which were used to determine
the optimum design for the sensing plate and to evaluate the sensitivity to
different configurations including conductor spacing and the height above
ground. For calibration values which are accurate to 1%, the line voltage can
be measured with an accuracy of 10%. The paper describes the theory, design,
and experimental verification of the sensor up to a line voltage of 7.5 kVrms.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:03:43 GMT""}]","2020-06-29"
"2006.14767","Aishwarya Padmakumar","Aishwarya Padmakumar, Raymond J. Mooney","Dialog as a Vehicle for Lifelong Learning","Position Paper Track at the SIGDIAL Special Session on Physically
  Situated Dialogue (RoboDial 2.0) - Camera Ready Version",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dialog systems research has primarily been focused around two main types of
applications - task-oriented dialog systems that learn to use clarification to
aid in understanding a goal, and open-ended dialog systems that are expected to
carry out unconstrained ""chit chat"" conversations. However, dialog interactions
can also be used to obtain various types of knowledge that can be used to
improve an underlying language understanding system, or other machine learning
systems that the dialog acts over. In this position paper, we present the
problem of designing dialog systems that enable lifelong learning as an
important challenge problem, in particular for applications involving
physically situated robots. We include examples of prior work in this
direction, and discuss challenges that remain to be addressed.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:08:33 GMT""}]","2020-06-29"
"2006.14768","Alexander Levine","Alexander Levine, Soheil Feizi","Deep Partition Aggregation: Provable Defense against General Poisoning
  Attacks","ICLR 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial poisoning attacks distort training data in order to corrupt the
test-time behavior of a classifier. A provable defense provides a certificate
for each test sample, which is a lower bound on the magnitude of any
adversarial distortion of the training set that can corrupt the test sample's
classification. We propose two novel provable defenses against poisoning
attacks: (i) Deep Partition Aggregation (DPA), a certified defense against a
general poisoning threat model, defined as the insertion or deletion of a
bounded number of samples to the training set -- by implication, this threat
model also includes arbitrary distortions to a bounded number of images and/or
labels; and (ii) Semi-Supervised DPA (SS-DPA), a certified defense against
label-flipping poisoning attacks. DPA is an ensemble method where base models
are trained on partitions of the training set determined by a hash function.
DPA is related to both subset aggregation, a well-studied ensemble method in
classical machine learning, as well as to randomized smoothing, a popular
provable defense against evasion attacks. Our defense against label-flipping
attacks, SS-DPA, uses a semi-supervised learning algorithm as its base
classifier model: each base classifier is trained using the entire unlabeled
training set in addition to the labels for a partition. SS-DPA significantly
outperforms the existing certified defense for label-flipping attacks on both
MNIST and CIFAR-10: provably tolerating, for at least half of test images, over
600 label flips (vs. < 200 label flips) on MNIST and over 300 label flips (vs.
175 label flips) on CIFAR-10. Against general poisoning attacks, where no prior
certified defenses exists, DPA can certify >= 50% of test images against over
500 poison image insertions on MNIST, and nine insertions on CIFAR-10. These
results establish new state-of-the-art provable defenses against poisoning
attacks.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:16:31 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2021 05:50:12 GMT""}]","2021-03-19"
"2006.14769","Mitchell Wortsman","Mitchell Wortsman, Vivek Ramanujan, Rosanne Liu, Aniruddha Kembhavi,
  Mohammad Rastegari, Jason Yosinski, Ali Farhadi","Supermasks in Superposition","NeurIPS 2020 Camera Ready",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the Supermasks in Superposition (SupSup) model, capable of
sequentially learning thousands of tasks without catastrophic forgetting. Our
approach uses a randomly initialized, fixed base network and for each task
finds a subnetwork (supermask) that achieves good performance. If task identity
is given at test time, the correct subnetwork can be retrieved with minimal
memory usage. If not provided, SupSup can infer the task using gradient-based
optimization to find a linear superposition of learned supermasks which
minimizes the output entropy. In practice we find that a single gradient step
is often sufficient to identify the correct mask, even among 2500 tasks. We
also showcase two promising extensions. First, SupSup models can be trained
entirely without task identity information, as they may detect when they are
uncertain about new data and allocate an additional supermask for the new
training distribution. Finally the entire, growing set of supermasks can be
stored in a constant-sized reservoir by implicitly storing them as attractors
in a fixed-sized Hopfield network.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:16:44 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 16:57:02 GMT""},{""version"":""v3"",""created"":""Thu, 22 Oct 2020 00:32:49 GMT""}]","2020-10-23"
"2006.14770","Yi Liu","Pierre Derbez, Yi Liu, and Shicheng Wang","Volume of Seifert representations for graph manifolds and their finite
  covers","49 pages",,,,"math.GT math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For any closed orientable 3-manifold, there is a volume function defined on
the space of all Seifert representations of the fundamental group. The maximum
absolute value of this function agrees with the Seifert volume of the manifold
due to Brooks and Goldman.
  For any Seifert representation of a graph manifold, the authors establish an
effective formula for computing its volume, and obtain restrictions to the
representation as analogous to the Milnor--Wood inequality (about transversely
projective foliations on Seifert fiber spaces). It is shown that the Seifert
volume of any graph manifold is a rational multiple of $\pi^2$.
  Among all finite covers of a given non-geometric graph manifold, the supremum
ratio of the Seifert volume over the covering degree can be a positive number,
and can be infinite. Examples of both possibilities are discovered, and
confirmed, with the explicit values determined for the finite ones.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:17:20 GMT""}]","2020-06-29"
"2006.14771","Zheng-Hai Huang","Xueli Bai, Zheng-Hai Huang, and Mengmeng Zheng","Unique solvability of weakly homogeneous generalized variational
  inequalities",,,,,"math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  An interesting observation is that most pairs of weakly homogeneous mappings
have no strongly monotonic property, which is one of the key conditions to
ensure the unique solvability of the generalized variational inequality. This
paper focuses on studying the unique solvability of the generalized variational
inequality with a pair of weakly homogeneous mappings. By using a weaker
condition than the strong monotonicity and some additional conditions, we
achieve several results on the unique solvability of the underlying problem.
These results are exported by making use of the exceptional family of elements
or derived from new obtained Karamardian-type theorems or established under the
exceptional regularity condition. They are new even when the problem comes down
to its important subclasses studied in recent years.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:20:26 GMT""}]","2020-06-29"
"2006.14772","Michael Harrison","Donald M. Davis, Michael Harrison, David Recio-Mitter","Two robots moving geodesically on a tree","20 pages, 17 figures","Algebr. Geom. Topol. 22 (2022) 785-814","10.2140/agt.2022.22.785",,"math.GT math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the geodesic complexity of the ordered and unordered configuration
spaces of graphs in both the $\ell_1$ and $\ell_2$ metrics. We determine the
geodesic complexity of the ordered two-point $\varepsilon$-configuration space
of any star graph in both the $\ell_1$ and $\ell_2$ metrics and of the
unordered two-point configuration space of any tree in the $\ell_1$ metric, by
finding explicit geodesics from any pair to any other pair, and arranging them
into a minimal number of continuously-varying families. In each case the
geodesic complexity matches the known value of the topological complexity.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:21:37 GMT""}]","2022-08-10"
"2006.14773","Jong Chul Ye","Shujaat Khan, Jaeyoung Huh, Jong Chul Ye","Pushing the Limit of Unsupervised Learning for Ultrasound Image Artifact
  Removal",,,,,"cs.CV cs.LG eess.IV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultrasound (US) imaging is a fast and non-invasive imaging modality which is
widely used for real-time clinical imaging applications without concerning
about radiation hazard. Unfortunately, it often suffers from poor visual
quality from various origins, such as speckle noises, blurring, multi-line
acquisition (MLA), limited RF channels, small number of view angles for the
case of plane wave imaging, etc. Classical methods to deal with these problems
include image-domain signal processing approaches using various adaptive
filtering and model-based approaches. Recently, deep learning approaches have
been successfully used for ultrasound imaging field. However, one of the
limitations of these approaches is that paired high quality images for
supervised training are difficult to obtain in many practical applications. In
this paper, inspired by the recent theory of unsupervised learning using
optimal transport driven cycleGAN (OT-cycleGAN), we investigate applicability
of unsupervised deep learning for US artifact removal problems without matched
reference data. Experimental results for various tasks such as deconvolution,
speckle removal, limited data artifact removal, etc. confirmed that our
unsupervised learning method provides comparable results to supervised learning
for many practical applications.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:21:56 GMT""}]","2020-06-29"
"2006.14774","Kumar Vijay Mishra","Jiawei Liu, Kumar Vijay Mishra and Mohammad Saquib","Co-Designing Statistical MIMO Radar and In-band Full-Duplex Multi-User
  MIMO Communications","20 pages, 8 figures, 1 table",,,,"eess.SP cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a spectral sharing problem in which a statistical (or widely
distributed) multiple-input-multiple-output (MIMO) radar and an in-band
full-duplex (IBFD) multi-user MIMO (MU-MIMO) communications system concurrently
operate within the same frequency band. Prior works on joint
MIMO-radar-MIMO-communications (MRMC) systems largely focus on either colocated
MIMO radars, half-duplex MIMO communications, single-user scenarios, omit
practical constraints, or MRMC co-existence that employs separate
transmit/receive units. In this paper, we present a co-design framework that
addresses all of these issues. In particular, we jointly design the statistical
MIMO radar codes, uplink (UL)/downlink (DL) precoders of in-band full-duplex
multi-user MIMO communications, and corresponding receive filters using our
proposed metric of compounded-and-weighted sum mutual information. This
formulation includes practical constraints of UL/DL transmit powers, UL/DL
quality-of-service, and peak-to-average-power ratio. We solve the resulting
highly non-convex problem through a combination of block coordinate descent and
alternating projection methods. Extensive numerical experiments show that our
methods achieve monotonic convergence in a few iterations, improve radar target
detection over conventional codes, and yield a higher achievable data rate than
standard precoders.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:22:24 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 00:54:13 GMT""},{""version"":""v3"",""created"":""Mon, 24 Jan 2022 00:34:51 GMT""},{""version"":""v4"",""created"":""Fri, 2 Sep 2022 17:24:11 GMT""}]","2022-09-05"
"2006.14775","Gonzalo Rivera","Felipe Lepe and Gonzalo Rivera","A virtual element approximation for the pseudostress formulation of the
  Stokes eigenvalue problem",,,"10.1016/j.cma.2021.113753",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we analyze a virtual element method (VEM) for a pseudostress
formulation of the Stokes eigenvalue problem. This formulation allows to
eliminate the velocity and the pressure, leading to an elliptic formulation
where the only unknown is the pseudostress tensor. The velocity and pressure
can be recovered by a post-process. Adapting the non-compact operator theory,
we prove that our method provides a correct approximation of the spectrum and
is spurious free. We prove a priori error estimates, with optimal order, which
we confirm with some numerical tests.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:26:05 GMT""}]","2021-04-07"
"2006.14776","Liu Tonghua","Tonghua Liu, Shuo Cao, Marek Biesiada, Yuting Liu, Shuaibo Geng, and
  Yujie Lian","Testing the cosmic opacity at higher redshifts: implication from quasars
  with available UV and X-ray observations","9 figures, 9 pages, accepted for publication in ApJ",,"10.3847/1538-4357/aba0b6",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a cosmological model-independent test for the
cosmic opacity at high redshifts ($z\sim5$). We achieve this with the
opacity-dependent luminosity distances derived from nonlinear relation between
X-ray and UV emissions of quasars, combined with two types of
opacity-independent luminosity distances derived from the Hubble parameter
measurements and simulated gravitational wave (GW) events achievable with the
Einstein Telescope (ET). In the framework of two phenomenological
parameterizations adopted to describe cosmic opacity at high redshifts, our
main results show that a transparent universe is supported by the current
observational data at 2$\sigma$ confidence level. However, the derived value of
the cosmic opacity is slightly sensitive to the parametrization of $\tau(z)$,
which highlights the importance of choosing a reliable parametrization to
describe the optical depth $\tau(z)$ in the early universe. Compared with the
previous works, the combination of the quasar data and the $H(z)$/GW
observations in similar redshift ranges provides a novel way to confirm a
transparent universe ($\epsilon=0$ at higher redshifts $z\sim 5$), with an
accuracy of $\Delta \epsilon\sim 10^{-2}$. More importantly, our findings
indicate that a strong degeneracy between the cosmic opacity parameter and the
parameters characterizing the $L_{UV}-L_X$ relation of quasars, which
reinforces the necessity of proper calibration for such new type of
high-redshift standard candle (in a cosmological model-independent way).
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:30:02 GMT""}]","2020-08-19"
"2006.14777","Susan Montgomery","Yuri Bahturin and Sjusan Montgomery","Group Gradings and Actions of Pointed Hopf Algebras",,,,,"math.QA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study actions of pointed Hopf algebras on matrix algebras. Our approach is
based on known facts about group gradings of matrix algebras.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:32:19 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 04:17:12 GMT""}]","2020-07-16"
"2006.14778","Jiarong Li","Jiarong Li, Jin Lin, Philipp-Matthias Heuser, Heidi Ursula Heinrichs,
  Jinyu Xiao, Feng Liu, Martin Robinius, Yonghua Song, Detlef Stolten","Optimal Configuration of Wind-to-Ammonia with the Electric Network and
  Hydrogen Supply Chain: A Case Study of Inner Mongolia",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Converting wind energy into ammonia (WtA) has been recognized as a promising
pathway to enhance the usage of wind generation. This paper proposes a generic
optimal configuration model of WtA at the network level to minimize the ammonia
production cost by optimizing capacities and locations of WtA facilities
including wind turbines, electrolyzers, hydrogen tanks and optimizing supply
modes among regions. Specifically, the temporal fluctuation characteristics of
wind resources, the operation flexibility of the ammonia synthesis reactor and
the transport distances are considered. Three typical supply modes, i.e., the
Local WtA, the EN (electric network)-based WtA and the HSC (hydrogen supply
chain)-based WtA, combined with two energy transport modes including EN and HT
(Hydrogen truck trailers) are included with the consideration of the maximal
energy transport capacity of EN and transport distance per day of HT (500km).
Real data of Inner Mongolia (a typical province in China with rich wind
resources and existing ammonia industries) is employed to verify the
effectiveness and significance of proposed model. The effect of above
significant factors on optimal planning capacity of WtA facilities and optimal
energy transport modes is analyzed, which provides guidelines for WtA
configuration. The economic analysis shows that the average LCOA (levelized
cost of ammonia) for WtA is approximately 0.57 euro/kg in Inner Mongolia and
comparable to that for CtA (coal-to-ammonia, 0.41 euro/kg) with a reduction of
30% in capacity cost of the facilities.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:32:56 GMT""}]","2020-06-29"
"2006.14779","Gagan Bansal","Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi,
  Ece Kamar, Marco Tulio Ribeiro, Daniel S. Weld","Does the Whole Exceed its Parts? The Effect of AI Explanations on
  Complementary Team Performance","CHI'21",,,,"cs.AI cs.CL cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many researchers motivate explainable AI with studies showing that human-AI
team performance on decision-making tasks improves when the AI explains its
recommendations. However, prior studies observed improvements from explanations
only when the AI, alone, outperformed both the human and the best team. Can
explanations help lead to complementary performance, where team accuracy is
higher than either the human or the AI working solo? We conduct mixed-method
user studies on three datasets, where an AI with accuracy comparable to humans
helps participants solve a task (explaining itself in some conditions). While
we observed complementary improvements from AI augmentation, they were not
increased by explanations. Rather, explanations increased the chance that
humans will accept the AI's recommendation, regardless of its correctness. Our
result poses new challenges for human-centered AI: Can we develop explanatory
approaches that encourage appropriate trust in AI, and therefore help generate
(or improve) complementary performance?
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:34:04 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 21:23:55 GMT""},{""version"":""v3"",""created"":""Tue, 12 Jan 2021 22:50:34 GMT""}]","2021-01-14"
"2006.14780","Insu Jeon","In S. Jeon, Deokyoung Kang, Suk I. Yoo","Blind Image Deconvolution using Student's-t Prior with Overlapping Group
  Sparsity",,"2017 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)","10.1109/ICASSP.2017.7952470",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we solve blind image deconvolution problem that is to remove
blurs form a signal degraded image without any knowledge of the blur kernel.
Since the problem is ill-posed, an image prior plays a significant role in
accurate blind deconvolution. Traditional image prior assumes coefficients in
filtered domains are sparse. However, it is assumed here that there exist
additional structures over the sparse coefficients. Accordingly, we propose new
problem formulation for the blind image deconvolution, which utilizes the
structural information by coupling Student's-t image prior with overlapping
group sparsity. The proposed method resulted in an effective blind
deconvolution algorithm that outperforms other state-of-the-art algorithms.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:34:44 GMT""}]","2020-06-29"
"2006.14781","Tuo Zhao","Tuo Zhao, Han Liu, Kathryn Roeder, John Lafferty, Larry Wasserman","The huge Package for High-dimensional Undirected Graph Estimation in R","Published on JMLR in 2012",,,,"stat.ML cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe an R package named huge which provides easy-to-use functions for
estimating high dimensional undirected graphs from data. This package
implements recent results in the literature, including Friedman et al. (2007),
Liu et al. (2009, 2012) and Liu et al. (2010). Compared with the existing graph
estimation package glasso, the huge package provides extra features: (1)
instead of using Fortan, it is written in C, which makes the code more portable
and easier to modify; (2) besides fitting Gaussian graphical models, it also
provides functions for fitting high dimensional semiparametric Gaussian copula
models; (3) more functions like data-dependent model selection, data generation
and graph visualization; (4) a minor convergence problem of the graphical lasso
algorithm is corrected; (5) the package allows the user to apply both lossless
and lossy screening rules to scale up large-scale problems, making a tradeoff
between computational and statistical efficiency.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:36:47 GMT""}]","2020-06-29"
"2006.14782","Gurpriya Kaur Bhatia","Gurpriya Kaur Bhatia and Shubham Gupta and Alpana Dubey and
  Ponnurangam Kumaraguru","WorkerRep: Immutable Reputation System For Crowdsourcing Platform Based
  on Blockchain",,,,,"cs.CR cs.HC","http://creativecommons.org/licenses/by/4.0/","  Crowdsourcing is a process wherein an individual or an organisation utilizes
the talent pool present over the Internet to accomplish their task. The
existing crowdsourcing platforms and their reputation computation are
centralised and hence prone to various attacks or malicious manipulation of the
data by the central entity. A few distributed crowdsourcing platforms have been
proposed but they lack a robust reputation mechanism. So we propose a
decentralised crowdsourcing platform having an immutable reputation mechanism
to tackle these problems. It is built on top of Ethereum network and does not
require the user to trust a third party for a non malicious experience. It also
utilizes IOTAs consensus mechanism which reduces the cost for task evaluation
significantly.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:37:41 GMT""}]","2020-06-29"
"2006.14783","Naihuan Jing","Fulin Chen, Naihuan Jing, Fei Kong and Shaobin Tan","Twisted quantum affinizations and quantization of extended affine Lie
  algebras","66 pages. Final version","Trans. Amer. Math. Soc. 376 (2) (2023), 969-1039","10.1090/tran/8706",,"math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, for an arbitrary Kac-Moody Lie algebra $\mathfrak g$ and a
diagram automorphism $\mu$ of $\mathfrak g$ satisfying certain natural linking
conditions, we introduce and study a $\mu$-twisted quantum affinization algebra
$\mathcal U_\hbar\left(\hat{\mathfrak g}_\mu\right)$ of $\mathfrak g$.
  When $\mathfrak g$ is of finite type, $\mathcal U_\hbar\left(\hat{\mathfrak
g}_\mu\right)$ is Drinfeld's current algebra realization of the twisted quantum
affine algebra. When $\mu=\mathrm{id}$ and $\mathfrak g$ in affine type,
$\mathcal U_\hbar\left(\hat{\mathfrak g}_\mu\right)$ is the quantum toroidal
algebra introduced by Ginzburg, Kapranov and Vasserot. As the main results of
this paper, we first prove a triangular decomposition for $\mathcal
U_\hbar\left(\hat{\mathfrak g}_\mu\right)$. Second, we give a simple
characterization of the affine quantum Serre relations on restricted $\mathcal
U_\hbar\left(\hat{\mathfrak g}_\mu\right)$-modules in terms of ""normal order
products"". Third, we prove that the category of restricted $\mathcal
U_\hbar\left(\hat{\mathfrak g}_\mu\right)$-modules is a monoidal category and
hence obtain a topological Hopf algebra structure on the ""restricted
completion"" of $\mathcal U_\hbar\left(\hat{\mathfrak g}_\mu\right)$. Last, we
study the classical limit of $\mathcal U_\hbar\left(\hat{\mathfrak
g}_\mu\right)$ and abridge it to the quantization theory of extended affine Lie
algebras. In particular, based on a classification result of
Allison-Berman-Pianzola, we obtain the $\hbar$-deformation of all nullity $2$
extended affine Lie algebras.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:49:31 GMT""},{""version"":""v2"",""created"":""Wed, 23 Mar 2022 02:10:10 GMT""}]","2022-12-09"
"2006.14784","Peter Vaillancourt","Peter Z. Vaillancourt, J. Eric Coulter, Richard Knepper, Brandon
  Barker","Self-Scaling Clusters and Reproducible Containers to Enable Scientific
  Computing","Accepted for publication in the IEEE conference proceedings for HPEC
  2020",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Container technologies such as Docker have become a crucial component of many
software industry practices especially those pertaining to reproducibility and
portability. The containerization philosophy has influenced the scientific
computing community, which has begun to adopt - and even develop - container
technologies (such as Singularity). Leveraging containers for scientific
software often poses challenges distinct from those encountered in industry,
and requires different methodologies. This is especially true for HPC. With an
increasing number of options for HPC in the cloud (including NSF-funded cloud
projects), there is strong motivation to seek solutions that provide
flexibility to develop and deploy scientific software on a variety of
computational infrastructures in a portable and reproducible way. The
flexibility offered by cloud services enables virtual HPC clusters that scale
on-demand, and the Cyberinfrastructure Resource Integration team in the XSEDE
project has developed a set of tools which provides scalable infrastructure in
the cloud. We now present a solution which uses the Nix package manager in an
MPI-capable Docker container that is converted to Singularity. It provides
consistent installations, dependencies, and environments in each image that are
reproducible and portable across scientific computing infrastructures. We
demonstrate the utility of these containers with cluster benchmark runs in a
self-scaling virtual cluster using the Slurm scheduler deployed in the
Jetstream and Aristotle Red Cloud OpenStack clouds. We conclude this technique
is useful as a template for scientific software application containers to be
used in the XSEDE compute environment, other Singularity HPC environments, and
cloud computing environments.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 03:57:19 GMT""},{""version"":""v2"",""created"":""Mon, 3 Aug 2020 23:40:15 GMT""}]","2020-08-05"
"2006.14785","Yinglun Zhu","Yinglun Zhu and Robert Nowak","On Regret with Multiple Best Arms",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a regret minimization problem with the existence of multiple
best/near-optimal arms in the multi-armed bandit setting. We consider the case
when the number of arms/actions is comparable or much larger than the time
horizon, and make no assumptions about the structure of the bandit instance.
Our goal is to design algorithms that can automatically adapt to the unknown
hardness of the problem, i.e., the number of best arms. Our setting captures
many modern applications of bandit algorithms where the action space is
enormous and the information about the underlying instance/structure is
unavailable. We first propose an adaptive algorithm that is agnostic to the
hardness level and theoretically derive its regret bound. We then prove a lower
bound for our problem setting, which indicates: (1) no algorithm can be minimax
optimal simultaneously over all hardness levels; and (2) our algorithm achieves
a rate function that is Pareto optimal. With additional knowledge of the
expected reward of the best arm, we propose another adaptive algorithm that is
minimax optimal, up to polylog factors, over all hardness levels. Experimental
results confirm our theoretical guarantees and show advantages of our
algorithms over the previous state-of-the-art.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:01:46 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 14:55:32 GMT""}]","2020-10-23"
"2006.14786","Daejun Kim","Jangwon Ju, Daejun Kim, Kyoungmin Kim, Mingyu Kim, and Byeong-Kweon Oh","Prime-universal diagonal quadratic forms","14 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A (positive definite and integral) quadratic form is said to be
$\textit{prime-universal}$ if it represents all primes. Recently, Doyle and
Williams in [2] classified all prime-universal diagonal ternary quadratic
forms, and all prime-universal diagonal quaternary quadratic forms under two
conjectures proposed by themselves. In this article, we classify all
prime-universal diagonal quadratic forms regardless of ranks. Furthermore, we
prove, so called, $67$-Theorem for a diagonal quadratic form to be
prime-universal.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:06:37 GMT""}]","2020-06-29"
"2006.14787","Zezhou Cheng","Zezhou Cheng, Jong-Chyi Su, Subhransu Maji","On Equivariant and Invariant Learning of Object Landmark Representations","Project Page:
  https://people.cs.umass.edu/~zezhoucheng/contrastive_landmark Code:
  https://github.com/cvl-umass/ContrastLandmark",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Given a collection of images, humans are able to discover landmarks by
modeling the shared geometric structure across instances. This idea of
geometric equivariance has been widely used for the unsupervised discovery of
object landmark representations. In this paper, we develop a simple and
effective approach by combining instance-discriminative and
spatially-discriminative contrastive learning. We show that when a deep network
is trained to be invariant to geometric and photometric transformations,
representations emerge from its intermediate layers that are highly predictive
of object landmarks. Stacking these across layers in a ""hypercolumn"" and
projecting them using spatially-contrastive learning further improves their
performance on matching and few-shot landmark regression tasks. We also present
a unified view of existing equivariant and invariant representation learning
approaches through the lens of contrastive learning, shedding light on the
nature of invariances learned. Experiments on standard benchmarks for landmark
learning, as well as a new challenging one we propose, show that the proposed
approach surpasses prior state-of-the-art.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:06:56 GMT""},{""version"":""v2"",""created"":""Fri, 2 Apr 2021 20:23:49 GMT""}]","2021-04-06"
"2006.14788","Jisui Huang","Na Lei, Jisui Huang, Yuxue Ren, Emil Saucan, Zhenchang Wang","Ricci Curvature Based Volumetric Segmentation of the Auditory Ossicles","There is a fundamental problem with the layout of our paper, and we
  should design a general segmentation framework rather than just focusing on
  the ossicles",,,,"cs.CV math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The auditory ossicles that are located in the middle ear are the smallest
bones in the human body. Their damage will result in hearing loss. It is
therefore important to be able to automatically diagnose ossicles' diseases
based on Computed Tomography (CT) 3D imaging. However CT images usually include
the whole head area, which is much larger than the bones of interest, thus the
localization of the ossicles, followed by segmentation, both play a significant
role in automatic diagnosis. The commonly employed local segmentation methods
require manually selected initial points, which is a highly time consuming
process. We therefore propose a completely automatic method to locate the
ossicles which requires neither templates, nor manual labels. It relies solely
on the connective properties of the auditory ossicles themselves, and their
relationship with the surrounding tissue fluid. For the segmentation task, we
define a novel energy function and obtain the shape of the ossicles from the 3D
CT image by minimizing this new energy. Compared to the state-of-the-art
methods which usually use the gradient operator and some normalization terms,
we propose to add a Ricci curvature term to the commonly employed energy
function. We compare our proposed method with the state-of-the-art methods and
show that the performance of discrete Forman-Ricci curvature is superior to the
others.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:09:15 GMT""},{""version"":""v2"",""created"":""Sun, 16 Aug 2020 08:56:31 GMT""},{""version"":""v3"",""created"":""Wed, 2 Mar 2022 10:09:36 GMT""}]","2022-03-03"
"2006.14789","Steve Shkoller","Tristan Buckmaster and Steve Shkoller and Vlad Vicol","Shock formation and vorticity creation for 3d Euler","87 Pages, this paper builds on methods developed in arXiv:1912.04429",,,,"math.AP physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the shock formation process for the 3d non-isentropic Euler
equations with the ideal gas law, in which sounds waves interact with entropy
waves to produce vorticity. Building on our theory for isentropic flows in
[3,4], we give a constructive proof of shock formation from smooth initial
data. Specifically, we prove that there exist smooth solutions to the
non-isentropic Euler equations which form a generic stable shock with
explicitly computable blowup time, location, and direction. This is achieved by
establishing the asymptotic stability of a generic shock profile in modulated
self-similar variables, controlling the interaction of wave families via: (i)
pointwise bounds along Lagrangian trajectories, (ii) geometric vorticity
structure, and (iii) high-order energy estimates in Sobolev spaces.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:19:28 GMT""}]","2020-06-29"
"2006.14790","Emilio Angelina Angelina","Emilio Angelina, Sebastian Andujar, Oscar Parravicini, Daniel Enriz
  and Nelida Peruchena","Drug Repurposing to find Inhibitors of SARS-CoV-2 Main Protease",,,,,"q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is the strain of
coronavirus that causes coronavirus disease 2019 (COVID-19), the respiratory
illness responsible for the COVID-19 pandemic. Currently there is no known
vaccine or specific antiviral treatment for COVID-19 and so, there is an urgent
need for expedite discovery of new therapeutics to combat the disease until a
vaccine will be available worldwide. Drug repurposing is a strategy for
identifying new uses for approved drugs that has the advantage (over
conventional approaches that attempt to develop a drug from scratch) that time
frame of the overall process can be significantly reduced because of the few
number of clinical trial required. In this work, a virtual screening of
FDA-approved drugs was performed for repositioning as potential inhibitors of
the main protease Mpro of SARS-CoV-2. As a result of this study, 12 drugs are
proposed as candidates for inhibitors of the Mpro enzyme. Some of the selected
compounds are antiviral drugs that are already being tested in COVID-19
clinical trials (i.e. ribavirin) or are used to alleviate symptoms of the
disease (i.e. codeine). Surprisingly, the most promising candidate is the
naturally occurring broad spectrum antibiotic oxytetracycline. This compound
has largely outperformed the remaining selected candidates along all filtering
steps of our virtual screening protocol. If the activity of any of these drugs
is experimentally corroborated, they could be used directly in clinical trials
without the need for pre-clinical testing or safety evaluation since they are
already used as drugs for other diseases.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:19:28 GMT""}]","2020-06-29"
"2006.14791","Walter Kob","Zhen Zhang, Simona Ispas, Walter Kob","Structure and vibrational properties of sodium silicate glass surfaces",,,"10.1063/5.0019514",,"cond-mat.dis-nn cond-mat.mtrl-sci cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using molecular dynamics simulations we investigate the dependence of the
structural and vibrational properties of the surfaces of sodo-silicate glasses
on the sodium content as well as the nature of the surface. Two types of glass
surfaces are considered: A melt-formed surface (MS) in which a liquid with a
free surface has been cooled down into the glass phase and a fracture surface
(FS) obtained by tensile loading of a glass sample. We find that the MS is more
abundant in Na and non-bridging oxygen atoms than the FS and the bulk glass,
whereas the FS has higher concentration of structural defects such as
two-membered rings and under-coordinated Si than the MS. We associate these
structural differences to the production histories of the glasses and the
mobility of the Na ions. It is also found that for Na-poor systems the
fluctuations in composition and local atomic charge density decay with a
power-law as a function of distance from the surface while Na-rich systems show
an exponential decay with a typical decay length of $\approx2.3$~\AA. The
vibrational density of states shows that the presence of the surfaces leads to
a decrease of the characteristic frequencies in the system. The two-membered
rings give rise to a pronounce band at $\approx880$~cm$^{-1}$ which is in good
agreement experimental observations.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:24:02 GMT""}]","2020-10-28"
"2006.14792","Cheng Chang","Cheng Chang and Zhixiong Chen","Math Course Redesign in a Private Four Year Hispanic Serving Institute
  to Address Diverse Equitable and Inclusive Issues",,,,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We identified three most challenging points related to diverse, equitable,
and inclusive (DEI) issues. First, the majority of our students entering the
College lack the math skills essential to success in Calculus, as basic as
College Algebra, some others have a multi-year gap after graduating high
school. Almost all but a few STEM students must start from College Algebra
before they can move on to Precalculus and then Calculus. Secondly, we noted
that many students who planned to pursue STEM dropped out of their majors
because they couldn't obtain the required grade in College Algebra to move
forward. This is one of the main reasons that the enrollment of calculus
classes is consistently low. Lastly, a large portion of basic math classes are
taught by adjunct instructors, the turnover ratio among adjunct instructors is
not small. One such consequence is that many students don't have equitable
learning experiences and some students are still struggling with College
Algebra even in the calculus class. In this paper, we describe an illustrative
case study of a college-wide initiative to tackle the DEI issues.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:25:03 GMT""}]","2020-06-29"
"2006.14793","Francisco Romero","Francisco Romero, Benjamin Braun, David Cheriton","The TRaCaR Ratio: Selecting the Right Storage Technology for Active
  Dataset-Serving Databases",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Main memory database systems aim to provide users with low latency and high
throughput access to data. Most data resides in secondary storage, which is
limited by the access speed of the technology. For hot content, data resides in
DRAM, which has become increasingly expensive as datasets grow in size and
access demand. With the emergence of low-latency storage solutions such as
Flash and Intel's 3D XPoint (3DXP), there is an opportunity for these systems
to give users high Quality-of-Service while reducing the cost for providers. To
achieve high performance, providers must provision the server hosts for these
datasets with the proper amount of DRAM and secondary storage, as well as
selecting a storage technology. The growth of capacity and transaction load
overtime makes it expensive to flip back-and-forth between different storage
technologies and memory-storage combinations. Servers set up for one storage
technology must now be reconfigured, repartitioned, and potentially replaced
altogether. As more low-latency storage solutions become available, how does
one decide on the right memory-storage combination, as well as selecting a
storage technology, given a predicted trend in dataset growth and offered load?
In this paper, we describe and make the case for using the TRaCaR ratio - the
transaction rate divided by the storage capacity needed for a workload - for
allowing providers to choose the most cost-effective memory-storage combination
and storage technology given their predicted dataset trend and load
requirement. We explore how the TRaCaR ratio can be used with 3DXP and Flash
with a highly-zipfian b-tree database, and discuss potential research
directions that can leverage the ratio.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:30:30 GMT""}]","2020-06-29"
"2006.14794","Cristopher Salvi","Cristopher Salvi, Thomas Cass, James Foster, Terry Lyons, Weixin Yang","The Signature Kernel is the solution of a Goursat PDE",,,"10.1137/20M1366794",,"math.AP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, there has been an increased interest in the development of kernel
methods for learning with sequential data. The signature kernel is a learning
tool with potential to handle irregularly sampled, multivariate time series. In
""Kernels for sequentially ordered data"" the authors introduced a kernel trick
for the truncated version of this kernel avoiding the exponential complexity
that would have been involved in a direct computation. Here we show that for
continuously differentiable paths, the signature kernel solves a hyperbolic PDE
and recognize the connection with a well known class of differential equations
known in the literature as Goursat problems. This Goursat PDE only depends on
the increments of the input sequences, does not require the explicit
computation of signatures and can be solved efficiently using
state-of-the-arthyperbolic PDE numerical solvers, giving a kernel trick for the
untruncated signature kernel, with the same raw complexity as the method from
""Kernels for sequentially ordered data"", but with the advantage that the PDE
numerical scheme is well suited for GPU parallelization, which effectively
reduces the complexity by a full order of magnitude in the length of the input
sequences. In addition, we extend the previous analysis to the space of
geometric rough paths and establish, using classical results from rough path
theory, that the rough version of the signature kernel solves a rough integral
equation analogous to the aforementioned Goursat PDE. Finally, we empirically
demonstrate the effectiveness of our PDE kernel as a machine learning tool in
various machine learning applications dealing with sequential data. We release
the library sigkernel publicly available at
https://github.com/crispitagorico/sigkernel.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:36:50 GMT""},{""version"":""v2"",""created"":""Tue, 1 Sep 2020 10:24:52 GMT""},{""version"":""v3"",""created"":""Wed, 16 Sep 2020 15:34:34 GMT""},{""version"":""v4"",""created"":""Fri, 30 Oct 2020 03:35:22 GMT""},{""version"":""v5"",""created"":""Fri, 6 Nov 2020 15:35:17 GMT""},{""version"":""v6"",""created"":""Sun, 15 Nov 2020 21:45:11 GMT""},{""version"":""v7"",""created"":""Wed, 25 Nov 2020 09:42:37 GMT""},{""version"":""v8"",""created"":""Sun, 17 Jan 2021 08:20:57 GMT""},{""version"":""v9"",""created"":""Sat, 20 Mar 2021 19:58:36 GMT""}]","2021-09-30"
"2006.14795","Tung Nguyen","Tung D. Nguyen, Kathryn E. Kasmarik, Hussein A. Abbass","Q-Learning with Differential Entropy of Q-Tables",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well-known that information loss can occur in the classic and simple
Q-learning algorithm. Entropy-based policy search methods were introduced to
replace Q-learning and to design algorithms that are more robust against
information loss. We conjecture that the reduction in performance during
prolonged training sessions of Q-learning is caused by a loss of information,
which is non-transparent when only examining the cumulative reward without
changing the Q-learning algorithm itself. We introduce Differential Entropy of
Q-tables (DE-QT) as an external information loss detector to the Q-learning
algorithm. The behaviour of DE-QT over training episodes is analyzed to find an
appropriate stopping criterion during training. The results reveal that DE-QT
can detect the most appropriate stopping point, where a balance between a high
success rate and a high efficiency is met for classic Q-Learning algorithm.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:37:10 GMT""}]","2020-06-29"
"2006.14796","Yuqing Du","Yuqing Du, Stas Tiomkin, Emre Kiciman, Daniel Polani, Pieter Abbeel,
  Anca Dragan","AvE: Assistance via Empowerment","Final version from NeurIPS 2020 Conference Proceedings",,,,"cs.AI cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One difficulty in using artificial agents for human-assistive applications
lies in the challenge of accurately assisting with a person's goal(s). Existing
methods tend to rely on inferring the human's goal, which is challenging when
there are many potential goals or when the set of candidate goals is difficult
to identify. We propose a new paradigm for assistance by instead increasing the
human's ability to control their environment, and formalize this approach by
augmenting reinforcement learning with human empowerment. This task-agnostic
objective preserves the person's autonomy and ability to achieve any eventual
state. We test our approach against assistance based on goal inference,
highlighting scenarios where our method overcomes failure modes stemming from
goal ambiguity or misspecification. As existing methods for estimating
empowerment in continuous domains are computationally hard, precluding its use
in real time learned assistance, we also propose an efficient
empowerment-inspired proxy metric. Using this, we are able to successfully
demonstrate our method in a shared autonomy user study for a challenging
simulated teleoperation task with human-in-the-loop training.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:40:11 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 02:16:27 GMT""},{""version"":""v3"",""created"":""Thu, 9 Jul 2020 22:11:44 GMT""},{""version"":""v4"",""created"":""Sun, 2 Aug 2020 04:20:40 GMT""},{""version"":""v5"",""created"":""Thu, 7 Jan 2021 20:54:48 GMT""}]","2021-01-11"
"2006.14797","Abhishek Goswami","Abhishek Goswami","Mass Gap in U(1) Higgs-Yukawa model on a unit lattice","Remarks addressing fermion doubling and chiral invariance added in
  the introduction. References updated. Typos corrected","J. Math. Phys. 64, 032302 (2023)","10.1063/5.0107644",,"math-ph hep-lat hep-th math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A non perturbative proof of the mass generation of fermions via the Higgs
mechanism is given. This is done by showing exponential decay of the two point
fermionic correlation function in a weakly coupled U(1) Higgs-Yukawa theory on
a unit lattice in $d=4$. This decay implies that the Higgs boson, the photon
and the fermion all have a non zero physical mass and the theory is said to
have a mass gap.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:45:42 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 11:36:02 GMT""}]","2023-03-07"
"2006.14798","Tolga Ergen","Tolga Ergen, Mert Pilanci","Implicit Convex Regularizers of CNN Architectures: Convex Optimization
  of Two- and Three-Layer Networks in Polynomial Time","Accepted for Spotlight Presentation at ICLR 2021","International Conference on Learning Representations (ICLR), 2021",,,"cs.LG cs.CC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study training of Convolutional Neural Networks (CNNs) with ReLU
activations and introduce exact convex optimization formulations with a
polynomial complexity with respect to the number of data samples, the number of
neurons, and data dimension. More specifically, we develop a convex analytic
framework utilizing semi-infinite duality to obtain equivalent convex
optimization problems for several two- and three-layer CNN architectures. We
first prove that two-layer CNNs can be globally optimized via an $\ell_2$ norm
regularized convex program. We then show that multi-layer circular CNN training
problems with a single ReLU layer are equivalent to an $\ell_1$ regularized
convex program that encourages sparsity in the spectral domain. We also extend
these results to three-layer CNNs with two ReLU layers. Furthermore, we present
extensions of our approach to different pooling methods, which elucidates the
implicit architectural bias as convex regularizers.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:47:20 GMT""},{""version"":""v2"",""created"":""Mon, 5 Oct 2020 15:17:31 GMT""},{""version"":""v3"",""created"":""Thu, 18 Mar 2021 15:30:26 GMT""}]","2021-03-19"
"2006.14799","Asli Celikyilmaz","Asli Celikyilmaz, Elizabeth Clark, Jianfeng Gao","Evaluation of Text Generation: A Survey","47 pages (revised version)",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper surveys evaluation methods of natural language generation (NLG)
systems that have been developed in the last few years. We group NLG evaluation
methods into three categories: (1) human-centric evaluation metrics, (2)
automatic metrics that require no training, and (3) machine-learned metrics.
For each category, we discuss the progress that has been made and the
challenges still being faced, with a focus on the evaluation of recently
proposed NLG tasks and neural NLG models. We then present two examples for
task-specific NLG evaluations for automatic text summarization and long text
generation, and conclude the paper by proposing future research directions.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:52:48 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 07:04:41 GMT""}]","2021-05-19"
"2006.14800","Randall O'Reilly","Randall C. O'Reilly, Jacob L. Russin, Maryam Zolfaghar, and John
  Rohrlich","Deep Predictive Learning in Neocortex and Pulvinar","56 pages, 22 figures",,,,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  How do humans learn from raw sensory experience? Throughout life, but most
obviously in infancy, we learn without explicit instruction. We propose a
detailed biological mechanism for the widely-embraced idea that learning is
based on the differences between predictions and actual outcomes (i.e.,
predictive error-driven learning). Specifically, numerous weak projections into
the pulvinar nucleus of the thalamus generate top-down predictions, and sparse,
focal driver inputs from lower areas supply the actual outcome, originating in
layer 5 intrinsic bursting (5IB) neurons. Thus, the outcome is only briefly
activated, roughly every 100 msec (i.e., 10 Hz, alpha), resulting in a temporal
difference error signal, which drives local synaptic changes throughout the
neocortex, resulting in a biologically-plausible form of error backpropagation
learning. We implemented these mechanisms in a large-scale model of the visual
system, and found that the simulated inferotemporal (IT) pathway learns to
systematically categorize 3D objects according to invariant shape properties,
based solely on predictive learning from raw visual inputs. These categories
match human judgments on the same stimuli, and are consistent with neural
representations in IT cortex in primates.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 05:02:44 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 10:56:07 GMT""}]","2021-01-29"
"2006.14801","Qian Qin","Qian Qin, Galin L. Jones","Convergence Rates of Two-Component MCMC Samplers",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Component-wise MCMC algorithms, including Gibbs and conditional
Metropolis-Hastings samplers, are commonly used for sampling from multivariate
probability distributions. A long-standing question regarding Gibbs algorithms
is whether a deterministic-scan (systematic-scan) sampler converges faster than
its random-scan counterpart. We answer this question when the samplers involve
two components by establishing an exact quantitative relationship between the
$L^2$ convergence rates of the two samplers. The relationship shows that the
deterministic-scan sampler converges faster. We also establish qualitative
relations among the convergence rates of two-component Gibbs samplers and some
conditional Metropolis-Hastings variants. For instance, it is shown that if
some two-component conditional Metropolis-Hastings samplers are geometrically
ergodic, then so are the associated Gibbs samplers.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 05:12:30 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jan 2021 03:46:25 GMT""},{""version"":""v3"",""created"":""Sun, 9 May 2021 02:48:11 GMT""}]","2021-05-11"
"2006.14802","Hendrik Ranocha","Hendrik Ranocha and Dimitrios Mitsotakis and David I. Ketcheson","A Broad Class of Conservative Numerical Methods for Dispersive Wave
  Equations",,"Communications in Computational Physics 29.4 (2021), pp. 979-1029","10.4208/cicp.OA-2020-0119",,"math.NA cs.NA physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a general framework for designing conservative numerical methods
based on summation by parts operators and split forms in space, combined with
relaxation Runge-Kutta methods in time. We apply this framework to create new
classes of fully-discrete conservative methods for several nonlinear dispersive
wave equations: Benjamin-Bona-Mahony (BBM), Fornberg-Whitham, Camassa-Holm,
Degasperis-Procesi, Holm-Hone, and the BBM-BBM system. These full
discretizations conserve all linear invariants and one nonlinear invariant for
each system. The spatial semidiscretizations include finite difference,
spectral collocation, and both discontinuous and continuous finite element
methods. The time discretization is essentially explicit, using relaxation
Runge-Kutta methods. We implement some specific schemes from among the derived
classes, and demonstrate their favorable properties through numerical tests.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 05:12:59 GMT""},{""version"":""v2"",""created"":""Tue, 10 Nov 2020 04:12:22 GMT""}]","2021-03-09"
"2006.14803","Takeo Moroi","Masahiro Kawasaki, Kazunori Kohri, Takeo Moroi, Kai Murai, Hitoshi
  Murayama","Big-bang nucleosynthesis with sub-GeV massive decaying particles","28 pages, 11 figures",,"10.1088/1475-7516/2020/12/048","KEK-Cosmo-254, KEK-TH-2214","hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the effects of the injections of energetic photon and electron
(or positron) on the big-bang nucleosynthesis. We study the photodissociation
of light elements in the early Universe paying particular attention to the case
that the injection energy is sub-GeV and derive upper bounds on the primordial
abundances of the massive decaying particle as a function of its lifetime. We
also discuss a solution of the $^7$Li problem in this framework.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 05:37:19 GMT""}]","2021-01-06"
"2006.14804","Lin Guan","Lin Guan, Mudit Verma, Sihang Guo, Ruohan Zhang, Subbarao Kambhampati","Widening the Pipeline in Human-Guided Reinforcement Learning with
  Explanation and Context-Aware Data Augmentation",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human explanation (e.g., in terms of feature importance) has been recently
used to extend the communication channel between human and agent in interactive
machine learning. Under this setting, human trainers provide not only the
ground truth but also some form of explanation. However, this kind of human
guidance was only investigated in supervised learning tasks, and it remains
unclear how to best incorporate this type of human knowledge into deep
reinforcement learning. In this paper, we present the first study of using
human visual explanations in human-in-the-loop reinforcement learning (HRL). We
focus on the task of learning from feedback, in which the human trainer not
only gives binary evaluative ""good"" or ""bad"" feedback for queried state-action
pairs, but also provides a visual explanation by annotating relevant features
in images. We propose EXPAND (EXPlanation AugmeNted feeDback) to encourage the
model to encode task-relevant features through a context-aware data
augmentation that only perturbs irrelevant features in human salient
information. We choose five tasks, namely Pixel-Taxi and four Atari games, to
evaluate the performance and sample efficiency of this approach. We show that
our method significantly outperforms methods leveraging human explanation that
are adapted from supervised learning, and Human-in-the-loop RL baselines that
only utilize evaluative feedback.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 05:40:05 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 23:08:58 GMT""},{""version"":""v3"",""created"":""Fri, 25 Sep 2020 23:59:18 GMT""},{""version"":""v4"",""created"":""Wed, 29 Sep 2021 18:32:45 GMT""},{""version"":""v5"",""created"":""Tue, 26 Oct 2021 19:16:10 GMT""}]","2021-10-28"
"2006.14805","Ray Norris","Ray P. Norris, Huib T. Intema, Anna D. Kapinska, Baerbel S.
  Koribalski, Emil Lenc, L. Rudnick, Rami Alsaberi, Craig Anderson, G. E.
  Anderson, E. Crawford, Roland Crocker, Jayanne English, Miroslav D.
  Filipovic, Andrew M. Hopkins, Natasha Hurley-Walker, Susumu Inoue, Kieran
  Luken, Peter Macgregor, Pero Manojlovic, Josh Marvil, Andrew N. O'Brien,
  Wasim Raja, Devika Shobhana, Tiziana Venturi, Jordan D. Collier, Catherine
  Hale, Aidan Hotan, Vanessa Moss, and Matthew Whiting","Unexpected Circular Radio Objects at High Galactic Latitude","Accepted for publication by PASA","Publ. Astron. Soc. Aust. 38 (2021) e003","10.1017/pasa.2020.52",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have found a class of circular radio objects in the Evolutionary Map of
the Universe Pilot Survey, using the Australian Square Kilometre Array
Pathfinder telescope. The objects appear in radio images as circular
edge-brightened discs, about one arcmin diameter, that are unlike other objects
previously reported in the literature. We explore several possible mechanisms
that might cause these objects, but none seems to be a compelling explanation.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 05:44:47 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 06:21:39 GMT""}]","2021-01-20"
"2006.14806","Xiang Deng","Xiang Deng, Huan Sun, Alyssa Lees, You Wu, Cong Yu","TURL: Table Understanding through Representation Learning","Accepted to VLDB 2021. Extended version with experiments added during
  revision. Our source code, benchmark, as well as pre-trained models will be
  available on https://github.com/sunlab-osu/TURL",,,,"cs.IR cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Relational tables on the Web store a vast amount of knowledge. Owing to the
wealth of such tables, there has been tremendous progress on a variety of tasks
in the area of table understanding. However, existing work generally relies on
heavily-engineered task-specific features and model architectures. In this
paper, we present TURL, a novel framework that introduces the
pre-training/fine-tuning paradigm to relational Web tables. During
pre-training, our framework learns deep contextualized representations on
relational tables in an unsupervised manner. Its universal model design with
pre-trained representations can be applied to a wide range of tasks with
minimal task-specific fine-tuning. Specifically, we propose a structure-aware
Transformer encoder to model the row-column structure of relational tables, and
present a new Masked Entity Recovery (MER) objective for pre-training to
capture the semantics and knowledge in large-scale unlabeled data. We
systematically evaluate TURL with a benchmark consisting of 6 different tasks
for table understanding (e.g., relation extraction, cell filling). We show that
TURL generalizes well to all tasks and substantially outperforms existing
methods in almost all instances.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 05:44:54 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 02:47:41 GMT""}]","2020-12-04"
"2006.14807","Eric Hall","Eric J. Hall and S{\o}ren Taverniers and Markos A. Katsoulakis and
  Daniel M. Tartakovsky","GINNs: Graph-Informed Neural Networks for Multiscale Physics","20 pages, 8 figures",,"10.1016/j.jcp.2021.110192",,"physics.comp-ph cs.NA math.NA stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the concept of a Graph-Informed Neural Network (GINN), a hybrid
approach combining deep learning with probabilistic graphical models (PGMs)
that acts as a surrogate for physics-based representations of multiscale and
multiphysics systems. GINNs address the twin challenges of removing intrinsic
computational bottlenecks in physics-based models and generating large data
sets for estimating probability distributions of quantities of interest (QoIs)
with a high degree of confidence. Both the selection of the complex physics
learned by the NN and its supervised learning/prediction are informed by the
PGM, which includes the formulation of structured priors for tunable control
variables (CVs) to account for their mutual correlations and ensure physically
sound CV and QoI distributions. GINNs accelerate the prediction of QoIs
essential for simulation-based decision-making where generating sufficient
sample data using physics-based models alone is often prohibitively expensive.
Using a real-world application grounded in supercapacitor-based energy storage,
we describe the construction of GINNs from a Bayesian network-embedded
homogenized model for supercapacitor dynamics, and demonstrate their ability to
produce kernel density estimates of relevant non-Gaussian, skewed QoIs with
tight confidence intervals.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 05:47:45 GMT""}]","2021-03-17"
"2006.14808","Masayoshi Aritsugi","Riku Anegawa and Masayoshi Aritsugi","Text Detection on Roughly Placed Books by Leveraging a Learning-based
  Model Trained with Another Domain Data",,,,,"cs.CV cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text detection enables us to extract rich information from images. In this
paper, we focus on how to generate bounding boxes that are appropriate to grasp
text areas on books to help implement automatic text detection. We attempt not
to improve a learning-based model by training it with an enough amount of data
in the target domain but to leverage it, which has been already trained with
another domain data. We develop algorithms that construct the bounding boxes by
improving and leveraging the results of a learning-based method. Our algorithms
can utilize different learning-based approaches to detect scene texts.
Experimental evaluations demonstrate that our algorithms work well in various
situations where books are roughly placed.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 05:53:23 GMT""}]","2020-06-29"
"2006.14809","Al-Waleed El-Sayed","Al-Waleed El-Sayed and Stephen Hughes","Quasinormal mode theory of elastic Purcell factors and Fano resonances
  of optomechanical beams","11 pages, 7 figures",,"10.1103/PhysRevResearch.2.043290",,"physics.optics cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a quasinormal mode theory of mechanical open-cavity modes for
optomechanical resonators, and demonstrate the importance of using a
generalized (complex) effective mode volume and the phase of the quasinormal
mode. We first generalize and fix the normal mode theories of the elastic
Purcell factor, and then show a striking example of coupled quasinormal modes
yielding a pronounced Fano resonance. Our theory is exemplified and confirmed
by full three-dimensional calculations on optomechanical beams, but the general
findings apply to a wide range of mechanical cavity modes. This quasinormal
mechanical mode formalism, when also coupled with a quasinormal theory of
optical cavities, offers a unified framework for describing a wide range of
optomechanical structures where dissipation is an inherent part of the
resonator modes.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 05:57:08 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 22:15:50 GMT""},{""version"":""v3"",""created"":""Tue, 27 Oct 2020 21:29:43 GMT""}]","2020-12-16"
"2006.14810","Sebastian Pokutta","Sebastian Pokutta","Restarting Algorithms: Sometimes there is Free Lunch",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this overview article we will consider the deliberate restarting of
algorithms, a meta technique, in order to improve the algorithm's performance,
e.g., convergence rates or approximation guarantees. One of the major
advantages is that restarts are relatively black box, not requiring any
(significant) changes to the base algorithm that is restarted or the underlying
argument, while leading to potentially significant improvements, e.g., from
sublinear to linear rates of convergence. Restarts are widely used in different
fields and have become a powerful tool to leverage additional information that
has not been directly incorporated in the base algorithm or argument. We will
review restarts in various settings from continuous optimization, discrete
optimization, and submodular function maximization where they have delivered
impressive results.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:02:35 GMT""}]","2020-06-29"
"2006.14811","Yu Tian","Yu Tian, Gabriel Maicas, Leonardo Zorron Cheng Tao Pu, Rajvinder
  Singh, Johan W. Verjans, Gustavo Carneiro","Few-Shot Anomaly Detection for Polyp Frames from Colonoscopy","Accept at MICCAI 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomaly detection methods generally target the learning of a normal image
distribution (i.e., inliers showing healthy cases) and during testing, samples
relatively far from the learned distribution are classified as anomalies (i.e.,
outliers showing disease cases). These approaches tend to be sensitive to
outliers that lie relatively close to inliers (e.g., a colonoscopy image with a
small polyp). In this paper, we address the inappropriate sensitivity to
outliers by also learning from inliers. We propose a new few-shot anomaly
detection method based on an encoder trained to maximise the mutual information
between feature embeddings and normal images, followed by a few-shot score
inference network, trained with a large set of inliers and a substantially
smaller set of outliers. We evaluate our proposed method on the clinical
problem of detecting frames containing polyps from colonoscopy video sequences,
where the training set has 13350 normal images (i.e., without polyps) and less
than 100 abnormal images (i.e., with polyps). The results of our proposed model
on this data set reveal a state-of-the-art detection result, while the
performance based on different number of anomaly samples is relatively stable
after approximately 40 abnormal training images.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:08:46 GMT""}]","2020-06-29"
"2006.14812","Doyun Koo","Myungho Kim, Doyun Koo","Polynomial invariants on matrices and partition, Brauer algebra","20 pages, changes of wrong conditions, typos, and grammar. Brauer
  algebras. Journal of Algebra (2021)",,"10.1016/j.jalgebra.2021.01.005",,"math.RA math.CO math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We identify the dimension of the centralizer of the symmetric group
$\mathfrak{S}_d$ in the partition algebra $\mathcal{A}_d(\delta)$ and in the
Brauer algebra $\mathcal{B}_d(\delta)$ with the number of multidigraphs with
$d$ arrows and the number of disjoint union of directed cycles with $d$ arrows,
respectively. Using Schur-Weyl duality as a fundamental theory, we conclude
that each centralizer is related with the $G$-invariant space
$P^d(M_n(\mathbf{k}))^G$ of degree $d$ homogeneous polynomials on $n \times n$
matrices, where $G$ is the orthogonal group and the group of permutation
matrices, respectively. Our approach gives a uniform way to show that the
dimensions of $P^d(M_n(\mathbf{k}))^G$ are stable for sufficiently large $n$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:14:20 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 09:33:08 GMT""}]","2021-03-08"
"2006.14813","Sergio Da Silva","YG Liang, Sergio Da Silva, Yang Zhang","The Tensor Rank Problem over the Quaternions","24 pages, no figures","Linear Algebra and Its Applications (2021), Volume 620, 37-60","10.1016/j.laa.2021.02.019",,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a nontrivial bound on the rank of any tensor $T$ over the
quaternions $\mathbb{H}$ in the $n_1\times n_2\times n_3$ cases where $2\leq
n_i\leq 3$. We describe a decomposition of $T$ into $3$ simple tensors in the
$2\times 2\times 2$ case. We also show that the upper bound is the best
possible for some of the cases, and we provide various partial results
involving tensor decompositions over $\mathbb{C}$ and $\mathbb{H}$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:22:43 GMT""},{""version"":""v2"",""created"":""Sat, 19 Dec 2020 07:01:54 GMT""}]","2021-03-04"
"2006.14814","Markus Hess","Markus Hess","A pure-jump mean-reverting short rate model","Published at https://doi.org/10.15559/20-VMSTA152 in the Modern
  Stochastics: Theory and Applications (https://vmsta.org/) by VTeX
  (http://www.vtex.lt/)","Modern Stochastics: Theory and Applications 2020, Vol. 7, No. 2,
  113-134","10.15559/20-VMSTA152","VTeX-VMSTA-VMSTA152","q-fin.MF math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new multi-factor short rate model is presented which is bounded from below
by a real-valued function of time. The mean-reverting short rate process is
modeled by a sum of pure-jump Ornstein--Uhlenbeck processes such that the
related bond prices possess affine representations. Also the dynamics of the
associated instantaneous forward rate is provided and a condition is derived
under which the model can be market-consistently calibrated. The analytical
tractability of this model is illustrated by the derivation of an explicit
plain vanilla option price formula. With view on practical applications,
suitable probability distributions are proposed for the driving jump processes.
The paper is concluded by presenting a post-crisis extension of the proposed
short and forward rate model.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:24:11 GMT""}]","2020-06-29"
"2006.14815","Weiwen Jiang","Weiwen Jiang, Jinjun Xiong, Yiyu Shi","A Co-Design Framework of Neural Networks and Quantum Circuits Towards
  Quantum Advantage","14 pages, 11 figures","Nature Communications 2021","10.1038/s41467-020-20729-5",,"quant-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the pursuit of quantum advantages in various applications, the power
of quantum computers in neural network computations has mostly remained
unknown, primarily due to a missing link that effectively designs a neural
network model suitable for quantum circuit implementation. In this article, we
present the co-design framework, namely QuantumFlow, to provide such a missing
link. QuantumFlow consists of novel quantum-friendly neural networks (QF-Nets),
a mapping tool (QF-Map) to generate the quantum circuit (QF-Circ) for QF-Nets,
and an execution engine (QF-FB). We discover that, in order to make full use of
the strength of quantum representation, it is best to represent data in a
neural network as either random variables or numbers in unitary matrices, such
that they can be directly operated by the basic quantum logical gates. Based on
these data representations, we propose two quantum friendly neural networks,
QF-pNet and QF-hNet in QuantumFlow. QF-pNet using random variables has better
flexibility, and can seamlessly connect two layers without measurement with
more qbits and logical gates than QF-hNet. On the other hand, QF-hNet with
unitary matrices can encode 2^k data into k qbits, and a novel algorithm can
guarantee the cost complexity to be O(k^2). Compared to the cost of O(2^k)in
classical computing, QF-hNet demonstrates the quantum advantages. Evaluation
results show that QF-pNet and QF-hNet can achieve 97.10% and 98.27% accuracy,
respectively. Results further show that for input sizes of neural computation
grow from 16 to 2,048, the cost reduction of QuantumFlow increased from 2.4x to
64x. Furthermore, on MNIST dataset, QF-hNet can achieve accuracy of 94.09%,
while the cost reduction against the classical computer reaches 10.85x. To the
best of our knowledge, QuantumFlow is the first work to demonstrate the
potential quantum advantage on neural network computation.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:25:03 GMT""},{""version"":""v2"",""created"":""Wed, 9 Sep 2020 14:19:57 GMT""}]","2021-06-25"
"2006.14816","Alexander A. Gushchin","Alexander A. Gushchin","Single jump filtrations and local martingales","Published at https://doi.org/10.15559/20-VMSTA153 in the Modern
  Stochastics: Theory and Applications (https://vmsta.org/) by VTeX
  (http://www.vtex.lt/)","Modern Stochastics: Theory and Applications 2020, Vol. 7, No. 2,
  135-156","10.15559/20-VMSTA153","VTeX-VMSTA-VMSTA153","math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A single jump filtration $({\mathscr{F}}_t)_{t\in \mathbb{R}_+}$ generated by
a random variable $\gamma$ with values in $\overline{\mathbb{R}}_+$ on a
probability space $(\Omega ,{\mathscr{F}},\mathsf{P})$ is defined as follows: a
set $A\in {\mathscr{F}}$ belongs to ${\mathscr{F}}_t$ if $A\cap \{\gamma >t\}$
is either $\varnothing$ or $\{\gamma >t\}$. A process $M$ is proved to be a
local martingale with respect to this filtration if and only if it has a
representation $M_t=F(t){\mathbb{1}}_{\{t<\gamma
\}}+L{\mathbb{1}}_{\{t\geqslant \gamma \}}$, where $F$ is a deterministic
function and $L$ is a random variable such that $\mathsf{E}|M_t|<\infty$ and
$\mathsf{E}(M_t)=\mathsf{E}(M_0)$ for every $t\in \{t\in
\mathbb{R}_+:{\mathsf{P}}(\gamma \geqslant t)>0\}$. This result seems to be new
even in a special case that has been studied in the literature, namely, where
${\mathscr{F}}$ is the smallest $\sigma$-field with respect to which $\gamma$
is measurable (and then the filtration is the smallest one with respect to
which $\gamma$ is a stopping time). As a consequence, a full description of all
local martingales is given and they are classified according to their global
behaviour.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:32:02 GMT""}]","2020-06-29"
"2006.14817","Ferran Garcia Gonzalez","Ferran Garcia, Frank R. N. Chambers, Anna L. Watts","Deep model simulation of polar vortices in gas giant atmospheres","18 pages, 13 figures and 3 tables",,"10.1093/mnras/staa2962",,"astro-ph.EP physics.ao-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Cassini and Juno probes have revealed large coherent cyclonic vortices in
the polar regions of Saturn and Jupiter, a dramatic contrast from the east-west
banded jet structure seen at lower latitudes. Debate has centered on whether
the jets are shallow, or extend to greater depths in the planetary envelope.
Recent experiments and observations have demonstrated the relevance of deep
convection models to a successful explanation of jet structure and cyclonic
coherent vortices away from the polar regions have been simulated recently
including an additional stratified shallow layer. Here we present new
convective models able to produce long-lived polar vortices. Using simulation
parameters relevant for giant planet atmospheres we find flow regimes that are
in agreement with geostrophic turbulence (GT) theory in rotating convection for
the formation of large scale coherent structures via an upscale energy transfer
fully three-dimensional. Our simulations generate polar characteristics
qualitatively similar to those seen by Juno and Cassini: they match the
structure of cyclonic vortices seen on Jupiter; or can account for the
existence of a strong polar vortex extending downwards to lower latitudes with
a marked spiral morphology and the hexagonal pattern seen on Saturn. Our
findings indicate that these vortices can be generated deep in the planetary
interior. A transition differentiating these two polar flows regimes is
described, interpreted in terms of different force balances and compared with
previous shallow atmospheric models which characterised polar vortex dynamics
in giant planets. In addition, the heat transport properties are investigated
confirming recent scaling laws obtained in the context of reduced models of GT.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:34:56 GMT""},{""version"":""v2"",""created"":""Wed, 23 Sep 2020 09:22:54 GMT""}]","2020-10-07"
"2006.14818","Alexander Kukush","Alexander Kukush, Ivan Senko","Prediction in polynomial errors-in-variables models","Published at https://doi.org/10.15559/20-VMSTA154 in the Modern
  Stochastics: Theory and Applications (https://vmsta.org/) by VTeX
  (http://www.vtex.lt/)","Modern Stochastics: Theory and Applications 2020, Vol. 7, No. 2,
  203-219","10.15559/20-VMSTA154","VTeX-VMSTA-VMSTA154","math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A multivariate errors-in-variables (EIV) model with an intercept term, and a
polynomial EIV model are considered. Focus is made on a structural
homoskedastic case, where vectors of covariates are i.i.d. and measurement
errors are i.i.d. as well. The covariates contaminated with errors are normally
distributed and the corresponding classical errors are also assumed normal. In
both models, it is shown that (inconsistent) ordinary least squares estimators
of regression parameters yield an a.s. approximation to the best prediction of
response given the values of observable covariates. Thus, not only in the
linear EIV, but in the polynomial EIV models as well, consistent estimators of
regression parameters are useless in the prediction problem, provided the size
and covariance structure of observation errors for the predicted subject do not
differ from those in the data used for the model fitting.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:36:08 GMT""}]","2020-06-29"
"2006.14819","Mohamed Marzougue","Mohamed Marzougue, Yaya Sagna","Irregular barrier reflected BDSDEs with general jumps under stochastic
  Lipschitz and linear growth conditions","Published at https://doi.org/10.15559/20-VMSTA155 in the Modern
  Stochastics: Theory and Applications (https://vmsta.org/) by VTeX
  (http://www.vtex.lt/)","Modern Stochastics: Theory and Applications 2020, Vol. 7, No. 2,
  157-190","10.15559/20-VMSTA155","VTeX-VMSTA-VMSTA155","math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a solution is given to reflected backward doubly stochastic
differential equations when the barrier is not necessarily right-continuous,
and the noise is driven by two independent Brownian motions and an independent
Poisson random measure. The existence and uniqueness of the solution is shown,
firstly when the coefficients are stochastic Lipschitz, and secondly by
weakening the conditions on the stochastic growth coefficient.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:41:07 GMT""}]","2020-06-29"
"2006.14820","Shonosuke Sugasawa","Takumi Saegusa, Shonosuke Sugasawa, and Partha Lahiri","Parametric Bootstrap Confidence Intervals for the Multivariate
  Fay-Herriot Model","21 pages",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The multivariate Fay-Herriot model is quite effective in combining
information through correlations among small area survey estimates of related
variables or historical survey estimates of the same variable or both. Though
the literature on small area estimation is already very rich, construction of
second-order efficient confidence intervals from multivariate models have so
far received very little attention. In this paper, we develop a parametric
bootstrap method for constructing a second-order efficient confidence interval
for a general linear combination of small area means using the multivariate
Fay-Herriot normal model. The proposed parametric bootstrap method replaces
difficult and tedious analytical derivations by the power of efficient
algorithm and high speed computer. Moreover, the proposed method is more
versatile than the analytical method because the parametric bootstrap method
can be easily applied to any method of model parameter estimation and any
specific structure of the variance-covariance matrix of the multivariate
Fay-Herriot model avoiding all the cumbersome and time-consuming calculations
required in the analytical method. We apply our proposed methodology in
constructing confidence intervals for the median income of four-person families
for the fifty states and the District of Columbia in the United States. Our
data analysis demonstrates that the proposed parametric bootstrap method
generally provides much shorter confidence intervals compared to the
corresponding traditional direct method. Moreover, the confidence intervals
obtained from the multivariate model is generally shorter than the
corresponding univariate model indicating the potential advantage of exploiting
correlations of median income of four-person families with median incomes of
three and five person families.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:41:08 GMT""}]","2020-06-29"
"2006.14821","Oksana Banna","Oksana Banna, Filipp Buryak, Yuliya Mishura","Distance from fractional Brownian motion with associated Hurst index
  $0<H<1/2$ to the subspaces of Gaussian martingales involving power integrands
  with an arbitrary positive exponent","Published at https://doi.org/10.15559/20-VMSTA156 in the Modern
  Stochastics: Theory and Applications (https://vmsta.org/) by VTeX
  (http://www.vtex.lt/)","Modern Stochastics: Theory and Applications 2020, Vol. 7, No. 2,
  191-202","10.15559/20-VMSTA156","VTeX-VMSTA-VMSTA156","math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We find the best approximation of the fractional Brownian motion with the
Hurst index $H\in (0,1/2)$ by Gaussian martingales of the form $\int
_0^ts^{\gamma}dW_s$, where $W$ is a Wiener process, $\gamma >0$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:47:04 GMT""}]","2020-06-29"
"2006.14822","Shruti Jadon","Shruti Jadon","A survey of loss functions for semantic segmentation","5 pages, 5 figures, 2 tables","2020 IEEE International Conference on Computational Intelligence
  in Bioinformatics and Computational Biology","10.1109/CIBCB48159.2020.9277638",,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Image Segmentation has been an active field of research as it has a wide
range of applications, ranging from automated disease detection to self-driving
cars. In the past five years, various papers came up with different objective
loss functions used in different cases such as biased data, sparse
segmentation, etc. In this paper, we have summarized some of the well-known
loss functions widely used for Image Segmentation and listed out the cases
where their usage can help in fast and better convergence of a model.
Furthermore, we have also introduced a new log-cosh dice loss function and
compared its performance on the NBFS skull-segmentation open-source data-set
with widely used loss functions. We also showcased that certain loss functions
perform well across all data-sets and can be taken as a good baseline choice in
unknown data distribution scenarios. Our code is available at Github:
https://github.com/shruti-jadon/Semantic-Segmentation-Loss-Functions.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:49:18 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 18:24:31 GMT""},{""version"":""v3"",""created"":""Wed, 12 Aug 2020 06:43:50 GMT""},{""version"":""v4"",""created"":""Thu, 3 Sep 2020 01:14:34 GMT""}]","2020-12-15"
"2006.14823","Jean Van Schaftingen","Antonin Monteil, R\'emy Rodiac, Jean Van Schaftingen","Renormalised energies and renormalisable singular harmonic maps into a
  compact manifold on planar domains","41 pages, minor corrections","Math. Annal. 383 (2022), 1061-1125","10.1007/s00208-021-02204-8",,"math.AP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define renormalised energies for maps that describe the first-order
asymptotics of harmonic maps outside of singularities arising due to
obstructions generated by the boundary data and the mutliple connectedness of
the target manifold. The constructions generalise the definition by Bethuel,
Brezis and H\'elein for the circle (Ginzburg-Landau vortices, 1994). In
general, the singularities are geometrical objects and the dependence on
homotopic singularities can be studied through a new notion of synharmony. The
renormalised energies are showed to be coercive and Lipschitz-continuous. The
renormalised energies are associated to minimising renormalisable singular
harmonic maps and minimising configurations of points can be characterised by
the flux of the stress-energy tensor at the singularities. We compute the
singular energy and the renormalised energy in several particular cases.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:53:19 GMT""},{""version"":""v2"",""created"":""Tue, 1 Sep 2020 05:18:19 GMT""},{""version"":""v3"",""created"":""Mon, 26 Apr 2021 12:52:39 GMT""}]","2022-08-09"
"2006.14824","Marian-Andrei Rizoiu","Adriana-Simona Mihaita, Zac Papachatgis and Marian-Andrei Rizoiu","Graph modelling approaches for motorway traffic flow prediction",,"In 23rd IEEE International Conference on Intelligent
  Transportation Systems (ITSC'20) (pp. 1--8). Rhodes, Greece (2020)",,,"eess.SP cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traffic flow prediction, particularly in areas that experience highly dynamic
flows such as motorways, is a major issue faced in traffic management. Due to
increasingly large volumes of data sets being generated every minute, deep
learning methods have been used extensively in the latest years for both short
and long term prediction. However, such models, despite their efficiency, need
large amounts of historical information to be provided, and they take a
considerable amount of time and computing resources to train, validate and
test. This paper presents two new spatial-temporal approaches for building
accurate short-term prediction along a popular motorway in Sydney, by making
use of the graph structure of the motorway network (including exits and
entries). The methods are built on proximity-based approaches, denoted
backtracking and interpolation, which uses the most recent and closest traffic
flow information for each of the target counting stations along the motorway.
The results indicate that for short-term predictions (less than 10 minutes into
the future), the proposed graph-based approaches outperform state-of-the-art
deep learning models, such as long-term short memory, convolutional neuronal
networks or hybrid models.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:54:14 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jul 2020 05:28:58 GMT""}]","2020-07-07"
"2006.14825","Wei Wang","Long-Bin Chen, Wei Wang, Ruilin Zhu","Next-to-next-to-leading order corrections to quark Quasi parton
  distribution functions","9 pages, 1 figure; comments and discussions are warmly welcome; v2:
  10 pages, 2 figures, an error corrected, and numerical results added","Phys. Rev. Lett. 126, 072002 (2021)","10.1103/PhysRevLett.126.072002",,"hep-ph hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the next-to-next-to-leading order (NNLO) calculation of quark
quasi parton distribution functions (PDFs) in the large momentum effective
theory. The nontrivial factorization at this order is established explicitly
and the full analytic matching coefficients between the quasi distribution and
the lightcone distribution are derived. We demonstrate that the NNLO numerical
contributions can improve the behavior of the extracted PDFs sizably. With the
unprecedented precision study of nucleon tomography at the planned electron-ion
collider, high precision Lattice QCD simulations with our NNLO results
implemented will enable to test the QCD theory and more precise results on the
PDFs of nucleons will be obtained.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:55:36 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 09:16:58 GMT""},{""version"":""v3"",""created"":""Tue, 8 Sep 2020 16:25:39 GMT""},{""version"":""v4"",""created"":""Sat, 16 Jan 2021 02:38:45 GMT""}]","2021-02-24"
"2006.14826","Markus Diehl","Gunnar S. Bali, Luca Castagnini, Markus Diehl, Jonathan R. Gaunt,
  Benjamin Gl\""a{\ss}le, Andreas Sch\""afer, Christian Zimmermann","Double parton distributions in the pion from lattice QCD","60 pages, 33 figures. v2: added clarifications and a comparison with
  quark model results",,"10.1007/JHEP02(2021)067","DESY 20-098, CERN-TH-2020-086","hep-lat hep-ph","http://creativecommons.org/licenses/by/4.0/","  We perform a lattice study of double parton distributions in the pion, using
the relationship between their Mellin moments and pion matrix elements of two
local currents. A good statistical signal is obtained for almost all relevant
Wick contractions. We investigate correlations in the spatial distribution of
two partons in the pion, as well as correlations involving the parton
polarisation. The patterns we observe depend significantly on the quark mass.
We investigate the assumption that double parton distributions approximately
factorise into a convolution of single parton distributions.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:58:25 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jan 2021 15:47:41 GMT""}]","2021-02-24"
"2006.14827","Xiangyu Zhao","Xiangyu Zhao, Haochen Liu, Hui Liu, Jiliang Tang, Weiwei Guo, Jun Shi,
  Sida Wang, Huiji Gao, Bo Long","Memory-efficient Embedding for Recommendations",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Practical large-scale recommender systems usually contain thousands of
feature fields from users, items, contextual information, and their
interactions. Most of them empirically allocate a unified dimension to all
feature fields, which is memory inefficient. Thus it is highly desired to
assign different embedding dimensions to different feature fields according to
their importance and predictability. Due to the large amounts of feature fields
and the nuanced relationship between embedding dimensions with feature
distributions and neural network architectures, manually allocating embedding
dimensions in practical recommender systems can be very difficult. To this end,
we propose an AutoML based framework (AutoDim) in this paper, which can
automatically select dimensions for different feature fields in a data-driven
fashion. Specifically, we first proposed an end-to-end differentiable framework
that can calculate the weights over various dimensions for feature fields in a
soft and continuous manner with an AutoML based optimization algorithm; then we
derive a hard and discrete embedding component architecture according to the
maximal weights and retrain the whole recommender framework. We conduct
extensive experiments on benchmark datasets to validate the effectiveness of
the AutoDim framework.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:07:59 GMT""},{""version"":""v2"",""created"":""Wed, 21 Oct 2020 19:15:37 GMT""}]","2020-10-23"
"2006.14828","Guus Regts","Pjotr Buys, Andreas Galanis, Viresh Patel, Guus Regts","Lee-Yang zeros and the complexity of the ferromagnetic Ising model on
  bounded-degree graphs","40 pages, 1 figure. We have included a new result for the case $b\in
  [1-2/\Delta,1)$. This essentially gives a complete picture of the complexity
  of the problem. An extended abstract has been presented at SODA 2021",,,,"cs.CC cs.DS math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the computational complexity of approximating the partition function
of the ferromagnetic Ising model with the external field parameter $\lambda$ on
the unit circle in the complex plane. Complex-valued parameters for the Ising
model are relevant for quantum circuit computations and phase transitions in
statistical physics, but have also been key in the recent deterministic
approximation scheme for all $|\lambda|\neq 1$ by Liu, Sinclair, and
Srivastava. Here, we focus on the unresolved complexity picture on the unit
circle, and on the tantalising question of what happens around $\lambda=1$,
where on one hand the classical algorithm of Jerrum and Sinclair gives a
randomised approximation scheme on the real axis suggesting tractability, and
on the other hand the presence of Lee-Yang zeros alludes to computational
hardness.
  Our main result establishes a sharp computational transition at the point
$\lambda=1$, and more generally on the entire unit circle. For an integer
$\Delta\geq 3$ and edge interaction parameter $b\in (0,1)$ we show #P-hardness
for approximating the partition function on graphs of maximum degree $\Delta$
on the arc of the unit circle where the Lee-Yang zeros are dense. This result
contrasts with known approximation algorithms when $|\lambda|\neq 1$ or when
$\lambda$ is in the complementary arc around $1$ of the unit circle. Our work
thus gives a direct connection between the presence/absence of Lee-Yang zeros
and the tractability of efficiently approximating the partition function on
bounded-degree graphs.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:09:04 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 13:34:10 GMT""},{""version"":""v3"",""created"":""Fri, 22 Jan 2021 12:57:14 GMT""}]","2021-01-25"
"2006.14829","Wen Chen","Ming Ding, David Lopez-Perez, Ruiqi Xue, Athanasios V. Vasilakos, Wen
  Chen","On Dynamic Time Division Duplex Transmissions for Small Cell Networks","TVT",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the promising benefits of dynamic Time Division Duplex (TDD), in
this paper, we use a unified framework to investigate both the technical issues
of applying dynamic TDD in homogeneous small cell networks (HomSCNs), and the
feasibility of introducing dynamic TDD into heterogeneous networks (HetNets).
First, HomSCNs are analyzed, and a small cell BS scheduler that dynamically and
independently schedules DL and UL subframes is presented, such that load
balancing between the DL and the UL traffic can be achieved. Moreover, the
effectiveness of various inter-link interference mitigation (ILIM) schemes as
well as their combinations, is systematically investigated and compared.
Besides, the interesting possibility of partial interference cancellation (IC)
is also explored. Second,based on the proposed schemes, the joint operation of
dynamic TDD together with cell range expansion (CRE) and almost blank subframe
(ABS) in HetNets is studied. In this regard, scheduling polices in small cells
and an algorithm to derive the appropriate macrocell traffic off-load and ABS
duty cycle under dynamic TDD operation are proposed. Moreover, the full IC and
the partial IC schemes are investigated for dynamic TDD in HetNets. The user
equipment (UE) packet throughput performance of the proposed/discussed schemes
is benchmarked using system-level simulations.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:14:39 GMT""}]","2020-06-29"
"2006.14830","Vincent A Traag","V.A. Traag, M. Malgarini, S. Sarlo","Metrics and peer review agreement at the institutional level",,,,,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past decades, many countries have started to fund academic
institutions based on the evaluation of their scientific performance. In this
context, post-publication peer review is often used to assess scientific
performance. Bibliometric indicators have been suggested as an alternative to
peer review. A recurrent question in this context is whether peer review and
metrics tend to yield similar outcomes. In this paper, we study the agreement
between bibliometric indicators and peer review based on a sample of
publications submitted for evaluation to the national Italian research
assessment exercise (2011--2014). In particular, we study the agreement between
bibliometric indicators and peer review at a higher aggregation level, namely
the institutional level. Additionally, we also quantify the internal agreement
of peer review at the institutional level. We base our analysis on a
hierarchical Bayesian model using cross-validation. We find that the level of
agreement is generally higher at the institutional level than at the
publication level. Overall, the agreement between metrics and peer review is on
par with the internal agreement among two reviewers for certain fields of
science in this particular context. This suggests that for some fields,
bibliometric indicators may possibly be considered as an alternative to peer
review for the Italian national research assessment exercise. Although results
do not necessarily generalise to other contexts, it does raise the question
whether similar findings would obtain for other research assessment exercises,
such as in the United Kingdom.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:18:48 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 11:59:05 GMT""}]","2023-03-28"
"2006.14831","Sungkyu Jung","Zhao Ren and Sungkyu Jung and Xingye Qiao","Covariance-engaged Classification of Sets via Linear Programming","86 pages, 5 figures",,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Set classification aims to classify a set of observations as a whole, as
opposed to classifying individual observations separately. To formally
understand the unfamiliar concept of binary set classification, we first
investigate the optimal decision rule under the normal distribution, which
utilizes the empirical covariance of the set to be classified. We show that the
number of observations in the set plays a critical role in bounding the Bayes
risk. Under this framework, we further propose new methods of set
classification. For the case where only a few parameters of the model drive the
difference between two classes, we propose a computationally-efficient approach
to parameter estimation using linear programming, leading to the
Covariance-engaged LInear Programming Set (CLIPS) classifier. Its theoretical
properties are investigated for both independent case and various (short-range
and long-range dependent) time series structures among observations within each
set. The convergence rates of estimation errors and risk of the CLIPS
classifier are established to show that having multiple observations in a set
leads to faster convergence rates, compared to the standard classification
situation in which there is only one observation in the set. The applicable
domains in which the CLIPS performs better than competitors are highlighted in
a comprehensive simulation study. Finally, we illustrate the usefulness of the
proposed methods in classification of real image data in histopathology.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:20:15 GMT""}]","2020-06-29"
"2006.14832","Taiji Marugame","Taiji Marugame","Global secondary CR invariants in dimension five","12pages",,,,"math.DG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A global secondary CR invariant is defined as the integral of a
pseudo-hermitian invariant which is independent of a choice of pseudo-Einstein
contact form. We prove that any global secondary CR invariant on CR
five-manifolds is a linear combination of the total $Q'$-curvature, the total
$\mathcal{I}'$-curvature, and the integral of a local CR invariant.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:21:05 GMT""}]","2020-06-29"
"2006.14833","Marc Lagunas","David R. Ba\~nos, Marc Lagunas-Merino, Salvador Ortiz-Latorre","Variance and interest rate risk in unit-linked insurance policies","21 pages, 7 figures",,,,"q-fin.PR math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the risks derived from selling long term policies that any insurance
company has, arises from interest rates. In this paper we consider a general
class of stochastic volatility models written in forward variance form. We also
deal with stochastic interest rates to obtain the risk-free price for
unit-linked life insurance contracts, as well as providing a perfect hedging
strategy by completing the market. We conclude with a simulation experiment,
where we price unit-linked policies using Norwegian mortality rates. In
addition we compare prices for the classical Black-Scholes model against the
Heston stochastic volatility model with a Vasicek interest rate model.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:22:31 GMT""}]","2020-06-29"
"2006.14834","Binzheng Zhang","Binzheng Zhang, Peter A. Delamere, Zhonghua Yao, Bertrand Bonfond, D.
  Lin, Kareem A. Sorathia, Oliver J. Brambles, William Lotko, Jeff S.
  Garretson, Viacheslav G. Merkin, Denis Grodent, William R. Dunn and John G.
  Lyon","How Jupiter's Unusual Magnetospheric Topology Structures Its Aurora",,,,,"physics.space-ph astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Jupiter's bright persistent polar aurora and Earth's dark polar region
indicate that the planets' magnetospheric topologies are very different.
High-resolution global simulations show that the reconnection rate at the
interface between the interplanetary and jovian magnetic fields is too slow to
generate a magnetically open, Earth-like polar cap on the timescale of
planetary rotation, resulting in only a small crescent-shaped region of
magnetic flux interconnected with the interplanetary magnetic field. Most of
the jovian polar cap is threaded by helical magnetic flux that closes within
the planetary interior, extends into the outer magnetosphere and piles-up near
its dawnside flank where fast differential plasma rotation pulls the field
lines sunward. This unusual magnetic topology provides new insights into
Jupiter's distinctive auroral morphology.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:26:30 GMT""}]","2020-06-29"
"2006.14835","Sandra Keiper","Sandra Keiper","Recovery of Binary Sparse Signals from Structured Biased Measurements",,,,,"cs.IT math.FA math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the reconstruction of binary sparse signals from
partial random circulant measurements. We show that the reconstruction via the
least-squares algorithm is as good as the reconstruction via the usually used
program basis pursuit. We further show that we need as many measurements to
recover an $s$-sparse signal $x_0\in\mathbb{R}^N$ as we need to recover a dense
signal, more-precisely an $N-s$-sparse signal $x_0\in\mathbb{R}^N$. We further
establish stability with respect to noisy measurements.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:29:58 GMT""}]","2020-06-29"
"2006.14836","Qingchen Liu","Lei Shi, Qingchen Liu, Jinliang Shao, Yuhua Cheng","Distributed Localization in Wireless Sensor Networks Under
  Denial-of-Service Attacks",,,"10.1109/LCSYS.2020.3003789",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the problem of localizing the sensors' positions in
presence of denial-of-service (DoS) attacks. We consider a general attack
model, in which the attacker action is only constrained through the frequency
and duration of DoS attacks. We propose a distributed iterative localization
algorithm with an abandonment strategy based on the barycentric coordinate of a
sensor with respect to its neighbors, which is computed through relative
distance measurements. In particular, if a sensor's communication links for
receiving its neighbors' information lose packets due to DoS attacks, then the
sensor abandons the location estimation. When the attacker launches DoS
attacks, the AS-DILOC algorithm is proved theoretically to be able to
accurately locate the sensors regardless of the attack strategy at each time.
The effectiveness of the proposed algorithm is demonstrated through simulation
examples.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:31:45 GMT""}]","2020-06-29"
"2006.14837","Masahiro Takahashi","Masahiro Takahashi, Alessandro Moro, Yonghoon Ji and Kazunori Umeda","Expandable YOLO: 3D Object Detection from RGB-D Images","5 pages, 8 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper aims at constructing a light-weight object detector that inputs a
depth and a color image from a stereo camera. Specifically, by extending the
network architecture of YOLOv3 to 3D in the middle, it is possible to output in
the depth direction. In addition, Intersection over Uninon (IoU) in 3D space is
introduced to confirm the accuracy of region extraction results. In the field
of deep learning, object detectors that use distance information as input are
actively studied for utilizing automated driving. However, the conventional
detector has a large network structure, and the real-time property is impaired.
The effectiveness of the detector constructed as described above is verified
using datasets. As a result of this experiment, the proposed model is able to
output 3D bounding boxes and detect people whose part of the body is hidden.
Further, the processing speed of the model is 44.35 fps.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:32:30 GMT""}]","2020-06-29"
"2006.14838","Benjamin Heymann","Benjamin Heymann, Michel de Lara (CERMICS), Jean-Philippe Chancelier
  (CERMICS)","Kuhn's Equivalence Theorem for Games in Intrinsic Form",,,,,"math.OC cs.GT econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We state and prove Kuhn's equivalence theorem for a new representation of
games, the intrinsic form. First, we introduce games in intrinsic form where
information is represented by $\sigma$-fields over a product set. For this
purpose, we adapt to games the intrinsic representation that Witsenhausen
introduced in control theory. Those intrinsic games do not require an explicit
description of the play temporality, as opposed to extensive form games on
trees. Second, we prove, for this new and more general representation of games,
that behavioral and mixed strategies are equivalent under perfect recall
(Kuhn's theorem). As the intrinsic form replaces the tree structure with a
product structure, the handling of information is easier. This makes the
intrinsic form a new valuable tool for the analysis of games with information.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:35:21 GMT""}]","2020-06-29"
"2006.14839","Yury Tchuvil'sky","D. M. Rodkin and Yu. M. Tchuvil'sky","Asymptotic characteristics of decay channels of light nuclei states in
  the ab initio approach","8 pages, 5 figures, 4 tables","Phys. Rev. C 103, 024304 (2021)","10.1103/PhysRevC.103.024304",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new convenient method for precise theoretical calculations of quantities of
traditional theory of nuclear reactions such as widths of resonances (including
sub-threshold), and asymptotic normalization coefficients is proposed. This
method may be considered as a step on the road to full theoretical ab initio
description of light nuclei spectroscopic data. As an illustration of this
method the computational results for all relevant two-body channels for all
known and some theoretically predicted states of 7Li nucleus are shown.
Well-proven on a large amount of data Daejeon16 potential was used in the
calculations. The most part of the results turn out to be in a good agreement
with the experimental data contained in spectroscopic tables.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:36:32 GMT""}]","2021-02-10"
"2006.14840","Alessia Nota","Marina A. Ferreira, Jani Lukkarinen, Alessia Nota, Juan J. L.
  Vel\'azquez","Localization in stationary non-equilibrium solutions for multicomponent
  coagulation systems","27 pages. The original manuscript has been split. This is a shorter
  version of the original manuscript containing the Localization Result",,"10.1007/s00220-021-04201-z",,"math-ph math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the multicomponent Smoluchowski coagulation equation under
non-equilibrium conditions induced either by a source term or via a constant
flux constraint. We prove that the corresponding stationary non-equilibrium
solutions have a universal localization property. More precisely, we show that
these solutions asymptotically localize into a direction determined by the
source or by a flux constraint: the ratio between monomers of a given type to
the total number of monomers in the cluster becomes ever closer to a
predetermined ratio as the cluster size is increased. The assumptions on the
coagulation kernel are quite general, with isotropic power law bounds. The
proof relies on a particular measure concentration estimate and on the control
of asymptotic scaling of the solutions which is allowed by previously derived
estimates on the mass current observable of the system.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:36:52 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 14:42:47 GMT""}]","2022-02-16"
"2006.14841","Alberto Olmo","Alberto Olmo, Sailik Sengupta, Subbarao Kambhampati","Not all Failure Modes are Created Equal: Training Deep Neural Networks
  for Explicable (Mis)Classification",,,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep Neural Networks are often brittle on image classification tasks and
known to misclassify inputs. While these misclassifications may be inevitable,
all failure modes cannot be considered equal. Certain misclassifications (eg.
classifying the image of a dog to an airplane) can perplex humans and result in
the loss of human trust in the system. Even worse, these errors (eg. a person
misclassified as a primate) can have odious societal impacts. Thus, in this
work, we aim to reduce inexplicable errors. To address this challenge, we first
discuss methods to obtain the class-level semantics that capture the human's
expectation ($M^h$) regarding which classes are semantically close {\em vs.}
ones that are far away. We show that for popular image benchmarks (like
CIFAR-10, CIFAR-100, ImageNet), class-level semantics can be readily obtained
by leveraging either human subject studies or publicly available human-curated
knowledge bases. Second, we propose the use of Weighted Loss Functions (WLFs)
to penalize misclassifications by the weight of their inexplicability. Finally,
we show that training (or fine-tuning) existing classifiers with the proposed
methods lead to Deep Neural Networks that have (1) comparable top-1 accuracy,
(2) more explicable failure modes on both in-distribution and
out-of-distribution (OOD) test data, and (3) incur significantly less cost in
the gathering of additional human labels compared to existing works.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:37:33 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 22:34:14 GMT""}]","2021-11-03"
"2006.14842","Jean-Bernard Chatelain","Jean-Bernard Chatelain (PJSE), Kirsten Ralf","The Welfare of Ramsey Optimal Policy Facing Auto-Regressive Shocks",,"Economics Bulletin, Economics Bulletin, 2020, 40 ((2)),
  pp.1797-1803",,,"math.OC econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With non-controllable auto-regressive shocks, the welfare of Ramsey optimal
policy is the solution of a single Riccati equation of a linear quadratic
regulator. The existing theory by Hansen and Sargent (2007) refers to an
additional Sylvester equation but miss another equation for computing the block
matrix weighting the square of non-controllable variables in the welfare
function. There is no need to simulate impulse response functions over a long
period, to compute period loss functions and to sum their discounted value over
this long period, as currently done so far. Welfare is computed for the case of
the new-Keynesian Phillips curve with an auto-regressive cost-push shock. JEL
classification numbers: C61, C62, C73, E47, E52, E61, E63.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:38:41 GMT""}]","2020-06-29"
"2006.14843","Alexey Chernikov","Jonas D. Ziegler, Jonas Zipfel, Barbara Meisinger, Matan Menahem,
  Xiangzhou Zhu, Takashi Taniguchi, Kenji Watanabe, Omer Yaffe, David A. Egger,
  Alexey Chernikov","Fast and anomalous exciton diffusion in two-dimensional hybrid
  perovskites",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-dimensional hybrid perovskites are currently in the spotlight of
condensed matter and nanotechnology research due to their intriguing
optoelectronic and vibrational properties with emerging potential for
light-harvesting and -emitting applications. While it is known that these
natural quantum wells host tightly bound excitons, the mobilities of these
fundamental optical excitations at the heart of the optoelectronic applications
are still largely unexplored. Here, we directly monitor the diffusion of
excitons through ultrafast emission microscopy from liquid helium to room
temperature in hBN-encapsulated two-dimensional hybrid perovskites. We find
very fast diffusion with characteristic hallmarks of free exciton propagation
for all temperatures above 50 K. In the cryogenic regime we observe nonlinear,
anomalous behavior with an exceptionally rapid expansion of the exciton cloud
followed by a very slow and even negative effective diffusion. We discuss our
findings in view of efficient exciton-phonon coupling, highlighting
two-dimensional hybrids as promising platforms for many-body physics research
and optoelectronic applications on the nanoscale.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:40:05 GMT""}]","2020-06-29"
"2006.14844","Gaetano Zampieri","Gianluca Gorni and Gaetano Zampieri","Lagrangian dynamics by nonlocal constants of motion",,,"10.3934/dcdss.2020216",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A simple general theorem is used as a tool that generates nonlocal constants
of motion for Lagrangian systems. We review some cases where the constants that
we find are useful in the study of the systems: the homogeneous potentials of
degree~$-2$, the mechanical systems with viscous fluid resistance and the
conservative and dissipative Maxwell-Bloch equations of laser dynamics. We also
prove a new result on explosion in the past for mechanical system with
hydraulic (quadratic) fluid resistance and bounded potential.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:41:21 GMT""}]","2020-09-28"
"2006.14845","Masaaki Takada Mr.","Masaaki Takada, Hironori Fujisawa","Transfer Learning via $\ell_1$ Regularization",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning algorithms typically require abundant data under a
stationary environment. However, environments are nonstationary in many
real-world applications. Critical issues lie in how to effectively adapt models
under an ever-changing environment. We propose a method for transferring
knowledge from a source domain to a target domain via $\ell_1$ regularization.
We incorporate $\ell_1$ regularization of differences between source parameters
and target parameters, in addition to an ordinary $\ell_1$ regularization.
Hence, our method yields sparsity for both the estimates themselves and changes
of the estimates. The proposed method has a tight estimation error bound under
a stationary environment, and the estimate remains unchanged from the source
estimate under small residuals. Moreover, the estimate is consistent with the
underlying function, even when the source estimate is mistaken due to
nonstationarity. Empirical results demonstrate that the proposed method
effectively balances stability and plasticity.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:42:03 GMT""}]","2020-06-29"
"2006.14846","Kijti Rodtes","Kijti Rodtes","A class of normal dilation matrices affirming the Marcus-de Oliveira
  conjecture",,,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  In this article, we prove a class of normal dilation matrices affirming the
Marcus-de Oliveira conjecture.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:48:44 GMT""}]","2020-06-29"
"2006.14847","Mitchell Cavanagh","Mitchell Cavanagh and Kenji Bekki","Bars formed in galaxy merging and their classification with deep
  learning","16 pages, 12 figures, accepted for publication in A&A","A&A 641, A77 (2020)","10.1051/0004-6361/202037963",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stellar bars are a common morphological feature of spiral galaxies. While it
is known that they can form in isolation, or be induced tidally, few studies
have explored the production of stellar bars in galaxy merging. We look to
investigate bar formation in galaxy merging using methods from deep learning to
analyse our N-body simulations. The primary aim is to determine the constraints
on the mass ratio and orientations of merging galaxies that are most conducive
to bar formation. We further aim to explore whether it is possible to classify
simulated barred spiral galaxies based on the mechanism of their formation. We
test the feasibility of this new classification schema with simulated galaxies.
Using a set of 29,400 images obtained from our simulations, we first trained a
convolutional neural network to distinguish between barred and non-barred
galaxies. We then tested the network on simulations with different mass ratios
and spin angles. We adapted the core neural network architecture for use with
our additional aims. We find that a strong inverse relationship between mass
ratio and the number of bars produced. We also identify two distinct phases in
the bar formation process; (1) the initial, tidally induced formation
pre-merger, and (2) the destruction and/or regeneration of the during and after
the merger. Mergers with low mass ratios and closely-aligned orientations are
considerably more conducive to bar formation compared to equal-mass mergers. We
demonstrate the flexibility of our deep learning approach by showing it is
feasible to classify bars based on their formation mechanism.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:50:51 GMT""}]","2020-09-16"
"2006.14848","Pascal Viot","Vincent Mancois, Julien Barr\'e, Chang Chi Kwong, Alain Olivetti,
  Pascal Viot, and David Wilkowski","Anisotropic long-range interaction investigated with cold atoms","11 pages, 8 figures, accepted in Physical Review A","Phys. Rev. A. 52 003300 (2020)","10.1103/PhysRevA.102.013311",,"physics.atom-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In two dimensions, a system of self-gravitating particles collapses and forms
a singularity in finite time below a critical temperature $T_c$. We investigate
experimentally a quasi two-dimensional cloud of cold neutral atoms in
interaction with two pairs of perpendicular counter-propagating quasi-resonant
laser beams, in order to look for a signature of this ideal phase transition:
indeed, the radiation pressure forces exerted by the laser beams can be viewed
as an anisotropic, and non-potential, generalization of two-dimensional
self-gravity. We first show that our experiment operates in a parameter range
which should be suitable to observe the collapse transition. However, the
experiment unveils only a moderate compression instead of a phase transition
between the two phases. A three-dimensional numerical simulation shows that
both the finite small thickness of the cloud, which induces a competition
between the effective gravity force and the repulsive force due to multiple
scattering, and the atomic losses due to heating in the third dimension,
contribute to smearing the transition.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:55:40 GMT""}]","2022-08-30"
"2006.14849","Urs Langenegger","Urs Langenegger (for the CMS collaboration)","Recent results on $B \to \mu^+ \mu^-$ decays with the CMS experiment","Invited short review submitted to MPLA",,"10.1142/S0217732320300177","CMS CR-2020/115","hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Results on $B \to \mu^+ \mu^-$ decays with the CMS experiment are reported,
using 61 fb$^{-1}$ of data recorded during LHC Run 1 and 2016. With an improved
muon identification algorithm and refined unbinned maximum likelihood fitting
methods, the decay $B_s^0 \to \mu^+ \mu^-$ is observed with a significance of
5.6 standard deviations. Its branching fraction is measured to be BF($B^0_s \to
\mu^+ \mu^-$) = [2.9+/-0.7(exp)+/-0.2(frag)]$\times 10^{-9}$, where the first
error is the combined statistical and systematic uncertainty and the second
error quantifies the uncertainty of the $B^0_s$ and $B^+$ fragmentation
probability ratio. The $B^0_s \to \mu^+ \mu^-$ effective lifetime is
$\tau_{\mu^+ \mu^-} =1.70^{+0.61}_{-0.44}$ps. No evidence for the decay $B^0
\to \mu^+ \mu^-$ is found and an upper limit of BF($B^0 \to \mu^+ \mu^-$) <
3.6$\times 10^{-10}$ (at 95% confidence level) is determined. All results are
consistent with the standard model of particle physics.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:01:04 GMT""}]","2020-12-02"
"2006.14850","Farhan Rana","Arjan Singh, Okan Koksal, Nicholas Tanen, Jonathan McCandless, Debdeep
  Jena, Huili (Grace) Xing, Hartwin Peelaers, Farhan Rana","Intra- and Inter-Conduction Band Optical Absorption Processes in
  $\beta$-Ga$_2$O$_3$","5 pages, 6 figures",,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  $\beta$-Ga$_2$O$_3$ is an ultra-wide bandgap semiconductor and is thus
expected to be optically transparent to light of sub-bandgap wavelengths well
into the ultraviolet. Contrary to this expectation, it is found here that free
electrons in n-doped $\beta$-Ga$_2$O$_3$ absorb light from the IR to the UV
wavelength range via intra- and inter-conduction band optical transitions.
Intra-conduction band absorption occurs via an indirect optical phonon mediated
process with a $1/\omega^{3}$ dependence in the visible to near-IR wavelength
range. This frequency dependence markedly differs from the $1/\omega^{2}$
dependence predicted by the Drude model of free-carrier absorption. The
inter-conduction band absorption between the lowest conduction band and a
higher conduction band occurs via a direct optical process at $\lambda \sim
349$ nm (3.55 eV). Steady state and ultrafast optical spectroscopy measurements
unambiguously identify both these absorption processes and enable quantitative
measurements of the inter-conduction band energy, and the frequency dependence
of absorption. Whereas the intra-conduction band absorption does not depend on
light polarization, inter-conduction band absorption is found to be strongly
polarization dependent. The experimental observations, in excellent agreement
with recent theoretical predictions for $\beta$-Ga$_2$O$_3$, provide important
limits of sub-bandgap transparency for optoelectronics in the deep-UV to
visible wavelength range, and are also of importance for high electric field
transport effects in this emerging semiconductor.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:16:09 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jul 2020 04:28:46 GMT""}]","2020-07-30"
"2006.14851","Jun Zhao","Yue Xiu, Jun Zhao, Chau Yuen, Zhongpei Zhang, Guan Gui","Secure Beamforming for Multiple Intelligent Reflecting Surfaces Aided
  mmWave Systems","This paper appears in IEEE Communications Letters. Please feel free
  to contact us for questions or remarks.
  https://doi.org/10.1109/LCOMM.2020.3028135/",,"10.1109/LCOMM.2020.3028135",,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  In this letter, secure beamforming in a multiple intelligent reflecting
surfaces (IRSs)-aided millimeter-wave (mmWave) system is investigated. In this
system, the secrecy rate is maximized by controlling the on-off status of each
IRS as well as optimizing the phase shift matrix of the IRSs. This problem is
posed as a joint optimization problem of transmit beamforming and IRS control,
whose goal is to maximize the secrecy rate under the total transmission power
and unit-modulus constraints. The problem is difficult to solve optimally due
to the nonconvexity of constraint conditions and coupled variables. To deal
with this problem, we propose an alternating optimization (AO)-based algorithm
based on successive convex approximation (SCA) and manifold optimization (MO)
technologies. Numerical simulations show that the proposed AO-based algorithm
can effectively improve the secrecy rate and outperforms the traditional single
IRS-aided scheme.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:18:37 GMT""},{""version"":""v2"",""created"":""Fri, 25 Dec 2020 16:38:15 GMT""}]","2020-12-29"
"2006.14852","Matteo Viale","Moreno Pierobon, Matteo Viale","Boolean valued models, presheaves, and \'etal\'e spaces",,,,,"math.LO math.CT","http://creativecommons.org/licenses/by/4.0/","  Boolean valued models for a signature $\mathcal{L}$ are generalizations of
$\mathcal{L}$-structures in which we allow the $\mathcal{L}$-relation symbols
to be interpreted by boolean truth values. For example, for elements
$a,b\in\mathcal{M}$ with $\mathcal{M}$ a $\mathsf{B}$-valued
$\mathcal{L}$-structure for some boolean algebra $\mathsf{B}$, $(a=b)$ may be
neither true nor false, but get an intermediate truth value in $\mathsf{B}$. In
this paper we introduce a topological characterization of the sheafification
process for presheaves on topological spaces induced by the dense Grothendieck
topology. On the way to produce our characterization, we also relate the notion
of open continuous mapping between topological spaces to that of complete
homomorphism between complete boolean algebras, and to that of adjoint
homomorphism between boolean algebras (e.g. an homomorphism which has a left
adjoint, if seen as a functor between partial orders/categories). Next we link
these topological/category theoretic results to the theory of boolean valued
models. We give a different proof of a result by Monro identifying topological
presheaves on Stone spaces with boolean valued models, and sheaves (according
to the dense Grothendieck topology) with boolean valued models having the
mixing property. We also give an exact topological characterization (the so
called fullness property) of which boolean valued models satisfy Lo\'s Theorem
(i.e. the general form of the Forcing Theorem which Cohen -- Scott, Solovay,
Vopenka -- established for the special case given by the forcing method in set
theory). Then we separate the fullness property from the mixing property, by
showing that the latter is strictly stronger. Finally we give an exact
categorical characterization of which presheaves correspond to full boolean
valued models in terms of the structure of global sections of their associated
\'etal\'e space
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:19:01 GMT""},{""version"":""v2"",""created"":""Fri, 1 Apr 2022 08:20:19 GMT""},{""version"":""v3"",""created"":""Sun, 2 Apr 2023 08:18:02 GMT""},{""version"":""v4"",""created"":""Fri, 12 May 2023 22:12:07 GMT""},{""version"":""v5"",""created"":""Wed, 31 May 2023 08:26:10 GMT""}]","2023-06-01"
"2006.14853","Marco Scarpetta","Filippo Attivissimo, Nicola Giaquinto, Marco Scarpetta, Maurizio
  Spadavecchia","An Automatic Reader of Identity Documents","6 pages, 9 figures",,"10.1109/SMC.2019.8914438",,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identity documents automatic reading and verification is an appealing
technology for nowadays service industry, since this task is still mostly
performed manually, leading to waste of economic and time resources. In this
paper the prototype of a novel automatic reading system of identity documents
is presented. The system has been thought to extract data of the main Italian
identity documents from photographs of acceptable quality, like those usually
required to online subscribers of various services. The document is first
localized inside the photo, and then classified; finally, text recognition is
executed. A synthetic dataset has been used, both for neural networks training,
and for performance evaluation of the system. The synthetic dataset avoided
privacy issues linked to the use of real photos of real documents, which will
be used, instead, for future developments of the system.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:22:40 GMT""}]","2020-06-29"
"2006.14854","Florent Pled","Tianyu Zhang (MSME), Florent Pled (MSME), Christophe Desceliers (MSME)","Robust Multiscale Identification of Apparent Elastic Properties at
  Mesoscale for Random Heterogeneous Materials with Multiscale Field
  Measurements",,"Materials, MDPI, 2020, 13 (12), pp.2826","10.3390/ma13122826",,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this work is to efficiently and robustly solve the statistical
inverse problem related to the identification of the elastic properties at both
macroscopic and mesoscopic scales of heterogeneous anisotropic materials with a
complex microstructure that usually cannot be properly described in terms of
their mechanical constituents at microscale. Within the context of linear
elasticity theory, the apparent elasticity tensor field at a given mesoscale is
modeled by a prior non-Gaussian tensor-valued random field. A general
methodology using multiscale displacement field measurements simultaneously
made at both macroscale and mesoscale has been recently proposed for the
identification the hyperparameters of such a prior stochastic model by solving
a multiscale statistical inverse problem using a stochastic computational model
and some information from displacement fields at both macroscale and mesoscale.
This paper contributes to the improvement of the computational efficiency,
accuracy and robustness of such a method by introducing (i) a mesoscopic
numerical indicator related to the spatial correlation length(s) of kinematic
fields, allowing the time-consuming global optimization algorithm (genetic
algorithm) used in a previous work to be replaced with a more efficient
algorithm and (ii) an ad hoc stochastic representation of the hyperparameters
involved in the prior stochastic model in order to enhance both the robustness
and the precision of the statistical inverse identification method. Finally,
the proposed improved method is first validated on in silico materials within
the framework of 2D plane stress and 3D linear elasticity (using multiscale
simulated data obtained through numerical computations) and then exemplified on
a real heterogeneous biological material (beef cortical bone) within the
framework of 2D plane stress linear elasticity (using multiscale experimental
data obtained through mechanical testing monitored by digital image
correlation).
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:23:43 GMT""}]","2020-06-29"
"2006.14855","Dominique Yvon","D. Yvon, V. Sharyy, M. Follin, J-P Bard, D. Breton, J. Maalmi, C.
  Morel, E. Delagnes","Design study of a scintronic crystal targeting tens of picoseconds time
  resolution for gamma ray imaging: the ClearMind detector","Accepted in Journal of Instrumentation : JINST_054P_0320",,"10.1088/1748-0221/15/07/P07029",,"physics.ins-det physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the concept of a new gamma ray scintronic detector targeting a
time resolution of the order of 25 ps FWHM, with millimetric volume
reconstruction and high detection efficiency. Its design consists of a
monolithic large PbWO4 scintillating crystal with an efficient photocathode
directly deposited on it. With an index of refraction higher for the
photocathode than for the crystal, this design negates the total reflection
effect of optical photons at the crystal/photo-detector optical interface, and
thus largely improves optical coupling between the crystal and the
photodetector. This allows to detect efficiently the Cherenkov light produced
by 511 keV photoelectric conversions in PbWO4, and to optimize the detector
time resolution. Furthermore, the low-yield, fast scintillation light produced
additionally by PbWO4 increases the detected photon statistics by a factor 10,
thus fostering accurate (3 dimensional) localization of the gamma ray
interaction within the crystal and providing a fair measurement of the
deposited energy. This paper lists the technological challenges that have to be
overcome in order to build this scintronic detector. We show that all the key
technologies have now been demonstrated and present results of a preliminary
Monte Carlo simulation, which include an innovative event reconstruction
algorithm to support the claimed performances of the detector.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:25:32 GMT""}]","2020-08-26"
"2006.14856","Mohammad Jalwana","Mohammad A. A. K. Jalwana, Naveed Akhtar, Mohammed Bennamoun, Ajmal
  Mian","Orthogonal Deep Models As Defense Against Black-Box Attacks","Accepted in IEEE Access",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning has demonstrated state-of-the-art performance for a variety of
challenging computer vision tasks. On one hand, this has enabled deep visual
models to pave the way for a plethora of critical applications like disease
prognostics and smart surveillance. On the other, deep learning has also been
found vulnerable to adversarial attacks, which calls for new techniques to
defend deep models against these attacks. Among the attack algorithms, the
black-box schemes are of serious practical concern since they only need
publicly available knowledge of the targeted model. We carefully analyze the
inherent weakness of deep models in black-box settings where the attacker may
develop the attack using a model similar to the targeted model. Based on our
analysis, we introduce a novel gradient regularization scheme that encourages
the internal representation of a deep model to be orthogonal to another, even
if the architectures of the two models are similar. Our unique constraint
allows a model to concomitantly endeavour for higher accuracy while maintaining
near orthogonal alignment of gradients with respect to a reference model.
Detailed empirical study verifies that controlled misalignment of gradients
under our orthogonality objective significantly boosts a model's robustness
against transferable black-box adversarial attacks. In comparison to regular
models, the orthogonal models are significantly more robust to a range of $l_p$
norm bounded perturbations. We verify the effectiveness of our technique on a
variety of large-scale models.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:29:05 GMT""}]","2020-06-29"
"2006.14857","Emmanuel Stratakis","Leonidas Mouchliadis, Sotiris Psilodimitrakopoulos, George Miltos
  Maragkakis, Ioanna Demeridou, George Kourmoulakis, Andreas Lemonis, George
  Kioseoglou, Emmanuel Stratakis","Probing valley population imbalance in transition metal dichalcogenides
  via temperature-dependent second harmonic generation imaging",,,,,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Degenerate minima in momentum space - valleys - provide an additional degree
of freedom that can be used for information transport and storage. Notably,
such minima naturally exist in the band structure of transition metal
dichalcogenides (TMDs). When these atomically thin crystals interact with
intense laser light, the second harmonic generated (SHG) field inherits special
characteristics that reflect not only the broken inversion symmetry in real
space, but also the valley anisotropy in reciprocal space. The latter is
present whenever there exists a valley population imbalance (VPI) between the
two valleys. In this work, it is shown that the temperature-induced changes of
the SHG intensity dependence on the excitation fieldpolarization, is a unique
fingerprint of VPI in TMDs. Analysis of such changes, in particular, enables
the calculation of the valley-induced to intrinsic second order
susceptibilities ratio. Unlike temperature-dependent photoluminescence (PL)
measurements of valley polarization and coherence, the proposed polarization
resolved SHG (PSHG) methodology is insensitive to the excitation field
wavelength, an advantage that renders it ideal for monitoring VPI in large
crystalline or stacked areas comprising different TMDs.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:34:12 GMT""}]","2020-06-29"
"2006.14858","David K\""ugler","David K\""ugler, Marc Uecker, Arjan Kuijper, Anirban Mukhopadhyay","AutoSNAP: Automatically Learning Neural Architectures for Instrument
  Pose Estimation","Accepted at MICCAI 2020 Preparing code for release at
  https://github.com/MECLabTUDA/AutoSNAP",,"10.1007/978-3-030-59716-0_36",,"cs.CV cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Despite recent successes, the advances in Deep Learning have not yet been
fully translated to Computer Assisted Intervention (CAI) problems such as pose
estimation of surgical instruments. Currently, neural architectures for
classification and segmentation tasks are adopted ignoring significant
discrepancies between CAI and these tasks. We propose an automatic framework
(AutoSNAP) for instrument pose estimation problems, which discovers and learns
the architectures for neural networks. We introduce 1)~an efficient testing
environment for pose estimation, 2)~a powerful architecture representation
based on novel Symbolic Neural Architecture Patterns (SNAPs), and 3)~an
optimization of the architecture using an efficient search scheme. Using
AutoSNAP, we discover an improved architecture (SNAPNet) which outperforms both
the hand-engineered i3PosNet and the state-of-the-art architecture search
method DARTS.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:34:47 GMT""}]","2022-08-15"
"2006.14859","Bruno Lecouat","Bruno Lecouat, Jean Ponce, Julien Mairal","A Flexible Framework for Designing Trainable Priors with Adaptive
  Smoothing and Game Encoding","NeurIPS 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a general framework for designing and training neural network
layers whose forward passes can be interpreted as solving non-smooth convex
optimization problems, and whose architectures are derived from an optimization
algorithm. We focus on convex games, solved by local agents represented by the
nodes of a graph and interacting through regularization functions. This
approach is appealing for solving imaging problems, as it allows the use of
classical image priors within deep models that are trainable end to end. The
priors used in this presentation include variants of total variation, Laplacian
regularization, bilateral filtering, sparse coding on learned dictionaries, and
non-local self similarities. Our models are fully interpretable as well as
parameter and data efficient. Our experiments demonstrate their effectiveness
on a large diversity of tasks ranging from image denoising and compressed
sensing for fMRI to dense stereo matching.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:34:54 GMT""},{""version"":""v2"",""created"":""Mon, 9 Nov 2020 10:00:10 GMT""}]","2020-11-10"
"2006.14860","Yuval Heller","Gilad Bavly, Yuval Heller, Amnon Schreiber","Social Welfare in Search Games with Asymmetric Information","34 pages main text (including 9 figures) + 14 pages of appendices +
  bibliography","Journal of Economic Theory, 2022",,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider games in which players search for a hidden prize, and they have
asymmetric information about the prize location. We study the social payoff in
equilibria of these games. We present sufficient conditions for the existence
of an equilibrium that yields the first-best payoff (i.e., the highest social
payoff under any strategy profile), and we characterize the first-best payoff.
The results have interesting implications for innovation contests and R&D
races.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:35:09 GMT""},{""version"":""v2"",""created"":""Sat, 16 Apr 2022 21:29:18 GMT""}]","2022-04-19"
"2006.14861","Ralph Brinks","Ralph Brinks, Annika Hoyer","Numerical considerations about the SIR epidemic model with infection age","10 pages, 3 figures",,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyse the infection-age-dependent SIR model from a numerical point of
view. First, we present an algorithm for calculating the solution the
infection-age-structured SIR model without demography of the background host.
Second, we examine how and under which conditions, the conventional SIR model
(without infection-age) serves as a practical approximation to the
infection-age SIR model. Special emphasis is given on the effective
reproduction number.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:40:16 GMT""}]","2020-06-29"
"2006.14862","Hendrik K\""ahler","Hendrik K\""ahler, Daniel Platz, and Silvan Schmid","Surface acoustic wave coupling between micromechanical resonators","11 pages, 4 figures in maint text, 9 figures in supplementary",,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The coupling of micro- or nanomechanical resonators via a shared substrate is
intensively exploited to built systems for fundamental studies and practical
applications. So far, the focus has been on devices operating in the kHz regime
with a spring-like coupling. At resonance frequencies above several 10 MHz,
wave propagation in the solid substrate becomes relevant. The resonators act as
sources for surface acoustic waves (SAWs) and it is unknown how this effects
the coupling between them. Here, we present a model for MHz frequency
resonators interacting by SAWs and derive the eigenfrequencies and quality
factors of a pair of resonators for the symmetric and antisymmetric mode. Our
results are in agreement with finite element method (FEM) simulations and show
that in contrast to the well-known strain-induced spring-like coupling, the
coupling via SAWs is not only dispersive but also dissipative. This can be
exploited to realize high quality phonon cavities, an alternative to acoustic
radiation shielding by, e.g. phononic crystals.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:44:35 GMT""},{""version"":""v2"",""created"":""Fri, 4 Dec 2020 17:23:11 GMT""},{""version"":""v3"",""created"":""Tue, 15 Jun 2021 12:49:49 GMT""},{""version"":""v4"",""created"":""Fri, 27 Aug 2021 11:45:07 GMT""}]","2021-08-30"
"2006.14863","Qixiang Ye","Feng Liu, Xiaoxong Zhang, Fang Wan, Xiangyang Ji, Qixiang Ye","Domain Contrast for Domain Adaptive Object Detection",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present Domain Contrast (DC), a simple yet effective approach inspired by
contrastive learning for training domain adaptive detectors. DC is deduced from
the error bound minimization perspective of a transferred model, and is
implemented with cross-domain contrast loss which is plug-and-play. By
minimizing cross-domain contrast loss, DC guarantees the transferability of
detectors while naturally alleviating the class imbalance issue in the target
domain. DC can be applied at either image level or region level, consistently
improving detectors' transferability and discriminability. Extensive
experiments on commonly used benchmarks show that DC improves the baseline and
state-of-the-art by significant margins, while demonstrating great potential
for large domain divergence.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:45:36 GMT""}]","2020-06-29"
"2006.14864","William Buchanan Prof","Will Abramson, Nicole E. van Deursen, William J Buchanan","Trust-by-Design: Evaluating Issues and Perceptions within Clinical
  Passporting",,"Blockchain in Healthcare Today, 3 (2020)","10.30953/bhty.v3.140",,"cs.CR cs.CY","http://creativecommons.org/licenses/by/4.0/","  A substantial administrative burden is placed on healthcare professionals as
they manage and progress through their careers. Identity verification,
pre-employment screening and appraisals: the bureaucracy associated with each
of these processes takes precious time out of a healthcare professional's day.
Time that could have been spent focused on patient care. In the midst of the
COVID-19 crisis, it is more important than ever to optimize these
professionals' time. This paper presents the synthesis of a design workshop
held at the Royal College of Physicians of Edinburgh (RCPE) and subsequent
interviews with healthcare professionals. The main research question posed is
whether these processes can be re-imagined using digital technologies,
specifically Self-Sovereign Identity? A key contribution in the paper is the
development of a set of user-led requirements and design principles for
identity systems used within healthcare. These are then contrasted with the
design principles found in the literature. The results of this study confirm
the need and potential of professionalising identity and credential management
throughout a healthcare professional's career.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:49:44 GMT""}]","2020-06-29"
"2006.14865","Zihao Yan","Zihao Yan, Ruizhen Hu, Xingguang Yan, Luanmin Chen, Oliver van Kaick,
  Hao Zhang, Hui Huang","RPM-Net: Recurrent Prediction of Motion and Parts from Point Cloud","Accepted to SIGGRAPH Asia 2019, project page at
  https://vcc.tech/research/2019/RPMNet","ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia),
  volume 38, number 6, pages 240:1--240:15, year 2019","10.1145/3355089.3356573",,"cs.CV cs.GR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce RPM-Net, a deep learning-based approach which simultaneously
infers movable parts and hallucinates their motions from a single,
un-segmented, and possibly partial, 3D point cloud shape. RPM-Net is a novel
Recurrent Neural Network (RNN), composed of an encoder-decoder pair with
interleaved Long Short-Term Memory (LSTM) components, which together predict a
temporal sequence of pointwise displacements for the input point cloud. At the
same time, the displacements allow the network to learn movable parts,
resulting in a motion-based shape segmentation. Recursive applications of
RPM-Net on the obtained parts can predict finer-level part motions, resulting
in a hierarchical object segmentation. Furthermore, we develop a separate
network to estimate part mobilities, e.g., per-part motion parameters, from the
segmented motion sequence. Both networks learn deep predictive models from a
training set that exemplifies a variety of mobilities for diverse objects. We
show results of simultaneous motion and part predictions from synthetic and
real scans of 3D objects exhibiting a variety of part mobilities, possibly
involving multiple movable parts.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:51:11 GMT""}]","2020-06-29"
"2006.14866","Tim Galvin","T. J. Galvin, M. Huynh, R. P. Norris, X. R. Wang, E. Hopkins, K.
  Polsterer, N. O. Ralph, A. N. O'Brien, G. H. Heald","Cataloging the radio-sky with unsupervised machine learning: a new
  approach for the SKA era",,,"10.1093/mnras/staa1890",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a new analysis approach towards identifying related radio
components and their corresponding infrared host galaxy based on unsupervised
machine learning methods. By exploiting PINK, a self-organising map algorithm,
we are able to associate radio and infrared sources without the a priori
requirement of training labels. We present an example of this method using
$894,415$ images from the FIRST and WISE surveys centred towards positions
described by the FIRST catalogue. We produce a set of catalogues that
complement FIRST and describe 802,646 objects, including their radio components
and their corresponding AllWISE infrared host galaxy. Using these data products
we (i) demonstrate the ability to identify objects with rare and unique radio
morphologies (e.g. 'X'-shaped galaxies, hybrid FR-I/FR-II morphologies), (ii)
can identify the potentially resolved radio components that are associated with
a single infrared host and (iii) introduce a ""curliness"" statistic to search
for bent and disturbed radio morphologies, and (iv) extract a set of 17 giant
radio galaxies between 700-1100 kpc. As we require no training labels, our
method can be applied to any radio-continuum survey, provided a sufficiently
representative SOM can be trained.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:57:42 GMT""}]","2020-07-08"
"2006.14867","Giovanni Pelliccioli","Ansgar Denner and Giovanni Pelliccioli","Polarized electroweak bosons in ${\bf \text{W}^+\text{W}^-}$ production
  at the LHC including NLO QCD effects","corrected typos, added new reference, added further comments on
  jet-veto effects in sect. 3, matches JHEP published version",,"10.1007/JHEP09(2020)164",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The measurement of polarization fractions of massive gauge bosons at the LHC
provides an important check of the Standard Model and in particular of the
Electroweak Symmetry Breaking mechanism. Owing to the unstable character of
$\text{W}$ and $\text{Z}$ bosons, devising a theoretical definition for
polarized signals is not straightforward and always subject to some ambiguity.
Focusing on $\text{W}$-boson pair production at the LHC in the fully leptonic
channel, we propose to compute polarized cross-sections and distributions based
on the gauge-invariant doubly-resonant part of the amplitude. We include NLO
QCD corrections to the leading quark-induced partonic process and also consider
the loop-induced gluon-initiated process contributing to the same final state.
We present results for both an inclusive setup and a realistic fiducial region,
with special focus on variables that are suited for the discrimination of
polarized cross-sections and on quantities that can be measured experimentally.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:01:29 GMT""},{""version"":""v2"",""created"":""Mon, 28 Sep 2020 13:22:02 GMT""}]","2020-10-28"
"2006.14868","Georgios Gerasimou","Miguel Costa-Gomes and Georgios Gerasimou","Status Quo Bias and the Decoy Effect: A Comparative Analysis in Choice
  under Risk",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inertia and context-dependent choice effects are well-studied classes of
behavioural phenomena. While much is known about these effects in isolation,
little is known about whether one of them ""dominates"" the other when both can
potentially be present. Knowledge of any such dominance is relevant for
effective choice architecture and descriptive modelling. We initiate this
empirical investigation with a between-subjects lab experiment in which each
subject made a single decision over two or three money lotteries. Our
experiment was designed to test for dominance between *status quo bias* and the
*decoy effect*. We find strong evidence for status quo bias and no evidence for
the decoy effect. We also find that status quo bias can be powerful enough so
that, at the aggregate level, a fraction of subjects switch from being
risk-averse to being risk-seeking. Survey evidence suggests that this is due to
subjects focusing on the maximum possible amount when the risky lottery is the
default and on the highest probability of winning the biggest possible reward
when there is no default. The observed reversal in risk attitudes is
explainable by a large class of Koszegi-Rabin (2006) reference-dependent
preferences.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:02:11 GMT""},{""version"":""v2"",""created"":""Tue, 20 Oct 2020 11:19:21 GMT""},{""version"":""v3"",""created"":""Fri, 26 Nov 2021 18:35:32 GMT""}]","2021-11-29"
"2006.14869","Andrew Ellis","Andrew Ellis and David J Freeman","Revealing Choice Bracketing",,,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a decision problem comprised of multiple choices, a person may fail to
take into account the interdependencies between her choices. To understand how
people make decisions in such problems we design a novel experiment and
revealed preference tests that determine how each subject brackets her choices.
In separate portfolio allocation under risk, social allocation, and
induced-utility shopping experiments, we find that 40-43\% of our subjects are
consistent with narrow bracketing while only 0-15\% are consistent with broad
bracketing. Classifying subjects while adjusting for models' predictive
precision, 73\% of subjects are best described by narrow bracketing, 14\% by
broad bracketing, and 5\% by intermediate cases.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:04:44 GMT""},{""version"":""v2"",""created"":""Wed, 30 Sep 2020 09:52:42 GMT""}]","2020-10-01"
"2006.14870","Arturo Castellanos Salinas","Aleksandrs Belovs, Arturo Castellanos, Fran\c{c}ois Le Gall, Guillaume
  Malod and Alexander A. Sherstov","Quantum Communication Complexity of Distribution Testing","11 pages",,,,"cs.CC quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical communication complexity of testing closeness of discrete
distributions has recently been studied by Andoni, Malkin and Nosatzki
(ICALP'19). In this problem, two players each receive $t$ samples from one
distribution over $[n]$, and the goal is to decide whether their two
distributions are equal, or are $\epsilon$-far apart in the $l_1$-distance. In
the present paper we show that the quantum communication complexity of this
problem is $\tilde{O}(n/(t\epsilon^2))$ qubits when the distributions have low
$l_2$-norm, which gives a quadratic improvement over the classical
communication complexity obtained by Andoni, Malkin and Nosatzki. We also
obtain a matching lower bound by using the pattern matrix method. Let us stress
that the samples received by each of the parties are classical, and it is only
communication between them that is quantum. Our results thus give one setting
where quantum protocols overcome classical protocols for a testing problem with
purely classical samples.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:05:58 GMT""}]","2020-06-29"
"2006.14871","Kaidi Jin","Kaidi Jin, Tianwei Zhang, Chao Shen, Yufei Chen, Ming Fan, Chenhao
  Lin, Ting Liu","Can We Mitigate Backdoor Attack Using Adversarial Detection Methods?","Accepted by IEEE TDSC",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep Neural Networks are well known to be vulnerable to adversarial attacks
and backdoor attacks, where minor modifications on the input are able to
mislead the models to give wrong results. Although defenses against adversarial
attacks have been widely studied, investigation on mitigating backdoor attacks
is still at an early stage. It is unknown whether there are any connections and
common characteristics between the defenses against these two attacks. We
conduct comprehensive studies on the connections between adversarial examples
and backdoor examples of Deep Neural Networks to seek to answer the question:
can we detect backdoor using adversarial detection methods. Our insights are
based on the observation that both adversarial examples and backdoor examples
have anomalies during the inference process, highly distinguishable from benign
samples. As a result, we revise four existing adversarial defense methods for
detecting backdoor examples. Extensive evaluations indicate that these
approaches provide reliable protection against backdoor attacks, with a higher
accuracy than detecting adversarial examples. These solutions also reveal the
relations of adversarial examples, backdoor examples and normal samples in
model sensitivity, activation space and feature space. This is able to enhance
our understanding about the inherent features of these two attacks and the
defense opportunities.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:09:27 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jul 2022 18:22:05 GMT""}]","2022-08-01"
"2006.14872","Tatsuki Kuwagaki","Tatsuki Kuwagaki","Sheaf quantization from exact WKB analysis","v4: shortened, corrected, and improved, 37 pages",,,,"math.SG hep-th math.AG math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A sheaf quantization is a sheaf associated to a Lagrangian brane. By using
the ideas of exact WKB analysis, spectral networks, and scattering diagrams, we
sheaf-quantize spectral curves over the Novikov ring under some assumptions on
the behavior of Stokes curves. For Schr\""odinger equations, we prove that the
local system associated to the sheaf quantization (microlocalization a.k.a.
abelianization) over the spectral curve can be identified with the
Voros-Iwaki-Nakanishi coordinate. We expect that these sheaf quantizations are
the object-level realizations of the $\hbar$-enhanced Riemann-Hilbert
correspondence.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:11:20 GMT""},{""version"":""v2"",""created"":""Mon, 12 Oct 2020 10:49:00 GMT""},{""version"":""v3"",""created"":""Tue, 22 Feb 2022 10:27:28 GMT""},{""version"":""v4"",""created"":""Mon, 17 Oct 2022 09:52:19 GMT""}]","2022-10-18"
"2006.14873","Simon Ollander","Simon Ollander, Friedrich-Wilhelm Bode, Marcus Baum","Simulation-based Analysis of Multipath Delay Distributions in Urban
  Canyons","10 pages, 10 figures, to be published in 2020 European Navigation
  Conference",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Global navigation satellite systems provide accurate positioning nearly
worldwide. However, in the urban canyons of dense cities, buildings block and
reflect the signals, causing multipath errors. To mitigate multipath errors,
knowledge of the distribution of the reflection delays is important.
Measurements of this distribution have been done in several dense cities, but
it is unknown how the delay distribution depends on the depth of the urban
canyon. To fill this gap, we simulated reflection scenarios in 12 different
environments: from suburban to deep urban canyon. Subsequently, we analyzed the
resulting delay distributions. This paper presents these distributions, and a
method to estimate them using the number of received satellites. According to
our simulation, the multipath delays follow gamma distributions, whose shape
parameters decrease when the urban canyon depth increases. A quadratic model
can estimate the shape parameter using the number of received satellites.
Consequently, depending on the number of received satellites, the distribution
of the reflection delays can be estimated. This information can be combined
with prior knowledge from other methods for improved multipath delay
estimation. In the future, for more realistic results, the effects on signals
that are reflected multiple times and environments other than urban canyons
should be simulated.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:11:29 GMT""},{""version"":""v2"",""created"":""Mon, 5 Oct 2020 11:54:56 GMT""}]","2020-10-06"
"2006.14874","Olivier Besson","Olivier Besson","Analysis of the SNR loss distribution with covariance mismatched
  training samples",,,"10.1109/TSP.2020.3028513",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the distribution of the signal to noise ratio (SNR) loss at the
output of an adaptive filter which is trained with samples that do not share
the same covariance matrix as the samples for which the filter is foreseen. Our
objective is to find an accurate approximation of the distribution of the SNR
loss which has a similar form as in the case of no mismatch. We successively
consider the case where the two covariance matrices satisfy the so-called
generalized eigenrelation and the case where they are arbitrary. In the former
case, this amounts to approximate a central quadratic form in normal variables
while the latter case entails approximating a non-central quadratic form in
Student distributed variables. In order to obtain the approximate distribution,
a Pearson type approach is advocated. A numerical study show that this
approximation is rather accurate and enables one to assess, in a
straightforward manner, the impact of covariance mismatch.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:11:58 GMT""},{""version"":""v2"",""created"":""Mon, 31 Aug 2020 09:45:05 GMT""}]","2020-12-02"
"2006.14875","Alix Marie d'Avigneau","A. Marie d'Avigneau, S. S. Singh, L. M. Murray","Anytime Parallel Tempering","34 Pages, 10 Figures",,"10.1007/s11222-021-10048-0",,"stat.CO","http://creativecommons.org/licenses/by/4.0/","  Developing efficient MCMC algorithms is indispensable in Bayesian inference.
In parallel tempering, multiple interacting MCMC chains run to more efficiently
explore the state space and improve performance. The multiple chains advance
independently through local moves, and the performance enhancement steps are
exchange moves, where the chains pause to exchange their current sample amongst
each other. To accelerate the independent local moves, they may be performed
simultaneously on multiple processors. Another problem is then encountered:
depending on the MCMC implementation and inference problem, local moves can
take a varying and random amount of time to complete. There may also be
infrastructure-induced variations, such as competing jobs on the same
processors, which arises in cloud computing. Before exchanges can occur, all
chains must complete the local moves they are engaged in to avoid introducing a
potentially substantial bias (Proposition 2.1). To solve this issue of randomly
varying local move completion times in multi-processor parallel tempering, we
adopt the Anytime Monte Carlo framework of Murray et al. (2016): we impose
real-time deadlines on the parallel local moves and perform exchanges at these
deadlines without any processor idling. We show our methodology for exchanges
at real-time deadlines does not introduce a bias and leads to significant
performance enhancements over the na\""ive approach of idling until every
processor's local moves complete. The methodology is then applied in an ABC
setting, where an Anytime ABC parallel tempering algorithm is derived for the
difficult task of estimating the parameters of a Lotka-Volterra predator-prey
model, and similar efficiency enhancements are observed.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:15:31 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 14:54:38 GMT""},{""version"":""v3"",""created"":""Tue, 14 Sep 2021 13:13:36 GMT""}]","2021-09-15"
"2006.14876","Tianping Ying","Yanpeng Qi, Tianping Ying, Xianxin Wu, Zhuoya Dong, Masato Sasase,
  Qing Zhang, Weiyan Liu, Masaki Ichihara, Yanhang Ma, Jiangping Hu, Hideo
  Hosono","Superconductivity from buckled-honeycomb-vacancy ordering","38 pages, 24 figures, 3 tables","Science Bulletin, 2021, 66(4):327-331","10.1016/j.scib.2020.12.007",,"cond-mat.supr-con cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vacancies are prevalent and versatile in solid-state physics and materials
science. The role of vacancies in strongly correlated materials, however,
remains uncultivated until now. Here, we report the discovery of an
unprecedented vacancy state forming an extended buckled-honeycomb-vacancy (BHV)
ordering in Ir$_{16}$Sb$_{18}$. Superconductivity emerges by suppressing the
BHV ordering through squeezing of extra Ir atoms into the vacancies or
isovalent Rh substitution. The phase diagram on vacancy ordering reveals the
superconductivity competes with the BHV ordering. Further theoretical
calculations suggest that this ordering originates from a synergistic effect of
the vacancy formation energy and Fermi surface nesting with a wave vector of
(1/3, 1/3, 0). The buckled structure breaks the crystal inversion symmetry and
can mostly suppress the density of states near the Fermi level. The
peculiarities of BHV ordering highlight the importance of ""correlated
vacancies"" and may serve as a paradigm for exploring other non-trivial
excitations and quantum criticality.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:19:02 GMT""}]","2021-05-14"
"2006.14877","Santeri Karppinen","Santeri Karppinen and Matti Vihola","Conditional particle filters with diffuse initial distributions","21 pages, 17 figures",,,,"stat.CO stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conditional particle filters (CPFs) are powerful smoothing algorithms for
general nonlinear/non-Gaussian hidden Markov models. However, CPFs can be
inefficient or difficult to apply with diffuse initial distributions, which are
common in statistical applications. We propose a simple but generally
applicable auxiliary variable method, which can be used together with the CPF
in order to perform efficient inference with diffuse initial distributions. The
method only requires simulatable Markov transitions that are reversible with
respect to the initial distribution, which can be improper. We focus in
particular on random-walk type transitions which are reversible with respect to
a uniform initial distribution (on some domain), and autoregressive kernels for
Gaussian initial distributions. We propose to use on-line adaptations within
the methods. In the case of random-walk transition, our adaptations use the
estimated covariance and acceptance rate adaptation, and we detail their
theoretical validity. We tested our methods with a linear-Gaussian random-walk
model, a stochastic volatility model, and a stochastic epidemic compartment
model with time-varying transmission rate. The experimental findings
demonstrate that our method works reliably with little user specification, and
can be substantially better mixing than a direct particle Gibbs algorithm that
treats initial states as parameters.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:21:13 GMT""},{""version"":""v2"",""created"":""Fri, 20 Nov 2020 14:16:41 GMT""}]","2020-11-23"
"2006.14878","Ema Jurkin","Sonja Gorjanc, Ema Jurkin","$q-$spherical surfaces in Euclidean space",,,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we define $q$-spherical surfaces as the surfaces that contain
the absolute conic of the Euclidean space as a $q-$fold curve. Particular
attention is paid to the surfaces with singular points of the highest order.
Two classes of such surfaces, with one and two $n-$fold points, are discussed
in detail. We study their properties, give their algebraic equations and
visualize them with the program {\it Mathematica}.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:21:26 GMT""}]","2020-06-29"
"2006.14879","David Barnes","D. Barnes, J. A. Davies, R. A. Harrison, J. P. Byrne, C. H. Perry, V.
  Bothmer, J. P. Eastwood, P. T. Gallagher, E. K. J. Kilpua, C. M\""ostl, L.
  Rodriguez, A. P. Rouillard, and D. Odstrcil","CMEs in the Heliosphere: III. A Statistical Analysis of the Kinematic
  Properties Derived from Stereoscopic Geometrical Modelling Techniques Applied
  to CMEs Detected in the Heliosphere from 2008 to 2014 by STEREO/HI-1",,,"10.1007/s11207-020-01717-w",,"astro-ph.SR physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an analysis of coronal mass ejections (CMEs) observed by the
Heliospheric Imagers (HIs) on board NASA's Solar Terrestrial Relations
Observatory (STEREO) spacecraft. Between August 2008 and April 2014 we identify
273 CMEs that are observed simultaneously, by the HIs on both spacecraft. For
each CME, we track the observed leading edge, as a function of time, from both
vantage points, and apply the Stereoscopic Self-Similar Expansion (SSSE)
technique to infer their propagation throughout the inner heliosphere. The
technique is unable to accurately locate CMEs when their observed leading edge
passes between the spacecraft, however, we are able to successfully apply the
technique to 151, most of which occur once the spacecraft separation angle
exceeds 180 degrees, during solar maximum. We find that using a small
half-width to fit the CME can result in observed acceleration to unphysically
high velocities and that using a larger half-width can fail to accurately
locate the CMEs close to the Sun because the method does not account for CME
over-expansion in this region. Observed velocities from SSSE are found to agree
well with single-spacecraft (SSEF) analysis techniques applied to the same
events. CME propagation directions derived from SSSE and SSEF analysis agree
poorly because of known limitations present in the latter. This work was
carried out as part of the EU FP7 HELCATS (Heliospheric Cataloguing, Analysis
and Techniques Service) project (http://www.helcats-fp7.eu/).
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:21:48 GMT""}]","2020-11-11"
"2006.14880","Ludwig Hothorn","Ludwig A. Hothorn and Frank Schaarschmidt","A modified Armitage test for more than a linear trend on proportions","5 Tables",,,,"stat.ME","http://creativecommons.org/publicdomain/zero/1.0/","  The Armitage test for linear trend in proportions can be modified using the
multiple marginal model approach for three regression models with arithmetic,
ordinal and logarithmic dose scores simultaneously, to be powerful against a
wide range of possible dose response relationships. Moreover, it can be used
for particular designs in the generalized linear (mixed) model for the three
common effect sizes odds ratio, risk ratio and risk difference. The related R
package tukeytrend allows simple generalizations, e.g. the analysis 2-by-k
table data with a possible plateau shape or analysing overdispersed
proportions. The evaluation of further real data examples are available in a
vignette to that R package.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:26:47 GMT""}]","2020-06-29"
"2006.14881","Matt Landreman","Matt Landreman and Rogerio Jorge","Magnetic well and Mercier stability of stellarators near the magnetic
  axis",,,"10.1017/S002237782000121X",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have recently demonstrated that by expanding in small distance from the
magnetic axis compared to the major radius, stellarator shapes with low
neoclassical transport can be generated efficiently. To extend the utility of
this new design approach, here we evaluate measures of magnetohydrodynamic
interchange stability within the same expansion. In particular, we evaluate
magnetic well, Mercier's criterion, and resistive interchange stability near a
magnetic axis of arbitrary shape. In contrast to previous work on interchange
stability near the magnetic axis, which used an expansion of the flux
coordinates, here we use the inverse expansion in which the flux coordinates
are the independent variables. Reduced expressions are presented for the
magnetic well and stability criterion in the case of quasisymmetry. The
analytic results are shown to agree with calculations from the VMEC equilibrium
code. Finally, we show that near the axis, Glasser, Greene, & Johnson's
stability criterion for resistive modes approximately coincides with Mercier's
ideal condition.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:27:19 GMT""},{""version"":""v2"",""created"":""Wed, 2 Sep 2020 15:29:48 GMT""}]","2020-10-28"
"2006.14882","Fan Zuo","Fan Zuo, Jingxing Wang, Jingqin Gao, Kaan Ozbay, Xuegang Jeff Ban,
  Yubin Shen, Hong Yang, Shri Iyer","An Interactive Data Visualization and Analytics Tool to Evaluate
  Mobility and Sociability Trends During COVID-19",,,,,"cs.HC cs.CV cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The COVID-19 outbreak has dramatically changed travel behavior in affected
cities. The C2SMART research team has been investigating the impact of COVID-19
on mobility and sociability. New York City (NYC) and Seattle, two of the cities
most affected by COVID-19 in the U.S. were included in our initial study. An
all-in-one dashboard with data mining and cloud computing capabilities was
developed for interactive data analytics and visualization to facilitate the
understanding of the impact of the outbreak and corresponding policies such as
social distancing on transportation systems. This platform is updated regularly
and continues to evolve with the addition of new data, impact metrics, and
visualizations to assist public and decision-makers to make informed decisions.
This paper presents the architecture of the COVID related mobility data
dashboard and preliminary mobility and sociability metrics for NYC and Seattle.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:27:53 GMT""}]","2020-06-29"
"2006.14883","Alberto Verga","Kevissen Sellapillay and Alberto D. Verga","Quantum walk on a graph of spins: magnetism and entanglement","50 pages, 114 references, 30 figures","Phys. Rev. E 103, 032123 (2021)","10.1103/PhysRevE.103.032123",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We introduce a model of a quantum walk on a graph in which a particle jumps
between neighboring nodes and interacts with independent spins sitting on the
edges. Entanglement propagates with the walker. We apply this model to the case
of a one dimensional lattice, to investigate its magnetic and entanglement
properties. In the continuum limit, we recover a Landau-Lifshitz equation that
describes the precession of spins. A rich dynamics is observed, with regimes of
particle propagation and localization, together with spin oscillations and
relaxation. Entanglement of the asymptotic states follows a volume law for most
parameters (the coin rotation angle and the particle-spin coupling).
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:32:57 GMT""}]","2021-03-30"
"2006.14884","Yikai Zhao","Tong Yang, Jizhou Li, Yikai Zhao, Kaicheng Yang, Hao Wang, Jie Jiang,
  Yinda Zhang, Nicholas Zhang","QCluster: Clustering Packets for Flow Scheduling",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Flow scheduling is crucial in data centers, as it directly influences user
experience of applications. According to different assumptions and design
goals, there are four typical flow scheduling problems/solutions: SRPT, LAS,
Fair Queueing, and Deadline-Aware scheduling. When implementing these solutions
in commodity switches with limited number of queues, they need to set static
parameters by measuring traffic in advance, while optimal parameters vary
across time and space. This paper proposes a generic framework, namely
QCluster, to adapt all scheduling problems for limited number of queues. The
key idea of QCluster is to cluster packets with similar weights/properties into
the same queue. QCluster is implemented in Tofino switches, and can cluster
packets at a speed of 3.2 Tbps. To the best of our knowledge, QCluster is the
fastest clustering algorithm. Experimental results in testbed with programmable
switches and ns-2 show that QCluster reduces the average flow completion time
(FCT) for short flows up to 56.6%, and reduces the overall average FCT up to
21.7% over state-of-the-art. All the source code in ns-2 is available in Github
without.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:38:43 GMT""},{""version"":""v2"",""created"":""Sat, 19 Mar 2022 17:38:29 GMT""}]","2022-03-22"
"2006.14885","Fernando Farroni","Fernando Farroni, Luigi Greco, Gioconda Moscariello, Gabriella Zecca","Noncoercive quasilinear elliptic operators with singular lower order
  terms",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a family of quasilinear second order elliptic differential
operators which are not coercive and are defined by functions in Marcinkiewicz
spaces. We prove the existence of a solution to the corresponding Dirichlet
problem. The associated obstacle problem is also solved. Finally, we show
higher integrability of a solution to the Dirichlet problem when the datum is
more regular.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:38:54 GMT""}]","2020-06-29"
"2006.14886","TseChun Wang","Jian Tang and Tse-Chun Wang","Flavour Symmetry Embedded -- GLoBES (FaSE-GLoBES)",,,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neutrino models based on flavour symmetries provide the natural way to
explain the origin of tiny neutrino masses. At the dawn of precision
measurements of neutrino mixing parameters, neutrino mass models can be
constrained and examined by on-going and up-coming neutrino experiments. We
present a supplemental tool Flavour Symmetry Embedded (FaSE) for General Long
Baseline Experiment Simulator (GLoBES), and it is available via the link
https://github.com/tcwphy/FASE_GLoBES. It can translate the neutrino mass model
parameters to standard neutrino oscillation parameters and offer prior
functions in a user-friendly way. We demonstrate the robustness of FaSE-GLoBE
with four examples on how the model parameters can be constrained and even
whether the model is excluded by an experiment or not. We wish that this
toolkit will facilitate the study of new neutrino mass models in an effecient
and effective manner.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:38:55 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 02:54:16 GMT""}]","2020-07-08"
"2006.14887","Andreas Klos","Andreas Klos, Marius Rosenbaum, Wolfram Schiffmann","Ensemble Transfer Learning for Emergency Landing Field Identification on
  Moderate Resource Heterogeneous Kubernetes Cluster",,,,,"cs.CV cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The full loss of thrust of an aircraft requires fast and reliable decisions
of the pilot. If no published landing field is within reach, an emergency
landing field must be selected. The choice of a suitable emergency landing
field denotes a crucial task to avoid unnecessary damage of the aircraft, risk
for the civil population as well as the crew and all passengers on board.
Especially in case of instrument meteorological conditions it is indispensable
to use a database of suitable emergency landing fields. Thus, based on public
available digital orthographic photos and digital surface models, we created
various datasets with different sample sizes to facilitate training and testing
of neural networks. Each dataset consists of a set of data layers. The best
compositions of these data layers as well as the best performing transfer
learning models are selected. Subsequently, certain hyperparameters of the
chosen models for each sample size are optimized with Bayesian and Bandit
optimization. The hyperparameter tuning is performed with a self-made
Kubernetes cluster. The models outputs were investigated with respect to the
input data by the utilization of layer-wise relevance propagation. With
optimized models we created an ensemble model to improve the segmentation
performance. Finally, an area around the airport of Arnsberg in North
Rhine-Westphalia was segmented and emergency landing fields are identified,
while the verification of the final approach's obstacle clearance is left
unconsidered. These emergency landing fields are stored in a PostgreSQL
database.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:40:32 GMT""},{""version"":""v2"",""created"":""Mon, 31 Aug 2020 09:35:34 GMT""}]","2020-09-01"
"2006.14888","Mattias Nordin","Mattias Nordin and M{\aa}rten Schultzberg","Properties of restricted randomization with implications for
  experimental design",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, there as been an increasing interest in the use of heavily
restricted randomization designs which enforces balance on observed covariates
in randomized controlled trials. However, when restrictions are strict, there
is a risk that the treatment effect estimator will have a very high mean
squared error. In this paper, we formalize this risk and propose a novel
combinatoric-based approach to describe and address this issue. First, we
validate our new approach by re-proving some known properties of complete
randomization and restricted randomization. Second, we propose a novel
diagnostic measure for restricted designs that only use the information
embedded in the combinatorics of the design. Third, we show that the variance
of the mean squared error of the difference-in-means estimator in a randomized
experiment is a linear function of this diagnostic measure. Finally, we
identify situations in which restricted designs can lead to an increased risk
of getting a high mean squared error and discuss how our diagnostic measure can
be used to detect such designs. Our results have implications for any
restricted randomization design and can be used to evaluate the trade-off
between enforcing balance on observed covariates and avoiding too restrictive
designs.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:56:09 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 13:04:00 GMT""},{""version"":""v3"",""created"":""Thu, 14 Oct 2021 14:40:39 GMT""}]","2021-10-15"
"2006.14889","Stefano Mandelli Dr.","Stefano Mandelli, Elenia Manzan, Aniello Mennella, Francesco
  Cavaliere, Daniele Vigan\`o, Cristian Franceschet, Paolo de Bernardis, Marco
  Bersanelli, Maria Gabriella Castellano, Alessandro Coppolecchia, Angelo
  Cruciani, Massimo Gervasi, Luca Lamagna, Andrea Limonta, Silvia Masi,
  Alessandro Paiella, Andrea Passerini, Giorgio Pettinari, Francesco
  Piacentini, Elisabetta Tommasi, Angela Volpe, Mario Zannoni","A chemically etched corrugated feedhorn array for D-band CMB
  observations",,"Experimental Astronomy, 2021","10.1007/s10686-021-09698-9",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the design, manufacturing, and testing of a 37-element array of
corrugated feedhorns for Cosmic Microwave Background (CMB) measurements between
$140$ and $170$ GHz. The array was designed to be coupled to Kinetic Inductance
Detector arrays, either directly (for total power measurements) or through an
orthomode transducer (for polarization measurements). We manufactured the array
in platelets by chemically etching aluminum plates of $0.3$ mm and $0.4$ mm
thickness. The process is fast, low-cost, scalable, and yields high-performance
antennas compared to other techniques in the same frequency range. Room
temperature electromagnetic measurements show excellent repeatability with an
average cross polarization level about $-20$ dB, return loss about $-25$ dB,
first sidelobes below $-25$ dB and far sidelobes below $-35$ dB. Our results
qualify this process as a valid candidate for state-of-the-art CMB experiments,
where large detector arrays with high sensitivity and polarization purity are
of paramount importance in the quest for the discovery of CMB polarization
$B$-modes.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:57:44 GMT""},{""version"":""v2"",""created"":""Mon, 19 Oct 2020 14:36:51 GMT""},{""version"":""v3"",""created"":""Wed, 21 Oct 2020 16:49:05 GMT""}]","2021-02-02"
"2006.14890","Dr Gregory Epiphaniou","Carsten Maple and Peter Davies and Kerstin Eder and Chris Hankin and
  Greg Chance and Gregory Epiphaniou","CyRes -- Avoiding Catastrophic Failure in Connected and Autonomous
  Vehicles (Extended Abstract)","7 pages, extended abstract",,,,"cs.CR cs.CY cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing approaches to cyber security and regulation in the automotive sector
cannot achieve the quality of outcome necessary to ensure the safe mass
deployment of advanced vehicle technologies and smart mobility systems. Without
sustainable resilience hard-fought public trust will evaporate, derailing
emerging global initiatives to improve the efficiency, safety and environmental
impact of future transport. This paper introduces an operational cyber
resilience methodology, CyRes, that is suitable for standardisation. The CyRes
methodology itself is capable of being tested in court or by publicly appointed
regulators. It is designed so that operators understand what evidence should be
produced by it and are able to measure the quality of that evidence. The
evidence produced is capable of being tested in court or by publicly appointed
regulators. Thus, the real-world system to which the CyRes methodology has been
applied is capable of operating at all times and in all places with a legally
and socially acceptable value of negative consequence.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:59:52 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 15:12:59 GMT""},{""version"":""v3"",""created"":""Fri, 3 Jul 2020 10:54:33 GMT""}]","2020-07-06"
"2006.14891","Manana Kachakhidze","Manana Kachakhidze, Nino Kachakhidze-Murphy, Badri Kvitia, Giorgi
  Khazaradze","Seismogenic Mobile Network","10 pages, one figure",,,,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  In the presented paper we will focus on the optimal option of network
arrangemnet of the VLF / LF EM radiation before the earthquakes. The paper
discusses the new possibility of arrangement of VLF / LF network based on
certain physical considerations, which is relatively simplified and completely
different from the existing networks. It will increase to the limit the number
of earthquakes fixed with the relevant EM emissions which is the aim of the new
network arrangement.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:01:40 GMT""}]","2020-06-29"
"2006.14892","Wolfgang Stockinger","Gunther Leobacher, Christoph Reisinger and Wolfgang Stockinger","Well-posedness and numerical schemes for one-dimensional McKean-Vlasov
  equations and interacting particle systems with discontinuous drift","33 pages, 4 figures",,,,"math.PR cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we first establish well-posedness results for one-dimensional
McKean-Vlasov stochastic differential equations (SDEs) and related particle
systems with a measure-dependent drift coefficient that is discontinuous in the
spatial component, and a diffusion coefficient which is a Lipschitz function of
the state only. We only require a fairly mild condition on the diffusion
coefficient, namely to be non-zero in a point of discontinuity of the drift,
while we need to impose certain structural assumptions on the
measure-dependence of the drift. Second, we study Euler-Maruyama type schemes
for the particle system to approximate the solution of the one-dimensional
McKean-Vlasov SDE. Here, we will prove strong convergence results in terms of
the number of time-steps and number of particles. Due to the discontinuity of
the drift, the convergence analysis is non-standard and the usual strong
convergence order $1/2$ known for the Lipschitz case cannot be recovered for
all schemes.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:04:34 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 08:40:07 GMT""},{""version"":""v3"",""created"":""Wed, 27 Oct 2021 07:34:06 GMT""},{""version"":""v4"",""created"":""Tue, 15 Mar 2022 09:32:50 GMT""}]","2022-03-16"
"2006.14893","Saurabh Shrivastava","K. Jotsaroop, Saurabh Shrivastava","Unimodular bilinear Fourier multipliers on $L^p$ spaces","Typos corrected. To appear in Monatsh. Math",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we investigate the boundedness properties of bilinear
multiplier operators associated with unimodular functions of the form
$m(\xi,\eta)=e^{i \phi(\xi-\eta)}$. We prove that if $\phi$ is a $C^1(\mathbb
R^n)$ real-valued non-linear function, then for all exponents $p,q,r$ lying
outside the local $L^2-$range and satisfying the H\""{o}lder's condition
$\frac{1}{p}+\frac{1}{q}=\frac{1}{r}$, the bilinear multiplier norm
$$\|e^{i\lambda \phi(\xi-\eta)}\|_{\mathcal M_{p,q,r}(\mathbb R^n)}\rightarrow
\infty,~ \lambda \in \mathbb R,~ |\lambda|\rightarrow \infty.$$ For exponents
in the local $L^2-$range, we give examples of unimodular functions of the form
$e^{i\phi(\xi-\eta)}$, which do not give rise to bilinear multipliers. Further,
we also discuss the essential continuity property of bilinear multipliers for
exponents outside local $L^2-$ range.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:09:18 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jul 2020 03:49:25 GMT""}]","2020-07-20"
"2006.14894","Marcin Bia{\l}as","Marcin Bia{\l}as, Marcin Micha{\l} Miro\'nczuk, Jacek Ma\'ndziuk","Biologically Plausible Learning of Text Representation with Spiking
  Neural Networks","This article was originally submitted for Parallel Problem Solving
  from Nature conference and will be available in Springer Lecture Notes in
  Computer Science (LNCS)","16th International Conference on Parallel Problem Solving from
  Nature, PPSN 2020, 433-447, LNCS vol. 12269","10.1007/978-3-030-58112-1_30",,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study proposes a novel biologically plausible mechanism for generating
low-dimensional spike-based text representation. First, we demonstrate how to
transform documents into series of spikes spike trains which are subsequently
used as input in the training process of a spiking neural network (SNN). The
network is composed of biologically plausible elements, and trained according
to the unsupervised Hebbian learning rule, Spike-Timing-Dependent Plasticity
(STDP). After training, the SNN can be used to generate low-dimensional
spike-based text representation suitable for text/document classification.
Empirical results demonstrate that the generated text representation may be
effectively used in text classification leading to an accuracy of $80.19\%$ on
the bydate version of the 20 newsgroups data set, which is a leading result
amongst approaches that rely on low-dimensional text representations.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:14:25 GMT""}]","2022-08-23"
"2006.14895","Martin J{\o}rgensen","Martin J{\o}rgensen, Marc Peter Deisenroth, Hugh Salimbeni","Stochastic Differential Equations with Variational Wishart Diffusions","ICML 2020",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a Bayesian non-parametric way of inferring stochastic differential
equations for both regression tasks and continuous-time dynamical modelling.
The work has high emphasis on the stochastic part of the differential equation,
also known as the diffusion, and modelling it by means of Wishart processes.
Further, we present a semi-parametric approach that allows the framework to
scale to high dimensions. This successfully lead us onto how to model both
latent and auto-regressive temporal systems with conditional heteroskedastic
noise. We provide experimental evidence that modelling diffusion often improves
performance and that this randomness in the differential equation can be
essential to avoid overfitting.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:21:35 GMT""}]","2020-06-29"
"2006.14896","Aleksandr Mosenkov","Aleksandr V. Mosenkov, Anton A. Smirnov, Olga K. Sil'chenko, R.
  Michael Rich, Vladimir P. Reshetnikov, John Kormendy","Tilted outer and inner structures in edge-on galaxies?","20 pages, 19 figures, Accepted for publication in MNRAS",,"10.1093/mnras/staa1885",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tilted and warped discs inside tilted dark matter haloes are predicted from
numerical and semi-analytical studies. In this paper, we use deep imaging to
demonstrate the likely existence of tilted outer structures in real galaxies.
We consider two SB0 edge-on galaxies, NGC4469 and NGC4452, which exhibit
apparent tilted outer discs with respect to the inner structure. In NGC4469,
this structure has a boxy shape, inclined by $\Delta$PA$\approx$3$^{\circ}$
with respect to the inner disc, whereas NGC4452 harbours a discy outer
structure with $\Delta$PA$\approx$6$^{\circ}$. In spite of the different
shapes, both structures have surface brightness profiles close to exponential
and make a large contribution ($\sim30$%) to the total galaxy luminosity. In
the case of NGC4452, we propose that its tilted disc likely originates from a
former fast tidal encounter (probably with IC3381). For NGC4469, a plausible
explanation may also be galaxy harassment, which resulted in a tilted or even a
tumbling dark matter halo. A less likely possibility is accretion of gas-rich
satellites several Gyr ago. New deep observations may potentially reveal more
such galaxies with tilted outer structures, especially in clusters. We also
consider galaxies, mentioned in the literature, where a central component (a
bar or a bulge) is tilted with respect to the stellar disc. According to our
numerical simulations, one of the plausible explanations of such observed
""tilts"" of the bulge/bar is a projection effect due to a not exactly edge-on
orientation of the galaxy coupled with a skew angle of the triaxial bulge/bar.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:21:55 GMT""}]","2020-07-15"
"2006.14897","Young-Jin Park","Young-Jin Park, Kyuyong Shin, Kyung-Min Kim","Hop Sampling: A Simple Regularized Graph Learning for Non-Stationary
  Environments","presented in KDD 2020 Workshop on Mining and Learning with Graphs
  (MLG)",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph representation learning is gaining popularity in a wide range of
applications, such as social networks analysis, computational biology, and
recommender systems. However, different with positive results from many
academic studies, applying graph neural networks (GNNs) in a real-world
application is still challenging due to non-stationary environments. The
underlying distribution of streaming data changes unexpectedly, resulting in
different graph structures (a.k.a., concept drift). Therefore, it is essential
to devise a robust graph learning technique so that the model does not overfit
to the training graphs. In this work, we present Hop Sampling, a
straightforward regularization method that can effectively prevent GNNs from
overfishing. The hop sampling randomly selects the number of propagation steps
rather than fixing it, and by doing so, it encourages the model to learn
meaningful node representation for all intermediate propagation layers and to
experience a variety of plausible graphs that are not in the training set.
Particularly, we describe the use case of our method in recommender systems, a
representative example of the real-world non-stationary case. We evaluated hop
sampling on a large-scale real-world LINE dataset and conducted an online A/B/n
test in LINE Coupon recommender systems of LINE Wallet Tab. Experimental
results demonstrate that the proposed scheme improves the prediction accuracy
of GNNs. We observed hop sampling provides 7.97% and 16.93% improvements for
NDCG and MAP compared to non-regularized GNN models in our online service.
Furthermore, models using hop sampling alleviate the oversmoothing issue in
GNNs enabling a deeper model as well as more diversified representation.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:22:57 GMT""},{""version"":""v2"",""created"":""Thu, 20 Aug 2020 05:47:55 GMT""}]","2020-08-21"
"2006.14898","Megan Griffin-Pickering","Megan Griffin-Pickering and Mikaela Iacobelli","Global strong solutions in $\mathbb{R}^3$ for ionic Vlasov-Poisson
  systems","25 pages; minor changes",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Systems of Vlasov-Poisson type are kinetic models describing dilute plasma.
The structure of the model differs according to whether it describes the
electrons or positively charged ions in the plasma. In contrast to the electron
case, where the well-posedness theory for Vlasov-Poisson systems is well
established, the well-posedness theory for ion models has been investigated
more recently. In this article, we prove global well-posedness for two
Vlasov-Poisson systems for ions, posed on the whole three-dimensional Euclidean
space $\mathbb{R}^3$, under minimal assumptions on the initial data and the
confining potential.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:33:54 GMT""},{""version"":""v2"",""created"":""Tue, 6 Oct 2020 14:21:21 GMT""},{""version"":""v3"",""created"":""Tue, 25 May 2021 19:11:17 GMT""}]","2021-05-27"
"2006.14899","Yulia Krasnikova","Yu. V. Krasnikova, S. C. Furuya, V. N. Glazkov, K. Yu. Povarov, D.
  Blosser, and A. Zheludev","Anisotropy-induced soliton excitation in magnetized strong-rung spin
  ladders","6 pages main text and 4 figures with supplemental materials 8 pages
  and 2 figures","Phys. Rev. Lett. 125 (2020) 027204","10.1103/PhysRevLett.125.027204",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report low temperature electron spin resonance experimental and
theoretical studies of an archetype $S=1/2$ strong-rung spin ladder material
(C$_{5}$H$_{12}$N)$_{2}$CuBr$_{4}$. Unexpected dynamics is detected deep in the
Tomonaga-Luttinger spin liquid regime. Close to the point where the system is
half-magnetized (and believed to be equivalent to a gapless easy plane chain in
zero field) we observed orientation-dependent spin gap and anomalous $g$-factor
values. Field theoretical analysis demonstrates that the observed low-energy
excitation modes in magnetized (C$_{5}$H$_{12}$N)$_{2}$CuBr$_{4}$ are solitonic
excitations caused by Dzyaloshinskii-Moriya interaction presence.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:34:03 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 15:51:15 GMT""}]","2020-07-21"
"2006.14900","Marek Szydlowski","Marek Szydlowski and Adam Krawiec","Interpretation of bulk viscosity as the generalized Chaplygin gas","LaTeX, 10 pages, 6 figures; new section on dynamics of two fluid
  model",,,,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cosmological observations suggest that the presently accelerating
universe should be filled by an exotic form of matter, violating the strong
energy condition, of unknown nature and origin. We propose the viscous dark
matter of a source of acceleration in the form of Chaplygin gas which is
characterized by equation of state in the phenomenological form
$p=-\frac{A}{\rho^{\alpha}}$, where $p$ and $\rho$ are pressure and energy
density respectively ($A$ and $\alpha$ are constants). Chaplygin gas is
interpreted in terms of viscous matter and without the cosmological constant.
The acceleration effect is caused only by viscosity in this class of
cosmological models. We show that bulk viscosity effects introduced to the
standard FRW cosmology give rise to the natural unification of both dark matter
and dark energy. We show that dust viscous cosmological models are structurally
stable if $m < 1/2$ ($1+\alpha=1/2-m$).
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:37:07 GMT""},{""version"":""v2"",""created"":""Tue, 4 Aug 2020 15:59:17 GMT""}]","2020-08-05"
"2006.14901","Jiajin Li","Jiajin Li, Anthony Man-Cho So, Wing-Kin Ma","Understanding Notions of Stationarity in Non-Smooth Optimization","Accepted for publication in IEEE Signal Processing Magazine, 2020",,,,"math.OC cs.LG eess.SP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many contemporary applications in signal processing and machine learning give
rise to structured non-convex non-smooth optimization problems that can often
be tackled by simple iterative methods quite effectively. One of the keys to
understanding such a phenomenon---and, in fact, one of the very difficult
conundrums even for experts---lie in the study of ""stationary points"" of the
problem in question. Unlike smooth optimization, for which the definition of a
stationary point is rather standard, there is a myriad of definitions of
stationarity in non-smooth optimization. In this article, we give an
introduction to different stationarity concepts for several important classes
of non-convex non-smooth functions and discuss the geometric interpretations
and further clarify the relationship among these different concepts. We then
demonstrate the relevance of these constructions in some representative
applications and how they could affect the performance of iterative methods for
tackling these applications.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:38:23 GMT""}]","2020-06-29"
"2006.14902","Nicola Maggiore","Erica Bertolini and Nicola Maggiore","Holographic Projection of Electromagnetic Maxwell Theory","29 pages","Symmetry 2020, 12, 1134","10.3390/sym12071134",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The 4D Maxwell theory with single-sided planar boundary is considered. As a
consequence of the presence of the boundary, two broken Ward identities are
recovered, which, on-shell, give rise to two conserved currents living on the
edge. A Ka\c{c}-Moody algebra formed by a subset of the bulk fields is obtained
with central charge proportional to the inverse of the Maxwell coupling
constant, and the degrees of freedom of the boundary theory are identified as
two vector fields, also suggesting that the 3D theory should be a gauge theory.
Finally the holographic contact between bulk and boundary theory is reached in
two inequivalent ways, both leading to a unique 3D action describing a new
gauge theory of two coupled vector fields with a topological Chern-Simons term
with massive coefficient. In order to check that the 3D projection of 4D
Maxwell theory is well defined, we computed the energy-momentum tensor and the
propagators. The role of discrete symmetries is briefly discussed.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:44:04 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jul 2020 16:49:16 GMT""}]","2020-07-08"
"2006.14903","Antoine Petit C.","Antoine C. Petit, Gabriele Pichierri, Melvyn B. Davies and Anders
  Johansen","The path to instability in compact multi-planetary systems","Accepted in A&A. Added numerical tests with test particles and non
  uniform systems. A notebook as well as python scripts to reproduce the
  article figure are available at
  https://github.com/acpetit/PlanetSysSurvivalTime","A&A 641, A176 (2020)","10.1051/0004-6361/202038764",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dynamical stability of tightly packed exoplanetary systems remains poorly
understood. While for a two-planet system a sharp stability boundary exists,
numerical simulations of three and more planet systems show that they can
experience instability on timescales up to billions of years. Moreover, an
exponential trend between the planet orbital separation measured in units of
Hill radii and the survival time has been reported. While these findings have
been observed in numerous numerical simulations, little is known of the actual
mechanism leading to instability. Contrary to a constant diffusion process,
planetary systems seem to remain dynamically quiescent for most of their
lifetime before a very short unstable phase. In this work, we show how the slow
chaotic diffusion due to the overlap of three-body resonances dominates the
timescale leading to the instability for initially coplanar and circular
orbits. While the last instability phase is related to scattering due to
two-planet mean motion resonances (MMR), for circular orbits the two-planets
MMR are too far separated to destabilize systems initially away from them. We
develop an analytical model to generalize the empirical trend obtained for
equal mass and equally-spaced planets to general systems. We obtain an
analytical estimate of the survival time consistent with simulations over four
orders of magnitude for the planet to star mass ratio $\epsilon$, and 6 to 8
orders of magnitude for the instability time. We also confirm that measuring
the orbital spacing in terms of Hill radii is not adapted and that the right
spacing unit scales as $\epsilon^{1/4}$. We predict that beyond a certain
spacing, the three-planet resonances are not overlapped, which results in an
increase of the survival time. We finally discuss the extension of our result
to more general systems, containing more planets on initially non circular
orbits.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:44:18 GMT""},{""version"":""v2"",""created"":""Tue, 18 Aug 2020 14:31:05 GMT""}]","2020-09-30"
"2006.14904","Andrea Skolik","Andrea Skolik, Jarrod R. McClean, Masoud Mohseni, Patrick van der
  Smagt, Martin Leib","Layerwise learning for quantum neural networks","11 pages, 7 figures","Quantum Machine Intelligence Vol. 3, No. 5 (2021)","10.1007/s42484-020-00036-4",,"quant-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the increased focus on quantum circuit learning for near-term
applications on quantum devices, in conjunction with unique challenges
presented by cost function landscapes of parametrized quantum circuits,
strategies for effective training are becoming increasingly important. In order
to ameliorate some of these challenges, we investigate a layerwise learning
strategy for parametrized quantum circuits. The circuit depth is incrementally
grown during optimization, and only subsets of parameters are updated in each
training step. We show that when considering sampling noise, this strategy can
help avoid the problem of barren plateaus of the error surface due to the low
depth of circuits, low number of parameters trained in one step, and larger
magnitude of gradients compared to training the full circuit. These properties
make our algorithm preferable for execution on noisy intermediate-scale quantum
devices. We demonstrate our approach on an image-classification task on
handwritten digits, and show that layerwise learning attains an 8% lower
generalization error on average in comparison to standard learning schemes for
training quantum circuits of the same size. Additionally, the percentage of
runs that reach lower test errors is up to 40% larger compared to training the
full circuit, which is susceptible to creeping onto a plateau during training.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:44:46 GMT""}]","2021-09-10"
"2006.14905","Marco Pezzella","Marco Pezzella, Krystel El Hage, Michiel J.M. Niesen, Sucheol Shin,
  Adam P. Willard, Markus Meuwly and Martin Karplus","Water Dynamics Around Proteins: T- and R-States of Hemoglobin and
  Melittin",,,,,"physics.chem-ph q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The water dynamics, as characterized by the local hydrophobicity (LH), is
investigated for tetrameric hemoglobin and dimeric melittin. For the T0 to R0
transition in Hb it is found that LH provides additional molecular-level
insight into the Perutz mechanism, i.e., the breaking and formation of salt
bridges at the alpha1 / beta2 and alpha2 / beta1 interface is accompanied by
changes in LH. For Hb in cubic water boxes with 90 Aengstroem and 120
Aengstroem edge length it is observed that following a decrease in LH as a
consequence of reduced water density or change of water orientation at the
protein/water interface the alpha / beta interfaces are destabilized; this is a
hallmark of the Perutz stereochemical model for the T to R transition in Hb.
The present work thus provides a dynamical view of the classical structural
model relevant to the molecular foundations of Hb function. For dimeric
melittin, earlier results by Cheng and Rossky (Nature, 1998, 392, 696-699) are
confirmed and interpreted on the basis of LH from simulations in which the
protein structure is frozen. For the flexible melittin dimer the changes in the
local hydration can be as much as 30 % than for the rigid dimer, reflecting the
fact that protein and water dynamics are coupled.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:46:54 GMT""}]","2020-06-29"
"2006.14906","Mieke Bouwhuis","Mieke Bouwhuis (1 and 2), Keith W. Bannister (1), Jean-Pierre Macquart
  (3), R. M. Shannon (4), David L. Kaplan (5), John D. Bunton (1), B\""arbel S.
  Koribalski (1), M. T. Whiting (1) ((1) CSIRO, (2) NIKHEF, (3) ICRAR, (4)
  Centre for Astrophysics and Supercomputing, Swinburne University, (5) Centre
  for Gravitation, Cosmology, and Astrophysics, University of
  Wisconsin-Milwaukee)","A search for fast radio burst-like emission from Fermi gamma-ray bursts","Accepted for publication in Monthly Notices of the Royal Astronomical
  Society Main Journal","MNRAS 497, 125-129 (2020)","10.1093/mnras/staa1889",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the results of the rapid follow-up observations of gamma-ray bursts
(GRBs) detected by the Fermi satellite to search for associated fast radio
bursts. The observations were conducted with the Australian Square Kilometre
Array Pathfinder at frequencies from 1.2-1.4 GHz. A set of 20 bursts, of which
four were short GRBs, were followed up with a typical latency of about one
minute, for a duration of up to 11 hours after the burst. The data was searched
using 4096 dispersion measure trials up to a maximum dispersion measure of 3763
pc cm$^{-3}$, and for pulse widths $w$ over a range of duration from 1.256 to
40.48 ms. No associated pulsed radio emission was observed above $26 {\rm Jy
ms} (w/1 {\rm ms})^{-1/2}$ for any of the 20 GRBs.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:47:02 GMT""}]","2020-08-24"
"2006.14907","Rachel Newton","Francesca Balestrieri, Alexis Johnson and Rachel Newton","Explicit uniform bounds for Brauer groups of singular K3 surfaces","Minor changes. Final version, to appear in Annales de l'Institut
  Fourier. 34 pages. Comments welcome!",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $k$ be a number field. We give an explicit bound, depending only on
$[k:\mathbf{Q}]$ and the discriminant of the N\'{e}ron--Severi lattice, on the
size of the Brauer group of a K3 surface $X/k$ that is geometrically isomorphic
to the Kummer surface attached to a product of isogenous CM elliptic curves. As
an application, we show that the Brauer--Manin set for such a variety is
effectively computable. Conditional on GRH, we can also make the explicit bound
depend only on $[k:\mathbf{Q}]$ and remove the condition that the elliptic
curves be isogenous. In addition, we show how to obtain a bound, depending only
on $[k:\mathbf{Q}]$, on the number of $\mathbf{C}$-isomorphism classes of
singular K3 surfaces defined over $k$, thus proving an effective version of the
strong Shafarevich conjecture for singular K3 surfaces.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:48:31 GMT""},{""version"":""v2"",""created"":""Wed, 4 Nov 2020 13:35:13 GMT""},{""version"":""v3"",""created"":""Sun, 15 Nov 2020 17:58:29 GMT""},{""version"":""v4"",""created"":""Fri, 5 Aug 2022 16:28:50 GMT""}]","2022-08-08"
"2006.14908","Geza Toth","J\'anos Pach, G\'abor Tardos, G\'eza T\'oth","Crossings between non-homotopic edges","Appears in the Proceedings of the 28th International Symposium on
  Graph Drawing and Network Visualization (GD 2020)",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We call a multigraph {\em non-homotopic} if it can be drawn in the plane in
such a way that no two edges connecting the same pair of vertices can be
continuously transformed into each other without passing through a vertex, and
no loop can be shrunk to its end-vertex in the same way. It is easy to see that
a non-homotopic multigraph on $n>1$ vertices can have arbitrarily many edges.
We prove that the number of crossings between the edges of a non-homotopic
multigraph with $n$ vertices and $m>4n$ edges is larger than $c\frac{m^2}{n}$
for some constant $c>0$, and that this bound is tight up to a polylogarithmic
factor. We also show that the lower bound is not asymptotically sharp as $n$ is
fixed and $m$ tends to infinity.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:53:12 GMT""},{""version"":""v2"",""created"":""Thu, 10 Sep 2020 14:30:15 GMT""},{""version"":""v3"",""created"":""Sat, 19 Sep 2020 13:38:11 GMT""}]","2020-09-22"
"2006.14909","David D. O'Regan","Claudia Backes, Davide Campi, Beata M. Szydlowska, Kevin Synnatschke,
  Ezgi Ojala, Farnia Rashvand, Andrew Harvey, Aideen Griffin, Zdenek Sofer,
  Nicola Marzari, Jonathan N. Coleman, and David D. O'Regan","Equipartition of Energy Defines the Size-Thickness Relationship in
  Liquid-Exfoliated Nanosheets","Accepted Manuscript (30 pages) and Supporting Information (68 pages)","ACS Nano 2019, 13, 6, 7050-7061","10.1021/acsnano.9b02234",,"physics.chem-ph cond-mat.mes-hall cond-mat.stat-mech physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Liquid phase exfoliation is a commonly used method to produce 2D nanosheets
from a range of layered crystals. However, such nanosheets display broad size
and thickness distributions and correlations between area and thickness, issues
that limit nanosheet application potential. To understand the factors
controlling the exfoliation process, we have liquid-exfoliated 11 different
layered materials, size-selecting each into fractions before using AFM to
measure the nanosheet length, width, and thickness distributions for each
fraction. The resultant data show a clear power-law scaling of nanosheet area
with thickness for each material. We have developed a simple nonequilibrium
thermodynamics-based model predicting that the power-law prefactor is
proportional to both the ratios of in-plane-tearing/out-of-plane-peeling
energies and in-plane/out-of-plane moduli. By comparing the experimental data
with the modulus ratio calculated from first-principles, we find close
agreement between experiment and theory. This supports our hypothesis that
energy equipartition holds between nanosheet tearing and peeling during
sonication-assisted exfoliation.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:56:01 GMT""}]","2020-06-29"
"2006.14910","Francisco Prada","Anatoly Klypin, Vivian Poulin, Francisco Prada, Joel Primack, Marc
  Kamionkowski, Vladimir Avila-Reese, Aldo Rodriguez-Puebla, Peter Behroozi,
  Doug Hellinger, Tristan L. Smith","Clustering and Halo Abundances in Early Dark Energy Cosmological Models","13 pages, 12 figures, submitted to MNRAS",,"10.1093/mnras/stab769",,"astro-ph.CO astro-ph.GA gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  LCDM cosmological models with Early Dark Energy (EDE) have been proposed to
resolve tensions between the Hubble constant H0 = 100h km/s/Mpc measured
locally, giving h ~ 0.73, and H0 deduced from Planck cosmic microwave
background (CMB) and other early universe measurements plus LCDM, giving h ~
0.67. EDE models do this by adding a scalar field that temporarily adds dark
energy equal to about 10% of the cosmological energy density at the end of the
radiation-dominated era at redshift z ~ 3500. Here we compare linear and
nonlinear predictions of a Planck-normalized LCDM model including EDE giving h
= 0.728 with those of standard Planck-normalized LCDM with h = 0.678. We find
that nonlinear evolution reduces the differences between power spectra of
fluctuations at low redshifts. As a result, at z = 0 the halo mass functions on
galactic scales are nearly the same, with differences only 1-2%. However, the
differences dramatically increase at high redshifts. The EDE model predicts 50%
more massive clusters at z = 1 and twice more galaxy-mass halos at z = 4. Even
greater increases in abundances of galaxy-mass halos at higher redshifts may
make it easier to reionize the universe with EDE. Predicted galaxy abundances
and clustering will soon be tested by JWST observations. Positions of baryonic
acoustic oscillations (BAOs) and correlation functions differ by about 2%
between the models -- an effect that is not washed out by nonlinearities. Both
standard LCDM and the EDE model studied here agree well with presently
available acoustic-scale observations, but DESI and Euclid measurements will
provide stringent new tests.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:58:29 GMT""}]","2021-04-07"
"2006.14911","Angelos Filos","Angelos Filos, Panagiotis Tigas, Rowan McAllister, Nicholas Rhinehart,
  Sergey Levine, Yarin Gal","Can Autonomous Vehicles Identify, Recover From, and Adapt to
  Distribution Shifts?","The first two authors contributed equally. Accepted at ICML 2020.
  Supplementary videos and code available at:
  https://sites.google.com/view/av-detect-recover-adapt",,,,"cs.LG cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Out-of-training-distribution (OOD) scenarios are a common challenge of
learning agents at deployment, typically leading to arbitrary deductions and
poorly-informed decisions. In principle, detection of and adaptation to OOD
scenes can mitigate their adverse effects. In this paper, we highlight the
limitations of current approaches to novel driving scenes and propose an
epistemic uncertainty-aware planning method, called \emph{robust imitative
planning} (RIP). Our method can detect and recover from some distribution
shifts, reducing the overconfident and catastrophic extrapolations in OOD
scenes. If the model's uncertainty is too great to suggest a safe course of
action, the model can instead query the expert driver for feedback, enabling
sample-efficient online adaptation, a variant of our method we term
\emph{adaptive robust imitative planning} (AdaRIP). Our methods outperform
current state-of-the-art approaches in the nuScenes \emph{prediction}
challenge, but since no benchmark evaluating OOD detection and adaption
currently exists to assess \emph{control}, we introduce an autonomous car
novel-scene benchmark, \texttt{CARNOVEL}, to evaluate the robustness of driving
agents to a suite of tasks with distribution shifts.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:07:32 GMT""},{""version"":""v2"",""created"":""Wed, 2 Sep 2020 08:22:46 GMT""}]","2020-09-03"
"2006.14912","Ke-Jin Zhou","Jiemin Li, Abhishek Nag, Jonathan Pelliciari, Hannah Robarts, Andrew
  Walters, Mirian Garcia-Fernandez, Hiroshi Eisaki, Dongjoon Song, Hong Ding,
  Steven Johnston, Riccardo Comin, Ke-Jin Zhou","Multi-orbital charge density wave excitations and concomitant phonon
  anomalies in Bi$_2$Sr$_2$LaCuO$_{6+\delta}$","25 pages + Supplementary Information. Proc. Natl Acad. Sci. USA,
  (2020)","PNAS July 14, 2020 117 (28) 16219-16225","10.1073/pnas.2001755117",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Charge density waves (CDWs) are ubiquitous in under-doped cuprate
superconductors. As a modulation of the valence electron density, CDWs in
hole-doped cuprates possess both Cu-3d and O-2p orbital character owing to the
strong hybridization of these orbitals near the Fermi level. Here, we
investigate under-doped Bi$_2$Sr$_{1.4}$La$_{0.6}$CuO$_{6+\delta}$ using
resonant inelastic X-ray scattering (RIXS) and find that a short-range CDW
exists at both Cu and O sublattices in the copper-oxide (CuO2) planes with a
comparable periodicity and correlation length. Furthermore, we uncover
bond-stretching and bond-buckling phonon anomalies concomitant to the CDWs.
Comparing to slightly over-doped Bi$_2$Sr$_{1.8}$La$_{0.2}$CuO$_{6+\delta}$,
where neither CDWs nor phonon anomalies appear, we highlight that a sharp
intensity anomaly is induced in the proximity of the CDW wavevector (QCDW) for
the bond-buckling phonon, in concert with the diffused intensity enhancement of
the bond-stretching phonon at wavevectors much greater than QCDW. Our results
provide a comprehensive picture of the quasi-static CDWs, their dispersive
excitations, and associated electron-phonon anomalies, which are key for
understanding the competing electronic instabilities in cuprates.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:08:33 GMT""}]","2021-01-27"
"2006.14913","Jian-Jia Weng","Jian-Jia Weng, Fady Alajaji, Tam\'as Linder","Two-Way Source-Channel Coding","44 pages, 6 figures",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an adaptive lossy joint source-channel coding (JSCC) scheme for
sending correlated sources over two-terminal discrete-memoryless two-way
channels (DM-TWCs). The main idea is to couple the independent operations of
the terminals via an adaptive coding mechanism, which can mitigate
cross-interference resulting from simultaneous channel transmissions and
concurrently exploit the sources' correlation to reduce the end-to-end
reconstruction distortions. Our adaptive JSCC scheme not only subsumes existing
lossy coding methods for two-way simultaneous communication but also improves
their performance. Furthermore, we derive outer bounds for our two-way lossy
transmission problem and establish complete JSCC theorems in some special
settings. In these special cases, a non-adaptive separate source-channel coding
(SSCC) scheme achieves the optimal performance, thus simplifying the design of
the source-channel communication system.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:10:55 GMT""}]","2020-06-29"
"2006.14914","Vanda Pereira","V.M. Pereira, C.N. Wu, C.-A. Knight, A. Choa, L.H. Tjeng, S.G.
  Altendorf","Interfacing topological insulators and ferrimagnets: Bi$_2$Te$_3$ and
  Fe$_3$O$_4$ heterostructures grown by molecular beam epitaxy","accepted for publication in APL Materials","APL Materials 8, 071114 (2020)","10.1063/5.0010339",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Relying on the magnetism induced by the proximity effect in heterostructures
of topological insulators and magnetic insulators is one of the promising
routes to achieve the quantum anomalous Hall effect. Here we investigate
heterostructures of Bi$_2$Te$_3$ and Fe$_3$O$_4$. By growing two different
types of heterostructures by molecular beam epitaxy, Fe$_3$O$_4$ on
Bi$_2$Te$_3$ and Bi$_2$Te$_3$ on Fe$_3$O$_4$, we explore differences in
chemical stability, crystalline quality, electronic structure, and transport
properties. We find the heterostructure Bi$_2$Te$_3$ on Fe$_3$O$_4$ to be a
more viable approach, with transport signatures in agreement with a gap opening
in the topological surface states.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:28:34 GMT""}]","2020-09-07"
"2006.14915","Dieter Mitsche","Dieter Mitsche and Mathew D. Penrose","Limit theory of combinatorial optimization for random geometric graphs","64 pages",,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the random geometric graph $G(n,r_n)$, $n$ vertices are placed randomly in
Euclidean $d$-space and edges are added between any pair of vertices distant at
most $r_n$ from each other. We establish strong laws of large numbers (LLNs)
for a large class of graph parameters, evaluated for $G(n,r_n)$ in the
thermodynamic limit with $nr_n^d =$ const., and also in the dense limit with $n
r_n^d \to \infty$, $r_n \to 0$. Examples include domination number,
independence number, clique-covering number, eternal domination number and
triangle packing number. The general theory is based on certain subadditivity
and superadditivity properties, and also yields LLNs for other functionals such
as the minimum weight for the travelling salesman, spanning tree, matching,
bipartite matching and bipartite travelling salesman problems, for a general
class of weight functions with at most polynomial growth of order
$d-\varepsilon$, under thermodynamic scaling of the distance parameter.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:28:43 GMT""}]","2020-06-29"
"2006.14916","Viacheslav Saenko","Viacheslav V. Saenko","The calculation of the Mittag-Leffler function",,,,,"math.CA math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of calculating the Mittag-Leffler function $E_{\rho,\mu} (z)$ is
considered in the paper. To solve this problem integral representations for the
function $E_{\rho,\mu}(z)$ are transformed in such a way that they could not
contain complex variables and parameters. Integral representations written in
this form allow one to use standard methods of numerical integration to
calculate integrals contained in them. To verify the correctness of the
integral representations obtained the function $E_{\rho,\mu}(z)$ was calculated
both with the use of obtained formulas and with the use of known
representations of the Mittag-Leffler function. The calculation results
demonstrate their exact matching. This fact is indicative of the correctness of
new integral representations of the function $E_{\rho,\mu}(z)$ that were
obtained.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:32:44 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 07:31:55 GMT""}]","2021-07-19"
"2006.14917","Luciano Teresi","Michele Curatolo, Paola Nardinocchi, Luciano Teresi","Modeling liquid migration in active swollen gel spheres",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Liquid migration in active soft solids is a very common phenomenon in Nature
at different scales: from cells to leaves. It can be caused by mechanical as
well as chemical actions. The work focuses on the migration of liquid provoked
by remodeling processes in an active impermeable gel sphere. Within this
context, we present a consistent mathematical theory capable to gain a deep
understanding of the phenomenon in both steady and transient conditions.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:34:23 GMT""}]","2020-06-29"
"2006.14918","Nobuhiro Shimizu","J. K. Ahn, B. Beckford, M. Campbell, S. H. Chen, J. M. Choi, J.
  Comfort, K. Dona, M. S. Farrington, N. Hara, H. Haraguchi, Y. B. Hsiung, M.
  Hutcheson, T. Inagaki, M. Isoe, I. Kamiji, E. J. Kim, J. L. Kim, H. M. Kim,
  T. K. Komatsubara, K. Kotera, J. W. Lee, G. Y. Lim, C. Lin, Q. S. Lin, Y.
  Luo, T. Mari, T. Matsumura, D. Mcfarland, K. Miyazaki, R. Murayama, K.
  Nakagiri, H. Nanjo, H. Nishimiya, Y. Noichi, T. Nomura, T. Nunes, M. Ohsugi,
  H. Okuno, J. C. Redeker, K. Sato, T. Sato, Y. Sato, N. Shimizu, T. Shimogawa,
  T. Shinkawa, S. Shinohara, K. Shiomi, R. Shiraishi, S. Su, Y. Sugiyama, S.
  Suzuki, Y. Tajima, M. Taylor, M. Tecchio, M. Togawa, T. Toyoda, Y. C. Tung,
  Q. H. Vuong, Y. W. Wah, H. Watanabe, T. Yamanaka, H. Y. Yoshida","First Search for the $K_L \to \pi^0 \gamma$ Decay",,"Phys. Rev. D 102, 051103 (2020)","10.1103/PhysRevD.102.051103",,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the first search for the $K_L \to \pi^0 \gamma$ decay, which is
forbidden by Lorentz invariance, using the data from 2016 to 2018 at the J-PARC
KOTO experiment. With a single event sensitivity of $(7.1\pm 0.3_{\rm stat.}
\pm 1.6_{\rm syst.})\times 10^{-8}$, no candidate event was observed in the
signal region. The upper limit on the branching fraction was set to be
$1.7\times 10^{-7}$ at the 90\% confidence level.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:40:31 GMT""},{""version"":""v2"",""created"":""Thu, 25 Mar 2021 00:49:59 GMT""}]","2021-03-26"
"2006.14919","Amrita Goswami","Amrita Goswami, Indranil Saha Dalal, Jayant K. Singh","Seeding Method for Ice Nucleation under Shear","17 pages, 7 figures, supporting information PDF",,,,"physics.comp-ph cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hydrodynamic flow can have complex and far-reaching consequences on the rate
of homogenous nucleation. We present a general formalism for calculating the
nucleation rates of simply sheared systems.
  We have derived an extension to the conventional Classical Nucleation Theory,
explicitly embodying the shear rate. Seeded Molecular Dynamics simulations form
the backbone of our approach.
  The framework can be used for moderate supercoolings, at which temperatures
brute-force methods are practically infeasible. The competing energetic and
kinetic effects of shear arise naturally from the equations.
  We show how the theory can be used to identify shear regimes of ice
nucleation behaviour for the mW water model, unifying disparate trends reported
in the literature. At each temperature, we define a crossover shear rate in the
limit of $1000-10,000 \ s^{-1}$, beyond which the nucleation rate increases
steadily upto a maximum, at the optimal shear rate.
  For $235$, $240$, $255$ and $260 \ K$, the optimal shear rates are in the
range of $\approx 10^6-10^7 \ s^{-1}$. For very high shear rates beyond $10^8 \
s^{-1}$, nucleation is strongly inhibited. Our results indicate that the
shear-dependent nucleation rate curves have a non-monotonic dependence on
temperature.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:43:34 GMT""},{""version"":""v2"",""created"":""Thu, 6 Aug 2020 03:53:39 GMT""}]","2020-08-07"
"2006.14920","Radoslav K. Zamanov","R. K. Zamanov, V. D. Marchev, K. A. Stoyanov","Interstellar extinction toward symbiotic stars","Bulgarian Astronomical Journal (accepted)",,,,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using diffuse interstellar bands (DIBs) at 5780 A, 5797 A and 6613 A, visible
in the high resolution spectra, and measuring their equivalent widths, we
estimate the interstellar extinction toward seven symbiotic stars. We find
$E_{B-V}$= $1.28 \pm 0.10$ for AS 289, $E_{B-V}$= $1.55 \pm 0.10$ for BI Cru,
$E_{B-V}$= $0.63 \pm 0.10$ for HD330036, $E_{B-V}$= $0.33 \pm 0.05$ for V2756
Sgr, $E_{B-V}$= $0.30 \pm 0.05$ for V2905 Sgr, $E_{B-V}$= $1.52 \pm 0.11$ for
V417 Cen, $E_{B-V}$= $0.81 \pm 0.10$ for PN Sa 3-22. The derived values are in
agreement with the extinction through the Galaxy.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:43:47 GMT""}]","2020-06-29"
"2006.14921","Leonid Sokolinsky","Leonid B. Sokolinsky, Irina M. Sokolinskaya","Scalable Method for Linear Optimization of Industrial Processes",,"Proceedings - 2020 Global Smart Industry Conference, GloSIC 2020.
  IEEE, 2020. P. 20-26. Article number 9267854","10.1109/GloSIC50886.2020.9267854",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the development of industrial digital twins, the optimization problem of
technological and business processes often arises. In many cases, this problem
can be reduced to a large-scale linear programming (LP) problem. The article is
devoted to the new method for solving large-scale LP problems. This method is
called the ""apex-method"". The apex-method uses the predictor-corrector
framework. The predictor step calculates a point belonging to the feasible
region of LP problem. The corrector step calculates a sequence of points
converging to the exact solution of the LP problem. The article gives a formal
description of the apex-method and provides information about its parallel
implementation in C++ language by using the MPI library. The results of
large-scale computational experiments on a cluster computing system to study
the scalability of the apex method are presented.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:49:57 GMT""}]","2021-02-16"
"2006.14922","Oscar Zapata","Genevi\`eve B\'elanger, Alexander Pukhov, Carlos Yaguna and Oscar
  Zapata","The $Z_5$ model of two-component dark matter","29 pages, 14 figures",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scenarios for multi-component scalar dark matter based on a single $Z_N$
($N\geq 4$) symmetry are simple and well-motivated. In this paper we
investigate, for the first time, the phenomenology of the $Z_5$ model for
two-component dark matter. This model, which can be seen as an extension of the
well-known singlet scalar model, features two complex scalar fields--the dark
matter particles--that are Standard Model singlets but have different charges
under a $Z_5$ symmetry. The interactions allowed by the $Z_5$ give rise to
novel processes between the dark matter particles that affect their relic
densities and their detection prospects, which we study in detail. The key
parameters of the model are identified and its viable regions are characterized
by means of random scans. We show that, unlike the singlet scalar model, dark
matter masses below the TeV are still compatible with present data. Even though
the dark matter density turns out to be dominated by the lighter component, we
find that current and future direct detection experiments may be sensitive to
signals from both dark matter particles.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:53:57 GMT""}]","2020-06-29"
"2006.14923","Manfred Jaeger","Manfred Jaeger, Giorgio Bacci, Giovanni Bacci, Kim Guldstrand Larsen,
  and Peter Gj{\o}l Jensen","Approximating Euclidean by Imprecise Markov Decision Processes",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Euclidean Markov decision processes are a powerful tool for modeling control
problems under uncertainty over continuous domains. Finite state imprecise,
Markov decision processes can be used to approximate the behavior of these
infinite models. In this paper we address two questions: first, we investigate
what kind of approximation guarantees are obtained when the Euclidean process
is approximated by finite state approximations induced by increasingly fine
partitions of the continuous state space. We show that for cost functions over
finite time horizons the approximations become arbitrarily precise. Second, we
use imprecise Markov decision process approximations as a tool to analyse and
validate cost functions and strategies obtained by reinforcement learning. We
find that, on the one hand, our new theoretical results validate basic design
choices of a previously proposed reinforcement learning approach. On the other
hand, the imprecise Markov decision process approximations reveal some
inaccuracies in the learned cost functions.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:58:04 GMT""}]","2020-06-29"
"2006.14924","Mikaela Iacobelli","Daniel Han-Kwan and Mikaela Iacobelli","From Newton's second law to Euler's equations of perfect fluids","Minor typos corrected",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vlasov equations can be formally derived from N-body dynamics in the
mean-field limit. In some suitable singular limits, they may themselves
converge to fluid dynamics equations. Motivated by this heuristic, we introduce
natural scalings under which the incompressible Euler equations can be
rigorously derived from N-body dynamics with repulsive Coulomb interaction. Our
analysis is based on the modulated energy methods of Brenier and Serfaty.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:59:25 GMT""},{""version"":""v2"",""created"":""Wed, 26 Aug 2020 16:34:59 GMT""}]","2020-08-27"
"2006.14925","Jiaxi Ying","Jiaxi Ying, Jos\'e Vin\'icius de M. Cardoso, Daniel P. Palomar","Does the $\ell_1$-norm Learn a Sparse Graph under Laplacian Constrained
  Graphical Models?",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of learning a sparse graph under Laplacian
constrained Gaussian graphical models. This problem can be formulated as a
penalized maximum likelihood estimation of the precision matrix under Laplacian
structural constraints. Like in the classical graphical lasso problem, recent
works made use of the $\ell_1$-norm regularization with the goal of promoting
sparsity in Laplacian structural precision matrix estimation. However, we find
that the widely used $\ell_1$-norm is not effective in imposing a sparse
solution in this problem. Through empirical evidence, we observe that the
number of nonzero graph weights grows with the increase of the regularization
parameter. From a theoretical perspective, we prove that a large regularization
parameter will surprisingly lead to a fully connected graph. To address this
issue, we propose a nonconvex estimation method by solving a sequence of
weighted $\ell_1$-norm penalized sub-problems and prove that the statistical
error of the proposed estimator matches the minimax lower bound. To solve each
sub-problem, we develop a projected gradient descent algorithm that enjoys a
linear convergence rate. Numerical experiments involving synthetic and
real-world data sets from the recent COVID-19 pandemic and financial stock
markets demonstrate the effectiveness of the proposed method. An open source
$\mathsf{R}$ package containing the code for all the experiments is available
at https://github.com/mirca/sparseGraph.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:06:10 GMT""}]","2020-06-29"
"2006.14926","Benjamin Vejnar","Henk Bruin and Benjamin Vejnar","Classification of one dimensional dynamical systems by countable
  structures",,,,,"math.DS math.GN math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the complexity of the classification problem of conjugacy on
dynamical systems on some compact metrizable spaces. Especially we prove that
the conjugacy equivalence relation of interval dynamical systems is Borel
bireducible to isomorphism equivalence relation of countable graphs. This
solves a special case of the Hjorth's conjecture which states that every orbit
equivalence relation induced by a continuous action of the group of all
homeomorphisms of the closed unit interval is classifiable by countable
structures. We also prove that conjugacy equivalence relation of Hilbert cube
homeomorphisms is Borel bireducible to the universal orbit equivalence
relation.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:10:35 GMT""},{""version"":""v2"",""created"":""Fri, 2 Sep 2022 16:26:54 GMT""}]","2022-09-05"
"2006.14927","Luisa Arrabito","Luisa Arrabito, Konrad Bernl\""ohr, Johan Bregeon, Matthieu Carr\`ere,
  Adnane Khattabi, Philippe Langlois, David Parello, Guillaume Revy","Optimizing Cherenkov photons generation and propagation in CORSIKA for
  CTA Monte-Carlo simulations",,,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  COsmic Ray SImulations for KAscade) is a program for detailed simulation of
extensive air showers initiated by high energy cosmic ray particles in the
atmosphere, and is used today by almost all the major instruments that aim at
measuring primary and secondary cosmic rays on the ground. The Cherenkov
Telescope Array (CTA), currently under construction, is the next-generation
instrument in the field of very-high-energy gamma-ray astronomy. Detailed
CORSIKA Monte Carlo simulations will be regularly performed in parallel to CTA
operations to estimate the instrument response functions, necessary to extract
the physical properties of the cosmic sources from the measurements during data
analysis. The estimated CPU time associated with these simulations is very
high, of the order of 200 million HS06 hours per year. Code optimization
becomes a necessity towards fast productions and limited costs. We propose in
this paper multiple code transformations that aim to facilitate automatic
vectorization done by the compiler, ensuring minimal external libraries
requirement and high hardware portability.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:15:02 GMT""}]","2020-06-29"
"2006.14934","Tom Bachmann","Tom Bachmann","Cancellation theorem for motivic spaces with finite flat transfers","14 pages v2: minor corrections (mostly typos) v3: final version","Doc. Math. 26, 1121-1144 (2021)","10.25537/dm.2021v26.1121-1144",,"math.AG math.KT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the category of motivic spaces with transfers along finite flat
morphisms, over a perfect field, satisfies all the properties we have come to
expect of good categories of motives. In particular we establish the analog of
Voevodsky's cancellation theorem.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:26:59 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 15:52:48 GMT""},{""version"":""v3"",""created"":""Tue, 11 Jan 2022 11:14:28 GMT""}]","2022-01-12"
"2006.14935","Tuomas Sahlsten","Etienne Le Masson, Tuomas Sahlsten","Quantum ergodicity for Eisenstein series on hyperbolic surfaces of large
  genus","v2: 35 pages, changed the statement from quantum variance to quantum
  mean absolute deviation, included new Proposition 4.3 on the logarithmic
  derivative of the scattering determinant and several details on random
  surfaces with growing number of cusps such as extending Monk's work on
  spectral convergence, using Hide's work on spectral gap and extending
  Mirzakhani's estimates on systole",,,,"math.SP math-ph math.DS math.MP math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a quantitative estimate for the quantum mean absolute deviation on
hyperbolic surfaces in terms of geometric parameters such as the genus, number
of cusps and injectivity radius. It implies a delocalisation result of quantum
ergodicity type for eigenfunctions of the Laplacian on hyperbolic surfaces of
finite area that Benjamini-Schramm converge to the hyperbolic plane. We show
that this is generic for Mirzakhani's model of random surfaces chosen uniformly
with respect to the Weil-Petersson volume. Depending on the particular sequence
of surfaces considered this gives a result of delocalisation of most cusp forms
or of Eisenstein series.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:29:19 GMT""},{""version"":""v2"",""created"":""Fri, 13 May 2022 14:33:40 GMT""}]","2022-05-16"
"2006.14936","Peter Tsun Ho Pang","Peter T. H. Pang, Tim Dietrich, Ingo Tews, Chris Van Den Broeck","Parameter estimation for strong phase transitions in supranuclear matter
  using gravitational-wave astronomy","17 pages, 11 figures","Phys. Rev. Research 2, 033514 (2020)","10.1103/PhysRevResearch.2.033514","LA-UR-20-24019","astro-ph.HE gr-qc nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  At supranuclear densities, explored in the core of neutron stars, a strong
phase transition from hadronic matter to more exotic forms of matter might be
present. To test this hypothesis, binary neutron-star mergers offer a unique
possibility to probe matter at densities that we can not create in any existing
terrestrial experiment. In this work, we show that, if present, strong phase
transitions can have a measurable imprint on the binary neutron-star
coalescence and the emitted gravitational-wave signal. We construct a new
parameterization of the supranuclear equation of state that allows us to test
for the existence of a strong phase transition and extract its characteristic
properties purely from the gravitational-wave signal of the inspiraling neutron
stars. We test our approach using a Bayesian inference study simulating 600
signals with three different equations of state and find that for current
gravitational-wave detector networks already twelve events might be sufficient
to verify the presence of a strong phase transition. Finally, we use our
methodology to analyze GW170817 and GW190425, but do not find any indication
that a strong phase transition is present at densities probed during the
inspiral.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:29:22 GMT""},{""version"":""v2"",""created"":""Wed, 30 Sep 2020 02:29:55 GMT""}]","2020-10-02"
"2006.14940","B\'alint Boldizs\'ar","B. Boldizs\'ar, T. Kov\'acs, J. Vany\'o","A new perturbative solution to the motion around triangular Lagrangian
  points in the elliptic restricted three-body problem","12 pages, 4 figures",,"10.1007/s10569-021-10018-8",,"astro-ph.EP gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The equations of motion of planar elliptic restricted three body problem are
transformed to four decoupled Hill's equations. By using the Floquet theorem
analytic solution to the oscillator equations with time dependent periodic
coefficients are presented. We show that the new analytic approach is valid for
system parameters $0 < e \leq 0.05$ and $0 < \mu \leq 0.01$ where $e$ denotes
the eccentricity of primaries while $\mu$ is the mass parameter, respectively.
We also clarify the transformation details that provide the applicability of
the method.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:32:41 GMT""}]","2021-05-26"
"2006.14950","Ananda Theertha Suresh","Corinna Cortes and Mehryar Mohri and Ananda Theertha Suresh","Relative Deviation Margin Bounds","29 pages",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a series of new and more favorable margin-based learning
guarantees that depend on the empirical margin loss of a predictor. We give two
types of learning bounds, both distribution-dependent and valid for general
families, in terms of the Rademacher complexity or the empirical $\ell_\infty$
covering number of the hypothesis set used. Furthermore, using our relative
deviation margin bounds, we derive distribution-dependent generalization bounds
for unbounded loss functions under the assumption of a finite moment. We also
briefly highlight several applications of these bounds and discuss their
connection with existing results.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:37:17 GMT""},{""version"":""v2"",""created"":""Wed, 28 Oct 2020 18:05:21 GMT""}]","2020-10-30"
"2006.14953","Rahma Chaabouni","Eugene Kharitonov and Rahma Chaabouni","What they do when in doubt: a study of inductive biases in seq2seq
  learners",,,,,"cs.CL cs.AI cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequence-to-sequence (seq2seq) learners are widely used, but we still have
only limited knowledge about what inductive biases shape the way they
generalize. We address that by investigating how popular seq2seq learners
generalize in tasks that have high ambiguity in the training data. We use SCAN
and three new tasks to study learners' preferences for memorization,
arithmetic, hierarchical, and compositional reasoning. Further, we connect to
Solomonoff's theory of induction and propose to use description length as a
principled and sensitive measure of inductive biases.
  In our experimental study, we find that LSTM-based learners can learn to
perform counting, addition, and multiplication by a constant from a single
training example. Furthermore, Transformer and LSTM-based learners show a bias
toward the hierarchical induction over the linear one, while CNN-based learners
prefer the opposite. On the SCAN dataset, we find that CNN-based, and, to a
lesser degree, Transformer- and LSTM-based learners have a preference for
compositional generalization over memorization. Finally, across all our
experiments, description length proved to be a sensitive measure of inductive
biases.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:43:10 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 09:43:36 GMT""}]","2021-03-30"
"2006.14954","Melissa Lee","Melissa Lee","Regular orbits of quasisimple linear groups II","45 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $V$ be a finite-dimensional vector space over a finite field, and suppose
$G \leq \Gamma \mathrm{L}(V)$ is a group with a unique subnormal quasisimple
subgroup $E(G)$ that is absolutely irreducible on $V$. A base for $G$ is a set
of vectors $B\subseteq V$ with pointwise stabiliser $G_B=1$. If $G$ has a base
of size 1, we say that it has a regular orbit on $V$. In this paper we
investigate the minimal base size of groups $G$ with $E(G)/Z(E(G)) \cong
\mathrm{PSL}_n(q)$ in defining characteristic, with an aim of classifying those
with a regular orbit on $V$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:47:27 GMT""}]","2020-06-29"
"2006.14955","Mori Watanabe","Mori Watanabe, Sanghyun Lee, Takuya Asano, Takashi Ibe, Masashi
  Tokuda, Hiroki Taniguchi, Daichi Ueta, Yoshinori Okada, Kensuke Kobayashi,
  and Yasuhiro Niimi","Quantum oscillations with magnetic hysteresis observed in CeTe$_{3}$
  thin films","5 pages, 4 figures, accepted for publication in Applied Physics
  Letters",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have performed magnetotransport measurements in CeTe$_{3}$ thin films down
to $0.2~{\rm K}$. It is known that CeTe$_{3}$ has two magnetic transitions at
$T_{\rm N1} \approx 3~{\rm K}$ and $T_{\rm N2} \approx 1~{\rm K}$. A clear
Shubnikov-de-Haas (SdH) oscillation was observed at $4~{\rm K}$, demonstrating
the strong two-dimensional nature in this material. Below $T_{\rm N2}$, the SdH
oscillation has two frequencies, indicating that the Fermi surface could be
slightly modulated due to the second magnetic transition. We also observed a
magnetic hysteresis in the SdH oscillation below $T_{\rm N1}$. Especially,
there is a unique spike in the magnetoresistance at $B \approx 0.6~{\rm T}$
only when the magnetic field is swept from a high enough field (more than
$2~{\rm T}$) to zero field.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:48:54 GMT""},{""version"":""v2"",""created"":""Wed, 5 Aug 2020 08:20:53 GMT""}]","2020-08-06"
"2006.14956","Kai Guther","Kai Guther, Robert J. Anderson, Nick S. Blunt, Nikolay A. Bogdanov,
  Deidre Cleland, Nike Dattani, Werner Dobrautz, Khaldoon Ghanem, Peter
  Jeszenski, Niklas Liebermann, Giovanni Li Manni, Alexander Y. Lozovoi,
  Hongjun Luo, Dongxia Ma, Florian Merz, Catherine Overy, Markus Rampp,
  Pradipta K. Samanta, Lauretta R. Schwarz, James J. Shepherd, Simon D. Smart,
  Eugenio Vitale, Oskar Weser, George H. Booth, Ali Alavi","NECI: N-Electron Configuration Interaction with emphasis on
  state-of-the-art stochastic methods","68 pages, 8 figures. To be published in the Journal of Chemical
  Physics, full supplementary files are to be published together with the
  article",,"10.1063/5.0005754",,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present NECI, a state-of-the-art implementation of the Full Configuration
Interaction Quantum Monte Carlo algorithm, a method based on a stochastic
application of the Hamiltonian matrix on a sparse sampling of the wave
function. The program utilizes a very powerful parallelization and scales
efficiently to more than 24000 CPU cores. In this paper, we describe the core
functionalities of NECI and recent developments. This includes the capabilities
to calculate ground and excited state energies, properties via the one- and
two-body reduced density matrices, as well as spectral and Green's functions
for ab initio and model systems. A number of enhancements of the bare FCIQMC
algorithm are available within NECI, allowing to use a partially deterministic
formulation of the algorithm, working in a spin-adapted basis or supporting
transcorrelated Hamiltonians. NECI supports the FCIDUMP file format for
integrals, supplying a convenient interface to numerous quantum chemistry
programs and it is licensed under GPL-3.0.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:50:10 GMT""}]","2020-08-26"
"2006.14957","Andres Cotorruelo","Andres Cotorruelo, Ilya Kolmanovsky, Daniel R. Ram\'irez, Daniel Limon
  and Emanuele Garone","Elimination of Redundant Polynomial Constraints and Its Use in
  Constrained Control",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The reduction of constraints to obtain minimal representations of sets is a
very common problem in many engineering applications. While well-established
methodologies exist for the case of linear constraints, the problem of how to
detect redundant non-linear constraints is an open problem. In this paper we
present a novel methodology based on Sum of Squares for the elimination of
redundant polynomial constraints. The paper also presents some relevant
applications of the presented method to constrained control problems. In
particular, we show how the proposed method can be used in the Model Predictive
Control and in the Reference Governor frameworks to reduce the computational
burden of the online algorithms. Furthermore, this method can also be used to
eliminate the terminal constraints in MPC in a simple way that is independent
from the cost function.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:53:51 GMT""}]","2020-06-29"
"2006.14958","Annika Johansson","Annika Johansson, B\""orge G\""obel, J\""urgen Henk, Manuel Bibes, Ingrid
  Mertig","Spin and orbital Edelstein effect in an oxide two-dimensional electron
  gas: theory and application to AlO$_x$/SrTiO$_{3}$","8 pages, 4 figures","Phys. Rev. Research 3, 013275 (2021)","10.1103/PhysRevResearch.3.013275",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Edelstein effect provides the purely electrical generation and control of
a homogeneous magnetization in primarily nonmagnetic materials with broken
inversion symmetry. Usually, only the spin density response to an external
electric field is discussed. Here, we report on the electrically induced
magnetization containing spin as well as orbital contributions in the
topological oxide two-dimensional electron gas at the interface between
SrTiO$_3$ and AlO. We find that in this particular system the orbital Edelstein
effect exceeds the spin Edelstein effect by more than one order of magnitude.
The main reason are orbital moments of different magnitude in the
Rashba-like-split band pairs.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:56:40 GMT""}]","2021-03-31"
"2006.14959","Miguel Angel Javaloyes","Miguel Angel Javaloyes and Bruno Learth Soares","Anisotropic conformal invariance of lightlike geodesics in
  pseudo-Finsler manifolds","12 pages. arXiv admin note: text overlap with arXiv:1401.8149",,"10.1088/1361-6382/abc225",,"math.DG gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we prove that lightlike geodesics of a pseudo-Finsler manifold
and its focal points are preserved up to reparametrization by anisotropic
conformal changes, using the Chern connection and the anisotropic calculus and
the fact that geodesics are critical points of the energy functional and Jacobi
fields, the kernel of its index form. This result has applications to the study
of Finsler spacetimes.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:58:31 GMT""}]","2022-08-10"
"2006.14960","Mar\'ia Anguiano","Mar\'ia Anguiano","On $p$-Laplacian reaction-diffusion problems with dynamical boundary
  conditions in perforated media","20 pages. arXiv admin note: text overlap with arXiv:1912.02445,
  arXiv:1712.01183, arXiv:2004.06513",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper deals with the homogenization of the $p$-Laplacian
reaction-diffusion problems in a domain containing periodically distributed
holes of size $\varepsilon$, with a dynamical boundary condition of
pure-reactive type. We generalize our previous results established in the case
where the diffusion is modeled by the Laplacian operator, i.e., with $p=2$. We
prove the convergence of the homogenization process to a nonlinear
$p$-Laplacian reaction-diffusion equation defined on a unified domain without
holes with zero Dirichlet boundary condition and with extra terms coming from
the influence of the nonlinear dynamical boundary conditions.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:52:14 GMT""}]","2020-06-29"
"2006.14961","Antonella Palmese","A. Palmese, J. deVicente, M. E. S. Pereira, J. Annis, W. Hartley, K.
  Herner, M. Soares-Santos, M. Crocce, D. Huterer, I. Magana Hernandez, T. M.
  Davis, A. Garcia, J. Garcia-Bellido, J. Gschwend, D. E. Holz, R. Kessler, O.
  Lahav, R. Morgan, C. Nicolaou, C. Conselice, R. J. Foley, M. S. S. Gill, T.
  M. C. Abbott, M. Aguena, S. Allam, S. Avila, K. Bechtol, E. Bertin, S.
  Bhargava, D. Brooks, E. Buckley-Geer, D. L. Burke, M. Carrasco Kind, J.
  Carretero, F. J. Castander, C. Chang, M. Costanzi, L. N. da Costa, S. Desai,
  H. T. Diehl, P. Doel, J. Estrada, S. Everett, A. E. Evrard, E. Fernandez, D.
  A. Finley, B. Flaugher, P. Fosalba, J. Frieman, E. Gaztanaga, D. W. Gerdes,
  D. Gruen, R. A. Gruendl, G. Gutierrez, S. R. Hinton, D. L. Hollowood, K.
  Honscheid, D. J. James, S. Kent, E. Krause, K. Kuehn, H. Lin, M. A. G. Maia,
  M. March, J. L. Marshall, P. Melchior, F. Menanteau, R. Miquel, R. L. C.
  Ogando, F. Paz-Chinchon, A. A. Plazas, A. Roodman, M. Sako, E. Sanchez, V.
  Scarpine, M. Schubnell, S. Serrano, I. Sevilla-Noarbe, J. Allyn Smith, M.
  Smith, E. Suchyta, G. Tarle, M. A. Troxel, D. L. Tucker, A. R. Walker, W.
  Wester, R.D. Wilkinson, J. Zuntz","A statistical standard siren measurement of the Hubble constant from the
  LIGO/Virgo gravitational wave compact object merger GW190814 and Dark Energy
  Survey galaxies","12 pages, 3 figures, replacement reflects published version","The Astrophysical Journal Letters, 2020, Volume 900, Number 2","10.3847/2041-8213/abaeff","FERMILAB-PUB-20-216-AE","astro-ph.CO astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a measurement of the Hubble constant $H_0$ using the gravitational
wave (GW) event GW190814, which resulted from the coalescence of a 23 $M_\odot$
black hole with a 2.6 $M_\odot$ compact object, as a standard siren. No
compelling electromagnetic counterpart has been identified for this event, thus
our analysis accounts for thousands of potential host galaxies within a
statistical framework. The redshift information is obtained from the
photometric redshift (photo-$z$) catalog from the Dark Energy Survey. The
luminosity distance is provided by the LIGO/Virgo gravitational wave sky map.
Since this GW event has the second-smallest localization volume after GW170817,
GW190814 is likely to provide the best constraint on cosmology from a single
standard siren without identifying an electromagnetic counterpart. Our analysis
uses photo-$z$ probability distribution functions and corrects for photo-$z$
biases. We also reanalyze the binary-black hole GW170814 within this updated
framework. We explore how our findings impact the $H_0$ constraints from
GW170817, the only GW merger associated with a unique host galaxy. From a
combination of GW190814, GW170814 and GW170817, our analysis yields $H_0 =
72.0^{+ 12}_{- 8.2 }~{\rm km~s^{-1}~Mpc^{-1}}$ (68\% Highest Density Interval,
HDI) for a prior in $H_0$ uniform between $[20,140]~{\rm km~s^{-1}~Mpc^{-1}}$.
The addition of GW190814 and GW170814 to GW170817 improves the 68\% HDI from
GW170817 alone by $\sim 18\%$, showing how well-localized mergers without
counterparts can provide a significant contribution to standard siren
measurements, provided that a complete galaxy catalog is available at the
location of the event.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:44:24 GMT""},{""version"":""v2"",""created"":""Thu, 10 Sep 2020 04:41:43 GMT""},{""version"":""v3"",""created"":""Mon, 28 Dec 2020 17:45:02 GMT""}]","2020-12-29"
"2006.14962","Marco Lauricella Dr.","Andrea Montessori, Adriano Tiribocchi, Marco Lauricella, Fabio
  Bonaccorso, Sauro Succi","A Multiresolution Mesoscale Approach for Microscale Hydrodynamics","13 pages, 10 figures. arXiv admin note: substantial text overlap with
  arXiv:2004.00304","Advanced Theory and Simulations, 2020, 3.4: 1900250","10.1002/adts.201900250",,"physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new class of multiscale scheme is presented for micro-hydrodynamic problems
based on a dual representation of the fluid observables. The hybrid model is
first tested against the classical flow between two parallel plates and then
applied to a plug flow within a micrometer-sized striction and a shear flow
within a microcavity. Both cases demonstrate the capability of the multiscale
approach to reproduce the correct macroscopic hydrodynamics also in the
presence of refined grids (one and two levels), while retaining the correct
thermal fluctuations, embedded in the multiparticle collision method. This
provides the first step toward a novel class of fully mesoscale hybrid
approaches able to capture the physics of fluids at the micro- and nanoscales
whenever a continuum representation of the fluid falls short of providing the
complete physical information, due to a lack of resolution and thermal
fluctuations.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:54:14 GMT""}]","2020-06-29"
"2006.14963","Anthony Torres","A. Torres-Hernandez and F. Brambila-Paz","An approximation to zeros of the Riemann zeta function using fractional
  calculus","arXiv admin note: text overlap with arXiv:2004.10860. text overlap
  with arXiv:1710.07634, arXiv:1804.08445","Mathematics and Statistics, 9(3): 309-318, 2021","10.13189/ms.2021.090312",,"math.NA cs.NA math.NT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this document, as far as the authors know, an approximation to the zeros
of the Riemann zeta function has been obtained for the first time using only
derivatives of constant functions, which was possible only because a fractional
iterative method was used. This iterative method, valid for one and several
variables, uses the properties of fractional calculus, in particular the fact
that the fractional derivatives of constants are not always zero, to find
multiple zeros of a function using a single initial condition. This partly
solves the intrinsic problem of iterative methods that if we want to find N
zeros it is necessary to give N initial conditions. Consequently, the method is
suitable for approximating nontrivial zeros of the Riemann zeta function when
the absolute value of its imaginary part tends to infinity. The deduction of
the iterative method is presented, some examples of its implementation, and
finally 53 different values near to the zeros of the Riemann zeta function are
shown.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:23:56 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 17:22:42 GMT""},{""version"":""v3"",""created"":""Fri, 3 Jul 2020 16:41:25 GMT""},{""version"":""v4"",""created"":""Wed, 4 Nov 2020 03:40:38 GMT""},{""version"":""v5"",""created"":""Fri, 22 Jan 2021 16:35:45 GMT""}]","2021-05-13"
"2006.14964","Anna Melnichenko","Hagen Echzell, Tobias Friedrich, Pascal Lenzner, Anna Melnichenko","Flow-Based Network Creation Games","To appear at the 29th International Joint Conference on Artificial
  Intelligence and the 17th Pacific Rim International Conference on Artificial
  Intelligence (IJCAI-PRICAI 2020)",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network Creation Games(NCGs) model the creation of decentralized
communication networks like the Internet. In such games strategic agents
corresponding to network nodes selfishly decide with whom to connect to
optimize some objective function. Past research intensively analyzed models
where the agents strive for a central position in the network. This models
agents optimizing the network for low-latency applications like VoIP. However,
with today's abundance of streaming services it is important to ensure that the
created network can satisfy the increased bandwidth demand. To the best of our
knowledge, this natural problem of the decentralized strategic creation of
networks with sufficient bandwidth has not yet been studied.
  We introduce Flow-Based NCGs where the selfish agents focus on bandwidth
instead of latency. In essence, budget-constrained agents create network links
to maximize their minimum or average network flow value to all other network
nodes. Equivalently, this can also be understood as agents who create links to
increase their connectivity and thus also the robustness of the network. For
this novel type of NCG we prove that pure Nash equilibria exist, we give a
simple algorithm for computing optimal networks, we show that the Price of
Stability is 1 and we prove an (almost) tight bound of 2 on the Price of
Anarchy. Last but not least, we show that our models do not admit a potential
function.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:59:24 GMT""}]","2020-06-29"
"2006.14965","Daniel Karlsson Dr","Daniel Karlsson, Robert van Leeuwen, Yaroslav Pavlyukh, Enrico
  Perfetto, Gianluca Stefanucci","Fast Green's function method for ultrafast electron-boson dynamics","7 pages, with additional supplementary materials","Phys. Rev. Lett. 127, 036402 (2021)","10.1103/PhysRevLett.127.036402",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interaction of electrons with quantized phonons and photons underlies the
ultrafast dynamics of systems ranging from molecules to solids, and it gives
rise to a plethora of physical phenomena experimentally accessible using
time-resolved techniques. Green's function methods offer an invaluable
interpretation tool since scattering mechanisms of growing complexity can be
selectively incorporated in the theory. Currently, however, real-time Green's
function simulations are either prohibitively expensive due to the cubic
scaling with the propagation time or do neglect the feedback of electrons on
the bosons, thus violating energy conservation. We put forward a
computationally efficient Green's function scheme which overcomes both
limitations. The numerical effort scales linearly with the propagation time
while the simultaneous dressing of electrons and bosons guarantees the
fulfillment of all fundamental conservation laws. We present a real-time study
of the phonon-driven relaxation dynamics in an optically excited narrow
band-gap insulator, highlighting the nonthermal behavior of the phononic
degrees of freedom. Our formulation paves the way to first-principles
simulations of electron-boson systems with unprecedented long propagation
times.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:59:52 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 21:31:48 GMT""}]","2021-07-21"
"2006.14966","Abbey Bourdon","Abbey Bourdon, David R. Gill, Jeremy Rouse, Lori D. Watson","Odd degree isolated points on $X_1(N)$ with rational $j$-invariant","26 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $C$ be a curve defined over a number field $k$. We say a closed point
$x\in C$ of degree $d$ is isolated if it does not belong to an infinite family
of degree $d$ points parametrized by the projective line or a positive rank
abelian subvariety of the curve's Jacobian. Building on work of Bourdon, Ejder,
Liu, Odumodu, and Viray, we characterize elliptic curves with rational
$j$-invariant which give rise to an isolated point of odd degree on
$X_1(N)/\mathbb{Q}$ for some positive integer $N$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:01:40 GMT""}]","2020-06-29"
"2006.14967","Pol Ribes Pleguezuelo","Pol Ribes-Pleguezuelo, Fanny Keller, Matteo Taccola","UV astronomy with small satellites","11 pages, 5 figures, to be published in 2020 4s Symposium postponed
  to March 2021",,,,"astro-ph.IM astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Small satellite platforms with high performance avionics are becoming more
affordable. So far, with a few exceptions, small satellites have been mainly
dedicated to earth observation. However, astronomy is a fascinating field with
a history of large missions and a future of promising large mission candidates.
This prompts many questions; can the recent affordability of small satellites
change the landscape of space astronomy? What are the potential applications
and scientific topics of interest, where small satellites could be instrumental
for astronomy? What are the requirements and objectives that need to be
fulfilled to successfully address the astronomical investigations of interest?
Which kind of instrumentation suits the small platforms and the scientific use
cases best? This paper discusses possible scientific use cases that can be
achievable with a relatively small telescope aperture of 36 cm, as an example.
The result of this survey points to a specific niche market -astronomy
observation in the UV spectral range. UV astronomy is a research field which
has had valuable scientific impact. It is, however, not the focus of many
current or past astronomical investigations. UV astronomy measurements cannot
be made from earth, due to atmospheric absorption in this spectral range. The
research field is currently sparsely addressed but of scientific interest for a
large community. Small satellites offer the opportunity to provide more means
of research for UV astronomy. Therefore, this paper also presents an instrument
design with a modest telescope aperture, a spectrometer and a detector that is
suitable for observations in the UV. The observatory design can be accommodated
on small platforms for the selected scientific use cases. It fulfills the
scientific objectives and requirements of those use cases.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:03:00 GMT""}]","2020-06-29"
"2006.14968","Jean-Camille Birget","J.C. Birget","The word problem of the Brin-Higman-Thompson groups","27 pages",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the word problem of the Brin-Higman-Thompson group $n G_{k,1}$
is {\sf coNP}-complete for all $n \ge 2$ and all $k \ge 2$. For this we prove
that $n G_{k,1}$ is finitely generated, and that $n G_{k,1}$ contains a
subgroup of $2 G_{2,1}$ that can represent bijective circuits.
  We also show that for all $n \ge 1$ and $k \ge 2$: \ If $\,K = 1 +
(k-1)\,N\,$ for some $N \ge 1$, then $n G_{K,1} \le n G_{k,1}$. In particular,
$n G_{K,1} \le n G_{2,1}$ for all $K \ge 2$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:05:11 GMT""}]","2020-06-29"
"2006.14969","Matteo Busi","Carmine Abate and Matteo Busi and Stelios Tsampas","Fully Abstract and Robust Compilation and How to Reconcile the Two,
  Abstractly","Extended version of the APLAS'21 paper",,,,"cs.PL cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The most prominent formal criterion for secure compilation is full
abstraction, the preservation and reflection of contextual equivalence. Recent
work introduced robust compilation, defined as the preservation of robust
satisfaction of hyperproperties, i.e., their satisfaction against arbitrary
attackers. In this paper, we initially set out to compare these two approaches
to secure compilation. To that end, we provide an exact description of the
hyperproperties that are robustly satisfied by programs compiled with a fully
abstract compiler, and show that they can be meaningless or trivial. We then
propose a novel criterion for secure compilation formulated in the framework of
Mathematical Operational Semantics (MOS), guaranteeing both full abstraction
and the preservation of robust satisfaction of hyperproperties in a more
sensible manner.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:15:35 GMT""},{""version"":""v2"",""created"":""Mon, 2 Nov 2020 16:29:29 GMT""},{""version"":""v3"",""created"":""Fri, 18 Jun 2021 22:16:01 GMT""},{""version"":""v4"",""created"":""Mon, 20 Sep 2021 14:17:33 GMT""}]","2021-09-21"
"2006.14970","Thomas Germer","Thomas Germer, Tobias Uelwer, Stefan Conrad, Stefan Harmeling","Fast Multi-Level Foreground Estimation","Accepted at the 25th International Conference on Pattern Recognition
  2020 (ICPR)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Alpha matting aims to estimate the translucency of an object in a given
image. The resulting alpha matte describes pixel-wise to what amount foreground
and background colors contribute to the color of the composite image. While
most methods in literature focus on estimating the alpha matte, the process of
estimating the foreground colors given the input image and its alpha matte is
often neglected, although foreground estimation is an essential part of many
image editing workflows. In this work, we propose a novel method for foreground
estimation given the alpha matte. We demonstrate that our fast multi-level
approach yields results that are comparable with the state-of-the-art while
outperforming those methods in computational runtime and memory usage.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:16:13 GMT""}]","2020-06-29"
"2006.14971","Aekta Aggarwal","Aekta Aggarwal, Ganesh Vaidya and G.D. Veerappa Gowda","Positivity--preserving numerical scheme for hyperbolic systems with
  $\delta\,-$ shock solutions and its convergence analysis",,,"10.1007/s00033-021-01590-y",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Godunov type numerical schemes for the class of hyperbolic systems, admitting
non-classical $\delta-$ shocks are proposed. It is shown that the numerical
approximations converge to the solution and preserve the physical properties of
the system such as positive density and bounded velocity. The scheme has been
extended to positivity preserving and velocity bound preserving second-order
accurate scheme by using appropriate slope limiters. The numerical results are
compared with the existing the literature and the scheme is shown to capture
the solution efficiently. The paper presents a hyperbolic system, for which an
entropy satisfying scheme is constructed through an appropriate decoupling of
the system into two scalar conservation laws with discontinuous flux.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:16:14 GMT""},{""version"":""v2"",""created"":""Thu, 4 Feb 2021 18:15:53 GMT""}]","2021-09-01"
"2006.14972","Andr\'e Nichterlein","Aleksander Figiel, Anne-Sophie Himmel, Andr\'e Nichterlein, Rolf
  Niedermeier","On 2-Clubs in Graph-Based Data Clustering: Theory and Algorithm
  Engineering",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Editing a graph into a disjoint union of clusters is a standard optimization
task in graph-based data clustering. Here, complementing classic work where the
clusters shall be cliques, we focus on clusters that shall be 2-clubs, that is,
subgraphs of diameter two. This naturally leads to the two NP-hard problems
2-Club Cluster Editing (the allowed editing operations are edge insertion and
edge deletion) and 2-Club Cluster Vertex Deletion (the allowed editing
operations are vertex deletions). Answering an open question from the
literature, we show that 2-Club Cluster Editing is W[2]-hard with respect to
the number of edge modifications, thus contrasting the fixed-parameter
tractability result for the classic Cluster Editing problem (considering
cliques instead of 2-clubs). Then focusing on 2-Club Cluster Vertex Deletion,
which is easily seen to be fixed-parameter tractable, we show that under
standard complexity-theoretic assumptions it does not have a polynomial-size
problem kernel when parameterized by the number of vertex deletions.
Nevertheless, we develop several effective data reduction and pruning rules,
resulting in a competitive solver, clearly outperforming a standard CPLEX
solver in most instances of an established biological test data set.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:16:46 GMT""}]","2020-06-29"
"2006.14973","Arvind Arun Dev","Arvind Arun Dev, Peter Dunne, Thomas M. Hermans, Bernard Doudin","Fluid drag reduction by magnetic confinement","MS- 22 pages, 5 figures",,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  The frictional forces of a viscous liquid flow are a major energy loss issue
and severely limit microfluidics practical use. Reducing this drag by more than
a few tens of percent remain illusive. Here, we show how cylindrical
liquid-in-liquid flow leads to drag reduction of 60-99% for sub mm and mm sized
channels, irrespective of whether the viscosity of the transported liquid is
larger or smaller than that of the encapsulating one. In contrast to
lubrication or sheath flow, we do not require the continuous flow of the
encapsulating lubricant, here made up of a ferrofluid held in place by magnetic
forces. In a laminar flow model with appropriate boundary conditions, we
introduce a modified Reynolds number with a scaling that depends on geometrical
factors and viscosity ratio of the two liquids. It explains our whole range of
data and reveal the key design parameters for optimizing the drag reduction
values. Our results therefore open the route to microfluidics designs with
pressure gradients possibly reduced by orders of magnitudes.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:18:47 GMT""},{""version"":""v2"",""created"":""Tue, 8 Dec 2020 11:51:00 GMT""},{""version"":""v3"",""created"":""Tue, 2 Mar 2021 11:49:17 GMT""},{""version"":""v4"",""created"":""Fri, 1 Oct 2021 13:52:01 GMT""}]","2021-10-04"
"2006.14975","Jayant Joshi","Jayant Joshi, Luc H. M. Rouppe van der Voort, and Jaime de la Cruz
  Rodr\'iguez","Signatures of ubiquitous magnetic reconnection in the lower solar
  atmosphere","Submitted to A&A letters","A&A 641, L5 (2020)","10.1051/0004-6361/202038769",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ellerman Bomb-like brightenings of the hydrogen Balmer line wings in the
quiet Sun (QSEBs) are a signature of the fundamental process of magnetic
reconnection at the smallest observable scale in the solar lower atmosphere. We
analyze high spatial resolution observations (0.1 arcsec) obtained with the
Swedish 1-m Solar Telescope to explore signatures of QSEBs in the H$\beta$
line. We find that QSEBs are ubiquitous and uniformly distributed throughout
the quiet Sun, predominantly occurring in intergranular lanes. We find up to
120 QSEBs in the FOV for a single moment in time; this is more than an order of
magnitude higher than the number of QSEBs found in earlier H$\alpha$
observations. This suggests that about half a million QSEBs could be present in
the lower solar atmosphere at any given time. The QSEB brightening found in the
H$\beta$ line wings also persist in the line core with a temporal delay and
spatial offset towards the nearest solar limb. Our results suggest that QSEBs
emanate through magnetic reconnection along vertically extended current sheets
in the solar lower atmosphere. The apparent omnipresence of small-scale
magnetic reconnection may play an important role in the energy balance of the
solar chromosphere.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:20:08 GMT""}]","2020-09-09"
"2006.14976","Gianluigi Bodo","Gianluigi Bodo, Fabrizo Tavecchio and Lorenzo Sironi","Kink-driven magnetic reconnection in relativistic jets: consequences for
  X-ray polarimetry of BL Lacs","12 pages, 14 figures, MNRAS in press",,"10.1093/mnras/staa3620",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate with relativistic MHD simulations the dissipation physics of
BL Lac jets, by studying the synchrotron polarization signatures of particles
accelerated by the kink instability in a magnetically-dominated plasma column.
The nonlinear stage of the kink instability generates current sheets, where
particles can be efficiently accelerated via magnetic reconnection. We identify
current sheets as regions where s = J d/B is above some predefined threshold
(where B is the field strength, J the current density and d the grid scale),
and assume that the particle injection efficiency scales as proportional to the
square of the current. X-ray emitting particles have short cooling times, so
they only probe the field geometry of their injection sites. In contrast,
particles emitting in the optical band, which we follow self-consistently as
they propagate away from their injection sites while cooling, sample a larger
volume, and so they may be expected to produce different polarimetric
signatures. We find that the degree of polarization is roughly the same between
X-ray and optical bands, because even the optical-emitting particles do not
travel far from the current sheet where they were injected, due to lack of
sufficient kink-generated turbulence. The polarization angle shows a different
temporal evolution between the two bands, due to the different regions probed
by X-ray and optical emitting particles. In view of the upcoming IXPE
satellite, our results can help constrain whether kink-induced reconnection (as
opposed to shocks) can be the source of multi-wavelength emission from BL Lacs.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:20:56 GMT""},{""version"":""v2"",""created"":""Tue, 17 Nov 2020 15:50:17 GMT""}]","2020-12-02"
"2006.14977","Jan Kumlin","Jan Kumlin, Kevin Kleinbeck, Nina Stiesdal, Hannes Busche, Sebastian
  Hofferberth, and Hans Peter B\""uchler","Non-exponential decay of a collective excitation in an atomic ensemble
  coupled to a one-dimensional waveguide","17 pages, 6 figures",,"10.1103/PhysRevA.102.063703",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dynamics of a single excitation coherently shared amongst an
ensemble of atoms and coupled to a one-dimensional wave guide. The coupling
between the matter and the light field gives rise to collective phenomena such
as superradiant states with an enhanced initial decay rate, but also to the
coherent exchange of the excitation between the atoms. We find that the
competition between the two phenomena provides a characteristic dynamics for
the decay of the excitations, and remarkably exhibits an algebraic behavior,
instead of the expected standard exponential one, for a large number of atoms.
The analysis is first performed for a chiral waveguide, where the problem can
be solved analytically, and then is extended to the bidirectional waveguide.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:26:35 GMT""},{""version"":""v2"",""created"":""Sun, 3 Jul 2022 15:05:26 GMT""}]","2022-07-05"
"2006.14978","Chenyang Zhu","Hang Zhao, Qijin She, Chenyang Zhu, Yin Yang, Kai Xu","Online 3D Bin Packing with Constrained Deep Reinforcement Learning","AAAI 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We solve a challenging yet practically useful variant of 3D Bin Packing
Problem (3D-BPP). In our problem, the agent has limited information about the
items to be packed into the bin, and an item must be packed immediately after
its arrival without buffering or readjusting. The item's placement also
subjects to the constraints of collision avoidance and physical stability. We
formulate this online 3D-BPP as a constrained Markov decision process. To solve
the problem, we propose an effective and easy-to-implement constrained deep
reinforcement learning (DRL) method under the actor-critic framework. In
particular, we introduce a feasibility predictor to predict the feasibility
mask for the placement actions and use it to modulate the action probabilities
output by the actor during training. Such supervisions and transformations to
DRL facilitate the agent to learn feasible policies efficiently. Our method can
also be generalized e.g., with the ability to handle lookahead or items with
different orientations. We have conducted extensive evaluation showing that the
learned policy significantly outperforms the state-of-the-art methods. A user
study suggests that our method attains a human-level performance.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:28:27 GMT""},{""version"":""v2"",""created"":""Sat, 2 Jan 2021 14:24:11 GMT""},{""version"":""v3"",""created"":""Thu, 4 Mar 2021 13:41:08 GMT""},{""version"":""v4"",""created"":""Sun, 21 Nov 2021 08:12:34 GMT""},{""version"":""v5"",""created"":""Thu, 13 Jan 2022 13:18:26 GMT""}]","2022-01-14"
"2006.14979","Juan C. Correa","J.C. Correa, H. Laverde-Rojas, F. Marmolejo-Ramos, J. Tejada, \v{S}.
  Bahn\'ik","The Sci-hub Effect: Sci-hub downloads lead to more article citations","19 pages, 8 figures, 11 tables",,,,"cs.DL cs.IR stat.AP","http://creativecommons.org/licenses/by/4.0/","  Citations are often used as a metric of the impact of scientific
publications. Here, we examine how the number of downloads from Sci-hub as well
as various characteristics of publications and their authors predicts future
citations. Using data from 12 leading journals in economics, consumer research,
neuroscience, and multidisciplinary research, we found that articles downloaded
from Sci-hub were cited 1.72 times more than papers not downloaded from Sci-hub
and that the number of downloads from Sci-hub was a robust predictor of future
citations. Among other characteristics of publications, the number of figures
in a manuscript consistently predicts its future citations. The results suggest
that limited access to publications may limit some scientific research from
achieving its full impact.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:29:07 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 18:27:38 GMT""}]","2020-07-01"
"2006.14980","Marco Iglesias","Marco Iglesias and Yuchen Yang","Adaptive regularisation for ensemble Kalman inversion",,,,,"math.NA cs.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new regularisation strategy for the classical ensemble Kalman
inversion (EKI) framework. The strategy consists of: (i) an adaptive choice for
the regularisation parameter in the update formula in EKI, and (ii) criteria
for the early stopping of the scheme. In contrast to existing approaches, our
parameter choice does not rely on additional tuning parameters which often have
severe effects on the efficiency of EKI. We motivate our approach using the
interpretation of EKI as a Gaussian approximation in the Bayesian tempering
setting for inverse problems. We show that our parameter choice controls the
symmetrised Kulback-Leibler divergence between consecutive tempering measures.
We further motivate our choice using a heuristic statistical discrepancy
principle.
  We test our framework using electrical impedance tomography with the complete
electrode model. Parameterisations of the unknown conductivity are employed
which enable us to characterise both smooth or a discontinuous
(piecewise-constant) fields. We show numerically that the proposed
regularisation of EKI can produce efficient, robust and accurate estimates,
even for the discontinuous case which tends to require larger ensembles and
more iterations to converge. We compare the proposed technique with a standard
method of choice and demonstrate that the proposed method is a viable choice to
address computational efficiency of EKI in practical/operational settings.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:29:22 GMT""},{""version"":""v2"",""created"":""Wed, 23 Sep 2020 14:41:43 GMT""}]","2020-09-24"
"2006.14981","Colin Ingalls","Colin Ingalls, Adam Logan","Crepant resolutions of double covers: On the Cynk-Hulek criterion for
  crepant resolutions of double cover",,,,,"math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A collection $S = \{D_1,\ldots, D_n\}$ of divisors in a smooth variety $X$ is
an {\em arrangement} if intersections of all subsets of $S$ are smooth. We show
that a double cover of $X$ ramified on an arrangement has a crepant resolution
under additional hypotheses. Namely, we assume that all intersection components
that change the canonical divisor when blown up satisfy are {\em splayed}, a
property of the tangent spaces of the components first studied by Faber. This
strengthens a result of Cynk and Hulek, which requires a stronger hypothesis on
the intersection components. Further, we study the singular subscheme of the
union of the divisors in $S$ and prove that it has a primary decomposition
where the primary components are supported on exactly the subvarieties which
are blown up in the course of constructing the crepant resolution of the double
cover.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:29:39 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 15:03:49 GMT""}]","2020-07-16"
"2006.14982","Solangel Rojas Torres","M. Broz, J.C. Cabanillas Noris, E. Calvo Villar, C. Duarte Galvan, E.
  Endress, L.G. Espinoza Beltran, A. Fernandez Tellez, D. Finogeev, A.M. Gago,
  G. Herrera Corral, T. Kim, A. Kurepin, A.B. Kurepin, N. Kurepin, I. Leon
  Monzon, M.I. Martinez Hernandez, C. Mayer, M.M. Mieskolainen, R. Orava, L. A.
  Perez Moreno, J.-P. Revol, M. Rodriguez Cahuantzi, S. Rojas Torres, D.
  Serebryakov, A. Shabanov, E. Usenko, A. Villatoro Tello","Performance of ALICE AD modules in the CERN PS test beam","12 pages, 9 figures",,"10.1088/1748-0221/16/01/P01017",,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two modules of the AD detector have been studied with the test beam at the
T10 facility at CERN. The AD detector is made of scintillator pads read out by
wave-length shifters (WLS)coupled to clean fibres that carry the produced light
to photo-multiplier tubes (PMTs). In ALICE the AD is used to trigger and study
the physics of diffractive and ultra-peripheral collisions as well as for a
variety of technical tasks like beam-gas background monitoring or as a
luminometer. The position dependence of the modules' efficiency has been
measured and the effect of hits on the WLS or PMTs has been evaluated. The
charge deposited by pions and protons has been measured at different momenta of
the test beam. The time resolution is determined as a function of the deposited
charge. These results are important ingredients to better understand the AD
detector, to benchmark the corresponding simulations, and very importantly they
served as a baseline for a similar device, the Forward Diffractive Detector
(FDD), being currently built and that will be in operation in ALICE during the
LHC Runs 3 and 4.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:35:41 GMT""}]","2021-02-03"
"2006.14983","Mohammad Reza Jafari Harandi","M. Reza J. Harandi and Hamid. D. Taghirad","Solution of matching equations of IDA-PBC by Pfaffian differential
  equations",,,"10.1080/00207179.2021.1972345",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding the general solution of partial differential equations (PDEs) is
essential for controller design in newly developed methods. Interconnection and
damping assignment passivity based control (IDA-PBC) is one of such methods in
which the solution to corresponding PDEs which are called matching equations,
is needed to apply it in practice. In this paper, these matching equations are
transformed to corresponding Pfaffian differential equations. Furthermore, it
is shown that upon satisfaction of the integrability condition, the solution to
the corresponding third-order Pfaffian differential equation may be obtained
quite easily. The method is applied to the PDEs of IDA-PBC in some benchmark
systems such as Magnetic levitation system, Pendubot, and underactuated cable
driven robot to verify its applicability.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:37:54 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jul 2020 07:24:24 GMT""},{""version"":""v3"",""created"":""Sun, 16 Aug 2020 14:00:28 GMT""},{""version"":""v4"",""created"":""Sun, 23 Aug 2020 12:25:32 GMT""},{""version"":""v5"",""created"":""Mon, 16 May 2022 13:31:08 GMT""}]","2022-05-17"
"2006.14984","Chengliang Dai","Chengliang Dai, Shuo Wang, Yuanhan Mo, Kaichen Zhou, Elsa Angelini,
  Yike Guo, and Wenjia Bai","Suggestive Annotation of Brain Tumour Images with Gradient-guided
  Sampling","Paper accepted by MICCAI 2020",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning has been widely adopted for medical image analysis in recent
years given its promising performance in image segmentation and classification
tasks. As a data-driven science, the success of machine learning, in particular
supervised learning, largely depends on the availability of manually annotated
datasets. For medical imaging applications, such annotated datasets are not
easy to acquire. It takes a substantial amount of time and resource to curate
an annotated medical image set. In this paper, we propose an efficient
annotation framework for brain tumour images that is able to suggest
informative sample images for human experts to annotate. Our experiments show
that training a segmentation model with only 19% suggestively annotated patient
scans from BraTS 2019 dataset can achieve a comparable performance to training
a model on the full dataset for whole tumour segmentation task. It demonstrates
a promising way to save manual annotation cost and improve data efficiency in
medical imaging applications.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:39:49 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 11:34:10 GMT""}]","2020-07-06"
"2006.14985","Maxime Herda","Pierre Degond, Maxime Herda, and Sepideh Mirrahimi","A Fokker-Planck approach to the study of robustness in gene expression","Minor revisions",,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study several Fokker-Planck equations arising from a stochastic chemical
kinetic system modeling a gene regulatory network in biology. The densities
solving the Fokker-Planck equations describe the joint distribution of the
messenger RNA and micro RNA content in a cell. We provide theoretical and
numerical evidences that the robustness of the gene expression is increased in
the presence of micro RNA. At the mathematical level, increased robustness
shows in a smaller coefficient of variation of the marginal density of the
messenger RNA in the presence of micro RNA. These results follow from explicit
formulas for solutions. Moreover, thanks to dimensional analyses and numerical
simulations we provide qualitative insight into the role of each parameter in
the model. As the increase of gene expression level comes from the underlying
stochasticity in the models, we eventually discuss the choice of noise in our
models and its influence on our results.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:42:04 GMT""},{""version"":""v2"",""created"":""Mon, 14 Sep 2020 09:30:26 GMT""}]","2020-09-15"
"2006.14986","Jonathan Simone","Jonathan Simone","Classification of torus bundles that bound rational homology circles","Final version. Reworked many lattice analysis arguments to improve
  the flow of the paper. Added two cases that were missing from version 1. To
  appear in Algebraic & Geometric Topology",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we completely classify torus bundles over the circle that
bound 4-manifolds with the rational homology of the circle. Along the way, we
classify certain integral surgeries along chain links that bound rational
homology balls and explore a connection to 3-braid closures whose double
branched covers bound rational homology 4-balls.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:45:20 GMT""},{""version"":""v2"",""created"":""Tue, 30 Aug 2022 20:41:26 GMT""}]","2022-09-01"
"2006.14987","Nick Luiken","Nick Luiken and Tristan van Leeuwen","Relaxed regularization for linear inverse problems","25 pages, 14 figures, submitted to SIAM Journal for Scientific
  Computing special issue Sixteenth Copper Mountain Conference on Iterative
  Methods",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider regularized least-squares problems of the form $\min_{x}
\frac{1}{2}\Vert Ax - b\Vert_2^2 + \mathcal{R}(Lx)$. Recently, Zheng et al.,
2019, proposed an algorithm called Sparse Relaxed Regularized Regression (SR3)
that employs a splitting strategy by introducing an auxiliary variable $y$ and
solves $\min_{x,y} \frac{1}{2}\Vert Ax - b\Vert_2^2 + \frac{\kappa}{2}\Vert Lx
- y\Vert_2^2 + \mathcal{R}(x)$. By minimizing out the variable $x$ we obtain an
equivalent system $\min_{y} \frac{1}{2} \Vert F_{\kappa}y -
g_{\kappa}\Vert_2^2+\mathcal{R}(y)$. In our work we view the SR3 method as a
way to approximately solve the regularized problem. We analyze the conditioning
of the relaxed problem in general and give an expression for the SVD of
$F_{\kappa}$ as a function of $\kappa$.
  Furthermore, we relate the Pareto curve of the original problem to the
relaxed problem and we quantify the error incurred by relaxation in terms of
$\kappa$. Finally, we propose an efficient iterative method for solving the
relaxed problem with inexact inner iterations. Numerical examples illustrate
the approach.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:45:26 GMT""},{""version"":""v2"",""created"":""Fri, 13 Nov 2020 14:57:06 GMT""}]","2020-11-16"
"2006.14988","Alex Chan","Alex J. Chan, Ahmed M. Alaa, Zhaozhi Qian and Mihaela van der Schaar","Unlabelled Data Improves Bayesian Uncertainty Calibration under
  Covariate Shift",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Modern neural networks have proven to be powerful function approximators,
providing state-of-the-art performance in a multitude of applications. They
however fall short in their ability to quantify confidence in their predictions
- this is crucial in high-stakes applications that involve critical
decision-making. Bayesian neural networks (BNNs) aim at solving this problem by
placing a prior distribution over the network's parameters, thereby inducing a
posterior distribution that encapsulates predictive uncertainty. While existing
variants of BNNs based on Monte Carlo dropout produce reliable (albeit
approximate) uncertainty estimates over in-distribution data, they tend to
exhibit over-confidence in predictions made on target data whose feature
distribution differs from the training data, i.e., the covariate shift setup.
In this paper, we develop an approximate Bayesian inference scheme based on
posterior regularisation, wherein unlabelled target data are used as
""pseudo-labels"" of model confidence that are used to regularise the model's
loss on labelled source data. We show that this approach significantly improves
the accuracy of uncertainty quantification on covariate-shifted data sets, with
minimal modification to the underlying model architecture. We demonstrate the
utility of our method in the context of transferring prognostic models of
prostate cancer across globally diverse populations.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:50:19 GMT""}]","2020-06-29"
"2006.14989","Cl\'ement Luneau","Cl\'ement Luneau and Nicolas Macris","Tensor estimation with structured priors",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider rank-one symmetric tensor estimation when the tensor is corrupted
by Gaussian noise and the spike forming the tensor is a structured signal
coming from a generalized linear model. The latter is a mathematically
tractable model of a non-trivial hidden lower-dimensional latent structure in a
signal. We work in a large dimensional regime with fixed ratio of
signal-to-latent space dimensions. Remarkably, in this asymptotic regime, the
mutual information between the spike and the observations can be expressed as a
finite-dimensional variational problem, and it is possible to deduce the
minimum-mean-square-error from its solution. We discuss, on examples,
properties of the phase transitions as a function of the signal-to-noise ratio.
Typically, the critical signal-to-noise ratio decreases with increasing
signal-to-latent space dimensions. We discuss the limit of vanishing ratio of
signal-to-latent space dimensions and determine the limiting tensor estimation
problem. We also point out similarities and differences with the case of
matrices.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:51:52 GMT""}]","2020-06-29"
"2006.14990","Andrey Korolkov","A. I. Korolkov, A. V. Shanin, K. S. Kniazeva","Asymptotical study of two-layered discrete waveguide with a weak
  coupling",,,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A thin two-layered waveguide is considered. The governing equations for this
waveguide is a matrix Klein--Gordon equation of dimension~2. A formal solution
of this system in the form of a double integral can be obtained by using
Fourier transformation. Then, the double integral can be reduced to a single
integral with the help of residue integration with respect to the time
frequency. However, such an integral can be difficult to estimate since it
involves branching and oscillating functions. This integral is studied
asymptotically. A zone diagram technique is proposed to represent the set of
possible asymptotic formulae. The zone diagram generalizes the concept of
far-field and near-field zones.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:52:22 GMT""}]","2020-06-29"
"2006.14991","Andrea Catalano","A. Catalano, A. Bideaud, O. Bourrion, M. Calvo, A. Fasano, J. Goupy,
  F. Levy-Bertrand, J.F. Mac\`ias-P\'erez, N. Ponthieu, Q.Y. Tang, A.
  Monfardini","LEKID sensitivity for space applications between 80 and 600 GHz",,,"10.1051/0004-6361/202038199",,"astro-ph.IM astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the design, fabrication and testing of Lumped Element Kinetic
Inductance Detectors (LEKID) showing performance in line with the requirements
of the next generation space telescopes operating in the spectral range from 80
to 600 GHz. This range is of particular interest for Cosmic Microwave
Background (CMB) studies. For this purpose we have designed and fabricated
100-pixel arrays covering five distinct bands. These wafers have been measured
via multiplexing, where a full array is read out using a single pair of lines.
We adopted a custom cold black-body installed in front of the detectors and
regulated at temperatures between 1 K and 20 K. We will describe in the present
paper the main design considerations, the fabrication processes, the testing
and the data analysis.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:57:08 GMT""}]","2022-10-19"
"2006.14992","Farnaz Niroui","Farnaz Niroui, Mayuran Saravanapavanantham, Jinchi Han, Jatin J.
  Patil, Timothy M. Swager, Jeffrey H. Lang, Vladimir Bulovi\'c","Precise Fabrication of Uniform Molecular Gaps for Active Nanoscale
  Devices",,,,,"physics.app-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Molecules with versatile functionalities and well-defined structures, can
serve as building blocks for extreme nanoscale devices. This requires their
precise integration into functional heterojunctions, most commonly in the form
of metal-molecule-metal architectures. Structural damage and nonuniformities
caused by current fabrication techniques, however, limit their effective
incorporation. Here, we present a hybrid fabrication approach enabling uniform
molecular gaps. Template-stripped lithographically-patterned gold electrodes
with sub-nanometer roughness are used as the bottom contacts upon which the
molecular layer is formed through self-assembly. The top contacts are assembled
using dielectrophoretic trapping of colloidal gold nanorods, resulting in
uniform sub-5 nm junctions. In these electrically-active designs, we further
explore the possibility of mechanical tunability. The presence of molecules may
help control sub-nanometer mechanical modulation which is conventionally
difficult to achieve due to instabilities caused by surface adhesive forces.
Our approach is versatile, providing a platform to develop and study active
molecular gaps towards functional nanodevices.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:58:10 GMT""}]","2020-06-29"
"2006.14993","Julia Maria Roquette","J. Roquette, S. H. P. Alencar, J. Bouvier, M.G. Guarcello and B.
  Reipurth","Near-infrared time-series photometry in the field of Cygnus OB2
  association II. Mapping the variability of candidate members","19 pages, 21 Figures","A&A 640, A128 (2020)","10.1051/0004-6361/201936984",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present the results of a J, H, and K photometric variability survey of the
central 0.78 square degrees of the young OB association Cygnus OB2. We used
data observed with the Wide-Field CAMera at the United Kingdom Infrared
Telescope in 2007 (spanning 217 days) to investigate the light curves of 5083
low mass candidate members in the association and explore the occurrence and
main characteristics of their near-infrared variability. We identified 2529
stars ($\sim$50$\%$ of the sample) with significant variability with
time-scales ranging from days to months. We classified the variable stars into
the following three groups according to their light curve morphology: periodic
variability (1697 stars), occultation variability (124 stars), and other types
of variability (726 stars). We verified that the disk-bearing stars in our
sample are significantly more variable in the near-infrared than diskless
stars, with a steep increase in the disk-fraction among stars with higher
variability amplitude. We investigated the trajectories described by variable
stars in the color-space and measured slopes for 335 stars describing linear
trajectories. Based on the trajectories in the color-space, we inferred that
the sample analyzed is composed of a mix of young stars presenting variability
due to hot and cold spots, extinction by circumstellar material, and changes in
the disk emission in the near-infrared. We contemplated using the use of
near-infrared variability to identify disk-bearing stars and verified that
53.4$\%$ of the known disk-bearing stars in our sample could have been
identified as such based solely on their variability. We present 18 newly
identified disk-bearing stars and 14 eclipsing binary candidates among CygOB2
lower-mass members.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:02:21 GMT""}]","2020-09-02"
"2006.14994","Andrei Damian I","Andrei Ionut Damian, Laurentiu Piciu, Cosmin Mihai Marinescu","ProVe -- Self-supervised pipeline for automated product replacement and
  cold-starting based on neural language models",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In retail vertical industries, businesses are dealing with human limitation
of quickly understanding and adapting to new purchasing behaviors. Moreover,
retail businesses need to overcome the human limitation of properly managing a
massive selection of products/brands/categories. These limitations lead to
deficiencies from both commercial (e.g. loss of sales, decrease in customer
satisfaction) and operational perspective (e.g. out-of-stock, over-stock). In
this paper, we propose a pipeline approach based on Natural Language
Understanding, for recommending the most suitable replacements for products
that are out-of-stock. Moreover, we will propose a solution for managing
products that were newly introduced in a retailer's portfolio with almost no
transactional history. This solution will help businesses: automatically assign
the new products to the right category; recommend complementary products for
cross-sell from day 1; perform sales predictions even with almost no
transactional history. Finally, the vector space model resulted by applying the
pipeline presented in this paper is directly used as semantic information in
deep learning-based demand forecasting solutions, leading to more accurate
predictions. The whole research and experimentation process have been done
using real-life private transactional data, however the source code is
available on https://github.com/Lummetry/ProVe
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:03:18 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jan 2021 12:55:40 GMT""}]","2021-01-13"
"2006.14995","Romain Danneau","R. Kraft, M.-H. Liu, P.B. Selvasundaram, S.-C. Chen, R. Krupke, K.
  Richter, R. Danneau","Anomalous Cyclotron Motion in Graphene Superlattice Cavities",,"Phys. Rev. Lett. 125, 217701 (2020)","10.1103/PhysRevLett.125.217701",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider graphene superlattice miniband fermions probed by electronic
interferometry in magneto-transport experiments. By decoding the observed
Fabry-P\'erot interference patterns together with our corresponding quantum
transport simulations, we find that the Dirac quasiparticles originating from
the superlattice minibands do not undergo conventional cyclotron motion but
follow more subtle trajectories. In particular, dynamics at low magnetic fields
is characterized by peculiar, straight trajectory segments. Our results provide
new insights into superlattice miniband fermions and open up novel
possibilities to use periodic potentials in electron optics experiments.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:10:29 GMT""}]","2020-11-25"
"2006.14996","Rohini Ramadas","Rohini Ramadas","Pullbacks of $\kappa$ classes on $\overline{\mathcal{M}}_{0,n}$","11 pages; comments welcome",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The moduli space $\overline{\mathcal{M}}_{0,n}$ carries a codimension-$d$
cycle class $\kappa_{d}$. We consider the subspace $\mathcal{K}^{d}_{n}$ of
$A^d(\overline{\mathcal{M}}_{0,n},\mathbb{Q})$ spanned by pullbacks of
$\kappa_d$ via forgetful maps. We find a permutation basis for
$\mathcal{K}^{d}_{n}$, and describe its annihilator under the intersection
pairing in terms of $d$-dimensional boundary strata. As an application, we give
a new permutation basis of the divisor class group of
$\overline{\mathcal{M}}_{0,n}$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:10:39 GMT""}]","2020-06-29"
"2006.14997","Kieran Leschinski","Kieran Leschinski (1) and Jo\~ao Alves (1) ((1) Department of
  Astrophysics, University of Vienna)","The Initial Mass Function in the ELT era","4 pages, 2 figures, related to doi.org/10.1051/0004-6361/202038145",,,,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The initial mass function (IMF) is an important, yet enigmatic aspect of the
star formation process. The two major open questions regarding the IMF are: is
the IMF constant regardless of environment? Is the IMF a universal property of
star formation? The next generation of extremely large telescopes will allow us
to observe further, fainter and more compact stellar clusters than is possible
with current facilities. In these proceeding we present our study looking at
just how much will these future observatories improve our knowledge of the IMF.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:11:39 GMT""}]","2020-06-29"
"2006.14998","Qingliang Fan","Qingliang Fan, Yaqian Wu","Endogenous Treatment Effect Estimation with some Invalid and Irrelevant
  Instruments","36 pages, 6 figures",,,,"econ.EM stat.AP stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Instrumental variables (IV) regression is a popular method for the estimation
of the endogenous treatment effects. Conventional IV methods require all the
instruments are relevant and valid. However, this is impractical especially in
high-dimensional models when we consider a large set of candidate IVs. In this
paper, we propose an IV estimator robust to the existence of both the invalid
and irrelevant instruments (called R2IVE) for the estimation of endogenous
treatment effects. This paper extends the scope of Kang et al. (2016) by
considering a true high-dimensional IV model and a nonparametric reduced form
equation. It is shown that our procedure can select the relevant and valid
instruments consistently and the proposed R2IVE is root-n consistent and
asymptotically normal. Monte Carlo simulations demonstrate that the R2IVE
performs favorably compared to the existing high-dimensional IV estimators
(such as, NAIVE (Fan and Zhong, 2018) and sisVIVE (Kang et al., 2016)) when
invalid instruments exist. In the empirical study, we revisit the classic
question of trade and growth (Frankel and Romer, 1999).
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:11:43 GMT""}]","2020-06-29"
"2006.14999","Christian Igel","Kai Br\""ugge, Asja Fischer, Christian Igel","On the convergence of the Metropolis algorithm with fixed-order updates
  for multivariate binary probability distributions",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Metropolis algorithm is arguably the most fundamental Markov chain Monte
Carlo (MCMC) method. But the algorithm is not guaranteed to converge to the
desired distribution in the case of multivariate binary distributions (e.g.,
Ising models or stochastic neural networks such as Boltzmann machines) if the
variables (sites or neurons) are updated in a fixed order, a setting commonly
used in practice. The reason is that the corresponding Markov chain may not be
irreducible. We propose a modified Metropolis transition operator that behaves
almost always identically to the standard Metropolis operator and prove that it
ensures irreducibility and convergence to the limiting distribution in the
multivariate binary case with fixed-order updates. The result provides an
explanation for the behaviour of Metropolis MCMC in that setting and closes a
long-standing theoretical gap. We experimentally studied the standard and
modified Metropolis operator for models were they actually behave differently.
If the standard algorithm also converges, the modified operator exhibits
similar (if not better) performance in terms of convergence speed.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:11:54 GMT""}]","2020-06-29"
"2006.15000","Vadim Malvone","Francesco Belardinelli, Catalin Dima, Vadim Malvone, and Ferucio
  Tiplea","A Hennessy-Milner Theorem for ATL with Imperfect Information",,,,,"cs.LO cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that a history-based variant of alternating bisimulation with
imperfect information allows it to be related to a variant of Alternating-time
Temporal Logic (ATL) with imperfect information by a full Hennessy-Milner
theorem. The variant of ATL we consider has a common knowledge semantics, which
requires that the uniform strategy available for a coalition to accomplish some
goal must be common knowledge inside the coalition, while other semantic
variants of ATL with imperfect information do not accommodate a Hennessy-Milner
theorem. We also show that the existence of a history-based alternating
bisimulation between two finite Concurrent Game Structures with imperfect
information (iCGS) is undecidable.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:12:11 GMT""}]","2020-06-29"
"2006.15001","Mona Ghassemi","Moein Borghei, Mona Ghassemi","Effects of Low Pressure Condition on Partial Discharges in WBG Power
  Electronics Modules",,,,,"physics.app-ph cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aviation industry aims to reduce CO2 emission by reducing energy
consumption and benefitting from more electrical systems than those based on
fossil fuels. The more electric aircraft (MEA) can take advantage of the drives
based on wide bandgap (WBG) based power modules that are lighter and can bear
higher voltages and currents. However, the fast-rise and repetitive voltage
pulses generated by WBG-based systems can endanger the insulating property of
dielectric materials due to the partial discharges. PDs cause the local
breakdown of insulation materials in regions with high electric field
magnitude. In the case of power electronic modules, silicone gel, which is a
predominant type of encapsulation material, is susceptible to these PDs. In
this study, it is aimed to investigate the impact of rise time on various PD
characteristics including PD true charge magnitude, inception and extinction
fields, duration, and so forth. Besides, those systems that are anticipated to
operate under harsh environmental conditions such as naval or aviation
industries, may expect additional threat. Therefore, this paper puts forth the
combination of low pressure conditions and fast rise, high frequency square
wave pulses. The results demonstrate that more intense and more intense ones
are going to be imposed at lower pressures. COMSOL Multiphysics interfaced with
MATLAB is used to simulate the PD detection process based on the experimental
data found in the literature.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:14:14 GMT""}]","2020-06-29"
"2006.15002","Mojtaba Alaei","Mohammad Amirabbasi and Mojtaba Alaei","Ab initio determination of magnetic ground state of pyrochlore
  Y$_2$Mn$_2$O$_7$",,"Phys. Rev. B 102, 125105 (2020)","10.1103/PhysRevB.102.125105",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are two discrepant experimental results on the magnetic ground state of
Y$_{2}$Mn$_{2}$O$_{7}$, one study proposes a spin glass state, while another
introduces the material as a ferromagnet. In this study, we attempt to resolve
this issue by employing density functional theory and Monte Carlo simulations.
We derive different spin models by varying the Hubbard $U$ parameter in ab
initio GGA+$U$ calculations. For the most range of Hubbard $U$, We obtain that
the leading terms in the spin Hamiltonian are bi-quadratic and the nearest
neighbor Heisenberg exchange interactions. By comparing Monte Carlo simulations
of these models with the experiments, we find a ferromagnetic ground state for
Y$_{2}$Mn$_{2}$O$_{7}$ as the most compatible with experiments. We also
consider Y$_{2}$Mo$_{2}$O$_{7}$ as a prototype of the defect-free pyrochlore
system with spin-glass behavior and compare it with Y$_{2}$Mn$_{2}$O$_{7}$. The
orbital degrees of freedom are considered as a leading factor in converting a
defect-free pyrochlore such as Y$_{2}$Mn$_{2}$O$_{7}$ to a spin glass system.
By changing the $d$ orbital occupations of Mo atoms, our GGA+$U$ calculations
for Y$_{2}$Mo$_{2}$O$_{7}$ indicate many nearly degenerate states with
different $d$ orbital orientations which reveals $d$ orbital degrees of freedom
in this material. While for Y$_{2}$Mn$_{2}$O$_{7}$, we find a single ground
state with a fixed orbital orientation. Consequently, all of our ab initio
approaches confirm Y$_{2}$Mn$_{2}$O$_{7}$ as a ferromagnetic system.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:15:47 GMT""}]","2020-09-09"
"2006.15003","Nadia Milazzo","Nadia Milazzo (1 and 2), Daniel Braun (1) and Olivier Giraud (2) ((1)
  Institut f\""ur theoretische Physik, Universit\""at T\""ubingen, T\""ubingen,
  Germany, (2) Universit\'e Paris-Saclay, CNRS, LPTMS, Orsay, France)","Truncated moment sequences and a solution to the channel separability
  problem","11 pages, 2 figures","Phys. Rev. A 102, 052406 (2020)","10.1103/PhysRevA.102.052406",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of separability of quantum channels via the Choi
matrix representation given by the Choi-Jamio{\l}kowski isomorphism. We explore
three classes of separability across different cuts between systems and
ancillae and we provide a solution based on the mapping of the coordinates of
the Choi state (in a fixed basis) to a truncated moment sequence (tms) $y$.
This results in an algorithm which gives a separability certificate using
semidefinite programming. The computational complexity and the performance of
it depend on the number of variables $n$ in the tms and on the size of the
moment matrix $M_t(y)$ of order $t$. We exploit the algorithm to numerically
investigate separability of families of 2-qubit and single-qutrit channels; in
the latter case we can provide an answer for examples explored earlier through
the criterion based on the negativity $N$, a criterion which remains
inconclusive for Choi matrices with $N=0$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:16:56 GMT""}]","2020-11-11"
"2006.15004","Alexander Potekhin","A. Y. Potekhin, D. A. Zyuzin, D. G. Yakovlev, M. V. Beznogov, Yu. A.
  Shibanov","Thermal luminosities of cooling neutron stars","23 pages, 3 figures, 2 tables, accepted by MNRAS. In v.2,
  acknowledgements are supplemented","MNRAS 496, 5052-5071 (2020)","10.1093/mnras/staa1871",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ages and thermal luminosities of neutron stars, inferred from observations,
can be interpreted with the aid of the neutron star cooling theory to gain
information on the properties of superdense matter in neutron-star interiors.
We present a survey of estimated ages, surface temperatures and thermal
luminosities of middle-aged neutron stars with relatively weak or moderately
strong magnetic fields, which can be useful for these purposes. The catalogue
includes results selected from the literature, supplemented with new results of
spectral analysis of a few cooling neutron stars. The data are compared with
the theory. We show that overall agreement of theoretical cooling curves with
observations improves substantially for models where neutron superfluidity in
stellar core is weak.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:19:23 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 09:00:00 GMT""}]","2020-07-21"
"2006.15005","Zhan Gao","Zhan Gao and Mark Eisen and Alejandro Ribeiro","Resource Allocation via Graph Neural Networks in Free Space Optical
  Fronthaul Networks",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates the optimal resource allocation in free space optical
(FSO) fronthaul networks. The optimal allocation maximizes an average weighted
sum-capacity subject to power limitation and data congestion constraints. Both
adaptive power assignment and node selection are considered based on the
instantaneous channel state information (CSI) of the links. By parameterizing
the resource allocation policy, we formulate the problem as an unsupervised
statistical learning problem. We consider the graph neural network (GNN) for
the policy parameterization to exploit the FSO network structure with
small-scale training parameters. The GNN is shown to retain the permutation
equivariance that matches with the permutation equivariance of resource
allocation policy in networks. The primal-dual learning algorithm is developed
to train the GNN in a model-free manner, where the knowledge of system models
is not required. Numerical simulations present the strong performance of the
GNN relative to a baseline policy with equal power assignment and random node
selection.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:20:48 GMT""}]","2020-06-29"
"2006.15006","Xi Chen","Lincan Fang, Esko Makkonen, Milica Todorovic, Patrick Rinke, Xi Chen","Efficient Cysteine Conformer Search with Bayesian Optimization",,,,,"physics.comp-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding low-energy molecular conformers is challenging due to the high
dimensionality of the search space and the computational cost of accurate
quantum chemical methods for determining conformer structures and energies.
Here, we combine active-learning Bayesian optimization (BO) algorithms with
quantum chemistry methods to address this challenge. Using cysteine as an
example, we show that our procedure is both efficient and accurate. After only
one thousand single-point calculations and approximately thirty structure
relaxations, which is less than 10% computational cost of the current fastest
method, we have found the low-energy conformers in good agreement with
experimental measurements and reference calculations.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:21:31 GMT""}]","2020-06-29"
"2006.15007","Aria Shahverdi","Aria Shahverdi, Mahammad Shirinov, Dana Dachman-Soled","Database Reconstruction from Noisy Volumes: A Cache Side-Channel Attack
  on SQLite","Source code :
  https://github.com/ariashahverdi/database_reconstruction",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the feasibility of database reconstruction under a cache
side-channel attack on SQLite. Specifically, we present a Flush+Reload attack
on SQLite that obtains approximate (or ""noisy"") volumes of range queries made
to a private database. We then present several algorithms that, taken together,
reconstruct nearly the exact database in varied experimental conditions, given
these approximate volumes. Our reconstruction algorithms employ novel
techniques for the approximate/noisy setting, including a noise-tolerant
clique-finding algorithm, a ""Match & Extend"" algorithm for extrapolating
volumes that are omitted from the clique, and a ""Noise Reduction Step"" that
makes use of a closest vector problem (CVP) solver to improve the overall
accuracy of the reconstructed database. The time complexity of our attacks
grows quickly with the size of the range of the queried attribute, but scales
well to large databases. Experimental results show that we can reconstruct
databases of size 100,000 and ranges of size 12 with error percentage of 0.11 %
in under 12 hours on a personal laptop.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:21:36 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 23:14:01 GMT""},{""version"":""v3"",""created"":""Tue, 16 Feb 2021 23:27:16 GMT""},{""version"":""v4"",""created"":""Sun, 20 Jun 2021 20:03:03 GMT""}]","2021-06-22"
"2006.15008","Sam Polk","Sam L. Polk and Bruce M. Boghosian","The Nonuniversality of Wealth Distribution Tails Near Wealth
  Condensation Criticality","20 pages, 2 figures","SIAM Journal on Applied Mathematics 81, no. 4 (2021): 1717-1741","10.1137/19M1306051",,"q-fin.GN physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we modify the affine wealth model of wealth distributions to
examine the effects of nonconstant redistribution on the very wealthy. Previous
studies of this model, restricted to flat redistribution schemes, have
demonstrated the presence of a phase transition to a partially wealth-condensed
state, or ""partial oligarchy,"" at the critical value of an order parameter.
These studies have also indicated the presence of an exponential tail in wealth
distribution precisely at criticality. Away from criticality, the tail was
observed to be Gaussian. In this work, we generalize the flat redistribution
within the affine wealth model to allow for an essentially arbitrary
redistribution policy. We show that the exponential tail observed near
criticality in prior work is, in fact, a special case of a much broader class
of critical, slower-than-Gaussian decays that depend sensitively on the
corresponding asymptotic behavior of the progressive redistribution model used.
We thereby demonstrate that the functional form of the tail of the wealth
distribution in a near-critical society is not universal in nature but rather
entirely determined by the specifics of public policy decisions. This is
significant because most major economies today are observed to be
near-critical.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:26:02 GMT""},{""version"":""v2"",""created"":""Mon, 24 May 2021 13:01:11 GMT""},{""version"":""v3"",""created"":""Tue, 26 Oct 2021 13:03:22 GMT""}]","2021-10-27"
"2006.15009","Thomas Moerland","Thomas M. Moerland, Joost Broekens, Aske Plaat, Catholijn M. Jonker","A Unifying Framework for Reinforcement Learning and Planning",,,,,"cs.LG cs.AI cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequential decision making, commonly formalized as optimization of a Markov
Decision Process, is a key challenge in artificial intelligence. Two successful
approaches to MDP optimization are reinforcement learning and planning, which
both largely have their own research communities. However, if both research
fields solve the same problem, then we might be able to disentangle the common
factors in their solution approaches. Therefore, this paper presents a unifying
algorithmic framework for reinforcement learning and planning (FRAP), which
identifies underlying dimensions on which MDP planning and learning algorithms
have to decide. At the end of the paper, we compare a variety of well-known
planning, model-free and model-based RL algorithms along these dimensions.
Altogether, the framework may help provide deeper insight in the algorithmic
design space of planning and reinforcement learning.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:30:41 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jul 2020 08:52:43 GMT""},{""version"":""v3"",""created"":""Thu, 23 Jul 2020 15:02:03 GMT""},{""version"":""v4"",""created"":""Thu, 31 Mar 2022 08:06:35 GMT""}]","2022-04-01"
"2006.15010","Ravi Kiran","Ravi Kiran, Madhumita Roy, Syed Abbas, A. Taraphder","Effect of population migration and punctuated lockdown on the spread of
  infectious diseases","17 pages, 14 figures","Nonauton. Dyn. Syst. 2021; 8:251-266",,,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the critical measures to control infectious diseases is a lockdown.
Once past the lockdown stage in many parts of the world, the crucial question
now concerns the effects of relaxing the lockdown and finding the best ways to
implement further lockdown(s), if required, to control the spread. With the
relaxation of lockdown, people migrate to different cities and enhance the
spread of the disease. This work presents the population migration model for
n-cities and applies the model for migration between two and three cities. The
reproduction number is calculated, and the effect of the migration rate is
analyzed. A punctuated lockdown is implemented to simulate a protocol of
repeated lockdowns that limits the resurgence of infections. A damped
oscillatory behavior is observed with multiple peaks over a period.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:32:41 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 15:18:06 GMT""},{""version"":""v3"",""created"":""Thu, 9 Dec 2021 13:24:24 GMT""}]","2021-12-10"
"2006.15011","Mitchell Young","Mitchell E. Young, Luca Fossati, Tommi T. Koskinen, Michael Salz,
  Patricio E. Cubillos, and Kevin France","Non-Local Thermodynamic Equilibrium Transmission Spectrum Modelling of
  HD209458b","Accepted for publication in A&A, 15 pages, 13 figures","A&A 641, A47 (2020)","10.1051/0004-6361/202037672",,"astro-ph.EP astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context - Exoplanetary upper atmospheres are low density environments where
radiative processes can compete with collisional ones and introduce non-local
thermodynamic equilibrium (NLTE) effects into transmission spectra.
  Aims - We develop a NLTE radiative transfer framework capable of modelling
exoplanetary transmission spectra over a wide range of planetary properties.
  Methods - We adapt the NLTE spectral synthesis code Cloudy to produce an
atmospheric structure and atomic transmission spectrum in both NLTE and local
thermodynamic equilibrium (LTE) for the hot Jupiter HD209458b, given a
published T-P profile and assuming solar metallicity. Selected spectral
features, including H$\alpha$, Na I D, He I $\lambda$10830, Fe I & II
ultra-violet (UV) bands, and C, O and Si UV lines, are compared with literature
observations and models where available. The strength of NLTE effects are
measured for individual spectral lines to identify which features are most
strongly affected.
  Results - The developed modelling framework computing NLTE synthetic spectra
reproduces literature results for the He I $\lambda$10830 triplet, the Na I D
lines, and the forest of Fe I lines in the optical. Individual spectral lines
in the NLTE spectrum exhibit up to 40 % stronger absorption relative to the LTE
spectrum.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:33:15 GMT""}]","2020-09-09"
"2006.15012","Weilong Fu","Ali Hirsa and Weilong Fu","An unsupervised deep learning approach in solving partial
  integro-differential equations","22 pages, 4 figures","Quantitative Finance, 2022","10.1080/14697688.2022.2057870",,"q-fin.CP cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate solving partial integro-differential equations (PIDEs) using
unsupervised deep learning in this paper. To price options, assuming underlying
processes follow Levy processes, we require to solve PIDEs. In supervised deep
learning, pre-calculated labels are used to train neural networks to fit the
solution of the PIDE. In an unsupervised deep learning, neural networks are
employed as the solution, and the derivatives and the integrals in the PIDE are
calculated based on the neural network. By matching the PIDE and its boundary
conditions, the neural network gives an accurate solution of the PIDE. Once
trained, it would be fast for calculating options values as well as option
Greeks.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:01:05 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 17:20:45 GMT""},{""version"":""v3"",""created"":""Thu, 10 Dec 2020 16:44:25 GMT""}]","2022-07-04"
"2006.15014","Rui Zhu","Rui Zhu, Baolin Tan, Yingna Su, Hui Tian, Yu Xu, Xingyao Chen,
  Yongliang Song, Guangyu Tan","Microwave diagnostics of magnetic field strengths in solar flaring loops",,,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have performed microwave diagnostics of the magnetic field strengths in
solar flare loops based on the theory of gyrosynchrotron emission. From
Nobeyama Radioheliograph observations of three flare events at 17 and 34 GHz,
we obtained the degree of circular polarization and the spectral index of
microwave flux density, which were then used to map the magnetic field
strengths in post-flare loops. Our results show that the magnetic field
strength typically decreases from ~800 G near the loop footpoints to ~100 G at
a height of 10--25 Mm. Comparison of our results with magnetic field modeling
using a flux rope insertion method is also discussed. Our study demonstrates
the potential of microwave imaging observations, even at only two frequencies,
in diagnosing the coronal magnetic field of flaring regions.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:36:41 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 05:46:25 GMT""}]","2020-06-30"
"2006.15016","Micha{\l} Szanecki","Michal Szanecki, Andrzej Niedzwiecki, Chris Done, Lukasz Klepczarek,
  Piotr Lubinski, Misaki Mizumoto","Geometry of the X-ray source 1H 0707-495","Accepted for publication in Astronomy & Astrophysics journal","A&A 641, A89 (2020)","10.1051/0004-6361/202038303",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate constraints for the size and location of the X-ray source in
1H 0707-495 determined from the shape of the relativistically smeared
reflection from the accretion disc. We develop a new code to model an extended
X-ray source and we apply it to all archival XMM observations of 1H 0707-495.
Contrary to Wilkins et al. we find that the relativistic reflection in this
source is not consistent with an extended uniform corona. Instead, we find that
the X-ray source must be very compact, with the size of at most a gravitational
radius, and located at most at a few gravitational radii from the black hole
horizon. A uniform extended corona does indeed produce an emissivity which is
like a twice broken power law, but the inner emissivity is fixed by the source
geometry rather than being a free parameter. In 1H0707-495, reflection from the
inner disc is much stronger than expected for a uniformly extended source.
Including the effect of ionised absorption from a wind does not change this
conclusion, but including scattered emission (and more complex absorption) from
the wind can dramatically change the reflection parameters.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:38:01 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 08:36:40 GMT""}]","2020-09-16"
"2006.15017","Timothy Clifton","Timothy Clifton, Pedro Carrilho, Pedro G. S. Fernandes, David J.
  Mulryne","Observational Constraints on the Regularized 4D Einstein-Gauss-Bonnet
  Theory of Gravity","17 pages","Phys. Rev. D 102, 084005 (2020)","10.1103/PhysRevD.102.084005",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the observational constraints that can be imposed on
the coupling parameter, $\hat \alpha$, of the regularized version of the
4-dimensional Einstein-Gauss-Bonnet theory of gravity. We use the scalar-tensor
field equations of this theory to perform a thorough investigation of its
slow-motion and weak-field limit, and apply our results to observations of a
wide array of physical systems that admit such a description. We find that the
LAGEOS satellites are the most constraining, requiring $| \hat \alpha |
\lesssim 10^{10} \,{\rm m}^2$. This constraint suggests that the possibility of
large deviations from general relativity is small in all systems except the
very early universe ($t<10^{-3}\, {\rm s}$), or the immediate vicinity of
stellar-mass black holes ($M\lesssim100\, M_{\odot}$). We then consider
constraints that can be imposed on this theory from cosmology, black hole
systems, and table-top experiments. It is found that early universe inflation
prohibits all but the smallest negative values of $\hat \alpha$, while
observations of binary black hole systems are likely to offer the tightest
constraints on positive values, leading to overall bounds $0 \lesssim \hat
\alpha \lesssim 10^8 \, {\rm m}^2$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:39:05 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 09:48:35 GMT""},{""version"":""v3"",""created"":""Fri, 2 Oct 2020 13:06:43 GMT""},{""version"":""v4"",""created"":""Wed, 7 Oct 2020 13:57:11 GMT""}]","2020-10-08"
"2006.15018","Savvas Nesseris","Manuel Trashorras, Juan Garc\'ia-Bellido, Savvas Nesseris","The clustering dynamics of primordial black boles in $N$-body
  simulations","50 pages, 16 figures, 19 tables","Universe 7 (2021) 1, 18","10.3390/universe7010018","IFT-UAM/CSIC-20-94","astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the possibility that Dark Matter (DM) may be explained by a
non-uniform background of approximately stellar-mass clusters of Primordial
Black Holes (PBHs), by simulating the evolution them from recombination to the
present with over 5000 realisations using a Newtonian $ N $-body code. We
compute the cluster rate of evaporation, and extract the binary and merged
sub-populations along with their parent and merger tree histories, lifetimes
and formation rates; the dynamical and orbital parameter profiles, the degree
of mass segregation and dynamical friction, and power spectrum of close
encounters. Overall, we find that PBHs can constitute a viable DM candidate,
and that their clustering presents a rich phenomenology throughout the history
of the Universe. We show that binary systems constitute about 9.5\% of all PBHs
at present, with mass ratios of $ \bar{q}_{\rm B} = 0.154 $, and total masses
of $ \bar{m}_{\rm T,\,B} = 303\,M_\odot$. Merged PBHs are rare, about 0.0023\%
of all PBHs at present, with mass ratios of $ \bar{q}_{\rm B}= 0.965 $ with
total and chirp masses of $ \bar{m}_{\rm T,\,B}= 1670\,M_\odot$ and $
\bar{m}_{c,{\rm M}} = 642\,M_\odot $ respectively. We find that cluster puffing
up and evaporation leads to bubbles of these PBHs of order 1 kpc containing at
present times about 36\% of objects and mass, with hundred pc sized cores. We
also find that these PBH sub-haloes are distributed in wider PBH haloes of
order hundreds of kpc, containing about 63\% of objects and mass, coinciding
with the sizes of galactic halos. We find at last high rates of close
encounters of massive Black Holes ($ M \sim 1000\,M_\odot$), with $
\Gamma^{\mathrm{S}} = (1.2^{+5.9}_{-0.9}) \times 10^{7} \mathrm{yr^{-1}
Gpc^{-3}}$ and mergers with $\Gamma^{\mathrm{M}} = 1337 \pm 41 \mathrm{yr^{-1}
Gpc^{-3}} $.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:39:08 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 11:53:27 GMT""}]","2021-03-17"
"2006.15019","Art\=urs Mozers","A. Mozers, L. Busaite, D. Osite, M. Auzinsh","Angular momentum alignment-to-orientation conversion in the ground state
  of Rb atoms at room temperature","11 pages, 11 figures","Phys. Rev. A 102, 053102 (2020)","10.1103/PhysRevA.102.053102",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated experimentally and theoretically angular momentum
alignment-to-orientation conversion created by the joint interaction of laser
radiation and an external magnetic field with atomic rubidium at room
temperature. In particular we were interested in alignment-to-orientation
conversion in atomic ground state. Experimentally the laser frequency was fixed
to the hyperfine transitions of $D_1$ line of rubidium. We used a theoretical
model for signal simulations that takes into account all neighboring hyperfine
levels, the mixing of magnetic sublevels in an external magnetic field, the
coherence properties of the exciting laser radiation, and the Doppler effect.
The experiments were carried out by exciting the atoms with linearly polarized
laser radiation. Two oppositely circularly polarized laser induced fluorescence
(LIF) components were detected and afterwards their difference was taken. The
combined LIF signals originating from the hyperfine magnetic sublevel
transitions of $^{85}$Rb and $^{87}$Rb rubidium isotopes were included. The
alignment-to-orientation conversion can be undoubtedly identified in the
difference signals for various laser frequencies as well as change in signal
shapes can be observed when the laser power density is increased. We studied
the formation and the underlying physical processes of the observed signal of
the LIF components and their difference by performing the analysis of the
influence of incoherent and coherent effects. We performed simulations of
theoretical signals that showed the influence of ground-state coherent effects
on the LIF difference signal.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:43:15 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 15:05:18 GMT""}]","2020-11-11"
"2006.15020","Marjan Ghazvininejad","Mike Lewis, Marjan Ghazvininejad, Gargi Ghosh, Armen Aghajanyan, Sida
  Wang, Luke Zettlemoyer","Pre-training via Paraphrasing",,,,,"cs.CL cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce MARGE, a pre-trained sequence-to-sequence model learned with an
unsupervised multi-lingual multi-document paraphrasing objective. MARGE
provides an alternative to the dominant masked language modeling paradigm,
where we self-supervise the reconstruction of target text by retrieving a set
of related texts (in many languages) and conditioning on them to maximize the
likelihood of generating the original. We show it is possible to jointly learn
to do retrieval and reconstruction, given only a random initialization. The
objective noisily captures aspects of paraphrase, translation, multi-document
summarization, and information retrieval, allowing for strong zero-shot
performance on several tasks. For example, with no additional task-specific
training we achieve BLEU scores of up to 35.8 for document translation. We
further show that fine-tuning gives strong performance on a range of
discriminative and generative tasks in many languages, making MARGE the most
generally applicable pre-training method to date.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:43:43 GMT""}]","2020-06-29"
"2006.15021","Nan Su","Hon Man Yau, Nan Su","On the generalizability of artificial neural networks in spin models","31 pages, 25 figures, 3 tables; v2 - published version","SciPost Phys. Core 5, 032 (2022)","10.21468/SciPostPhysCore.5.2.032",,"cond-mat.dis-nn cond-mat.stat-mech hep-lat hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The applicability of artificial neural networks (ANNs) is typically limited
to the models they are trained with and little is known about their
generalizability, which is a pressing issue in the practical application of
trained ANNs to unseen problems. Here, by using the task of identifying phase
transitions in spin models, we establish a systematic generalizability such
that simple ANNs trained with the two-dimensional ferromagnetic Ising model can
be applied to the ferromagnetic $q$-state Potts model in different dimensions
for $q \geq 2$. The same scheme can be applied to the highly nontrivial
antiferromagnetic $q$-state Potts model. We demonstrate that similar results
can be obtained by reducing the exponentially large state space spanned by the
training data to one that comprises only three representative configurations
artificially constructed through symmetry considerations. We expect our
findings to simplify and accelerate the development of machine
learning-assisted tasks in spin-model related disciplines in physics and
materials science.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:45:39 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 12:10:33 GMT""}]","2022-08-09"
"2006.15022","Asta Heinesen","Asta Heinesen","Cosmological homogeneity scale estimates are dressed","25 pages, 4 figures","JCAP 10 (2020) 052","10.1088/1475-7516/2020/10/052",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate number count statistics as measures for transition to
homogeneity of the matter distribution in the Universe and analyse how such
statistics might be `dressed' by the assumed survey selection function. Since
the estimated survey selection function -- which ideally accounts for selection
bias in the observed distribution -- is partially degenerate with the estimated
underlying distribution of galaxies, the ability to identify the correct survey
selection function is of importance for obtaining reliable estimates for
clustering statistics. Selection functions of existing galaxy catalogues are
modelled from data to resemble the redshift distribution and mean density of
the observed galaxies. Proposed estimates of the selection function for
upcoming surveys in addition use the angular distribution of galaxies to
generate the angular selection function instead of using angular completeness
estimates. We argue that such modelling of the selection function could
potentially underestimate the deviance from homogeneity at scales probed by
existing catalogues. We investigate the impact of conventionally applied
methods for estimation of the survey selection function on number count in
sphere statistics in a toy model setting. The example density distribution is
asymptotically homogeneous, while non-linear density fluctuations are present
regionally. We find that density oscillations with period comparable to
characteristic scales of the survey are suppressed when conventional estimates
of the survey selection function are invoked, resulting in number count
statistics that are biased towards homogeneity. For our concrete toy model with
maximum density contrasts of 1 and period of the density oscillation comparable
in size to the survey radius, we find that the homogeneity scale is
underestimated by ~40%, however this quantitative result is dependent on the
model setup.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:46:16 GMT""},{""version"":""v2"",""created"":""Mon, 2 Nov 2020 17:20:52 GMT""}]","2020-11-03"
"2006.15023","Sam Young","Sam Young and Adrian S. Hamers","The impact of distant fly-bys on the rate of binary primordial black
  hole mergers","26 pages, 7 figures. V2: Updated to match the published version",,"10.1088/1475-7516/2020/10/036",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By performing Monte Carlo simulations of the evolution of binary primordial
black hole (PBH) systems, we estimate the effect of distant encounters with
single PBHs upon the coalescence time and merger rate of binary PBHs. We find
that, for models where PBHs compose a large fraction of dark matter,
$f_\mathrm{PBH}\sim 1$, the expected fractional change in coalescence time is
negligible, of order $10^{-6}$ for most binaries. For models with significantly
lower PBH abundances, $f_\mathrm{PBH}\ll 1$, we find that the average change in
binary lifetime due to encounters can be as large as $\mathcal{O}(10^{-2})$,
with a small number of binaries experiencing an order unity change in lifetime.
In the absence of encounters, we also compare the use of an analytic
approximation for the coalescence time to numerically evolving the binary
system, finding that the analytic approximation results in an order $10\%$
error in the coalescence time. However, when these effects are taken into
consideration, there is a negligible change to the calculated merger rate,
placing previous constraints on the PBH abundance arising from observed
gravitational wave signals from merging binary black holes on a more secure
footing.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:46:35 GMT""},{""version"":""v2"",""created"":""Tue, 27 Oct 2020 13:05:34 GMT""}]","2020-10-28"
"2006.15024","Shahbaz Khan","Massimo Cairo, Shahbaz Khan, Romeo Rizzi, Sebastian Schmidt, Alexandru
  I. Tomescu and Elia Zirondelli","Computing all $s$-$t$ bridges and articulation points simplified","5 pages, 5 figures",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a directed graph $G$ and a pair of nodes $s$ and $t$, an $s$-$t$ bridge
of $G$ is an edge whose removal breaks all $s$-$t$ paths of $G$. Similarly, an
$s$-$t$ articulation point of $G$ is a node whose removal breaks all $s$-$t$
paths of $G$. Computing the sequence of all $s$-$t$ bridges of $G$ (as well as
the $s$-$t$ articulation points) is a basic graph problem, solvable in linear
time using the classical min-cut algorithm.
  When dealing with cuts of unit size ($s$-$t$ bridges) this algorithm can be
simplified to a single graph traversal from $s$ to $t$ avoiding an arbitrary
$s$-$t$ path, which is interrupted at the $s$-$t$ bridges. Further, the
corresponding proof is also simplified making it independent of the theory of
network flows.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:47:13 GMT""}]","2020-06-29"
"2006.15025","Carlo Spartaco Casari","Sonia Peggiani, Anna Facibeni, Alberto Milani, Chiara Castiglioni,
  Valeria Russo, Andrea Li Bassi, Carlo S. Casari","In situ synthesis of polyynes in a polymer matrix by pulsed laser
  ablation in liquid",,"RSC Materials Advances 1, 2729 (2020)","10.1039/d0ma00545b",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polyynes are finite chains formed by sp-hybridized carbon atoms with
alternating single and triple bonds and displaying intriguing electronic and
optical properties. Pulsed laser ablation in liquid (PLAL) is a well assessed
technique for the physical synthesis of hydrogen-capped polyynes in solution,
however, their limited stability prevents further exploitation in materials for
different applications. In this work, polyynes in poly(vinyl alcohol) (PVA)
were produced in a single-step PLAL process by ablating graphite directly in
aqueous solution of PVA, investigating the role of polymer concentration. The
presence of PVA solution, as a participating medium for PLAL, is shown to
favour the formation of polyynes. The addition of Ag colloids to the aqueous
PVA/polyynes solution allowed surface-enhanced Raman spectroscopy (SERS)
measurements, carried out both on liquid samples and on free-standing
nanocomposites, obtained after solvent evaporation. We show that polyynes in
the nanocomposite remain stable at least for 11 months, whereas the
corresponding PVA/Ag/polyynes solution displayed a strong polyyne reduction
already after 3 weeks. These results open the view to further characterizations
of the properties of polyyne-based films and materials.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:47:25 GMT""}]","2021-08-03"
"2006.15026","Pierre Fromholz","Tommaso Micallo, Vittorio Vitale, Marcello Dalmonte, and Pierre
  Fromholz","Topological entanglement properties of disconnected partitions in the
  Su-Schrieffer-Heeger model","20 pages, 9 figures. Submission to SciPost v2: -added a section
  elaborating on why $S^D$ is invariant after a quench, and a section why the
  conclusion of the paper extend to the whole BDI class. -added references -now
  25 pages, 11 figures","SciPost Phys. Core 3, 012 (2020)","10.21468/SciPostPhysCore.3.2.012",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the disconnected entanglement entropy, $S^D$, of the
Su-Schrieffer-Heeger model. $S^D$ is a combination of both connected and
disconnected bipartite entanglement entropies that removes all area and volume
law contributions, and is thus only sensitive to the non-local entanglement
stored within the ground state manifold. Using analytical and numerical
computations, we show that $S^D$ behaves as a topological invariant, i.e., it
is quantized to either $0$ or $2 \log (2)$ in the topologically trivial and
non-trivial phases, respectively. These results also hold in the presence of
symmetry-preserving disorder. At the second-order phase transition separating
the two phases, $S^D$ displays a system-size scaling behavior akin to those of
conventional order parameters, that allows us to compute entanglement critical
exponents. To corroborate the topological origin of the quantized values of
$S^D$, we show how the latter remain quantized after applying unitary time
evolution in the form of a quantum quench, a characteristic feature of
topological invariants.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:47:51 GMT""},{""version"":""v2"",""created"":""Fri, 30 Oct 2020 17:32:13 GMT""}]","2021-01-18"
"2006.15027","Tim Uhlemann","Tim Uhlemann, Sebastian Cammerer, Alexander Span, Sebastian D\""orner
  and Stephan ten Brink","Deep-learning Autoencoder for Coherent and Nonlinear Optical
  Communication","Accepted (21.02.2020) for presentation at the 21st IEEE/ITG-Symposium
  on Photonic Networks, Leipzig, Germany, 13-14.05.2020",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the recent success of end-to-end training of communications in
the wireless domain, we strive to adapt the end-to-end-learning idea from the
wireless case (i.e., linear) to coherent optical fiber links (i.e., nonlinear).
Although, at first glance, it sounds like a straightforward extension, it turns
out that several pitfalls exist - in terms of theory but also in terms of
practical implementation. This paper analyzes the potential of an autoencoder
and limitations for the optical fiber under the influence of Kerr-nonlinearity
and chromatic dispersion. As there is no exact capacity limit known and, hence,
no analytical perfect system solution available, we set great value to the
interpretability on the learnings of the autoencoder. Therefore, we design its
architecture to be as close as possible to the structure of a classic
communication system, knowing that this may limit its degree of freedom and,
thus, its performance. Nevertheless, we were able to achieve an unexpected high
gain in terms of spectral efficiency compared to a conventional reference
system.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:50:01 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 06:00:23 GMT""}]","2020-06-30"
"2006.15028","Tom\'as M\""uller Mr.","Tom\'as E. M\""uller-Bravo, Claudia P. Guti\'errez, Mark Sullivan,
  Anders Jerkstrand, Joseph P. Anderson, Santiago Gonz\'alez-Gait\'an, Jesper
  Sollerman, Iair Arcavi, Jamison Burke, Llu\'is Galbany, Avishay Gal-Yam,
  Mariusz Gromadzki, Daichi Hiramatsu, Griffin Hosseinzadeh, D. Andrew Howell,
  Cosimo Inserra, Erki Kankare, Alexandra Kozyreva, Curtis McCully, Matt
  Nicholl, Stephen Smartt, Stefano Valenti and Dave R. Young","The low-luminosity type II SN\,2016aqf: A well-monitored spectral
  evolution of the Ni/Fe abundance ratio","Accepted for publication in MNRAS",,"10.1093/mnras/staa1932",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-luminosity type II supernovae (LL SNe~II) make up the low explosion
energy end of core-collapse SNe, but their study and physical understanding
remain limited. We present SN\,2016aqf, a LL SN~II with extensive spectral and
photometric coverage. We measure a $V$-band peak magnitude of $-14.58$\,mag, a
plateau duration of $\sim$100\,days, and an inferred $^{56}$Ni mass of $0.008
\pm 0.002$\,\msun. The peak bolometric luminosity, L$_{\rm bol} \approx
10^{41.4}$\,erg\,s$^{-1}$, and its spectral evolution is typical of other SNe
in the class. Using our late-time spectra, we measure the [\ion{O}{i}]
$\lambda\lambda6300, 6364$ lines, which we compare against SN II spectral
synthesis models to constrain the progenitor zero-age main-sequence mass. We
find this to be 12 $\pm$ 3\,\msun. Our extensive late-time spectral coverage of
the [\ion{Fe}{ii}] $\lambda7155$ and [\ion{Ni}{ii}] $\lambda7378$ lines permits
a measurement of the Ni/Fe abundance ratio, a parameter sensitive to the inner
progenitor structure and explosion mechanism dynamics. We measure a constant
abundance ratio evolution of $0.081^{+0.009}_{-0.010}$, and argue that the best
epochs to measure the ratio are at $\sim$200 -- 300\,days after explosion. We
place this measurement in the context of a large sample of SNe II and compare
against various physical, light-curve and spectral parameters, in search of
trends which might allow indirect ways of constraining this ratio. We do not
find correlations predicted by theoretical models; however, this may be the
result of the exact choice of parameters and explosion mechanism in the models,
the simplicity of them and/or primordial contamination in the measured
abundance ratio.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:52:10 GMT""}]","2020-07-15"
"2006.15029","Jonathan Doye","Hemani Chhabra, Garima Mishra, Yijing Cao, Domen Pre\v{s}ern, Enrico
  Skoruppa, Maxime M. C. Tortora and Jonathan P. K. Doye","Computing the elastic mechanical properties of rod-like DNA
  nanostructures",,"J. Chem. Theory Comput. 16, 7748-7763 (2020)","10.1021/acs.jctc.0c00661",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To study the elastic properties of rod-like DNA nanostructures, we perform
long simulations of these structure using the oxDNA coarse-grained model. By
analysing the fluctuations in these trajectories we obtain estimates of the
bend and twist persistence lengths, and the underlying bend and twist elastic
moduli and couplings between them. Only on length scales beyond those
associated with the spacings between the interhelix crossovers do the bending
fluctuations behave like those of a worm-like chain. The obtained bending
persistence lengths are much larger than that for double-stranded DNA and
increase non-linearly with the number of helices, whereas the twist moduli
increase approximately linearly. To within the numerical error in our data, the
twist-bend coupling constants are of order zero. That the bending persistence
lengths we obtain are generally somewhat higher than in experiment probably
reflects both that the simulated origami have no assembly defects and that the
oxDNA extensional modulus for double-stranded DNA is too large.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:53:47 GMT""}]","2021-03-10"
"2006.15030","Yue Wu","Yue Wu and Terry J. Lyons and Kate E.A. Saunders","Deriving information from missing data: implications for mood prediction",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The availability of mobile technologies has enabled the efficient collection
prospective longitudinal, ecologically valid self-reported mood data from
psychiatric patients. These data streams have potential for improving the
efficiency and accuracy of psychiatric diagnosis as well predicting future mood
states enabling earlier intervention. However, missing responses are common in
such datasets and there is little consensus as to how this should be dealt with
in practice. A signature-based method was used to capture different elements of
self-reported mood alongside missing data to both classify diagnostic group and
predict future mood in patients with bipolar disorder, borderline personality
disorder and healthy controls. The missing-response-incorporated
signature-based method achieves roughly 66\% correct diagnosis, with f1 scores
for three different clinic groups 59\% (bipolar disorder), 75\% (healthy
control) and 61\% (borderline personality disorder) respectively. This was
significantly more efficient than the naive model which excluded missing data.
Accuracies of predicting subsequent mood states and scores were also improved
by inclusion of missing responses. The signature method provided an effective
approach to the analysis of prospectively collected mood data where missing
data was common and should be considered as an approach in other similar
datasets.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:57:03 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jul 2020 10:25:46 GMT""},{""version"":""v3"",""created"":""Wed, 8 Jul 2020 11:33:40 GMT""}]","2020-07-09"
"2006.15031","Stephan Garbin Mr","Stephan J. Garbin, Marek Kowalski, Matthew Johnson, and Jamie Shotton","High Resolution Zero-Shot Domain Adaptation of Synthetically Rendered
  Face Images",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generating photorealistic images of human faces at scale remains a
prohibitively difficult task using computer graphics approaches. This is
because these require the simulation of light to be photorealistic, which in
turn requires physically accurate modelling of geometry, materials, and light
sources, for both the head and the surrounding scene. Non-photorealistic
renders however are increasingly easy to produce. In contrast to computer
graphics approaches, generative models learned from more readily available 2D
image data have been shown to produce samples of human faces that are hard to
distinguish from real data. The process of learning usually corresponds to a
loss of control over the shape and appearance of the generated images. For
instance, even simple disentangling tasks such as modifying the hair
independently of the face, which is trivial to accomplish in a computer
graphics approach, remains an open research question. In this work, we propose
an algorithm that matches a non-photorealistic, synthetically generated image
to a latent vector of a pretrained StyleGAN2 model which, in turn, maps the
vector to a photorealistic image of a person of the same pose, expression,
hair, and lighting. In contrast to most previous work, we require no synthetic
training data. To the best of our knowledge, this is the first algorithm of its
kind to work at a resolution of 1K and represents a significant leap forward in
visual realism.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:00:04 GMT""}]","2020-06-29"
"2006.15032","Ghislain Haine","Ghislain Haine and Denis Matignon and Anass Serhani","Numerical analysis of a structure-preserving space-discretization for an
  anisotropic and heterogeneous boundary controlled N-dimensional wave equation
  as port-Hamiltonian system","36 pages, 12 figure, submitted",,,,"math.NA cs.NA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The anisotropic and heterogeneous $N$-dimensional wave equation, controlled
and observed at the boundary, is considered as a port-Hamiltonian system. A
recent structure-preserving mixed Galerkin method is applied, leading directly
to a finite-dimensional port-Hamiltonian system: its numerical analysis is
carried out in a general framework. Optimal choices of mixed finite elements
are then proved to reach the best trade-off between the convergence rate and
the number of degrees of freedom for the state error. Exta compatibility
conditions are identified for the Hamiltonian error to be twice that of the
state error, and numerical evidence is provided that some combinations of
finite element families meet these conditions. Numerical simulations in 2D are
performed to illustrate the main theorems among several choices of classical
finite element families. Several test cases are provided, including non-convex
domain, anisotropic or hetergoneous cases and absorbing boundary conditions.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:00:56 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 07:32:53 GMT""},{""version"":""v3"",""created"":""Sat, 26 Feb 2022 00:11:55 GMT""},{""version"":""v4"",""created"":""Tue, 31 May 2022 14:20:25 GMT""}]","2022-06-01"
"2006.15033","Alberto Enciso","Alberto Enciso, Daniel Peralta-Salas, \'Alvaro Romaniega","Beltrami fields exhibit knots and chaos almost surely","45 pages",,,,"math.SP math.AP math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we show that, with probability 1, a random Beltrami field
exhibits chaotic regions that coexist with invariant tori of complicated
topologies. The motivation to consider this question, which arises in the study
of stationary Euler flows in dimension 3, is V.I. Arnold's 1965 conjecture that
a typical Beltrami field exhibits the same complexity as the restriction to an
energy hypersurface of a generic Hamiltonian system with two degrees of
freedom. The proof hinges on the obtention of asymptotic bounds for the number
of horseshoes, zeros, and knotted invariant tori and periodic trajectories that
a Gaussian random Beltrami field exhibits, which we obtain through a nontrivial
extension of the Nazarov--Sodin theory for Gaussian random monochromatic waves
and the application of different tools from the theory of dynamical systems,
including KAM theory, Melnikov analysis and hyperbolicity. Our results hold
both in the case of Beltrami fields on $\mathbf{R}^3$ and of high-frequency
Beltrami fields on the 3-torus.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:01:25 GMT""}]","2020-06-29"
"2006.15034","Hasan Javed Khan","Hasan J. Khan, Ayaz Mehmani, Ma\v{s}a Prodanovi\'c, David DiCarlo, and
  Dayeed J. Khan","Capillary rise in vuggy media","22 pages, data available at
  https://www.digitalrocksportal.org/projects/287",,"10.1016/j.advwatres.2020.103671",,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Carbonates are highly heterogeneous formations with large variations in pore
size distribution and pore space topology, which results in complex multiphase
flow behavior. Here we investigate the spontaneous imbibition behavior of
fluids in vuggy carbonates. Glass beads of 1.0 mm diameter, with dissolvable
inclusions, are sintered to form multiple configurations of heterogeneous vuggy
core with variations in matrix porosity, vug size, vug spatial location, and
number of vugs. The core fabrication process is repeatable and allows the
impact of vug textural properties to be investigated in a controlled manner.
  Capillary rise experiments are conducted in these proxy vuggy carbonate core
and compared with the homogeneous non-vuggy core as reference. Continuous
optical imaging is performed to track the position of the air-water interface
in the cores. To understand the change in capillary height in the presence of a
vug, a volume-of-fluid two-phase numerical simulation is performed in a
parallel set of connected and disconnected tubes. Finally x-ray tomography
scans are performed to identify the shape of the air-water interface in a
select few cores.
  The results can be summarized as follows: disconnected vugs result in higher
capillary rise compared to non-vuggy porous media. The vugs act as capillary
barriers, diverting fluid flow to the adjacent connected channels, which
ultimately results in a higher overall capillary rise.
  The results of this work highlight that radius of spontaneous invasion of
aqueous phases, such as fracture fluid and hazardous wastes, are affected by
vug porosity but not their distribution.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:03:38 GMT""}]","2020-06-30"
"2006.15035","Rahul Singh","Rahul Singh, Isabel Haasler, Qinsheng Zhang, Johan Karlsson, Yongxin
  Chen","Incremental inference of collective graphical models",,,,,"stat.ML cs.IT cs.LG cs.SY eess.SY math.IT math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider incremental inference problems from aggregate data for collective
dynamics. In particular, we address the problem of estimating the aggregate
marginals of a Markov chain from noisy aggregate observations in an incremental
(online) fashion. We propose a sliding window Sinkhorn belief propagation
(SW-SBP) algorithm that utilizes a sliding window filter of the most recent
noisy aggregate observations along with encoded information from discarded
observations. Our algorithm is built upon the recently proposed multi-marginal
optimal transport based SBP algorithm that leverages standard belief
propagation and Sinkhorn algorithm to solve inference problems from aggregate
data. We demonstrate the performance of our algorithm on applications such as
inferring population flow from aggregate observations.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:04:31 GMT""}]","2020-06-29"
"2006.15036","Norman Danner","Joseph W. Cutler, Daniel R. Licata, Norman Danner","Denotational recurrence extraction for amortized analysis","To appear in ICFP 2020; formatting changes","Proc. ACM Program. Lang. 4, ICFP, Article 97 (August 2020)","10.1145/3408979",,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  A typical way of analyzing the time complexity of functional programs is to
extract a recurrence expressing the running time of the program in terms of the
size of its input, and then to solve the recurrence to obtain a big-O bound.
For recurrence extraction to be compositional, it is also necessary to extract
recurrences for the size of outputs of helper functions. Previous work has
developed techniques for using logical relations to state a formal correctness
theorem for a general recurrence extraction translation: a program is bounded
by a recurrence when the operational cost is bounded by the extracted cost, and
the output value is bounded, according to a value bounding relation defined by
induction on types, by the extracted size. This previous work supports
higher-order functions by viewing recurrences as programs in a lambda-calculus,
or as mathematical entities in a denotational semantics thereof. In this paper,
we extend these techniques to support amortized analysis, where costs are
rearranged from one portion of a program to another to achieve more precise
bounds. We give an intermediate language in which programs can be annotated
according to the banker's method of amortized analysis; this language has an
affine type system to ensure credits are not spent more than once. We give a
recurrence extraction translation of this language into a recurrence language,
a simply-typed lambda-calculus with a cost type, and state and prove a bounding
logical relation expressing the correctness of this translation. The recurrence
language has a denotational semantics in preorders, and we use this semantics
to solve recurrences, e.g analyzing binary counters and splay trees.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:05:57 GMT""},{""version"":""v2"",""created"":""Fri, 31 Jul 2020 14:34:17 GMT""}]","2020-08-03"
"2006.15037","Emanuele Dalsasso","Emanuele Dalsasso, Lo\""ic Denis, Florence Tupin","SAR2SAR: a semi-supervised despeckling algorithm for SAR images","The manuscript is the accepted version of IEEE STARS. Code is made
  available at https://gitlab.telecom-paris.fr/RING/SAR2SAR","IEEE Journal of Selected Topics in Applied Earth Observations and
  Remote Sensing (Early Access), 2020","10.1109/JSTARS.2021.3071864",,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Speckle reduction is a key step in many remote sensing applications. By
strongly affecting synthetic aperture radar (SAR) images, it makes them
difficult to analyse. Due to the difficulty to model the spatial correlation of
speckle, a deep learning algorithm with self-supervision is proposed in this
paper: SAR2SAR. Multi-temporal time series are leveraged and the neural network
learns to restore SAR images by only looking at noisy acquisitions. To this
purpose, the recently proposed noise2noise framework has been employed. The
strategy to adapt it to SAR despeckling is presented, based on a compensation
of temporal changes and a loss function adapted to the statistics of speckle.
  A study with synthetic speckle noise is presented to compare the performances
of the proposed method with other state-of-the-art filters. Then, results on
real images are discussed, to show the potential of the proposed algorithm. The
code is made available to allow testing and reproducible research in this
field.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:07:28 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jul 2020 07:06:50 GMT""},{""version"":""v3"",""created"":""Tue, 13 Apr 2021 09:41:33 GMT""}]","2021-04-14"
"2006.15038","Joby P. Kochappan","Joby P. Kochappan, Aparajita Sen, Tuhin Ghosh, Pravabati Chingangbam,
  Soumen Basak","Statistical Isotropy of the CMB E-mode signal","19 pages, 7 figures",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We test the statistical isotropy (SI) of the $E$-mode polarization of the
cosmic microwave background (CMB) radiation observed by the Planck satellite
using two statistics, namely, the contour Minkowski Tensor (CMT) and the
Directional statistic ($\mathcal{D}$ statistic). The parameter $\alpha$
obtained from the CMT provides information of the alignment of structures and
can be used to infer statistical properties such as Gaussianity and SI of
random fields. The $\mathcal{D}$ statistic is based on detecting preferred
directionality shown by vectors defined by the field. These two tests are
complementary to each other in terms of sensitivity at different angular
scales. The CMT is sensitive towards small-scale information present in the CMB
map while $\mathcal{D}$ statistic is more sensitive at large-scales. We compute
$\alpha$ and $\mathcal{D}$ statistic for the observed $E$-mode of CMB
polarization, focusing on the SMICA maps, and compare with the values
calculated using FFP10 SMICA simulations which contain both CMB and noise. We
find good agreement between the observed data and simulations. Further, in
order to specifically analyze the CMB signal in the data, we compare the values
of the two statistics obtained from the observed Planck data with the values
obtained from isotropic simulations having the same power spectrum, and from
SMICA noise simulations. We find no statistically significant deviation from SI
using the $\alpha$ parameter. From $\mathcal{D}$ statistic we find that the
data shows slight deviation from SI at large angular scales.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:10:43 GMT""}]","2020-06-29"
"2006.15039","Petar Danev","P. Danev, D. Bakalov, V.I. Korobov, S. Schiller","Hyperfine structure and electric quadrupole transitions in the deuterium
  molecular ion","19 pages, 4 figures. Comparison with the available experimental data
  about the hyperfine structure of D2+ has been added in Section IIC; A new
  Section IIID has been added with a thorough analysis of the determination of
  the electric quadrupole moment of the deuteron from D2+ spectroscopy; A new
  Section IIIE has been added discussing further applications of the composite
  frequency method","Phys. Rev. A 103, 012805 (2021)","10.1103/PhysRevA.103.012805",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Molecular hydrogen ions are of metrological relevance due to the possibility
of precise theoretical evaluation of their spectrum and of
external-field-induced shifts. In homonuclear molecular ions the electric
dipole $E1$ transitions are strongly suppressed, and of primary laser
spectroscopy interest is the electric quadrupole ($E2$) transition spectrum. In
continuation of previous work on the H$_2^+$ ion, we report here the results of
the calculations of the hyperfine structure of the laser-induced electric
quadrupole transitions between a large set of ro-vibrational states of D$_2^+$;
the inaccuracies of previous evaluations have been corrected. The effects of
the laser polarization are studied in detail. We show that the electric
quadrupole moment of the deuteron can in principle be determined with low
fractional uncertainty $(\simeq1\times10^{-4})$ by comparing the results
presented here with future data from precision spectroscopy of D$_2^+$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:14:33 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 12:58:38 GMT""}]","2021-01-20"
"2006.15040","Julien Barrier","Julien Barrier, Piranavan Kumaravadivel, Roshan Krishna-Kumar, L.A.
  Ponomarenko, Na Xin, Matthew Holwill, Ciaran Mullan, Minsoo Kim, R.V.
  Gorbachev, M.D. Thompson, J. R. Prance, T. Taniguchi, K. Watanabe, I.V.
  Grigorieva, K.S. Novoselov, A. Mishchenko, V.I. Fal'ko, A. K. Geim and A.I.
  Berdyugin","Long-range ballistic transport of Brown-Zak fermions in graphene
  superlattices","16 pages, 13 figures","Nat Commun 11, 5756 (2020)","10.1038/s41467-020-19604-0",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-sa/4.0/","  In quantizing magnetic fields, graphene superlattices exhibit a complex
fractal spectrum often referred to as the Hofstadter butterfly. It can be
viewed as a collection of Landau levels that arise from quantization of
Brown-Zak minibands recurring at rational ($p/q$) fractions of the magnetic
flux quantum per superlattice unit cell. Here we show that, in
graphene-on-boron-nitride superlattices, Brown-Zak fermions can exhibit
mobilities above 10$^6$ cm$^2$V$^{-1}$s$^{-1}$ and the mean free path exceeding
several micrometers. The exceptional quality of our devices allows us to show
that Brown-Zak minibands are $4q$ times degenerate and all the degeneracies
(spin, valley and mini-valley) can be lifted by exchange interactions below 1K.
We also found negative bend resistance at $1/q$ fractions for electrical probes
placed as far as several micrometers apart. The latter observation highlights
the fact that Brown-Zak fermions are Bloch quasiparticles propagating in high
fields along straight trajectories, just like electrons in zero field.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:15:10 GMT""},{""version"":""v2"",""created"":""Tue, 6 Oct 2020 10:24:11 GMT""}]","2020-11-16"
"2006.15041","Matthew Scourfield","M. Scourfield, S. Viti, S. Garcia-Burillo, A. Saintonge, F. Combes, A.
  Fuente, C. Henkel, A. Alonso-Herrero, N. Harada, S. Takano, T. Nakajima, S.
  Martin, M. Krips, P. P. van der Werf, S. Aalto, A. Usero, K. Kohno","ALMA observations of CS in NGC 1068: chemistry and excitation","32 pages, 19 figures, 6 tables, accepted for publication in MNRAS",,"10.1093/mnras/staa1891",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present results from Atacama Large Millimeter/submillimeter Array (ALMA)
observations of CS from the nearby galaxy NGC 1068 ($\sim14$ Mpc). This Seyfert
2 barred galaxy possesses a circumnuclear disc (CND, $r\sim200$ pc) and a
starburst ring (SB ring, $r\sim1.3$ kpc). These high-resolution maps
($\sim0.5$"", $\sim35$ pc) allow us to analyse specific sub-regions in the
galaxy and investigate differences in line intensity ratios and physical
conditions, particularly those between the CND and SB ring. Local thermodynamic
equilibrium (LTE) analysis of the gas is used to calculate CS densities in each
sub-region, followed by non-LTE analysis conducted using the radiative transfer
code RADEX to fit observations and constrain gas temperature, CS column density
and hydrogen density. Finally, the chemical code UCLCHEM is used to reconstruct
the gas, allowing an insight into its origin and chemical history. The density
of hydrogen in the CND is found to be $\geq10^5$ cm$^{-2}$, although exact
values vary, reaching $10^6$ cm$^{-2}$ at the AGN. The conditions in the two
arms of the SB ring appear similar to one another, though the density found
($\sim10^4$ cm$^{-2}$) is lower than in the CND. The temperature in the CND
increases from east to west, and is also overall greater than found in the SB
ring. These modelling methods indicate the requirement for multi-phase gas
components in order to fit the observed emission over the galaxy. A larger
number of high resolution transitions across the SLED may allow for further
constraining of the conditions, particularly in the SB ring.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:15:53 GMT""}]","2020-06-30"
"2006.15042","Alexander Barron","Alex Barron, Michael Christ, Benoit Pausader","Global endpoint Strichartz estimates for Schr\""odinger equations on the
  cylinder $\mathbb{R}\times\mathbb{T}$",,,,,"math.AP math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a sharp, global-in-time Strichartz estimate for the Schr\""odinger
equation on the cylinder $\mathbb{R}\times\mathbb{T}$.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:19:07 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 22:09:16 GMT""}]","2021-02-03"
"2006.15043","Guillaume Ausset","Guillaume Ausset, Stephan Cl\'emen\c{c}on, Fran\c{c}ois Portier","Nearest Neighbour Based Estimates of Gradients: Sharp Nonasymptotic
  Bounds and Applications",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by a wide variety of applications, ranging from stochastic
optimization to dimension reduction through variable selection, the problem of
estimating gradients accurately is of crucial importance in statistics and
learning theory. We consider here the classic regression setup, where a real
valued square integrable r.v. $Y$ is to be predicted upon observing a (possibly
high dimensional) random vector $X$ by means of a predictive function $f(X)$ as
accurately as possible in the mean-squared sense and study a
nearest-neighbour-based pointwise estimate of the gradient of the optimal
predictive function, the regression function $m(x)=\mathbb{E}[Y\mid X=x]$.
Under classic smoothness conditions combined with the assumption that the tails
of $Y-m(X)$ are sub-Gaussian, we prove nonasymptotic bounds improving upon
those obtained for alternative estimation methods. Beyond the novel theoretical
results established, several illustrative numerical experiments have been
carried out. The latter provide strong empirical evidence that the estimation
method proposed works very well for various statistical problems involving
gradient estimation, namely dimensionality reduction, stochastic gradient
descent optimization and quantifying disentanglement.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:19:43 GMT""}]","2020-06-29"
"2006.15044","Alessandro Pilloni","Angelo Esposito, Elena G. Ferreiro, Alessandro Pilloni, Antonio D.
  Polosa, Carlos A. Salgado","The nature of $X(3872)$ from high-multiplicity $pp$ collisions","11 pages, 6 figures. Presentation updated, references added,
  conclusions unchanged. Version accepted in EPJC","Eur. Phys. J. C 81, 669 (2021)","10.1140/epjc/s10052-021-09425-w",,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The structure of exotic resonances that do not trivially fit the usual quark
model expectations has been a matter of intense scientific debate during the
last two decades. A possible way of estimating the size of these states is to
study their behavior when immersed in QCD matter. Recently, LHCb has measured
the relative abundance of the exotic $X(3872)$ over the ordinary $\psi(2S)$. We
use the comover interaction model to study the yield of a compact $X(3872)$. To
confirm the reliability of the model in high-multiplicity $pp$ collisions, we
describe the suppression of excited over ground $\Upsilon$ states. With this at
hand, we show that the size of the compact $X(3872)$ would be slightly larger
than that of the $\psi(2S)$. If the $X(3872)$ is instead assumed to be a meson
molecule of large size, we argue that its evolution in QCD matter should be
described via a coalescence model, as suggested by data on deuteron production.
We show that the predictions of this model for the $X(3872)$ are in contrast
with data.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:21:27 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 13:08:04 GMT""}]","2021-08-02"
"2006.15045","Ryan Ridden-Harper","R. Ridden-Harper, B. E. Tucker, M. Gully-Santiago, G. Barentsen, A.
  Rest, P. Garnavich, E. Shaya","K2: Background Survey -- the search for undiscovered transients in
  Kepler/K2 data","13 pages, 10 figures, 4 tables",,"10.1093/mnras/staa2247",,"astro-ph.IM astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The K2 mission of the Kepler Space Telescope offers a unique possibility to
examine sources of both Galactic and Extra-galactic origin with high cadence
photometry. Alongside the multitude of supernovae and quasars detected within
targeted galaxies, it is likely that Kepler has serendipitously observed many
transients throughout K2. Such events will likely have occurred in background
pixels, coincidentally surrounding science targets. Analysing the background
pixels presents the possibility to conduct a high cadence survey with areas of
a few square degrees per campaign. We demonstrate the capacity to independently
recover key K2 transients such as KSN 2015K and SN 2018oh. With this survey, we
expect to detect numerous transients and determine the first comprehensive
rates for transients with lifetimes $\leq1$ day.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:24:52 GMT""}]","2020-08-12"
"2006.15046","Masahiro Yamamoto","Masahiro Yamamoto","Uniqueness in determining the orders of time and spatial fractional
  derivatives",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the uniqueness in determining both orders of fractional time
derivatives and spatial derivatives in diffusion equations by pointwise data.
The proof relies on the eigenfunction expansion and the asymptotics of the
Mittag-Leffler function.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:25:32 GMT""}]","2020-06-29"
"2006.15047","Vaibhav Tiwari","Vaibhav Tiwari","VAMANA: Modeling Binary Black Hole Population with Minimal Assumptions",,,"10.1088/1361-6382/ac0b54",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The population analysis of compact binaries involves the reconstruction of
some of the gravitational wave (GW) signal parameters, such as, the mass and
the spin distribution, that gave rise to the observed data. This article
introduces VAMANA, which reconstructs the binary black hole population using a
mixture model and facilitates excellent density measurement as informed by the
data. VAMANA uses a mixture of weighted Gaussians to reconstruct the chirp mass
distribution. We expect Gaussian mixtures to provide flexibility in modeling
complex distributions and enable us in capturing details in the astrophysical
chirp mass distribution. Each of the Gaussian in the mixture is combined with
another Gaussian and a power-law to simultaneously model the spin component
aligned with the orbital angular momentum and the mass ratio distribution, thus
also allowing us to capture their variation with the chirp mass. Additionally,
we can also introduce broadband smoothing by restricting the Gaussian mixture
to lie within a threshold distance of a predefined reference chirp mass
distribution. Using simulated data we show the robustness of our method in
reconstructing complex populations for a large number of observations. We also
apply our method to the publicly available catalog of GW observations made
during LIGO's and Virgo's first and second observation runs and present the
reconstructed mass, spin distribution, and the estimated merger rate of binary
black holes.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:25:40 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 05:18:13 GMT""},{""version"":""v3"",""created"":""Wed, 16 Jun 2021 04:31:16 GMT""}]","2021-06-17"
"2006.15048","Mohammed Mou\c{c}ouf","Mohammed Moucouf","Arbitrary positive powers of semicirculant and r-circulant matrices","16 pages; typos corrected",,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  We provide a novel recursive method, which does not require any assumption,
to compute the entries of the kth power of a semicirculant matrix. As an
application, a method for computing the entries of the kth power of r-circulant
matrices is also presented.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:26:04 GMT""},{""version"":""v2"",""created"":""Tue, 4 Aug 2020 12:44:29 GMT""}]","2020-08-05"
"2006.15049","Ping Zhou","Ping Zhou, Shing-Chi Leung, Zhiyuan Li, Ken'ichi Nomoto, Jacco Vink,
  and Yang Chen","Chemical abundances in Sgr A East: evidence for a Type Iax supernova
  remnant","17 pages, 7 figures, 2 tables; accepted for publication in the
  Astrophysical Journal",,"10.3847/1538-4357/abbd45",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent observations have shown a remarkable diversity of observational
behaviors and explosion mechanisms in thermonuclear supernovae (SNe). An
emerging class of peculiar thermonuclear SNe, called Type Iax, show photometric
and spectroscopic behaviors distinct from normal Type Ia. Their origin remains
highly controversial, but pure turbulent deflagration of white dwarfs (WDs) has
been regarded as the leading formation theory. The large population of Type Iax
indicates the existence of unidentified Galactic Type Iax supernova remnants
(SNRs). We report evidence that SNR Sgr A East in the Galactic center resulted
from a pure turbulent deflagration of a Chandrasekhar-mass carbon-oxygen WD, an
explosion mechanism used for Type Iax SNe. Our X-ray spectroscopic study of Sgr
A East using 3 Ms of Chandra data shows a low ratio of intermediate-mass
elements to Fe and large Mn/Fe and Ni/Fe ratios. This abundance pattern does
not accord with the core-collapse or normal Type Ia models. Sgr A East is thus
the first Galactic SNR for which a likely Type Iax origin has been proposed and
the nearest target for studying this peculiar class. We compared Sgr A East
with the Fe-rich SNRs 3C 397 and W49B, which also have high Mn and Cr
abundances and were claimed to result from deflagration-to-detonation
explosions of Chandrasekhar-mass WDs (although with disputes). Our study shows
that they have distinct abundance patterns. The X-ray spectroscopic studies of
thermonuclear SNRs provide observational evidence for the theories that there
are diverse explosion channels and various metal outputs for Chandrasekhar-mass
WDs.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:26:09 GMT""},{""version"":""v2"",""created"":""Tue, 24 Nov 2020 15:03:34 GMT""}]","2021-02-17"
"2006.15050","Alexander Pitchford PhD","Alexander Pitchford, Andrey A. Rakhubovsky, Rick Mukherjee, Darren W.
  Moore, Fr\'ed\'eric Sauvage, Daniel Burgarth, Radim Filip, and Florian
  Mintert","Optimal non-classical correlations of light with a levitated nano-sphere","21 pages, 9 figures, including the 2 appendices and bibliography",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonclassical correlations provide a resource for many applications in quantum
technology as well as providing strong evidence that a system is indeed
operating in the quantum regime. Optomechanical systems can be arranged to
generate quantum entanglement between the mechanics and a mode of travelling
light. Here we propose automated optimisation of the production of quantum
correlations in such a system, beyond what can be achieved through analytical
methods, by applying Bayesian optimisation to the control parameters. Two-mode
optomechanical squeezing experiment is simulated using a detailed theoretical
model of the system, while the Bayesian optimisation process modifies the
controllable parameters in order to maximise the non-classical two-mode
squeezing and its detection, independently of the inner workings of the model.
The Bayesian optimisation treats the simulations or the experiments as a black
box. This we refer to as \emph{theory-blind} optimisation, and the optimisation
process is designed to be unaware of whether it is working with a simulation or
the actual experimental setup. We find that in the experimentally relevant
thermal regimes, the ability to vary and optimise a broad array of control
parameters provides access to large values of two-mode squeezing that would
otherwise be difficult or intractable to discover. In particular we observe
that modulation of the driving frequency around the resonant sideband, when
added to the set of control parameters, produces strong nonclassical
correlations greater on average than the maximum achieved by optimising over
the remaining parameters. We also find that using our optimisation approach
raises the upper limit to the thermal regime in which squeezing can be
achieved. This extends the range of experimental setups in which non-classical
correlations could be generated beyond the region of high quantum
cooperativity.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:27:47 GMT""},{""version"":""v2"",""created"":""Fri, 2 Oct 2020 17:21:01 GMT""}]","2020-10-05"
"2006.15051","Peter Williams","Peter H. Williams, Gustavo P\'erez-Segurana, Ian R. Bailey, Sara
  Thorin, Bill Kyle, Jonas Bj\""orklund Svensson","Arc-Like Variable Bunch Compressors","9 pages","Phys. Rev. Accel. Beams 23, 100701 (2020)","10.1103/PhysRevAccelBeams.23.100701",,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electron bunch compressors formed of achromat arcs have a natural advantage
over the more commonly used chicane compressors in that linearisation of the
longitudinal phase space is of the correct sign to compensate for the curvature
imprinted by rf acceleration. Here we extend the utility of arc compressors to
enable variation of the longitudinal compaction within a fixed footprint. We
also show that this variability can be achieved independently order-by-order in
momentum deviation. The technique we employ consists of additional dipoles,
leading to the advantageous property that variability can be achieved without
incurring significant penalty in terms of chromatic degradation. We show this
by comparison to an alternative system where additional quadrupoles are
utilised to enable variation of momentum compaction. Each of these alternative
approaches are being considered in the context of an upgrade of the MAX IV
linac, Sweden, to enable a soft X-ray free-electron laser (FEL) in addition to
its existing functions.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:30:50 GMT""},{""version"":""v2"",""created"":""Thu, 3 Sep 2020 08:38:58 GMT""}]","2020-10-21"
"2006.15052","Leigh Whitehead","DUNE Collaboration: B. Abi, R. Acciarri, M. A. Acero, G. Adamov, D.
  Adams, M. Adinolfi, Z. Ahmad, J. Ahmed, T. Alion, S. Alonso Monsalve, C. Alt,
  J. Anderson, C. Andreopoulos, M. P. Andrews, F. Andrianala, S. Andringa, A.
  Ankowski, M. Antonova, S. Antusch, A. Aranda-Fernandez, A. Ariga, L. O.
  Arnold, M. A. Arroyave, J. Asaadi, A. Aurisano, V. Aushev, D. Autiero, F.
  Azfar, H. Back, J. J. Back, C. Backhouse, P. Baesso, L. Bagby, R. Bajou, S.
  Balasubramanian, P. Baldi, B. Bambah, F. Barao, G. Barenboim, G. J. Barker,
  W. Barkhouse, C. Barnes, G. Barr, J. Barranco Monarca, N. Barros, J. L.
  Barrow, A. Bashyal, V. Basque, F. Bay, J. L. Bazo Alba, J. F. Beacom, E.
  Bechetoille, B. Behera, L. Bellantoni, G. Bellettini, V. Bellini, O.
  Beltramello, D. Belver, N. Benekos, F. Bento Neves, J. Berger, S. Berkman, P.
  Bernardini, R. M. Berner, H. Berns, S. Bertolucci, M. Betancourt, Y.
  Bezawada, M. Bhattacharjee, B. Bhuyan, S. Biagi, J. Bian, M. Biassoni, K.
  Biery, B. Bilki, M. Bishai, A. Bitadze, A. Blake, B. Blanco Siffert, F. D. M.
  Blaszczyk, G. C. Blazey, E. Blucher, J. Boissevain, S. Bolognesi, T. Bolton,
  M. Bonesini, M. Bongrand, F. Bonini, A. Booth, C. Booth, S. Bordoni, A.
  Borkum, T. Boschi, N. Bostan, P. Bour, S. B. Boyd, D. Boyden, J. Bracinik, D.
  Braga, D. Brailsford, A. Brandt, J. Bremer, C. Brew, E. Brianne, S. J. Brice,
  C. Brizzolari, C. Bromberg, G. Brooijmans, J. Brooke, A. Bross, G. Brunetti,
  N. Buchanan, H. Budd, D. Caiulo, P. Calafiura, J. Calcutt, M. Calin, S.
  Calvez, E. Calvo, L. Camilleri, A. Caminata, M. Campanelli, D. Caratelli, G.
  Carini, B. Carlus, P. Carniti, I. Caro Terrazas, H. Carranza, A. Castillo, C.
  Castromonte, C. Cattadori, F. Cavalier, F. Cavanna, S. Centro, G. Cerati, A.
  Cervelli, A. Cervera Villanueva, M. Chalifour, C. Chang, E. Chardonnet, A.
  Chatterjee, S. Chattopadhyay, J. Chaves, H. Chen, M. Chen, Y. Chen, D.
  Cherdack, C. Chi, S. Childress, A. Chiriacescu, K. Cho, S. Choubey, A.
  Christensen, D. Christian, G. Christodoulou, E. Church, P. Clarke, T. E.
  Coan, A. G. Cocco, J. A. B. Coelho, E. Conley, J. M. Conrad, M. Convery, L.
  Corwin, P. Cotte, L. Cremaldi, L. Cremonesi, J. I. Crespo-Anad\'on, E.
  Cristaldo, R. Cross, C. Cuesta, Y. Cui, D. Cussans, M. Dabrowski, H. da
  Motta, L. Da Silva Peres, C. David, Q. David, G. S. Davies, S. Davini, J.
  Dawson, K. De, R. M. De Almeida, P. Debbins, I. De Bonis, M. P. Decowski, A.
  de Gouv\^ea, P. C. De Holanda, I. L. De Icaza Astiz, A. Deisting, P. De Jong,
  A. Delbart, D. Delepine, M. Delgado, A. Dell'Acqua, P. De Lurgio, J. R. T. de
  Mello Neto, D. M. DeMuth, S. Dennis, C. Densham, G. Deptuch, A. De Roeck, V.
  De Romeri, J. J. De Vries, R. Dharmapalan, M. Dias, F. Diaz, J. S. D\'iaz, S.
  Di Domizio, L. Di Giulio, P. Ding, L. Di Noto, C. Distefano, R. Diurba, M.
  Diwan, Z. Djurcic, N. Dokania, M. J. Dolinski, L. Domine, D. Douglas, F.
  Drielsma, D. Duchesneau, K. Duffy, P. Dunne, T. Durkin, H. Duyang, O.
  Dvornikov, D. A. Dwyer, A. S. Dyshkant, M. Eads, D. Edmunds, J. Eisch, S.
  Emery, A. Ereditato, C. O. Escobar, L. Escudero Sanchez, J. J. Evans, E.
  Ewart, A. C. Ezeribe, K. Fahey, A. Falcone, C. Farnese, Y. Farzan, J. Felix,
  E. Fernandez-Martinez, P. Fernandez Menendez, F. Ferraro, L. Fields, A.
  Filkins, F. Filthaut, R. S. Fitzpatrick, W. Flanagan, B. Fleming, R. Flight,
  J. Fowler, W. Fox, J. Franc, K. Francis, D. Franco, J. Freeman, J. Freestone,
  J. Fried, A. Friedland, S. Fuess, I. Furic, A. P. Furmanski, A. Gago, H.
  Gallagher, A. Gallego-Ros, N. Gallice, V. Galymov, E. Gamberini, T. Gamble,
  R. Gandhi, R. Gandrajula, S. Gao, F. Garc\'ia-Carballeira, D. Garcia-Gamez,
  M. \'A. Garc\'ia-Peris, S. Gardiner, D. Gastler, G. Ge, B. Gelli, A.
  Gendotti, S. Gent, Z. Ghorbani-Moghaddam, D. Gibin, I. Gil-Botella, C.
  Girerd, A. K. Giri, D. Gnani, O. Gogota, M. Gold, S. Gollapinni, K.
  Gollwitzer, R. A. Gomes, L. V. Gomez Bermeo, L. S. Gomez Fajardo, F.
  Gonnella, J. A. Gonzalez-Cuevas, M. C. Goodman, O. Goodwin, S. Goswami, C.
  Gotti, E. Goudzovski, C. Grace, M. Graham, E. Gramellini, R. Gran, E.
  Granados, A. Grant, C. Grant, D. Gratieri, P. Green, S. Green, L. Greenler,
  M. Greenwood, J. Greer, W. C. Griffith, M. Groh, J. Grudzinski, K. Grzelak,
  W. Gu, V. Guarino, R. Guenette, A. Guglielmi, B. Guo, K. K. Guthikonda, R.
  Gutierrez, P. Guzowski, M. M. Guzzo, S. Gwon, A. Habig, A. Hackenburg, H.
  Hadavand, R. Haenni, A. Hahn, J. Haigh, J. Haiston, T. Hamernik, P. Hamilton,
  J. Han, K. Harder, D. A. Harris, J. Hartnell, T. Hasegawa, R. Hatcher, E.
  Hazen, A. Heavey, K. M. Heeger, J. Heise, K. Hennessy, S. Henry, M. A.
  Hernandez Morquecho, K. Herner, L. Hertel, A. S. Hesam, V Hewes, A. Higuera,
  T. Hill, S. J. Hillier, A. Himmel, J. Hoff, C. Hohl, A. Holin, E. Hoppe, G.
  A. Horton-Smith, M. Hostert, A. Hourlier, B. Howard, R. Howell, J. Huang, J.
  Huang, J. Hugon, G. Iles, N. Ilic, A. M. Iliescu, R. Illingworth, A.
  Ioannisian, R. Itay, A. Izmaylov, E. James, B. Jargowsky, F. Jediny, C.
  Jes\`us-Valls, X. Ji, L. Jiang, S. Jim\'enez, A. Jipa, A. Joglekar, C.
  Johnson, R. Johnson, B. Jones, S. Jones, C. K. Jung, T. Junk, Y. Jwa, M.
  Kabirnezhad, A. Kaboth, I. Kadenko, F. Kamiya, G. Karagiorgi, A. Karcher, M.
  Karolak, Y. Karyotakis, S. Kasai, S. P. Kasetti, L. Kashur, N. Kazaryan, E.
  Kearns, P. Keener, K.J. Kelly, E. Kemp, W. Ketchum, S. H. Kettell, M.
  Khabibullin, A. Khotjantsev, A. Khvedelidze, D. Kim, B. King, B. Kirby, M.
  Kirby, J. Klein, K. Koehler, L. W. Koerner, S. Kohn, P. P. Koller, M.
  Kordosky, T. Kosc, U. Kose, V. A. Kosteleck\'y, K. Kothekar, F. Krennrich, I.
  Kreslo, Y. Kudenko, V. A. Kudryavtsev, S. Kulagin, J. Kumar, R. Kumar, C.
  Kuruppu, V. Kus, T. Kutter, A. Lambert, K. Lande, C. E. Lane, K. Lang, T.
  Langford, P. Lasorak, D. Last, C. Lastoria, A. Laundrie, A. Lawrence, I.
  Lazanu, R. LaZur, T. Le, J. Learned, P. LeBrun, G. Lehmann Miotto, R.
  Lehnert, M. A. Leigui de Oliveira, M. Leitner, M. Leyton, L. Li, S. Li, S. W.
  Li, T. Li, Y. Li, H. Liao, C. S. Lin, S. Lin, A. Lister, B. R. Littlejohn, J.
  Liu, S. Lockwitz, T. Loew, M. Lokajicek, I. Lomidze, K. Long, K. Loo, D.
  Lorca, T. Lord, J. M. LoSecco, W. C. Louis, K.B. Luk, X. Luo, N. Lurkin, T.
  Lux, V. P. Luzio, D. MacFarland, A. A. Machado, P. Machado, C. T. Macias, J.
  R. Macier, A. Maddalena, P. Madigan, S. Magill, K. Mahn, A. Maio, J. A.
  Maloney, G. Mandrioli, J. Maneira, L. Manenti, S. Manly, A. Mann, K.
  Manolopoulos, M. Manrique Plata, A. Marchionni, W. Marciano, D. Marfatia, C.
  Mariani, J. Maricic, F. Marinho, A. D. Marino, M. Marshak, C. Marshall, J.
  Marshall, J. Marteau, J. Martin-Albo, N. Martinez, D. A. Martinez Caicedo, S.
  Martynenko, K. Mason, A. Mastbaum, M. Masud, S. Matsuno, J. Matthews, C.
  Mauger, N. Mauri, K. Mavrokoridis, R. Mazza, A. Mazzacane, E. Mazzucato, E.
  McCluskey, N. McConkey, K. S. McFarland, C. McGrew, A. McNab, A. Mefodiev, P.
  Mehta, P. Melas, M. Mellinato, O. Mena, S. Menary, H. Mendez, A. Menegolli,
  G. Meng, M. D. Messier, W. Metcalf, M. Mewes, H. Meyer, T. Miao, G. Michna,
  T. Miedema, J. Migenda, R. Milincic, W. Miller, J. Mills, C. Milne, O.
  Mineev, O. G. Miranda, S. Miryala, C. S. Mishra, S. R. Mishra, A. Mislivec,
  D. Mladenov, I. Mocioiu, K. Moffat, N. Moggi, R. Mohanta, T. A. Mohayai, N.
  Mokhov, J. Molina, L. Molina Bueno, A. Montanari, C. Montanari, D. Montanari,
  L. M. Montano Zetina, J. Moon, M. Mooney, A. Moor, D. Moreno, B. Morgan, C.
  Morris, C. Mossey, E. Motuk, C. A. Moura, J. Mousseau, W. Mu, L. Mualem, J.
  Mueller, M. Muether, S. Mufson, F. Muheim, A. Muir, M. Mulhearn, H.
  Muramatsu, S. Murphy, J. Musser, J. Nachtman, S. Nagu, M. Nalbandyan, R.
  Nandakumar, D. Naples, S. Narita, D. Navas-Nicol\'as, N. Nayak, M.
  Nebot-Guinot, L. Necib, K. Negishi, J. K. Nelson, J. Nesbit, M. Nessi, D.
  Newbold, M. Newcomer, D. Newhart, R. Nichol, E. Niner, K. Nishimura, A.
  Norman, A. Norrick, R. Northrop, P. Novella, J. A. Nowak, M. Oberling, A.
  Olivares Del Campo, A. Olivier, Y. Onel, Y. Onishchuk, J. Ott, L. Pagani, S.
  Pakvasa, O. Palamara, S. Palestini, J. M. Paley, M. Pallavicini, C.
  Palomares, E. Pantic, V. Paolone, V. Papadimitriou, R. Papaleo, A.
  Papanestis, S. Paramesvaran, S. Parke, Z. Parsa, M. Parvu, S. Pascoli, L.
  Pasqualini, J. Pasternak, J. Pater, C. Patrick, L. Patrizii, R. B. Patterson,
  S. J. Patton, T. Patzak, A. Paudel, B. Paulos, L. Paulucci, Z. Pavlovic, G.
  Pawloski, D. Payne, V. Pec, S. J. M. Peeters, Y. Penichot, E. Pennacchio, A.
  Penzo, O. L. G. Peres, J. Perry, D. Pershey, G. Pessina, G. Petrillo, C.
  Petta, R. Petti, F. Piastra, L. Pickering, F. Pietropaolo, J. Pillow, J.
  Pinzino, R. Plunkett, R. Poling, X. Pons, N. Poonthottathil, S. Pordes, M.
  Potekhin, R. Potenza, B. V. K. S. Potukuchi, J. Pozimski, M. Pozzato, S.
  Prakash, T. Prakash, S. Prince, G. Prior, D. Pugnere, K. Qi, X. Qian, J. L.
  Raaf, R. Raboanary, V. Radeka, J. Rademacker, B. Radics, A. Radovic, A.
  Rafique, E. Raguzin, M. Rai, M. Rajaoalisoa, I. Rakhno, H. T.
  Rakotondramanana, L. Rakotondravohitra, Y. A. Ramachers, R. Rameika, M. A.
  Ramirez Delgado, B. Ramson, A. Rappoldi, G. Raselli, P. Ratoff, S. Ravat, H.
  Razafinime, J.S. Real, B. Rebel, D. Redondo, M. Reggiani-Guzzo, T. Rehak, J.
  Reichenbacher, S. D. Reitzner, A. Renshaw, S. Rescia, F. Resnati, A.
  Reynolds, G. Riccobene, L. C. J. Rice, K. Rielage, Y. Rigaut, D. Rivera, L.
  Rochester, M. Roda, P. Rodrigues, M. J. Rodriguez Alonso, J. Rodriguez
  Rondon, A. J. Roeth, H. Rogers, S. Rosauro-Alcaraz, M. Rossella, J. Rout, S.
  Roy, A. Rubbia, C. Rubbia, B. Russell, J. Russell, D. Ruterbories, R.
  Saakyan, S. Sacerdoti, T. Safford, N. Sahu, P. Sala, N. Samios, M. C.
  Sanchez, D. A. Sanders, D. Sankey, S. Santana, M. Santos-Maldonado, N.
  Saoulidou, P. Sapienza, C. Sarasty, I. Sarcevic, G. Savage, V. Savinov, A.
  Scaramelli, A. Scarff, A. Scarpelli, T. Schaffer, H. Schellman, P. Schlabach,
  D. Schmitz, K. Scholberg, A. Schukraft, E. Segreto, J. Sensenig, I. Seong, A.
  Sergi, F. Sergiampietri, D. Sgalaberna, M. H. Shaevitz, S. Shafaq, M. Shamma,
  H. R. Sharma, R. Sharma, T. Shaw, C. Shepherd-Themistocleous, S. Shin, D.
  Shooltz, R. Shrock, L. Simard, N. Simos, J. Sinclair, G. Sinev, J. Singh, J.
  Singh, V. Singh, R. Sipos, F. W. Sippach, G. Sirri, A. Sitraka, K. Siyeon, D.
  Smargianaki, A. Smith, A. Smith, E. Smith, P. Smith, J. Smolik, M. Smy, P.
  Snopok, M. Soares Nunes, H. Sobel, M. Soderberg, C. J. Solano Salinas, S.
  S\""oldner-Rembold, N. Solomey, V. Solovov, W. E. Sondheim, M. Sorel, J.
  Soto-Oton, A. Sousa, K. Soustruznik, F. Spagliardi, M. Spanu, J. Spitz, N. J.
  C. Spooner, K. Spurgeon, R. Staley, M. Stancari, L. Stanco, H. M. Steiner, J.
  Stewart, B. Stillwell, J. Stock, F. Stocker, T. Stokes, M. Strait, T.
  Strauss, S. Striganov, A. Stuart, D. Summers, A. Surdo, V. Susic, L. Suter,
  C. M. Sutera, R. Svoboda, B. Szczerbinska, A. M. Szelc, R. Talaga, H. A.
  Tanaka, B. Tapia Oregui, A. Tapper, S. Tariq, E. Tatar, R. Tayloe, A. M.
  Teklu, M. Tenti, K. Terao, C. A. Ternes, F. Terranova, G. Testera, A. Thea,
  J. L. Thompson, C. Thorn, S. C. Timm, A. Tonazzo, M. Torti, M. Tortola, F.
  Tortorici, D. Totani, M. Toups, C. Touramanis, J. Trevor, W. H. Trzaska, Y.
  T. Tsai, Z. Tsamalaidze, K. V. Tsang, N. Tsverava, S. Tufanli, C. Tull, E.
  Tyley, M. Tzanov, M. A. Uchida, J. Urheim, T. Usher, M. R. Vagins, P. Vahle,
  G. A. Valdiviesso, E. Valencia, Z. Vallari, J. W. F. Valle, S. Vallecorsa, R.
  Van Berg, R. G. Van de Water, D. Vanegas Forero, F. Varanini, D. Vargas, G.
  Varner, J. Vasel, G. Vasseur, K. Vaziri, S. Ventura, A. Verdugo, S. Vergani,
  M. A. Vermeulen, M. Verzocchi, H. Vieira de Souza, C. Vignoli, C. Vilela, B.
  Viren, T. Vrba, T. Wachala, A. V. Waldron, M. Wallbank, H. Wang, J. Wang, Y.
  Wang, Y. Wang, K. Warburton, D. Warner, M. Wascko, D. Waters, A. Watson, P.
  Weatherly, A. Weber, M. Weber, H. Wei, A. Weinstein, D. Wenman, M. Wetstein,
  M. R. While, A. White, L. H. Whitehead, D. Whittington, M. J. Wilking, C.
  Wilkinson, Z. Williams, F. Wilson, R. J. Wilson, J. Wolcott, T. Wongjirad, K.
  Wood, L. Wood, E. Worcester, M. Worcester, C. Wret, W. Wu, W. Wu, Y. Xiao, G.
  Yang, T. Yang, N. Yershov, K. Yonehara, T. Young, B. Yu, J. Yu, R. Zaki, J.
  Zalesak, L. Zambelli, B. Zamorano, A. Zani, L. Zazueta, G. P. Zeller, J.
  Zennamo, K. Zeug, C. Zhang, M. Zhao, E. Zhivun, G. Zhu, E. D. Zimmerman, M.
  Zito, S. Zucchelli, J. Zuklin, V. Zutshi, R. Zwaska","Neutrino interaction classification with a convolutional neural network
  in the DUNE far detector","39 pages, 11 figures","Phys. Rev. D 102, 092003 (2020)","10.1103/PhysRevD.102.092003",,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  The Deep Underground Neutrino Experiment is a next-generation neutrino
oscillation experiment that aims to measure $CP$-violation in the neutrino
sector as part of a wider physics program. A deep learning approach based on a
convolutional neural network has been developed to provide highly efficient and
pure selections of electron neutrino and muon neutrino charged-current
interactions. The electron neutrino (antineutrino) selection efficiency peaks
at 90% (94%) and exceeds 85% (90%) for reconstructed neutrino energies between
2-5 GeV. The muon neutrino (antineutrino) event selection is found to have a
maximum efficiency of 96% (97%) and exceeds 90% (95%) efficiency for
reconstructed neutrino energies above 2 GeV. When considering all electron
neutrino and antineutrino interactions as signal, a selection purity of 90% is
achieved. These event selections are critical to maximize the sensitivity of
the experiment to $CP$-violating effects.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:30:57 GMT""},{""version"":""v2"",""created"":""Tue, 10 Nov 2020 13:51:35 GMT""}]","2023-02-18"
"2006.15053","Alexandru Maries","Alexandru Maries and Chandralekha Singh","Case of two electrostatics problems: Can providing a diagram adversely
  impact introductory physics students' problem solving performance?",,"Physical Review PHYSICS EDUCATION RESEARCH 14, 010114 (2018)","10.1103/PhysRevPhysEducRes.14.010114",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Drawing appropriate diagrams is a useful problem solving heuristic that can
transform a problem into a representation that is easier to exploit for solving
it. One major focus while helping introductory physics students learn effective
problem solving is to help them understand that drawing diagrams can facilitate
problem solution. We conducted an investigation in which two different
interventions were implemented during recitation quizzes in a large enrollment
algebra-based introductory physics course. Students were either (i) asked to
solve problems in which the diagrams were drawn for them or (ii) explicitly
told to draw a diagram. A comparison group was not given any instruction
regarding diagrams. We developed rubrics to score the problem solving
performance of students in different intervention groups and investigated ten
problems. We found that students who were provided diagrams never performed
better and actually performed worse than the other students on three problems,
one involving standing sound waves in a tube (discussed elsewhere) and two
problems in electricity which we focus on here. These two problems were the
only problems in electricity that involved considerations of initial and final
conditions, which may partly account for why students provided with diagrams
performed significantly worse than students who were not provided with
diagrams. In order to explore potential reasons for this finding, we conducted
interviews with students and found that some students provided with diagrams
may have spent less time on the conceptual analysis and planning stage of the
problem solving process. In particular, those provided with the diagram were
more likely to jump into the implementation stage of problem solving early
without fully analyzing and understanding the problem, which can increase the
likelihood of mistakes in solutions.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:31:44 GMT""}]","2020-06-29"
"2006.15054","Michael Fu","Michael C. Fu, Bingqing Li, Rongwen Wu, Tianqi Zhang","Option Pricing Under a Discrete-Time Markov Switching Stochastic
  Volatility with Co-Jump Model",,,,,"q-fin.PR q-fin.CP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider option pricing using a discrete-time Markov switching stochastic
volatility with co-jump model, which can model volatility clustering and
varying mean-reversion speeds of volatility. For pricing European options, we
develop a computationally efficient method for obtaining the probability
distribution of average integrated variance (AIV), which is key to option
pricing under stochastic-volatility-type models. Building upon the efficiency
of the European option pricing approach, we are able to price an American-style
option, by converting its pricing into the pricing of a portfolio of European
options. Our work also provides constructive guidance for analyzing derivatives
based on variance, e.g., the variance swap. Numerical results indicate our
methods can be implemented very efficiently and accurately.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:31:54 GMT""}]","2020-06-29"
"2006.15055","Thomas Kipf","Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh
  Mahendran, Georg Heigold, Jakob Uszkoreit, Alexey Dosovitskiy, Thomas Kipf","Object-Centric Learning with Slot Attention","NeurIPS 2020. Code available at
  https://github.com/google-research/google-research/tree/master/slot_attention",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning object-centric representations of complex scenes is a promising step
towards enabling efficient abstract reasoning from low-level perceptual
features. Yet, most deep learning approaches learn distributed representations
that do not capture the compositional properties of natural scenes. In this
paper, we present the Slot Attention module, an architectural component that
interfaces with perceptual representations such as the output of a
convolutional neural network and produces a set of task-dependent abstract
representations which we call slots. These slots are exchangeable and can bind
to any object in the input by specializing through a competitive procedure over
multiple rounds of attention. We empirically demonstrate that Slot Attention
can extract object-centric representations that enable generalization to unseen
compositions when trained on unsupervised object discovery and supervised
property prediction tasks.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:31:57 GMT""},{""version"":""v2"",""created"":""Wed, 14 Oct 2020 08:51:40 GMT""}]","2020-10-15"
"2006.15056","Zitian Chen","Zitian Chen, Zhiqiang Shen, Jiahui Yu, Erik Learned-Miller","Cross-Supervised Object Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After learning a new object category from image-level annotations (with no
object bounding boxes), humans are remarkably good at precisely localizing
those objects. However, building good object localizers (i.e., detectors)
currently requires expensive instance-level annotations. While some work has
been done on learning detectors from weakly labeled samples (with only class
labels), these detectors do poorly at localization. In this work, we show how
to build better object detectors from weakly labeled images of new categories
by leveraging knowledge learned from fully labeled base categories. We call
this novel learning paradigm cross-supervised object detection. We propose a
unified framework that combines a detection head trained from instance-level
annotations and a recognition head learned from image-level annotations,
together with a spatial correlation module that bridges the gap between
detection and recognition. These contributions enable us to better detect novel
objects with image-level annotations in complex multi-object scenes such as the
COCO dataset.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:33:48 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 03:11:46 GMT""}]","2020-06-30"
"2006.15057","Steffen Czolbe","Steffen Czolbe, Oswin Krause, Ingemar Cox, Christian Igel","A Loss Function for Generative Neural Networks Based on Watson's
  Perceptual Model","Published at the 34th Conference on Neural Information Processing
  Systems (NeurIPS 2020)",,,,"cs.LG cs.CV eess.IV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To train Variational Autoencoders (VAEs) to generate realistic imagery
requires a loss function that reflects human perception of image similarity. We
propose such a loss function based on Watson's perceptual model, which computes
a weighted distance in frequency space and accounts for luminance and contrast
masking. We extend the model to color images, increase its robustness to
translation by using the Fourier Transform, remove artifacts due to splitting
the image into blocks, and make it differentiable. In experiments, VAEs trained
with the new loss function generated realistic, high-quality image samples.
Compared to using the Euclidean distance and the Structural Similarity Index,
the images were less blurry; compared to deep neural network based losses, the
new approach required less computational resources and generated images with
less artifacts.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:36:11 GMT""},{""version"":""v2"",""created"":""Tue, 20 Oct 2020 16:15:05 GMT""},{""version"":""v3"",""created"":""Wed, 6 Jan 2021 11:16:21 GMT""}]","2021-01-07"
"2006.15058","Alexandru Maries","Nafis I Karim, Alexandru Maries, and Chandralekha Singh","Exploring one aspect of pedagogical content knowledge of teaching
  assistants using the Conceptual Survey of Electricity and Magnetism",,"Physical Review PHYSICS EDUCATION RESEARCH 14, 010117 (2018)","10.1103/PhysRevPhysEducRes.14.010117",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Instruction is unlikely to be effective if instructors do not know the common
alternate conceptions of introductory physics students and explicitly take into
account common student difficulties in their instructional design. Here, we
discuss research involving the Conceptual Survey of Electricity and Magnetism
(CSEM) to evaluate one aspect of the pedagogical content knowledge of teaching
assistants (TAs): knowledge of introductory students' alternate conceptions in
electricity and magnetism as revealed by the CSEM. For each item on the CSEM,
the TAs were asked to identify the most common incorrect answer choice selected
by introductory physics students if they did not know the correct answer after
traditional instruction. Then, we used introductory student CSEM post-test data
to assess the extent to which TAs were able to identify the most common
alternate conception of introductory students in each question on the CSEM. We
find that the TAs were thoughtful when attempting to identify common student
difficulties and they enjoyed learning about student difficulties this way.
However, they struggled to identify many common difficulties of introductory
students that persist after traditional instruction. We discuss specific
alternate conceptions that persist after traditional instruction, the extent to
which TAs were able to identify them, and results from think-aloud interviews
with TAs which provided valuable information regarding why the TAs sometimes
selected certain alternate conceptions as the most common but were instead very
rare among introductory students. We also discuss how tasks such as the one
used in this study can be used in professional development programs to engender
productive discussions about the importance of being knowledgeable about
student alternate conceptions in order to help students learn.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:36:54 GMT""}]","2020-06-29"
"2006.15059","Jos Stam","Jos Stam","Computing Light Transport Gradients using the Adjoint Method","23 pages, 8 figures, unpublished manuscript",,,,"cs.GR cs.CV cs.LG physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a new equation from continuous adjoint theory to compute
the gradient of quantities governed by the Transport Theory of light. Unlike
discrete gradients ala autograd, which work at the code level, we first
formulate the continuous theory and then discretize it. The key insight of this
paper is that computing gradients in Transport Theory is akin to computing the
importance, a quantity adjoint to radiance that satisfies an adjoint equation.
Importance tells us where to look for light that matters. This is one of the
key insights of this paper. In fact, this mathematical journey started from a
whimsical thought that these adjoints might be related. Computing gradients is
therefore no more complicated than computing the importance field. This insight
and the following paper hopefully will shed some light on this complicated
problem and ease the implementations of gradient computations in existing path
tracers.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:38:14 GMT""}]","2020-06-29"
"2006.15060","Natarajan Shriethar","Natarajan S, Chandrmohan R, Swaminathan R","Conformal cyclic evolution of phantom energy dominated universe",,"Revista Mexicana de F\'isica, 66(2 Mar-Apr), 209-223 (2020)",,,"gr-qc","http://creativecommons.org/publicdomain/zero/1.0/","  From the Wheeler-Dewitt solutions, the scale factor of the initial universe
is discussed. In this study, scale factors from Wheeler-Dewitt solutions, loop
quantum gravity, and phantom energy dominated stages are compared. Certain
modifications have been attempted in scale factor and quantum potentials driven
by canonical quantum gravity approaches. Their results are discussed in this
work. Despite an increment of phantom energy density, avoidance of Big Rip is
reported. Scale factors predicted from various models are discussed in this
work. The relationship between scale factors and the smooth continuation of
Aeon is discussed by the application of conformal cyclic cosmology. Quantum
potentials for various models are correlated and a correction parameter is
included in the cosmological constant. Phantom energy dominated, final stage
non-singular evolution of the universe is found. Eternal increment of phantom
energy density without interacting with dark matter is reported for the
consequence of the evolution of the future universe. Also, the non-interacting
solutions of phantom energy and dark matter are explained. As the evolution
continues even after the final singularity is approached, the validity of
conformal cyclic cosmology is predicted. Non zero values for the scale factor
for the set of eigenvalues are presented. Results are compared with
supersymmetric classical cosmology. The non-interacting solutions are compared
with SiBI solutions
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:39:37 GMT""}]","2020-06-29"
"2006.15061","Xingrui Yu","Xingrui Yu, Yueming Lyu and Ivor W. Tsang","Intrinsic Reward Driven Imitation Learning via Generative Model",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Imitation learning in a high-dimensional environment is challenging. Most
inverse reinforcement learning (IRL) methods fail to outperform the
demonstrator in such a high-dimensional environment, e.g., Atari domain. To
address this challenge, we propose a novel reward learning module to generate
intrinsic reward signals via a generative model. Our generative method can
perform better forward state transition and backward action encoding, which
improves the module's dynamics modeling ability in the environment. Thus, our
module provides the imitation agent both the intrinsic intention of the
demonstrator and a better exploration ability, which is critical for the agent
to outperform the demonstrator. Empirical results show that our method
outperforms state-of-the-art IRL methods on multiple Atari games, even with
one-life demonstration. Remarkably, our method achieves performance that is up
to 5 times the performance of the demonstration.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:39:40 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 09:34:29 GMT""},{""version"":""v3"",""created"":""Sun, 16 Aug 2020 05:52:22 GMT""},{""version"":""v4"",""created"":""Fri, 11 Sep 2020 09:40:12 GMT""}]","2020-09-14"
"2006.15062","Carlos Acha","C. Acha, M. Barella, G. A. Sanca, F. Gomez Marlasca, H. Huhtinen, P.
  Paturi, P. Levy and F. Golmar","YBCO-based non-volatile ReRAM tested in Low Earth Orbit","20 pages, 11 figures","Journal of Materials Science: Materials in Electronics (2020)","10.1007/s10854-020-04190-0",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An YBCO-based test structure corresponding to the family of ReRAM devices
associated with the valence change mechanism is presented. We have
characterized its electrical response previous to its lift-off to a Low Earth
Orbit (LEO) using standard electronics and also with the dedicated LabOSat-01
controller. Similar results were obtained in both cases. After about 200 days
at LEO on board a small satellite, electrical tests started on the memory
device using the LabOSat-01 controller. We discuss the results of the first 150
tests, performed along a 433-day time interval in space. The memory device
remained operational despite the hostile conditions that involved launching,
lift-off vibrations, permanent thermal cycling and exposure to ionizing
radiation, with doses 3 orders of magnitude greater than the usual ones on
Earth. The device showed resistive switching and IV characteristics similar to
those measured on Earth, although with changes that follow a smooth drift in
time. A detailed study of the electrical transport mechanisms, based on
previous models that indicate the existence of various conducting mechanisms
through the metal-YBCO interface showed that the observed drift can be
associated with a local temperature drift at the LabOSat controller, with no
clear evidence that allows determining changes in the underlying microscopic
factors. These results show the reliability of complex-oxide non-volatile
ReRAM-based devices in order to operate under all the hostile conditions
encountered in space-borne applications.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:39:58 GMT""}]","2020-08-27"
"2006.15063","Dimitra-Dionysia Stergiopoulou","Mihalis Maliakas and Dimitra-Dionysia Stergiopoulou","On homomorphisms involving a hook Weyl module","Updated with reviewers' suggestions. Subsection 3.2 was added. Minor
  corrections. To appear in J. Algebra","Journal of Algebra, Volume 585, 2021, Pages 1-24","10.1016/j.jalgebra.2021.05.016",,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $k$ be an infinite field of positive characteristic. We determine all
homomorphisms between Weyl modules for $GLn(k)$, where one of the partitions is
a hook. As a consequence we obtain a nonvanishing result concerning
homomorphisms between Weyl modules for algebraic groups of type B, C and D when
one of the partitions is a hook.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:40:15 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 16:18:31 GMT""}]","2021-11-19"
"2006.15064","Elias Frantz","Elias B. Frantz, Nicholas J. Harmon Stephen R. McMillan, Stephen J.
  Moxim, Michael E. Flatte, Patrick M. Lenahan","Extraction of Isotropic Electron-Nuclear Hyperfine Coupling Constants of
  Paramagnetic Point Defects from Near-Zero Field Magnetoresistance Spectra via
  Least Squares Fitting to Models Developed from the Stochastic Quantum
  Liouville Equation",,"J. Appl. Phys. 128, 124504 (2020)","10.1063/5.0019875",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on a method by which we can systematically extract spectroscopic
information such as isotropic electron-nuclear hyperfine coupling constants
from near-zero field magnetoresistance spectra. The method utilizes a least
squares fitting of models developed from the stochastic quantum Liouville
equation. We applied our fitting algorithm to two distinct material systems:
Si/SiO2 MOSFETs, and a-Si:H MIS capacitors. Our fitted results and hyperfine
parameters are in reasonable agreement with existing knowledge of the defects
present in the systems. Our work indicates that the NZFMR response and fitting
of the NZFMR spectrum via models developed from the stochastic quantum
Liouville equation could be a relatively simple yet powerful addition to the
family of spin-based techniques used to explore the chemical and structural
nature of point defects in semiconductor devices and insulators.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:44:33 GMT""}]","2020-09-30"
"2006.15065","Asunci\'on Fuente","A. Fuente, S. P. Trevi\~no-Morales, R. Le Gal, P. Riviere-Marichalar,
  P. Pilleri, M. Rodriguez-Baras, D. Navarro-Almaida","Gas kinematics of key prebiotic molecules in GV Tau N revealed with an
  ALMA, PdBI, and Herschel synergy","12 pages, 8 figures. Accepted for publication in MNRAS",,"10.1093/mnras/staa1919",,"astro-ph.SR astro-ph.EP astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A large effort has been made to detect warm gas in the planet formation zone
of circumstellar discs using space and ground-based near infrared facilities.
GV Tau N, the most obscured component of the GV Tau system, is an outstanding
source, being one of the first targets detected in HCN and the only one
detected in CH$_4$ so far. Although near infrared observations have shed light
on its chemical content, the physical structure and kinematics of the
circumstellar matter remained unknown. We use interferometric images of the HCN
3-2 and $^{13}$CO 3-2 lines, and far-IR observations of $^{13}$CO, HCN, CN and
H$_2$O transitions to discern the morphology, kinematics, and chemistry of the
dense gas close to the star. These observations constitute the first detection
of H$_2$O towards GV Tau N. Moreover, ALMA high spatial resolution (~ 7 au)
images of the continuum at 1.1 mm and the HCN 3-2 line resolve different gas
components towards GV Tau N, a gaseous disc with R~25 au, an ionized jet, and
one (or two) molecular outflows. The asymmetric morphology of the gaseous disc
shows that it has been eroded by the jet. All observations can be explained if
GV Tau N is binary, and the primary component has a highly inclined individual
disc relative to the circumbinary disc. We discuss the origin of the water and
the other molecules emission according to this scenario. In particular, we
propose that the water emission would come from the disrupted gaseous disc and
the molecular outflows.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:46:13 GMT""}]","2020-07-15"
"2006.15066","Daniel Duffy","Daniel Duffy and John S. Biggins","Defective nematogenesis: Gauss curvature in programmable
  shape-responsive sheets with topological defects","Final peer reviewed version","Soft Matter, 2020,16, 10935-10945","10.1039/d0sm01192d",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Flat sheets encoded with patterns of contraction/elongation morph into curved
surfaces. If the surfaces bear Gauss curvature, the resulting actuation can be
strong and powerful. We deploy the Gauss-Bonnet theorem to deduce the Gauss
curvature encoded in a pattern of uniform-magnitude contraction/elongation with
spatially varying direction, as is commonly implemented in patterned liquid
crystal elastomers. This approach reveals two fundamentally distinct
contributions: a structural curvature which depends on the precise form of the
pattern, and a topological curvature generated by defects in the contractile
direction. These curvatures grow as different functions the
contraction/elongation magnitude, explaining the apparent contradiction between
previous calculations for simple +1 defects, and smooth defect-free patterns.
We verify these structural and topological contributions by conducting
numerical shell calculations on sheets encoded with simple higher-order
contractile defects to reveal their activated morphology. Finally we calculate
the Gauss curvature generated by patterns with spatially varying magnitude and
direction, which leads to additional magnitude gradient contributions to the
structural term. We anticipate this form will be useful whenever magnitude and
direction are natural variables, including in describing the contraction of a
muscle along its patterned fiber direction, or a tissue growing by elongating
its cells.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:50:28 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 19:04:04 GMT""}]","2021-07-01"
"2006.15067","Steve Reinhardt","Uchenna Chukwu, Raouf Dridi, Jesse Berwald, Michael Booth, John
  Dawson, DeYung Le, Mark Wainger, Steven P. Reinhardt","Constrained-optimization Approach Delivers Superior Classical
  Performance for Graph Partitioning via Quantum-ready Method",,,,,"quant-ph math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph partitioning is one of an important set of well-known compute-intense
(NP-hard) graph problems that devolve to discrete constrained optimization. We
sampled solutions to the problem via two different quantum-ready methods to
understand the pros and cons of each method. First we formulated and sampled
the problem as a quadratic unconstrained binary optimization (QUBO) problem,
via the best known QUBO formulation, using a best-in-class QUBO sampler running
purely classically. Second, we formulated the problem at a higher level, as a
set of constraints and an objective function, and sampled it with a
constrained-optimization sampler (which internally samples the problem via
QUBOs also sampled classically). We find that both approaches often deliver
better partitions than the purpose-built classical graph partitioners. Further,
we find that the constrained-optimization approach is often able to deliver
better partitions in less time than the bespoke-QUBO approach, without
knowledge of the graph-partitioning problem.
  Stepping back from graph partitioning itself, one key controversial question
is whether bespoke algorithms or general tools are more likely to deliver the
power of QCs to real-world users. These results bear on that question, though
they require confirmation on other problems and instances as well as
replacement of the low-level sampler by a QC. Still, this early evidence
supports the proposition that general tools will contribute significantly to a
range of problems, expanding the impact of QCs. This benefit is independent of
the low-level sampler employed, whether software or QC, so reinforces the need
for more work on high-level optimization. An early version of such software is
commercially available in the cloud today, delivering superior classical
performance for some problems, enables quantum-forward organizations to migrate
to quantum-ready methods now.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:55:12 GMT""}]","2020-06-29"
"2006.15144","Nikolai Sinitsyn","V. Y. Chernyak, and N. A. Sinitsyn","Integrability in the multistate Landau-Zener model with time-quadratic
  commuting operators","12 pages, 9 figures",,,,"quant-ph cond-mat.quant-gas math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exactly solvable multistate Landau-Zener (MLZ) models are associated with
families of operators that commute with the MLZ Hamiltonians and depend on time
linearly. There can also be operators that satisfy the integrability conditions
with the MLZ Hamiltonians but depend on time quadratically. We show that, among
the MLZ systems, such time-quadratic operators are much more common. We
demonstrate then that such operators generally lead to constraints on the
independent variables that parametrize the scattering matrix. We show how such
constraints lead to asymptotically exact expressions for the transition
probabilities in the adiabatic limit of a three-level MLZ model. New fully
solvable MLZ systems are also found.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 23:39:20 GMT""},{""version"":""v2"",""created"":""Fri, 18 Sep 2020 20:36:01 GMT""},{""version"":""v3"",""created"":""Wed, 20 Jan 2021 22:56:54 GMT""}]","2021-01-22"
"2006.15970","Fabio Angelo Maccheroni","Simone Cerreia-Vioglio, Fabio Maccheroni, Massimo Marinacci, Aldo
  Rustichini","Axiomatic Tests for the Boltzmann Distribution",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Boltzmann distribution describes a single parameter (temperature) family
of probability distributions over a state space; at any given temperature, the
ratio of probabilities of two states depends on their difference in energy. The
same family is known in other disciplines (economics, psychology, computer
science) with different names and interpretations. Such widespread use in very
diverse fields suggests a common conceptual structure. We identify it on the
basis of few natural axioms. Checking whether observables satisfy these axioms
is easy, so our characterization provides a simple empirical test of the
Boltzmannian modeling theories.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 09:50:12 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 12:31:05 GMT""}]","2020-07-01"
"2006.15988","Chika Okafor","Chika O. Okafor","Social Networks as a Mechanism for Discrimination","4 figures",,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I study labor markets in which firms hire via referrals. I develop an
employment model showing that--despite initial equality in ability, employment,
wages, and network structure--minorities receive fewer jobs through referral
and lower expected wages, simply because their social group is smaller. This
disparity, termed ""social network discrimination,"" falls outside the dominant
economics discrimination models--taste-based and statistical. Social network
discrimination can be mitigated by minorities having more social ties or a
""stronger-knit"" network. I calibrate the model using a
nationally-representative U.S. sample and estimate the lower-bound welfare gap
caused by social network discrimination at over four percent, disadvantaging
black workers.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:20:23 GMT""},{""version"":""v2"",""created"":""Fri, 25 Feb 2022 02:19:16 GMT""}]","2022-02-28"
"2006.15992","Hidenori Ogata","Hidenori Ogata","A method of fundamental solutions for doubly-periodic potential flow
  problems using the Weierstrass elliptic function","11 pages, 3 figures, 1 table. arXiv admin note: substantial text
  overlap with arXiv:2006.12763",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a method of fundamental solutions for the problems
of two-dimensional potential flow past a doubly-periodic array of obstacles.
The solutions of these problems involve doubly-periodic functions, and it is
difficult to apply the conventional method of fundamental solutions to
approximate them. The method that we propose gives approximate solutions which
is expressed by a linear combination of periodic fundamental solutions
constructed using the Weierstrass elliptic functions, and it satisfies the
periodicity that we expect. Numerical examples show the effectiveness of our
method.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 01:33:03 GMT""}]","2020-06-30"
"2006.15993","Chunhui Li","Chunhui Li and Shihao Yan and Nan Yang and Xiangyun Zhou","Truncated Channel Inversion Power Control to Enable One-Way URLLC with
  Imperfect Channel Reciprocity","Submitted to IEEE Transactions on Communications. arXiv admin note:
  text overlap with arXiv:1909.00908",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose to use channel inversion power control (CIPC) to achieve one-way
ultra-reliable and low-latency communications (URLLC), where only the
transmission in one direction requires ultra reliability and low latency. Based
on channel reciprocity, our proposed CIPC schemes guarantee the power of
received signal that is used to decode the information to be a constant value
$Q$, by varying the transmit signal and power, which relaxes the assumption of
knowing channel state information (CSI) at the user. Thus, the CIPC schemes
eliminate the overhead of CSI feedback, reduce communication latency, and
explore the benefits of multiple antennas to significantly improve transmission
reliability. We derive analytical expressions for the packet loss probability
of the proposed CIPC schemes, based on which we determine a closed interval and
a convex set for optimizing $Q$ in CIPC with imperfect and perfect channel
reciprocity, respectively. Our results show that CIPC is an effective means to
achieve one-way URLLC. The tradeoff among reliability, latency, and required
resources (e.g., transmit antennas) is further revealed, which provides novel
principles for designing one-way URLLC systems.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 00:42:43 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 05:56:27 GMT""}]","2022-02-22"
"2006.15995","Can G\""okler","Can Gokler","Quantum behavior of a classical particle subject to a random force",,,"10.1007/s10701-021-00422-3",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a partial answer to the question whether the Schrodinger equation can
be derived from the Newtonian mechanics of a particle in a potential subject to
a random force. We show that the fluctuations around the classical motion of a
one dimensional harmonic oscillator subject to a random force can be described
by the Schrodinger equation for a period of time depending on the frequency and
the energy of the oscillator. We achieve this by deriving the postulates of
Nelson's stochastic formulation of quantum mechanics for a random force
depending on a small parameter. We show that the same result applies to small
potential perturbations around the harmonic oscillator as long as the total
potential preserves the periodicity of motion with a small shift in frequency.
We also show that the noise spectrum can be chosen to obtain the result for all
oscillator frequencies for fixed mass. We discuss heuristics to generalize the
result for a particle in one dimension in a potential where the motion can be
described using action-angle variables.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:28:20 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 06:54:21 GMT""}]","2021-02-24"
"2006.15996","Nicholas Mertes","Nicholas Mertes","Torsor-cotorsor duality of Ext groups","arXiv admin note: text overlap with arXiv:2006.04230",,,,"math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $A$ be a ring, and let $M$ and $N$ be $A$-modules. Then $N$ can be viewed
as a group object in the category $A$-Mod/$M$ of $A$-modules over $M$ and
Ext$^1(M, N)$ can be interpreted as the set of isomorphism classes of
$N$-torsors. Alternatively, $M$ can be viewed as a cogroup object in the
category $N$/$A$-Mod of $A$-modules under $N$ and Ext$^1(M, N)$ can be
interpreted as the set of isomorphism classes of $M$-cotorsors.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 23:56:06 GMT""}]","2020-06-30"
"2006.15997","Vincent Chin","Vincent Chin, Noelle I. Samia, Roman Marchant, Ori Rosen, John P.A.
  Ioannidis, Martin A. Tanner, Sally Cripps","A Case Study in Model Failure? COVID-19 Daily Deaths and ICU Bed
  Utilisation Predictions in New York State",,,"10.1007/s10654-020-00669-6",,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Forecasting models have been influential in shaping decision-making in the
COVID-19 pandemic. However, there is concern that their predictions may have
been misleading. Here, we dissect the predictions made by four models for the
daily COVID-19 death counts between March 25 and June 5 in New York state, as
well as the predictions of ICU bed utilisation made by the influential IHME
model. We evaluated the accuracy of the point estimates and the accuracy of the
uncertainty estimates of the model predictions. First, we compared the ""ground
truth"" data sources on daily deaths against which these models were trained.
Three different data sources were used by these models, and these had
substantial differences in recorded daily death counts. Two additional data
sources that we examined also provided different death counts per day. For
accuracy of prediction, all models fared very poorly. Only 10.2% of the
predictions fell within 10% of their training ground truth, irrespective of
distance into the future. For accurate assessment of uncertainty, only one
model matched relatively well the nominal 95% coverage, but that model did not
start predictions until April 16, thus had no impact on early, major decisions.
For ICU bed utilisation, the IHME model was highly inaccurate; the point
estimates only started to match ground truth after the pandemic wave had
started to wane. We conclude that trustworthy models require trustworthy input
data to be trained upon. Moreover, models need to be subjected to prespecified
real time performance tests, before their results are provided to policy makers
and public health officials.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 02:41:34 GMT""}]","2020-08-12"
"2006.15998","Gaurav Kumar Agarwal","Gaurav Kumar Agarwal, Mohammed Karmoose, Suhas Diggavi, Christina
  Fragouli, Paulo Tabuada","Distortion based Light-weight Security for Cyber-Physical Systems","arXiv admin note: substantial text overlap with arXiv:1809.04580","Transactions in Automatic Control 2020",,,"cs.IT cs.CR math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Cyber-Physical Systems (CPS), inference based on communicated data is of
critical significance as it can be used to manipulate or damage the control
operations by adversaries. This calls for efficient mechanisms for secure
transmission of data since control systems are becoming increasingly
distributed over larger geographical areas. Distortion based security, recently
proposed as one candidate for secure transmissions in CPS, is not only more
appropriate for these applications but also quite frugal in terms of prior
requirements on shared keys. In this paper, we propose distortion-based metrics
to protect CPS communication and show that it is possible to confuse
adversaries with just a few bits of pre-shared keys. In particular, we will
show that a linear dynamical system can communicate its state in a manner that
prevents an eavesdropper from accurately learning the state.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 23:41:41 GMT""}]","2020-06-30"
"2006.16000","Se\c{c}il Tokg\""oz","Franklin D. Tall, Stevo Todorcevic, Se\c{c}il Tokg\""oz","The Strength of Menger's Conjecture","arXiv admin note: text overlap with arXiv:1803.08578",,,,"math.GN math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Menger conjectured that subsets of R with the Menger property must be
${\sigma}$-compact. While this is false when there is no restriction on the
subsets of R, for projective subsets it is known to follow from the Axiom of
Projective Determinacy, which has considerable large cardinal consistency
strength. We note that in fact, Menger's conjecture for projective sets has
consistency strength of only an inaccessible cardinal.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:01:18 GMT""}]","2020-06-30"
"2006.16001","Anderson Barbosa A. L. R. Barbosa","Eucymara F. N. Santosa, Anderson L. R. Barbosa, Paulo J. Duarte-Neto","Global correlation matrix spectra of the surfacetemperature of the
  Oceans from Random MatrixTheory to Poisson fluctuations","Accepted for publication in Physics Letters A","Physics Letters A 384, 126689 (2020)","10.1016/j.physleta.2020.126689",,"physics.ao-ph nlin.CD physics.app-ph physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we use the random matrix theory (RMT) to correctly describethe
behavior of spectral statistical properties of the sea surface temperatureof
oceans. This oceanographic variable plays an important role in theglobalclimate
system. The data were obtained from National Oceanic and Atmo-spheric
Administration (NOAA) and delimited for the period 1982 to 2016.The results
show that oceanographic systems presented specific $\beta$ values thatcan be
used to classify each ocean according to its correlation behavior.
Thenearest-neighbors spacing of correlation matrix for north, central and south
ofthe three oceans get close to a RMT distribution. However, the regions
delim-ited in the Antarctic pole exhibited the distribution of the
nearest-neighborsspacing well described by the Poisson model, which shows
astatistical changeof RMT to Poisson fluctuations.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 17:53:29 GMT""}]","2020-07-07"
"2006.16002","Samina S. Masood","Samina Masood","QED Plasma at Extremely High Temperature and Density","12 pages. arXiv admin note: substantial text overlap with
  arXiv:1801.07835",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use the renormalization scheme of QED (Quantum Electrodynamics) in
real-time formalism to calculate the effective parameters of the theory,
indicating the existence of relativistic QED plasma at extremely high
temperatures and extremely high densities. High-density plasma is found inside
the stellar cores and high temperature QED plasma could only exist, right after
the neutrino decoupling temperature in the early universe, before the
nucleosynthesis is complete. Radiation couples with the medium through the
vacuum polarization in a hot and dense medium. Calculating the vacuum
polarization tensor in a medium, the effect of radiation on matter is
investigated in such a medium. We explicitly compute the parameters of QED
plasma such as plasma frequency, Debye shielding length and the propagation
frequency in terms of temperature and density of the superhot and superdense
medium, respectively. This study helps to understand short term existence of
QED plasma in the superhot and superdense systems.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 16:01:04 GMT""}]","2020-06-30"
"2006.16046","Ettore Vicari","Claudio Bonati, Alessio Franchi, Andrea Pelissetto, Ettore Vicari","Asymptotic low-temperature critical behavior of two-dimensional
  multiflavor lattice SO(Nc) gauge theories","8 pages. arXiv admin note: text overlap with arXiv:2001.07386","Phys. Rev. D 102, 034512 (2020)","10.1103/PhysRevD.102.034512",,"hep-lat cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the interplay between global and local gauge nonabelian symmetries
in lattice gauge theories with multicomponent scalar fields. We consider
two-dimensional lattice scalar nonabelian gauge theories with a local SO(Nc)
(Nc >= 3) and a global O(Nf) invariance, obtained by partially gauging a
maximally O(Nf x Nc)-symmetric multicomponent scalar model. Correspondingly,
the scalar fields belong to the coset S(Nf Nc-1)/SO(Nc), where S(N) is the
N-dimensional sphere. In agreement with the Mermin-Wagner theorem, these
lattice SO(Nc) gauge models with Nf >= 3 do not have finite-temperature
transitions related to the breaking of the global nonabelian O(Nf) symmetry.
However, in the zero-temperature limit they show a critical behavior
characterized by a correlation length that increases exponentially with the
inverse temperature, similarly to nonlinear O(N) sigma models. Their universal
features are investigated by numerical finite-size scaling methods. The results
show that the asymptotic low-temperature behavior belongs to the universality
class of the two-dimensional RP(Nf-1) model.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:49:31 GMT""}]","2020-09-02"
"2006.16047","Yukio Ohsawa","Yukio Ohsawa, Masaharu Tsubokura","Stay with Your Community: Bridges between Clusters Trigger Expansion of
  COVID-19","22 pages, 9 figures, 4 Tables. arXiv admin note: text overlap with
  arXiv:2004.09372","PLOS ONE
  https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0242766 :
  embargo till ET14:00 (US), 3 Dec 2020","10.1371/journal.pone.0242766",,"cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  The spreading of virus infection is here simulated over artificial human
networks. The real-space urban life of people is modeled as a modified
scale-free network with constraints. A scale-free network has been adopted in
several studies for modeling on-line communities so far but is modified here
for the aim to represent peoples' social behaviors where the generated
communities are restricted reflecting the spatiotemporal constraints in the
real life. Furthermore, the networks have been extended by introducing multiple
cliques in the initial step of network construction and enabling people to
zero-degree people as well as popular (large degree) people. As a result, four
findings and a policy proposal have been obtained. First, the ""second waves""
occur without external influence or constraints on contacts or the releasing of
the constraints. These second waves, mostly lower than the first wave, implies
the bridges between infected and fresh clusters may trigger new expansions of
spreading. Second, if the network changes the structure on the way of infection
spreading or after its suppression, the peak of the second wave can be larger
than the first. Third, the peak height in the time series depends on the
difference between the upper bound of the number of people each member accepts
to meet and the number of people one chooses to meet. This tendency is observed
for two kinds of artificial networks and implies the impact of the bridges
between communities on the virus spreading. Fourth, the release of once given
constraint may trigger a second wave higher than the peak of the time series
without introducing any constraint from the beginning, if the release is
introduced at a time close to the peak. Thus, both governments and individuals
should be careful in returning to human society with inter-community contacts.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:00:38 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jul 2020 02:43:25 GMT""}]","2020-12-03"
"2006.16049","Ibrahima Bakayoko","Ibrahima Bakayoko and Ismail Laraiedh","Constructions and generalised derivations of multiplicative n-BiHom-Lie
  color algebras","arXiv admin note: text overlap with arXiv:1912.10216; text overlap
  with arXiv:1004.2080, arXiv:2003.01080, arXiv:1601.02356 by other authors",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is introduce and give some constructions results and
examples of n-BiHom-Lie color algebras. Next, we introduce the definition of
BiHom-modules over n- BiHom-Lie color algebras and we provide some properties.
Moreover we investigate generalized derivations of n-BiHom-Lie color algebras
and their BiHom-subalgebras.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:37:30 GMT""}]","2020-06-30"
"2006.16050","Matheus Lazo Lazo","A. G. Goulart and M. J. Lazo and J. M. S. Suarez","A deformed derivative model for turbulent diffusion of contaminants in
  the atmosphere","accepted in Physica A. arXiv admin note: substantial text overlap
  with arXiv:1812.02038",,"10.1016/j.physa.2020.124847",,"physics.flu-dyn physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present work, we propose an advection-diffusion equation with
Hausdorff deformed derivatives to stud the turbulent diffusion of contaminants
in the atmosphere. We compare the performance of our model to fit experimental
data against models with classical and Caputo fractional derivatives. We found
that the Hausdorff equation gives better results than the tradition
advection-diffusion equation when fitting experimental data. Most importantly,
we show that our model and the Caputo fractional derivative model display a
very similar performance for all experiments. This last result indicates that
regardless of the kind of non-classical derivative we use, an
advection-diffusion equation with non-classical derivative displaying power-law
mean square displacement is more adequate to describe the diffusion of
contaminants in the atmosphere than a model with classical derivatives.
Furthermore, since Hausdorff derivatives can be related to several deformed
operators, and since differential equations with the Hausdorff derivatives are
easier to solve than equations with Caputo and other non-local fractional
derivatives, our result highlights the potential of deformed derivative models
to describe the diffusion of contaminants in the atmosphere.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:36:55 GMT""}]","2020-06-30"
"2006.16052","Francisco Sebastian Ponciano-Ojeda","Francisco S. Ponciano-Ojeda, Fraser D. Logue and Ifan G. Hughes","Absorption spectroscopy and Stokes polarimetry in a $^{87}$Rb vapour in
  the Voigt geometry with a 1.5 T external magnetic field","10 pages; submitted to J. Phys. B. arXiv admin note: text overlap
  with arXiv:1810.01135",,"10.1088/1361-6455/abc7ff",,"physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  We present a detailed spectroscopic investigation of a thermal $^{87}$Rb
atomic vapour in a magnetic field of 1.5~T in the Voigt geometry. We fit
experimental spectra for all Stokes parameters with our theoretical model
\textit{ElecSus} and find very good quantitative agreement, with RMS errors of
$\sim 1.5$\% in all cases. We extract the magnetic field strength and the angle
between the polarisation of the light and the magnetic field from the atomic
signal, and we measure the birefringence effects of the cell windows on the
optical rotation signals. This allows us to carry out precise measurements at a
high field strength and arbitrary geometries, allowing further development of
possible areas of application for atomic magnetometers.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:16:37 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jan 2021 10:27:56 GMT""}]","2021-01-12"
"2006.16053","Helmut L\""anger","Ivan Chajda and Helmut L\""anger","Consistent posets","arXiv admin note: text overlap with arXiv:2006.04417",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce so-called consistent posets which are bounded posets with an
antitone involution ' where the lower cones of x,x' and of y,y' coincide
provided x,y are different form 0,1 and, moreover, if x,y are different form 0
then their lower cone is different form 0, too. We show that these posets can
be represented by means of commutative meet-directoids with an antitone
involution satisfying certain identities and implications. In the case of a
finite distributive or strongly modular consistent poset, this poset can be
converted into a residuated structure and hence it can serve as an algebraic
semantics of a certain non-classical logic with unsharp conjunction and
implication. Finally we show that the Dedekind-MacNeille completion of a
consistent poset is a consistent lattice, i.e. a bounded lattice with an
antitone involution satisfying the above mentioned properties.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:51:29 GMT""}]","2020-06-30"
"2006.16054","Nobutaka Nakazono","Nalini Joshi and Nobutaka Nakazono","Reduction of quad-equations consistent around a cuboctahedron I:
  additive case","arXiv admin note: text overlap with arXiv:1906.06650",,,,"nlin.SI math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider a reduction of a new system of partial difference
equations, which was obtained in our previous paper (Joshi and Nakazono,
arXiv:1906.06650) and shown to be consistent around a cuboctahedron. We show
that this system reduces to $A_2^{(1)\ast}$-type discrete Painlev\'e equations
by considering a periodic reduction of a three-dimensional lattice constructed
from overlapping cuboctahedra.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:23:50 GMT""}]","2020-06-30"
"2006.16070","Alexandru Maries","Ryan Sayer, Alexandru Maries, and Chandralekha Singh","Quantum interactive learning tutorial on the double-slit experiment to
  improve student understanding of quantum physics","20 pages, 7 figures","Physical Review PHYSICS EDUCATION RESEARCH 13, 010123 (2017)","10.1103/PhysRevPhysEducRes.13.010123",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning quantum mechanics is challenging, even for upper-level undergraduate
and graduate students. Research-validated interactive tutorials that build on
students' prior knowledge can be useful tools to enhance student learning. We
have been investigating student difficulties with quantum mechanics pertaining
to the double-slit experiment in various situations that appear to be
counterintuitive and contradict classical notions of particles and waves. For
example, if we send single electrons through the slits, they may behave as a
""wave"" in part of the experiment and as a ""particle"" in another part of the
same experiment. Here we discuss the development and evaluation of a
research-validated Quantum Interactive Learning Tutorial (QuILT) which makes
use of an interactive simulation to improve student understanding of the
double-slit experiment and strives to help students develop a good grasp of
foundational issues in quantum mechanics. We discuss common student
difficulties identified during the development and evaluation of the QuILT and
analyze the data from the pretest and post test administered to the upper-level
undergraduate and first-year physics graduate students before and after they
worked on the QuILT to assess its effectiveness. These data suggest that on
average, the QuILT was effective in helping students develop a more robust
understanding of foundational concepts in quantum mechanics that defy classical
intuition using the context of the double-slit experiment. Moreover, the
upper-level undergraduates outperformed physics graduate students on the post
test. One possible reason for this difference in performance may be the level
of student engagement with the QuILT due to the grade incentive. In the
undergraduate course, the post test was graded for correctness while in the
graduate course, it was only graded for completeness.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:45:49 GMT""}]","2020-06-30"
"2006.16071","Alexandru Maries","Alexandru Maries, Shih-Yin Lin, and Chandralekha Singh","The impact of students' epistemological framing on a task requiring
  representational consistency","4 pages, 2 figures","Proceedings of the 2016 Physics Education Research Conference,
  Sacramento, CA, 212-215","10.1119/perc.2016.pr.048",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to flexibly transform between different representations (e.g.,
from mathematical to graphical representations) of the same concept is a
hallmark of expertise. Prior research suggests that many introductory physics
students show lack of representational consistency, e.g., they may construct
two representations of the same concept in the same situation that are
inconsistent with one another. In this case study, we asked students to
construct two representations for the electric field for a situation involving
Gauss's law with spherical symmetry (charge conducting sphere surrounded by
charged conducting spherical shell). Prior research also suggests that this
type of problem results in many students constructing representations that are
not consistent with one another. Here we present findings from individual
interviews with three students about this problem which suggest that students'
lack of representational consistency may be partly attributed to the type of
knowledge that the graphical and mathematical representations trigger. In the
epistemic games framework terminology, the two representations students are
asked to construct (mathematical vs. graphical) in the problem may contribute
to their lack of representational consistency.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:11:49 GMT""}]","2020-06-30"
"2006.16093","Jack Morava","Jack Morava","What $Ell$ sees that $K$ doesn't (when $p >3$)","A spin-off from the May 2020 Perimeter Institute conference on
  elliptic cohomology and physics. Thanks to the conference organizers, and
  especially to Andrew Baker, Nitu Kitchloo, and Ken Ono for conversations and
  help with this note",,,,"math.AT math.NT","http://creativecommons.org/publicdomain/zero/1.0/","  We use Andrew Baker's analysis of the cofiber of the endomorphism of the
$p$-adic elliptic spectrum ($p>3$) defined by multiplication by the `Hasse
invariant' $E_{p-1}$ to present its completion away from the locus of ordinary
elliptic curves as a sum of roughly $p/12$ copies (indexed by supesingular
elliptic curves) of $p$-adic lifts of the height two mod $p$ cohomology theory
$K(2)$. See a recent paper of Zhu Yifei for a much deeper exploration of the
topics considered in this note.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:32:59 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jul 2020 14:14:28 GMT""}]","2020-07-07"
"2006.16098","Chen Wu","Chen Wu, Yinong Guo, Haonan Guo, Jingwen Yuan, Lixiang Ru, Hongruixuan
  Chen, Bo Du, Liangpei Zhang","An Investigation of Traffic Density Changes inside Wuhan during the
  COVID-19 Epidemic with GF-2 Time-Series Images","35 pages, 9 figures, submitted to International Journal of Applied
  Earth Observation and Geoinformation",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to mitigate the spread of COVID-19, Wuhan was the first city to
implement strict lockdown policy in 2020. Even though numerous researches have
discussed the travel restriction between cities and provinces, few studies
focus on the effect of transportation control inside the city due to the lack
of the measurement and available data in Wuhan. Since the public transports
have been shut down in the beginning of city lockdown, the change of traffic
density is a good indicator to reflect the intracity population flow.
Therefore, in this paper, we collected time-series high-resolution remote
sensing images with the resolution of 1m acquired before, during and after
Wuhan lockdown by GF-2 satellite. Vehicles on the road were extracted and
counted for the statistics of traffic density to reflect the changes of human
transmissions in the whole period of Wuhan lockdown. Open Street Map was used
to obtain observation road surfaces, and a vehicle detection method combing
morphology filter and deep learning was utilized to extract vehicles with the
accuracy of 62.56%. According to the experimental results, the traffic density
of Wuhan dropped with the percentage higher than 80%, and even higher than 90%
on main roads during city lockdown; after lockdown lift, the traffic density
recovered to the normal rate. Traffic density distributions also show the
obvious reduction and increase throughout the whole study area. The significant
reduction and recovery of traffic density indicates that the lockdown policy in
Wuhan show effectiveness in controlling human transmission inside the city, and
the city returned to normal after lockdown lift.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:30:12 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 07:26:58 GMT""}]","2021-07-16"
"2006.16184","Lilla Lugosi","L. Lugosi, T. Kov\'acs","Diffusion and escape times in the open-leaky standard map","8 pages, 11 figures","Phys. Rev. E 102, 042202 (2020)","10.1103/PhysRevE.102.042202",,"cond-mat.stat-mech nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the connection between transport phenomenon and escape rate
statistics in two-dimensional standard map. For the purpose of having an open
phase space, we let the momentum co-ordinate vary freely and restrict only
angle with periodic boundary condition. We also define a pair of artificial
holes placed symmetrically along the momentum axis where the particles might
leave the system. As a consequence of the leaks the diffusion can be analysed
making use of only the ensemble of survived particles. We present how the
diffusion coefficient depends on the size and position of the escape regions.
Since the accelerator modes and, thus, the diffusion are strongly related to
the system's control parameter, we also investigate effects of the perturbation
strength. Numerical simulations show that the short-time escape statistics does
not follow the well-known exponential decay especially for large values of
perturbation parameters. The analysis of the escape direction also supports
this picture as a significant amount of particles skip the leaks and leave the
system just after a longtime excursion in the remote zones of the phase space.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:32:41 GMT""}]","2020-10-07"
"2006.16750","Yury Tchuvil'sky","D. M. Rodkin and Yu. M. Tchuvil'sky","Description of alpha-clustering of 8Be nucleus states in high-precision
  theoretical approach","12 pages, 5 figures, 6 tables. arXiv admin note: text overlap with
  arXiv:2006.14839",,"10.1088/1674-1137/abb4d4",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scrupulous theoretical study of 8Be nucleus states, both clustered and
non-clustered, is performed over a wide range of the excitation energies. The
quantities which characterize the degree of the alpha-clustering of these
states: spectroscopic factors, cluster form factors as well as the alpha-decay
widths are computed in the framework of an accurate ab initio approach
developed. Other basic properties of 8Be spectrum: the binding and excitation
energies, mean values of the isospin are calculated simultaneously. In the
majority of instances the results of the computations turn out to be in a good
agreement with the spectroscopic data. A number of predictions are made and
corresponding verification experiment is proposed. Prospects of the developed
approach for nuclear spectroscopy are demonstrated.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:49:06 GMT""}]","2020-12-30"
"2006.16753","Alexandru Maries","Alexandru Maries and Chandralekha Singh","Exploring pedagogical content knowledge of physics instructors using the
  force concept inventory","4 pages. arXiv admin note: substantial text overlap with
  arXiv:1307.7177","Proceedings of the 6th International Conference on Women in
  Physics, Birmingham, UK, AIP Conf. Proc. Melville NY 2109, 120002 (pp. 1-4)
  (2019)","10.1063/1.5110146",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Force Concept Inventory (FCI) has been widely used to assess student
understanding of introductory mechanics concepts by educators and physics
education researchers. Many of the items on the FCI have strong distractor
choices corresponding to students' alternate conceptions in mechanics.
Instruction is unlikely to be effective if instructors do not explicitly take
into account students' initial knowledge state in their instructional design.
We discuss research involving the FCI to evaluate the pedagogical content
knowledge of instructors of varying teaching experience. For each item on the
FCI, instructors were asked to identify the most common incorrect answer choice
of introductory physics students. We also discussed the responses individually
with some instructors. Then we used the FCI pre-test and post-test data from a
large population (~900) of introductory students to assess the pedagogical
content knowledge of the physics instructors related to the FCI. While the
physics instructors, on average, performance better than random guessing at
identifying introductory students' difficulties with FCI content, they did not
identify many common difficulties of introductory physics students. Moreover,
the ability to correctly identify students' difficulties was not correlated
with the teaching experience of instructors.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:52:47 GMT""}]","2020-07-01"
"2006.16842","Alexandru Maries","Alexandru Maries, Shih-Yin Lin, and Chandralekha Singh","Challenges in designing appropriate scaffolding to improve students'
  representational consistency: The case of a Gauss's law problem","14 pages, 7 figures",,"10.1103/PhysRevPhysEducRes.13.020103",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prior research suggest that introductory physics students have difficulty
with graphing and interpreting graphs. Here, we discuss an investigation of
student difficulties in translating between mathematical and graphical
representations for a problem in electrostatics and the effect of increasing
levels of scaffolding on students' representational consistency. Students in
calculus-based introductory physics were given a typical problem that can be
solved using Gauss's law involving a spherically symmetric charge distribution
in which they were asked to write a mathematical expression for the electric
field in various regions and then plot the electric field. In study 1, we found
that students had great difficulty in plotting the electric field as a function
of the distance from the center of the sphere consistent with the mathematical
expressions in various regions, and interviews with students suggested possible
reasons which may account for this difficulty. Therefore, in study 2, we
designed two scaffolding interventions with levels of support which built on
each other (i.e., the second scaffolding level built on the first) in order to
help students plot their expressions consistently and compared the performance
of students provided with scaffolding with a comparison group which was not
given any scaffolding support. Analysis of student performance with different
levels of scaffolding reveals that scaffolding from an expert perspective
beyond a certain level may sometimes hinder student performance and students
may not even discern the relevance of the additional support. We provide
possible interpretations for these findings based on in-depth, think-aloud
interviews.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:33:09 GMT""}]","2020-07-01"
"2006.16843","Alexandru Maries","Alexandru Maries, Ryan Sayer, and Chandralekha Singh","Effectiveness of interactive tutorials in promoting ""which-path""
  information reasoning in advanced quantum mechanics","18 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:2005.07560","Physical Review PHYSICS EDUCATION RESEARCH 13, 020115 (2017)","10.1103/PhysRevPhysEducRes.13.020115",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have been investigating advanced students' learning of quantum mechanics
concepts and have developed interactive tutorials which strive to help students
learn these concepts. Two such tutorials, focused on the Mach-Zehnder
interferometer (MZI) and the double-slit experiment (DSE), help students learn
how to use the concept of ""which-path"" information to reason about the presence
or absence of interference in these two experiments in different situations.
After working on a pretest that asked students to predict interference in the
MZI with single photons and polarizers of various orientations placed in one or
both paths of the MZI, students worked on the MZI tutorial which, among other
things, guided them to reason in terms of which-path information in order to
predict interference in similar situations. We investigated the extent to which
students were able to use reasoning related to which-path information learned
in the MZI tutorial to answer analogous questions on the DSE (before working on
the DSE tutorial). After students worked on the DSE pretest they worked on a
DSE tutorial in which they learned to use the concept of which-path information
to answer questions about interference in the DSE with single particles with
mass sent through the two slits and a monochromatic lamp placed between the
slits and the screen. We investigated if this additional exposure to the
concept of which-path information promoted improved learning and performance in
the DSE questions with single photons and polarizers placed after one or both
slits. We find evidence that both tutorials promoted which-path information
reasoning and helped students use this reasoning appropriately in contexts
different from the ones in which they had learned it.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 20:44:46 GMT""}]","2020-07-01"
"2006.16845","Xiaoming Li","Xiaoming Li, Chun Wang, Xiao Huang, Yimin Nie","A GRU-based Mixture Density Network for Data-Driven Dynamic Stochastic
  Programming",,,,,"eess.SP cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The conventional deep learning approaches for solving time-series problem
such as long-short term memory (LSTM) and gated recurrent unit (GRU) both
consider the time-series data sequence as the input with one single unit as the
output (predicted time-series result). Those deep learning approaches have made
tremendous success in many time-series related problems, however, this cannot
be applied in data-driven stochastic programming problems since the output of
either LSTM or GRU is a scalar rather than probability distribution which is
required by stochastic programming model. To fill the gap, in this work, we
propose an innovative data-driven dynamic stochastic programming (DD-DSP)
framework for time-series decision-making problem, which involves three
components: GRU, Gaussian Mixture Model (GMM) and SP. Specifically, we devise
the deep neural network that integrates GRU and GMM which is called GRU-based
Mixture Density Network (MDN), where GRU is used to predict the time-series
outcomes based on the recent historical data, and GMM is used to extract the
corresponding probability distribution of predicted outcomes, then the results
will be input as the parameters for SP. To validate our approach, we apply the
framework on the car-sharing relocation problem. The experiment validations
show that our framework is superior to data-driven optimization based on LSTM
with the vehicle average moving lower than LSTM.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:42:59 GMT""}]","2020-07-01"
"2006.16846","Alexandru Maries","Alexandru Maries, Nafis I. Karim, and Chandralekha Singh","Is agreeing with a gender stereotype correlated with the performance of
  female students in introductory physics?",,,,,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several prior studies in introductory physics have found a gender gap on
conceptual assessments such as the Force Concept Inventory (FCI) and the
Conceptual Survey of Electricity and Magnetism (CSEM) with male students
performing better than female students. Moreover, prior studies in the context
of mathematics have also found that activation of a negative stereotype about a
group can lead to deteriorated performance of the stereotyped group. Here, we
describe two studies in which we investigated the impact of interventions on
the gender gap on the FCI and CSEM in large introductory physics courses at a
large research university. In the first study, we investigated whether asking
introductory physics students to indicate their gender immediately before
taking the CSEM increased the gender gap compared to students who were not
asked for this information. We found no difference in performance between male
and female students in the two conditions. In the second study, conducted with
several thousand introductory physics students, we investigated the prevalence
of the belief that men generally perform better in physics than women and the
extent to which this belief is correlated with the performance of both female
and male students on the FCI and the CSEM in introductory physics courses. We
found that at the end of the year-long calculus-based introductory physics
sequence, in which female students are significantly underrepresented, agreeing
with a gender stereotype was correlated negatively with the performance of
female students on the conceptual physics surveys. The fact that female
students who agreed with the gender stereotype performed worse than female
students who disagreed with it at the end of the year-long calculus-based
physics course may partly be due to an increased stereotype threat that female
students who agree with the stereotype may experience in this course.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:44:01 GMT""}]","2020-07-01"
"2006.16900","Anita Graser","Anita Graser, Esteban Zim\'anyi, Krishna Chaitanya Bommakanti","From Simple Features to Moving Features and Beyond?","6 pages, 4 figures, originally prepared for GIScience2020 (which was
  postponed to 2021)",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mobility data science lacks common data structures and analytical functions.
This position paper assesses the current status and open issues towards a
universal API for mobility data science. In particular, we look at
standardization efforts revolving around the OGC Moving Features standard
which, so far, has not attracted much attention within the mobility data
science community. We discuss the hurdles any universal API for movement data
has to overcome and propose key steps of a roadmap that would provide the
foundation for the development of this API.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 08:02:41 GMT""}]","2020-07-01"
"2006.16907","Konstantin Zioutas","K. Zioutas, G. Cantatore, M. Karuza, A. Kryemadhi, M. Maroudas, Y.K.
  Semertzidis","Response-suggestion to The XENON1T excess: an overlooked dark matter
  signature?","1 page",,,,"hep-ph astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main alternatives of the recent XENON1T observation are solar axions,
neutrino magnetic moment and tritium. In this short note we suggest to
crosscheck whether the observation is related or not to dark matter (DM)
streams, by searching for planetary dependence of the observed excess. If such
a correlation is derived, this hint (<3.5sigma) can become the overlooked
direct DM discovery. To do this it is necessary to analyze the time
distribution of all the XENON1T data, and in particular the electronic events
with their time stamp and energy. Notably, the velocities of the dark sector
allow for planetary focusing effects towards the earth either by a single
celestial body or combined by the whole solar system. Surprisingly, as yet this
possibility has not been applied in the field of direct dark matter search,
even though DM velocities fit-in well planetary gravitational lensing effects.
The widely used signature of a direct dark matter search needs to be redefined,
while, with luck, such an analysis might confirm or exclude the solar origin of
the observed excess. Therefore, we suggest that XENON1T and DAMA release the
data.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:28:58 GMT""}]","2020-07-01"
"2006.16967","Alireza Ghasemi","Alireza Ghasemi and Amina Chebira","Lest We Forget: A Dataset of Coronavirus-Related News Headlines in Swiss
  Media",,,,,"cs.DL cs.CL","http://creativecommons.org/licenses/by/4.0/","  We release our COVID-19 news dataset, containing more than 10,000 links to
news articles related to the Coronavirus pandemic published in the Swiss media
since early January 2020. This collection can prove beneficial in mining and
analysis of the reaction of the Swiss media and the COVID-19 pandemic and
extracting insightful information for further research. We hope this dataset
helps researchers and the public deliver results that will help analyse the
pandemic and potentially lead to a better understanding of the events.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 19:43:13 GMT""}]","2020-07-01"
"2007.00428","Yann Cabanes","Fr\'ed\'eric Barbaresco, Yann Cabanes (IMB)","The Basic Geometric Structures of Electromagnetic Digital Information:
  Statistical characterization of the digital measurement of spatio-Doppler and
  polarimetric fluctuations of the radar electromagnetic wave","in French, JS19, Mar 2019, Guyancourt, France",,,,"eess.SP cs.IT cs.LG math.DG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim is to describe new geometric approaches to define the statistics of
spatio-temporal and polarimetric measurements of the states of an
electromagnetic wave, using the works of Maurice Fr{\'e}chet, Jean-Louis Koszul
and Jean-Marie Souriau, with in particular the notion of 'average' state of
this digital measurement as a Fr{\'e}chet barycentre in a metric space and a
model derived from statistical mechanics to define and calculate a maximum
density of entropy (extension of the notion of Gaussian) to describe the
fluctuations of the electromagnetic wave. The article will illustrate these new
tools with examples of radar application for Doppler, spatio-temporal and
polarimetric measurement of the electromagnetic wave by introducing a distance
on the covariance matrices of the electromagnetic digital signal, based on
Fisher's metric from Information Geometry.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 07:47:18 GMT""}]","2020-07-02"
"2007.00434","Mehmet Aktas","Mehmet Emin Aktas, Esra Akbas","Graph Classification via Heat Diffusion on Simplicial Complexes",,,,,"cs.SI math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the graph classification problem in vertex-labeled
graphs. Our main goal is to classify the graphs comparing their higher-order
structures thanks to heat diffusion on their simplices. We first represent
vertex-labeled graphs as simplex-weighted super-graphs. We then define the
diffusion Frechet function over their simplices to encode the higher-order
network topology and finally reach our goal by combining the function values
with machine learning algorithms. Our experiments on real-world bioinformatics
networks show that using diffusion Fr{\'e}chet function on simplices is
promising in graph classification and more effective than the baseline methods.
To the best of our knowledge, this paper is the first paper in the literature
using heat diffusion on higher-dimensional simplices in a graph mining problem.
We believe that our method can be extended to different graph mining domains,
not only the graph classification problem.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 12:46:11 GMT""}]","2020-07-02"
"2007.00481","Alexandru Maries","Alexandru Maries and Chandralekha Singh","Do students benefit from drawing productive diagrams themselves while
  solving introductory physics problems? The case of two electrostatic problems","17 pages, 4 figures","European Journal of Physics 39, 015703 (2018)","10.1088/1361-6404/aa9038",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An appropriate diagram is a required element of a solution building process
in physics problem solving and it can transform a given problem into a
representation that is easier to exploit for solving the problem. A major focus
while helping introductory physics students learn problem solving is to help
them appreciate that drawing diagrams facilitates problem solving. We conducted
an investigation in which two different interventions were implemented during
recitation quizzes throughout the semester in a large enrollment, algebra-based
introductory physics course. Students were either (1) asked to solve problems
in which the diagrams were drawn for them or (2) explicitly told to draw a
diagram. A comparison group was not given any instruction regarding diagrams.
We developed a rubric to score the problem solving performance of students in
different intervention groups. We investigated two problems involving electric
field and electric force and found that students who drew productive diagrams
were more successful problem solvers and that a higher level of relevant detail
in a student's diagram corresponded to a better score. We also conducted
think-aloud interviews with nine students who were at the time taking an
equivalent introductory algebra-based physics course in order to gain insight
into how drawing diagrams affects the problem solving process. These interviews
supported some of the interpretations of the quantitative results. We end by
discussing instructional implications of the findings.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:39:16 GMT""}]","2020-07-02"
"2007.01141","Alexandru Maries","Nafis I Karim, Alexandru Maries, and Chandralekha Singh","Teaching assistants' performance at identifying common introductory
  student difficulties revealed by the conceptual survey of electricity and
  magnetism","4 pages, 3 figures. arXiv admin note: substantial text overlap with
  arXiv:2006.15058","2017 Physics Education Research Conference Proceedings, 208-2011
  (2018)","10.1119/perc.2017.pr.047",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss research involving the Conceptual Survey of Electricity and
Magnetism (CSEM) to evaluate one aspect of the pedagogical content knowledge of
teaching assistants (TAs): the knowledge of introductory students' alternate
conceptions in electricity and magnetism as revealed by the CSEM. For each item
on the CSEM, the TAs were asked to (1) identify the most common incorrect
answer choice of introductory physics students and (2) predict the percentage
of introductory students who would answer the question correctly in a
post-test. Then, we used the CSEM post-test data from approximately 400
introductory physics students (provided in the original paper describing the
CSEM) to assess the extent to which the TAs were able to identify the alternate
conceptions of introductory students related to electricity and magnetism. In
addition, we conducted think-aloud interviews with TAs who had at least two
semester of teaching experience in recitations to explore their reasoning about
this task. We find that the TAs struggled to think about the difficulty of the
questions from introductory students' perspective and they often underestimated
the difficulty of the questions. Moreover, the TAs often expected certain
incorrect answer choices to be common among introductory students when in fact
those answer choices were not common.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 14:48:14 GMT""}]","2020-07-03"
"2007.01144","Jun Yan Dai","Jun Yan Dai, Jin Yang, Wankai Tang, Ming Zheng Chen, Jun Chen Ke,
  Qiang Cheng, Shi Jin, and Tie Jun Cui","Arbitrary manipulations of dual harmonics and their wave behaviors based
  on space-time-coding digital metasurface","21 pages, 6 figures",,"10.1063/5.0017885",,"physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Space-time modulated metasurfaces have attracted significant attention due to
the additional degree of freedom in manipulating the electromagnetic (EM) waves
in both space and time domains. However, the existing techniques have limited
wave control capabilities, leading to just a few feasible schemes like
regulation of only one specific harmonic. Here, we propose to realize
independent manipulations of arbitrarily dual harmonics and their wave
behaviors using a space-time-coding (STC) digital metasurface. By employing
different STC sequences to the reflection phase of the metasurface, independent
phase-pattern configurations of two desired harmonics can be achieved
simultaneously, which further leads to independent beam shaping at the two
harmonic frequencies. An analytical theory is developed to offer the physical
insights in the arbitrary dual-harmonic manipulations of spectra and spatial
beams, which is verified by experiments with good agreements. The presented STC
strategy provides a new way to design multifunctional programmable systems,
which will find potential applications such as cognitive radar and multi-user
wireless communications.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 11:32:36 GMT""}]","2020-12-07"
"2007.01355","Alexandru Maries","Nafis I Karim, Alexandru Maries, and Chandralekha Singh","Impact of evidence-based flipped or active-engagement non-flipped
  courses on student performance in introductory physics","8 pages, 1 figure","Canadian Journal of Physics 96 (4), 411-419 (2018)","10.1139/cjp-2017-0171",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the impact of physics education research-based pedagogical
techniques in flipped and active-engagement non-flipped courses on student
performance on validated conceptual surveys. We compare student performance in
courses that make significant use of evidence-based active engagement (EBAE)
strategies with courses that primarily use lecture-based (LB) instruction. All
courses had large enrollment and often had 100-200 students. The analysis of
data for validated conceptual surveys presented here includes data from large
numbers of students from two-semester sequences of introductory algebra-based
and calculus-based introductory physics courses. The conceptul surveys used to
assess student learning in the first and second semester courses were the Force
Concept Inventory and the Conceptual Survey of Electricity and Magnetism,
respectively. In the research discussed here, the performance of students in
EBAE courses at a particular level is compared with LB courses in two
situations: (i) the same instructor taught two courses, one of which was a
flipped course involving EBAE methods and the other an LB course, while the
homework, recitations, and final exams were kept the same; (ii) student
perforamnce in all of the EBAE courses taught by different instructors was
averaged and compared with LB courses of the same type also averaged over
different instructors. In all classes, we find that students in courses that
make significant use of active-engagement strategies, on average, outperformed
students in courses using primarily LB instruction of the same type on
conceptual surveys even though there was no statistically significant
difference on the pretest before instruction. We also discuss correlation
between the performance on the validated conceptual surveys and the final exam,
which typically placed a heavy weight on quantitative problem solving.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:10:13 GMT""}]","2020-07-06"
"2007.01710","Jean-Francois Pommaret","J.-F. Pommaret","Nonlinear Conformal Electromagnetism and Gravitation","These new nonlinear results question the mathematical foundations of
  both elasticity theory, gauge theory and general relativity",,,,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 1909 the brothers E. and F. Cosserat discovered a new nonlinear group
theoretical approach to elasticity (EL), with the only experimental need to
measure the EL constants. In a modern language, their idea has been to use the
nonlinear Spencer sequence instead of the nonlinear Janet sequence for the Lie
groupoid defining the group of rigid motions of space. Following H. Weyl, our
purpose is to compute for the first time the nonlinear Spencer sequence for the
Lie groupoid defining the conformal group of space-time in order to provide the
physical foundations of both electromagnetism (EM) and gravitation, with the
only experimental need to measure the EM constant in vacuum and the
gravitational constant. With a manifold of dimension $n$, the difficulty is to
deal with the $n$ nonlinear transformations that have been called ""elations"" by
E. Cartan in 1922. Using the fact that dimension $n=4$ has very specific
properties for the computation of the Spencer cohomology, we prove that there
is no conceptual difference between the Cosserat EL field or induction
equations and the Maxwell EM field or induction equations. As a byproduct, the
well known field/matter couplings (piezzoelectricity, photoelasticity, ...) can
be described abstractly, with the only experimental need to measure the
corresponding coupling constants. In the sudy of gravitation, the dimension
$n=4$ also allows to have a conformal factor defined everywhere but at the
central attractive mass and the inversion law of the subgroupoid made by strict
second order jets transforms attraction into repulsion.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 10:52:18 GMT""}]","2020-07-06"
"2007.02311","Alexandru Maries","Alexandru Maries, Nafis I Karim and Chandralekha Singh","The impact of stereotype threat on gender gap in introductory physics","4 pages, i figure. arXiv admin note: substantial text overlap with
  arXiv:2006.16846","2017 Physics Education Research Conference Proceedings, 256-259
  (2018)","10.1119/perc.2017.pr.059.",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many prior studies have found a gender gap between male and female students'
performance on conceptual assessments such as the Force Concept Inventory (FCI)
and the Conceptual Survey of Electricity and Magnetism (CSEM) with male
students performing better than female students. Prior studies have also found
that activation of a negative stereotype about a group or stereotype threat,
e.g., asking test-takers to indicate their ethnicity before taking a test, can
lead to deteriorated performance of the stereotyped group. Here, we describe
two studies in which we investigated the gender gap on the FCI and CSEM. In the
first study, we investigated whether asking students to indicate their gender
immediately before taking hte CSEM increased the gender gap compared to
students who were not asked for this information. In the second study,
conducted with over 1100 introductory physics students, we investigated the
prevalence of the belief that men generally perform better in physics than
women and the extent to which this belief is correlated with the performance of
both the female and male students on the FCI.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 15:13:16 GMT""}]","2020-07-07"
"2007.06637","Ali Ayub","Ali Ayub, Alan R. Wagner","Storing Encoded Episodes as Concepts for Continual Learning","Accepted at ICML2020 (Workshop on Lifelong Learning)",,,,"cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The two main challenges faced by continual learning approaches are
catastrophic forgetting and memory limitations on the storage of data. To cope
with these challenges, we propose a novel, cognitively-inspired approach which
trains autoencoders with Neural Style Transfer to encode and store images.
Reconstructed images from encoded episodes are replayed when training the
classifier model on a new task to avoid catastrophic forgetting. The loss
function for the reconstructed images is weighted to reduce its effect during
classifier training to cope with image degradation. When the system runs out of
memory the encoded episodes are converted into centroids and covariance
matrices, which are used to generate pseudo-images during classifier training,
keeping classifier performance stable with less memory. Our approach increases
classification accuracy by 13-17% over state-of-the-art methods on benchmark
datasets, while requiring 78% less storage space.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 04:15:56 GMT""}]","2020-07-15"
"2007.06708","Todd Murphey","Taosha Fan, Hanlin Wang, Michael Rubenstein and Todd Murphey","CPL-SLAM: Efficient and Certifiably Correct Planar Graph-Based SLAM
  Using the Complex Number Representation",,"IEEE Transactions on Robotics, 2020",,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the problem of planar graph-based simultaneous
localization and mapping (SLAM) that involves both poses of the autonomous
agent and positions of observed landmarks. We present CPL-SLAM, an efficient
and certifiably correct algorithm to solve planar graph-based SLAM using the
complex number representation. We formulate and simplify planar graph-based
SLAM as the maximum likelihood estimation (MLE) on the product of unit complex
numbers, and relax this nonconvex quadratic complex optimization problem to
convex complex semidefinite programming (SDP). Furthermore, we simplify the
corresponding complex semidefinite programming to Riemannian staircase
optimization (RSO) on the complex oblique manifold that can be solved with the
Riemannian trust region (RTR) method. In addition, we prove that the SDP
relaxation and RSO simplification are tight as long as the noise magnitude is
below a certain threshold. The efficacy of this work is validated through
applications of CPL-SLAM and comparisons with existing state-of-the-art methods
on planar graph-based SLAM, which indicates that our proposed algorithm is
capable of solving planar graph-based SLAM certifiably, and is more efficient
in numerical computation and more robust to measurement noise than existing
state-of-the-art methods. The C++ code for CPL-SLAM is available at
https://github.com/MurpheyLab/CPL-SLAM.
","[{""version"":""v1"",""created"":""Thu, 25 Jun 2020 21:17:50 GMT""}]","2020-07-15"
"2007.10285","Yudier Pe\~na P\'erez","Yudier Pe\~na P\'erez, Juan Bory Reyes","Condici\'on de Lorentz y ecuaciones de ondas electromagn\'eticas como
  propiedades emergentes del sistema de Maxwell","in Spanish. The sections were organized in a better way. Revised
  argument in section 4, results unchanged. The reference list has been updated",,,,"physics.class-ph physics.hist-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article deals with the study of electromagnetic waves equations and the
Lorentz condition, as emergent properties of Maxwell's system in the context of
systems theory. To do this, the wave equations and the Helmholtz equation are
first deduced. Using the displaced Dirac operator, which is closely related to
the main vector calculation operators, it is possible to establish a direct
connection between the solutions of the Maxwell time-harmonic system and two
quaternion equations. Also, the application of the Lorentz condition to
transform the time-harmonic Maxwell system into a simple quaternion equation
based on the scalar and vector potentials is exposed.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 06:18:53 GMT""},{""version"":""v2"",""created"":""Mon, 26 Oct 2020 19:48:10 GMT""}]","2020-10-28"
"2008.00084","Junsung Choi","Junsung Choi, Vuk Marojevic, Carl B. Dietrich, Jeffrey H. Reed, and
  Seungyoung Ahn","Survey of Spectrum Regulation for Intelligent Transportation Systems",,,"10.1109/ACCESS.2020.3012788",,"cs.NI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As 5G communication technology develops, vehicular communications that
require high reliability, low latency, and massive connectivity are drawing
increasing interest from those in academia and industry. Due to these
developing technologies, vehicular communication is not limited to vehicle
components in the forms of Vehicle-to-Vehicle (V2V) or
Vehicle-to-Infrastructure (V2I) networks, but has also been extended to connect
with others, such as pedestrians and cellular users. Dedicated Short-Range
Communications (DSRC) is the conventional vehicular communication standard for
Intelligent Transportation Systems (ITS). More recently, the 3rd Generation
Partnership Project introduced Cellular-Vehicle-to-Everything (C-V2X), a
competitor to DSRC. Meanwhile, the Federal Communications Commission
(FCC)issued a Notice of Proposed Rulemaking (NPRM) to consider deploying
Unlicensed National Information Infrastructure (U-NII)devices in the ITS band
with two interference mitigation approaches: Detect-and-Vacate (DAV)and
Re-channelization (Re-CH). With multiple standard options and interference
mitigation approaches, numerous regulatory taxonomies can be identified and
notification of relevant technical challenges issued. However, these challenges
are much broader than the current and future regulatory taxonomies pursued by
the different countries involved. Because their plans differ, the technical and
regulatory challenges vary. This paper presents a literature survey about the
technical challenges, the current and future ITS band usage plans, and the
major research testbeds for the U.S., Europe, China, Korea, and Japan. This
survey shows that the most likely deployment taxonomies are (1) DSRC, C-V2X,
and Wi-Fi with Re-CH; (2) DSRC and C-V2X with interoperation, and (3) C-V2X
only. The most difficult technical challenge is the interoperability between
the Wi-Fi-like DSRC and 4G LTE-like C-V2X.
","[{""version"":""v1"",""created"":""Fri, 26 Jun 2020 13:00:58 GMT""},{""version"":""v2"",""created"":""Tue, 4 Aug 2020 00:56:26 GMT""}]","2020-08-05"
