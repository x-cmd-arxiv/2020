"2006.04550","Aaron Tohuvavohu","Aaron Tohuvavohu, Casey J. Law, Jamie A. Kennea, Elizabeth A. K.
  Adams, Kshitij Aggarwal, Geoffrey Bower, Sarah Burke-Spolaor, Bryan J.
  Butler, John M. Cannon, S. Bradley Cenko, James DeLaunay, Paul Demorest,
  Maria R. Drout, Philip A. Evans, Alec S. Hirschauer, T. J. W. Lazio, Justin
  Linford, Francis E. Marshall, K. McQuinn, Emily Petroff, Evan D. Skillman","A Demonstration of Extremely Low Latency $\gamma$-ray, X-Ray & UV
  Follow-Up of a Millisecond Radio Transient","Technical note and capability update for the community. We encourage
  low latency FRB alerts from relevant facilities to enable this science",,,,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report results of a novel high-energy follow-up observation of a potential
Fast Radio Burst. The radio burst was detected by VLA/realfast and followed-up
by the Neil Gehrels Swift Observatory in very low latency utilizing new
operational capabilities of Swift (arXiv:2005.01751), with pointed soft X-ray
and UV observations beginning at T0+32 minutes, and hard X-ray/gamma-ray event
data saved around T0. These observations are $>10$x faster than previous
X-ray/UV follow-up of any radio transient to date. No emission is seen
coincident with the FRB candidate at T0, with a 0.2s fluence $5\sigma$ upper
limit of $1.35\times10^{-8}$ erg cm$^{-2}$ (14-195 keV) for a SGR
1935+2154-like flare, nor at T0+32 minutes down to $3\sigma$ upper limits of
22.18 AB mag in UVOT u band, and $3.33\times10^{-13}$ erg cm$^{-2}$ s$^{-1}$
from 0.3-10 keV for the 2 ks observation. The candidate FRB alone is not
significant enough to be considered astrophysical, so this note serves as a
technical demonstration. These new Swift operational capabilities will allow
future FRB detections to be followed up with Swift at even lower latencies than
demonstrated here: 15-20 minutes should be regularly achievable, and 5-10
minutes occasionally achievable. We encourage FRB detecting facilities to
release alerts in low latency to enable this science.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:57:12 GMT""}]","2020-06-09"
"2006.04704","Jakub Tarnawski","Silvio Lattanzi, Slobodan Mitrovi\'c, Ashkan Norouzi-Fard, Jakub
  Tarnawski, Morteza Zadimoghaddam","Fully Dynamic Algorithm for Constrained Submodular Optimization",,"NeurIPS 2020","10.5555/3495724.3496808",,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The task of maximizing a monotone submodular function under a cardinality
constraint is at the core of many machine learning and data mining
applications, including data summarization, sparse regression and coverage
problems. We study this classic problem in the fully dynamic setting, where
elements can be both inserted and removed. Our main result is a randomized
algorithm that maintains an efficient data structure with a poly-logarithmic
amortized update time and yields a $(1/2-\epsilon)$-approximate solution. We
complement our theoretical analysis with an empirical study of the performance
of our algorithm.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:00:30 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 21:39:38 GMT""}]","2023-05-26"
"2006.04705","Mauro Salazar","Theo Hofman and Mauro Salazar","Transmission Ratio Design for Electric Vehicles via Analytical Modeling
  and Optimization","5 pages, 4 figures, submitted to the 2020 IEEE Vehicle Power and
  Propulsion Conference",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present an effective analytical modeling approach for the
design of the transmission of electric vehicles. Specifically, we first devise
an analytical loss model for an electric machine and show that it can be
accurately fitted by only sampling three points from the original motor map.
Second, we leverage this model to derive the optimal transmission ratio as a
function of the wheels' speed and torque, and use it to optimize the
transmission ratio. Finally, we showcase our analytical approach with a
real-world case-study comparing two different transmission technologies on a
BMW i3: a fixed-gear transmission (FGT) and a continuously variable
transmission (CVT). Our results show that even for e-machines intentionally
designed for a FGT, the implementation of a CVT can significantly improve their
operational efficiency by more than 3%. The provided model will ultimately
bridge the gap in understanding how to efficiently specify the e-machine and
the transmission technology in an integrated fashion, and enable to effectively
compare single- and multi-speed-based electric powertrains.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:00:47 GMT""}]","2020-06-09"
"2006.04706","Yuting Fang","Yuting Fang, Adam Noel, Andrew W. Eckford, Nan Yang, Jing Guo","Characterization of Cooperators in Quorum Sensing with 2D Molecular
  Signal Analysis","33 pages; 22 figures; submitted for possible publication",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In quorum sensing (QS), bacteria exchange molecular signals to work together.
An analytically-tractable model is presented for characterizing QS signal
propagation within a population of bacteria and the number of responsive
cooperative bacteria (i.e., cooperators) in a two-dimensional (2D) environment.
Unlike prior works with a deterministic topology and a simplified molecular
propagation channel, this work considers continuous emission, diffusion,
degradation, and reception among randomly-distributed bacteria. Using
stochastic geometry, the 2D channel response and the corresponding probability
of cooperation at a bacterium are derived. Based on this probability, new
expressions are derived for the moment generating function and different orders
of moments of the number of cooperators. The analytical results agree with the
simulation results obtained by a particle-based method. In addition, the
Poisson and Gaussian distributions are compared to approximate the distribution
of the number of cooperators and the Poisson distribution provides the best
overall approximation. The derived channel response can be generally applied to
any molecular communication model where single or multiple transmitters
continuously release molecules into a 2D environment. The derived statistics of
the number of cooperators can be used to predict and control the QS process,
e.g., predicting and decreasing the likelihood of biofilm formation.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:00:54 GMT""},{""version"":""v2"",""created"":""Wed, 2 Sep 2020 08:30:38 GMT""}]","2020-09-03"
"2006.04707","Daniel Schiff","Daniel Schiff and Bogdana Rakova and Aladdin Ayesh and Anat Fanti and
  Michael Lennon","Principles to Practices for Responsible AI: Closing the Gap","Preprint draft. A version has been submitted to the 2020 European
  Conference on AI (ECAI) Workshop on ""ADVANCING TOWARDS THE SDGs: ARTIFICIAL
  INTELLIGENCE FOR A FAIR, JUST AND EQUITABLE WORLD (AI4EQ)""",,,,"cs.CY cs.AI","http://creativecommons.org/licenses/by/4.0/","  Companies have considered adoption of various high-level artificial
intelligence (AI) principles for responsible AI, but there is less clarity on
how to implement these principles as organizational practices. This paper
reviews the principles-to-practices gap. We outline five explanations for this
gap ranging from a disciplinary divide to an overabundance of tools. In turn,
we argue that an impact assessment framework which is broad, operationalizable,
flexible, iterative, guided, and participatory is a promising approach to close
the principles-to-practices gap. Finally, to help practitioners with applying
these recommendations, we review a case study of AI's use in forest ecosystem
restoration, demonstrating how an impact assessment framework can translate
into effective and responsible AI practices.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:04:44 GMT""}]","2020-06-09"
"2006.04708","Jean-Paul Allouche","J.-P. Allouche, J. Shallit","On three conjectures of P. Barry","This paper is superseded by a new paper [arXiv:2006.08909] authored
  by J.-P. Allouche, G.-N. Han, and J. Shallit entitled ""On some conjectures of
  P. Barry""",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove three conjectures, related to the paperfolding sequence, in a recent
paper [arXiv:2005.04066] of P. Barry.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:07:37 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 20:10:54 GMT""}]","2020-06-25"
"2006.04709","Qiming Du","Qiming Du, G\'erard Biau, Fran\c{c}ois Petit and Rapha\""el Porcher","Wasserstein Random Forests and Applications in Heterogeneous Treatment
  Effects",,,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new insights into causal inference in the context of Heterogeneous
Treatment Effects by proposing natural variants of Random Forests to estimate
the key conditional distributions. To achieve this, we recast Breiman's
original splitting criterion in terms of Wasserstein distances between
empirical measures. This reformulation indicates that Random Forests are well
adapted to estimate conditional distributions and provides a natural extension
of the algorithm to multivariate outputs. Following the philosophy of Breiman's
construction, we propose some variants of the splitting rule that are
well-suited to the conditional distribution estimation problem. Some
preliminary theoretical connections are established along with various
numerical experiments, which show how our approach may help to conduct more
transparent causal inference in complex situations.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:08:10 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 13:46:07 GMT""},{""version"":""v3"",""created"":""Mon, 15 Feb 2021 09:10:38 GMT""}]","2021-02-16"
"2006.04710","Hyunjik Kim","Hyunjik Kim, George Papamakarios, Andriy Mnih","The Lipschitz Constant of Self-Attention",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lipschitz constants of neural networks have been explored in various contexts
in deep learning, such as provable adversarial robustness, estimating
Wasserstein distance, stabilising training of GANs, and formulating invertible
neural networks. Such works have focused on bounding the Lipschitz constant of
fully connected or convolutional networks, composed of linear maps and
pointwise non-linearities. In this paper, we investigate the Lipschitz constant
of self-attention, a non-linear neural network module widely used in sequence
modelling. We prove that the standard dot-product self-attention is not
Lipschitz for unbounded input domain, and propose an alternative L2
self-attention that is Lipschitz. We derive an upper bound on the Lipschitz
constant of L2 self-attention and provide empirical evidence for its asymptotic
tightness. To demonstrate the practical relevance of our theoretical work, we
formulate invertible self-attention and use it in a Transformer-based
architecture for a character-level language modelling task.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:08:38 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 14:13:40 GMT""}]","2021-06-10"
"2006.04711","Payman Rasekh","Payman Rasekh and Akbar Safari and Murat Yildirim and Ravi Bhardwaj
  and Jean-Michel M\'enard and Ksenia Dolgaleva and Robert W. Boyd","Terahertz Nonlinear Optical Response of Water Vapor",,,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the nonlinear spectroscopy of water vapor at THz frequencies.
Atmospheric water vapor has a rich spectrum with several strong resonances at
frequencies below 3 THz, falling within the range of operation of most existing
THz sources. We observe an extremely large nonlinear response to THz radiation
at the positions of these resonances. Using the optical Kerr model for the
nonlinear response, we estimate a minimum nonlinear refractive index of the
order of 10^2 m^2/W. Our results provide insight into the energy levels of the
water molecule and give a more accurate picture of its response to
electromagnetic radiation, paving the way to more accurate THz spectroscopy,
imaging and sensing systems, and thereby facilitating future emerging THz
technologies.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:09:29 GMT""}]","2020-06-09"
"2006.04712","Damien Busatto-Gaston","Damien Busatto-Gaston, Debraj Chakraborty, Jean-Francois Raskin","Monte Carlo Tree Search guided by Symbolic Advice for MDPs",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the online computation of a strategy that aims at
optimizing the expected average reward in a Markov decision process. The
strategy is computed with a receding horizon and using Monte Carlo tree search
(MCTS). We augment the MCTS algorithm with the notion of symbolic advice, and
show that its classical theoretical guarantees are maintained. Symbolic advice
are used to bias the selection and simulation strategies of MCTS. We describe
how to use QBF and SAT solvers to implement symbolic advice in an efficient
way. We illustrate our new algorithm using the popular game Pac-Man and show
that the performances of our algorithm exceed those of plain MCTS as well as
the performances of human players.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:11:10 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 13:15:17 GMT""}]","2020-07-17"
"2006.04713","Nadeem Malik A","M. Syed Usama and Nadeem A. Malik","A Comparison of Turbulence Generated by 3DS Sparse Grids With Different
  Blockage Ratios and Different Co-Frame Arrangements","10 pages; 21 figures; Submitted to Recent Advances in Mathematical
  and Statistical Methods, Springer, Eds. D. Kilgour, H. Kunze, R. Makarov, R.
  Melnik and S. Wang",,,,"physics.flu-dyn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new type of grid turbulence generator, the 3D sparse grid (3DS), is a
co-planar arrangement of co-frames each containing a different length scale of
grid elements [Malik, N. A. US Patent No. US 9,599,269 B2 (2017)] and
possessing a much bigger parameter space than the flat 2D fractal square grid
(2DF). Using DNS we compare the characteristics of the turbulence (mean flow,
turbulence intensity, energy spectrum) generated by different types of 3DS
grids. The peak intensities generated by 3DS can exceed the peaks generated by
the 2DF by 80\%; we observe that a 3DS with blockage ratio 24\% produces
turbulence similar to the 2DF with blockage ratio 32\% implying lower energy
input for the same turbulence.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:11:25 GMT""}]","2020-06-09"
"2006.04714","Erhard Seiler","Erhard Seiler","Complex Langevin: Boundary terms at poles","17 pages, 5 figures. Section 6.2. and some eferences added; several
  typos corrected. Version as published","Phys. Rev. D 102, 094507 (2020)","10.1103/PhysRevD.102.094507","MPP-2020-90","hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the problem of possible boundary terms at poles of the drift in
the complex Langevin method, which spoil correctness of the method. For the
simplest, however paradigmatic cases we can find complete answers. Lessons for
more generic cases as well as open mathematical problems are discussed.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:12:01 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jul 2020 16:51:25 GMT""},{""version"":""v3"",""created"":""Mon, 16 Nov 2020 11:27:04 GMT""}]","2020-11-18"
"2006.04715","Tao Zhu","Sen Yang, Cheng Liu, Tao Zhu, Li Zhao, Qiang Wu, Ke Yang, and Mubasher
  Jamil","Spherical Accretion Flow onto General Parameterized Spherically
  Symmetric Black Hole Spacetimes","15 pages, 9 figures; v2: version to be published in Chinese Physics C","Chinese Physics C Vol. 45, No. 1 (2021) 015102","10.1088/1674-1137/abc066",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The transonic phenomenon of black hole accretion and the existence of the
photon sphere are the characteristics of strong gravitational fields near a
black hole horizon. In this work, we study spherical accretion flow onto a
general parametrized spherically symmetric black hole spacetimes. For this
purpose, we analyze the accretion process of various perfect fluids, such as
the isothermal fluid of ultra-stiff, ultra-relativistic, and sub-relativistic
types and polytropic fluid, respectively. The influences of extra parameters
beyond the Schwarzschild black hole in the general parameterized spherically
symmetric black hole on the flow behaviors of the above-mentioned test fluids
are studied in detail. In addition, by studying the accretion of ideal photon
gas, we further discuss the correspondence between the sonic radius of
accreting photon gas and the photon sphere for the general parameterized
spherically symmetric black hole. Some possible future extensions of our
analysis are also discussed.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:12:36 GMT""},{""version"":""v2"",""created"":""Tue, 25 Aug 2020 16:13:41 GMT""}]","2021-01-01"
"2006.04716","Andrew Fountain","Andrew Fountain and Cory Merkel","Energy Constraints Improve Liquid State Machine Performance","8 pages, 5 figures. Submitted to ICONS 2020",,,,"cs.NE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A model of metabolic energy constraints is applied to a liquid state machine
in order to analyze its effects on network performance. It was found that, in
certain combinations of energy constraints, a significant increase in testing
accuracy emerged; an improvement of 4.25% was observed on a seizure detection
task using a digital liquid state machine while reducing overall reservoir
spiking activity by 6.9%. The accuracy improvements appear to be linked to the
energy constraints' impact on the reservoir's dynamics, as measured through
metrics such as the Lyapunov exponent and the separation of the reservoir.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:13:16 GMT""}]","2020-06-09"
"2006.04717","Kasia Jankiewicz","Kasia Jankiewicz","Residual finiteness of certain 2-dimensional Artin groups","29 pages, 18 figures. The mistakes from the previous version have
  been corrected. The statement of Theorem A has been weakened to exclude some
  cases",,,,"math.GR math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that many $2$-dimensional Artin groups are residually finite. This
includes $3$-generator Artin groups with labels $\geq 4$ except for $(2m+1,
4,4)$ for any $m\geq 2$. As a first step towards residual finiteness we show
that these Artin groups, and many more, split as free products with
amalgamation or HNN extensions of finite rank free groups. Among others, this
holds for all large type Artin groups with defining graph admitting an
orientation, where each simple cycle is directed.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:13:52 GMT""},{""version"":""v2"",""created"":""Sat, 7 May 2022 20:11:33 GMT""}]","2022-05-10"
"2006.04718","Corey Rae McRae","Corey Rae Harrington McRae, Haozhi Wang, Jiansong Gao, Michael
  Vissers, Teresa Brecht, Andrew Dunsworth, David Pappas, Josh Mutus","Materials loss measurements using superconducting microwave resonators","Review Article",,"10.1063/5.0017378",,"physics.app-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The performance of superconducting circuits for quantum computing is limited
by materials losses. In particular, coherence times are typically bounded by
two-level system (TLS) losses at single photon powers and millikelvin
temperatures. The identification of low loss fabrication techniques, materials,
and thin film dielectrics is critical to achieving scalable architectures for
superconducting quantum computing. Superconducting microwave resonators provide
a convenient qubit proxy for assessing performance and studying TLS loss and
other mechanisms relevant to superconducting circuits such as non-equilibrium
quasiparticles and magnetic flux vortices. In this review article, we provide
an overview of considerations for designing accurate resonator experiments to
characterize loss, including applicable types of loss, cryogenic setup, device
design, and methods for extracting material and interface losses, summarizing
techniques that have been evolving for over two decades. Results from
measurements of a wide variety of materials and processes are also summarized.
Lastly, we present recommendations for the reporting of loss data from
superconducting microwave resonators to facilitate materials comparisons across
the field.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:17:53 GMT""},{""version"":""v2"",""created"":""Mon, 21 Sep 2020 16:59:01 GMT""}]","2021-09-08"
"2006.04719","Xi Li","Xuewei Li, Songyuan Li, Bourahla Omar, Fei Wu, and Xi Li","ResKD: Residual-Guided Knowledge Distillation","The first two authors (Xuewei Li and Songyuan Li) contribute equally.
  Accepted to IEEE TRANSACTIONS ON IMAGE PROCESSING (TIP)",,"10.1109/TIP.2021.3066051",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge distillation, aimed at transferring the knowledge from a heavy
teacher network to a lightweight student network, has emerged as a promising
technique for compressing neural networks. However, due to the capacity gap
between the heavy teacher and the lightweight student, there still exists a
significant performance gap between them. In this paper, we see knowledge
distillation in a fresh light, using the knowledge gap, or the residual,
between a teacher and a student as guidance to train a much more lightweight
student, called a res-student. We combine the student and the res-student into
a new student, where the res-student rectifies the errors of the former
student. Such a residual-guided process can be repeated until the user strikes
the balance between accuracy and cost. At inference time, we propose a
sample-adaptive strategy to decide which res-students are not necessary for
each sample, which can save computational cost. Experimental results show that
we achieve competitive performance with 18.04$\%$, 23.14$\%$, 53.59$\%$, and
56.86$\%$ of the teachers' computational costs on the CIFAR-10, CIFAR-100,
Tiny-ImageNet, and ImageNet datasets. Finally, we do thorough theoretical and
empirical analysis for our method.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:18:45 GMT""},{""version"":""v2"",""created"":""Tue, 9 Jun 2020 11:39:18 GMT""},{""version"":""v3"",""created"":""Sat, 1 Aug 2020 17:21:09 GMT""},{""version"":""v4"",""created"":""Tue, 9 Mar 2021 03:35:20 GMT""}]","2021-12-01"
"2006.04721","Junxuan Chen","Junxuan Chen, Xiang Li, Jiarui Zhang, Chulun Zhou, Jianwei Cui, Bin
  Wang, Jinsong Su","Modeling Discourse Structure for Document-level Neural Machine
  Translation",,"AutoSimTrans2020 camera-ready",,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, document-level neural machine translation (NMT) has become a hot
topic in the community of machine translation. Despite its success, most of
existing studies ignored the discourse structure information of the input
document to be translated, which has shown effective in other tasks. In this
paper, we propose to improve document-level NMT with the aid of discourse
structure information. Our encoder is based on a hierarchical attention network
(HAN). Specifically, we first parse the input document to obtain its discourse
structure. Then, we introduce a Transformer-based path encoder to embed the
discourse structure information of each word. Finally, we combine the discourse
structure information with the word embedding before it is fed into the
encoder. Experimental results on the English-to-German dataset show that our
model can significantly outperform both Transformer and Transformer+HAN.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:24:03 GMT""}]","2020-06-23"
"2006.04722","Guillaume Bourdarot","Guillaume Bourdarot, Hugues Guillet de Chatellus and Jean-Philippe
  Berger","Toward a large bandwidth photonic correlator for infrared heterodyne
  interferometry","7 pages, 4 figures. Accepted in Astronomy & Astrophysics","A&A 639, A53 (2020)","10.1051/0004-6361/201937368",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Infrared heterodyne interferometry has been proposed as a practical
alternative for recombining a large number of telescopes over kilometric
baselines in the mid-infrared. However, the current limited correlation
capacities impose strong restrictions on the sensitivity of this appealing
technique. In this paper, we propose to address the problem of transport and
correlation of wide-bandwidth signals over kilometric distances by introducing
photonic processing in infrared heterodyne interferometry. We describe the
architecture of a photonic double-sideband correlator for two telescopes, along
with the experimental demonstration of this concept on a proof-of-principle
test bed. We demonstrate the \textit{a posteriori} correlation of two infrared
signals previously generated on a two-telescope simulator in a double-sideband
photonic correlator. A degradation of the signal-to-noise ratio of $13\%$,
equivalent to a noise factor $\text{NF}=1.15$, is obtained through the
correlator, and the temporal coherence properties of our input signals are
retrieved from these measurements. Our results demonstrate that photonic
processing can be used to correlate heterodyne signals with a potentially large
increase of detection bandwidth. These developments open the way to photonic
processing of wide bandwidth signals for mid-infrared heterodyne
interferometry, in particular for a large number of telescopes and for direct
imager recombiners.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:24:53 GMT""}]","2020-07-08"
"2006.04723","Juergen Hausen","Juergen Hausen, Christian Mauz, Milena Wrobel","The anticanonical complex for non-degenerate toric complete
  intersections","27 pages, further resuls added",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The anticanonical complex generalizes the Fano polytope from toric geometry
and has been used to study Fano varieties with torus action so far. We work out
the case of complete intersections in toric varieties defined by non-degenerate
systems of Laurent polynomials. As an application, we classify the terminal
Fano threefolds that are embedded into a fake weighted projective space via a
general system of Laurent polynomials.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:25:47 GMT""},{""version"":""v2"",""created"":""Thu, 10 Sep 2020 11:52:36 GMT""}]","2020-09-11"
"2006.04724","Xiaoyan Shi","Xurui Zhang, John M. Woods, Judy J. Cha, Xiaoyan Shi","Crossover Between Weak Antilocalization and Weak Localization and
  Electron-Electron Interaction in Few-Layer WTe$_2$",,"Phys. Rev. B 102, 115161 (2020)","10.1103/PhysRevB.102.115161",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report electron transport studies in an encapsulated few-layer WTe$_2$ at
low temperatures and high magnetic fields. The magnetoconductance reveals a
temperature-induced crossover between weak antilocalization (WAL) and weak
localization (WL) in quantum diffusive regime. We show that the crossover
clearly manifests coexistence and competition among several characteristic
lengths, including the dephasing length, the spin-flip length, and the mean
free path. In addition, low temperature conductance increases logarithmically
with the increase of temperature indicating an interplay of electron-electron
interaction (EEI) and spin-orbit coupling (SOC). We demonstrate the existences
and quantify the strengths of EEI and SOC which are considered to be
responsible for gap opening in the quantum spin hall state in WTe2 at the
monolayer limit.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:25:57 GMT""}]","2020-10-07"
"2006.04725","Chen Qin","Chen Qin, Shuo Wang, Chen Chen, Huaqi Qiu, Wenjia Bai and Daniel
  Rueckert","Biomechanics-informed Neural Networks for Myocardial Motion Tracking in
  MRI","The paper is early accepted by MICCAI 2020",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image registration is an ill-posed inverse problem which often requires
regularisation on the solution space. In contrast to most of the current
approaches which impose explicit regularisation terms such as smoothness, in
this paper we propose a novel method that can implicitly learn
biomechanics-informed regularisation. Such an approach can incorporate
application-specific prior knowledge into deep learning based registration.
Particularly, the proposed biomechanics-informed regularisation leverages a
variational autoencoder (VAE) to learn a manifold for biomechanically plausible
deformations and to implicitly capture their underlying properties via
reconstructing biomechanical simulations. The learnt VAE regulariser then can
be coupled with any deep learning based registration network to regularise the
solution space to be biomechanically plausible. The proposed method is
validated in the context of myocardial motion tracking on 2D stacks of cardiac
MRI data from two different datasets. The results show that it can achieve
better performance against other competing methods in terms of motion tracking
accuracy and has the ability to learn biomechanical properties such as
incompressibility and strains. The method has also been shown to have better
generalisability to unseen domains compared with commonly used L2
regularisation schemes.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:29:13 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jul 2020 11:24:17 GMT""},{""version"":""v3"",""created"":""Wed, 8 Jul 2020 09:42:11 GMT""}]","2020-07-09"
"2006.04726","Lucy Oswald","Lucy Oswald, Aris Karastergiou, Simon Johnston","Pulsar polarimetry with the Parkes Ultra-Wideband receiver","Accepted for publication in MNRAS. 13 pages, 10 figures, 2 tables",,"10.1093/mnras/staa1597",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pulsar radio emission and its polarization are observed to evolve with
frequency. This frequency dependence is key to the emission mechanism and the
structure of the radio beam. With the new Ultra-Wideband receiver (UWL) on the
Parkes radio telescope we are able, for the first time, to observe how pulsar
profiles evolve over a broad continuous bandwidth of 700-4000 MHz. We describe
here a technique for processing broadband polarimetric observations to
establish a meaningful alignment and visualize the data across the band. We
apply this to observations of PSRs J1056-6258 and J1359-6038, chosen due to
previously unresolved questions about the frequency evolution of their
emission. Application of our technique reveals that it is possible to align the
polarization position angle (PA) across a broad frequency range when
constrained to applying only corrections for dispersion and Faraday rotation to
do so. However, this does not correspond to aligned intensity profiles for
these two sources. We find that it is possible to convert these misalignments
into emission height range estimates that are consistent with published and
simulated values, suggesting that they can be attributed to relativistic
effects in the magnetosphere. We discuss this work in the context of the radio
beam structure and prepare the ground for a wider study of pulsar emission
using broadband polarimetric data.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:30:46 GMT""}]","2020-06-17"
"2006.04727","Florian Krach","Calypso Herrera, Florian Krach, Josef Teichmann","Neural Jump Ordinary Differential Equations: Consistent Continuous-Time
  Prediction and Filtering",,"International Conference on Learning Representations (2021)",,,"stat.ML cs.LG math.PR q-fin.CP q-fin.ST","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Combinations of neural ODEs with recurrent neural networks (RNN), like
GRU-ODE-Bayes or ODE-RNN are well suited to model irregularly observed time
series. While those models outperform existing discrete-time approaches, no
theoretical guarantees for their predictive capabilities are available.
Assuming that the irregularly-sampled time series data originates from a
continuous stochastic process, the $L^2$-optimal online prediction is the
conditional expectation given the currently available information. We introduce
the Neural Jump ODE (NJ-ODE) that provides a data-driven approach to learn,
continuously in time, the conditional expectation of a stochastic process. Our
approach models the conditional expectation between two observations with a
neural ODE and jumps whenever a new observation is made. We define a novel
training framework, which allows us to prove theoretical guarantees for the
first time. In particular, we show that the output of our model converges to
the $L^2$-optimal prediction. This can be interpreted as solution to a special
filtering problem. We provide experiments showing that the theoretical results
also hold empirically. Moreover, we experimentally show that our model
outperforms the baselines in more complex learning tasks and give comparisons
on real-world datasets.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:34:51 GMT""},{""version"":""v2"",""created"":""Sat, 3 Oct 2020 06:46:28 GMT""},{""version"":""v3"",""created"":""Wed, 9 Dec 2020 13:36:20 GMT""},{""version"":""v4"",""created"":""Fri, 16 Apr 2021 12:54:38 GMT""}]","2021-05-11"
"2006.04728","Linden Parkes PhD","Linden Parkes, Theodore D. Satterthwaite, Danielle S. Bassett","Towards precise resting-state fMRI biomarkers in psychiatry:
  synthesizing developments in transdiagnostic research, dimensional models of
  psychopathology, and normative neurodevelopment","Keywords: Psychiatry; biomarker; transdiagnostic; dimensional
  psychopathology; normative modeling; fingerprint; network science",,,,"q-bio.NC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Searching for biomarkers has been a chief pursuit of the field of psychiatry.
Toward this end, studies have catalogued candidate resting-state biomarkers in
nearly all forms of mental disorder. However, it is becoming increasingly clear
that these biomarkers lack specificity, limiting their capacity to yield
clinical impact. We discuss three avenues of research that are overcoming this
limitation: (i) the adoption of transdiagnostic research designs, which involve
studying and explicitly comparing multiple disorders from distinct diagnostic
axes of psychiatry; (ii) dimensional models of psychopathology that map the
full spectrum of symptomatology and that cut across traditional disorder
boundaries; and (iii) modeling individuals' unique functional connectomes
throughout development. We provide a framework for tying these subfields
together that draws on tools from machine learning and network science.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:35:17 GMT""}]","2020-06-09"
"2006.04729","Phan Th\`anh Nam","Kevin K\""ogler and Phan Th\`anh Nam","The Lieb-Thirring inequality for interacting systems in strong-coupling
  limit","Final version to appear in Arch. Ration. Mech. Anal",,"10.1007/s00205-021-01633-8",,"math-ph math.AP math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider an analogue of the Lieb-Thirring inequality for quantum systems
with homogeneous repulsive interaction potentials, but without the antisymmetry
assumption on the wave functions. We show that in the strong-coupling limit,
the Lieb-Thirring constant converges to the optimal constant of the one-body
Gagliardo-Nirenberg interpolation inequality without interaction.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:36:06 GMT""},{""version"":""v2"",""created"":""Mon, 15 Jun 2020 05:51:00 GMT""},{""version"":""v3"",""created"":""Mon, 15 Feb 2021 15:22:39 GMT""}]","2021-03-31"
"2006.04730","Zifan Liu","Zifan Liu and Zhechun Zhou and Theodoros Rekatsinas","Picket: Guarding Against Corrupted Data in Tabular Data during Learning
  and Inference","23 pages, 24 figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data corruption is an impediment to modern machine learning deployments.
Corrupted data can severely bias the learned model and can also lead to invalid
inferences. We present, Picket, a simple framework to safeguard against data
corruptions during both training and deployment of machine learning models over
tabular data. For the training stage, Picket identifies and removes corrupted
data points from the training data to avoid obtaining a biased model. For the
deployment stage, Picket flags, in an online manner, corrupted query points to
a trained machine learning model that due to noise will result in incorrect
predictions. To detect corrupted data, Picket uses a self-supervised deep
learning model for mixed-type tabular data, which we call PicketNet. To
minimize the burden of deployment, learning a PicketNet model does not require
any human-labeled data. Picket is designed as a plugin that can increase the
robustness of any machine learning pipeline. We evaluate Picket on a diverse
array of real-world data considering different corruption models that include
systematic and adversarial noise during both training and testing. We show that
Picket consistently safeguards against corrupted data during both training and
deployment of various models ranging from SVMs to neural networks, beating a
diverse array of competing methods that span from data quality validation
models to robust outlier-detection models.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:37:25 GMT""},{""version"":""v2"",""created"":""Thu, 29 Oct 2020 19:31:09 GMT""},{""version"":""v3"",""created"":""Mon, 26 Jul 2021 04:09:01 GMT""}]","2021-07-27"
"2006.04731","Nicholas Geneva","Nicholas Geneva, Nicholas Zabaras","Multi-fidelity Generative Deep Learning Turbulent Flows","45 pages, 30 figures","Foundations.Data.Science. 2 (2020) Pg. 391","10.3934/fods.2020019",,"physics.comp-ph cs.LG physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In computational fluid dynamics, there is an inevitable trade off between
accuracy and computational cost. In this work, a novel multi-fidelity deep
generative model is introduced for the surrogate modeling of high-fidelity
turbulent flow fields given the solution of a computationally inexpensive but
inaccurate low-fidelity solver. The resulting surrogate is able to generate
physically accurate turbulent realizations at a computational cost magnitudes
lower than that of a high-fidelity simulation. The deep generative model
developed is a conditional invertible neural network, built with normalizing
flows, with recurrent LSTM connections that allow for stable training of
transient systems with high predictive accuracy. The model is trained with a
variational loss that combines both data-driven and physics-constrained
learning. This deep generative model is applied to non-trivial high Reynolds
number flows governed by the Navier-Stokes equations including turbulent flow
over a backwards facing step at different Reynolds numbers and turbulent wake
behind an array of bluff bodies. For both of these examples, the model is able
to generate unique yet physically accurate turbulent fluid flows conditioned on
an inexpensive low-fidelity solution.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:37:48 GMT""},{""version"":""v2"",""created"":""Fri, 11 Dec 2020 20:01:38 GMT""}]","2021-01-12"
"2006.04732","Numair Sani","Numair Sani, Jaron Lee, Razieh Nabi, Ilya Shpitser","A Semiparametric Approach to Interpretable Machine Learning",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Black box models in machine learning have demonstrated excellent predictive
performance in complex problems and high-dimensional settings. However, their
lack of transparency and interpretability restrict the applicability of such
models in critical decision-making processes. In order to combat this
shortcoming, we propose a novel approach to trading off interpretability and
performance in prediction models using ideas from semiparametric statistics,
allowing us to combine the interpretability of parametric regression models
with performance of nonparametric methods. We achieve this by utilizing a
two-piece model: the first piece is interpretable and parametric, to which a
second, uninterpretable residual piece is added. The performance of the overall
model is optimized using methods from the sufficient dimension reduction
literature. Influence function based estimators are derived and shown to be
doubly robust. This allows for use of approaches such as double Machine
Learning in estimating our model parameters. We illustrate the utility of our
approach via simulation studies and a data application based on predicting the
length of stay in the intensive care unit among surgery patients.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:38:15 GMT""}]","2020-06-09"
"2006.04733","Wencai Liu","Wencai Liu","Irreducibility of the Fermi variety for discrete periodic Schr\""odinger
  operators and embedded eigenvalues",,,"10.1007/s00039-021-00587-z",,"math-ph math.AG math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $H_0$ be a discrete periodic Schr\""odinger operator on
$\ell^2(\mathbb{Z}^d)$:
  $$H_0=-\Delta+V,$$ where $\Delta$ is the discrete Laplacian and $V:
\mathbb{Z}^d\to \mathbb{C}$ is periodic. We prove that for any $d\geq3$, the
Fermi variety at every energy level is irreducible (modulo periodicity). For
$d=2$, we prove that the Fermi variety at every energy level except for the
average of the potential is irreducible (modulo periodicity) and the Fermi
variety at the average of the potential has at most two irreducible components
(modulo periodicity). This is sharp since for $d=2$ and a constant potential
$V$, the Fermi variety at $V$-level has exactly two irreducible components
(modulo periodicity). We also prove that the Bloch variety is irreducible
(modulo periodicity) for any $d\geq 2$. As applications, we prove that when $V$
is a real-valued periodic function, the level set of any extrema of any
spectral band functions, spectral band edges in particular, has dimension at
most $d-2$ for any $d\geq 3$, and finite cardinality for $d=2$. We also show
that $H=-\Delta +V+v$ does not have any embedded eigenvalues provided that $v$
decays super-exponentially.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:40:00 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 01:13:39 GMT""},{""version"":""v3"",""created"":""Tue, 2 Nov 2021 16:57:52 GMT""}]","2022-01-10"
"2006.04734","Adrien Ecoffet","Adrien Ecoffet and Joel Lehman","Reinforcement Learning Under Moral Uncertainty","28 pages, 18 figures; update adds discussion of a possible flaw of
  Nash voting, discussion of further possible research into MEC, as well as a
  few more references; updated to ICML version",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An ambitious goal for machine learning is to create agents that behave
ethically: The capacity to abide by human moral norms would greatly expand the
context in which autonomous agents could be practically and safely deployed,
e.g. fully autonomous vehicles will encounter charged moral decisions that
complicate their deployment. While ethical agents could be trained by rewarding
correct behavior under a specific moral theory (e.g. utilitarianism), there
remains widespread disagreement about the nature of morality. Acknowledging
such disagreement, recent work in moral philosophy proposes that ethical
behavior requires acting under moral uncertainty, i.e. to take into account
when acting that one's credence is split across several plausible ethical
theories. This paper translates such insights to the field of reinforcement
learning, proposes two training methods that realize different points among
competing desiderata, and trains agents in simple environments to act under
moral uncertainty. The results illustrate (1) how such uncertainty can help
curb extreme behavior from commitment to single theories and (2) several
technical complications arising from attempting to ground moral philosophy in
RL (e.g. how can a principled trade-off between two competing but incomparable
reward functions be reached). The aim is to catalyze progress towards
morally-competent agents and highlight the potential of RL to contribute
towards the computational grounding of moral philosophy.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:40:12 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 00:15:50 GMT""},{""version"":""v3"",""created"":""Mon, 19 Jul 2021 18:52:16 GMT""}]","2021-07-21"
"2006.04735","Blake Woodworth","Blake Woodworth, Kumar Kshitij Patel, Nathan Srebro","Minibatch vs Local SGD for Heterogeneous Distributed Learning","34 pages",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze Local SGD (aka parallel or federated SGD) and Minibatch SGD in the
heterogeneous distributed setting, where each machine has access to stochastic
gradient estimates for a different, machine-specific, convex objective; the
goal is to optimize w.r.t. the average objective; and machines can only
communicate intermittently. We argue that, (i) Minibatch SGD (even without
acceleration) dominates all existing analysis of Local SGD in this setting,
(ii) accelerated Minibatch SGD is optimal when the heterogeneity is high, and
(iii) present the first upper bound for Local SGD that improves over Minibatch
SGD in a non-homogeneous regime.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:40:49 GMT""},{""version"":""v2"",""created"":""Wed, 10 Jun 2020 14:26:00 GMT""},{""version"":""v3"",""created"":""Thu, 18 Jun 2020 14:57:56 GMT""},{""version"":""v4"",""created"":""Mon, 27 Jul 2020 15:38:54 GMT""},{""version"":""v5"",""created"":""Tue, 1 Mar 2022 09:30:34 GMT""}]","2022-03-02"
"2006.04736","Jinzi Mac Huang","Jinzi Mac Huang, Michael J. Shelley and David B. Stein","A stable and accurate scheme for solving the Stefan problem coupled with
  natural convection using the Immersed Boundary Smooth Extension method","For supplemental movies, see
  https://math.nyu.edu/~jinzi/research/IBSE/SI-Movies/",,"10.1016/j.jcp.2021.110162",,"physics.flu-dyn cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dissolution of solids has created spectacular geomorphologies ranging
from centimeter-scale cave scallops to the kilometer-scale ""stone forests"" of
China and Madagascar. Mathematically, dissolution processes are modeled by a
Stefan problem, which describes how the motion of a phase-separating interface
depends on local concentration gradients, coupled to a fluid flow. Simulating
these problems is challenging, requiring the evolution of a free interface
whose motion depends on the normal derivatives of an external field in an
ever-changing domain. Moreover, density differences created in the fluid domain
induce self-generated convecting flows that further complicate the numerical
study of dissolution processes. In this contribution, we present a numerical
method for the simulation of the Stefan problem coupled to a fluid flow. The
scheme uses the Immersed Boundary Smooth Extension method to solve the bulk
advection-diffusion and fluid equations in the complex, evolving geometry,
coupled to a {\theta}-L scheme that provides stable evolution of the boundary.
We demonstrate third-order temporal and pointwise spatial convergence of the
scheme for the classical Stefan problem, and second-order temporal and
pointwise spatial convergence when coupled to flow. Examples of dissolution of
solids that result in high-Rayleigh number convection are numerically studied,
and qualitatively reproduce the complex morphologies observed in recent
experiments.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:42:11 GMT""},{""version"":""v2"",""created"":""Wed, 10 Jun 2020 01:26:33 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jan 2021 02:28:18 GMT""}]","2021-02-08"
"2006.04737","Jiabo Huang","Jiabo Huang and Shaogang Gong","Unsupervised Transfer Learning with Self-Supervised Remedy",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalising deep networks to novel domains without manual labels is
challenging to deep learning. This problem is intrinsically difficult due to
unpredictable changing nature of imagery data distributions in novel domains.
Pre-learned knowledge does not transfer well without making strong assumptions
about the learned and the novel domains. Different methods have been studied to
address the underlying problem based on different assumptions, e.g. from domain
adaptation to zero-shot and few-shot learning. In this work, we address this
problem by transfer clustering that aims to learn a discriminative latent space
of the unlabelled target data in a novel domain by knowledge transfer from
labelled related domains. Specifically, we want to leverage relative (pairwise)
imagery information, which is freely available and intrinsic to a target
domain, to model the target domain image distribution characteristics as well
as the prior-knowledge learned from related labelled domains to enable more
discriminative clustering of unlabelled target data. Our method mitigates
nontransferrable prior-knowledge by self-supervision, benefiting from both
transfer and self-supervised learning. Extensive experiments on four datasets
for image clustering tasks reveal the superiority of our model over the
state-of-the-art transfer clustering techniques. We further demonstrate its
competitive transferability on four zero-shot learning benchmarks.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:42:17 GMT""}]","2020-06-09"
"2006.04738","Chittaranjan Hens","Chittaranjan Hens, Uzi Harush, Simcha Haber, Reuven Cohen and Baruch
  Barzel","Response times of nodes in a complex network environment -- two
  potential derivation tracks","12 pages, 1 figure",,,,"nlin.AO cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spread of perturbative signals in complex networks is governed by the
combined effect of the network topology and its intrinsic nonlinear dynamics.
Recently, the resulting spreading patterns have been analyzed and predicted,
shown to depend on a single scaling relationship, linking a node's weighted
degree $S_i$ to its intrinsic response time $\tau_i$. The relevant scaling
exponent $\theta$ can be analytically traced to the system's nonlinear
dynamics. Here we show that $\theta$ can be obtained via two different
derivation tracks, leading to seemingly different functions. Analyzing the
resulting predictions, we find that, despite their distinct form, they are
fully consistent, predicting the exact same scaling relationship under
potentially diverse types of dynamics.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:42:23 GMT""}]","2020-06-09"
"2006.04739","Shuanglong Liu","Hai-Ping Cheng, Shuanglong Liu, Xiao Chen, Long Zhang and James N Fry","First-principles study of magnetism and electric field effects in 2D
  systems",,,"10.1116/5.0009316",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This review article provides a bird's-eye view of what first-principles based
methods can contribute to next-generation device design and simulation. After a
brief overview of methods and capabilities in the area, we focus on published
work by our group since 2015 and current work on $\textrm{CrI}_3$. We introduce
both single- and dual-gate models in the framework of density functional theory
and the constrained random phase approximation in estimating the Hubbard $U$
for 2D systems vs. their 3D counterparts. A wide range of systems, including
graphene-based heterogeneous systems, transition metal dichalcogenides, and
topological insulators, and a rich array of physical phenomena, including the
macroscopic origin of polarization, field effects on magnetic order, interface
state resonance induced peak in transmission coefficients, spin filtration,
etc., are covered. For $\textrm{CrI}_3$ we present our new results on bilayer
systems such as the interplay between stacking and magnetic order, pressure
dependence, and electric field induced magnetic phase transitions. We find that
a bare bilayer $\textrm{CrI}_3$, graphene$\,|\,$bilayer
$\textrm{CrI}_3\,|\,$graphene, $h$-BN$\,|\,$bilayer $\textrm{CrI}_3\,|\,h$-BN,
and $h$-BN$\,|\,$bilayer $\textrm{CrI}_3\,|\,$graphene all have a different
response at high field, while small field the difference is small except for
graphene$\,|\,$bilayer $\textrm{CrI}_3\,|\,$graphene. We conclude with
discussion of some ongoing work and work planned in the near future, with the
inclusion of further method development and applications.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:42:32 GMT""}]","2020-11-13"
"2006.04740","Umut \c{S}im\c{s}ekli","Mert Gurbuzbalaban, Umut \c{S}im\c{s}ekli, Lingjiong Zhu","The Heavy-Tail Phenomenon in SGD",,"Published as a conference paper at International Conference on
  Machine Learning (ICML) 2021",,,"math.OC cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, various notions of capacity and complexity have been
proposed for characterizing the generalization properties of stochastic
gradient descent (SGD) in deep learning. Some of the popular notions that
correlate well with the performance on unseen data are (i) the `flatness' of
the local minimum found by SGD, which is related to the eigenvalues of the
Hessian, (ii) the ratio of the stepsize $\eta$ to the batch-size $b$, which
essentially controls the magnitude of the stochastic gradient noise, and (iii)
the `tail-index', which measures the heaviness of the tails of the network
weights at convergence. In this paper, we argue that these three seemingly
unrelated perspectives for generalization are deeply linked to each other. We
claim that depending on the structure of the Hessian of the loss at the
minimum, and the choices of the algorithm parameters $\eta$ and $b$, the SGD
iterates will converge to a \emph{heavy-tailed} stationary distribution. We
rigorously prove this claim in the setting of quadratic optimization: we show
that even in a simple linear regression problem with independent and
identically distributed data whose distribution has finite moments of all
order, the iterates can be heavy-tailed with infinite variance. We further
characterize the behavior of the tails with respect to algorithm parameters,
the dimension, and the curvature. We then translate our results into insights
about the behavior of SGD in deep learning. We support our theory with
experiments conducted on synthetic data, fully connected, and convolutional
neural networks.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:43:56 GMT""},{""version"":""v2"",""created"":""Fri, 2 Oct 2020 16:04:31 GMT""},{""version"":""v3"",""created"":""Mon, 15 Feb 2021 02:36:01 GMT""},{""version"":""v4"",""created"":""Tue, 8 Jun 2021 15:34:12 GMT""},{""version"":""v5"",""created"":""Mon, 14 Jun 2021 15:45:36 GMT""}]","2021-06-15"
"2006.04741","Detlev Hoffmann","Detlev W. Hoffmann","Similarity of quadratic and symmetric bilinear forms in characteristic 2","17 pages",,,,"math.NT math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We say that a field extension $L/F$ has the descent property for isometry
(resp. similarity) of quadratic or symmetric bilinear forms if any two forms
defined over $F$ that become isometric (resp. similar) over $L$ are already
isometric (resp. similar) over $F$. The famous Artin-Springer theorem states
that anisotropic quadratic or symmetric bilinear forms over a field stay
anisotropic over an odd degree field extension. As a consequence, odd degree
extensions have the descent property for isometry of quadratic as well as
symmetric bilinear forms. While this is well known for nonsingular quadratic
forms, it is perhaps less well known for arbitrary quadratic or symmetric
bilinear forms in characteristic $2$. We provide a proof in this situation.
More generally, we show that odd degree extensions also have the descent
property for similarity. Moreover, for symmetric bilinear forms in
characteristic $2$, one even has the descent property for isometry and for
similarity for arbitrary separable algebraic extensions. We also show
Scharlau's norm principle for arbitrary quadratic or bilinear forms in
characteristic $2$.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:44:58 GMT""}]","2020-06-09"
"2006.04742","Jan M. L. Martin","Emmanouil Semidalas and Jan M.L. Martin","Canonical and DLPNO-based G4(MP2)XK-inspired composite wavefunction
  methods parametrized against large and chemically diverse training sets: Are
  they more accurate and/or robust than double hybrid DFT?","J. Chem. Theor. Comp., ASAP (2020). CC:BY 4.0 Open Access article","Journal of Chemical Theory and Computation 16, 4238-4255 (2020)","10.1021/acs.jctc.0c00189",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  The large and chemically diverse GMTKN55 benchmark was used as a training set
for parametrizing composite wave function thermochemistry protocols akin to
G4(MP2)XK theory (Chan et al, JCTC 2019, 15, 4478-4484). Even after
reparametrization, the GMTKN55 WTMAD2 (weighted mean absolute deviation, type
2) for G4(MP2)-XK is actually inferior to that of the best rung-4 DFT
functional, wB97M-V. By increasing the basis set for the MP2 part to
def2-QZVPPD, we were able to substantially improve performance at modest cost
(if an RI-MP2 approximation is made), with WTMAD2 for this G4(MP2)-XK-D method
now comparable to the better rung-5 functionals (albeit at greater cost). A
three-tier approach with a scaled MP3/def2-TZVPP intermediate step, however,
leads to a G4(MP3)-D method that is markedly superior to even the best double
hybrids wB97M(2) and revDSD-PBEP86-D4. Evaluating the CCSD(T) component with a
triple-zeta, rather than split-valence, basis set yields only a modest further
improvement that is incommensurate with the drastic increase in computational
cost. G4(MP3)-D and G4(MP2)- XK-D have about 40% better WTMAD2, at similar or
lower computational cost, than their counterparts G4 and G4(MP2), respectively:
detailed comparison reveals that the difference lies in larger molecules due to
basis set incompleteness error. An E2/ {T,Q} extrapolation and a
CCSD(T)/def2-TZVP step provided the G4-T method of high accuracy and with just
three fitted parameters. Using KS orbitals in MP2 leads to the G4(MP3|KS)-D
method, which entirely eliminates the CCSD(T) step and has no steps costlier
than scaled MP3; this shows a path forward to further improvements in
double-hybrid density functional methods. G4-T-DLPNO, a variant in which
post-MP2 corrections are evaluated at the DLPNO- CCSD(T) level, achieves nearly
the accuracy of G4-T but is applicable to much larger systems.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:45:00 GMT""}]","2020-10-16"
"2006.04743","Louigi Addario-Berry","Louigi Addario-Berry, Jessica Lin, Thomas Tendron","Barycentric Brownian Bees","36 pages. This version incorporates useful feedback from an anonymous
  referee. To appear in Annals of Applied Probability",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish an invariance principle for the barycenter of a Brunet-Derrida
particle system in $d$ dimensions. The model consists of $N$ particles
undergoing dyadic branching Brownian motion with rate $1$. At a branching
event, the number of particles is kept equal to $N$ by removing the particle
located furthest away from the barycenter. To prove the invariance principle, a
key step is to establish Harris recurrence for the process viewed from its
barycenter.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:46:17 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 17:35:11 GMT""}]","2021-08-17"
"2006.04744","Ahsan Noor Khan","Ahsan Noor Khan, Achintha Avin Ihalage, Yihan Ma, Baiyang Liu, Yujie
  Liu, Yang Hao","Deep learning framework for subject-independent emotion detection using
  wireless signals","13 Pages, 7 Figures",,"10.1371/journal.pone.0242946",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Emotion states recognition using wireless signals is an emerging area of
research that has an impact on neuroscientific studies of human behaviour and
well-being monitoring. Currently, standoff emotion detection is mostly reliant
on the analysis of facial expressions and/or eye movements acquired from
optical or video cameras. Meanwhile, although they have been widely accepted
for recognizing human emotions from the multimodal data, machine learning
approaches have been mostly restricted to subject dependent analyses which lack
of generality. In this paper, we report an experimental study which collects
heartbeat and breathing signals of 15 participants from radio frequency (RF)
reflections off the body followed by novel noise filtering techniques. We
propose a novel deep neural network (DNN) architecture based on the fusion of
raw RF data and the processed RF signal for classifying and visualising various
emotion states. The proposed model achieves high classification accuracy of
71.67 % for independent subjects with 0.71, 0.72 and 0.71 precision, recall and
F1-score values respectively. We have compared our results with those obtained
from five different classical ML algorithms and it is established that deep
learning offers a superior performance even with limited amount of raw RF and
post processed time-sequence data. The deep learning model has also been
validated by comparing our results with those from ECG signals. Our results
indicate that using wireless signals for stand-by emotion state detection is a
better alternative to other technologies with high accuracy and have much wider
applications in future studies of behavioural sciences.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:46:54 GMT""}]","2021-06-09"
"2006.04745","Ramandeep S. Johal","Ramandeep S. Johal","Generalized golden mean and the efficiency of thermal machines","Pedagogic article, RevTex4-1 9 pages, two figures. One figure added,
  references updated","European Journal of Physics (2020)","10.1088/1361-6404/aba9f4",,"physics.class-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate generic heat engines and refrigerators operating between two
heat reservoirs, for the condition when their efficiencies are equal to each
other. It is shown that the corresponding value of efficiency is given as the
inverse of the generalized golden mean, $\phi_p$, where the parameter $p$
depends on the degree of irreversibility of both engine and refrigerator. The
reversible case ($p=1$) yields the efficiency in terms of the standard golden
mean. We also extend the analysis to a three-heat-resrervoir setup.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:47:26 GMT""},{""version"":""v2"",""created"":""Sat, 13 Jun 2020 11:57:28 GMT""}]","2020-08-18"
"2006.04746","Anton Tsitsulin","Anton Tsitsulin, Marina Munkhoeva, Davide Mottin, Panagiotis Karras,
  Ivan Oseledets, Emmanuel M\""uller","FREDE: Anytime Graph Embeddings","As appeared in VLDB 14",,"10.14778/3447689.3447713",,"cs.LG cs.SI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-dimensional representations, or embeddings, of a graph's nodes facilitate
several practical data science and data engineering tasks. As such embeddings
rely, explicitly or implicitly, on a similarity measure among nodes, they
require the computation of a quadratic similarity matrix, inducing a tradeoff
between space complexity and embedding quality. To date, no graph embedding
work combines (i) linear space complexity, (ii) a nonlinear transform as its
basis, and (iii) nontrivial quality guarantees.
  In this paper we introduce FREDE (FREquent Directions Embedding), a graph
embedding based on matrix sketching that combines those three desiderata.
Starting out from the observation that embedding methods aim to preserve the
covariance among the rows of a similarity matrix}, FREDE iteratively improves
on quality while individually processing rows of a nonlinearly transformed PPR
similarity matrix derived from a state-of-the-art graph embedding method} and
provides, at any iteration, column-covariance approximation guarantees in due
course almost indistinguishable from those of the optimal approximation by SVD.
Our experimental evaluation on variably sized networks shows that FREDE
performs almost as well as SVD and competitively against state-of-the-art
embedding methods in diverse data science tasks, even when it is based on as
little as 10% of node similarities.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:51:24 GMT""},{""version"":""v2"",""created"":""Thu, 5 Jan 2023 14:26:48 GMT""}]","2023-01-06"
"2006.04747","Lie He","Lie He and Sai Praneeth Karimireddy and Martin Jaggi","Secure Byzantine-Robust Machine Learning",,,,,"cs.LG cs.CR stat.ML","http://creativecommons.org/licenses/by/4.0/","  Increasingly machine learning systems are being deployed to edge servers and
devices (e.g. mobile phones) and trained in a collaborative manner. Such
distributed/federated/decentralized training raises a number of concerns about
the robustness, privacy, and security of the procedure. While extensive work
has been done in tackling with robustness, privacy, or security individually,
their combination has rarely been studied. In this paper, we propose a secure
two-server protocol that offers both input privacy and Byzantine-robustness. In
addition, this protocol is communication-efficient, fault-tolerant and enjoys
local differential privacy.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:55:15 GMT""},{""version"":""v2"",""created"":""Sun, 18 Oct 2020 22:37:16 GMT""}]","2020-10-20"
"2006.04748","Bell Raj Eapen","Bell Raj Eapen, Kamran Sartipi and Norm Archer","Serverless on FHIR: Deploying machine learning models for healthcare on
  the cloud","10 pages, 1 figure",,,,"cs.CY cs.LG q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine Learning (ML) plays a vital role in implementing digital health. The
advances in hardware and the democratization of software tools have
revolutionized machine learning. However, the deployment of ML models -- the
mathematical representation of the task to be performed -- for effective and
efficient clinical decision support at the point of care is still a challenge.
ML models undergo constant improvement of their accuracy and predictive power
with a high turnover rate. Updating models consumed by downstream health
information systems is essential for patient safety. We introduce a functional
taxonomy and a four-tier architecture for cloud-based model deployment for
digital health. The four tiers are containerized microservices for
maintainability, serverless architecture for scalability, function as a service
for portability and FHIR schema for discoverability. We call this architecture
Serverless on FHIR and propose this as a standard to deploy digital health
applications that can be consumed by downstream systems such as EMRs and
visualization tools.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:57:30 GMT""}]","2020-06-09"
"2006.04749","Ronald Orozco","Ronald Orozco L\'opez","Ring of flows of one-dimensional differential equations","22 pages",,,,"math.DS math.RA","http://creativecommons.org/licenses/by/4.0/","  In this article, the ring of flows of autonomous differential equations of
order one on integral domains is constructed. First, we build the autonomous
ring $\Opa(\hurw_{R}[[x]])$ and then its structure is studied. Next, we build
the ring of formal exponential generating series of the ring $\Opa(\hurw_ {R}
[[x]]) $, where it is possible to find solutions of differential equations of
order one when the vector field of the system can be decomposed in sum or
product of functions.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:03:26 GMT""},{""version"":""v2"",""created"":""Wed, 10 Jun 2020 18:56:24 GMT""},{""version"":""v3"",""created"":""Mon, 9 Nov 2020 01:43:17 GMT""},{""version"":""v4"",""created"":""Mon, 29 Mar 2021 16:28:46 GMT""}]","2021-03-30"
"2006.04750","Terence Parr","Terence Parr, James D. Wilson, Jeff Hamrick","Nonparametric Feature Impact and Importance",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Practitioners use feature importance to rank and eliminate weak predictors
during model development in an effort to simplify models and improve
generality. Unfortunately, they also routinely conflate such feature importance
measures with feature impact, the isolated effect of an explanatory variable on
the response variable. This can lead to real-world consequences when importance
is inappropriately interpreted as impact for business or medical insight
purposes. The dominant approach for computing importances is through
interrogation of a fitted model, which works well for feature selection, but
gives distorted measures of feature impact. The same method applied to the same
data set can yield different feature importances, depending on the model,
leading us to conclude that impact should be computed directly from the data.
While there are nonparametric feature selection algorithms, they typically
provide feature rankings, rather than measures of impact or importance. They
also typically focus on single-variable associations with the response. In this
paper, we give mathematical definitions of feature impact and importance,
derived from partial dependence curves, that operate directly on the data. To
assess quality, we show that features ranked by these definitions are
competitive with existing feature selection techniques using three real data
sets for predictive tasks.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:07:35 GMT""}]","2020-06-09"
"2006.04751","Stefan Jaeger","Stefan Jaeger","The Golden Ratio of Learning and Momentum","10 pages, 3 figures, under review",,,,"cs.LG cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gradient descent has been a central training principle for artificial neural
networks from the early beginnings to today's deep learning networks. The most
common implementation is the backpropagation algorithm for training
feed-forward neural networks in a supervised fashion. Backpropagation involves
computing the gradient of a loss function, with respect to the weights of the
network, to update the weights and thus minimize loss. Although the mean square
error is often used as a loss function, the general stochastic gradient descent
principle does not immediately connect with a specific loss function. Another
drawback of backpropagation has been the search for optimal values of two
important training parameters, learning rate and momentum weight, which are
determined empirically in most systems. The learning rate specifies the step
size towards a minimum of the loss function when following the gradient, while
the momentum weight considers previous weight changes when updating current
weights. Using both parameters in conjunction with each other is generally
accepted as a means to improving training, although their specific values do
not follow immediately from standard backpropagation theory. This paper
proposes a new information-theoretical loss function motivated by neural signal
processing in a synapse. The new loss function implies a specific learning rate
and momentum weight, leading to empirical parameters often used in practice.
The proposed framework also provides a more formal explanation of the momentum
term and its smoothing effect on the training process. All results taken
together show that loss, learning rate, and momentum are closely connected. To
support these theoretical findings, experiments for handwritten digit
recognition show the practical usefulness of the proposed loss function and
training parameters.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:08:13 GMT""}]","2020-06-09"
"2006.04752","Giandomenico Palumbo","Patricio Salgado-Rebolledo, Giandomenico Palumbo, Jiannis K. Pachos","Effective field theories for interacting boundaries of 3D topological
  crystalline insulators through bosonisation","8 pages, published version","Scientific Reports 10, 21998 (2020)","10.1038/s41598-020-77966-3",,"cond-mat.mes-hall hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here, we analyse two Dirac fermion species in two spatial dimensions in the
presence of general quartic contact interactions. By employing functional
bosonisation techniques, we demonstrate that depending on the couplings of the
fermion interactions the system can be effectively described by a rich variety
of topologically massive gauge theories. Among these effective theories, we
obtain an extended Chern-Simons theory with higher order derivatives as well as
two coupled Chern-Simons theories. Our formalism allows for a general
description of interacting fermions emerging, for example, at the gapped
boundary of three-dimensional topological crystalline insulators.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:08:14 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 16:00:49 GMT""}]","2021-01-07"
"2006.04753","Zhigao Guo","Zhigao Guo and Anthony C. Constantinou","Approximate learning of high dimensional Bayesian network structures via
  pruning of Candidate Parent Sets",,,"10.3390/e22101142",,"cs.AI cs.GR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Score-based algorithms that learn Bayesian Network (BN) structures provide
solutions ranging from different levels of approximate learning to exact
learning. Approximate solutions exist because exact learning is generally not
applicable to networks of moderate or higher complexity. In general,
approximate solutions tend to sacrifice accuracy for speed, where the aim is to
minimise the loss in accuracy and maximise the gain in speed. While some
approximate algorithms are optimised to handle thousands of variables, these
algorithms may still be unable to learn such high dimensional structures. Some
of the most efficient score-based algorithms cast the structure learning
problem as a combinatorial optimisation of candidate parent sets. This paper
explores a strategy towards pruning the size of candidate parent sets, aimed at
high dimensionality problems. The results illustrate how different levels of
pruning affect the learning speed relative to the loss in accuracy in terms of
model fitting, and show that aggressive pruning may be required to produce
approximate solutions for high complexity problems.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:09:18 GMT""},{""version"":""v2"",""created"":""Thu, 10 Sep 2020 15:48:29 GMT""}]","2020-12-02"
"2006.04754","Felix Beierle","Zolt\'an Andr\'as Lux and Dirk Thatmann and Sebastian Zickau and Felix
  Beierle","Distributed-Ledger-based Authentication with Decentralized Identifiers
  and Verifiable Credentials","Accepted for publication at the 2nd Conference on Blockchain Research
  & Applications for Innovative Networks and Services (BRAINS 2020)",,,,"cs.DC cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Authentication with username and password is becoming an inconvenient process
for the user. End users typically have little control over their personal
privacy, and data breaches effecting millions of users have already happened
several times. We have implemented a proof of concept decentralized OpenID
Connect Provider by marrying it with Self-Sovereign Identity, which gives users
the freedom to choose from a very large pool of identity providers instead of
just a select few corporations, thus enabling the democratization of the highly
centralized digital identity landscape. Furthermore, we propose a verifiable
credential powered decentralized Public Key Infrastructure using distributed
ledger technologies, which creates a straightforward and verifiable way for
retrieving digital certificates.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:09:34 GMT""}]","2020-06-09"
"2006.04755","Simon Blouin","Simon Blouin","Magnesium abundances in cool metal-polluted white dwarfs","11 pages, 7 figures, 4 tables. Published in MNRAS. The complete
  versions of Figure 1, Table 1 and Table 2 are available for download as
  ancillary files. Corrected formatting errors in table2.txt",,"10.1093/mnras/staa1689",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The accretion of rocky material is responsible for the presence of heavy
elements in the atmospheres of a large fraction of white dwarf stars. Those
objects represent a unique opportunity to infer the bulk composition of
exoplanetesimals. This chemical characterization requires the use of detailed
atmosphere models to determine the elemental abundances at the photospheres of
white dwarfs. In this work, we use a state-of-the-art model atmosphere code to
reanalyse the first large survey of metal-polluted white dwarfs for which
abundances are found for multiple elements. We show that the improved
constitutive physics of our models lead to systematically higher Mg abundances
than previous analyses. We find an average log Mg/Ca number abundance ratio of
1.5. This value is significantly above the reference abundance for chondrites,
which is expected as current diffusion models predict that for the cool
helium-atmosphere white dwarfs of our sample Mg should remain in the atmosphere
longer than Ca. This helps resolve a recently identified Mg depletion problem,
where the planetesimals accreted by white dwarfs were reported to be
Mg-deficient compared to the expected composition of their planetary systems.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:09:36 GMT""},{""version"":""v2"",""created"":""Thu, 10 Sep 2020 16:18:53 GMT""}]","2020-09-11"
"2006.04756","Steven Heilman","Steven Heilman","Independent Sets of Random Trees and of Sparse Random Graphs","28 pages",,,,"math.PR cs.DM math-ph math.CO math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An independent set of size $k$ in a finite undirected graph $G$ is a set of
$k$ vertices of the graph, no two of which are connected by an edge. Let
$x_{k}(G)$ be the number of independent sets of size $k$ in the graph $G$ and
let $\alpha(G)=\max\{k\geq0\colon x_{k}(G)\neq0\}$. In 1987, Alavi, Malde,
Schwenk and Erd\""{o}s asked if the independent set sequence
$x_{0}(G),x_{1}(G),\ldots,x_{\alpha(G)}(G)$ of a tree is unimodal (the sequence
goes up and then down). This problem is still open. In 2006, Levit and
Mandrescu showed that the last third of the independent set sequence of a tree
is decreasing. We show that the first 46.8\% of the independent set sequence of
a random tree is increasing with (exponentially) high probability as the number
of vertices goes to infinity. So, the question of Alavi, Malde, Schwenk and
Erd\""{o}s is ``four-fifths true'', with high probability.
  We also show unimodality of the independent set sequence of Erd\""{o}s-Renyi
random graphs, when the expected degree of a single vertex is large (with
(exponentially) high probability as the number of vertices in the graph goes to
infinity, except for a small region near the mode). A weaker result is shown
for random regular graphs.
  The structure of independent sets of size $k$ as $k$ varies is of interest in
probability, statistical physics, combinatorics, and computer science.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:11:23 GMT""}]","2020-06-09"
"2006.04757","Markus N Rabe","Markus N. Rabe and Dennis Lee and Kshitij Bansal and Christian Szegedy","Mathematical Reasoning via Self-supervised Skip-tree Training",,,,,"cs.LG cs.AI cs.PL stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine whether self-supervised language modeling applied to mathematical
formulas enables logical reasoning. We suggest several logical reasoning tasks
that can be used to evaluate language models trained on formal mathematical
statements, such as type inference, suggesting missing assumptions and
completing equalities. To train language models for formal mathematics, we
propose a novel skip-tree task. We find that models trained on the skip-tree
task show surprisingly strong mathematical reasoning abilities, and outperform
models trained on standard skip-sequence tasks. We also analyze the models'
ability to formulate new conjectures by measuring how often the predictions are
provable and useful in other proofs.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:12:08 GMT""},{""version"":""v2"",""created"":""Wed, 10 Jun 2020 04:30:28 GMT""},{""version"":""v3"",""created"":""Wed, 12 Aug 2020 07:48:41 GMT""}]","2020-08-13"
"2006.04758","Federico Amadio Guidi","Federico Amadio Guidi","Integral Points on Elliptic Curves and Modularity","11 pages. Comments are welcome!",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove the finiteness of the set of S-integral points of a
punctured rational elliptic curve without complex multiplication using the
Chabauty-Kim method. This extends previous results of Kim in the complex
multiplication case. The key input of our approach is the use of modularity
techniques to prove the vanishing of certain Selmer groups involved in the
Chabauty-Kim method.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:13:10 GMT""}]","2020-06-09"
"2006.04759","Qiang Li","Silei Wang, Qiang Li and Mingjie Shao","One-Bit Symbol-Level Precoding for MU-MISO Downlink with Intelligent
  Reflecting Surface","Accepted by IEEE Signal Processing Letters",,"10.1109/LSP.2020.3028029",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers symbol-level precoding (SLP) for multiuser multi-input
single-output (MISO) downlink transmission with the aid of intelligent
reflecting surface (IRS). Specifically, by assuming one-bit transmitted signals
at the base station (BS), which arises from the use of low-resolution DACs in
the regime of massive transmit antennas, a joint design of one-bit SLP at the
BS and the phase shifts at the IRS is proposed with a goal of minimizing the
worst-case symbol error probability (SEP) of the users under the PSK
modulation. This joint design problem is essentially a mixed integer nonlinear
program (MINLP). To tackle it, we alternately optimize the one-bit signal and
the phase shifts. For the former, a dual of the relaxed one-bit SLP problem is
solved by the mirror descent (MD) method with the maximum block improvement
(MBI) heuristics. For the latter, the accelerated projected gradient (APG)
method is employed to optimize the phases. Numerical results demonstrate that
the proposed joint design can attain better SEP performance than the
conventional linear precoding and one-bit SLP.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:17:59 GMT""},{""version"":""v2"",""created"":""Mon, 28 Sep 2020 15:02:19 GMT""},{""version"":""v3"",""created"":""Tue, 29 Sep 2020 01:30:20 GMT""}]","2020-12-02"
"2006.04760","Ding Liu","Ding Liu, Hui Li","Outlier Detection Using a Novel method: Quantum Clustering","9 pages, 18 figures",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new assumption in outlier detection: Normal data instances are
commonly located in the area that there is hardly any fluctuation on data
density, while outliers are often appeared in the area that there is violent
fluctuation on data density. And based on this hypothesis, we apply a novel
density-based approach to unsupervised outlier detection. This approach, called
Quantum Clustering (QC), deals with unlabeled data processing and constructs a
potential function to find the centroids of clusters and the outliers. The
experiments show that the potential function could clearly find the hidden
outliers in data points effectively. Besides, by using QC, we could find more
subtle outliers by adjusting the parameter $\sigma$. Moreover, our approach is
also evaluated on two datasets (Air Quality Detection and Darwin Correspondence
Project) from two different research areas, and the results show the wide
applicability of our method.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:19:41 GMT""}]","2020-06-09"
"2006.04761","Qi Cai","Yufeng Zhang, Qi Cai, Zhuoran Yang, Yongxin Chen, Zhaoran Wang","Can Temporal-Difference and Q-Learning Learn Representation? A
  Mean-Field Theory",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Temporal-difference and Q-learning play a key role in deep reinforcement
learning, where they are empowered by expressive nonlinear function
approximators such as neural networks. At the core of their empirical successes
is the learned feature representation, which embeds rich observations, e.g.,
images and texts, into the latent space that encodes semantic structures.
Meanwhile, the evolution of such a feature representation is crucial to the
convergence of temporal-difference and Q-learning.
  In particular, temporal-difference learning converges when the function
approximator is linear in a feature representation, which is fixed throughout
learning, and possibly diverges otherwise. We aim to answer the following
questions: When the function approximator is a neural network, how does the
associated feature representation evolve? If it converges, does it converge to
the optimal one?
  We prove that, utilizing an overparameterized two-layer neural network,
temporal-difference and Q-learning globally minimize the mean-squared projected
Bellman error at a sublinear rate. Moreover, the associated feature
representation converges to the optimal one, generalizing the previous analysis
of Cai et al. (2019) in the neural tangent kernel regime, where the associated
feature representation stabilizes at the initial one. The key to our analysis
is a mean-field perspective, which connects the evolution of a
finite-dimensional parameter to its limiting counterpart over an
infinite-dimensional Wasserstein space. Our analysis generalizes to soft
Q-learning, which is further connected to policy gradient.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:25:22 GMT""}]","2020-06-09"
"2006.04762","Francesco Tudisco","Francesco Tudisco, Austin R. Benson, Konstantin Prokopchik","Nonlinear Higher-Order Label Spreading",,,,,"cs.LG cs.SI math.SP physics.data-an stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Label spreading is a general technique for semi-supervised learning with
point cloud or network data, which can be interpreted as a diffusion of labels
on a graph. While there are many variants of label spreading, nearly all of
them are linear models, where the incoming information to a node is a weighted
sum of information from neighboring nodes. Here, we add nonlinearity to label
spreading through nonlinear functions of higher-order structure in the graph,
namely triangles in the graph. For a broad class of nonlinear functions, we
prove convergence of our nonlinear higher-order label spreading algorithm to
the global solution of a constrained semi-supervised loss function. We
demonstrate the efficiency and efficacy of our approach on a variety of point
cloud and network datasets, where the nonlinear higher-order model compares
favorably to classical label spreading, as well as hypergraph models and graph
neural networks.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:29:40 GMT""}]","2020-06-09"
"2006.04763","Omar Benslimane","Omar Benslimane, Ahmed Aberqi and Jaouad Bennouna","Existence and Uniqueness of Weak solution of $ p( x ) $- laplacian in
  Sobolev spaces with variable exponents in complete manifolds",,,,,"math.AP","http://creativecommons.org/publicdomain/zero/1.0/","  The paper deals with the existence and uniqueness of a non-trivial solution
to non-homogeneous $ p ( x ) -$laplacian equations, managed by non polynomial
growth operator in the framework of variable exponent Sobolev spaces on
Riemannian manifolds. The mountain pass Theorem is used.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:31:19 GMT""}]","2020-06-09"
"2006.04764","Tanya Khovanova","Eric Chen, William Du, Tanmay Gupta, Tanya Khovanova, Alicia Li,
  Srikar Mallajosyula, Rohith Raghavan, Arkajyoti Sinha, Maya Smith, Matthew
  Qian, Samuel Wang","The Classification of Magic SET Squares","22 pages, 27 figures, 15 tables",,,,"math.HO math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A magic SET square is a 3 by 3 table of SET cards such that each row, column,
diagonal, and anti-diagonal is a set. We allow the following transformations of
the square: shuffling features, shuffling values within the features, rotations
and reflections of the square. Under these transformations, there are 21 types
of magic SET squares. We calculate the number of squares of each type. In
addition, we discuss a game of SET tic-tac-toe.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:32:55 GMT""}]","2020-06-09"
"2006.04765","Konstantinos Michmizos","Ioannis Polykretis, Konstantinos P. Michmizos","An Astrocyte-Modulated Neuromorphic Central Pattern Generator for
  Hexapod Robot Locomotion on Intel's Loihi","8 pages, 7 figures, International Conference on Neuromorphic Systems
  (ICONS) 2020",,,,"cs.NE cs.RO q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Locomotion is a crucial challenge for legged robots that is addressed
""effortlessly"" by biological networks abundant in nature, named central pattern
generators (CPG). The multitude of CPG network models that have so far become
biomimetic robotic controllers is not applicable to the emerging neuromorphic
hardware, depriving mobile robots of a robust walking mechanism that would
result in inherently energy-efficient systems. Here, we propose a brain-morphic
CPG controler based on a comprehensive spiking neural-astrocytic network that
generates two gait patterns for a hexapod robot. Building on the recently
identified astrocytic mechanisms for neuromodulation, our proposed CPG
architecture is seamlessly integrated into Intel's Loihi neuromorphic chip by
leveraging a real-time interaction framework between the chip and the robotic
operating system (ROS) environment, that we also propose. Here, we demonstrate
that a Loihi-run CPG can be used to control a walking robot with robustness to
sensory noise and varying speed profiles. Our results pave the way for scaling
this and other approaches towards Loihi-controlled locomotion in autonomous
mobile robots.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:35:48 GMT""}]","2020-06-09"
"2006.04766","Hongmei He Ph.D","Hongmei He and Zhenhuan Zhu","A Heuristically Self-Organised Linguistic Attribute Deep Learning in
  Edge Computing For IoT Intelligence",,,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the development of Internet of Things (IoT), IoT intelligence becomes
emerging technology. ""Curse of Dimensionality"" is the barrier of data fusion in
edge devices for the success of IoT intelligence. A Linguistic Attribute
Hierarchy (LAH), embedded with Linguistic Decision Trees (LDTs), can represent
a new attribute deep learning. In contrast to the conventional deep learning,
an LAH could overcome the shortcoming of missing interpretation by providing
transparent information propagation through the rules, produced by LDTs in the
LAH. Similar to the conventional deep learning, the computing complexity of
optimising LAHs blocks the applications of LAHs. In this paper, we propose a
heuristic approach to constructing an LAH, embedded with LDTs for decision
making or classification by utilising the distance correlations between
attributes and between attributes and the goal variable. The set of attributes
is divided to some attribute clusters, and then they are heuristically
organised to form a linguistic attribute hierarchy. The proposed approach was
validated with some benchmark decision making or classification problems from
the UCI machine learning repository. The experimental results show that the
proposed self-organisation algorithm can construct an effective and efficient
linguistic attribute hierarchy. Such a self-organised linguistic attribute
hierarchy embedded with LDTs can not only efficiently tackle ""curse of
dimensionality"" in a single LDT for data fusion with massive attributes, but
also achieve better or comparable performance on decision making or
classification, compared to the single LDT for the problem to be solved. The
self-organisation algorithm is much efficient than the Genetic Algorithm in
Wrapper for the optimisation of LAHs. This makes it feasible to embed the
self-organisation algorithm in edge devices for IoT intelligence.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:36:05 GMT""}]","2020-06-09"
"2006.04767","Elena Corina Grigore","Freddy A. Boulton and Elena Corina Grigore and Eric M. Wolff","Motion Prediction using Trajectory Sets and Self-Driving Domain
  Knowledge",,,,,"cs.LG cs.CV cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Predicting the future motion of vehicles has been studied using various
techniques, including stochastic policies, generative models, and regression.
Recent work has shown that classification over a trajectory set, which
approximates possible motions, achieves state-of-the-art performance and avoids
issues like mode collapse. However, map information and the physical
relationships between nearby trajectories is not fully exploited in this
formulation. We build on classification-based approaches to motion prediction
by adding an auxiliary loss that penalizes off-road predictions. This auxiliary
loss can easily be pretrained using only map information (e.g., off-road area),
which significantly improves performance on small datasets. We also investigate
weighted cross-entropy losses to capture spatial-temporal relationships among
trajectories. Our final contribution is a detailed comparison of classification
and ordinal regression on two public self-driving datasets.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:37:15 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jan 2021 20:41:54 GMT""}]","2021-01-15"
"2006.04768","Sinong Wang","Sinong Wang, Belinda Z. Li, Madian Khabsa, Han Fang, Hao Ma","Linformer: Self-Attention with Linear Complexity",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large transformer models have shown extraordinary success in achieving
state-of-the-art results in many natural language processing applications.
However, training and deploying these models can be prohibitively costly for
long sequences, as the standard self-attention mechanism of the Transformer
uses $O(n^2)$ time and space with respect to sequence length. In this paper, we
demonstrate that the self-attention mechanism can be approximated by a low-rank
matrix. We further exploit this finding to propose a new self-attention
mechanism, which reduces the overall self-attention complexity from $O(n^2)$ to
$O(n)$ in both time and space. The resulting linear transformer, the
\textit{Linformer}, performs on par with standard Transformer models, while
being much more memory- and time-efficient.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:37:52 GMT""},{""version"":""v2"",""created"":""Tue, 9 Jun 2020 03:03:56 GMT""},{""version"":""v3"",""created"":""Sun, 14 Jun 2020 08:15:54 GMT""}]","2020-06-16"
"2006.04769","Frederick Liu","Frederick Liu, Amir Najmi, Mukund Sundararajan","The Penalty Imposed by Ablated Data Augmentation",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a set of data augmentation techniques that ablate parts of the input
at random. These include input dropout, cutout, and random erasing. We term
these techniques ablated data augmentation. Though these techniques seems
similar in spirit and have shown success in improving model performance in a
variety of domains, we do not yet have a mathematical understanding of the
differences between these techniques like we do for other regularization
techniques like L1 or L2. First, we study a formal model of mean ablated data
augmentation and inverted dropout for linear regression. We prove that ablated
data augmentation is equivalent to optimizing the ordinary least squares
objective along with a penalty that we call the Contribution Covariance Penalty
and inverted dropout, a more common implementation than dropout in popular
frameworks, is equivalent to optimizing the ordinary least squares objective
along with Modified L2. For deep networks, we demonstrate an empirical version
of the result if we replace contributions with attributions and coefficients
with average gradients, i.e., the Contribution Covariance Penalty and Modified
L2 Penalty drop with the increase of the corresponding ablated data
augmentation across a variety of networks.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:38:21 GMT""}]","2020-06-09"
"2006.04770","Aleks Jevnikar","Daniele Bartolucci, Aleks Jevnikar","On the uniqueness and monotonicity of solutions of free boundary
  problems","29 pages","J. Diff. Eq. (2022)","10.1016/j.jde.2021.10.026",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For any $\Omega\subset \mathbb{R}^N$ smooth and bounded domain, we prove
uniqueness of positive solutions of free boundary problems arising in plasma
physics on $\Omega$ in a neat interval depending only by the best constant of
the Sobolev embedding $H^{1}_0(\Omega)\hookrightarrow L^{2p}(\Omega)$, $p\in
[1,\frac{N}{N-2})$ and show that the boundary density and a suitably defined
energy share a universal monotonic behavior. At least to our knowledge, for
$p>1$, this is the first result about the uniqueness for a domain which is not
a two-dimensional ball and in particular the very first result about the
monotonicity of solutions, which seems to be new even for $p=1$. The threshold,
which is sharp for $p=1$, yields a new condition which guarantees that there is
no free boundary inside $\Omega$. As a corollary, in the same range, we solve a
long-standing open problem (dating back to the work of Berestycki-Brezis in
1980) about the uniqueness of variational solutions. Moreover, on a
two-dimensional ball we describe the full branch of positive solutions, that
is, we prove the monotonicity along the curve of positive solutions until the
boundary density vanishes.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:41:27 GMT""},{""version"":""v2"",""created"":""Wed, 10 Jun 2020 06:04:12 GMT""},{""version"":""v3"",""created"":""Mon, 8 Feb 2021 16:54:37 GMT""}]","2021-10-29"
"2006.04771","Miltiadis Allamanis","Sheena Panthaplackel, Miltiadis Allamanis, Marc Brockschmidt","Copy that! Editing Sequences by Copying Spans","Published in AAAI 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural sequence-to-sequence models are finding increasing use in editing of
documents, for example in correcting a text document or repairing source code.
In this paper, we argue that common seq2seq models (with a facility to copy
single tokens) are not a natural fit for such tasks, as they have to explicitly
copy each unchanged token. We present an extension of seq2seq models capable of
copying entire spans of the input to the output in one step, greatly reducing
the number of decisions required during inference. This extension means that
there are now many ways of generating the same output, which we handle by
deriving a new objective for training and a variation of beam search for
inference that explicitly handles this problem. In our experiments on a range
of editing tasks of natural language and source code, we show that our new
model consistently outperforms simpler baselines.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:42:18 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 10:03:21 GMT""}]","2020-12-15"
"2006.04772","Athena Karsa","Athena Karsa and Stefano Pirandola","Noisy receivers for quantum illumination","15 pages, 2 figures","IEEE Aerospace and Electronic Systems Magazine, vol. 35, no. 11,
  pp. 22-29 (2020)","10.1109/MAES.2020.3004019",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum illumination (QI) promises unprecedented performances in target
detection but there are various problems surrounding its implementation. Where
target ranging is a concern, signal and idler recombination forms a crucial
barrier to the protocol's success. This could potentially be mitigated if
performing a measurement on the idler mode could still yield a quantum
advantage. In this paper we investigate the QI protocol for a generically
correlated Gaussian source and study the phase-conjugating (PC) receiver,
deriving the associated SNR in terms of the signal and idler energies, and
their cross-correlations, which may be readily adapted to incorporate added
noise due to Gaussian measurements. We confirm that a heterodyne measurement
performed on the idler mode leads to a performance which asymptotically
approaches that of a coherent state with homodyne detection. However, if the
signal mode is affected by heterodyne but the idler mode is maintained clean,
the performance asymptotically approaches that of the PC receiver without any
added noise.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:42:19 GMT""}]","2020-11-10"
"2006.04773","Konstantinos Mamis","K. I. Mamis","Probabilistic responses of dynamical systems subjected to Gaussian
  coloured noise excitation. Foundations of a non-Markovian theory","217 pages. PhD thesis, National Technical University of Athens, May
  2020. Includes results from arXiv:1811.06579 and arXiv:1811.12383",,"10.26240/heal.ntua.18569",,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The topic of this PhD thesis is the derivation of evolution equations for
probability density functions (pdfs) describing the non-Markovian response to
dynamical systems under Gaussian coloured (smoothly-correlated) noise. These
pdf evolution equations are derived from the stochastic Liouville equations
(SLEs), which are formulated by representing the pdfs as averaged random delta
functions. SLEs are exact yet non-closed, since they contain averaged terms
that are expressed via higher-order pdfs. These averaged terms are further
evaluated by employing generalizations of the Novikov-Furutsu (NF) theorem.
After the NF theorem, SLE averages are expressed equivalently as nonlocal terms
depending on the whole history of the response (in some cases, on the history
of excitation too). Then, nonlocal terms are approximated by a novel closure
scheme, employing the history of appropriate moments of the response (or joint
response-excitation moments). Application of this scheme results in a family of
novel pdf evolution equations. These equations are nonlinear and retain a
tractable amount of the original nonlocality of SLEs, being also in closed form
and solvable. Last, the new evolution equations for the one-time response pdf
are solved numerically and their results are compared to Monte Carlo (MC)
simulations, for the case of a scalar bistable random differential equation
under Ornstein-Uhlenbeck excitation. The results show that the novel evolution
equations are in very good agreement with the MC simulations, even for high
noise intensities and large correlation times of the excitation, that is, away
from the white noise limit, where the existing pdf evolution equations found in
literature fail. It should be noted that the computational effort for solving
the new pdf evolution equations is comparable to the effort required for
solving the respective classical Fokker-Planck-Kolmogorov equation.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:42:59 GMT""}]","2022-02-01"
"2006.04774","Jasel Berra Montiel","R. Cartas-Fuentevilla, J. Berra-Montiel, O. Meza-Aldama","Hyperbolic ring based formulation for thermo field dynamics, quantum
  dissipation, entanglement, and holography","30 pages, 2 figures",,"10.1140/epjc/s10052-020-8161-x",,"hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical and quantum formulations for open systems related to
dissipative dynamics are constructed on a complex hyperbolic ring, following
universal symmetry principles, and considering the double thermal fields
approach for modeling the system of interest, and the environment. The
hyperbolic rotations are revealed as an underlying internal symmetry for the
dissipative dynamics, and a chemical potential is identified as conjugate
variable to the charge operator, and thus a grand partition function is
constructed. As opposed to the standard scheme, there are not patologies
associated with the existence of many unitarity inequivalent representations on
the hyperbolic ring, since the whole of the dissipative quantum dynamics is
realized by choosing only one representation of the field commutation
relations. Entanglement entropy operators for the subsystem of interest and the
environment, are constructed as a tool for study the entanglement generated
from the dissipation. The holographic perspectives of our results are
discussed.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:47:17 GMT""}]","2020-08-26"
"2006.04775","Bernd Beschoten","F. Volmer, M. Ersfeld, L. Rathmann, M. Heithoff, L. Kotewitz, K.
  Watanabe, T. Taniguchi, C. Stampfer, B. Beschoten","How the dynamic of photo-induced gate screening complicates the
  investigation of valley physics in 2D materials","7 pages, 3 figures","Phys. Status Solidi RRL, 2000298 (2020)","10.1002/pssr.202000298",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An in-depth analysis of valley physics in 2D materials like transition metal
dichalcogenides requires the measurement of many material properties as a
function of Fermi level position within the electronic band structure. This is
normally done by changing the charge carrier density of the 2D material via the
gate electric field effect. Here, we show that a comparison of gate-dependent
measurements, which were acquired under different measurement conditions can
encounter significant problems due to the temporal evolution of the charging of
trap states inside the dielectric layer or at its interfaces. The impact of,
e.g., the gate sweep direction and the sweep rate on the overall gate
dependence gets especially prominent in optical measurements due to
photo-excitation of donor and acceptor states. Under such conditions the same
nominal gate-voltage may lead to different gate-induced charge carrier
densities and, hence, Fermi level positions. We demonstrate that a current flow
from or even through the dielectric layer via leakage currents can
significantly diminish the gate tunability in optical measurements of 2D
materials.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:48:32 GMT""}]","2020-07-31"
"2006.04776","Robert Niederriter","Robert D. Niederriter, Chandler Schlupf, Paul Hamilton","Cavity probe for real-time detection of atom dynamics in an optical
  lattice","6+2 pages, 4 figures","Phys. Rev. A 102, 051301 (2020)","10.1103/PhysRevA.102.051301",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose and demonstrate real-time sub-wavelength cavity QED measurements
of the spatial distribution of atoms in an optical lattice. Atoms initially
confined in one ""trap"" standing wave of an optical cavity mode are probed with
a second ""probe"" standing wave. With frequencies offset by one free spectral
range, the nodes of the trap fall on the anti-nodes of the probe in the
${\approx}$10$^4$ lattice sites around the center of the cavity. This lattice
site independent atom-cavity coupling enables high sensitivity detection of
atom dynamics even with atoms spread over many lattice sites. To demonstrate,
we measure the temperature of 20-70 $\mu$K atom ensembles in ${<}$10 $\mu$s by
monitoring their expansion of ${\approx}$100 nm after sudden release from the
trap lattice. Atom-cavity coupling imprints the atom dynamics on the probe
transmission. The new technique will enable improved non-destructive detection
of Bloch oscillations and other atom dynamics in optical lattices.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:48:46 GMT""}]","2020-11-18"
"2006.04777","Subhadeep Sarkar","Subhadeep Sarkar, Tarikul Islam Papon, Dimitris Staratzis, Manos
  Athanassoulis","Lethe: A Tunable Delete-Aware LSM Engine (Updated Version)",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data-intensive applications fueled the evolution of log structured merge
(LSM) based key-value engines that employ the out-of-place paradigm to support
high ingestion rates with low read/write interference. These benefits, however,
come at the cost of treating deletes as a second-class citizen. A delete
inserts a tombstone that invalidates older instances of the deleted key.
State-of-the-art LSM engines do not provide guarantees as to how fast a
tombstone will propagate to persist the deletion. Further, LSM engines only
support deletion on the sort key. To delete on another attribute (e.g.,
timestamp), the entire tree is read and re-written. We highlight that fast
persistent deletion without affecting read performance is key to support: (i)
streaming systems operating on a window of data, (ii) privacy with latency
guarantees on the right-to-be-forgotten, and (iii) en masse cloud deployment of
data systems that makes storage a precious resource.
  To address these challenges, in this paper, we build a new key-value storage
engine, Lethe, that uses a very small amount of additional metadata, a set of
new delete-aware compaction policies, and a new physical data layout that
weaves the sort and the delete key order. We show that Lethe supports any
user-defined threshold for the delete persistence latency offering higher read
throughput ($1.17-1.4\times$) and lower space amplification ($2.1-9.8\times$),
with a modest increase in write amplification (between $4\%$ and $25\%$). In
addition, Lethe supports efficient range deletes on a secondary delete key by
dropping entire data pages without sacrificing read performance nor employing a
costly full tree merge.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:52:03 GMT""},{""version"":""v2"",""created"":""Tue, 9 Jun 2020 01:06:57 GMT""},{""version"":""v3"",""created"":""Thu, 11 Jun 2020 01:23:44 GMT""},{""version"":""v4"",""created"":""Sat, 13 Jun 2020 00:01:32 GMT""}]","2020-06-16"
"2006.04778","Vijay Keswani","L. Elisa Celis and Lingxiao Huang and Vijay Keswani and Nisheeth K.
  Vishnoi","Fair Classification with Noisy Protected Attributes: A Framework with
  Provable Guarantees",,,,,"cs.LG cs.AI cs.CY cs.DS stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an optimization framework for learning a fair classifier in the
presence of noisy perturbations in the protected attributes. Compared to prior
work, our framework can be employed with a very general class of linear and
linear-fractional fairness constraints, can handle multiple, non-binary
protected attributes, and outputs a classifier that comes with provable
guarantees on both accuracy and fairness. Empirically, we show that our
framework can be used to attain either statistical rate or false positive rate
fairness guarantees with a minimal loss in accuracy, even when the noise is
large, in two real-world datasets.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:52:48 GMT""},{""version"":""v2"",""created"":""Wed, 14 Oct 2020 14:18:18 GMT""},{""version"":""v3"",""created"":""Tue, 16 Feb 2021 17:21:58 GMT""}]","2021-02-17"
"2006.04779","Aviral Kumar","Aviral Kumar, Aurick Zhou, George Tucker, Sergey Levine","Conservative Q-Learning for Offline Reinforcement Learning","Preprint. Website at: https://sites.google.com/view/cql-offline-rl",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Effectively leveraging large, previously collected datasets in reinforcement
learning (RL) is a key challenge for large-scale real-world applications.
Offline RL algorithms promise to learn effective policies from
previously-collected, static datasets without further interaction. However, in
practice, offline RL presents a major challenge, and standard off-policy RL
methods can fail due to overestimation of values induced by the distributional
shift between the dataset and the learned policy, especially when training on
complex and multi-modal data distributions. In this paper, we propose
conservative Q-learning (CQL), which aims to address these limitations by
learning a conservative Q-function such that the expected value of a policy
under this Q-function lower-bounds its true value. We theoretically show that
CQL produces a lower bound on the value of the current policy and that it can
be incorporated into a policy learning procedure with theoretical improvement
guarantees. In practice, CQL augments the standard Bellman error objective with
a simple Q-value regularizer which is straightforward to implement on top of
existing deep Q-learning and actor-critic implementations. On both discrete and
continuous control domains, we show that CQL substantially outperforms existing
offline RL methods, often learning policies that attain 2-5 times higher final
return, especially when learning from complex and multi-modal data
distributions.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:53:42 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 17:46:40 GMT""},{""version"":""v3"",""created"":""Wed, 19 Aug 2020 17:07:05 GMT""}]","2020-08-20"
"2006.04780","Alexander Bogatskiy","Alexander Bogatskiy, Brandon Anderson, Jan T. Offermann, Marwah
  Roussi, David W. Miller, Risi Kondor","Lorentz Group Equivariant Neural Network for Particle Physics",,,,,"hep-ph cs.LG hep-ex physics.comp-ph stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a neural network architecture that is fully equivariant with
respect to transformations under the Lorentz group, a fundamental symmetry of
space and time in physics. The architecture is based on the theory of the
finite-dimensional representations of the Lorentz group and the equivariant
nonlinearity involves the tensor product. For classification tasks in particle
physics, we demonstrate that such an equivariant architecture leads to
drastically simpler models that have relatively few learnable parameters and
are much more physically interpretable than leading approaches that use CNNs
and point cloud approaches. The competitive performance of the network is
demonstrated on a public classification dataset [27] for tagging top quark
decays given energy-momenta of jet constituents produced in proton-proton
collisions.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:54:43 GMT""}]","2020-06-09"
"2006.04781","Samuel L\""aubli","Lukas Fischer and Samuel L\""aubli","What's the Difference Between Professional Human and Machine
  Translation? A Blind Multi-language Study on Domain-specific MT","EAMT 2020 (Research Track)",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine translation (MT) has been shown to produce a number of errors that
require human post-editing, but the extent to which professional human
translation (HT) contains such errors has not yet been compared to MT. We
compile pre-translated documents in which MT and HT are interleaved, and ask
professional translators to flag errors and post-edit these documents in a
blind evaluation. We find that the post-editing effort for MT segments is only
higher in two out of three language pairs, and that the number of segments with
wrong terminology, omissions, and typographical problems is similar in HT.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:55:14 GMT""}]","2020-06-09"
"2006.04782","Moon jip Park","Moon Jip Park and GiBaik Sim and Min Yong Jeong and Archana Mishra and
  Myung Joon Han and SungBin Lee","Pressure Induced Topological Superconductivity in the Spin-Orbit Mott
  Insulator GaTa4Se8","5+11 pages, accepted in npj Quantum Materials",,,,"cond-mat.str-el cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lacunar spinel GaTa$_4$Se$_8$ is a unique example of spin-orbit coupled Mott
insulator described by molecular $j_{\text{eff}}\!=\!3/2$ states. It becomes
superconducting at T$_c$=5.8K under pressure without doping. In this work, we
show, this pressure-induced superconductivity is a realization of a new type
topological phase characterized by spin-2 Cooper pairs. Starting from
first-principles density functional calculations and random phase
approximation, we construct the microscopic model and perform the detailed
analysis. Applying pressure is found to trigger the virtual interband tunneling
processes assisted by strong Hund coupling, thereby stabilizing a particular
$d$-wave quintet channel. Furthermore, we show that its Bogoliubov
quasiparticles and their surface states exhibit novel topological nature. To
verify our theory, we propose unique experimental signatures that can be
measured by Josephson junction transport and scanning tunneling microscope. Our
findings open up new directions searching for exotic superconductivity in
spin-orbit coupled materials.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:55:34 GMT""}]","2020-06-09"
"2006.04783","David Sumner Lipham","David S. Lipham","Distinguishing endpoint sets from Erd\H{o}s space","11 pages, 4 figures","Mathematical Proceedings of the Cambridge Philosophical Society
  (2022)","10.1017/S0305004122000032",,"math.DS math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the set of all endpoints of the Julia set of $f(z)=\exp(z)-1$
which escape to infinity under iteration of $f$ is not homeomorphic to the
rational Hilbert space $\mathfrak E$. As a corollary, we show that the set of
all points $z\in \mathbb C$ whose orbits either escape to $\infty$ or attract
to $0$ is path-connected. We extend these results to many other functions in
the exponential family.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:56:05 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 14:19:00 GMT""},{""version"":""v3"",""created"":""Tue, 16 Jun 2020 17:57:09 GMT""},{""version"":""v4"",""created"":""Thu, 18 Jun 2020 22:33:50 GMT""},{""version"":""v5"",""created"":""Sun, 12 Jul 2020 17:18:53 GMT""},{""version"":""v6"",""created"":""Sat, 29 Aug 2020 16:08:23 GMT""},{""version"":""v7"",""created"":""Tue, 27 Oct 2020 22:07:40 GMT""},{""version"":""v8"",""created"":""Tue, 15 Dec 2020 18:27:42 GMT""},{""version"":""v9"",""created"":""Wed, 26 Jan 2022 20:13:14 GMT""}]","2022-04-13"
"2006.04784","Sulin Wang","Andrew Christlieb, Keith Promislow, Zengqiang Tan, Sulin Wang, Brian
  Wetton, Steven Wise","Benchmark Computation of Morphological Complexity in the Functionalized
  Cahn-Hilliard Gradient Flow","34 pages,18 figures,7 tables",,,,"physics.comp-ph cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reductions of the self-consistent mean field theory model of amphiphilic
molecules in solvent leads to a singular family of functionalized Cahn-Hilliard
(FCH) energies. We modify the energy, removing singularities to stabilize the
computation of the gradient flows and develop a series of benchmark problems
that emulate the ""morphological complexity"" observed in experiments. These
benchmarks investigate the delicate balance between the rate of arrival of
amphiphilic materials onto an interface and a least energy mechanism to
accommodate the arriving mass. The result is a trichotomy of responses in which
two-dimensional interfaces grow either by a regularized motion against
curvature, pearling bifurcations, or curve-splitting directly into networks of
interfaces. We evaluate a number of schemes that use second order BDF2-type
time stepping coupled with Fourier pseudo-spectral spatial discretization. The
BDF2-type schemes are either based on a fully implicit time discretization with
a preconditioned steepest descent (PSD) nonlinear solver or upon linearly
implicit time discretization based on the standard implicit-explicit (IMEX) and
the scalar auxiliary variable (SAV) approaches. We add an exponential time
differencing (ETD) scheme for comparison purposes. All schemes use a fixed
local truncation error target with adaptive time-stepping to achieve the error
target. Each scheme requires proper ""preconditioning"" to achieve robust
performance that can enhance efficiency by several orders of magnitude. The
nonlinear PSD scheme achieves the smallest global discretization error at fixed
local truncation error, however the IMEX and SAV schemes are the most
computationally efficient as measured by the number of FFT calls required to
achieve a desired global error.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:56:05 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 01:44:04 GMT""},{""version"":""v3"",""created"":""Fri, 4 Mar 2022 10:28:48 GMT""}]","2022-03-07"
"2006.04785","Hung Tran","Diogo A. Gomes, Hiroyoshi Mitake, Hung V. Tran","The large time profile for Hamilton--Jacobi--Bellman equations","43 pages",,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here, we study the large-time limit of viscosity solutions of the Cauchy
problem for second-order Hamilton--Jacobi--Bellman equations with convex
Hamiltonians in the torus. This large-time limit solves the corresponding
stationary problem, sometimes called the ergodic problem. This problem,
however, has multiple viscosity solutions and, thus, a key question is which of
these solutions is selected by the limit. Here, we provide a representation for
the viscosity solution to the Cauchy problem in terms of generalized holonomic
measures. Then, we use this representation to characterize the large-time limit
in terms of the initial data and generalized Mather measures. In addition, we
establish various results on generalized Mather measures and duality theorems
that are of independent interest.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:57:03 GMT""}]","2020-06-09"
"2006.04786","Jiaojian Shi","Jiaojian Shi, Edoardo Baldini, Simone Latini, Shunsuke A. Sato, Yaqing
  Zhang, Brandt C. Pein, Pin-Chun Shen, Jing Kong, Angel Rubio, Nuh Gedik and
  Keith A. Nelson","Room Temperature Terahertz Electroabsorption Modulation by Excitons in
  Monolayer Transition Metal Dichalcogenides","40 pages, 11 figures",,"10.1021/acs.nanolett.0c01134",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interaction between off-resonant laser pulses and excitons in monolayer
transition metal dichalcogenides is attracting increasing interest as a route
for the valley-selective coherent control of the exciton properties. Here, we
extend the classification of the known off-resonant phenomena by unveiling the
impact of a strong THz field on the excitonic resonances of monolayer MoS$_2$.
We observe that the THz pump pulse causes a selective modification of the
coherence lifetime of the excitons, while keeping their oscillator strength and
peak energy unchanged. We rationalize these results theoretically by invoking a
hitherto unobserved manifestation of the Franz-Keldysh effect on an exciton
resonance. As the modulation depth of the optical absorption reaches values as
large as 0.05 dB/nm at room temperature, our findings open the way to the use
of semiconducting transition metal dichalcogenides as compact and efficient
platforms for high-speed electroabsorption devices.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:57:50 GMT""}]","2020-08-26"
"2006.04787","Sitan Chen","Sitan Chen, Frederic Koehler, Ankur Moitra, Morris Yau","Classification Under Misspecification: Halfspaces, Generalized Linear
  Models, and Connections to Evolvability","51 pages, comments welcome",,,,"cs.LG cs.DS math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we revisit some classic problems on classification under
misspecification. In particular, we study the problem of learning halfspaces
under Massart noise with rate $\eta$. In a recent work, Diakonikolas,
Goulekakis, and Tzamos resolved a long-standing problem by giving the first
efficient algorithm for learning to accuracy $\eta + \epsilon$ for any
$\epsilon > 0$. However, their algorithm outputs a complicated hypothesis,
which partitions space into $\text{poly}(d,1/\epsilon)$ regions. Here we give a
much simpler algorithm and in the process resolve a number of outstanding open
questions:
  (1) We give the first proper learner for Massart halfspaces that achieves
$\eta + \epsilon$. We also give improved bounds on the sample complexity
achievable by polynomial time algorithms.
  (2) Based on (1), we develop a blackbox knowledge distillation procedure to
convert an arbitrarily complex classifier to an equally good proper classifier.
  (3) By leveraging a simple but overlooked connection to evolvability, we show
any SQ algorithm requires super-polynomially many queries to achieve
$\mathsf{OPT} + \epsilon$.
  Moreover we study generalized linear models where $\mathbb{E}[Y|\mathbf{X}] =
\sigma(\langle \mathbf{w}^*, \mathbf{X}\rangle)$ for any odd, monotone, and
Lipschitz function $\sigma$. This family includes the previously mentioned
halfspace models as a special case, but is much richer and includes other
fundamental models like logistic regression. We introduce a challenging new
corruption model that generalizes Massart noise, and give a general algorithm
for learning in this setting. Our algorithms are based on a small set of core
recipes for learning to classify in the presence of misspecification.
  Finally we study our algorithm for learning halfspaces under Massart noise
empirically and find that it exhibits some appealing fairness properties.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:59:11 GMT""}]","2020-06-09"
"2006.04788","Alex Campbell","Alex Campbell, Pietro Li\`o","tvGP-VAE: Tensor-variate Gaussian Process Prior Variational Autoencoder","8 pages, 2 Figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variational autoencoders (VAEs) are a powerful class of deep generative
latent variable model for unsupervised representation learning on
high-dimensional data. To ensure computational tractability, VAEs are often
implemented with a univariate standard Gaussian prior and a mean-field Gaussian
variational posterior distribution. This results in a vector-valued latent
variables that are agnostic to the original data structure which might be
highly correlated across and within multiple dimensions. We propose a
tensor-variate extension to the VAE framework, the tensor-variate Gaussian
process prior variational autoencoder (tvGP-VAE), which replaces the standard
univariate Gaussian prior and posterior distributions with tensor-variate
Gaussian processes. The tvGP-VAE is able to explicitly model correlation
structures via the use of kernel functions over the dimensions of tensor-valued
latent variables. Using spatiotemporally correlated image time series as an
example, we show that the choice of which correlation structures to explicitly
represent in the latent space has a significant impact on model performance in
terms of reconstruction.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:59:13 GMT""}]","2020-06-09"
"2006.04789","Takenori Kataoka","Takenori Kataoka","Fitting invariants in equivariant Iwasawa theory","40 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main conjectures in Iwasawa theory predict the relationship between the
Iwasawa modules and the $p$-adic $L$-functions. Using a certain proved
formulation of the main conjecture, Greither and Kurihara described explicitly
the (initial) Fitting ideals of the Iwasawa modules for the cyclotomic
$\mathbb{Z}_p$-extensions of finite abelian extensions of totally real fields.
In this paper, we generalize the algebraic theory behind their work by
developing the theory of ``shifts of Fitting invariants.'' As applications to
Iwasawa theory, we obtain a noncommutative version and a two-variable version
of the work of Greither and Kurihara.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:59:15 GMT""}]","2020-06-09"
"2006.04790","Brett Meggison","M.E. Carrington, A.R. Frey, B.A. Meggison","The effect of anisotropy on phase transitions in graphene",,"Phys. Rev. B 102, 125427 (2020)","10.1103/PhysRevB.102.125427",,"cond-mat.mes-hall hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the effect of anisotropy (strain) on dynamical gap generation in
graphene. We work with a low energy effective theory obtained from a
tight-binding Hamiltonian expanded around the Dirac points in momentum space.
We use a non-perturbative Schwinger-Dyson approach and calculate a coupled set
of five momentum dependent dressing functions. Our results show that the
critical coupling depends only weakly on the anisotropy parameter, and
increases with greater anisotropy.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:59:16 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 21:24:54 GMT""}]","2021-06-08"
"2006.04791","Przemek Witaszczyk","Romuald A. Janik, Przemek Witaszczyk","Complexity for deep neural networks and other characteristics of deep
  feature representations","Significant extension including developments in neuroscience context
  and more. 36 pages",,,,"cs.LG cond-mat.dis-nn cs.NE hep-th stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a notion of complexity, which quantifies the nonlinearity of the
computation of a neural network, as well as a complementary measure of the
effective dimension of feature representations. We investigate these
observables both for trained networks for various datasets as well as explore
their dynamics during training, uncovering in particular power law scaling.
These observables can be understood in a dual way as uncovering hidden internal
structure of the datasets themselves as a function of scale or depth. The
entropic character of the proposed notion of complexity should allow to
transfer modes of analysis from neuroscience and statistical physics to the
domain of artificial neural networks. The introduced observables can be applied
without any change to the analysis of biological neuronal systems.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:59:30 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 14:50:33 GMT""}]","2021-03-18"
"2006.04792","Joao Caetano","Joao Caetano, Wolfger Peelaers, Leonardo Rastelli","Maximally Supersymmetric RG Flows in 4D and Integrability","39 pages; v2: references and comments added",,"10.1007/JHEP12(2021)119",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the leading irrelevant deformation of $\mathcal{N}=4$ Super
Yang-Mills theory that preserves sixteen supercharges. We consider the deformed
theory on $S^3 \times \mathbb{R}$. We are able to write a closed form
expression of the classical action thanks to a formalism that realizes eight
supercharges off shell. We then investigate integrability of the spectral
problem, by studying the spin-chain Hamiltonian in planar perturbation theory.
While there are some structural indications that a suitably defined deformation
might preserve integrability, we are unable to settle this question by our
two-loop calculation; indeed up to this order we recover the integrable
Hamiltonian of undeformed $\mathcal{N}=4$ SYM due to accidental symmetry
enhancement. We also comment on the holographic interpretation of the theory.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:59:41 GMT""},{""version"":""v2"",""created"":""Wed, 29 Sep 2021 22:16:37 GMT""}]","2022-01-05"
"2006.04802","Chi Zhang","Chi Zhang, Sanmukh Rao Kuppannagari, Viktor K Prasanna","Maximum Entropy Model Rollouts: Fast Model Based Policy Optimization
  without Compounding Errors","ICML BIG Workshop 2020, camera ready version",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model usage is the central challenge of model-based reinforcement learning.
Although dynamics model based on deep neural networks provide good
generalization for single step prediction, such ability is over exploited when
it is used to predict long horizon trajectories due to compounding errors. In
this work, we propose a Dyna-style model-based reinforcement learning
algorithm, which we called Maximum Entropy Model Rollouts (MEMR). To eliminate
the compounding errors, we only use our model to generate single-step rollouts.
Furthermore, we propose to generate \emph{diverse} model rollouts by
non-uniform sampling of the environment states such that the entropy of the
model rollouts is maximized. We mathematically derived the maximum entropy
sampling criteria for one data case under Gaussian prior. To accomplish this
criteria, we propose to utilize a prioritized experience replay. Our
preliminary experiments in challenging locomotion benchmarks show that our
approach achieves the same sample efficiency of the best model-based
algorithms, matches the asymptotic performance of the best model-free
algorithms, and significantly reduces the computation requirements of other
model-based methods.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:38:15 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 00:07:27 GMT""}]","2020-06-30"
"2006.04803","Omar Abdul Wahab","Omar Abdel Wahab, Jamal Bentahar, Robin Cohen, Hadi Otrok, Azzam
  Mourad","A two-level solution to fight against dishonest opinions in
  recommendation-based trust systems","12 pages",,,,"cs.IR cs.CY cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a mechanism to deal with dishonest opinions in
recommendation-based trust models, at both the collection and processing
levels. We consider a scenario in which an agent requests recommendations from
multiple parties to build trust toward another agent. At the collection level,
we propose to allow agents to self-assess the accuracy of their recommendations
and autonomously decide on whether they would participate in the recommendation
process or not. At the processing level, we propose a recommendations
aggregation technique that is resilient to collusion attacks, followed by a
credibility update mechanism for the participating agents. The originality of
our work stems from its consideration of dishonest opinions at both the
collection and processing levels, which allows for better and more persistent
protection against dishonest recommenders. Experiments conducted on the
Epinions dataset show that our solution yields better performance in protecting
the recommendation process against Sybil attacks, in comparison with a
competing model that derives the optimal network of advisors based on the
agents' trust values.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 00:34:11 GMT""}]","2020-06-11"
"2006.04806","Ruimin Sun","Ruimin Sun, Alejandro Mera, Long Lu, David Choffnes","SoK: Attacks on Industrial Control Logic and Formal Verification-Based
  Defenses","18 pages w/ ref, Sok, PLC, ICS, CPS, attack, formal verification",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Programmable Logic Controllers (PLCs) play a critical role in the industrial
control systems. Vulnerabilities in PLC programs might lead to attacks causing
devastating consequences to the critical infrastructure, as shown in Stuxnet
and similar attacks. In recent years, we have seen an exponential increase in
vulnerabilities reported for PLC control logic. Looking back on past research,
we found extensive studies explored control logic modification attacks, as well
as formal verification-based security solutions. We performed systematization
on these studies, and found attacks that can compromise a full chain of control
and evade detection. However, the majority of the formal verification research
investigated ad-hoc techniques targeting PLC programs. We discovered challenges
in every aspect of formal verification, rising from (1) the ever-expanding
attack surface from evolved system design, (2) the real-time constraint during
the program execution, and (3) the barrier in security evaluation given
proprietary and vendor-specific dependencies on different techniques. Based on
the knowledge systematization, we provide a set of recommendations for future
research directions, and we highlight the need of defending security issues
besides safety issues.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:20:19 GMT""},{""version"":""v2"",""created"":""Wed, 11 Nov 2020 04:21:37 GMT""},{""version"":""v3"",""created"":""Tue, 23 Mar 2021 16:24:15 GMT""}]","2021-03-24"
"2006.04807","Anjali Piette","Anjali A. A. Piette, Nikku Madhusudhan, Laura K. McKemmish, Siddharth
  Gandhi, Thomas Masseron, Luis Welbanks","Assessing Spectra and Thermal Inversions due to TiO in Hot Jupiter
  Atmospheres","Accepted for publication in MNRAS, 19 pages, 14 figures",,"10.1093/mnras/staa1592",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent detections of thermal inversions in the dayside atmospheres of some
hot Jupiters are motivating new avenues to understand the interplay between
their temperature structures and other atmospheric conditions. In particular,
TiO has long been proposed to cause thermal inversions in hot Jupiters,
depending on other factors such as stellar irradiation, C/O, and vertical
mixing. TiO also has spectral features in the optical and near-infrared that
have been detected. However, interpretations of TiO signatures rely on the
accuracy of TiO opacity used in the models. The recently reported Toto TiO line
list provides a new opportunity to investigate these dependencies, which is the
goal of the present work. First, we investigate how the Toto line list affects
observable transmission and emission spectra of hot Jupiters at low and high
resolution. The improvement in the Toto line list compared to a previous line
list results in observable differences in the model spectra, particularly in
the optical at high resolution. Secondly, we explore the interplay between
temperature structure, irradiation and composition with TiO as the primary
source of optical opacity, using 1D self-consistent atmospheric models. Among
other trends, we find that the propensity for thermal inversions due to TiO
peaks at C/O$\sim$0.9, consistent with recent studies. Using these models, we
further assess metrics to quantify thermal inversions due to TiO, compared to
frequently-used Spitzer photometry, over a range in C/O, irradiation,
metallicity, gravity and stellar type.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:00 GMT""}]","2020-07-15"
"2006.04808","Andrea Botteon","A. Botteon, G. Brunetti, R. J. van Weeren, T. W. Shimwell, R. F.
  Pizzo, R. Cassano, M. Iacobelli, F. Gastaldello, L. B\^irzan, A. Bonafede, M.
  Br\""uggen, V. Cuciti, D. Dallacasa, F. de Gasperin, G. Di Gennaro, A.
  Drabent, M. J. Hardcastle, M. Hoeft, S. Mandal, H. J. A. R\""ottgering, A.
  Simionescu","The beautiful mess in Abell 2255","17 pages, 13 figures, 4 tables (including appendix). Accepted for
  publication in ApJ",,"10.3847/1538-4357/ab9a2f",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present LOFAR observations of one of the most spectacular objects in the
radio sky: Abell 2255. This is a nearby ($z = 0.0806$) merging galaxy cluster
hosting one of the first radio halos ever detected in the intra-cluster medium
(ICM). The deep LOFAR images at 144 MHz of the central $\sim10$ Mpc$^2$ region
show a plethora of emission on different scales, from tens of kpc to above Mpc
sizes. In this work, we focus on the innermost region of the cluster. Among the
numerous interesting features observed, we discover remarkable bright and
filamentary structures embedded in the radio halo. We incorporate archival WSRT
1.2 GHz data to study the spectral properties of the diffuse synchrotron
emission and find a very complex spectral index distribution in the halo
spanning a wide range of values. We combine the radio data with Chandra
observations to investigate the connection between the thermal and non-thermal
components by quantitatively comparing the radio and X-ray surface brightness
and the spectral index of the radio emission with the thermodynamical
quantities of the ICM. Despite the multitude of structures observed in the
radio halo, we find that the X-ray and radio emission are overall well
correlated. The fact that the steepest spectrum emission is located in the
cluster center and traces regions with high entropy possibly suggests the
presence of seed particles injected by radio galaxies that are spread in the
ICM by turbulence generating the extended radio halo.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:00 GMT""}]","2020-07-15"
"2006.04809","Raymond Co","Raymond T. Co, Lawrence J. Hall, and Keisuke Harigaya","Predictions for Axion Couplings from ALP Cogenesis","24 pages, 3 figures",,"10.1007/JHEP01(2021)172","LCTP-20-11","hep-ph astro-ph.CO hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adding an axion-like particle (ALP) to the Standard Model, with a field
velocity in the early universe, simultaneously explains the observed baryon and
dark matter densities. This requires one or more couplings between the ALP and
photons, nucleons, and/or electrons that are predicted as functions of the ALP
mass. These predictions arise because the ratio of dark matter to baryon
densities is independent of the ALP field velocity, allowing a correlation
between the ALP mass, $m_a$, and decay constant, $f_a$. The predicted couplings
are orders of magnitude larger than those for the QCD axion and for dark matter
from the conventional ALP misalignment mechanism. As a result, this scheme, ALP
cogenesis, is within reach of future experimental ALP searches from the lab and
stellar objects, and for dark matter.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:00 GMT""}]","2021-02-24"
"2006.04810","Stephen Taylor","Stephen R. Taylor, Rutger van Haasteren, Alberto Sesana","From Bright Binaries To Bumpy Backgrounds: Mapping Realistic
  Gravitational Wave Skies With Pulsar-Timing Arrays","19 pages, 7 figures. Code available at
  https://github.com/stevertaylor/gworf. Matches version accepted by PRD","Phys. Rev. D 102, 084039 (2020)","10.1103/PhysRevD.102.084039",,"astro-ph.IM astro-ph.GA gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the next several years, pulsar-timing array programs will likely usher
in the next era of gravitational-wave astronomy through the detection of a
stochastic background of nanohertz-frequency gravitational waves, originating
from a cosmological population of inspiraling supermassive binary black holes.
While the source positions will likely be isotropic to a good approximation,
the gravitational-wave angular power distribution will be anisotropic, with the
most massive and/or nearby binaries producing signals that may resound above
the background. We study such a realistic angular power distribution,
developing fast and accurate sky-mapping strategies to localize pixels and
extended regions of excess power while simultaneously modeling the background
signal from the less massive and more distant ensemble. We find that power
anisotropy will be challenging to discriminate from isotropy for realistic
gravitational-wave skies, requiring SNR $>10$ in order to favor anisotropy with
$10:1$ posterior odds in our case study. Amongst our techniques, modeling the
population signal with multiple point sources in addition to an isotropic
background provides the most physically-motivated and easily interpreted maps,
while spherical-harmonic modeling of the square-root power distribution,
$P(\hat\Omega)^{1/2}$, performs best in discriminating from overall isotropy.
Our techniques are modular and easily incorporated into existing pulsar-timing
array analysis pipelines.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 26 Aug 2020 16:02:43 GMT""}]","2020-10-21"
"2006.04811","S Adam Stanford-Moore","S Adam Stanford-Moore, Eric L. Nielsen, Robert J. De Rosa, Bruce
  Macintosh, Ian Czekala","BAFFLES: Bayesian Ages for Field Lower-Mass Stars","Accepted to ApJ, 80 pages, 14 figures, 3 tables",,"10.3847/1538-4357/ab9a35",,"astro-ph.SR astro-ph.EP astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Age is a fundamental parameter of stars, yet in many cases ages of individual
stars are presented without robust estimates of the uncertainty. We have
developed a Bayesian framework, BAFFLES, to produce the age posterior for a
star from its calcium emission strength (log($R'_{HK}$)) or lithium abundance
(Li EW) and $B-V$ color. We empirically determine the likelihood functions for
calcium and lithium as functions of age from literature measurements of stars
in benchmark clusters with well-determined ages. We use a uniform prior on age
which reflects a uniform star formation rate. The age posteriors we derive for
several test cases are consistent with literature ages found from other
methods. BAFFLES represents a robust method to determine the age posterior
probability distribution for any field star with $0.45 \leq B-V \leq 0.9$ and a
measurement of $R'_{HK}$ and/or $0.35 \leq B-V \leq 1.9$ and measured Li EW. We
compile colors, $R'_{HK}$, and Li EW from over 2630 nearby field stars from the
literature and present the derived BAFFLES age posterior for each star.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 18:30:35 GMT""}]","2020-10-07"
"2006.04812","Cheng Cheng","Cheng Cheng, Edo Ibar, Wei Du, Juan Molina, Gustavo
  Orellana-Gonz\'ales, Bo Zhang, Ming Zhu, Cong Kevin Xu, Shumei Wu, Tianwen
  Cao, Jia-Sheng Huang, Roger Leiton, Thomas M. Hughes, Chuan He, Zijian Li,
  Hai Xu, Y. Sophia Dai, Xu Shao, Marat Musin","The atomic gas of star-forming galaxies at z$\sim$0.05 as revealed by
  the Five-hundred-meter Aperture Spherical Radio Telescope","5 pages, 3 figures, 2 appendix, A&A Letter accepted","A&A 638, L14 (2020)","10.1051/0004-6361/202038483",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We report new HI observations of four z$\sim$0.05 star-forming galaxies
undertaken during the commissioning phase of the Five-hundred-meter Aperture
Spherical Radio Telescope (FAST). FAST is the largest single-dish telescope
with a 500 meter aperture and a 19-Beam receiver. Exploiting the unprecedented
sensitivity provided by FAST, we aim to study the atomic gas, via the HI 21cm
emission line, in low-$z$ star-forming galaxies taken from the Valpara\'iso
ALMA/APEX Line Emission Survey (VALES) project. Together with previous ALMA
CO($J=1-0$) observations, the HI data provides crucial information to measure
the gas mass and dynamics. As a pilot HI survey, we targeted four local
star-forming galaxies at $z\sim0.05$. In particular, one of them has already
been detected in HI by the Arecibo Legacy Fast ALFA survey (ALFALFA), allowing
a careful comparison. We use an ON-OFF observing approach that allowed us to
reach an rms of 0.7mJy/beam at a 1.7km/s velocity resolution within only 20
minutes ON-target integration time. We demonstrate the great capabilities of
the FAST 19-beam receiver for pushing the detectability of the HI emission line
of extra-galactic sources. The HI emission line detected by FAST shows good
consistency with the previous ALFALFA results. Our observations are put in
context with previous multi-wavelength data to reveal the physical properties
of these low-$z$ galaxies. We find that the CO($J=1-0$) and HI emission line
profiles are similar. The dynamical mass estimated from the HI data is an order
of magnitude higher than the baryon mass and the dynamical mass derived from
the CO observations, implying that the mass probed by dynamics of HI is
dominated by the dark matter halo. In one case, a target shows an excess of
CO($J=1-0$) in the line centre, which can be explained by an enhanced
CO($J=1-0$) emission induced by a nuclear starburst showing high velocity
dispersion.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:01 GMT""}]","2020-07-01"
"2006.04813","Nazim Boudjada","Nazim Boudjada, Finn Lasse Buessen, and Arun Paramekanti","Domes of $T_c$ in single-band and multiband superconductors with
  finite-range attractive interactions","13 pages including appendices, 11 figures","Phys. Rev. B 102, 054504 (2020)","10.1103/PhysRevB.102.054504",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rise and fall of the superconducting transition temperature $T_c$ upon
tuning carrier density or external parameters, such as pressure or magnetic
field, is ubiquitously observed in a wide range of quantum materials. In order
to investigate such domes of $T_c$, we go beyond the prototypical attractive
Hubbard model, and consider a lattice model of electrons coupled via
instantaneous, spatially extended, attractive interactions. By numerically
solving the mean-field equations, as well as going beyond mean field theory
using a functional renormalization group approach, we find that for a
characteristic interaction range $\ell$, there exists a dome in $T_c$ around
$k_F \ell \! \sim \! {\mathcal{O}}(1)$. For multiband systems, our mean field
theory shows the presence of additional domes in the vicinity of Lifshitz
transitions. Our results hold in both two and three dimensions and can be
intuitively understood from the geometric relation between the Fermi surface
and the interaction range. Our model may be relevant for domes of $T_c$ in
dilute weakly coupled superconductors or in engineered cold atom systems.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 11 Aug 2020 18:00:00 GMT""},{""version"":""v3"",""created"":""Fri, 14 Aug 2020 13:40:20 GMT""}]","2020-08-17"
"2006.04814","Bin Liu","Bin Liu, Rongmon Bordoloi","A Deep Learning Approach to Quasar Continuum Prediction","MNRAS Accepted 2021 January 18. 24 pages, 18 figures",,"10.1093/mnras/stab177",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel intelligent quasar continuum neural network (iQNet),
predicting the intrinsic continuum of any quasar in the rest-frame wavelength
range 1020 Angstroms $\leq \lambda \leq$ 1600 Angstroms. We train this network
using high-resolution Hubble Space Telescope/Cosmic Origin Spectrograph
ultraviolet quasar spectra at low redshift ($z \sim 0.2$) from the Hubble
Spectroscopic Legacy Archive, and apply it to predict quasar continua from
different astronomical surveys. We utilize the HSLA quasar spectra that are
well-defined in the rest-frame wavelength range [1020, 1600] Angstroms with an
overall median signal-to-noise ratio of at least five. The iQNet achieves a
median AFFE of 2.24% on the training quasar spectra, and 4.17% on the testing
quasar spectra. We apply iQNet and predict the continua of $\sim$3200 SDSS-DR16
quasar spectra at higher redshift ($2< z \leq 5$) and measure the redshift
evolution of mean transmitted flux ($< F >$) in the Ly-$\alpha$ forest region.
We measure a gradual evolution of $< F >$ with redshift, which we characterize
as a power-law fit to the effective optical depth of the Ly-$\alpha$ forest.
Our measurements are broadly consistent with other estimates of $<F>$ in the
literature, but provide a more accurate measurement as we are directly
measuring the quasar continuum where there is minimum contamination from the
Ly-$\alpha$ forest. This work proves that the deep learning iQNet model can
predict the quasar continuum with high accuracy and shows the viability of such
methods for quasar continuum prediction.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 17:53:27 GMT""}]","2021-02-03"
"2006.04815","Myriam Prasow-\'Emond","M. Prasow-\'Emond, J. Hlavacek-Larrondo, C. L. Rhea, M. Latulippe,
  M.-L. Gendron-Marsolais, A. Richard-Laferri\`ere, J. S. Sanders, A. C. Edge,
  S. W. Allen, A. Mantz and A. von der Linden","A Multiwavelength Study of the Massive Cool Core Cluster MACS
  J1447.4+0827","19 pages, 15 figures, 5 tables, resubmitted to ApJ (minor
  corrections)",,"10.3847/1538-3881/ab9ff3",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Clusters of galaxies are outstanding laboratories for understanding the
physics of supermassive black hole feedback. Here, we present the first
\textit{Chandra}, Karl G. Janksy Very Large Array and \textit{Hubble Space
Telescope} analysis of MACS J1447.4+0827 ($z = 0.3755$), one of the strongest
cool core clusters known, in which extreme feedback from its central
supermassive black hole is needed to prevent the hot intracluster gas from
cooling. Using this multiwavelength approach, including 70 ks of
\textit{Chandra} X-ray observations, we detect the presence of collimated
jetted-outflows that coincides with a southern and a northern X-ray cavity. The
total mechanical power associated with these outflows ($P_{\mathrm{cav}}
\approx 6 \times 10^{44}$ erg s$^{-1}$) is roughly consistent with the energy
required to prevent catastrophic cooling of the hot intracluster gas
($L_{\mathrm{cool}} = 1.71 \pm 0.01 \times 10^{45}$ erg s$^{-1}$ for
t$_\mathrm{cool}$ = 7.7 Gyrs); implying that powerful supermassive black hole
feedback has been in place several Giga-years ago in MACS J1447.7+0827. In
addition, we detect the presence of a radio mini-halo that extends over 300 kpc
in diameter ($P_{1.4 \mathrm{GHz}} = 3.0 \pm 0.3 \times 10^{24}$ W Hz$^{-1}$).
The X-ray observations also reveal a $\sim20$ kpc plume-like structure that
coincides with optical dusty filaments that surround the central galaxy.
Overall, this study demonstrates that the various physical phenomena occurring
in the most nearby clusters of galaxies are also occurring in their more
distant analogues.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:02 GMT""}]","2020-08-19"
"2006.04816","Shuo Zhang","Jason Shuo Zhang, Brian C. Keegan, Qin Lv, Chenhao Tan","Understanding the Diverging User Trajectories in Highly-related Online
  Communities during the COVID-19 Pandemic","12 pages, 10 figures, accepted to ICWSM 2021",,,,"cs.SI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the COVID-19 pandemic is disrupting life worldwide, related online
communities are popping up. In particular, two ""new"" communities, /r/China flu
and /r/Coronavirus, emerged on Reddit and have been dedicated to COVID- related
discussions from the very beginning of this pandemic. With /r/Coronavirus
promoted as the official community on Reddit, it remains an open question how
users choose between these two highly-related communities.
  In this paper, we characterize user trajectories in these two communities
from the beginning of COVID-19 to the end of September 2020. We show that new
users of /r/China flu and /r/Coronavirus were similar from January to March.
After that, their differences steadily increase, evidenced by both language
distance and membership prediction, as the pandemic continues to unfold.
Furthermore, users who started at /r/China flu from January to March were more
likely to leave, while those who started in later months tend to remain highly
""loyal"". To understand this difference, we develop a movement analysis
framework to understand membership changes in these two communities and
identify a significant proportion of /r/China flu members (around 50%) that
moved to /r/Coronavirus in February. This movement turns out to be highly
predictable based on other subreddits that users were previously active in. Our
work demonstrates how two highly-related communities emerge and develop their
own identity in a crisis, and highlights the important role of existing
communities in understanding such an emergence.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Sun, 4 Apr 2021 22:08:31 GMT""}]","2021-04-06"
"2006.04817","Bitan Roy","Bitan Roy, Vladimir Juricic","Dislocation as a bulk probe of higher-order topological insulators","Published version: 17 Pages, 6 Figures & 3 Tables","Phys. Rev. Research 3, 033107 (2021)","10.1103/PhysRevResearch.3.033107",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Topological materials occupy the central stage in the modern condensed matter
physics because of their robust metallic edge or surface states protected by
the topological invariant, characterizing the electronic band structure in the
bulk. Higher-order topological (HOT) states extend this usual bulk-boundary
correspondence, so they host the modes localized at lower-dimensional
boundaries, such as corners and hinges. Here we theoretically demonstrate that
dislocations, ubiquitous defects in crystalline materials, can probe
higher-order topology, recently realized in various platforms. We uncover that
HOT insulators respond to dislocations through symmetry protected finite-energy
in-gap electronic modes, localized at the defect core, which originate from an
interplay between the orientation of the HOT mass domain wall and the Burgers
vector of the dislocation. As such, these modes become gapless only when the
Burgers vector points toward lower-dimensional gapless boundaries. Our findings
are consequential for the systematic probing of the extended bulk-boundary
correspondence in a broad range of HOT crystals, and photonic and phononic or
mechanical metamaterials through the bulk topological lattice defects.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 17:30:47 GMT""},{""version"":""v3"",""created"":""Wed, 4 Aug 2021 16:13:01 GMT""}]","2021-08-05"
"2006.04818","Carlos O. Lousto","Carlos O. Lousto and James Healy","Exploring the small mass ratio binary black hole merger via Zeno's
  dichotomy approach","6 pages, 4 figures","Phys. Rev. Lett. 125, 191102 (2020)","10.1103/PhysRevLett.125.191102",,"gr-qc astro-ph.CO astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a sequence of binary black hole simulations with increasingly
small mass ratios, reaching to a 128:1 binary that displays 13 orbits before
merger. Based on a detailed convergence study of the $q=m_1/m_2=1/15$
nonspinning case, we apply additional mesh refinements levels around the
smaller hole horizon to reach successively the $q=1/32$, $q=1/64$, and
$q=1/128$ cases. Roughly a linear computational resources scaling with $1/q$ is
observed on 8-nodes simulations. We compute the remnant properties of the
merger: final mass, spin, and recoil velocity, finding precise consistency
between horizon and radiation measures. We also compute the gravitational
waveforms: its peak frequency, amplitude, and luminosity. We compare those
values with predictions of the corresponding phenomenological formulas,
reproducing the particle limit within 2%, and we then use the new results to
improve their fitting coefficients.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Wed, 16 Sep 2020 16:52:05 GMT""},{""version"":""v3"",""created"":""Wed, 7 Oct 2020 13:25:04 GMT""}]","2020-11-11"
"2006.04819","Andrew Winter","Andrew J. Winter, Megan Ansdell, Thomas J. Haworth, J. M. Diederik
  Kruijssen","Testing viscous disc theory using the balance between stellar accretion
  and external photoevaporation of protoplanetary discs","6 pages, 4 figures, accepted for publication by MNRAS Letters",,"10.1093/mnrasl/slaa110",,"astro-ph.EP astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nature and rate of (viscous) angular momentum transport in protoplanetary
discs (PPDs) has important consequences for the formation process of planetary
systems. While accretion rates onto the central star yield constraints on such
transport in the inner regions of a PPD, empirical constraints on viscous
spreading in the outer regions remain challenging to obtain. Here we
demonstrate a novel method to probe the angular momentum transport at the outer
edge of the disc. This method applies to PPDs that have lost a significant
fraction of their mass due to thermal winds driven by UV irradiation from a
neighbouring OB star. We demonstrate that this external photoevaporation can
explain the observed depletion of discs in the 3-5 Myr old $\sigma$ Orionis
region, and use our model to make predictions motivating future empirical
investigations of disc winds. For populations of intermediate-age PPDs, in
viscous models we show that the mass flux outwards due to angular momentum
redistribution is balanced by the mass-loss in the photoevaporative wind. A
comparison between wind mass-loss and stellar accretion rates therefore offers
an independent constraint on viscous models in the outer regions of PPDs.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:02 GMT""}]","2020-06-11"
"2006.04820","Philip S{\o}rensen","Sergey Sibiryakov, Philip S{\o}rensen, Tien-Tien Yu","BBN constraints on universally-coupled ultralight scalar dark matter","23 pages + appendices and bibliography, 6 figures, v2: typos
  corrected, expanded discussion around eq. 4.5, published version","J. High Energ. Phys. 2020, 75 (2020)","10.1007/JHEP12(2020)075","DESY-19-234, CERN-TH-2020-091, INR-TH-2020-001","hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Ultralight scalar dark matter can interact with all massive Standard Model
particles through a universal coupling. Such a coupling modifies the Standard
Model particle masses and affects the dynamics of Big Bang Nucleosynthesis. We
model the cosmological evolution of the dark matter, taking into account the
modifications of the scalar mass by the environment as well as the full
dynamics of Big Bang Nucleosynthesis. We find that precision measurements of
the helium-4 abundance set stringent constraints on the available parameter
space, and that these constraints are strongly affected by both the dark matter
environmental mass and the dynamics of the neutron freeze-out. Furthermore, we
perform the analysis in both the Einstein and Jordan frames, the latter of
which allows us to implement the model into numerical Big Bang Nucleosynthesis
codes and analyze additional light elements. The numerical analysis shows that
the constraint from helium-4 dominates over deuterium, and that the effect on
lithium is insufficient to solve the lithium problem. Comparing to several
other probes, we find that Big Bang Nucleosynthesis sets the strongest
constraints for the majority of the parameter space.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:02 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 19:55:53 GMT""}]","2020-12-16"
"2006.04821","Gian Luca Giorgi","Johannes Nokkala, Rodrigo Mart\'inez-Pe\~na, Gian Luca Giorgi,
  Valentina Parigi, Miguel C. Soriano and Roberta Zambrini","Gaussian states of continuous-variable quantum systems provide universal
  and versatile reservoir computing","14 pages, 4 figures. Supplementary material is 10 pages. This is a
  preprint of an article published in Communications Physics. The final
  authenticated version is available online at:
  https://doi.org/10.1038/s42005-021-00556-w","Communications Physics 4, 53 (2021)","10.1038/s42005-021-00556-w",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish the potential of continuous-variable Gaussian states of linear
dynamical systems for machine learning tasks. Specifically, we consider
reservoir computing, an efficient framework for online time series processing.
As a reservoir we consider a quantum harmonic network modeling e.g. linear
quantum optical systems. We prove that unlike universal quantum computing,
universal reservoir computing can be achieved without non-Gaussian resources.
We find that encoding the input time series into Gaussian states is both a
source and a means to tune the nonlinearity of the overall input-output map. We
further show that the full potential of the proposed model can be reached by
encoding to quantum fluctuations, such as squeezed vacuum, instead of classical
intense fields or thermal fluctuations. Our results introduce a new research
paradigm for reservoir computing harnessing the dynamics of a quantum system
and the engineering of Gaussian quantum states, pushing both fields into a new
direction.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 05:21:18 GMT""},{""version"":""v3"",""created"":""Wed, 31 Mar 2021 17:37:16 GMT""}]","2021-04-01"
"2006.04822","Martin Hoferichter","T. Aoyama, N. Asmussen, M. Benayoun, J. Bijnens, T. Blum, M. Bruno, I.
  Caprini, C. M. Carloni Calame, M. C\`e, G. Colangelo, F. Curciarello, H.
  Czy\.z, I. Danilkin, M. Davier, C. T. H. Davies, M. Della Morte, S. I.
  Eidelman, A. X. El-Khadra, A. G\'erardin, D. Giusti, M. Golterman, Steven
  Gottlieb, V. G\""ulpers, F. Hagelstein, M. Hayakawa, G. Herdo\'iza, D. W.
  Hertzog, A. Hoecker, M. Hoferichter, B.-L. Hoid, R. J. Hudspith, F. Ignatov,
  T. Izubuchi, F. Jegerlehner, L. Jin, A. Keshavarzi, T. Kinoshita, B. Kubis,
  A. Kupich, A. Kup\'s\'c, L. Laub, C. Lehner, L. Lellouch, I. Logashenko, B.
  Malaescu, K. Maltman, M. K. Marinkovi\'c, P. Masjuan, A. S. Meyer, H. B.
  Meyer, T. Mibe, K. Miura, S. E. M\""uller, M. Nio, D. Nomura, A. Nyffeler, V.
  Pascalutsa, M. Passera, E. Perez del Rio, S. Peris, A. Portelli, M. Procura,
  C. F. Redmer, B. L. Roberts, P. S\'anchez-Puertas, S. Serednyakov, B.
  Shwartz, S. Simula, D. St\""ockinger, H. St\""ockinger-Kim, P. Stoffer, T.
  Teubner, R. Van de Water, M. Vanderhaeghen, G. Venanzoni, G. von Hippel, H.
  Wittig, Z. Zhang, M. N. Achasov, A. Bashir, N. Cardoso, B. Chakraborty, E.-H.
  Chao, J. Charles, A. Crivellin, O. Deineka, A. Denig, C. DeTar, C. A.
  Dominguez, A. E. Dorokhov, V. P. Druzhinin, G. Eichmann, M. Fael, C. S.
  Fischer, E. G\'amiz, Z. Gelzer, J. R. Green, S. Guellati-Khelifa, D. Hatton,
  N. Hermansson-Truedsson, S. Holz, B. H\""orz, M. Knecht, J. Koponen, A. S.
  Kronfeld, J. Laiho, S. Leupold, P. B. Mackenzie, W. J. Marciano, C. McNeile,
  D. Mohler, J. Monnard, E. T. Neil, A. V. Nesterenko, K. Ottnad, V. Pauk, A.
  E. Radzhabov, E. de Rafael, K. Raya, A. Risch, A. Rodr\'iguez-S\'anchez, P.
  Roig, T. San Jos\'e, E. P. Solodov, R. Sugar, K. Yu. Todyshev, A. Vainshtein,
  A. Vaquero Avil\'es-Casco, E. Weil, J. Wilhelm, R. Williams, A. S. Zhevlakov","The anomalous magnetic moment of the muon in the Standard Model","196 pages, 103 figures, version published in Phys. Rept., bib files
  for the citation references are available from:
  https://muon-gm2-theory.illinois.edu","Phys. Rept. 887 (2020) 1-166","10.1016/j.physrep.2020.07.006","FERMILAB-PUB-20-207-T, INT-PUB-20-021, KEK Preprint 2020-5,
  MITP/20-028, CERN-TH-2020-075, IFT-UAM/CSIC-20-74, LMU-ASC 18/20, LTH 1234,
  LU TP 20-20, MAN/HEP/2020/003, PSI-PR-20-06, UWThPh 2020-14, ZU-TH 18/20","hep-ph hep-ex hep-lat nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review the present status of the Standard Model calculation of the
anomalous magnetic moment of the muon. This is performed in a perturbative
expansion in the fine-structure constant $\alpha$ and is broken down into pure
QED, electroweak, and hadronic contributions. The pure QED contribution is by
far the largest and has been evaluated up to and including
$\mathcal{O}(\alpha^5)$ with negligible numerical uncertainty. The electroweak
contribution is suppressed by $(m_\mu/M_W)^2$ and only shows up at the level of
the seventh significant digit. It has been evaluated up to two loops and is
known to better than one percent. Hadronic contributions are the most difficult
to calculate and are responsible for almost all of the theoretical uncertainty.
The leading hadronic contribution appears at $\mathcal{O}(\alpha^2)$ and is due
to hadronic vacuum polarization, whereas at $\mathcal{O}(\alpha^3)$ the
hadronic light-by-light scattering contribution appears. Given the low
characteristic scale of this observable, these contributions have to be
calculated with nonperturbative methods, in particular, dispersion relations
and the lattice approach to QCD. The largest part of this review is dedicated
to a detailed account of recent efforts to improve the calculation of these two
contributions with either a data-driven, dispersive approach, or a
first-principle, lattice-QCD approach. The final result reads
$a_\mu^\text{SM}=116\,591\,810(43)\times 10^{-11}$ and is smaller than the
Brookhaven measurement by 3.7$\sigma$. The experimental uncertainty will soon
be reduced by up to a factor four by the new experiment currently running at
Fermilab, and also by the future J-PARC experiment. This and the prospects to
further reduce the theoretical uncertainty in the near future-which are also
discussed here-make this quantity one of the most promising places to look for
evidence of new physics.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:04 GMT""},{""version"":""v2"",""created"":""Fri, 13 Nov 2020 12:36:28 GMT""}]","2020-11-16"
"2006.04823","David Sutter","David Sutter, Giacomo Nannicini, Tobias Sutter, Stefan Woerner","Quantum Legendre-Fenchel Transform","28 pages; v3: error in correctness proof of Algorithm 5",,,,"quant-ph cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a quantum algorithm to compute the discrete Legendre-Fenchel
transform. Given access to a convex function evaluated at $N$ points, the
algorithm outputs a quantum-mechanical representation of its corresponding
discrete Legendre-Fenchel transform evaluated at $K$ points in the transformed
space. For a fixed regular discretization of the dual space the expected
running time scales as $O(\sqrt{\kappa}\,\mathrm{polylog}(N,K))$, where
$\kappa$ is the condition number of the function. If the discretization of the
dual space is chosen adaptively with $K$ equal to $N$, the running time reduces
to $O(\mathrm{polylog}(N))$. We explain how to extend the presented algorithm
to the multivariate setting and prove lower bounds for the query complexity,
showing that our quantum algorithm is optimal up to polylogarithmic factors.
For multivariate functions with $\kappa=1$, the quantum algorithm computes a
quantum-mechanical representation of the Legendre-Fenchel transform at $K$
points exponentially faster than any classical algorithm can compute it at a
single point.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:05 GMT""},{""version"":""v2"",""created"":""Sat, 5 Dec 2020 07:47:03 GMT""},{""version"":""v3"",""created"":""Wed, 17 Mar 2021 07:07:52 GMT""}]","2021-03-18"
"2006.04824","Luiz Vale Silva","J. Charles, S. Descotes-Genon, Z. Ligeti, S. Monteil, M. Papucci, K.
  Trabelsi, L. Vale Silva","New physics in $B$ meson mixing: future sensitivity and limitations",,"Phys. Rev. D 102, 056023 (2020)","10.1103/PhysRevD.102.056023",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mixing of neutral mesons is sensitive to some of the highest scales
probed in laboratory experiments. In light of the planned LHCb Upgrade II, a
possible upgrade of Belle II, and the broad interest in flavor physics in the
tera-$Z$ phase of the proposed FCC-ee program, we study constraints on new
physics contributions to $B_d$ and $B_s$ mixings which can be obtained in these
benchmark scenarios. We explore the limitations of this program, and identify
the measurement of $|V_{cb}|$ as one of the key ingredients in which progress
beyond current expectations is necessary to maximize future sensitivity. We
speculate on possible solutions to this bottleneck. Given the current tension
with the standard model (SM) in semileptonic $B$ decays, we explore how its
resolution may impact the search for new physics in mixing. Even if new physics
has the same CKM and loop suppressions of flavor changing processes as the SM,
the sensitivity will reach 2 TeV, and it can be much higher if any SM
suppressions are lifted. We illustrate the discovery potential of this program.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:05 GMT""}]","2020-10-07"
"2006.04825","Alan Morningstar","Alan Morningstar, David A. Huse, and John Z. Imbrie","Many-body localization near the critical point","11 pages, 1 figure; published in Physical Review B","Phys. Rev. B 102, 125134 (2020)","10.1103/PhysRevB.102.125134",,"cond-mat.stat-mech cond-mat.dis-nn cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the many-body localization (MBL) phase transition in
one-dimensional quantum systems with quenched randomness and short-range
interactions. Following recent works, we use a strong-randomness
renormalization group (RG) approach where the phase transition is due to the
so-called avalanche instability of the MBL phase. We show that the critical
behavior can be determined analytically within this RG. On a rough
$\textit{qualitative}$ level the RG flow near the critical fixed point is
similar to the Kosterlitz-Thouless (KT) flow as previously shown, but there are
important differences in the critical behavior. Thus we show that this MBL
transition is in a new universality class that is different from KT. The
divergence of the correlation length corresponds to critical exponent $\nu
\rightarrow \infty$, but the divergence is weaker than for the KT transition.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:06 GMT""},{""version"":""v2"",""created"":""Mon, 21 Sep 2020 15:02:54 GMT""}]","2020-09-22"
"2006.04826","Luke Hart Mr.","Luke Hart, Aditya Rotti, Jens Chluba","Sensitivity forecasts for the cosmological recombination radiation in
  the presence of foregrounds","14 pages, 7 figures, 7 tables, submitted to MNRAS",,"10.1093/mnras/staa2255",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cosmological recombination radiation (CRR) is one of the inevitable
$\Lambda$CDM spectral distortions of the cosmic microwave background (CMB).
While it shows a rich spectral structure across dm-mm wavelengths, it is also
one of the smallest signals to target. Here we carry out a detailed forecast
for the expected sensitivity levels required to not only detect but also
extract cosmological information from the CRR in the presence of foregrounds.
We use ${\tt CosmoSpec}$ to compute the CRR including all important radiative
transfer effects and modifications to the recombination dynamics. We confirm
that detections of the overall CRR signal are possible with spectrometer
concepts like ${\it SuperPIXIE}$. However, for real exploitation of the
cosmological information, a $\simeq 50$ times more sensitive spectrometer is
required. While extremely futuristic, this could provide independent
constraints on the primordial helium abundance, $Y_p$, and probe the presence
of extra relativistic degrees of freedom during BBN and recombination.
Significantly improving the constraints on other cosmological parameters
requires even higher sensitivity (another factor of $\simeq 5$) when
considering a combination of a CMB spectrometer with existing CMB data. To a
large part this is due to astrophysical foregrounds which interestingly do not
degrade the constraints on $Y_p$ and $N_{\rm eff}$ as much. A future CMB
spectrometer could thus open a novel way of probing non-standard BBN scenarios,
dark radiation and sterile neutrinos. In addition, inflation physics could be
indirectly probed using the CRR in combination with existing and forthcoming
CMB anisotropy data.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:06 GMT""}]","2020-08-12"
"2006.04827","Ivan Khaymovich","I. M. Khaymovich, V. E. Kravtsov, B. L. Altshuler, L. B. Ioffe","Fragile ergodic phases in logarithmically-normal Rosenzweig-Porter model","12 pages, 7 figures, 1 table, 76 references + 7 pages, 7 figures, 1
  table in Appendices. Added the justification of fractal structure of
  minibands (Sec. IX, Fig. 7)","Phys. Rev. Research 2, 043346 (2020)","10.1103/PhysRevResearch.2.043346",,"cond-mat.dis-nn cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we suggest an extension of the Rosenzweig-Porter (RP) model,
the LN-RP model, in which the off-diagonal matrix elements have a wide,
log-normal distribution. We argue that this model is more suitable to describe
a generic many body localization problem. In contrast to RP model, in LN-RP
model a fragile weakly ergodic phase appears that is characterized by broken
basis-rotation symmetry which the fully-ergodic phase, also present in this
model, strictly respects in the thermodynamic limit. Therefore, in addition to
the localization and ergodic transitions in LN-RP model there exists also the
transition between the two ergodic phases (FWE transition). We suggest new
criteria of stability of the non-ergodic phases which give the points of
localization and ergodic transitions and prove that the Anderson localization
transition in LN-RP model involves a jump in the fractal dimension of the
eigenfunction support set. We also formulate the criterion of FWE transition
and obtain the full phase diagram of the model. We show that truncation of the
log-normal tail shrinks the region of weakly-ergodic phase and restores the
multifractal and the fully-ergodic phases.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:06 GMT""},{""version"":""v2"",""created"":""Sat, 18 Jul 2020 12:04:16 GMT""},{""version"":""v3"",""created"":""Tue, 17 Nov 2020 08:30:01 GMT""}]","2020-12-14"
"2006.04828","Gabriel Araneda","Gabriel Araneda, Giovanni Cerchiari, Daniel B. Higginbottom, Philip C.
  Holz, Kirill Lakhmanskiy, Petr Ob\v{s}il, Yves Colombe, Rainer Blatt","The Panopticon device: an integrated Paul-trap-hemispherical mirror
  system for quantum optics","16 pages, 17 figures",,"10.1063/5.0020661",,"quant-ph physics.atom-ph physics.ins-det physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the design and construction of a new experimental apparatus for
the trapping of single Ba$^+$ ions in the center of curvature of an
optical-quality hemispherical mirror. We describe the layout, fabrication and
integration of the full setup, consisting of a high-optical access monolithic
`3D-printed' Paul trap, the hemispherical mirror, a diffraction-limited
in-vacuum lens (NA = 0.7) for collection of atomic fluorescence and a
state-of-the art ultra-high vacuum vessel. This new apparatus enables the study
of quantum electrodynamics effects such as strong inhibition and enhancement of
spontaneous emission, and achieves a collection efficiency of the emitted light
in a single optical mode of 31%.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:07 GMT""},{""version"":""v2"",""created"":""Fri, 26 Jun 2020 00:00:40 GMT""},{""version"":""v3"",""created"":""Sat, 17 Oct 2020 09:44:00 GMT""}]","2020-12-02"
"2006.04829","Anna Rosen","Anna L. Rosen and Mark R. Krumholz","The Role of Outflows, Radiation Pressure, and Magnetic Fields in Massive
  Star Formation","21 pages, 16 figures, accepted by ApJ",,"10.3847/1538-3881/ab9abf",,"astro-ph.SR astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Stellar feedback in the form of radiation pressure and magnetically-driven
collimated outflows may limit the maximum mass that a star can achieve and
affect the star-formation efficiency of massive pre-stellar cores. Here we
present a series of 3D adaptive mesh refinement radiation-magnetohydrodynamic
simulations of the collapse of initially turbulent, massive pre-stellar cores.
Our simulations include radiative feedback from both the direct stellar and
dust-reprocessed radiation fields, and collimated outflow feedback from the
accreting stars. We find that protostellar outflows punches holes in the dusty
circumstellar gas along the star's polar directions, thereby increasing the
size of optically thin regions through which radiation can escape. Precession
of the outflows as the star's spin axis changes due to the turbulent accretion
flow further broadens the outflow, and causes more material to be entrained.
Additionally, the presence of magnetic fields in the entrained material leads
to broader entrained outflows that escape the core. We compare the injected and
entrained outflow properties and find that the entrained outflow mass is a
factor of $\sim$3 larger than the injected mass and the momentum and energy
contained in the entrained material are $\sim$25% and $\sim$5% of the injected
momentum and energy, respectively. As a result, we find that, when one includes
both outflows and radiation pressure, the former are a much more effective and
important feedback mechanism, even for massive stars with significant radiative
outputs.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:08 GMT""}]","2020-07-29"
"2006.04830","Steve Campbell","Ricardo Puebla, Sebastian Deffner, Steve Campbell","Kibble-Zurek scaling in quantum speed limits for shortcuts to
  adiabaticity","6+5 pages, v2 close to published version","Phys. Rev. Research 2, 032020 (2020)","10.1103/PhysRevResearch.2.032020",,"quant-ph cond-mat.quant-gas cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Geometric quantum speed limits quantify the trade-off between the rate with
which quantum states can change and the resources that are expended during the
evolution. Counterdiabatic driving is a unique tool from shortcuts to
adiabaticity to speed up quantum dynamics while completely suppressing
nonequilibrium excitations. We show that the quantum speed limit for
counterdiabatically driven systems undergoing quantum phase transitions fully
encodes the Kibble-Zurek mechanism by correctly predicting the transition from
adiabatic to impulse regimes. Our findings are demonstrated for three
scenarios, namely the transverse field Ising, the Landau-Zener, and the
Lipkin-Meshkov-Glick models.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:17 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jul 2020 17:19:36 GMT""}]","2020-07-29"
"2006.04831","Jason Larkin","Jason Larkin, Mat\'ias Jonsson, Daniel Justice, and Gian Giacomo
  Guerreschi","Evaluation of QAOA based on the approximation ratio of individual
  samples",,"Quantum Sci. Technol. 7, 045014 (2022)","10.1088/2058-9565/ac6973",,"quant-ph cs.CC cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Quantum Approximate Optimization Algorithm (QAOA) is a hybrid
quantum-classical algorithm to solve binary-variable optimization problems. Due
to the short circuit depth and its expected robustness to systematic errors, it
is one of the promising candidates likely to run on near-term quantum devices.
We simulate the performance of QAOA applied to the Max-Cut problem and compare
it with some of the best classical alternatives, for exact, approximate and
heuristic solution. When comparing solvers, their performance is characterized
by the computational time taken to achieve a given quality of solution. Since
QAOA is based on sampling, we utilize performance metrics based on the
probability of observing a sample above a certain quality. In addition, we show
that the QAOA performance varies significantly with the graph type. By
selecting a suitable optimizer for the variational parameters and reducing the
number of function evaluations, QAOA performance improves by up to 2 orders of
magnitude compared to previous estimates. Especially for 3-regular random
graphs, this setting decreases the performance gap with classical alternatives.
Because of the evolving QAOA computational complexity-theoretic guidance, we
utilize a framework for the search for quantum advantage which incorporates a
large number of problem instances and all three classical solver modalities:
exact, approximate, and heuristic.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:18 GMT""},{""version"":""v2"",""created"":""Mon, 7 Dec 2020 20:03:38 GMT""}]","2022-08-23"
"2006.04832","Alina Wilhelm","A. Wilhelm, I. Telezhinsky, V.V. Dwarkadas, M. Pohl","Stochastic re-acceleration and magnetic-field damping in Tycho's
  supernova remnant","14 pages, 10 figures, accepted for publication in Astronomy and
  Astrophysics","A&A 639, A124 (2020)","10.1051/0004-6361/201936079",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  A number of studies suggest that shock acceleration with particle feedback
and very efficient magnetic-field amplification combined with Alfv\'{e}nic
drift are needed to explain the rather soft radio spectrum and the narrow rims
observed for Tycho's SNR. We show that the broadband spectrum of Tycho's SNR
can alternatively be well explained when accounting for stochastic acceleration
as a secondary process. The re-acceleration of particles in the turbulent
region immediately downstream of the shock should be efficient enough to impact
particle spectra over several decades in energy. The so-called Alfv\'{e}nic
drift and particle feedback on the shock structure are not required in this
scenario. Additionally, we investigate whether synchrotron losses or
magnetic-field damping play a more profound role in the formation of the
non-thermal filaments. We solve the full particle transport equation in
test-particle mode using hydrodynamic simulations of the SNR plasma flow. The
background magnetic field is either computed from the induction equation or
follows analytic profiles, depending on the model considered. Fast-mode waves
in the downstream region provide the diffusion of particles in momentum space.
We show that the broadband spectrum of Tycho can be well explained if
magnetic-field damping and stochastic re-acceleration of particles are taken
into account. Although not as efficient as standard DSA, stochastic
acceleration leaves its imprint on the particle spectra, which is especially
notable in the emission at radio wavelengths. We find a lower limit for the
post-shock magnetic-field strength $\sim330\,\mathrm{\mu G}$, implying
efficient amplification even for the magnetic-field damping scenario. For the
formation of the filaments in the radio range magnetic-field damping is
necessary, while the X-ray filaments are shaped by both the synchrotron losses
and magnetic-field damping.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:19 GMT""}]","2020-07-22"
"2006.04833","Benoit Cote","Benoit C\^ot\'e, Marius Eichler, Andr\'es Yag\""ue, Nicole Vassh,
  Matthew R. Mumpower, Blanka Vil\'agos, Benj\'amin So\'os, Almudena Arcones,
  Trevor M. Sprouse, Rebecca Surman, Marco Pignatari, Maria K. Pet\H{o},
  Benjamin Wehmeyer, Thomas Rauscher, Maria Lugaro","129I and 247Cm in Meteorites Constrain the Last Astrophysical Source of
  Solar r-process Elements","36 pages, 7 figures, 7 tables","Science 26 Feb 2021: Vol. 371, Issue 6532, pp. 945-948","10.1126/science.aba1111",,"astro-ph.SR astro-ph.HE nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The composition of the early Solar System can be inferred from meteorites.
Many elements heavier than iron were formed by the rapid neutron-capture
process (r process), but the astrophysical sources where this occurred remain
poorly understood. We demonstrate that the near-identical half-lives ($\simeq$
15.6 Myr) of the radioactive r-process nuclei 129I and 247Cm preserve their
ratio, irrespective of the time between production and incorporation into the
Solar System. We constrain the last r-process source by comparing the measured
meteoritic 129I / 247Cm = 438 $\pm$ 184 to nucleosynthesis calculations based
on neutron star merger and magneto-rotational supernova simulations. Moderately
neutron-rich conditions, often found in merger disk ejecta simulations, are
most consistent with the meteoritic value. Uncertain nuclear physics data limit
our confidence in this conclusion.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:35 GMT""},{""version"":""v2"",""created"":""Tue, 2 Mar 2021 20:04:04 GMT""}]","2021-03-04"
"2006.04834","Trithep Devakul","Trithep Devakul, S. L. Sondhi, S. A. Kivelson, Erez Berg","Floating topological phases","15 pages","Phys. Rev. B 102, 125136 (2020)","10.1103/PhysRevB.102.125136",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While quasi-two-dimensional (layered) materials can be highly anisotropic,
their asymptotic long-distance behavior generally reflects the properties of a
fully three dimensional phase of matter. However, certain topologically ordered
quantum phases with an emergent 2+1 dimensional gauge symmetry can be
asymptotically impervious to interplane couplings. We discuss the stability of
such ""floating topological phases"", as well as their diagnosis by means of a
non-local order parameter. Such a phase can produce a divergent ratio
$\rho_{\perp}/\rho_{\parallel}$ of the inter-layer to intra-layer resistivity
as $T\to 0$, even in an insulator where both $\rho_{\perp}$ and
$\rho_\parallel$ individually diverge. Experimental observation of such a
divergence would constitute proof of the existence of a topological (e.g. spin
liquid) phase.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:36 GMT""}]","2020-09-30"
"2006.04835","Lin Yan","Lin Yan (Caltech), A. Sajina (Tufts University), F. Loiacono, G.
  Lagache, M. B\`ethermin, A. Faisst, M. Ginolfi, O. Le F\`evre, C. Gruppioni,
  P.L. Capak, P. Cassata, D. Schaerer, J.D. Silverman, S. Bardelli, M.
  Dessauges-Zavadsky, A. Cimatti, N.P. Hathi, B.C. Lemaux, E. Ibar, G.C. Jones,
  A.M. Koekemoer, P.A. Oesch, M. Talia, F. Pozzi, D.A. Riechers, L.A. Tasca, S.
  Toft, L. Vallini, D. Vergani, G. Zamorani, E. Zucca","The ALPINE-ALMA [C II] Survey: [C II]158micron Emission Line Luminosity
  Functions at $z \sim 4-6$","17 pages, 9 Figures, Update to match with the published version.
  Accepted for the publication in ApJ",,"10.3847/1538-4357/abc41c",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the [CII]158$\mu$m line luminosity functions (LFs) at $z\sim4-6$
using the ALMA observations of 118 sources, which are selected to have UV
luminosity $M_{1500A}<-20.2$ and optical spectroscopic redshifts in COSMOS and
ECDF-S. Of the 118 targets, 75 have significant [CII] detections and 43 are
upper limits. This is by far the largest sample of [CII] detections which
allows us to set constraints to the volume density of [CII] emitters at
$z\sim4-6$. But because this is a UV-selected sample, we are missing
[CII]-bright but UV-faint sources making our constraints strict lower limits.
Our derived LFs are statistically consistent with the $z\sim0$ [CII] LF at
$10^{8.25} - 10^{9.75}L_\odot$. We compare our results with the upper limits of
the [CII] LF derived from serendipitous sources in the ALPINE maps (Loiacono et
al. 2020). We also infer the [CII] LFs based on published far-IR and CO LFs at
$z\sim4-6$. Combining our robust lower limits with these additional estimates,
we set further constraints to the true number density of [CII] emitters at
$z\sim 4 - 6$. These additional LF estimates are largely above our LF at
$L_{[CII]}>10^9L_{\odot}$, suggesting that UV-faint but [CII]-bright sources
likely make a significant contributions to the [CII] emitter volume density.
When we include all the LF estimates, we find that available model predictions
underestimate the number densities of [CII] emitters at $z\sim4-6$. Finally, we
set a constraint on the molecular gas mass density at $z\sim4-6$, with
$\rho_{mol} \sim (2-7)\times10^7M_\odot$\,Mpc$^{-3}$. This is broadly
consistent with previous studies.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:01:12 GMT""},{""version"":""v2"",""created"":""Thu, 29 Oct 2020 19:36:27 GMT""}]","2021-01-06"
"2006.04836","Khashayar Namdar","Khashayar Namdar, Masoom A. Haider, Farzad Khalvati","A Modified AUC for Training Convolutional Neural Networks: Taking
  Confidence into Account",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Receiver operating characteristic (ROC) curve is an informative tool in
binary classification and Area Under ROC Curve (AUC) is a popular metric for
reporting performance of binary classifiers. In this paper, first we present a
comprehensive review of ROC curve and AUC metric. Next, we propose a modified
version of AUC that takes confidence of the model into account and at the same
time, incorporates AUC into Binary Cross Entropy (BCE) loss used for training a
Convolutional neural Network for classification tasks. We demonstrate this on
three datasets: MNIST, prostate MRI, and brain MRI. Furthermore, we have
published GenuineAI, a new python library, which provides the functions for
conventional AUC and the proposed modified AUC along with metrics including
sensitivity, specificity, recall, precision, and F1 for each point of the ROC
curve.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:01:34 GMT""},{""version"":""v2"",""created"":""Sun, 12 Sep 2021 20:05:30 GMT""}]","2021-09-14"
"2006.04837","Federica Loiacono","Federica Loiacono, Roberto Decarli, Carlotta Gruppioni, Margherita
  Talia, Andrea Cimatti, Gianni Zamorani, Francesca Pozzi, Lin Yan, Brian C.
  Lemaux, Dominik A. Riechers, Olivier Le F\`evre, Matthieu B\'ethermin, Peter
  Capak, Paolo Cassata, Andreas Faisst, Daniel Schaerer, John D. Silverman,
  Sandro Bardelli, M\'ed\'eric Boquien, Sandra Burkutean, Miroslava
  Dessauges-Zavadsky, Yoshinobu Fudamoto, Seiji Fujimoto, Michele Ginolfi,
  Nimish P. Hathi, Gareth C. Jones, Yana Khusanova, Anton M. Koekemoer,
  Guilaine Lagache, Marcella Massardi, Pascal Oesch, Michael Romano, Livia
  Vallini, Daniela Vergani and Elena Zucca","The ALPINE-ALMA [C II] survey: the luminosity function of serendipitous
  [C II] line emitters at $z\sim 5$","19 pages, 12 figures; submitted to Astronomy & Astrophysics","A&A 646, A76 (2021)","10.1051/0004-6361/202038607",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first [CII] 158 $\mu$m luminosity function (LF) at $z\sim 5$
from a sample of serendipitous lines detected in the ALMA Large Program to
INvestigate [CII] at Early times (ALPINE). A search performed over the 118
ALPINE pointings revealed several serendipitous lines. Based on their fidelity,
we selected 14 lines for the final catalog. According to the redshift of their
counterparts, we identified 8 out of 14 detections as [CII] lines at $z\sim 5$,
and two as CO transitions at lower redshifts. The remaining 4 lines have an
elusive identification in the available catalogs and we considered them as
[CII] candidates. We used the 8 confirmed [CII] and the 4 [CII] candidates to
build one of the first [CII] LFs at $z\sim 5$. We found that 11 out of these 12
sources have a redshift very similar to that of the ALPINE target in the same
pointing, suggesting the presence of overdensities around the targets.
Therefore, we split the sample in two (a ""clustered"" and ""field"" sub-sample)
according to their redshift separation and built two separate LFs. Our
estimates suggest that there could be an evolution of the [CII] LF between $z
\sim 5$ and $z \sim 0$. By converting the [CII] luminosity to star formation
rate we evaluated the cosmic star formation rate density (SFRD) at $z\sim 5$.
The clustered sample results in a SFRD $\sim 10$ times higher than previous
measurements from UV-selected galaxies. On the other hand, from the field
sample (likely representing the average galaxy population) we derived a SFRD
$\sim 1.6$ higher compared to current estimates from UV surveys but compatible
within the errors. Because of the large uncertainties, observations of larger
samples are necessary to better constrain the SFRD at $z\sim 5$. This study
represents one of the first efforts aimed at characterizing the demography of
[CII] emitters at $z\sim 5$ using a mm-selection of galaxies.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:01:46 GMT""}]","2021-02-10"
"2006.04838","Stela Seo","Stela H. Seo, James E. Young, Pourang Irani","How are your robot friends doing? A design exploration of graphical
  techniques supporting awareness of robot team members in teleoperation","submitted to International Journal of Social Robotics
  https://www.springer.com/journal/12369/",,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  While teleoperated robots continue to proliferate in domains including search
and rescue, field exploration, or the military, human error remains a primary
cause for accidents or mistakes. One challenge is that teleoperating a remote
robot is cognitively taxing as the operator needs to understand the robot's
state and monitor all its sensor data. In a multi-robot team, an operator needs
to additionally monitor other robots' progress, states, notifications, errors,
and so on to maintain team cohesion. One strategy for supporting the operator
to comprehend this information is to improve teleoperation interface designs to
carefully present data. We present a set of prototypes that simplify complex
team robot states and actions, with an aim to help the operator to understand
information from the robots easily and quickly. We conduct a series of pilot
studies to explore a range of design parameters used in our prototypes (text,
icon, facial expression, use of color, animation, and number of team robots),
and develop a set of guidelines for graphically representing team robot states
in the remote team teleoperation.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:02:28 GMT""}]","2020-06-11"
"2006.04839","Henry Cohn","Nima Afkhami-Jeddi, Henry Cohn, Thomas Hartman, and Amirhossein
  Tajdini","Free partition functions and an averaged holographic duality","47 pages, 7 figures","J. High Energ. Phys. 01 (2021) 130","10.1007/JHEP01(2021)130",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the torus partition functions of free bosonic CFTs in two
dimensions. Integrating over Narain moduli defines an ensemble-averaged free
CFT. We calculate the averaged partition function and show that it can be
reinterpreted as a sum over topologies in three dimensions. This result leads
us to conjecture that an averaged free CFT in two dimensions is holographically
dual to an exotic theory of three-dimensional gravity with $U(1)^c \times
U(1)^c$ symmetry and a composite boundary graviton. Additionally, for small
central charge $c$, we obtain general constraints on the spectral gap of free
CFTs using the spinning modular bootstrap, construct examples of Narain
compactifications with a large gap, and find an analytic bootstrap functional
corresponding to a single self-dual boson.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:03:49 GMT""},{""version"":""v2"",""created"":""Wed, 3 Feb 2021 05:38:37 GMT""}]","2021-02-04"
"2006.04840","Simon Tavar\'e","Poly H. da Silva, Arash Jamshidpey, Simon Tavar\'e","Random derangements and the Ewens Sampling Formula","16 pages, 9 tables",,,,"math.PR stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study derangements of $\{1,2,\ldots,n\}$ under the Ewens distribution with
parameter $\theta$. We give the moments and marginal distributions of the cycle
counts, the number of cycles, and asymptotic distributions for large $n$. We
develop a $\{0,1\}$-valued non-homogeneous Markov chain with the property that
the counts of lengths of spacings between the 1s have the derangement
distribution. This chain, an analog of the so-called Feller Coupling, provides
a simple way to simulate derangements in time independent of $\theta$ for a
given $n$ and linear in the size of the derangement.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:04:16 GMT""}]","2020-06-11"
"2006.04841","Bertrand Lacroix-A-Chez-Toine","Bertrand Lacroix-A-Chez-Toine and Asaf Miron","Extreme value statistics for branching run-and-tumble particles","14 pages, 6 figures",,,,"cond-mat.stat-mech math-ph math.MP physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The extreme value statistics of active matter offer significant insight into
their unique properties. A phase transition has recently been reported in a
model of branching run-and-tumble particles, describing the spatial spreading
of an evolving colony of active matter in one-dimension. In a ""persistent""
phase, the particles form macroscopic robust clusters that ballistically
propagate as a whole while in an ""intermittent"" phase, particles are isolated
instead. We focus our study on the fluctuations of the rightmost position
$x_{\max}(t)$ reached by time $t$ for this model. At long time, as the colony
progressively invades the unexplored region, the cumulative probability of
$x_{\max}(t)$ is described by a travelling front. The transition has a
remarkable impact on this front. In the intermittent phase it is qualitatively
similar to the front satisfying the Fisher-KPP equation, which famously
describes the extreme value statistics of the non-active branching Brownian
motion. A dramatically different behaviour appears in the persistent phase,
where activity imparts the front with unexpected and unusual features which we
compute exactly.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:04:21 GMT""}]","2020-06-11"
"2006.04842","Rahul Singh","Leonardo C. Mihalcea and Rahul Singh","Mather classes and conormal spaces of Schubert varieties in cominuscule
  spaces","39 pages, 9 Tables. Includes computation of Mather classes for
  Gr(4,8), LG(4,8) and most of the Cayley plane. Also includes computation of
  Euler obstructions in LG(4,8)",,,,"math.AG math.CO math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G/P$ be a complex cominuscule flag manifold. We prove a type independent
formula for the torus equivariant Mather class of a Schubert variety in $G/P$,
and for a Schubert variety pulled back via the natural projection $G/Q \to
G/P$. We apply this to find formulae for the local Euler obstructions of
Schubert varieties, and for the torus equivariant localizations of the conormal
spaces of these Schubert varieties. We conjecture positivity properties for the
local Euler obstructions and for the Schubert expansion of Mather classes. We
check the conjectures in many cases, by utilizing results of Boe and Fu about
the characteristic cycles of the intersection homology sheaves of Schubert
varieties. We also conjecture that certain `Mather polynomials' are unimodal in
general Lie type, and log concave in type A.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:06:57 GMT""}]","2020-06-11"
"2006.04843","Soren Pirk","S\""oren Pirk, Karol Hausman, Alexander Toshev, Mohi Khansari","Modeling Long-horizon Tasks as Sequential Interaction Landscapes","Published at 4th Conference on Robot Learning (CoRL 2020), Cambridge
  MA, USA More details available at: http://www.pirk.io",,,,"cs.RO cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Complex object manipulation tasks often span over long sequences of
operations. Task planning over long-time horizons is a challenging and open
problem in robotics, and its complexity grows exponentially with an increasing
number of subtasks. In this paper we present a deep learning network that
learns dependencies and transitions across subtasks solely from a set of
demonstration videos. We represent each subtask as an action symbol (e.g. move
cup), and show that these symbols can be learned and predicted directly from
image observations. Learning from demonstrations and visual observations are
two main pillars of our approach. The former makes the learning tractable as it
provides the network with information about the most frequent transitions and
relevant dependency between subtasks (instead of exploring all possible
combination), while the latter allows the network to continuously monitor the
task progress and thus to interactively adapt to changes in the environment. We
evaluate our framework on two long horizon tasks: (1) block stacking of puzzle
pieces being executed by humans, and (2) a robot manipulation task involving
pick and place of objects and sliding a cabinet door with a 7-DoF robot arm. We
show that complex plans can be carried out when executing the robotic task and
the robot can interactively adapt to changes in the environment and recover
from failure cases.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:07:18 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 20:34:50 GMT""}]","2020-10-27"
"2006.04844","Takuji Yamashita","Takuji Yamashita, Tohru Nagao, Hiroyuki Ikeda, Yoshiki Toba, Masaru
  Kajisawa, Yoshiaki Ono, Masayuki Tanaka, Masayuki Akiyama, Yuichi Harikane,
  Kohei Ichikawa, Toshihiro Kawaguchi, Taiki Kawamuro, Kotaro Kohno, Chien-Hsiu
  Lee, Kianhong Lee, Yoshiki Matsuoka, Mana Niida, Kazuyuki Ogura, Masafusa
  Onoue, Hisakazu Uchiyama","Wide and Deep Exploration of Radio Galaxies with Subaru HSC (WERGS).
  III. Discovery of a z = 4.72 Radio Galaxy with Lyman Break Technique","10 pages, 5 figures, accepted for publication in AJ",,"10.3847/1538-3881/ab98fe",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a discovery of $z = 4.72$ radio galaxy, HSC J083913.17+011308.1, by
using the Lyman break technique with the Hyper Suprime-Cam Subaru Strategic
Survey (HSC-SSP) catalog for VLA FIRST radio sources. The number of known
high-$z$ radio galaxies (HzRGs) at $z > 3$ is quite small to constrain the
evolution of HzRGs so far. The deep and wide-area optical survey by HSC-SSP
enables us to apply the Lyman break technique to a large search for HzRGs. For
an HzRG candidate among pre-selected $r$-band dropouts with a radio detection,
a follow-up optical spectroscopy with GMOS/Gemini has been performed. The
obtained spectrum presents a clear Ly$\alpha$ emission line redshifted to
$z=4.72$. The SED fitting analysis with the rest-frame UV and optical
photometries suggests the massive nature of this HzRG with $\log{M_*/M_{\odot}}
= 11.4$. The small equivalent width of Ly$\alpha$ and the moderately red UV
colors indicate its dusty host galaxy, implying a chemically evolved and dusty
system. The radio spectral index does not meet a criterion for an ultra-steep
spectrum: $\alpha^{325}_{1400}$ of $-1.1$ and $\alpha^{150}_{1400}$ of $-0.9$,
demonstrating that the HSC-SSP survey compensates for a sub-population of HzRGs
which are missed in surveys focusing on an ultra-steep spectral index.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:08:15 GMT""}]","2020-07-22"
"2006.04845","Hankun Cao","Hankun Cao, Qifa Yan, Xiaohu Tang, Guojun Han","Adaptive Gradient Coding",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on mitigating the impact of stragglers in distributed
learning system. Unlike the existing results designed for a fixed number of
stragglers, we developed a new scheme called Adaptive Gradient Coding(AGC) with
flexible tolerance of various number of stragglers. Our scheme gives an optimal
tradeoff between computation load, straggler tolerance and communication cost.
In particular, it allows to minimize the communication cost according to the
real-time number of stragglers in the practical environments. Implementations
on Amazon EC2 clusters using Python with mpi4py package verify the flexibility
in several situations.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:08:17 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 07:23:24 GMT""},{""version"":""v3"",""created"":""Tue, 19 Oct 2021 02:03:16 GMT""}]","2021-10-20"
"2006.04846","Jose Soares Andrade Jr.","H.J. Seybold, H.A. Carmona, F.A. Leandro Filho, A.D. Ara\'ujo, F.
  Nepomuceno Filho, J.S. Andrade Jr","Flow through three-dimensional self-affine fractures","10 pages, 8 figures","Phys. Rev. Fluids 5, 104101 (2020)","10.1103/PhysRevFluids.5.104101",,"physics.flu-dyn physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate through numerical simulations of the Navier-Stokes equations
the influence of the surface roughness on the fluid flow through fracture
joints. Using the Hurst exponent $H$ to characterize the roughness of the
self-affine surfaces that constitute the fracture, our analysis reveal the
important interplay between geometry and inertia on the flow. Precisely, for
low values of Reynolds numbers Re, we use Darcy's law to quantify the hydraulic
resistance $G$ of the fracture and show that its dependence on $H$ can be
explained in terms of a simple geometrical model for the tortuosity $\tau$ of
the channel. At sufficiently high values of Re, when inertial effects become
relevant, our results reveal that nonlinear corrections up to third-order to
Darcy's law are aproximately proportional to $H$. These results imply that the
resistance $G$ to the flow follows a universal behavior by simply rescaling it
in terms of the fracture resistivity and using an effective Reynolds number,
namely, Re/$H$. Our results also reveal the presence of quasi-one-dimensional
channeling, even considering the absence of shear displacement between upper
and lower surfaces of the self-affine fracture.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:08:19 GMT""}]","2020-10-14"
"2006.04847","Mariano Tepper","Mariano Tepper, Dipanjan Sengupta, Ted Willke","Procrustean Orthogonal Sparse Hashing",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hashing is one of the most popular methods for similarity search because of
its speed and efficiency. Dense binary hashing is prevalent in the literature.
Recently, insect olfaction was shown to be structurally and functionally
analogous to sparse hashing [6]. Here, we prove that this biological mechanism
is the solution to a well-posed optimization problem. Furthermore, we show that
orthogonality increases the accuracy of sparse hashing. Next, we present a
novel method, Procrustean Orthogonal Sparse Hashing (POSH), that unifies these
findings, learning an orthogonal transform from training data compatible with
the sparse hashing mechanism. We provide theoretical evidence of the
shortcomings of Optimal Sparse Lifting (OSL) [22] and BioHash [30], two related
olfaction-inspired methods, and propose two new methods, Binary OSL and
SphericalHash, to address these deficiencies. We compare POSH, Binary OSL, and
SphericalHash to several state-of-the-art hashing methods and provide empirical
results for the superiority of the proposed methods across a wide range of
standard benchmarks and parameter settings.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:09:33 GMT""}]","2020-06-11"
"2006.04848","Xizhi Liu","Xizhi Liu and Sayan Mukherjee","Stability theorems for some Kruskal-Katona type results","21 pages, major revision",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical Kruskal-Katona theorem gives a tight upper bound for the size
of an $r$-uniform hypergraph $\mathcal{H}$ as a function of the size of its
shadow. Its stability version was obtained by Keevash who proved that if the
size of $\mathcal{H}$ is close to the maximum, then $\mathcal{H}$ is
structurally close to a complete $r$-uniform hypergraph. We prove similar
stability results for two classes of hypergraphs whose extremal properties have
been investigated by many researchers: the cancellative hypergraphs and
hypergraphs without expansion of cliques.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:09:55 GMT""},{""version"":""v2"",""created"":""Sun, 4 Apr 2021 15:58:11 GMT""}]","2021-04-06"
"2006.04849","Franco Vargas Pallete","Ian Adelstein, Franco Vargas Pallete","The length of the shortest closed geodesic on positively curved
  2-spheres","12 pages, 1 figure. Main result updated, typos corrected. Comments
  are welcome!",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the shortest closed geodesic on a 2-sphere with non-negative
curvature has length bounded above by three times the diameter. We prove a new
isoperimetric inequality for 2-spheres with pinched curvature; this allows us
to improve our bound on the length of the shortest closed geodesic in the
pinched curvature setting.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:11:41 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 20:52:25 GMT""}]","2021-09-08"
"2006.04850","Matilde Mingozzi","M. Mingozzi, G. Cresci, G. Venturi, A. Marconi and F. Mannucci","Interstellar medium properties and feedback in local AGN with the MAGNUM
  survey","5 pages, 3 figures. To appear in Proceedings of IAU Symposium 359 (T.
  Storchi-Bergmann, R. Overzier, W. Forman & R. Riffel, eds.)",,"10.1017/S1743921320002422",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated the interstellar medium (ISM) properties in the central
regions of nearby Seyfert galaxies characterised by prominent conical or
bi-conical outflows belonging to the MAGNUM survey by exploiting the
unprecedented sensitivity, spatial and spectral coverage of the integral field
spectrograph MUSE at the Very Large Telescope. We developed a novel approach
based on the gas and stars kinematics to disentangle high-velocity gas in the
outflow from gas in the disc to spatially track the differences in their ISM
properties. This allowed us to reveal the presence of an ionisation structure
within the extended outflows that can be interpreted with different
photoionisation and shock conditions, and to trace tentative evidence of
outflow-induced star formation (''positive'' feedback) in a galaxy of the
sample, Centaurus A.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:15:20 GMT""}]","2021-04-07"
"2006.04851","Ignacio A. Reyes","Hong Zhe Chen, Robert C. Myers, Dominik Neuenfeld, Ignacio A. Reyes,
  Joshua Sandor","Quantum Extremal Islands Made Easy, Part I: Entanglement on the Brane","Updated discussion section",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent progress in our understanding of the black hole information paradox
has lead to a new prescription for calculating entanglement entropies, which
involves special subsystems in regions where gravity is dynamical, called
\textit{quantum extremal islands}. We present a simple holographic framework
where the emergence of quantum extremal islands can be understood in terms of
the standard Ryu-Takayanagi prescription, used for calculating entanglement
entropies in the boundary theory. Our setup describes a $d$-dimensional
boundary CFT coupled to a ($d$-1)-dimensional defect, which are dual to global
AdS${}_{d+1}$ containing a codimension-one brane. Through the Randall-Sundrum
mechanism, graviton modes become localized at the brane, and in a certain
parameter regime, an effective description of the brane is given by Einstein
gravity on an AdS${}_d$ background coupled to two copies of the boundary CFT.
Within this effective description, the standard RT formula implies the
existence of quantum extremal islands in the gravitating region, whenever the
RT surface crosses the brane. This indicates that islands are a universal
feature of effective theories of gravity and need not be tied to the presence
of black holes.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:16:33 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jul 2020 09:34:18 GMT""},{""version"":""v3"",""created"":""Wed, 26 Aug 2020 13:43:38 GMT""}]","2020-08-27"
"2006.04852","Robert Magnusson","Hafez Hemmati and Robert Magnusson","Applicability of the Rytov full effective-medium formalism to the
  physical description and design of resonant metasurfaces","14 pages, 7 figures",,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Periodic photonic lattices constitute a fundamental pillar of physics
supporting a plethora of scientific concepts and applications. The advent of
metamaterials and metastructures is grounded in deep understanding of their
properties. Based on the original 1956 formulation by Rytov, it is well known
that a photonic lattice with deep subwavelength periodicity can be approximated
with a homogeneous space having an effective refractive index. Whereas the
attendant effective-medium theory (EMT) commonly used in the literature is
based on the zeroth root, the closed-form transcendental equations possess an
infinite number of roots. Thus far, these higher-order solutions have been
totally ignored; even Rytov himself discarded them and proceeded to approximate
solutions for the deep-subwavelength regime. In spite of the fact that the
Rytov EMT models an infinite half-space lattice, it is highly relevant to
modeling practical thin-film periodic structures with finite thickness as we
show. Therefore, here, we establish a theoretical framework to systematically
describe subwavelength resonance behavior and to predict the optical response
of resonant photonic lattices using the full Rytov solutions. Expeditious
results are obtained with direct, new physical insights available for resonant
lattice properties. We show that the full Rytov formulation implicitly contains
refractive-index solutions pertaining directly to evanescent waves that drive
the laterally-propagating Bloch modes foundational to resonant lattice
properties. In fact, the resonant reradiated Bloch modes experience
wavelength-dependent refractive indices that are solutions of the Rytov
expressions. This insight is useful in modeling guided-mode resonant devices
including wideband reflectors, bandpass filters, and polarizers.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:16:45 GMT""}]","2020-06-11"
"2006.04853","Nicolas Dupuis","N. Dupuis, L. Canet, A. Eichhorn, W. Metzner, J. M. Pawlowski, M.
  Tissier, N. Wschebor","The nonperturbative functional renormalization group and its
  applications","v3) Review article, 93 pages + bibliography, 35 figures","Physics Reports 910, 1 (2021)","10.1016/j.physrep.2021.01.001",,"cond-mat.stat-mech gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The renormalization group plays an essential role in many areas of physics,
both conceptually and as a practical tool to determine the long-distance
low-energy properties of many systems on the one hand and on the other hand
search for viable ultraviolet completions in fundamental physics. It provides
us with a natural framework to study theoretical models where degrees of
freedom are correlated over long distances and that may exhibit very distinct
behavior on different energy scales. The nonperturbative functional
renormalization-group (FRG) approach is a modern implementation of Wilson's RG,
which allows one to set up nonperturbative approximation schemes that go beyond
the standard perturbative RG approaches. The FRG is based on an exact
functional flow equation of a coarse-grained effective action (or Gibbs free
energy in the language of statistical mechanics). We review the main
approximation schemes that are commonly used to solve this flow equation and
discuss applications in equilibrium and out-of-equilibrium statistical physics,
quantum many-particle systems, high-energy physics and quantum gravity.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:17:41 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 08:00:13 GMT""},{""version"":""v3"",""created"":""Fri, 7 May 2021 08:46:33 GMT""}]","2021-05-10"
"2006.04854","George Younes","G. Younes (1), P. S. Ray (2), M. G. Baring (3), C. Kouveliotou (1), C.
  Fletcher (4), Z. Wadiasingh (5), A. K. Harding (5), A. Goldstein (4) ((1)
  George Washington University, (2) Naval Research Lab, (3) Rice University,
  (4) USRA/NASA/MSFC, (5) NASA/GSFC)","A radiatively-quiet glitch and anti-glitch in the magnetar 1E 2259+586","Accepted for publication in the Astrophysical Journal Letters --
  Acknowledgment fixed to note the correct grant number",,"10.3847/2041-8213/ab9a48",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the timing and spectral properties of the soft X-ray emission
from the magnetar 1E 2259+586 from January 2013, $\sim 8$ months after the
detection of an anti-glitch, until September 2019, using the Neil Gehrels Swift
and NICER observatories. During this time span, we detect two timing
discontinuities. The first, occurring around 5 years after the April 2012
anti-glitch, is a relatively large spin-up glitch with a fractional amplitude
$\Delta\nu/\nu=1.24(2)\times10^{-6}$. We find no evidence for flux enhancement
or change in the spectral or pulse profile shape around the time of this
glitch. This is consistent with the picture that a significant number of
magnetar spin-up glitches are radiatively-quiet. Approximately 1.5 years later
in April 2019, 1E 2259+586 exhibited an anti-glitch with spin-down of a
fractional amplitude $\Delta\nu/\nu=-5.8(1)\times10^{-7}$; similar to the
fractional change detected in 2012. We do not, however, detect any change to
the pulse-profile shape or increase in the rms pulsed flux of the source, nor
do we see any possible bursts from its direction around the time of the
anti-glitch; all of which occurred during the 2012 event. Hence, similar to
spin-up glitches, anti-glitches can occur silently. This may suggest that these
phenomena originate in the neutron star interior, and that their locale and
triggering mechanism do not necessarily have to be connected to the
magnetosphere. Lastly, our observations suggest that the occurrence rate of
spin-up and spin-down glitches is about the same in 1E 2259+586, with the
former having a larger net fractional change.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:18:42 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 16:40:11 GMT""}]","2020-07-01"
"2006.04855","Alexander Maloney","Alexander Maloney and Edward Witten","Averaging Over Narain Moduli Space","46 pages",,"10.1007/JHEP10(2020)187",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent developments involving JT gravity in two dimensions indicate that
under some conditions, a gravitational path integral is dual to an average over
an ensemble of boundary theories, rather than to a specific boundary theory.
For an example in one dimension more, one would like to compare a random
ensemble of two-dimensional CFT's to Einstein gravity in three dimensions. But
this is difficult. For a simpler problem, here we average over Narain's family
of two-dimensional CFT's obtained by toroidal compactification. These theories
are believed to be the most general ones with their central charges and abelian
current algebra symmetries, so averaging over them means picking a random CFT
with those properties. The average can be computed using the Siegel-Weil
formula of number theory and has some properties suggestive of a bulk dual
theory that would be an exotic theory of gravity in three dimensions. The bulk
dual theory would be more like $U(1)^{2D}$ Chern-Simons theory than like
Einstein gravity.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:19:10 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 17:48:55 GMT""}]","2020-12-02"
"2006.04856","Julian Yarkony","Naveed Haghani, Jiaoyang Li, Sven Koenig, Gautam Kunapuli, Claudio
  Contardo, Julian Yarkony","Integer Programming for Multi-Robot Planning: A Column Generation
  Approach",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of coordinating a fleet of robots in a warehouse so
as to maximize the reward achieved within a time limit while respecting problem
and robot specific constraints. We formulate the problem as a weighted set
packing problem where elements are defined as being the space-time positions a
robot can occupy and the items that can be picked up and delivered. We enforce
that robots do not collide, that each item is delivered at most once, and that
the number of robots active at any time does not exceed the total number
available. Since the set of robot routes is not enumerable, we attack
optimization using column generation where pricing is a resource-constrained
shortest-path problem.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:19:14 GMT""}]","2020-06-11"
"2006.04857","Evan Philip","Sahal Kaushik, Dmitri E. Kharzeev, Evan John Philip","Transverse Chiral Magnetic Photocurrent Induced by Linearly Polarized
  Light in Mirror-Symmetric Weyl Semimetals",,"Phys. Rev. Research 2, 042011 (2020)","10.1103/PhysRevResearch.2.042011",,"cond-mat.mes-hall hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new class of photocurrents is predicted to occur in both type-I and type-II
Weyl semimetals. Unlike the previously studied photocurrents in chiral
materials, the proposed current requires neither circularly polarized light,
nor an absence of symmetry with respect to a plane of reflection. We show that
if a Weyl semimetal has a broken inversion symmetry then linearly polarized
light can induce a photocurrent transverse to the direction of an applied
magnetic field, in spite of the symmetry with respect to a reflection plane and
the time reversal symmetry. The class of materials in which we expect this to
occur is sufficiently broad and includes the transition metal monopnictides
such as TaAs. The effect stems from the dynamics of Weyl chiral quasi-particles
in a magnetic field, restricted by the symmetries described above; because the
resulting current is transverse to the direction of magnetic field, we call it
the transverse chiral magnetic photocurrent. The magnitude of the resulting
photocurrent is predicted to be significant in the THz frequency range, about
$0.75\; \mathrm{\mu A}$ for type-I and $2.5\; \mathrm{\mu A}$ for type-II Weyl
semimetals. This opens the possibility to utilize the predicted transverse
chiral magnetic photocurrent for sensing unpolarized THz radiation.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:19:42 GMT""},{""version"":""v2"",""created"":""Wed, 14 Oct 2020 17:04:27 GMT""}]","2020-10-21"
"2006.04858","Heinrich Jiang","Heinrich Jiang, Qijia Jiang, Aldo Pacchiano","Learning the Truth From Only One Side of the Story",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning under one-sided feedback (i.e., where we only observe the labels for
examples we predicted positively on) is a fundamental problem in machine
learning -- applications include lending and recommendation systems. Despite
this, there has been surprisingly little progress made in ways to mitigate the
effects of the sampling bias that arises. We focus on generalized linear models
and show that without adjusting for this sampling bias, the model may converge
suboptimally or even fail to converge to the optimal solution. We propose an
adaptive approach that comes with theoretical guarantees and show that it
outperforms several existing methods empirically. Our method leverages variance
estimation techniques to efficiently learn under uncertainty, offering a more
principled alternative compared to existing approaches.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:20:28 GMT""},{""version"":""v2"",""created"":""Tue, 13 Oct 2020 17:34:54 GMT""}]","2020-10-14"
"2006.04859","Suryansh Saxena","Suryansh Saxena and Isaac K Isukapati","Novel Perception Algorithmic Framework For Object Identification and
  Tracking In Autonomous Navigation",,,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a novel perception framework that has the ability to
identify and track objects in autonomous vehicle's field of view. The proposed
algorithms don't require any training for achieving this goal. The framework
makes use of ego-vehicle's pose estimation and a KD-Tree-based segmentation
algorithm to generate object clusters. In turn, using a VFH technique, the
geometry of each identified object cluster is translated into a multi-modal PDF
and a motion model is initiated with every new object cluster for the purpose
of robust spatio-temporal tracking. The methodology further uses statistical
properties of high-dimensional probability density functions and Bayesian
motion model estimates to identify and track objects from frame to frame. The
effectiveness of the methodology is tested on a KITTI dataset. The results show
that the median tracking accuracy is around 91% with an end-to-end
computational time of 153 milliseconds
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:21:40 GMT""}]","2020-06-11"
"2006.04860","Heinz Bauschke","Salihah Alwadani, Heinz H. Bauschke, Julian P. Revalski, Xianfu Wang","Resolvents and Yosida approximations of displacement mappings of
  isometries",,,,,"math.FA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Maximally monotone operators are fundamental objects in modern optimization.
The main classes of monotone operators are subdifferential operators and
matrices with a positive semidefinite symmetric part. In this paper, we study a
nice class of monotone operators: displacement mappings of isometries of finite
order. We derive explicit formulas for resolvents, Yosida approximations, and
(set-valued and MoorePenrose) inverses. We illustrate our results by
considering certain rational rotators and circular shift operators.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:27:27 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 22:10:21 GMT""}]","2021-03-25"
"2006.04861","Jasson Vindas","Andreas Debrouwere, Bojan Prangoski and Jasson Vindas","Factorization in Denjoy-Carleman classes associated to representations
  of $(\mathbb{R}^{d},+)$","27 pages","J. Funct. Anal. 280 (2021), Article 108831 (31 pages)","10.1016/j.jfa.2020.108831",,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For two types of moderate growth representations of $(\mathbb{R}^d,+)$ on
sequentially complete locally convex Hausdorff spaces (including
F-representations [J. Funct. Anal. 262 (2012), 667-681], we introduce
Denjoy-Carleman classes of ultradifferentiable vectors and show a strong
factorization theorem of Dixmier-Malliavin type for them. In particular, our
factorization theorem solves [Conjecture 6.; J. Funct. Anal. 262 (2012),
667-681] for analytic vectors of representations of $G =(\mathbb{R}^d,+)$. As
an application, we show that various convolution algebras and modules of
ultradifferentiable functions satisfy the strong factorization property.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:28:21 GMT""},{""version"":""v2"",""created"":""Sun, 1 Nov 2020 02:12:17 GMT""}]","2021-08-19"
"2006.04862","Chulhee Yun","Chulhee Yun, Yin-Wen Chang, Srinadh Bhojanapalli, Ankit Singh Rawat,
  Sashank J. Reddi, Sanjiv Kumar","$O(n)$ Connections are Expressive Enough: Universal Approximability of
  Sparse Transformers","31 pages, NeurIPS 2020 Camera-ready",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Transformer networks have redefined the state of the art in many
NLP tasks. However, these models suffer from quadratic computational cost in
the input sequence length $n$ to compute pairwise attention in each layer. This
has prompted recent research into sparse Transformers that sparsify the
connections in the attention layers. While empirically promising for long
sequences, fundamental questions remain unanswered: Can sparse Transformers
approximate any arbitrary sequence-to-sequence function, similar to their dense
counterparts? How does the sparsity pattern and the sparsity level affect their
performance? In this paper, we address these questions and provide a unifying
framework that captures existing sparse attention models. We propose sufficient
conditions under which we prove that a sparse attention model can universally
approximate any sequence-to-sequence function. Surprisingly, our results show
that sparse Transformers with only $O(n)$ connections per attention layer can
approximate the same function class as the dense model with $n^2$ connections.
Lastly, we present experiments comparing different patterns/levels of sparsity
on standard NLP tasks.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:30:12 GMT""},{""version"":""v2"",""created"":""Sat, 19 Dec 2020 07:16:15 GMT""}]","2020-12-22"
"2006.04863","Aida Ahmadzadegan","Aida Ahmadzadegan, Petar Simidzija, Ming Li, Achim Kempf","Learning to Utilize Correlated Auxiliary Noise: A Possible Quantum
  Advantage","11 pages, 3 figures",,,,"quant-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper has two messages. First, we demonstrate that neural networks that
process noisy data can learn to exploit, when available, access to auxiliary
noise that is correlated with the noise on the data. In effect, the network
learns to use the correlated auxiliary noise as an approximate key to decipher
its noisy input data. Second, we show that, for this task, the scaling behavior
with increasing noise is such that future quantum machines could possess an
advantage. In particular, decoherence generates correlated auxiliary noise in
the environment. The new approach could, therefore, help enable future quantum
machines by providing machine-learned quantum error correction.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:33:19 GMT""},{""version"":""v2"",""created"":""Wed, 16 Sep 2020 16:47:36 GMT""}]","2020-09-17"
"2006.04865","Diksha Gupta","Diksha Gupta, Jared Saia, Maxwell Young","Resource Burning for Permissionless Systems","35 pages",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Proof-of-work puzzles and CAPTCHAS consume enormous amounts of energy and
time. These techniques are examples of resource burning: verifiable consumption
of resources solely to convey information.
  Can these costs be eliminated? It seems unlikely since resource burning
shares similarities with ""money burning"" and ""costly signaling"", which are
foundational to game theory, biology, and economics. Can these costs be
reduced? Yes, research shows we can significantly lower the asymptotic costs of
resource burning in many different settings.
  In this paper, we survey the literature on resource burning; take positions
based on predictions of how the tool is likely to evolve; and propose several
open problems targeted at the theoretical distributed-computing research
community.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:33:39 GMT""}]","2020-06-11"
"2006.04866","Jesus Salas","Jes\'us Salas","The phase diagram for the bisected-hexagonal-lattice five-state Potts
  antiferromagnet","26 pages, pdflatex. Contains 25 pdf figures. Minor changes with
  respect to version 1, including a slight change in the title. Final version
  published in journal","Phys. Rev. E 102, 032124 (2020)","10.1103/PhysRevE.102.032124",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the phase diagram of the five-state Potts
antiferromagnet on the bisected-hexagonal lattice. This question is important
since Delfino and Tartaglia recently showed that a second-order transition in a
five-state Potts antiferromagnet is allowed, and the bisected-hexagonal lattice
had emerged as a candidate for such a transition on numerical grounds. By using
high-precision Monte Carlo simulations and two complementary analysis methods,
we conclude that there is a finite-temperature first-order transition point.
This one separates a paramagnetic high-temperature phase, and a low-temperature
phase where five phases coexist. This phase transition is very weak in the
sense that its latent heat (per edge) is two orders of magnitude smaller than
that of other well-known weak first-order phase transitions.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:37:51 GMT""},{""version"":""v2"",""created"":""Wed, 16 Sep 2020 08:40:30 GMT""}]","2020-09-23"
"2006.04867","Ian Boutle","Ian A. Boutle, Manoj Joshi, F. Hugo Lambert, Nathan J. Mayne, Duncan
  Lyster, James Manners, Robert Ridgway, Krisztian Kohary","Mineral dust increases the habitability of terrestrial planets but
  confounds biomarker detection","15 pages, 4 figures, 3 tables","Nature Communications, 2020","10.1038/s41467-020-16543-8",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identification of habitable planets beyond our solar system is a key goal of
current and future space missions. Yet habitability depends not only on the
stellar irradiance, but equally on constituent parts of the planetary
atmosphere. Here we show, for the first time, that radiatively active mineral
dust will have a significant impact on the habitability of Earth-like
exoplanets. On tidally-locked planets, dust cools the day-side and warms the
night-side, significantly widening the habitable zone. Independent of orbital
configuration, we suggest that airborne dust can postpone planetary water loss
at the inner edge of the habitable zone, through a feedback involving
decreasing ocean coverage and increased dust loading. The inclusion of dust
significantly obscures key biomarker gases (e.g. ozone, methane) in simulated
transmission spectra, implying an important influence on the interpretation of
observations. We demonstrate that future observational and theoretical studies
of terrestrial exoplanets must consider the effect of dust.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:38:19 GMT""}]","2020-06-11"
"2006.04868","Debesh Jha","Debesh Jha, Michael A. Riegler, Dag Johansen, P{\aa}l Halvorsen,
  H{\aa}vard D. Johansen","DoubleU-Net: A Deep Convolutional Neural Network for Medical Image
  Segmentation",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semantic image segmentation is the process of labeling each pixel of an image
with its corresponding class. An encoder-decoder based approach, like U-Net and
its variants, is a popular strategy for solving medical image segmentation
tasks. To improve the performance of U-Net on various segmentation tasks, we
propose a novel architecture called DoubleU-Net, which is a combination of two
U-Net architectures stacked on top of each other. The first U-Net uses a
pre-trained VGG-19 as the encoder, which has already learned features from
ImageNet and can be transferred to another task easily. To capture more
semantic information efficiently, we added another U-Net at the bottom. We also
adopt Atrous Spatial Pyramid Pooling (ASPP) to capture contextual information
within the network. We have evaluated DoubleU-Net using four medical
segmentation datasets, covering various imaging modalities such as colonoscopy,
dermoscopy, and microscopy. Experiments on the MICCAI 2015 segmentation
challenge, the CVC-ClinicDB, the 2018 Data Science Bowl challenge, and the
Lesion boundary segmentation datasets demonstrate that the DoubleU-Net
outperforms U-Net and the baseline models. Moreover, DoubleU-Net produces more
accurate segmentation masks, especially in the case of the CVC-ClinicDB and
MICCAI 2015 segmentation challenge datasets, which have challenging images such
as smaller and flat polyps. These results show the improvement over the
existing U-Net model. The encouraging results, produced on various medical
image segmentation datasets, show that DoubleU-Net can be used as a strong
baseline for both medical image segmentation and cross-dataset evaluation
testing to measure the generalizability of Deep Learning (DL) models.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:38:24 GMT""},{""version"":""v2"",""created"":""Sat, 27 Jun 2020 15:40:40 GMT""}]","2020-06-30"
"2006.04869","Juan Arias-de-Reyna","Juan Arias de Reyna","Computation of the secondary zeta function","19 pages, 11 figures",,,,"math.NT math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The secondary zeta function $Z(s)=\sum_{n=1}^\infty\alpha_n^{-s}$, where
$\rho_n=\frac12+i\alpha_n$ are the zeros of zeta with $\Im(\rho)>0$, extends to
a meromorphic function on the hole complex plane. If we assume the Riemann
hypothesis the numbers $\alpha_n=\gamma_n$, but we do not assume the RH. We
give an algorithm to compute the analytic prolongation of the Dirichlet series
$Z(s)=\sum_{n=1}^\infty \alpha_n^{-s}$, for all values of $s$ and to a given
precision.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:40:54 GMT""}]","2020-06-11"
"2006.04870","Hedongliang Liu","Hedongliang Liu, Hengjia Wei, Sven Puchinger, Antonia Wachter-Zeh,
  Moshe Schwartz","On the Gap between Scalar and Vector Solutions of Generalized
  Combination Networks","extended version of arXiv:2001.04150v2; 13 pages, 5 figures, 1 table,
  accepted for publication in IEEE Transactions on Information Theory",,"10.1109/TIT.2021.3065364",,"cs.IT cs.NI cs.SI math.CO math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study scalar-linear and vector-linear solutions of the generalized
combination network. We derive new upper and lower bounds on the maximum number
of nodes in the middle layer, depending on the network parameters and the
alphabet size. These bounds improve and extend the parameter range of known
bounds. Using these new bounds we present a lower bound and an upper bound on
the gap in the alphabet size between optimal scalar-linear and optimal
vector-linear network coding solutions. For a fixed network structure, while
varying the number of middle-layer nodes $r$, the asymptotic behavior of the
upper and lower bounds shows that the gap is in $\Theta(\log(r))$.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:46:24 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 09:53:55 GMT""},{""version"":""v3"",""created"":""Thu, 11 Mar 2021 08:25:12 GMT""}]","2021-03-12"
"2006.04871","Roland Zweim\""uller","Roland Zweim\""uller","Image sets and basic ergodic properties in non-invertible dynamics",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While routinely used in other areas of dynamics, image sets are ill-defined
objects in non-invertible measurable dynamics. We propose a way of consistently
working with them, and illustrate it in the context of basic ergodic properties
like recurrence, ergodicity and exactness of null-preserving transformations.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:49:22 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jul 2020 15:32:51 GMT""}]","2020-07-31"
"2006.04872","Hugo Parlier","Ara Basmajian, Hugo Parlier and Ser Peow Tan","Prime orthogeodesics, concave cores and families of identities on
  hyperbolic surfaces","45 pages, 20 figures",,,,"math.GT math.DG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove and explore a family of identities relating lengths of curves and
orthogeodesics of hyperbolic surfaces. These identities hold over a large space
of metrics including ones with hyperbolic cone points, and in particular, show
how to extend a result of the first author to surfaces with cusps. One of the
main ingredients in the approach is a partition of the set of orthogeodesics
into sets depending on their dynamical behavior, which can be understood
geometrically by relating them to geodesics on orbifold surfaces. These
orbifold surfaces turn out to be exactly on the boundary of the space in which
the underlying identity holds.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:52:14 GMT""}]","2020-06-11"
"2006.04873","Mert G\""urb\""uzbalaban","Mert G\""urb\""uzbalaban, Andrzej Ruszczy\'nski and Landi Zhu","A Stochastic Subgradient Method for Distributionally Robust Non-Convex
  Learning",,,,,"math.OC cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a distributionally robust formulation of stochastic optimization
problems arising in statistical learning, where robustness is with respect to
uncertainty in the underlying data distribution. Our formulation builds on
risk-averse optimization techniques and the theory of coherent risk measures.
It uses semi-deviation risk for quantifying uncertainty, allowing us to compute
solutions that are robust against perturbations in the population data
distribution. We consider a large family of loss functions that can be
non-convex and non-smooth and develop an efficient stochastic subgradient
method. We prove that it converges to a point satisfying the optimality
conditions. To our knowledge, this is the first method with rigorous
convergence guarantees in the context of non-convex non-smooth distributionally
robust stochastic optimization. Our method can achieve any desired level of
robustness with little extra computational cost compared to population risk
minimization. We also illustrate the performance of our algorithm on real
datasets arising in convex and non-convex supervised learning problems.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:52:40 GMT""},{""version"":""v2"",""created"":""Sat, 15 Aug 2020 20:02:44 GMT""},{""version"":""v3"",""created"":""Tue, 8 Jun 2021 01:24:32 GMT""}]","2021-06-09"
"2006.04874","Jane Wu","Jane Wu, Zhenglin Geng, Hui Zhou, Ronald Fedkiw","Skinning a Parameterization of Three-Dimensional Space for Neural
  Network Cloth",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel learning framework for cloth deformation by embedding
virtual cloth into a tetrahedral mesh that parametrizes the volumetric region
of air surrounding the underlying body. In order to maintain this volumetric
parameterization during character animation, the tetrahedral mesh is
constrained to follow the body surface as it deforms. We embed the cloth mesh
vertices into this parameterization of three-dimensional space in order to
automatically capture much of the nonlinear deformation due to both joint
rotations and collisions. We then train a convolutional neural network to
recover ground truth deformation by learning cloth embedding offsets for each
skeletal pose. Our experiments show significant improvement over learning cloth
offsets from body surface parameterizations, both quantitatively and visually,
with prior state of the art having a mean error five standard deviations higher
than ours. Moreover, our results demonstrate the efficacy of a general learning
paradigm where high-frequency details can be embedded into low-frequency
parameterizations.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:53:03 GMT""}]","2020-06-11"
"2006.04875","Stefan Frick","Stefan Frick, Alex McMillan and John Rarity","Quantum Rangefinding",,"Opt. Express 28, 37118-37128 (2020)","10.1364/OE.399902",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum light generated in non-degenerate squeezers has many applications
such as sub-shot-noise transmission measurements to maximise the information
extracted by one photon or quantum illumination to increase the probability in
target detection. However, any application thus far fails to consider the
thermal characteristics of one half of the bipartite down-converted photon
state often used in these experiments. We show here that a maximally mixed
state, normally viewed as nuisance, can indeed be used to extract information
about the position of an object while at the same time providing efficient
camouflaging against other thermal or background light.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:54:42 GMT""},{""version"":""v2"",""created"":""Wed, 25 Nov 2020 08:08:37 GMT""}]","2020-11-26"
"2006.04876","Lisa L\""obling","L. L\""obling","NLTE spectral analysis of the intermediate helium-rich subdwarf B star
  CPD-20{\deg}1123","16 pages, 13 figures",,"10.1093/mnras/staa1686",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Subdwarf B (sdB) stars are core helium-burning stars with stratified
atmospheres. Their atmospheres are dominated by hydrogen (H) while the helium
(He) and metal abundances are shaped by an interplay of gravitational settling
and radiative levitation. However, a small fraction of these show spectra
dominated by He I absorption lines. In between these groups of He-deficient and
extreme He-rich sdBs, some are found to have intermediate surface He
abundances. These objects are proposed to be young ""normal"" (He-deficient) sdBs
for which the dynamical stratification of the atmosphere is still ongoing. We
present an analysis of the optical spectrum of such an intermediate He-rich
sdB, namely CPD-20{\deg}1123, by means of non-local thermodynamic equilibrium
(NLTE) stellar atmosphere models. It has a He-to-H number ratio of
$\mathrm{He/H} = 0.13 \pm 0.05$ and its effective temperature of
$T_\mathrm{eff} = 25\,500 \pm 1\,000$ together with a surface gravity of
$\log\,(g\,/\,\mathrm{cm}/\mathrm{s}^2) = 5.3 \pm 0.3$ places the star close to
the high-temperature edge until which it may be justified to use LTE model
atmospheres. This work states a test of the T\""ubingen NLTE Model Atmosphere
Package for this temperature regime. We present the first application of
revised, elaborated model atoms of low ionization stages of light metals usable
with this atmosphere code.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:55:13 GMT""}]","2020-06-24"
"2006.04877","Vahid Partovi Nia","Vahid Partovi Nia, Xinlin Li, Masoud Asgharian, Shoubo Hu, Zhitang
  Chen, Yanhui Geng","A Causal Direction Test for Heterogeneous Populations",,,,,"stat.ME cs.LG stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A probabilistic expert system emulates the decision-making ability of a human
expert through a directional graphical model. The first step in building such
systems is to understand data generation mechanism. To this end, one may try to
decompose a multivariate distribution into product of several conditionals, and
evolving a blackbox machine learning predictive models towards transparent
cause-and-effect discovery. Most causal models assume a single homogeneous
population, an assumption that may fail to hold in many applications. We show
that when the homogeneity assumption is violated, causal models developed based
on such assumption can fail to identify the correct causal direction. We
propose an adjustment to a commonly used causal direction test statistic by
using a $k$-means type clustering algorithm where both the labels and the
number of components are estimated from the collected data to adjust the test
statistic. Our simulation result show that the proposed adjustment
significantly improves the performance of the causal direction test statistic
for heterogeneous data. We study large sample behaviour of our proposed test
statistic and demonstrate the application of the proposed method using real
data.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:59:14 GMT""},{""version"":""v2"",""created"":""Mon, 27 Sep 2021 20:51:37 GMT""}]","2021-09-29"
"2006.04878","Valanarasu Jeya Maria Jose","Jeya Maria Jose, Vishwanath Sindagi, Ilker Hacihaliloglu, Vishal M.
  Patel","KiU-Net: Towards Accurate Segmentation of Biomedical Images using
  Over-complete Representations","Accepted at MICCAI 2020",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to its excellent performance, U-Net is the most widely used backbone
architecture for biomedical image segmentation in the recent years. However, in
our studies, we observe that there is a considerable performance drop in the
case of detecting smaller anatomical landmarks with blurred noisy boundaries.
We analyze this issue in detail, and address it by proposing an over-complete
architecture (Ki-Net) which involves projecting the data onto higher dimensions
(in the spatial sense). This network, when augmented with U-Net, results in
significant improvements in the case of segmenting small anatomical landmarks
and blurred noisy boundaries while obtaining better overall performance.
Furthermore, the proposed network has additional benefits like faster
convergence and fewer number of parameters. We evaluate the proposed method on
the task of brain anatomy segmentation from 2D Ultrasound (US) of preterm
neonates, and achieve an improvement of around 4% in terms of the DICE accuracy
and Jaccard index as compared to the standard-U-Net, while outperforming the
recent best methods by 2%. Code:
https://github.com/jeya-maria-jose/KiU-Net-pytorch .
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:59:24 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 21:20:48 GMT""}]","2020-07-10"
"2006.04879","Xihe Li","Xihe Li, Hajo Broersma, Ligong Wang","Extremal problems and results related to Gallai-colorings","20 pages, 1 figure","DiscreteMathematics, 2021","10.1016/j.disc.2021.112567",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Gallai-coloring (Gallai-$k$-coloring) is an edge-coloring (with colors from
$\{1, 2, \ldots, k\}$) of a complete graph without rainbow triangles. Given a
graph $H$ and a positive integer $k$, the $k$-colored Gallai-Ramsey number
$GR_k(H)$ is the minimum integer $n$ such that every Gallai-$k$-coloring of the
complete graph $K_n$ contains a monochromatic copy of $H$. In this paper, we
consider two extremal problems related to Gallai-$k$-colorings. First, we
determine upper and lower bounds for the maximum number of edges that are not
contained in any rainbow triangle or monochromatic triangle in a
$k$-edge-coloring of $K_n$. Second, for $n\geq GR_k(K_3)$, we determine upper
and lower bounds for the minimum number of monochromatic triangles in a
Gallai-$k$-coloring of $K_{n}$, yielding the exact value for $k=3$.
Furthermore, we determine the Gallai-Ramsey number $GR_k(K_4+e)$ for the graph
on five vertices consisting of a $K_4$ with a pendant edge.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:00:23 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 14:11:19 GMT""}]","2022-03-23"
"2006.04880","Wei Zhan","Uma Girish, Ran Raz, Wei Zhan","Quantum Logspace Algorithm for Powering Matrices with Bounded Norm",,,,,"cs.CC quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a quantum logspace algorithm for powering contraction matrices, that
is, matrices with spectral norm at most~1. The algorithm gets as an input an
arbitrary $n\times n$ contraction matrix $A$, and a parameter $T \leq
\mathrm{poly}(n)$ and outputs the entries of $A^T$, up to (arbitrary)
polynomially small additive error. The algorithm applies only unitary
operators, without intermediate measurements. We show various implications and
applications of this result:
  First, we use this algorithm to show that the class of quantum logspace
algorithms with only quantum memory and with intermediate measurements is
equivalent to the class of quantum logspace algorithms with only quantum memory
without intermediate measurements. This shows that the deferred-measurement
principle, a fundamental principle of quantum computing, applies also for
quantum logspace algorithms (without classical memory). More generally, we give
a quantum algorithm with space $O(S + \log T)$ that takes as an input the
description of a quantum algorithm with quantum space $S$ and time $T$, with
intermediate measurements (without classical memory), and simulates it
unitarily with polynomially small error, without intermediate measurements.
  Since unitary transformations are reversible (while measurements are
irreversible) an interesting aspect of this result is that it shows that any
quantum logspace algorithm (without classical memory) can be simulated by a
reversible quantum logspace algorithm. This proves a quantum analogue of the
result of Lange, McKenzie and Tapp that deterministic logspace is equal to
reversible logspace [LMT00].
  Finally, we use our results to show non-trivial classical simulations of
quantum logspace learning algorithms.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:01:04 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 15:33:21 GMT""},{""version"":""v3"",""created"":""Thu, 6 May 2021 20:57:50 GMT""}]","2021-05-10"
"2006.04881","Jiaxin Yin","Jia-Xin Yin, Wenlong Ma, Tyler A. Cochran, Xitong Xu, Songtian S.
  Zhang, Hung-Ju Tien, Nana Shumiya, Guangming Cheng, Kun Jiang, Biao Lian,
  Zhida Song, Guoqing Chang, Ilya Belopolski, Daniel Multer, Maksim Litskevich,
  Zijia Cheng, Xian Yang, Bianca Swidler, Huibin Zhou, Hsin Lin, Titus Neupert,
  Ziqiang Wang, Nan Yao, Tay-Rong Chang, Shuang Jia, M. Zahid Hasan","Discovery of a quantum limit Chern magnet TbMn6Sn6","To appear in Nature (2020)","Nature 583, 533-536 (2020)","10.1038/s41586-020-2482-7",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quantum level interplay between geometry, topology, and correlation is at
the forefront of fundamental physics. Owing to the unusual lattice geometry and
breaking of time-reversal symmetry, kagome magnets are predicted to support
intrinsic Chern quantum phases. However, quantum materials hosting ideal
spin-orbit coupled kagome lattices with strong out-of-plane magnetization have
been lacking. Here we use scanning tunneling microscopy to discover a new
topological kagome magnet TbMn6Sn6, which is close to satisfying the above
criteria. We visualize its effectively defect-free purely Mn-based
ferromagnetic kagome lattice with atomic resolution. Remarkably, its electronic
state exhibits distinct Landau quantization upon the application of a magnetic
field, and the quantized Landau fan structure features spin-polarized Dirac
dispersion with a large Chern gap. We further demonstrate the bulk-boundary
correspondence between the Chern gap and topological edge state, as well as the
Berry curvature field correspondence of Chern gapped Dirac fermions. Our
results point to the realization of a quantum-limit Chern phase in TbMn6Sn6,
opening up an avenue for discovering topological quantum phenomena in the
RMn6Sn6 (R = rare earth element) family with a variety of magnetic structures.
Our visualization of the magnetic bulk-boundary-Berry correspondence covering
real and momentum space demonstrates a proof-of-principle method revealing
topological magnets.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:03:10 GMT""}]","2020-07-28"
"2006.04882","Os Keyes","Calvin Liang, Jevan Hutson and Os Keyes","Surveillance, Stigma & Sociotechnical Design for HIV",,,,,"cs.HC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Online dating and hookup platforms have fundamentally changed people's
day-to-day practices of sex and love-but exist in tension with older social and
medicolegal norms. This is particularly the case for people with HIV, who are
frequently stigmatized, surveilled, ostracized and incarcerated because of
their status. Efforts to make intimate platforms ""work"" for HIV frequently
focus on user-to-user interactions and disclosure of one's HIV status but elide
both the structural forces at work in regulating sex and the involvement of the
state in queer lives. In an effort to foreground these forces and this
involvement, we analyze the approaches that intimate platforms have taken in
designing for HIV disclosure through a content analysis of 49 current
platforms. We argue that the implicit reinforcement of stereotypes about who
HIV is or is not a concern for, along with the failure to consider state
practices when designing for data disclosure, opens up serious risks for
HIV-positive and otherwise marginalized people. While we have no panacea for
the tension between disclosure and risk, we point to bottom-up, communal, and
queer approaches to design as a way of potentially making that tension easier
to safely navigate.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:03:15 GMT""}]","2020-06-11"
"2006.04883","Wojciech Szmyt Mr","Wojciech Szmyt, Carlos Guerra-Nunez, Clemens Dransfeld and Ivo Utke","Solving the inverse Knudsen problem: gas diffusion in random fibrous
  media","33 pages, 16 figures. Revision: Added list of symbols, replaced
  Figure 1, extended explanation in section 3.1, added practical calculation
  section 6.2, corrected typos",,"10.1016/j.memsci.2020.118728",,"physics.app-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  About a century ago, Knudsen derived the groundbreaking theory of gas
diffusion through straight pipes and holes, which since then found widespread
application in innumerable fields of science and inspired the development of
vacuum and related coating technologies, from academic research to numerous
industrial sectors. Knudsen's theory can be straightforwardly applied to filter
membranes with arrays of extended holes for example, however, for the inverse
geometry arrangement, which arises when solid nanowires or fibers are arranged
into porous interwoven material (like in carpets or brushes) the derivation of
an analytical theory framework was still missing. In this paper, we have
identified the specific geometric and thermodynamic parameters that determine
the gas diffusion kinetics in arrays of randomly oriented cylinders and provide
a set of analytical expressions allowing to comprehensively describe the gas
transport in such structures. We confirmed analytical solutions by Monte Carlo
simulations. We specify our findings for an atomic layer deposition process,
the diffusion of trimethyaluminium molecules into a carbon nanotube array, but
highlight the applicability of our derivation for other fields comprising gas
diffusion membranes, composite materials, fuel cells and more.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:03:40 GMT""},{""version"":""v2"",""created"":""Wed, 2 Sep 2020 18:48:11 GMT""}]","2020-10-21"
"2006.04884","Marius Mosbach","Marius Mosbach, Maksym Andriushchenko, Dietrich Klakow","On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and
  Strong Baselines","ICLR 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fine-tuning pre-trained transformer-based language models such as BERT has
become a common practice dominating leaderboards across various NLP benchmarks.
Despite the strong empirical performance of fine-tuned models, fine-tuning is
an unstable process: training the same model with multiple random seeds can
result in a large variance of the task performance. Previous literature (Devlin
et al., 2019; Lee et al., 2020; Dodge et al., 2020) identified two potential
reasons for the observed instability: catastrophic forgetting and small size of
the fine-tuning datasets. In this paper, we show that both hypotheses fail to
explain the fine-tuning instability. We analyze BERT, RoBERTa, and ALBERT,
fine-tuned on commonly used datasets from the GLUE benchmark, and show that the
observed instability is caused by optimization difficulties that lead to
vanishing gradients. Additionally, we show that the remaining variance of the
downstream task performance can be attributed to differences in generalization
where fine-tuned models with the same training loss exhibit noticeably
different test performance. Based on our analysis, we present a simple but
strong baseline that makes fine-tuning BERT-based models significantly more
stable than the previously proposed approaches. Code to reproduce our results
is available online: https://github.com/uds-lsv/bert-stable-fine-tuning.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:06:24 GMT""},{""version"":""v2"",""created"":""Tue, 6 Oct 2020 10:03:47 GMT""},{""version"":""v3"",""created"":""Thu, 25 Mar 2021 07:39:38 GMT""}]","2021-03-26"
"2006.04885","Boyan Torosov","Boyan T. Torosov, Michael Drewsen, Nikolay V. Vitanov","Chiral resolution by composite Raman pulses","7 pages, 7 figures","Phys. Rev. Research 2, 043235 (2020)","10.1103/PhysRevResearch.2.043235",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present two methods for efficient detection of chiral molecules based on
sequences of single pulses and Raman pulse pairs. The chiral molecules are
modelled by a closed-loop three-state system with different signs in one of the
couplings for the two enantiomers. One method uses a sequence of three
interaction steps: a single pulse, a Raman pulse, and another single pulse. The
other method uses a sequence of only two interaction steps: a Raman pulse, and
a single pulse. The second method is simpler and faster but requires a more
sophisticated Raman pulse than the first one. Both techniques allow for
straightforward generalizations by replacing the single and Raman pulses with
composite pulse sequences. The latter achieve very high signal contrast and far
greater robustness to experimental errors than by using single pulses. We
demonstrate that both constant-rotation (i.e., with phase compensation) and
variable-rotation (i.e., with phase distortion) composite pulses can be used,
the former being more accurate and the latter being simpler and faster.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:07:47 GMT""}]","2020-11-18"
"2006.04886","Juan S. Cruz","Wen-Yuan Ai and Juan S. Cruz and Bjorn Garbrecht and Carlos Tamarit","Gradient effects on false vacuum decay in gauge theory","39 pages, 12 figures, 2 tables","Phys. Rev. D 102, 085001 (2020)","10.1103/PhysRevD.102.085001","TUM-HEP-1265-20, CP3-20-21","hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study false vacuum decay for a gauged complex scalar field in a polynomial
potential with nearly degenerate minima. Radiative corrections to the profile
of the nucleated bubble as well as the full decay rate are computed in the
planar thin-wall approximation using the effective action. This allows to
account for the inhomogeneity of the bounce background and the radiative
corrections in a self-consistent manner. In contrast to scalar or fermion
loops, for gauge fields one must deal with a coupled system that mixes the
Goldstone boson and the gauge fields, which considerably complicates the
numerical calculation of Green's functions. In addition to the renormalization
of couplings, we employ a covariant gradient expansion in order to
systematically construct the counterterm for the wave-function renormalization.
The result for the full decay rate however does not rely on such an expansion
and accounts for all gradient corrections at the chosen truncation of the loop
expansion. The ensuing gradient effects are shown to be of the same order of
magnitude as non-derivative one-loop corrections.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:13:51 GMT""},{""version"":""v2"",""created"":""Tue, 6 Oct 2020 09:55:01 GMT""}]","2020-10-07"
"2006.04887","Mehdi Abbasi","Mehdi Abbasi, Alexander Farutin, Hamid Ez-Zahraouy, Abdelilah
  Benyoussef and Chaouqi Misbah","Erythrocyte-erythrocyte aggregation dynamics under shear flow","14pages","Phys. Rev. Fluids 6, 023602 (2021)","10.1103/PhysRevFluids.6.023602",,"physics.bio-ph physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Red blood cells (RBCs) -- erythrocytes -- suspended in plasma tend to
aggregate and form rouleaux. During aggregation the first stage consists in the
formation of RBC doublets [Blood cells, molecules, and diseases 25, 339
(1999)]. While aggregates are normally dissociated by moderate flow stresses,
under some pathological conditions the aggregation becomes irreversible, which
leads to high blood viscosity and vessel occlusion. We perform here
two-dimensional simulations to study the doublet dynamics under shear flow in
different conditions and its impact on rheology. We sum up our results on the
dynamics of doublet in a rich phase diagram in the parameter space (flow
strength, adhesion energy) showing four different types of doublet
configurations and dynamics. We find that membrane tank-treading plays an
important role in doublet disaggregation, in agreement with experiments on
RBCs. A remarkable feature found here is that when a single cell performs
tumbling (by increasing vesicle internal viscosity) the doublet formed due to
adhesion (even very weak) remains stable even under a very strong shear rate.
It is seen in this regime that an increase of shear rate induces an adaptation
of the doublet conformation allowing the aggregate to resist cell-cell
detachment. We show that the normalized effective viscosity of doublet
suspension increases significantly with the adhesion energy, a fact which
should affect blood perfusion in microcirculation.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:17:56 GMT""}]","2021-06-04"
"2006.04888","Ronald Lipton","M. Alyari, R. Bradford, M. Campanella, P. Camporeale, R. Demina, J.
  Everts, Z. Gecse, R. Halenza, U. Heintz, S. Holland, S. Hong, S. Korjenevski,
  A. Lampis, R. Lipton, R. Patti, J. Segal, K.W. Shin","200 mm Sensor Development Using Bonded Wafers","11 pages",,"10.1088/1748-0221/16/02/T02002","FERMILAB-PUB-20-223-CMS-E","physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sensors fabricated from high resistivity, float zone, silicon material have
been the basis of vertex detectors and trackers for the last 30 years. The
areas of these devices have increased from a few square cm to $\> 200\ m^2$ for
the existing CMS tracker. High Luminosity Large Hadron Collider (HL-LHC), CMS
and ATLAS tracker upgrades will each require more than $200\ m^2$ of silicon
and the CMS High Granularity Calorimeter (HGCAL) will require more than $600\
m^2$. The cost and complexity of assembly of these devices is related to the
area of each module, which in turn is set by the size of the silicon sensors.
In addition to large area, the devices must be radiation hard, which requires
the use of sensors thinned to 200 microns or less. The combination of wafer
thinning and large wafer diameter is a significant technical challenge, and is
the subject of this work. We describe work on development of thin sensors on
$200 mm$ wafers using wafer bonding technology. Results of development runs
with float zone, Silicon-on-Insulator and Silicon-Silicon bonded wafer
technologies are reported.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:19:22 GMT""},{""version"":""v2"",""created"":""Wed, 2 Sep 2020 21:18:32 GMT""}]","2021-03-24"
"2006.04889","Kumar Vijay Mishra","John A. Hodge, Kumar Vijay Mishra and Amir I. Zaghloul","Intelligent Time-Varying Metasurface Transceiver for Index Modulation in
  6G Wireless Networks","5 pages, 4 figures",,"10.1109/LAWP.2020.3025333",,"physics.app-ph eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Index modulation (IM) is one of the candidate technologies for the upcoming
sixth generation (6G) wireless communications networks. In this paper, we
propose a space-time-modulated reconfigurable intelligent metasurface (RI-MTS)
that is configured to implement various frequency-domain IM techniques in a
multiple-input multiple-output (MIMO) array configuration. Unlike prior works
which mostly analyze signal theory of general RI-MTS IM, we present novel
electromagnetics-compliant designs of specific IMs such as sub-carrier index
modulation (SIM) and MIMO orthogonal frequency-domain modulation IM
(MIMO-OFDM-IM). Our full-wave electromagnetic simulations and analytical
computations establish the programmable ability of these transceivers to vary
the reflection phase and generate frequency harmonics for IM. Our experiments
for bit error rate show that RI-MTS-based SIM and MIMO-OFDM-IM are lower than
conventional MIMO-OFDM.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:19:49 GMT""},{""version"":""v2"",""created"":""Wed, 23 Sep 2020 00:46:28 GMT""}]","2020-12-30"
"2006.04890","Barry Bradlyn","Jennifer Cano and Barry Bradlyn","Band Representations and Topological Quantum Chemistry","24pgs, 2 figures. To appear in Annual Reviews of Condensed Matter
  Physics",,"10.1146/annurev-conmatphys-041720-124134",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we provide a pedagogical review of the theory of topological
quantum chemistry and topological crystalline insulators. We begin with an
overview of the properties of crystal symmetry groups in position and momentum
space. Next, we introduce the concept of a band representation, which
quantifies the symmetry of topologically trivial band structures. By combining
band representations with symmetry constraints on the connectivity of bands in
momentum space, we show how topologically nontrivial bands can be catalogued
and classified. We present several examples of new topological phases
discovered using this paradigm, and conclude with an outlook towards future
developments.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:21:03 GMT""}]","2021-02-15"
"2006.04891","Elton J. G. Santos","Alexey Kartsev, Mathias Augustin, Richard F. L. Evans, Kostya S.
  Novoselov, Elton J. G. Santos","Higher-order exchange interactions in two-dimensional magnets",,"npj Comput Mater 6, 150 (2020)","10.1038/s41524-020-00416-1",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetism in recently discovered van der Waals materials has opened new
avenues in the study of fundamental spin interactions in truly two-dimensions.
A paramount question is what effect higher-order interactions beyond bilinear
Heisenberg exchange have on the magnetic properties of few-atom thick
compounds. Here we demonstrate that biquadratic exchange interactions, which is
the simplest and most natural form of non-Heisenberg coupling, assume a key
role in the magnetic properties of layered magnets. Using a combination of
nonperturbative analytical techniques, non-collinear first-principles methods
and classical Monte Carlo calculations that incorporate higher-order exchange,
we show that several quantities including magnetic anisotropies, spin-wave gaps
and topological spin-excitations are intrinsically renormalized leading to
further thermal stability of the layers. We develop a spin Hamiltonian that
also contains antisymmetric exchanges (e.g. Dzyaloshinskii-Moriya interactions)
to successfully rationalize numerous observations currently under debate, such
as the non-Ising character of several compounds despite a strong magnetic
anisotropy, peculiarities of the magnon spectrum of 2D magnets, and the
discrepancy between measured and calculated Curie temperatures. Our results lay
the foundation of a universal higher-order exchange theory for novel 2D
magnetic design strategies.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:22:17 GMT""}]","2020-10-30"
"2006.04892","Piero Nicolini","Bernard Carr, Heather Mentzer, Jonas Mureika, Piero Nicolini","Self-complete and GUP-Modified Charged and Spinning Black Holes","18 pages, 10 figures: v2: minor corrections","Eur. Phys. J. C (2020) 80:1166","10.1140/epjc/s10052-020-08706-0",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore some implications of our previous proposal, motivated in part by
the Generalised Uncertainty Principle (GUP) and the possibility that black
holes have quantum mechanical hair that the ADM mass of a system has the form
$M + \beta M_\mathrm{Pl}^2/(2M)$, where $M$ is the bare mass, $M_\mathrm{Pl}$
is the Planck mass and $\beta$ is a positive constant. This also suggests some
connection between black holes and elementary particles and supports the
suggestion that gravity is self-complete. We extend our model to charged and
rotating black holes, since this is clearly relevant to elementary particles.
The standard Reissner-Nordstr\""om and Kerr solutions include zero-temperature
states, representing the smallest possible black holes, and already exhibit
features of the GUP-modified Schwarzschild solution. However, interesting new
features arise if the charged and rotating solutions are themselves
GUP-modified. In particular, there is an interesting transition below some
value of $\beta$ from the GUP solutions (spanning both super-Planckian and
sub-Planckian regimes) to separated super-Planckian and sub-Planckian
solutions. Equivalently, for a given value of $\beta$, there is a critical
value of the charge and spin above which the solutions bifurcate into
sub-Planckian and super-Planckian phases, separated by a mass gap in which no
black holes can form.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:24:31 GMT""},{""version"":""v2"",""created"":""Sat, 19 Dec 2020 14:17:36 GMT""}]","2020-12-22"
"2006.04893","Stefan Groha","Stefan Groha, Sebastian M Schmon, Alexander Gusev","A General Framework for Survival Analysis and Multi-State Modelling","19 pages, 14 figures",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Survival models are a popular tool for the analysis of time to event data
with applications in medicine, engineering, economics, and many more. Advances
like the Cox proportional hazard model have enabled researchers to better
describe hazard rates for the occurrence of single fatal events, but are unable
to accurately model competing events and transitions. Common phenomena are
often better described through multiple states, for example: the progress of a
disease modeled as healthy, sick and dead instead of healthy and dead, where
the competing nature of death and disease has to be taken into account.
Moreover, Cox models are limited by modeling assumptions, like proportionality
of hazard rates and linear effects. Individual characteristics can vary
significantly between observational units, like patients, resulting in
idiosyncratic hazard rates and different disease trajectories. These
considerations require flexible modeling assumptions. To overcome these issues,
we propose the use of neural ordinary differential equations as a flexible and
general method for estimating multi-state survival models by directly solving
the Kolmogorov forward equations. To quantify the uncertainty in the resulting
individual cause-specific hazard rates, we further introduce a variational
latent variable model and show that this enables meaningful clustering with
respect to multi-state outcomes as well as interpretability regarding covariate
values. We show that our model exhibits state-of-the-art performance on popular
survival data sets and demonstrate its efficacy in a multi-state setting
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:24:54 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 17:53:45 GMT""}]","2021-02-16"
"2006.04894","David Paz","David Paz, Hengyuan Zhang, Qinru Li, Hao Xiang, Henrik Christensen","Probabilistic Semantic Mapping for Urban Autonomous Driving Applications","6 pages, 7 figures, IROS 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advancements in statistical learning and computational abilities have
enabled autonomous vehicle technology to develop at a much faster rate. While
many of the architectures previously introduced are capable of operating under
highly dynamic environments, many of these are constrained to smaller-scale
deployments, require constant maintenance due to the associated scalability
cost with high-definition (HD) maps, and involve tedious manual labeling. As an
attempt to tackle this problem, we propose to fuse image and pre-built point
cloud map information to perform automatic and accurate labeling of static
landmarks such as roads, sidewalks, crosswalks, and lanes. The method performs
semantic segmentation on 2D images, associates the semantic labels with point
cloud maps to accurately localize them in the world, and leverages the
confusion matrix formulation to construct a probabilistic semantic map in
bird's eye view from semantic point clouds. Experiments from data collected in
an urban environment show that this model is able to predict most road features
and can be extended for automatically incorporating road features into HD maps
with potential future work directions.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:29:09 GMT""},{""version"":""v2"",""created"":""Fri, 11 Sep 2020 17:29:49 GMT""}]","2020-09-14"
"2006.04895","Liu Erfu","Erfu Liu, Jeremiah van Baren, Zhengguang Lu, Takashi Taniguchi, Kenji
  Watanabe, Dmitry Smirnov, Yia-Chung Chang, Chun Hung Lui","Gate-tunable exciton-polaron Rydberg series with strong roton effect",,,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The electronic exciton polaron is a hypothetical many-body quasiparticle
formed by an exciton dressed with a polarized electron-hole cloud in the Fermi
sea (FS). It is predicted to display rich many-body physics and unusual
roton-like dispersion. Exciton polarons were recently evoked to explain the
excitonic spectra of doped monolayer transition metal dichalcogenides (TMDs),
but these studies are limited to the ground state. Excited-state exciton
polarons can exhibit richer many-body physics due to their larger spatial
extent, but detection is challenging due to their inherently weak signals. Here
we observe gate-tunable exciton polarons for the 1s - 3s excitonic Rydberg
series in ultraclean monolayer MoSe$_2$ devices by optical spectroscopy. When
the FS expands, we observe increasingly severe suppression and steep energy
shift from low to high Rydberg states. Their gate-dependent energy shifts go
beyond the trion description but match our exciton-polaron theory. Notably, the
exciton-polaron absorption and emission bands are separated with an energy gap,
which increases from ground to excited state. Such peculiar characteristics are
attributed to the roton-like exciton-polaron dispersion, where energy minima
occur at finite momenta. The roton effect increases from ground to excited
state. Such exciton-polaron Rydberg series with progressively significant
many-body and roton effect shall provide a new platform to explore complex
many-body phenomena.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:29:31 GMT""}]","2020-06-11"
"2006.04896","Cosimo Izzo","Cosimo Izzo and Aldo Lipani and Ramin Okhrati and Francesca Medda","A Baseline for Shapley Values in MLPs: from Missingness to Neutrality",,"ESANN 2021 proceedings, European Symposium on Artificial Neural
  Networks, Computational Intelligence and Machine Learning","10.14428/esann/2021.ES2021-18",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks have gained momentum based on their accuracy, but their
interpretability is often criticised. As a result, they are labelled as black
boxes. In response, several methods have been proposed in the literature to
explain their predictions. Among the explanatory methods, Shapley values is a
feature attribution method favoured for its robust theoretical foundation.
However, the analysis of feature attributions using Shapley values requires
choosing a baseline that represents the concept of missingness. An arbitrary
choice of baseline could negatively impact the explanatory power of the method
and possibly lead to incorrect interpretations. In this paper, we present a
method for choosing a baseline according to a neutrality value: as a parameter
selected by decision-makers, the point at which their choices are determined by
the model predictions being either above or below it. Hence, the proposed
baseline is set based on a parameter that depends on the actual use of the
model. This procedure stands in contrast to how other baselines are set, i.e.
without accounting for how the model is used. We empirically validate our
choice of baseline in the context of binary classification tasks, using two
datasets: a synthetic dataset and a dataset derived from the financial domain.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:29:36 GMT""},{""version"":""v2"",""created"":""Sun, 14 Jun 2020 14:10:33 GMT""},{""version"":""v3"",""created"":""Mon, 9 Aug 2021 20:20:01 GMT""}]","2022-07-05"
"2006.04897","Alejandro Cohen","Alejandro Cohen, Amit Solomon, Ken R. Duffy, and Muriel M\'edard","Noise Recycling",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce Noise Recycling, a method that substantially enhances decoding
performance of orthogonal channels subject to correlated noise without the need
for joint encoding or decoding. The method can be used with any combination of
codes, code-rates and decoding techniques. In the approach, a continuous
realization of noise is estimated from a lead channel by subtracting its
decoded output from its received signal. The estimate is recycled to reduce the
Signal to Noise Ratio (SNR) of an orthogonal channel that is experiencing
correlated noise and so improve the accuracy of its decoding. In this design,
channels only aid each other only through the provision of noise estimates
post-decoding.
  For a system with arbitrary noise correlation between orthogonal channels
experiencing potentially distinct conditions, we introduce an algorithm that
determines a static decoding order that maximizes total effective SNR. We prove
that this solution results in higher effective SNR than independent decoding,
which in turn leads to a larger rate region. We derive upper and lower bounds
on the capacity of any sequential decoding of orthogonal channels with
correlated noise where the encoders are independent and show that those bounds
are almost tight. We numerically compare the upper bound with the capacity of
jointly Gaussian noise channel with joint encoding and decoding, showing that
they match.
  Simulation results illustrate that Noise Recycling can be employed with any
combination of codes and decoders, and that it gives significant Block Error
Rate (BLER) benefits when applying the static predetermined order used to
enhance the rate region. We further establish that an additional BLER
improvement is possible through Dynamic Noise Recycling, where the lead channel
is not pre-determined but is chosen on-the-fly based on which decoder provides
the most confident decoding.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:29:41 GMT""}]","2020-06-11"
"2006.04898","Markus Knoche","Markus Knoche, Istv\'an S\'ar\'andi, Bastian Leibe","Reposing Humans by Warping 3D Features","Accepted at CVPR 2020 Workshop on Human-Centric Image/Video Synthesis","Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR) Workshops, 2020, pp. 1044-1045","10.1109/CVPRW50498.2020.00530",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of reposing an image of a human into any desired novel
pose. This conditional image-generation task requires reasoning about the 3D
structure of the human, including self-occluded body parts. Most prior works
are either based on 2D representations or require fitting and manipulating an
explicit 3D body mesh. Based on the recent success in deep learning-based
volumetric representations, we propose to implicitly learn a dense feature
volume from human images, which lends itself to simple and intuitive
manipulation through explicit geometric warping. Once the latent feature volume
is warped according to the desired pose change, the volume is mapped back to
RGB space by a convolutional decoder. Our state-of-the-art results on the
DeepFashion and the iPER benchmarks indicate that dense volumetric human
representations are worth investigating in more detail.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:31:02 GMT""}]","2023-01-09"
"2006.04899","Joel Williams","Joel Williams, Aditya Rotti, Richard Battye","Constraining cosmic polarization rotation and implications for
  primordial B-modes","17 pages, 2 figures, prepared for submission to JCAP","JCAP09(2020)006","10.1088/1475-7516/2020/09/006",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cosmological Birefringence (CB) is a phenomenon, caused by parity violating
modifications to electrodynamics, whereby the linear polarisation angle of
light changes as photons traverse a vacuum. It is possible to use a number of
different analysis techniques to constrain this effect using Cosmic Microwave
Background (CMB) polarisation observations. We investigate two different
methods of constraining direction dependent birefringence for present and
future CMB experiments including BICEP/Keck, Simons Observatory (SO), and
LiteBIRD . Specifically we compare the constraints placed on anisotropic CB
from a quadratic estimator technique to those derived from estimates of the
$B$-mode power-spectrum for the three different experiments. The constraints
derived from estimates of the $B$-mode power spectrum are found to be
comparable to those derived from quadratic estimator for BICEP/Keck and SO, but
not LiteBIRD due to its larger sky coverage. These forecasted upper bounds for
CB are converted to constraints on primordial magnetic fields and the coupling
between photons and pseudo Nambu-Goldstone bosons. Finally we show that even
with the best constraints on CB, for the respective experiments, the
potentially induced $B$-mode power can act as a significant contaminant in the
prospective measurement of primordial $B$-modes.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:32:28 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jul 2020 15:07:42 GMT""}]","2020-09-04"
"2006.04900","Noam Izenberg","Noam R. Izenberg, Ralph L. McNutt Jr., Kirby D. Runyon, Paul K. Byrne,
  and Alexander Macdonald","Human Assisted Science at Venus: Venus Exploration in the New Human
  Spaceflight Age","A White Paper for the Planetary Science and Astrobiology Decadal
  Survey 2023-2032. 7 pages +cover page, 2 figures +cover image",,,,"astro-ph.IM physics.pop-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Some human mission trajectories to Mars include flybys of Venus. These flybys
provide opportunities to practice deep space human operations, and offer
numerous safe-return-to-Earth options, before committing to longer and
lower-cadence Mars-only flights. Venus flybys, as part of dedicated missions to
Mars, also enable human-in-the-loop scientific study of the second planet. The
time to begin coordinating such Earth-to-Mars-via-Venus missions is now
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:36:07 GMT""}]","2020-06-11"
"2006.04901","Felix Schwenninger","Kelly Bickel, Pamela Gorkin, Anne Greenbaum, Thomas Ransford, Felix
  Schwenninger, Elias Wegert","Crouzeix's Conjecture and related problems","24 pages","Comput. Methods Funct. Theory, 2020","10.1007/s40315-020-00350-9",,"math.FA cs.NA math.CV math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we establish several results related to Crouzeix's conjecture.
We show that the conjecture holds for contractions with eigenvalues that are
sufficiently well-separated. This separation is measured by the so-called
separation constant, which is defined in terms of the pseudohyperbolic metric.
Moreover, we study general properties of related extremal functions and
associated vectors. Throughout, compressions of the shift serve as illustrating
examples which also allow for refined results.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:36:09 GMT""}]","2020-11-11"
"2006.04902","Rico Jonschkowski","Rico Jonschkowski, Austin Stone, Jonathan T. Barron, Ariel Gordon,
  Kurt Konolige, Anelia Angelova","What Matters in Unsupervised Optical Flow","Accepted at ECCV 2020 (Oral). Source code is available at
  https://github.com/google-research/google-research/tree/master/uflow",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We systematically compare and analyze a set of key components in unsupervised
optical flow to identify which photometric loss, occlusion handling, and
smoothness regularization is most effective. Alongside this investigation we
construct a number of novel improvements to unsupervised flow models, such as
cost volume normalization, stopping the gradient at the occlusion mask,
encouraging smoothness before upsampling the flow field, and continual
self-supervision with image resizing. By combining the results of our
investigation with our improved model components, we are able to present a new
unsupervised flow technique that significantly outperforms the previous
unsupervised state-of-the-art and performs on par with supervised FlowNet2 on
the KITTI 2015 dataset, while also being significantly simpler than related
approaches.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:36:26 GMT""},{""version"":""v2"",""created"":""Fri, 14 Aug 2020 13:39:34 GMT""}]","2020-08-17"
"2006.04903","Xuezhi Ma","Xuezhi Ma, Qiushi Liu, Ning Yu, Da Xu, Sanggon Kim, Zebin Liu, Kaili
  Jiang, Bryan M. Wong, Ruoxue Yan and Ming Liu","6 nm super-resolution optical transmission and scattering spectroscopic
  imaging of carbon nanotubes using a nanometer-scale white light source","4 Figures",,"10.1038/s41467-021-27216-5",,"physics.optics cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optical hyperspectral imaging based on absorption and scattering of photons
at the visible and adjacent frequencies denotes one of the most informative and
inclusive characterization methods in material research. Unfortunately,
restricted by the diffraction limit of light, it is unable to resolve the
nanoscale inhomogeneity in light-matter interactions, which is diagnostic of
the local modulation in material structure and properties. Moreover, many
nanomaterials have highly anisotropic optical properties that are outstandingly
appealing yet hard to characterize through conventional optical methods.
Therefore, there has been a pressing demand in the diverse fields including
electronics, photonics, physics, and materials science to extend the optical
hyperspectral imaging into the nanometer length scale. In this work, we report
a super-resolution hyperspectral imaging technique that simultaneously measures
optical absorption and scattering spectra with the illumination from a
tungsten-halogen lamp. We demonstrated sub-5 nm spatial resolution in both
visible and near-infrared wavelengths (415 to 980 nm) for the hyperspectral
imaging of strained single-walled carbon nanotubes (SWNT) and reconstructed
true-color images to reveal the longitudinal and transverse optical
transition-induced light absorption and scattering in the SWNTs. This is the
first time transverse optical absorption in SWNTs were clearly observed
experimentally. The new technique provides rich near-field spectroscopic
information that had made it possible to analyze the spatial modulation of
band-structure along a single SWNT induced through strain engineering.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:39:47 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 16:52:33 GMT""}]","2022-01-05"
"2006.04904","Lingqi Meng","Lingqi Meng, Naoki Masuda","Analysis of node2vec random walks on networks","9 figures, 2 tables","Proceedings of the Royal Society A, 476, 20200447 (2020)","10.1098/rspa.2020.0447",,"physics.soc-ph cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Random walks have been proven to be useful for constructing various
algorithms to gain information on networks. Algorithm node2vec employs biased
random walks to realize embeddings of nodes into low-dimensional spaces, which
can then be used for tasks such as multi-label classification and link
prediction. The performance of the node2vec algorithm in these applications is
considered to depend on properties of random walks that the algorithm uses. In
the present study, we theoretically and numerically analyze random walks used
by the node2vec. Those random walks are second-order Markov chains. We exploit
the mapping of its transition rule to a transition probability matrix among
directed edges to analyze the stationary probability, relaxation times in terms
of the spectral gap of the transition probability matrix, and coalescence time.
In particular, we show that node2vec random walk accelerates diffusion when
walkers are designed to avoid both back-tracking and visiting a neighbor of the
previously visited node but do not avoid them completely.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:40:41 GMT""},{""version"":""v2"",""created"":""Mon, 20 Dec 2021 19:40:04 GMT""}]","2021-12-22"
"2006.04905","Goncalo Oliveira","Goncalo Oliveira","Early epidemic spread, percolation and Covid-19",,,,,"q-bio.PE math.PR q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human to human transmissible infectious diseases spread in a population using
human interactions as its transmission vector. The early stages of such an
outbreak can be modeled by a graph whose edges encode these interactions
between individuals, the vertices. This article attempts to account for the
case when each individual entails in different kinds of interactions which have
therefore different probabilities of transmitting the disease. The majority of
these results can be also stated in the language of percolation theory.
  The main contributions of the article are: (1) Extend to this setting some
results which were previously known in the case when each individual has only
one kind of interactions. (2) Find an explicit formula for the basic
reproduction number $R_0$ which depends only on the probabilities of
transmitting the disease along the different edges and the first two moments of
the degree distributions of the associated graphs. (3) Motivated by the recent
Covid-19 pandemic, we use the framework developed to compute the $R_0$ of a
model disease spreading in populations whose trees and degree distributions are
adjusted to several different countries. In this setting, we shall also compute
the probability that the outbreak will not lead to an epidemic. In all cases we
find such probability to be very low if no interventions are put in place.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:41:20 GMT""}]","2020-06-11"
"2006.04906","Reshmi Roy","Reshmi Roy, Parongama Sen and Purusattam Ray","$A+ A \to \emptyset$ system in one dimension with particle motion
  determined by nearest neighbour distances: results for parallel updates","10 pages, 16 figures","Physica A 569 (2021) 125754","10.1016/j.physa.2021.125754",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A one dimensional $A+A \to \emptyset$ system where the direction of motion of
the particles is determined by the position of the nearest neighours is
studied. The particles move with a probability $0.5 + \epsi$ towards their
nearest neighbours with $-0.5 \leq \epsi \leq 0.5$. This implies a stochastic
motion towards the nearest neighbour or away from it for positive and negative
values of $\epsi$ respectively, with $\epsi = \pm ~0.5$ the two deterministic
limits. The position of the particles are updated in parallel. The macroscopic
as well as tagged particle dynamics are studied which show drastic changes from
the diffusive case $\epsi=0$. The decay of particle density shows departure
from the usual power law behaviour as found in $\epsi =0$, on both sides of
$\epsi =0$ and a scaling regime is obtained for $\epsi > 0$. The $\epsi =0.5$
point is characterized by the presence of dimers, which are isolated pairs of
particles in adjacent sites that are never annihilated. The persistence
probability is also calculated that decays in a stretched exponential manner
for $\epsi < 0$ and switches over to power law behaviour for $\epsi \geq 0$,
with different exponents for $\epsi =0$ and $\epsi > 0$. For the tagged
particle, the probability distribution $\Pi(x,t)$ that it is at position $x$ at
time $t$ shows the existence of a scaling variable $x/t^\nu$ where $\nu = 0.55
\pm 0.05$ for $\epsi > 0$ and varies with $\epsi$ for $\epsi < 0$. Finally, a
comparative analysis for the behaviour of all the relevant quantities for the
system using parallel and asynchronous dynamics (studied recently) shows that
there are significant differences for $\epsi > 0$ while the results are
qualitatively similar for $\epsi < 0$.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:44:28 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 10:56:31 GMT""}]","2021-02-12"
"2006.04907","David Milstead","A. Addazi, K. Anderson, S. Ansell, K. Babu, J. Barrow, D.V. Baxter,
  P.M. Bentley, Z. Berezhiani, R. Bevilacqua, C. Bohm, G. Brooijmans, J.
  Broussard, R. Biondi, B. Dev, C. Crawford, A. Dolgov, K. Dunne, P.
  Fierlinger, M.R. Fitzsimmons, A. Fomin, M. Frost, S. Gardner, A.
  Galindo-Uribarri, E. Golubeva, S. Girmohanta, G.L. Greene, T. Greenshaw, V.
  Gudkov, R. Hall-Wilton, L. Heilbronn, J. Herrero-Garcia, G. Ichikawa T.M.
  Ito, E. Iverson, T. Johansson, L. Joensson, Y-J. Jwa, Y. Kamyshkov, K.
  Kanaki, E. Kearns, M. Kitaguchi, T. Kittelmann, E. Klinkby, L.W. Koerner, B.
  Kopeliovich, A. Kozela, V. Kudryatsev, A. Kupsc, Y. Lee, M. Lindroos, J.
  Makkinje, J.I. Marquez, R. Mohapatra, B. Meirose, T.M. Miller, D. Milstead,
  T. Morishima, G. Muhrer, H.P. Mumm, K. Nagamoto, V.V. Nesvizhevsky, T.
  Nilsson, A. Oskarsson, E. Paryev, R.W. Pattie Jr, S. Penttil, Y. N.
  Pokotilovski, I. Potashnikova, C. Redding, J-M Richard, D. Ries, E. Rinaldi,
  A. Ruggles, B. Rybolt, V. Santoro, U. Sarkar, A. Saunders, G. Senjanovic,
  A.P. Serebrov, H.M. Shimizu, R. Shrock, S. Silverstein, D. Silvermyr, W.M.
  Snow, A. Takibayev, L. Townsend, I. Tkachev, L. Varriano, A. Vainshtein, J.
  de VRies, R. Woracek, Y. Yamagata, A.R. Young, L. Zanini, Z. Zhang, O. Zimmer","New high-sensitivity searches for neutrons converting into antineutrons
  and/or sterile neutrons at the European Spallation Source",,,"10.1088/1361-6471/abf429",,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The violation of Baryon Number, $\mathcal{B}$, is an essential ingredient for
the preferential creation of matter over antimatter needed to account for the
observed baryon asymmetry in the universe. However, such a process has yet to
be experimentally observed. The HIBEAM/NNBAR %experiment program is a proposed
two-stage experiment at the European Spallation Source (ESS) to search for
baryon number violation. The program will include high-sensitivity searches for
processes that violate baryon number by one or two units: free
neutron-antineutron oscillation ($n\rightarrow \bar{n}$) via mixing,
neutron-antineutron oscillation via regeneration from a sterile neutron state
($n\rightarrow [n',\bar{n}'] \rightarrow \bar{n}$), and neutron disappearance
($n\rightarrow n'$); the effective $\Delta \mathcal{B}=0$ process of neutron
regeneration ($n\rightarrow [n',\bar{n}'] \rightarrow n$) is also possible. The
program can be used to discover and characterise mixing in the neutron,
antineutron, and sterile neutron sectors. The experiment addresses topical open
questions such as the origins of baryogenesis, the nature of dark matter, and
is sensitive to scales of new physics substantially in excess of those
available at colliders. A goal of the program is to open a discovery window to
neutron conversion probabilities (sensitivities) by up to three orders of
magnitude compared with previous searches. The opportunity to make such a leap
in sensitivity tests should not be squandered. The experiment pulls together a
diverse international team of physicists from the particle (collider and low
energy) and nuclear physics communities, while also including specialists in
neutronics and magnetics.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:53:33 GMT""}]","2021-07-07"
"2006.04908","Biruniy Fayzullaev","B.A.Fayzullaev and E.Qayumov","Schwinger-Dyson type equations for some QFT models","12 pages, 13 figures",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Schwinger-Dyson equations connecting free and full Green functions and
vertex parts widely were used in QED for finding full Green functions under
different conditions. Undoubtedly, the same approach should leads to derivation
of many useful information about other models of QFT. In this work we present
some technique based on variational equations for effective action to derive
many different Schwinger-Dyson type equations in QFT models such as nonlinear
sigma model and scalar field theory.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:54:17 GMT""}]","2020-06-11"
"2006.04909","Shuo Li","Shuo Li","$\phi$-Thue-Morse sequences and infinite products",,,,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we introduce a new approach to compute infinite products
defined by automatic sequences involving the Thue-Morse sequence. As examples,
for any positive integers $q$ and $r$ such that $0 \leq r \leq q-1$, we find
infinitely many couples of rational functions $R(x)$ and $S(n)$ such that
$$\prod_{n=0}^{\infty}R(n)^{\frac{1+a_n}{2}}S(n)^{\frac{1-a_n}{2}}=2cos(\frac{2r+1}{2q}\pi),$$
where $(a_n)_{n \in \mathbf{N}}$ is the Thue-Morse sequence beginning with
$a_0=1,a_1= -1$.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:57:26 GMT""}]","2020-06-11"
"2006.04910","Andrew Stirn","Andrew Stirn and David A. Knowles","Variational Variance: Simple, Reliable, Calibrated Heteroscedastic Noise
  Variance Parameterization","17 pages, 6 figures, 10 tables",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Brittle optimization has been observed to adversely impact model likelihoods
for regression and VAEs when simultaneously fitting neural network mappings
from a (random) variable onto the mean and variance of a dependent Gaussian
variable. Previous works have bolstered optimization and improved likelihoods,
but fail other basic posterior predictive checks (PPCs). Under the PPC
framework, we propose critiques to test predictive mean and variance
calibration and the predictive distribution's ability to generate sensible
data. We find that our attractively simple solution, to treat heteroscedastic
variance variationally, sufficiently regularizes variance to pass these PPCs.
We consider a diverse gamut of existing and novel priors and find our methods
preserve or outperform existing model likelihoods while significantly improving
parameter calibration and sample quality for regression and VAEs.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:58:35 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 12:29:21 GMT""},{""version"":""v3"",""created"":""Fri, 30 Oct 2020 14:50:33 GMT""}]","2020-11-02"
"2006.04911","Ali Ghanbari","Ali Ghanbari","ObjSim: Lightweight Automatic Patch Prioritization via Object Similarity","Proceedings of the 29th ACM SIGSOFT International Symposium on
  Software Testing and Analysis (ISSTA '20), July 18--22, 2020, Virtual Event,
  USA",,"10.1145/3395363.3404362",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of test case based automatic program repair (APR), patches
that pass all the test cases but fail to fix the bug are called overfitted
patches. Currently, patches generated by APR tools get inspected manually by
the users to find and adopt genuine fixes. Being a laborious activity hindering
widespread adoption of APR, automatic identification of overfitted patches has
lately been the topic of active research. This paper presents engineering
details of ObjSim: a fully automatic, lightweight similarity-based patch
prioritization tool for JVM-based languages. The tool works by comparing the
system state at the exit point(s) of patched method before and after patching
and prioritizing patches that result in state that is more similar to that of
original, unpatched version on passing tests while less similar on failing
ones. Our experiments with patches generated by the recent APR tool PraPR for
fixable bugs from Defects4J v1.4.0 show that ObjSim prioritizes 16.67% more
genuine fixes in top-1 place. A demo video of the tool is located at
https://bit.ly/2K8gnYV.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 19:58:58 GMT""}]","2020-06-11"
"2006.04912","V\'ictor H. Purrello","V\'ictor H. Purrello, Jos\'e L. Iguain, Vivien Lecomte and Alejandro
  B. Kolton","Hysteretic depinning of a particle in a periodic potential: Phase
  diagram and criticality","13 pages, 13 figures, published version","Phys. Rev. E 102, 022131 (2020)","10.1103/PhysRevE.102.022131",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a massive particle driven with a constant force in a periodic
potential and subjected to a dissipative friction. As a function of the drive
and damping, the phase diagram of this paradigmatic model is well known to
present a pinned, a sliding, and a bistable regime separated by three distinct
bifurcation lines. In physical terms, the average velocity $v$ of the particle
is nonzero only if either (i) the driving force is large enough to remove any
stable point, forcing the particle to slide, or (ii) there are local minima but
the damping is small enough, below a critical damping, for the inertia to allow
the particle to cross barriers and follow a limit cycle; this regime is
bistable and whether $v > 0$ or $v = 0$ depends on the initial state. In this
paper, we focus on the asymptotes of the critical line separating the bistable
and the pinned regimes. First, we study its behavior near the ""triple point""
where the pinned, the bistable, and the sliding dynamical regimes meet. Just
below the critical damping we uncover a critical regime, where the line
approaches the triple point following a power-law behavior. We show that its
exponent is controlled by the normal form of the tilted potential close to its
critical force. Second, in the opposite regime of very low damping, we revisit
existing results by providing a simple method to determine analytically the
exact behavior of the line in the case of a generic potential. The analytical
estimates, accurately confirmed numerically, are obtained by exploiting exact
soliton solutions describing the orbit in a modified tilted potential which can
be mapped to the original tilted washboard potential. Our methods and results
are particularly useful for an accurate description of underdamped nonuniform
oscillators driven near their triple point.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:02:03 GMT""},{""version"":""v2"",""created"":""Tue, 25 Aug 2020 20:54:16 GMT""}]","2020-08-27"
"2006.04913","Jack Raymond","Jack Raymond and Ndiam\'e Ndiaye and Gautam Rayaprolu and Andrew King","Improving performance of logical qubits by parameter tuning and topology
  compensation","11 pages, 15 figures, accepted QCE20","J. Raymond, N. Ndiaye, G. Rayaprolu and A. D. King, ""Improving
  performance of logical qubits by parameter tuning and topology compensation,""
  2020 IEEE International Conference on Quantum Computing and Engineering
  (QCE), 2020, pp. 295-305","10.1109/QCE49297.2020.00044",,"quant-ph cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimization or sampling of arbitrary pairwise Ising models, in a quantum
annealing protocol of constrained interaction topology, can be enabled by a
minor-embedding procedure. The logical problem of interest is transformed to a
physical (device programmable) problem, where one binary variable is
represented by a logical qubit consisting of multiple physical qubits. In this
paper we discuss tuning of this transformation for the cases of clique,
biclique, and cubic lattice problems on the D-Wave 2000Q quantum computer. We
demonstrate parameter tuning protocols in spin glasses and channel
communication problems, focusing on anneal duration, chain strength, and
mapping from the result on physical qubits back to the logical space.
Inhomogeneities in effective coupling strength arising from minor-embedding are
shown to be mitigated by an efficient reweighting of programmed couplings,
accounting for logical qubit topology.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:03:34 GMT""},{""version"":""v2"",""created"":""Thu, 6 Aug 2020 23:47:10 GMT""}]","2021-05-20"
"2006.04914","Kimball Martin","Kimball Martin","Exact double averages of twisted L-values","33 pages; minor revisions; to appear in Math Z",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider central $L$-values of even weight elliptic or Hilbert modular forms
$f$ twisted by ideal class characters $\chi$ of an imaginary quadratic
extension $K$. Fixing $\chi$, and assuming $K$ is inert at each prime dividing
the level, one knows simple exact formulas for averages over newforms $f$ of
squarefree levels satisfying a parity condition on the number of prime factors.
These averages stabilize when the level is large with respect to $K$ (the
""stable range"").
  In weight 2, we obtain exact formulas for a simultaneous average over both
$f$ and $\chi$. We allow for non-squarefree levels with any number of prime
factors, and ramification or splitting of $K$ above the level. Under elementary
conditions on the level, these double averages are ""stable"" in all ranges. Two
consequences are generalizations of the aforementioned stable (single) averages
and effective results on nonvanishing of central $L$-values.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:09:20 GMT""},{""version"":""v2"",""created"":""Tue, 2 Aug 2022 07:57:56 GMT""}]","2022-08-03"
"2006.04915","Alejo Costa","A. Costa and M. B. Sturla","Vortex lattice in two-dimensional chiral XY ferromagnets and the inverse
  Berezinskii-Kosterlitz-Thouless transition","6 pages, 5 figures",,"10.1103/PhysRevB.102.100406",,"cond-mat.str-el cond-mat.stat-mech hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this Letter we will show that, in the presence of a properly modulated
Dzyaloshinskii-Moriya (DM) interaction, a $U(1)$ vortex-antivortex lattice
appears at low temperatures for a wide range of the DM interaction. Even more,
in the region dominated by the exchange interaction, a standard BKT transition
occurs. In the opposite regime, the one dominated by the DM interaction, a kind
of inverse BKT transition (iBKT) takes place. As temperature rises, the
vortex-antivortex lattice starts melting by annihilation of pairs of
vortex-antivortex, in a sort of ""inverse"" BKT transition.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:15:43 GMT""},{""version"":""v2"",""created"":""Wed, 23 Dec 2020 15:12:05 GMT""}]","2020-12-24"
"2006.04916","Bernardo Gonzalez Torres","Bernardo A. Gonzalez-Torres","An Algorithmic Introduction to Clustering","26 pages, 14 figures",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  This paper tries to present a more unified view of clustering, by identifying
the relationships between five different clustering algorithms. Some of the
results are not new, but they are presented in a cleaner, simpler and more
concise way. To the best of my knowledge, the interpretation of DBSCAN as a
climbing procedure, which introduces a theoretical connection between DBSCAN
and Mean shift, is a novel result.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:21:34 GMT""}]","2020-06-11"
"2006.04917","Finn Lindgren","Finn Lindgren, Haakon Bakka, David Bolin, Elias Krainski, H{\aa}vard
  Rue","A diffusion-based spatio-temporal extension of Gaussian Mat\'ern fields","40 pages, 10 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gaussian random fields with Mat\'ern covariance functions are popular models
in spatial statistics and machine learning. In this work, we develop a
spatio-temporal extension of the Gaussian Mat\'ern fields formulated as
solutions to a stochastic partial differential equation. The spatially
stationary subset of the models have marginal spatial Mat\'ern covariances, and
the model also extends to Whittle-Mat\'ern fields on curved manifolds, and to
more general non-stationary fields. In addition to the parameters of the
spatial dependence (variance, smoothness, and practical correlation range) it
additionally has parameters controlling the practical correlation range in
time, the smoothness in time, and the type of non-separability of the
spatio-temporal covariance. Through the separability parameter, the model also
allows for separable covariance functions. We provide a sparse representation
based on a finite element approximation, that is well suited for statistical
inference and which is implemented in the R-INLA software. The flexibility of
the model is illustrated in an application to spatio-temporal modeling of
global temperature data.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:21:53 GMT""},{""version"":""v2"",""created"":""Mon, 17 Oct 2022 02:54:06 GMT""},{""version"":""v3"",""created"":""Wed, 5 Apr 2023 15:56:54 GMT""}]","2023-04-06"
"2006.04918","Vladimir Lipunov","V. M. Lipunov, V. G. Kornilov, K. K. Zhirkov, E. S. Gorbovskoy, N.M.
  Budnev, D.A.H. Buckley, R. Rebolo, M. Serra-Ricart, R. Podesta, N. Tyurina,
  O. Gress, Yu. Sergienko, V. Yurkov, A. Gabovich, P. Balanutsa, I. Gorbunov,
  D. Vlasenko, F. Balakin, V. Topolev, A. Pozdnyakov, A. Kuznetsov, V.
  Vladimirov, A. Chasovnikov, D. Kuvshinov, V. Grinshpun, E. Minkina, V. B.
  Petkov, S. I. Svertilov, C. Lopez, F. Podesta, H. Levato, A. Tlatov, B. van
  Soelen, S. Razzaque, M. B\""ottcher","Optical Observations Reveal Strong Evidence for High Energy Neutrino
  Progenitor","17 pages, 3 figures, 1 Table accepted to The Astrophysical Journal
  Letters","The Astrophysical Journal Letters, 2020","10.3847/2041-8213/ab96ba",,"astro-ph.HE hep-ex physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the earliest astronomical observation of a high energy neutrino
error box in which its variability was discovered after high-energy neutrinos
detection. The one robotic telescope of the MASTER global international network
(Lipunov et al. 2010) automatically imaged the error box of the very
high-energy neutrino event IceCube-170922A. Observations were carried out in
minute after the IceCube-170922A neutrino event was detected by the IceCube
observatory at the South Pole. MASTER found the blazar TXS 0506+056 to be in
the off-state after one minute and then switched to the on-state no later than
two hours after the event. The effect is observed at a 50-sigma significance
level. Also we present own unique 16-years light curve of blazar TXS 0506+056
(518 data set).
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:29:19 GMT""}]","2020-06-24"
"2006.04919","Fabio Giavazzi","Fabio Giavazzi and Veronique Trappe and Roberto Cerbino","Multiple dynamic regimes in a coarsening foam","J. Phys.: Condens. Matter (2020)",,"10.1088/1361-648X/abb684",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use differential dynamic microscopy and particle tracking to determine the
dynamical characteristics of a coarsening foam in reciprocal and direct space.
At all wavevectors $q$ investigated, the intermediate scattering function
exhibits a compressed exponential decay. However, the access to unprecedentedly
small $q$s highlights the existence of two distinct regimes for the
$q$-dependence of the foam relaxation rate $\Gamma (q)$. At any given foam age,
$\Gamma (q)\sim q$ at high $q$, consistent with directionally-persistent and
intermittent bubble displacements. At low $q$, we find $\Gamma (q) \sim
q^{1.6}$. We show that such change in $q$-dependence of $\Gamma (q)$ relates to
a bubble displacement distribution exhibiting a cut-off length of the order of
the bubble diameter. Investigations of the $q$-dependence of $\Gamma (q)$ at
different foam ages reveal that foam dynamics is not only governed by the
bubble length scale, but also by the strain rate imposed by the bubble growth;
normalizing $\Gamma (q)$ by this strain rate and multiplying $q$ with the
age-dependent bubble radius leads to a collapse of all data sets onto a unique
master-curve.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:34:03 GMT""}]","2020-09-25"
"2006.04920","Hyunsu Cho","Avinash Barnwal, Hyunsu Cho, Toby Dylan Hocking","Survival regression with accelerated failure time model in XGBoost",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Survival regression is used to estimate the relation between time-to-event
and feature variables, and is important in application domains such as
medicine, marketing, risk management and sales management. Nonlinear tree based
machine learning algorithms as implemented in libraries such as XGBoost,
scikit-learn, LightGBM, and CatBoost are often more accurate in practice than
linear models. However, existing state-of-the-art implementations of tree-based
models have offered limited support for survival regression. In this work, we
implement loss functions for learning accelerated failure time (AFT) models in
XGBoost, to increase the support for survival modeling for different kinds of
label censoring. We demonstrate with real and simulated experiments the
effectiveness of AFT in XGBoost with respect to a number of baselines, in two
respects: generalization performance and training speed. Furthermore, we take
advantage of the support for NVIDIA GPUs in XGBoost to achieve substantial
speedup over multi-core CPUs. To our knowledge, our work is the first
implementation of AFT that utilizes the processing power of NVIDIA GPUs.
Starting from the 1.2.0 release, the XGBoost package natively supports the AFT
model. The addition of AFT in XGBoost has had significant impact in the open
source community, and a few statistics packages now utilize the XGBoost AFT
model.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:34:20 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 20:04:08 GMT""},{""version"":""v3"",""created"":""Sat, 21 Aug 2021 05:14:02 GMT""}]","2021-08-24"
"2006.04921","Giorgio Viavattene","G. Viavattene, D. Calchetti, F. Berrilli, D. Del Moro, L. Giovannelli,
  E. Pietropaolo, M. Oliviero, L. Terranegra","Optical design of the Tor vergata Synoptic Solar Telescope (TSST)","10 pages, 5 figures",,,,"astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Synoptic full-disk solar telescope are fundamental instruments for present
and future Solar Physics and Space Weather. They are typically used to study
and monitor the solar activity by using high temporal cadence observations at
different wavelength. The TSST (Tor vergata Synoptic Solar Telescope) is a new
synoptic telescope composed of two spectral channels: an H$\alpha$ (656.3 nm)
telescope and a Magneto Optical Filter (MOF)-based telescope in the Potassium
(KI D1) absorption spectral line at 769.9 nm. H$\alpha$ observations are
fundamental for the identification of flaring regions. The MOF-based telescope
will produce line of sight magnetograms and dopplergrams of the solar
photosphere, which are respectively used to study the magnetic field's geometry
in active regions and dynamics of the solar atmosphere. In this work, we
present an overview on the TSST and the optical design and characteristics of
the MOF-based telescope, whose optical scheme is a double-Keplerian 80mm
refractor with an aberration-free imaging lens.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:34:58 GMT""}]","2020-06-11"
"2006.04922","Abbas Askar","Abbas Askar, Melvyn B. Davies, Ross P. Church","Formation of super-massive black holes in galactic nuclei I: delivering
  seed intermediate-mass black holes in massive stellar clusters","19 pages, 17 figures, 6 tables, accepted for publication in MNRAS",,"10.1093/mnras/stab113",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supermassive black holes (SMBHs) are found in most galactic nuclei. A
significant fraction of these nuclei also contain a nuclear stellar cluster
(NSC) surrounding the SMBH. In this paper, we consider the idea that the NSC
forms first, from the merger of several stellar clusters that may contain
intermediate-mass black holes (IMBHs). These IMBHs can subsequently grow in the
NSC and form an SMBH. We carry out $N$-body simulations of the simultaneous
merger of three stellar clusters to form an NSC, and investigate the outcome of
simulated runs containing zero, one, two and three IMBHs. We find that IMBHs
can efficiently sink to the centre of the merged cluster. If multiple merging
clusters contain an IMBH, we find that an IMBH binary is likely to form and
subsequently merge by gravitational wave emission. We show that these mergers
are catalyzed by dynamical interactions with surrounding stars, which
systematically harden the binary and increase its orbital eccentricity. The
seed SMBH will be ejected from the NSC by the recoil kick produced when two
IMBHs merge, if their mass ratio $q\gtrsim 0.15$. If the seed is ejected then
no SMBH will form in the NSC. This is a natural pathway to explain those
galactic nuclei that contain an NSC but apparently lack an SMBH, such as M33.
However, if an IMBH is retained then it can seed the growth of an SMBH through
gas accretion and tidal disruption of stars.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:39:29 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jan 2021 17:52:07 GMT""}]","2021-01-27"
"2006.04923","Kevin Luhman","K. L. Luhman, C. J. Hapich","New Candidates for Planetary-mass Brown Dwarfs in IC 348","Astronomical Journal, in press",,"10.3847/1538-3881/ab96bb",,"astro-ph.SR astro-ph.EP astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have used infrared images obtained with the Wide Field Camera 3 on board
the Hubble Space Telescope to search for planetary-mass brown dwarfs in the
star-forming cluster IC 348. In those images, we have identified 12 objects
that have colors indicative of spectral types later than M8, corresponding to
masses of <=30 Jupiter masses at the age of IC 348. The four brightest
candidates have been observed with spectroscopy, all of which are confirmed to
have late types. Two of those candidates appear to be young, and thus are
likely members of the cluster, while the ages and membership of the other two
candidates are uncertain. One of the former candidates is the faintest known
member of IC 348 in extinction-corrected K_s and is expected to have a mass of
4-5 Jupiter masses based on evolutionary models and an assumed age of 3 Myr.
Four of the remaining eight candidates have ground-based photometry that
further supports their candidacy as brown dwarfs, some of which are fainter
(and potentially less massive) than the known members.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:41:03 GMT""}]","2020-07-22"
"2006.04924","Muzammal Naseer","Muzammal Naseer, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Fatih
  Porikli","A Self-supervised Approach for Adversarial Robustness","CVPR-2020 (Oral). Code this http
  https://github.com/Muzammal-Naseer/NRP}",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial examples can cause catastrophic mistakes in Deep Neural Network
(DNNs) based vision systems e.g., for classification, segmentation and object
detection. The vulnerability of DNNs against such attacks can prove a major
roadblock towards their real-world deployment. Transferability of adversarial
examples demand generalizable defenses that can provide cross-task protection.
Adversarial training that enhances robustness by modifying target model's
parameters lacks such generalizability. On the other hand, different input
processing based defenses fall short in the face of continuously evolving
attacks. In this paper, we take the first step to combine the benefits of both
approaches and propose a self-supervised adversarial training mechanism in the
input space. By design, our defense is a generalizable approach and provides
significant robustness against the \textbf{unseen} adversarial attacks (\eg by
reducing the success rate of translation-invariant \textbf{ensemble} attack
from 82.6\% to 31.9\% in comparison to previous state-of-the-art). It can be
deployed as a plug-and-play solution to protect a variety of vision systems, as
we demonstrate for the case of classification, segmentation and detection. Code
is available at: {\small\url{https://github.com/Muzammal-Naseer/NRP}}.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:42:39 GMT""}]","2020-06-11"
"2006.04925","Oliver Roth","J\""urgen Grahl, Daniela Kraus, Oliver Roth","Blow--up Solutions of Liouville's Equation and Quasi--Normality",,,,,"math.CV math.AP math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the family $\mathcal{F}_C(D)$ of all meromorphic functions $f$
on a domain $D\subseteq \mathbb{C}$ with the property that the spherical area
of the image domain $f(D)$ is uniformly bounded by $C \pi$ is quasi--normal of
order $\le C$. We also discuss the close relations between this result and the
well--known work of Br\'ezis and Merle on blow--up solutions of Liouville's
equation. These results are completely in the spirit of Gromov's compactness
theorem, as pointed out at the end of the paper.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:43:09 GMT""}]","2020-06-11"
"2006.04926","Jiusi Zhou","Jiusi Zhou, Shuping Dang, Basem Shihada, Mohamed-Slim Alouini","Energy-Efficient Fixed-Gain AF Relay Assisted OFDM with Index Modulation",,,"10.1109/LWC.2020.2995365",,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To broaden the application scenario and reduce energy consumption, we propose
an energy-efficient fixed-gain (FG) amplify-and-forward (AF) relay assisted
orthogonal frequency-division multiplexing with index modulation (OFDM-IM)
scheme in this letter. The proposed system needs neither instantaneous channel
state information (CSI) nor complicated processing at the relay node. It
operates based on the power allocation scheme that minimizes the sum of
transmit power at both source and relay node, given an outage probability
constraint. Through a series of problem transformation and simplification, we
convert the original power allocation problem to its relaxed version and solve
it using convex programming techniques. To reveal the computing efficiency of
the proposed power allocation scheme, we analyze its computational complexity.
Numerical simulations substantiate that the proposed optimization scheme has a
neglectable loss compared with the brute force search, but the computational
complexity can be considerably reduced.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:45:25 GMT""}]","2020-06-11"
"2006.04927","Joseph Kramer-Miller","Joe Kramer-Miller","Some unlikely intersections between the Torelli locus and Newton strata
  in $\mathcal{A}_g$",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $p$ be an odd prime. What are the possible Newton polygons for a curve in
characteristic $p$? Equivalently, which Newton strata intersect the Torelli
locus in $\mathcal{A}_g$? In this note, we study the Newton polygons of certain
curves with $\mathbb{Z}/p\mathbb{Z}$-actions. Many of these curves exhibit
unlikely intersections between the Torelli locus and the Newton stratification
in $\mathcal{A}_g$. Here is one example of particular interest: fix a genus
$g$. We show that for any $k$ with $\frac{2g}{3}-\frac{2p(p-1)}{3}\geq
2k(p-1)$, there exists a curve of genus $g$ whose Newton polygon has slopes
$\{0,1\}^{g-k(p-1)} \sqcup \{\frac{1}{2}\}^{2k(p-1)}$. This provides evidence
for Oort's conjecture that the amalgamation of the Newton polygons of two
curves is again the Newton polygon of a curve. We also construct families of
curves $\{C_g\}_{g \geq 1}$, where $C_g$ is a curve of genus $g$, whose Newton
polygons have interesting asymptotic properties. For example, we construct a
family of curves whose Newton polygons are asymptotically bounded below by the
graph $y=\frac{x^2}{4g}$. The proof uses a Newton-over-Hodge result for
$\mathbb{Z}/p\mathbb{Z}$-covers of curves due to the author, in addition to
recent work of Booher-Pries on the realization of this Hodge bound.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:47:45 GMT""}]","2020-06-11"
"2006.04928","George Sterpu","George Sterpu, Christian Saam, Naomi Harte","Learning to Count Words in Fluent Speech enables Online Speech
  Recognition","Accepted at the 8th IEEE Spoken Language Technology Workshop (SLT
  2021)",,,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequence to Sequence models, in particular the Transformer, achieve state of
the art results in Automatic Speech Recognition. Practical usage is however
limited to cases where full utterance latency is acceptable. In this work we
introduce Taris, a Transformer-based online speech recognition system aided by
an auxiliary task of incremental word counting. We use the cumulative word sum
to dynamically segment speech and enable its eager decoding into words.
Experiments performed on the LRS2, LibriSpeech, and Aishell-1 datasets of
English and Mandarin speech show that the online system performs comparable
with the offline one when having a dynamic algorithmic delay of 5 segments.
Furthermore, we show that the estimated segment length distribution resembles
the word length distribution obtained with forced alignment, although our
system does not require an exact segment-to-word equivalence. Taris introduces
a negligible overhead compared to a standard Transformer, while the local
relationship modelling between inputs and outputs grants invariance to sequence
length by design.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:49:39 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 10:37:03 GMT""},{""version"":""v3"",""created"":""Tue, 24 Nov 2020 13:59:17 GMT""}]","2020-11-25"
"2006.04929","Naveen Kumar","Ujjwal Sinha, and Naveen Kumar","Pair-beam propagation in a magnetised plasma for modelling the polarized
  radiation emission from gamma-ray bursts in laboratory astrophysics
  experiments",,"Phys. Rev. E, 101, 063204 (2020)","10.1103/PhysRevE.101.063204",,"physics.plasm-ph astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The propagation of a relativistic electron-positron beam in a magnetized
electron-ion plasma is studied, focusing on the polarization of the radiation
generated in this case. Special emphasis is laid on investigating the
polarization of the generated radiation for a range of beam-plasma parameters,
transverse and longitudinal beam sizes, and the external magnetic fields. Our
results not only help in understanding the high degrees of circular
polarization observed in gamma-rays bursts but they also help in distinguishing
the different modes associated with the filamentation dynamics of the pair-beam
in laboratory astrophysics experiments.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:51:04 GMT""}]","2020-06-11"
"2006.04930","Aleksandra Grokhovskaya","Aleksandra Grokhovskaya, Sergei N. Dodonov, T. A. Movsessian","Large Scale Distribution of Galaxies in The Field HS 47.5-22. II.
  Observational Data Analysis","Accepted for publication in Astrophysical Bulletin, 16 pages, 14
  figures, 2 tabels",,"10.1134/S1990341320030062",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The results of the study of the large-scale distribution of galaxies up to z
~0.8 in the field HS 47.5-22 on the basis of photometric data of the 1-meter
Schmidt telescope of the BAO NAS Armenia are presented. The full sample
contains 28,398 galaxies. Candidates for large-scale structures were determined
using two independent methods for reconstructing density contrast maps in 57
narrow slices of the three-dimensional distribution of galaxies: adaptive
aperture algorithm with smoothing and 2D Voronoi tessellation. We have
identified more than 250 statistically significant overdense structures. The
obtained results demonstrate a wide range of overdense structures over the full
range of redshifts up to z ~0.8.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:51:56 GMT""}]","2020-10-28"
"2006.04931","Jinfeng Liu","Xunyuan Yin, Song Bo, Jinfeng Liu, Biao Huang","A consensus-based approach for parameter and state estimation of
  agro-hydrological system",,,"10.1002/aic.17096",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The development of advanced closed-loop irrigation systems requires accurate
soil moisture information. In this work, we address the problem of soil
moisture estimation for the agro-hydrological systems in a robust and reliable
manner. A nonlinear state-space model is established based on the
discretization of the Richards equation to describe the dynamics of
agro-hydrological systems. We consider that model parameters are unknown and
need to be estimated together with the states simultaneously. We propose a
consensus-based estimation mechanism, which comprises two main parts: 1) a
distributed extended Kalman filtering algorithm used to estimate several model
parameters; and 2) a distributed moving horizon estimation algorithm used to
estimate the state variables and one remaining model parameter. Extensive
simulations are conducted, and comparisons with existing methods are made to
demonstrate the effectiveness and superiority of the proposed approach. In
particular, the proposed approach can provide accurate soil moisture estimate
even when poor initial guesses of the parameters and the states are used, which
can be challenging to be handled using existing algorithms.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:54:21 GMT""}]","2021-02-16"
"2006.04932","Sergii Torba M.","Nelson Guti\'errez Jim\'enez and Sergii M. Torba","Analytic approximation of transmutation operators for one-dimensional
  stationary Dirac operators and applications to solution of initial value and
  spectral problems","32 pages, 2 figures. Some typos corrected and small changes to the
  text",,,,"math.CA cs.NA math-ph math.AP math.MP math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A method for approximate solution of initial value and spectral problems for
one dimensional Dirac equation based on an analytic approximation of the
transmutation operator is presented. In fact the problem of numerical
approximation of solutions is reduced to approximation of the potential matrix
by a finite linear combination of matrix valued functions related to
generalized formal powers introduced in arXiv:1904.03361. Convergence rate
estimates in terms of smoothness of the potential are proved. The method allows
one to compute both lower and higher eigendata with an extreme accuracy.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:55:10 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jan 2021 21:32:47 GMT""}]","2021-01-29"
"2006.04933","Neil Simonetti","Robert D. Carr, Neil Simonetti","A New Integer Programming Formulation of the Graphical Traveling
  Salesman Problem","19 pages, only one figure from an external image",,,,"cs.DM cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the Traveling Salesman Problem (TSP), a salesman wants to visit a set of
cities and return home. There is a cost $c_{ij}$ of traveling from city $i$ to
city $j$, which is the same in either direction for the Symmetric TSP. The
objective is to visit each city exactly once, minimizing total travel costs. In
the Graphical TSP, a city may be visited more than once, which may be necessary
on a sparse graph. We present a new integer programming formulation for the
Graphical TSP requiring only two classes of constraints that are either
polynomial in number or polynomially separable, while addressing an open
question proposed by Denis Naddef.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:58:23 GMT""}]","2020-06-11"
"2006.04934","Will Sawin","Will Sawin","Identifying measures on non-abelian groups and modules by their moments
  via reduction to a local problem","21 pages",,,,"math.NT math.GR math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Work on generalizations of the Cohen-Lenstra and Cohen-Martinet heuristics
has drawn attention to probability measures on the space of isomorphism classes
of profinite groups. As is common in probability theory, it would be desirable
to know that these measures are determined by their moments, which in this
context are the expected number of surjections to a fixed finite group. We show
a wide class of measures, including those appearing in a recent paper of Liu,
Wood, and Zurieck-Brown, have this property. The method is to work ""locally""
with groups that are extensions of a fixed group by a product of finite simple
groups. This eventually reduces the problem to the case of powers of a fixed
finite simple group, which can be handled by a simple explicit calculation. We
can also prove a similar theorem for random modules over an algebra.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:04:08 GMT""},{""version"":""v2"",""created"":""Thu, 15 Dec 2022 09:15:34 GMT""},{""version"":""v3"",""created"":""Fri, 30 Dec 2022 00:41:47 GMT""}]","2023-01-02"
"2006.04935","Maryna Karpusha","Maryna Karpusha, Sunghee Yun, Istvan Fehervari","Calibrated neighborhood aware confidence measure for deep metric
  learning",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep metric learning has gained promising improvement in recent years
following the success of deep learning. It has been successfully applied to
problems in few-shot learning, image retrieval, and open-set classifications.
However, measuring the confidence of a deep metric learning model and
identifying unreliable predictions is still an open challenge. This paper
focuses on defining a calibrated and interpretable confidence metric that
closely reflects its classification accuracy. While performing similarity
comparison directly in the latent space using the learned distance metric, our
approach approximates the distribution of data points for each class using a
Gaussian kernel smoothing function. The post-processing calibration algorithm
with proposed confidence metric on the held-out validation dataset improves
generalization and robustness of state-of-the-art deep metric learning models
while provides an interpretable estimation of the confidence. Extensive tests
on four popular benchmark datasets (Caltech-UCSD Birds, Stanford Online
Product, Stanford Car-196, and In-shop Clothes Retrieval) show consistent
improvements even at the presence of distribution shifts in test data related
to additional noise or adversarial examples.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:05:38 GMT""}]","2020-06-11"
"2006.04936","Joseph Kramer-Miller","Joe Kramer-Miller","$p$-adic estimates of abelian Artin $L$-functions on curves","Improved exposition and some simplified proofs",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this article is to prove a ""Newton over Hodge"" result for
finite characters on curves. Let $X$ be a smooth proper curve over a finite
field $\mathbb{F}_q$ of characteristic $p\geq 3$ and let $V \subset X$ be an
affine curve. Consider a nontrivial finite character $\rho:\pi_1^{et}(V) \to
\mathbb{C}^\times$. In this article, we prove a lower bound on the Newton
polygon of the $L$-function $L(\rho,s)$. The estimate depends on monodromy
invariants of $\rho$: the Swan conductor and the local exponents. Under certain
nondegeneracy assumptions this lower bound agrees with the irregular Hodge
filtration introduced by Deligne. In particular, our result further
demonstrates Deligne's prediction that the irregular Hodge filtration would
force $p$-adic bounds on $L$-functions. As a corollary, we obtain estimates on
the Newton polygon of a curve with a cyclic action in terms of monodromy
invariants.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:08:11 GMT""},{""version"":""v2"",""created"":""Sat, 10 Jul 2021 22:24:26 GMT""}]","2021-07-13"
"2006.04937","Matteo Sesia","Charmaine Chia, Matteo Sesia, Chi-Sing Ho, Stefanie S. Jeffrey,
  Jennifer Dionne, Emmanuel J. Cand\`es, Roger T. Howe","Interpretable Classification of Bacterial Raman Spectra with Knockoff
  Wavelets","9 pages, 6 figures, 4 tables",,"10.1109/JBHI.2021.3094873",,"eess.SP stat.AP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks and other sophisticated machine learning models are
widely applied to biomedical signal data because they can detect complex
patterns and compute accurate predictions. However, the difficulty of
interpreting such models is a limitation, especially for applications involving
high-stakes decision, including the identification of bacterial infections. In
this paper, we consider fast Raman spectroscopy data and demonstrate that a
logistic regression model with carefully selected features achieves accuracy
comparable to that of neural networks, while being much simpler and more
transparent. Our analysis leverages wavelet features with intuitive chemical
interpretations, and performs controlled variable selection with knockoffs to
ensure the predictors are relevant and non-redundant. Although we focus on a
particular data set, the proposed approach is broadly applicable to other types
of signal data for which interpretability may be important.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:09:50 GMT""},{""version"":""v2"",""created"":""Thu, 3 Sep 2020 22:08:50 GMT""},{""version"":""v3"",""created"":""Sun, 2 May 2021 02:22:54 GMT""}]","2021-07-12"
"2006.04938","Swagat Kumar","Swagat Kumar","Balancing a CartPole System with Reinforcement Learning -- A Tutorial","8 pages, 8 figures, 15 code listings and one table",,,,"cs.RO cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we provide the details of implementing various reinforcement
learning (RL) algorithms for controlling a Cart-Pole system. In particular, we
describe various RL concepts such as Q-learning, Deep Q Networks (DQN), Double
DQN, Dueling networks, (prioritized) experience replay and show their effect on
the learning performance. In the process, the readers will be introduced to
OpenAI/Gym and Keras utilities used for implementing the above concepts. It is
observed that DQN with PER provides best performance among all other
architectures being able to solve the problem within 150 episodes.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:14:43 GMT""},{""version"":""v2"",""created"":""Fri, 12 Jun 2020 16:27:27 GMT""}]","2020-06-15"
"2006.04942","Ralf Herbrich","Ralf Herbrich and Rajeev Rastogi and Roland Vollgraf","CRISP: A Probabilistic Model for Individual-Level COVID-19 Infection
  Risk Estimation Based on Contact Data",,,,,"cs.SI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present CRISP (COVID-19 Risk Score Prediction), a probabilistic graphical
model for COVID-19 infection spread through a population based on the SEIR
model where we assume access to (1) mutual contacts between pairs of
individuals across time across various channels (e.g., Bluetooth contact
traces), as well as (2) test outcomes at given times for infection, exposure
and immunity tests. Our micro-level model keeps track of the infection state
for each individual at every point in time, ranging from susceptible, exposed,
infectious to recovered. We develop both a Monte Carlo EM as well as a message
passing algorithm to infer contact-channel specific infection transmission
probabilities. Our Monte Carlo algorithm uses Gibbs sampling to draw samples of
the latent infection status of each individual over the entire time period of
analysis, given the latent infection status of all contacts and test outcome
data. Experimental results with simulated data demonstrate our CRISP model can
be parametrized by the reproduction factor $R_0$ and exhibits population-level
infectiousness and recovery time series similar to those of the classical SEIR
model. However, due to the individual contact data, this model allows fine
grained control and inference for a wide range of COVID-19 mitigation and
suppression policy measures. Moreover, the block-Gibbs sampling algorithm is
able to support efficient testing in a test-trace-isolate approach to contain
COVID-19 infection spread. To the best of our knowledge, this is the first
model with efficient inference for COVID-19 infection spread based on
individual-level contact data; most epidemic models are macro-level models that
reason over entire populations. The implementation of CRISP is available in
Python and C++ at https://github.com/zalandoresearch/CRISP.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:25:56 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jun 2022 18:59:25 GMT""}]","2022-07-04"
"2006.04949","Xiang Yu","Xiang Yu, Yibin Fu, Hui-Hui Dai","A refined dynamic finite-strain shell theory for incompressible
  hyperelastic materials: equations and two-dimensional shell virtual work
  principle","26 pages, 1 figure. Some errors in Section 4 were fixed","Proc Royal Soc A, Vol 476, Issue 2237 (May 2020)","10.1098/rspa.2020.0031",,"cs.CE physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on previous work for the static problem, in this paper we first derive
one form of dynamic finite-strain shell equations for incompressible
hyperelastic materials that involve three shell constitutive relations. In
order to single out the bending effect as well as to reduce the number of shell
constitutive relations, a further refinement is performed, which leads to a
refined dynamic finite-strain shell theory with only two shell constitutive
relations (deducible from the given three-dimensional (3D) strain energy
function) and some new insights are also deduced. By using the weak formulation
of the shell equations and the variation of the 3D Lagrange functional,
boundary conditions and the two-dimensional (2D) shell virtual work principle
are derived. As a benchmark problem, we consider the extension and inflation of
an arterial segment. The good agreement between the asymptotic solution based
on the shell equations and that from the 3D exact one gives verification of the
former. The refined shell theory is also applied to study the plane-strain
vibrations of a pressurized artery, and the effects of the axial pre-stretch,
pressure and fibre angle on the vibration frequencies are investigated in
detail.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:38:21 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 17:11:58 GMT""},{""version"":""v3"",""created"":""Sun, 19 Jul 2020 17:06:18 GMT""},{""version"":""v4"",""created"":""Mon, 24 Aug 2020 17:49:20 GMT""},{""version"":""v5"",""created"":""Sun, 11 Oct 2020 09:43:21 GMT""},{""version"":""v6"",""created"":""Fri, 16 Oct 2020 08:24:22 GMT""},{""version"":""v7"",""created"":""Sun, 8 Nov 2020 16:12:05 GMT""},{""version"":""v8"",""created"":""Tue, 15 Dec 2020 14:17:12 GMT""}]","2020-12-16"
"2006.04953","Binghui Peng","Xi Chen and Binghui Peng","Hedging in games: Faster convergence of external and swap regrets",,,,,"cs.GT cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the setting where players run the Hedge algorithm or its
optimistic variant to play an $n$-action game repeatedly for $T$ rounds.
  1) For two-player games, we show that the regret of optimistic Hedge decays
at $\tilde{O}( 1/T ^{5/6} )$, improving the previous bound $O(1/T^{3/4})$ by
Syrgkanis, Agarwal, Luo and Schapire (NIPS'15)
  2) In contrast, we show that the convergence rate of vanilla Hedge is no
better than $\tilde{\Omega}(1/ \sqrt{T})$, addressing an open question posted
in Syrgkanis, Agarwal, Luo and Schapire (NIPS'15).
  For general m-player games, we show that the swap regret of each player
decays at rate $\tilde{O}(m^{1/2} (n/T)^{3/4})$ when they combine optimistic
Hedge with the classical external-to-internal reduction of Blum and Mansour
(JMLR'07). The algorithm can also be modified to achieve the same rate against
itself and a rate of $\tilde{O}(\sqrt{n/T})$ against adversaries. Via standard
connections, our upper bounds also imply faster convergence to coarse
correlated equilibria in two-player games and to correlated equilibria in
multiplayer games.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:18:27 GMT""},{""version"":""v2"",""created"":""Mon, 19 Oct 2020 01:18:43 GMT""}]","2020-10-21"
"2006.04954","D. Delepine","Jose de Jesus Bernal-Alvarado and David Delepine (Guanajuato
  University)","Morphology and numerical characteristics of epidemic curves for
  SARS-Cov-II using Moyal distribution","8 pages, 5 figures",,,,"q-bio.PE physics.med-ph physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, it is shown that the Moyal distribution is an excelent tool to
study the SARS-Cov-II (Covid-19) epidemiological associated curves and its
propagation. The Moyal parameters give all the information to describe the form
and the impact of the illness outbreak in the different affected countries and
its global impact. We checked that the Moyal distribution can accurately fit
the daily report of {\it{new confirmed cases of infected people}} (NCC) per
country, in that places where the contagion is reaching their final phase,
describing the beginning, the most intense phase and the descend of the
contagion, simultaneously . In order to achieve the purpose of this work, it is
important to work with a complete and well compilated set of the data to be
used to fit the curves. Data from European countries like France, Spain, Italy
Belgium, Sweden, United Kingdom, Denmark and others like USA and China, have
been used. Also, the correlation between the parameters of the Moyal
distribution fitting and the general public health measures imposed in each
country, have been discussed. A relation between those policies and the
features of the Moyal distribution, in terms of their parameters and critical
points, is shown; from that, it can be seen that the knowledge of the time
evolution of the epidemiological curve, their critical points, superposition
properties and rates of the rising and the ending, could help to find a way to
estimate the efficiency of social distancing measures, imposed in each country,
and anticipate the different phases of the pandemic.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:20:17 GMT""}]","2020-06-11"
"2006.04955","Alejandro C\'orsico","Alejandro H. C\'orsico","White-dwarf asteroseismology with the Kepler space telescope","28 pages, 7 figures, 3 tables. To be published in the volume
  ""Asteroseismology in the Kepler Era"", hosted by Dr(s) Andrzej S Baran,
  Anthony Eugene Lynas-Gray, and Karen Kinemuchi in Frontiers in Astronomy and
  Space Sciences",,,,"astro-ph.SR hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the course of their evolution, white-dwarf stars go through at least one
phase of variability in which the global pulsations they undergo allow
astronomers to peer into their interiors, this way making possible to shed
light on their deep inner structure and evolutionary stage by means of
asteroseismology. The study of pulsating white dwarfs has witnessed substantial
progress in the last decade, and this has been so largely thanks to the arrival
of continuous observations of unprecedented quality from space, like those of
the CoRoT, Kepler, and TESS missions. This, along with the advent of new
detailed thoretical models and the development of improved asteroseismological
techniques, has helped to unravel the internal chemical structure of many
pulsating white dwarfs, and, at the same time, has opened new questions that
challenge theoreticians. In particular, uninterrupted monitoring of white-dwarf
stars for months has allowed discovering phenomena impossible to detect with
ground-based observations, despite admirable previous efforts like the Whole
Earth Telescope (WET). Here, we start by reviewing the essential properties of
white-dwarf and pre-white dwarf stars and their pulsations, and then, we go
through the different families of pulsating objects known to date. Finally, we
review the most outstanding findings about pulsating white dwarfs and pre-white
dwarfs made possible with the unprecedented-quality observations of the Kepler
space telescope, although we envisage that future analyzes of space data from
this mission that still await to be examined may reveal new secrets of these
extremely interesting variable stars.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:23:01 GMT""}]","2020-06-11"
"2006.04956","Mark Hagmann","Mark J. Hagmann and Logan D. Gibb","Consistent analytical solution of the time-dependent Schr\""odinger
  equation for nanoscale circuits with laser-assisted quantum tunneling","18 pages",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is now common practice to solve the Schr\""odinger equation to estimate the
tunneling current between two metal electrodes at specified potentials, or the
transmission through a potential barrier by assuming an incident, reflected,
and transmitted wave. However, we suggest that these methods may not be
appropriate for nanoscale circuits. The electron man-free path may be as long
as 68.2 nm in metallic elements so we consider the possibility that quantum
effects may occur throughout a nanoscale circuit, including the connections.
Analytical methods are presented for modeling the coherent transfer of the
wavefunction through a closed circuit.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:26:03 GMT""}]","2020-06-11"
"2006.04957","Christian Gaetz","Christian Gaetz and Christopher Ryba","Stable characters from permutation patterns","11 pages","Selecta Mathematica, Volume 27 (2021)","10.1007/s00029-021-00692-9",,"math.CO math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a fixed permutation $\sigma \in S_k$, let $N_{\sigma}$ denote the
function which counts occurrences of $\sigma$ as a pattern in permutations from
$S_n$. We study the expected value (and $d$-th moments) of $N_{\sigma}$ on
conjugacy classes of $S_n$ and prove that the irreducible character support of
these class functions stabilizes as $n$ grows. This says that there is a single
polynomial in the variables $n, m_1, \ldots, m_{dk}$ which computes these
moments on any conjugacy class (of cycle type $1^{m_1}2^{m_2}\cdots$) of any
symmetric group. This result generalizes results of Hultman and of Gill, who
proved the cases $(d,k)=(1,2)$ and $(1,3)$ using ad hoc methods. Our proof is,
to our knowledge, the first application of partition algebras to the study of
permutation patterns.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:35:26 GMT""}]","2021-11-12"
"2006.04958","Josh Pollitz","Jian Liu, Josh Pollitz","Duality and symmetry of complexity over complete intersections via
  exterior homology","13 pages, comments welcome","Proceedings of the American Mathematical Society (2021)","10.1090/proc/15276",,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study homological properties of a locally complete intersection ring by
importing facts from homological algebra over exterior algebras. One
application is showing that the thick subcategories of the bounded derived
category of a locally complete intersection ring are self-dual under
Grothendieck duality. This was proved by Stevenson when the ring is a quotient
of a regular ring modulo a regular sequence; we offer two independent proofs in
the more general setting. Second, we use these techniques to supply new proofs
that complete intersections possess symmetry of complexity.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:38:54 GMT""}]","2021-09-21"
"2006.04959","Rebekah Overdorf","Rebekah Overdorf and Christopher Schwartz","Thinking Taxonomically about Fake Accounts: Classification, False
  Dichotomies, and the Need for Nuance",,,,,"cs.CY cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is often said that war creates a fog in which it becomes difficult to
discern friend from foe on the battlefield. In the ongoing war on fake
accounts, conscious development of taxonomies of the phenomenon has yet to
occur, resulting in much confusion on the digital battlefield about what
exactly a fake account is. This paper intends to address this problem, not by
proposing a taxonomy of fake accounts, but by proposing a systematic way to
think taxonomically about the phenomenon. Specifically, we examine fake
accounts through both a combined philosophical and computer science-based
perspective. Through these lenses, we deconstruct narrow binary thinking about
fake accounts, both in the form of general false dichotomies and specifically
in relation to the Facebook's conceptual framework ""Coordinated Inauthentic
Behavior"" (CIB). We then address the false dichotomies by constructing a more
complex way of thinking taxonomically about fake accounts.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:40:00 GMT""}]","2020-06-11"
"2006.04960","Matth\""aus Kleindessner","Matth\""aus Kleindessner, Pranjal Awasthi, Jamie Morgenstern","A Notion of Individual Fairness for Clustering",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A common distinction in fair machine learning, in particular in fair
classification, is between group fairness and individual fairness. In the
context of clustering, group fairness has been studied extensively in recent
years; however, individual fairness for clustering has hardly been explored. In
this paper, we propose a natural notion of individual fairness for clustering.
Our notion asks that every data point, on average, is closer to the points in
its own cluster than to the points in any other cluster. We study several
questions related to our proposed notion of individual fairness. On the
negative side, we show that deciding whether a given data set allows for such
an individually fair clustering in general is NP-hard. On the positive side,
for the special case of a data set lying on the real line, we propose an
efficient dynamic programming approach to find an individually fair clustering.
For general data sets, we investigate heuristics aimed at minimizing the number
of individual fairness violations and compare them to standard clustering
approaches on real data sets.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:41:39 GMT""}]","2020-06-11"
"2006.04961","Maarten De Boeck","Maarten De Boeck and Geertrui Van de Voorde","The weight distributions of linear sets in PG(1,q^5)",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the weight distributions of $\mathbb{F}_q$-linear
sets in $\mathrm{PG}(1,q^5)$. Our main theorem proves that a linear set $S$ of
rank $5$, which is not scattered has the following weight distribution for its
points with weight larger than 1: (i) one point of weight $4$ or $5$, (ii) one
point of weight $3$ and $0$, $q$, $q^2$ points of weight two, (iii) $s$ points
of weight $2$ where $s\in
[q-2\sqrt{q}+1,q+2\sqrt{q}+1]\cup\{2q,2q+1,2q+2,3q,3q+1,q^2+1\}$. In
particular, there are no $2$-clubs in $\mathrm{PG}(1,q^5)$.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:42:47 GMT""},{""version"":""v2"",""created"":""Wed, 17 Nov 2021 23:10:34 GMT""},{""version"":""v3"",""created"":""Mon, 21 Mar 2022 10:28:46 GMT""},{""version"":""v4"",""created"":""Sat, 23 Apr 2022 08:20:26 GMT""}]","2022-04-26"
"2006.04962","Hongmei He Ph.D","Meng-Yuan Chen, Yong-Jian Wu, Hongmei He","A Novel Navigation System for an Autonomous Mobile Robot in an Uncertain
  Environment",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we developed a new navigation system, which detects obstacles
in a sliding window with an adaptive threshold clustering algorithm, classifies
the detected obstacles with a decision tree, heuristically predicts potential
collision and finds optimal path with a simplified Mophin algorithm. This
system has the merits of optimal free-collision path, small memory size and
less computing complexity, compared with the state of the arts in robot
navigation. The experiments on simulation and a robot for eight scenarios
demonstrate that the robot can effectively and efficiently avoid potential
collisions with any static or dynamic obstacles in its surrounding environment.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:45:45 GMT""}]","2020-06-11"
"2006.04963","Zidu Lin","Zidu Lin, Matthew E. Caplan, Charles J. Horowitz, and Cecilia
  Lunardini","Fast neutrino cooling of nuclear pasta in neutron stars: molecular
  dynamics simulations","12 pages, 9 figures, Accepted by PRC, Fig. 9b was given at wrong
  temperature in earlier version, and the mistake was corrected in this version","Phys. Rev. C 102, 045801 (2020)","10.1103/PhysRevC.102.045801",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The direct URCA process of rapid neutrino emission can occur in nonuniform
nuclear pasta phases that are expected in the inner crust of neutron stars.
Here, the periodic potential for a nucleon in nuclear pasta allows momentum
conservation to be satisfied for direct URCA reactions. We improve on earlier
work by modeling a rich variety of pasta phases (gnocchi, waffle, lasagna, and
anti-spaghetti) with large-scale molecular dynamics simulations. We find that
the neutrino luminosity due to direct URCA reactions in nuclear pasta can be 3
to 4 orders of magnitude larger than that from the modified URCA process in the
NS core. Thus neutrino radiation from pasta could dominate radiation from the
core and this could significantly impact the cooling of neutron stars
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:52:51 GMT""},{""version"":""v2"",""created"":""Mon, 14 Sep 2020 15:53:59 GMT""},{""version"":""v3"",""created"":""Tue, 29 Sep 2020 16:12:14 GMT""}]","2020-10-14"
"2006.04964","Nitin Jonathan Myers","Nitin Jonathan Myers, Robert W. Heath Jr","InFocus: A spatial coding technique to mitigate misfocus in near field
  LoS beamforming","Submitted to the IEEE Transactions on Wireless Communications.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phased arrays, commonly used in IEEE 802.11ad and 5G radios, are capable of
focusing radio frequency signals in a specific direction or a spatial region.
Beamforming achieves such directional or spatial concentration of signals and
enables phased array-based radios to achieve high data rates. Designing beams
for millimeter wave and terahertz communication using massive phased arrays,
however, is challenging due to hardware constraints and the wide bandwidth in
these systems. For example, beams which are optimal at the center frequency may
perform poor in wideband communication systems where the radio frequencies
differ substantially from the center frequency. The poor performance in such
systems is due to differences in the optimal beamformers corresponding to
distinct radio frequencies within the wide bandwidth. Such a mismatch leads to
a misfocus effect in near field systems and the beam squint effect in far field
systems. In this paper, we investigate the misfocus effect and propose InFocus,
a low complexity technique to construct beams that are well suited for massive
wideband phased arrays. The beams are constructed using a carefully designed
frequency modulated waveform in the spatial dimension. For the special case of
beamforming along the boresight of an array, this waveform is analogous to the
frequency modulated continuous wave (FMCW) chirp signal in radar. InFocus
mitigates beam misfocus and beam squint when applied to near field and far
field systems. Simulation results indicate that InFocus enables massive
wideband phased array-based radios to achieve higher data rates than comparable
beamforming solutions.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:11:40 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 17:49:46 GMT""}]","2021-03-09"
"2006.04965","Francisco Rubilar A.","Edoardo Ballico, Elizabeth Gasparim, Francisco Rubilar and Bruno
  Suzuki","The Kuranishi map for moduli of bundles on surfaces of general type","Minor typos fixed",,,,"math.AG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study moduli of vector bundles on surfaces of general type, focusing on
the case of a product of smooth projective curves. We compare the moduli space
of stable bundles $\mathfrak M^s$ to the coarse moduli space of the stack of
all bundles $\mathfrak M$. After removing the irreducible component consisting
only of unstable bundles from $\mathfrak M$, we then show that $\mathfrak M$
and $\mathfrak M^s$ have the same homology at range smaller than $c_2$.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:19:34 GMT""},{""version"":""v2"",""created"":""Thu, 15 Oct 2020 15:06:14 GMT""}]","2020-10-16"
"2006.04966","Nicos Makris","Nicos Makris","The fractional derivative of the Dirac delta function and new results on
  the inverse Laplace transform of irrational functions","arXiv admin note: substantial text overlap with arXiv:2002.04581","Fractal Fractional. 2021, 5, 18","10.3390/fractalfract5010018",,"math-ph math.CA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated from studies on anomalous diffusion, we show that the memory
function $M(t)$ of complex materials, that their creep compliance follows a
power law, $J(t)\sim t^q$ with $q\in \mathbb{R}^+$, is the fractional
derivative of the Dirac delta function,
$\frac{\mathrm{d}^q\delta(t-0)}{\mathrm{d}t^q}$ with $q\in \mathbb{R}^+$. This
leads to the finding that the inverse Laplace transform of $s^q$ for any $q\in
\mathbb{R}^+$ is the fractional derivative of the Dirac delta function,
$\frac{\mathrm{d}^q\delta(t-0)}{\mathrm{d}t^q}$. This result, in association
with the convolution theorem, makes possible the calculation of the inverse
Laplace transform of $\frac{s^q}{s^{\alpha}\mp\lambda}$ where
$\alpha<q\in\mathbb{R}^+$ which is the fractional derivative of order $q$ of
the Rabotnov function $\varepsilon_{\alpha-1}(\pm\lambda,
t)=t^{\alpha-1}E_{\alpha, \alpha}(\pm\lambda t^{\alpha})$. The fractional
derivative of order $q\in \mathbb{R}^+$ of the Rabotnov function,
$\varepsilon_{\alpha-1}(\pm\lambda, t)$ produces singularities which are
extracted with a finite number of fractional derivatives of the Dirac delta
function depending on the strength of $q$ in association with the recurrence
formula of the two-parameter Mittag-Leffler function.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:21:17 GMT""}]","2021-03-02"
"2006.04967","Abdulkadir \c{S}eker","Abdulkadir \c{S}eker, Banu Diri, Halil Arslan","Summarising Big Data: Common GitHub Dataset for Software Engineering
  Challenges","7 pages, The article was submitted to Cumhuriyet Science Journal","Cumhuriyet Science Journal, 41, (2020), 720-724","10.17776/csj.728932",,"cs.SE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In open-source software development environments; textual, numerical and
relationship-based data generated are of interest to researchers. Various data
sets are available for this data, which is frequently used in areas such as
software engineering and natural language processing. However, since these data
sets contain all the data in the environment, the problem arises in the
terabytes of data processing. For this reason, almost all of the studies using
GitHub data use filtered data according to certain criteria. In this context,
using a different data set in each study makes a comparison of the accuracy of
the studies quite difficult. In order to solve this problem, a common dataset
was created and shared with the researchers, which would allow us to work on
many software engineering problems.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:21:25 GMT""}]","2020-10-01"
"2006.04968","Brantly Callaway","Afrouz Azadikhah Jahromi, Brantly Callaway","Heterogeneous Effects of Job Displacement on Earnings","40 pages, 15 figures",,,,"econ.EM econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers how the effect of job displacement varies across
different individuals. In particular, our interest centers on features of the
distribution of the individual-level effect of job displacement. Identifying
features of this distribution is particularly challenging -- e.g., even if we
could randomly assign workers to be displaced or not, many of the parameters
that we consider would not be point identified. We exploit our access to panel
data, and our approach relies on comparing outcomes of displaced workers to
outcomes the same workers would have experienced if they had not been displaced
and if they maintained the same rank in the distribution of earnings as they
had before they were displaced. Using data from the Displaced Workers Survey,
we find that displaced workers earn about $157 per week less, on average, than
they would have earned if they had not been displaced. We also find that there
is substantial heterogeneity. We estimate that 42% of workers have higher
earnings than they would have had if they had not been displaced and that a
large fraction of workers have experienced substantially more negative effects
than the average effect of displacement. Finally, we also document major
differences in the distribution of the effect of job displacement across
education levels, sex, age, and counterfactual earnings levels. Throughout the
paper, we rely heavily on quantile regression. First, we use quantile
regression as a flexible (yet feasible) first step estimator of conditional
distributions and quantile functions that our main results build on. We also
use quantile regression to study how covariates affect the distribution of the
individual-level effect of job displacement.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:27:05 GMT""},{""version"":""v2"",""created"":""Wed, 30 Sep 2020 17:07:15 GMT""}]","2020-10-01"
"2006.04969","Heiko Hamann","Heiko Hamann and Andreagiovanni Reina","Scalability in Computing and Robotics","33 pages, 8 figures",,"10.1109/TC.2021.3089044",,"cs.DC cs.MA cs.PF cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Efficient engineered systems require scalability. A scalable system has
increasing performance with increasing system size. In an ideal case, the
increase in performance (e.g., speedup) corresponds to the number of units that
are added to the system. However, if multiple units work on the same task, then
coordination among these units is required. This coordination can introduce
overheads with an impact on system performance. The coordination costs can lead
to sublinear improvement or even diminishing performance with increasing system
size. However, there are also systems that implement efficient coordination and
exploit collaboration of units to attain superlinear improvement. Modeling the
scalability dynamics is key to understanding efficient systems. Known laws of
scalability, such as Amdahl's law, Gustafson's law, and Gunther's Universal
Scalability Law, are minimalistic phenomenological models that explain a rich
variety of system behaviors through concise equations. While useful to gain
general insights, the phenomenological nature of these models may limit the
understanding of the underlying dynamics, as they are detached from first
principles that could explain coordination overheads among units. Through a
decentralized system approach, we propose a general model based on generic
interactions between units that is able to describe, as specific cases, any
general pattern of scalability included by previously reported laws. The
proposed general model of scalability is built on first principles, or at least
on a microscopic description of interaction between units, and therefore has
the potential to contribute to a better understanding of system behavior and
scalability. We show that this model can be applied to a diverse set of
systems, such as parallel supercomputers, robot swarms, or wireless sensor
networks, creating a unified view on interdisciplinary design for scalability.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:28:59 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 14:25:50 GMT""}]","2021-06-14"
"2006.04970","Tomoyuki Ichiba","Tomoyuki Ichiba and Ioannis Karatzas","Degenerate Competing Three-Particle Systems","39 pages, 5 figures",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study systems of three interacting particles, in which drifts and
variances are assigned by rank. These systems are ""degenerate"": the variances
corresponding to one or two ranks can vanish, so the corresponding ranked
motions become ballistic rather than diffusive. Depending on which ranks are
allowed to ""go ballistic"" the systems exhibit markedly different behavior which
we study in some detail. Also studied are stability properties for the
resulting planar process of gaps between successive ranks.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:30:44 GMT""},{""version"":""v2"",""created"":""Sat, 21 Aug 2021 19:48:50 GMT""}]","2021-08-24"
"2006.04971","Jan Florek","Jan Florek","A plane version of the Fleischner theorem","5 pages, 2 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\cal G$ be a family of all $3$-regular $2$-connected plane multigraphs
without loops. We prove the following plane version of the Fleischner theorem:
Let $G$ be a graph in $\cal G$. For every $2$-factor $X$ of $G$ having
$n$-components there exists a plane graph $J$ having a Hamilton cycle omitting
all edges of $E(G)\backslash E(X)$ and such that $G \subseteq J \subset G^{2}$,
$\Delta(J) \leqslant 5$ and $|E(J)|= |E(G)| + 2n -2$. Moreover, if $G$ is
simple, then $J$ is simple too.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:31:32 GMT""}]","2020-06-11"
"2006.04972","Zheng Wang","Zheng Wang, Wei Xing, Robert Kirby, Shandian Zhe","Multi-Fidelity High-Order Gaussian Processes for Physical Simulation",,,,,"stat.ML cs.LG physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The key task of physical simulation is to solve partial differential
equations (PDEs) on discretized domains, which is known to be costly. In
particular, high-fidelity solutions are much more expensive than low-fidelity
ones. To reduce the cost, we consider novel Gaussian process (GP) models that
leverage simulation examples of different fidelities to predict
high-dimensional PDE solution outputs. Existing GP methods are either not
scalable to high-dimensional outputs or lack effective strategies to integrate
multi-fidelity examples. To address these issues, we propose Multi-Fidelity
High-Order Gaussian Process (MFHoGP) that can capture complex correlations both
between the outputs and between the fidelities to enhance solution estimation,
and scale to large numbers of outputs. Based on a novel nonlinear
coregionalization model, MFHoGP propagates bases throughout fidelities to fuse
information, and places a deep matrix GP prior over the basis weights to
capture the (nonlinear) relationships across the fidelities. To improve
inference efficiency and quality, we use bases decomposition to largely reduce
the model parameters, and layer-wise matrix Gaussian posteriors to capture the
posterior dependency and to simplify the computation. Our stochastic
variational learning algorithm successfully handles millions of outputs without
extra sparse approximations. We show the advantages of our method in several
typical applications.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:31:59 GMT""}]","2020-06-11"
"2006.04973","Manikandasriram Srinivasan Ramanagopal","Manikandasriram Srinivasan Ramanagopal, Zixu Zhang, Ram Vasudevan,
  Matthew Johnson-Roberson","Pixel-Wise Motion Deblurring of Thermal Videos","10 pages, 8 figures, Accepted to Robotics: Science and Systems 2020",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Uncooled microbolometers can enable robots to see in the absence of visible
illumination by imaging the ""heat"" radiated from the scene. Despite this
ability to see in the dark, these sensors suffer from significant motion blur.
This has limited their application on robotic systems. As described in this
paper, this motion blur arises due to the thermal inertia of each pixel. This
has meant that traditional motion deblurring techniques, which rely on
identifying an appropriate spatial blur kernel to perform spatial
deconvolution, are unable to reliably perform motion deblurring on thermal
camera images. To address this problem, this paper formulates reversing the
effect of thermal inertia at a single pixel as a Least Absolute Shrinkage and
Selection Operator (LASSO) problem which we can solve rapidly using a quadratic
programming solver. By leveraging sparsity and a high frame rate, this
pixel-wise LASSO formulation is able to recover motion deblurred frames of
thermal videos without using any spatial information. To compare its quality
against state-of-the-art visible camera based deblurring methods, this paper
evaluated the performance of a family of pre-trained object detectors on a set
of images restored by different deblurring algorithms. All evaluated object
detectors performed systematically better on images restored by the proposed
algorithm rather than any other tested, state-of-the-art methods.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:35:12 GMT""}]","2020-06-11"
"2006.04974","Carlotta Gruppioni Dr.","C. Gruppioni, M. Bethermin, F. Loiacono, O. Le Fevre, P. Capak, P.
  Cassata, A.L. Faisst, D. Schaerer, J. Silverman, L. Yan, S. Bardelli, M.
  Boquien, R. Carraro, A. Cimatti, M. Dessauges-Zavadsky, M. Ginolfi, S.
  Fujimoto, N.P. Hathi, G.C. Jones, Y. Khusanova, A.M. Koekemoer, G. Lagache,
  B.C. Lemaux, P. Oesch, F. Pozzi, D.A. Riechers, G. Rodighiero, M. Romano, M.
  Talia, L. Vallini, D. Vergani, G. Zamorani, E. Zucca","The ALPINE-ALMA [CII] Survey: The nature, luminosity function and star
  formation history of dusty galaxies up to z~6","26 pages, 18 figures. Accepted for publication in A&A","A&A 643, A8 (2020)","10.1051/0004-6361/202038487",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the detailed characterisation of a sample of 56 sources
serendipitously detected in ALMA band 7, as part of the ALMA Large Program to
INvestigate CII at Early Times (ALPINE) in COSMOS and ECDFS. These sources have
been used to derive the total infrared luminosity function (LF) and to estimate
the cosmic star formation rate density (SFRD) up to z=6. We have looked for
counterparts in all the available multi-wavelength and photometric redshift
catalogues, and in deeper near- and mid-IR source lists and maps, to identify
optically dark sources with no matches in the public catalogues. Our ALMA blind
survey allows us to push further the study of the nature and evolution of dusty
galaxies at high-z, identifying luminous and massive sources to redshifts and
faint luminosities never probed before by any far-infrared surveys. The ALPINE
data are the first ones to sample the faint-end of the infrared LF, showing
little evolution from z=2.5 to z=6, and a flat slope up to the highest
redshifts. The SFRD obtained by integrating the luminosity function remains
almost constant between z=2 and 6, and significantly higher than the optical/UV
derivations, showing an important contribution of dusty galaxies and obscured
star formation up to high-z. About 14 per cent of the ALPINE serendipitous
continuum sources are optically+near-IR dark (six show a counterpart only in
the mid-IR and no HST or near-IR identification, while two are detected as
[CII] emitters at z=5). The six HST and near-IR dark galaxies with mid-IR
counterpart contribute for about 17 per cent of the total SFRD at z=5 and
dominate the high-mass end of the stellar mass function at z>3.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:38:14 GMT""},{""version"":""v2"",""created"":""Wed, 30 Sep 2020 16:40:59 GMT""}]","2020-10-28"
"2006.04975","Philippe Kruchten","Philippe Kruchten","Architectural Blueprints: The 4+1 View Model of Software Architecture","Early draft, better quality than IEEE published version",,"10.1109/52.469759",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article presents a model for describing the architecture of
software-intensive systems, based on the use of multiple, concurrent views.
This use of multiple views allows to address separately the concerns of the
various stakeholders of the architecture: end-user, developers, systems
engineers, project managers, etc., and to handle separately the functional and
non functional requirements. Each of the five views is described, together with
a notation to capture it. The views are designed using an
architecture-centered, scenario-driven, iterative development process.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:38:39 GMT""}]","2020-06-11"
"2006.04976","Zheng Wang","Zheng Wang, Wei Xing, Robert Kirby, Shandian Zhe","Physics Informed Deep Kernel Learning","8 pages, 5 figures, AISTATS",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep kernel learning is a promising combination of deep neural networks and
nonparametric function learning. However, as a data driven approach, the
performance of deep kernel learning can still be restricted by scarce or
insufficient data, especially in extrapolation tasks. To address these
limitations, we propose Physics Informed Deep Kernel Learning (PI-DKL) that
exploits physics knowledge represented by differential equations with latent
sources. Specifically, we use the posterior function sample of the Gaussian
process as the surrogate for the solution of the differential equation, and
construct a generative component to integrate the equation in a principled
Bayesian hybrid framework. For efficient and effective inference, we
marginalize out the latent variables in the joint probability and derive a
collapsed model evidence lower bound (ELBO), based on which we develop a
stochastic model estimation algorithm. Our ELBO can be viewed as a nice,
interpretable posterior regularization objective. On synthetic datasets and
real-world applications, we show the advantage of our approach in both
prediction accuracy and uncertainty quantification.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:43:31 GMT""},{""version"":""v2"",""created"":""Tue, 18 Jan 2022 19:03:54 GMT""}]","2022-01-20"
"2006.04977","Helmut Prodinger","Helmut Prodinger","Retakh's Motzkin paths and some combinatorial comments",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dyck paths where peaks are only allowed on level 1 and on even-indexed
levels, were introduced by Retakh and analysed by Zeilberger, with assistance
from Ekhad. We add some combinatorial comments to the enumeration, which
involves Motzkin numbers, in particular, about the average height of such
objects.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:47:24 GMT""},{""version"":""v2"",""created"":""Tue, 8 Sep 2020 13:36:05 GMT""}]","2020-09-09"
"2006.04978","William Rogers","W. Erick Rogers, Michael H. Meylan, Alison L. Kohout","Estimates of dissipation of wave energy by sea ice for a field
  experiment in the Southern Ocean, using model/data inversion","I am unfortunately not able to upload the Supplemental Information
  due to arxiv 10 MB limit on file size",,,,"physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A model-data inversion is applied to a very large observational dataset
collected in the Southern Ocean north of the Ross Sea during late autumn to
early winter, producing estimates of the frequency-dependent rate of
dissipation by sea ice. The modeling platform is WAVEWATCH III(R) which
accounts for non-stationarity, advection, wave generation, and other relevant
processes. The resulting 9477 dissipation profiles are co-located with other
variables such as ice thickness to quantify correlations which might be
exploited in later studies to improve predictions. Mean dissipation profiles
from the inversion are fitted to simple binomials. Variability about the mean
profile is not small, but the binomials show remarkable qualitative similarity
to prior observation-based estimates of dissipation, and the power dependence
is consistent with at least three theoretical models, one of which assumes that
dissipation is dominated by turbulence generated by shear at the ice-water
interface.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:53:23 GMT""},{""version"":""v2"",""created"":""Fri, 12 Jun 2020 19:03:31 GMT""}]","2020-06-16"
"2006.04979","Mahfujur Rahaman","Mahfujur Rahaman, Oleksandr Selyshchev, Yang Pan, Ilya Milekhin,
  Apoorva Sharma, Georgeta Salvan, Sibylle Gemming, and Dietrich R T Zahn","Radiative Decay of Dark Exciton Related Emission in a Sandwiched
  Monolayer WSe2 Revealed by Room Temperature Micro and Nano Photoluminescence","17 pages, 6 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-sa/4.0/","  TMDCs have attracted a lot of attention in recent years due to their unique
indirect to direct band gap transition from bulk to monolayer thickness. Strong
confinement in the out-of-plane direction enhances the Coulomb potential
between the charged particles (e-h pairs) and thus increases the exciton
binding energy dramatically. The lattice inversion asymmetry in a monolayer
creates two non-equivalent (but degenerate in energy) band edges protected by
time reversal polarisation via pseudo-spin. However, the presence of strong
spin-orbit coupling in the valence band and weak spin-splitting in the
conduction band results in the lowest lying exciton in WX2 (X = S, Se) being
spin forbidden and optically dark. Because of their long life times, dark
excitons (XD) are highly attractive for quantum optics and optoelectronic
applications. To date studying XD emission is limited to cryogenic temperature
or required very complex experimental configurations to observe them at room
temperature (RT). Here, we demonstrate a novel approach of radiative decay of
XD related emissions in 1L-WSe2 studied by micro and nano PL at RT. 1L-WSe2
flakes were sandwiched by noble metal (Au or Ag) substrates and PDMS
nano-patches providing a strong local out-of-plane dipole moment with respect
to the 2D plane. This strong dipole moment not only enhances the XD in WSe2, it
also produces bound excitons due to extrinsic charge defects visible at RT. The
spatial distributions of these XD related emissions were studied by TEPL with a
spatial resolution < 10 nm confirming the confinement of these excitons within
the PDMS nano-patches. Finally, by removing the nano-patches from the top of
the flakes we are able to recover the bright excitons in the 1L-WSe2. Our
approach paves the way for deep understanding and to harness excitonic
properties in low dimensional semiconductors, thus offering a platform towards
quantum optics.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:55:44 GMT""},{""version"":""v2"",""created"":""Thu, 1 Oct 2020 23:12:26 GMT""}]","2020-10-05"
"2006.04980","Jan Overgoor","Jan Overgoor and Bogdan State and Lada Adamic","The Structure of U.S. College Networks on Facebook","ICWSM-2020",,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anecdotally, social connections made in university have life-long impact. Yet
knowledge of social networks formed in college remains episodic, due in large
part to the difficulty and expense involved in collecting a suitable dataset
for comprehensive analysis. To advance and systematize insight into college
social networks, we describe a dataset of the largest online social network
platform used by college students in the United States. We combine
de-identified and aggregated Facebook data with College Scorecard data,
campus-level information provided by U.S. Department of Education, to produce a
dataset covering the 2008-2015 entry year cohorts for 1,159 U.S. colleges and
universities, spanning 7.6 million students. To perform the difficult task of
comparing these networks of different sizes we develop a new methodology. We
compute features over sampled ego-graphs, train binary classifiers for every
pair of graphs, and operationalize distance between graphs as predictive
accuracy. Social networks of different year cohorts at the same school are
structurally more similar to one another than to cohorts at other schools.
Networks from similar schools have similar structures, with the public/private
and graduation rate dimensions being the most distinguishable. We also relate
school types to specific outcomes. For example, students at private schools
have larger networks that are more clustered and with higher homophily by year.
Our findings may help illuminate the role that colleges play in shaping social
networks which partly persist throughout people's lives.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:58:38 GMT""}]","2020-06-11"
"2006.04981","Alex Labach","Alex Labach and Shahrokh Valaee","A Framework for Neural Network Pruning Using Gibbs Distributions","v1 was presented at IEEE GLOBECOM 2020. v2 is a substantially
  expanded revision, also written in 2020",,"10.1109/GLOBECOM42002.2020.9322333",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern deep neural networks are often too large to use in many practical
scenarios. Neural network pruning is an important technique for reducing the
size of such models and accelerating inference. Gibbs pruning is a novel
framework for expressing and designing neural network pruning methods.
Combining approaches from statistical physics and stochastic regularization
methods, it can train and prune a network simultaneously in such a way that the
learned weights and pruning mask are well-adapted for each other. It can be
used for structured or unstructured pruning and we propose a number of specific
methods for each. We compare our proposed methods to a number of contemporary
neural network pruning methods and find that Gibbs pruning outperforms them. In
particular, we achieve a new state-of-the-art result for pruning ResNet-56 with
the CIFAR-10 dataset.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:04:53 GMT""},{""version"":""v2"",""created"":""Tue, 28 Dec 2021 22:16:43 GMT""}]","2021-12-30"
"2006.04982","Wayne De Paula","Orlando Oliveira, Tobias Frederico and Wayne de Paula","The soft-gluon limit and the infrared enhancement of the quark-gluon
  vertex",,"Eur. Phys. J. C (2020) 80: 484","10.1140/epjc/s10052-020-8037-0",,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Schwinger-Dyson quark equation (SDE) combined with results from lattice
simulation for the propagators are used to obtain information on the
quark-gluon vertex, taking into account the recent full QCD lattice results for
the soft-gluon limit. Its inclusion leads to a clear enhancement of the
infrared quark-gluon vertex. We also find that the relative contribution of the
quark-ghost kernel to the quark-gluon vertex in the infrared region does not
follow the rules from the perturbative analysis of the ultraviolet region. This
shows that for QCD the intuition based on perturbation theory does not apply to
the full momentum range. The framework developed in the current work provides
analytical expressions for all the longitudinal components of vertex taken into
account.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:05:58 GMT""}]","2020-06-11"
"2006.04983","Daniel Semrau","Daniel Semrau and Lidia Galdino and Eric Sillekens and Domanic Lavery
  and Robert I. Killey and Polina Bayvel","Modulation Format Dependent, Closed-Form Formula for Estimating
  Nonlinear Interference in S+C+L Band Systems",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  A closed-form formula for the nonlinear interference estimation of arbitrary
modulation formats in ultra-wideband transmission systems is presented. Enabled
by the proposed approach, the formula is applied to the entire S+C+L band (20
THz) and validated by numerical simulations with experimentally measured fibre
data.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:12:21 GMT""}]","2020-06-11"
"2006.04984","Siva Kumar Sastry Hari","Siva Kumar Sastry Hari, Michael B. Sullivan, Timothy Tsai, and Stephen
  W. Keckler","Making Convolutions Resilient via Algorithm-Based Error Detection
  Techniques",,,,,"cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability of Convolutional Neural Networks (CNNs) to accurately process
real-time telemetry has boosted their use in safety-critical and
high-performance computing systems. As such systems require high levels of
resilience to errors, CNNs must execute correctly in the presence of hardware
faults. Full duplication provides the needed assurance but incurs a prohibitive
100% overhead. Algorithmic techniques are known to offer low-cost solutions,
but the practical feasibility and performance of such techniques have never
been studied for CNN deployment platforms (e.g., TensorFlow or TensorRT on
GPUs). In this paper, we focus on algorithmically verifying Convolutions, which
are the most resource-demanding operations in CNNs. We use checksums to verify
convolutions, adding a small amount of redundancy, far less than
full-duplication. We first identify the challenges that arise in employing
Algorithm-Based Error Detection (ABED) for Convolutions in optimized inference
platforms that fuse multiple network layers and use reduced-precision
operations, and demonstrate how to overcome them. We propose and evaluate
variations of ABED techniques that offer implementation complexity, runtime
overhead, and coverage trade-offs. Results show that ABED can detect all
transient hardware errors that might otherwise corrupt output and does so while
incurring low runtime overheads (6-23%), offering at least 1.6X throughput to
workloads compared to full duplication.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:17:57 GMT""}]","2020-06-11"
"2006.04985","Gisliany Lillian Alves De Oliveira","Gisliany Lillian Alves de Oliveira, Luciana Concei\c{c}\~ao de Lima,
  Ivanovitch Silva, Marcel da C\^amara Ribeiro-Dantas, Kayo Henrique Monteiro,
  Patricia Takako Endo","Medidas de distanciamento social e mobilidade na Am\'erica do Sul
  durante a pandemia por COVID-19: Condi\c{c}\~oes necess\'arias e suficientes?","in Portuguese",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  In a scenario where there is no vaccine for COVID-19, non-pharmaceutical
interventions are necessary to contain the spread of the virus and the collapse
of the health system in the affected regions. One of these measures is social
distancing, which aims to reduce interactions in the community by closing
public and private establishments that involve crowds of people. The lockdown
presupposes a drastic reduction in community interactions, representing a more
extreme measure of social distancing. Based on geolocation data provided by
Google for six categories of physical spaces, this article identifies the
variations in the circulation of people in South America for different types of
social distancing measures adopted during the COVID-19 pandemic. In this study,
population mobility trends for a group of countries between February 15, 2020
and May 16, 2020 were analyzed. To summarize these trends in a single metric, a
general circulation index was created, and to identify regional mobility
patterns, descriptive analyzes of spatial autocorrelation (global and local
Moran index) were used. The first hypothesis of this study is that countries
with a lockdown decree can achieve greater success in reducing the mobility of
the population, and the second hypothesis is that Argentina, Brazil and
Colombia have regional mobility patterns. The first hypothesis was partially
confirmed (considering 10 countries in South America), and the results obtained
in the spatial analyzes confirmed the second hypothesis. In general, the
observed data shows that less rigid lockdown or social distancing measures are
necessary, however, they are not sufficient to achieve a significant reduction
in the circulation of people during the pandemic.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:22:58 GMT""}]","2020-06-11"
"2006.04986","Mojtaba Nayyeri","Mojtaba Nayyeri, Sahar Vahdati, Can Aykul, Jens Lehmann","5* Knowledge Graph Embeddings with Projective Transformations","Accepted in AAAI 2021",,,,"cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Performing link prediction using knowledge graph embedding models has become
a popular approach for knowledge graph completion. Such models employ a
transformation function that maps nodes via edges into a vector space in order
to measure the likelihood of the links. While mapping the individual nodes, the
structure of subgraphs is also transformed. Most of the embedding models
designed in Euclidean geometry usually support a single transformation type -
often translation or rotation, which is suitable for learning on graphs with
small differences in neighboring subgraphs. However, multi-relational knowledge
graphs often include multiple sub-graph structures in a neighborhood (e.g.
combinations of path and loop structures), which current embedding models do
not capture well. To tackle this problem, we propose a novel KGE model (5*E) in
projective geometry, which supports multiple simultaneous transformations -
specifically inversion, reflection, translation, rotation, and homothety. The
model has several favorable theoretical properties and subsumes the existing
approaches. It outperforms them on the most widely used link prediction
benchmarks
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:28:07 GMT""},{""version"":""v2"",""created"":""Sun, 14 Mar 2021 16:46:48 GMT""}]","2021-03-16"
"2006.04987","Hao Shen","Ajay Chandra, Ilya Chevyrev, Martin Hairer, Hao Shen","Langevin dynamic for the 2D Yang-Mills measure","141 pages. Revised according to referee reports. Added figures in
  Section 3. Accepted for publication in Publ. Math. IH\'ES",,"10.1007/s10240-022-00132-0",,"math.PR math-ph math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a natural state space and Markov process associated to the
stochastic Yang-Mills heat flow in two dimensions. To accomplish this we first
introduce a space of distributional connections for which holonomies along
sufficiently regular curves (Wilson loop observables) and the action of an
associated group of gauge transformations are both well-defined and satisfy
good continuity properties. The desired state space is obtained as the
corresponding space of orbits under this group action and is shown to be a
Polish space when equipped with a natural Hausdorff metric. To construct the
Markov process we show that the stochastic Yang-Mills heat flow takes values in
our space of connections and use the ""DeTurck trick"" of introducing a time
dependent gauge transformation to show invariance, in law, of the solution
under gauge transformations. Our main tool for solving for the Yang-Mills heat
flow is the theory of regularity structures and along the way we also develop a
""basis-free"" framework for applying the theory of regularity structures in the
context of vector-valued noise - this provides a conceptual framework for
interpreting several previous constructions and we expect this framework to be
of independent interest.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:30:31 GMT""},{""version"":""v2"",""created"":""Mon, 10 Jan 2022 17:35:35 GMT""},{""version"":""v3"",""created"":""Wed, 25 May 2022 17:31:32 GMT""}]","2022-08-29"
"2006.04988","Andrey Voynov","Andrey Voynov, Stanislav Morozov, Artem Babenko","Object Segmentation Without Labels with Large-Scale Generative Models",,,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent rise of unsupervised and self-supervised learning has dramatically
reduced the dependency on labeled data, providing effective image
representations for transfer to downstream vision tasks. Furthermore, recent
works employed these representations in a fully unsupervised setup for image
classification, reducing the need for human labels on the fine-tuning stage as
well. This work demonstrates that large-scale unsupervised models can also
perform a more challenging object segmentation task, requiring neither
pixel-level nor image-level labeling. Namely, we show that recent unsupervised
GANs allow to differentiate between foreground/background pixels, providing
high-quality saliency masks. By extensive comparison on standard benchmarks, we
outperform existing unsupervised alternatives for object segmentation,
achieving new state-of-the-art.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:30:43 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 09:49:40 GMT""}]","2021-06-14"
"2006.04989","Oscar Morales-Ponce","Nagarathna Hema Balaji, Jyothsna Kilaru, Oscar Morales-Ponce","Synchronous Robotic Framework","Wi-DroIT 2020",,,,"cs.RO","http://creativecommons.org/publicdomain/zero/1.0/","  We present a synchronous robotic testbed called SyROF that allows fast
implementation of robotic swarms. Our main goal is to lower the entry barriers
to cooperative-robot systems for undergraduate and graduate students. The
testbed provides a high-level programming environment that allows the
implementation of Timed Input/Output Automata (TIOA). SyROF offers the
following unique characteristics: 1) a transparent mechanism to synchronize
robot maneuvers, 2) a membership service with a failure detector, and 3) a
transparent service to provide common knowledge in every round. These
characteristics are fundamental to simplifying the implementation of robotic
swarms. The software is organized in five layers: The lower layer consists of a
real-time publish-subscribe system that allows efficient communication between
tasks. The next layer is an implementation of a Kalman filter to estimate the
position, orientation, and speed of the robot. The third layer consists of a
synchronizer that synchronously executes the robot maneuvers, provides common
knowledge to all the active participants, and handles failures. The fifth layer
consists of the programming environment.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:31:04 GMT""}]","2020-06-11"
"2006.04990","Alphonse Sterling","Alphonse C. Sterling and Ronald L. Moore","Coronal-Jet-Producing Minifilament Eruptions as a Possible Source of
  Parker Solar Probe (PSP) Switchbacks",,,"10.3847/2041-8213/ab96be",,"astro-ph.SR physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Parker Solar Probe (PSP) has observed copious rapid magnetic field
direction changes in the near-Sun solar wind. These features have been called
""switchbacks,"" and their origin is a mystery. But their widespread nature
suggests that they may be generated by a frequently occurring process in the
Sun's atmosphere. We examine the possibility that the switchbacks originate
from coronal jets. Recent work suggests that many coronal jets result when
photospheric magnetic flux cancels, and forms a small-scale ""minifilament"" flux
rope that erupts and reconnects with coronal field. We argue that the
reconnected erupting minifilament flux rope can manifest as an outward
propagating Alfv\'enic fluctuation that steepens into an increasingly compact
disturbance as it moves through the solar wind. Using previous observed
properties of coronal jets that connect to coronagraph-observed white-light
jets (a.k.a. ""narrow CMEs""), along with typical solar wind speed values, we
expect the coronal-jet-produced disturbances to traverse near-perihelion PSP in
~<25 min, with a velocity of ~400 km/s. To consider further the plausibility of
this idea, we show that a previously studied series of equatorial latitude
coronal jets, originating from the periphery of an active region, generate
white-light jets in the outer corona (seen in STEREO/COR2 coronagraph images;
2.5---15 R_sun), and into the inner heliosphere (seen in STEREO/Hi1
heliospheric imager images; 15---84 R_sun). Thus it is tenable that
disturbances put onto open coronal magnetic field lines by
coronal-jet-producing erupting minifilament flux ropes can propagate out to PSP
space and appear as switchbacks.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:31:15 GMT""}]","2020-06-24"
"2006.04991","Zhizheng Zhang","Zhizheng Zhang, Cuiling Lan, Wenjun Zeng, Zhibo Chen, Shih-Fu Chang","Beyond Triplet Loss: Meta Prototypical N-tuple Loss for Person
  Re-identification","Accepted by IEEE Transactions on Multimedia",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Person Re-identification (ReID) aims at matching a person of interest across
images. In convolutional neural network (CNN) based approaches, loss design
plays a vital role in pulling closer features of the same identity and pushing
far apart features of different identities. In recent years, triplet loss
achieves superior performance and is predominant in ReID. However, triplet loss
considers only three instances of two classes in per-query optimization (with
an anchor sample as query) and it is actually equivalent to a two-class
classification. There is a lack of loss design which enables the joint
optimization of multiple instances (of multiple classes) within per-query
optimization for person ReID. In this paper, we introduce a multi-class
classification loss, i.e., N-tuple loss, to jointly consider multiple (N)
instances for per-query optimization. This in fact aligns better with the ReID
test/inference process, which conducts the ranking/comparisons among multiple
instances. Furthermore, for more efficient multi-class classification, we
propose a new meta prototypical N-tuple loss. With the multi-class
classification incorporated, our model achieves the state-of-the-art
performance on the benchmark person ReID datasets.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:34:08 GMT""},{""version"":""v2"",""created"":""Fri, 24 Sep 2021 08:55:05 GMT""}]","2021-09-27"
"2006.04992","Akash Doshi","Akash Doshi, Alexander Issa, Puneet Sachdeva, Sina Rafati, Somnath
  Rakshit","Deep Stock Predictions",,"arXiv preprint arXiv:2006.04992",,,"cs.LG q-fin.PM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Forecasting stock prices can be interpreted as a time series prediction
problem, for which Long Short Term Memory (LSTM) neural networks are often used
due to their architecture specifically built to solve such problems. In this
paper, we consider the design of a trading strategy that performs portfolio
optimization using the LSTM stock price prediction for four different
companies. We then customize the loss function used to train the LSTM to
increase the profit earned. Moreover, we propose a data driven approach for
optimal selection of window length and multi-step prediction length, and
consider the addition of analyst calls as technical indicators to a multi-stack
Bidirectional LSTM strengthened by the addition of Attention units. We find the
LSTM model with the customized loss function to have an improved performance in
the training bot over a regressive baseline such as ARIMA, while the addition
of analyst call does improve the performance for certain datasets.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:37:47 GMT""}]","2021-06-14"
"2006.04993","Spencer Leslie","Spencer Leslie","On the stabilization of relative trace formulae: descent and the
  fundamental lemma","v4, accepted version, to appear in Advances in Mathematics: edits
  throughout, added detail on symmetric spaces over ring of integers",,,,"math.NT math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the study of periods of automorphic forms and relative trace
formulae, we develop the theory of descent necessary to study orbital integrals
arising in the fundamental lemma for a general class of symmetric spaces over a
$p$-adic field $F$. More precisely, we prove that a connected symmetric space
over $F$ enjoys a notion of topological Jordan decomposition, which may be of
independent interest, and establish a relative version of a lemma of Kazhdan
that played a crucial role in the proof of the Langlands-Shelstad fundamental
lemma.
  As our main application, we use these results to prove the endoscopic
fundamental lemma for the unit element of the Hecke algebra for the symmetric
space associated to unitary Friedberg-Jacquet periods.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 23:45:18 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 19:07:09 GMT""},{""version"":""v3"",""created"":""Mon, 25 Jan 2021 16:15:36 GMT""},{""version"":""v4"",""created"":""Mon, 16 Aug 2021 13:14:24 GMT""}]","2021-08-17"
"2006.04994","Hangjie Ji","Hangjie Ji, Roman Taranets, and Marina Chugunova","On travelling wave solutions of a model of a liquid film flowing down a
  fibre","30 pages, 6 figures",,,,"math.AP physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existence of non-negative weak solutions is shown for a full curvature
thin-film model of a liquid thin film flowing down a vertical fibre. The proof
is based on the application of a priori estimates derived for energy-entropy
functionals. Long-time behaviour of these weak solutions is analysed and, under
some additional constraints for the model parameters and initial values,
convergence towards a travelling wave solution is obtained. Numerical studies
of energy minimizers and travelling waves are presented to illustrate
analytical results.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 00:07:56 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 14:48:09 GMT""}]","2021-07-02"
"2006.04995","Amol Upadhye","Steen Hannestad, Amol Upadhye, Yvonne Y. Y. Wong","Spoon or slide? The non-linear matter power spectrum in the presence of
  massive neutrinos","24 pages, 9 figures (matches accepted version)",,"10.1088/1475-7516/2020/11/062",,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Numerical simulations of massive neutrino cosmologies consistently find a
spoon-like feature in the non-linear matter power spectrum ratios of
cosmological models that differ only in the neutrino mass fraction f_N.
Typically, the ratio approaches unity at low wave numbers k, decreases by ~ 10
f_N at k ~ 1 h/Mpc, and turns up again at large k. Using the halo model of
large-scale structure, we show that this spoon feature originates in the
transition from the two-halo power spectrum to the one-halo power spectrum. The
former's sensitivity to f_N rises with k, while that of the latter decreases
with k. The presence of this spoon feature is robust with respect to different
choices of the halo mass function and the halo density profile, and does not
require any parameter tuning within the halo model. We demonstrate that a
standard halo model calculation is already able to predict the depth, width,
and position of this spoon as well as its evolution with redshift z with
remarkable accuracy. Predictions at z >= 1 can be further improved using
non-linear perturbative inputs.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 00:15:29 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 07:33:20 GMT""}]","2020-12-09"
"2006.04996","Xiang Jiang","Xiang Jiang, Qicheng Lao, Stan Matwin, Mohammad Havaei","Implicit Class-Conditioned Domain Alignment for Unsupervised Domain
  Adaptation","Accepted at ICML2020. For code, see
  https://github.com/xiangdal/implicit_alignment",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an approach for unsupervised domain adaptation---with a strong
focus on practical considerations of within-domain class imbalance and
between-domain class distribution shift---from a class-conditioned domain
alignment perspective. Current methods for class-conditioned domain alignment
aim to explicitly minimize a loss function based on pseudo-label estimations of
the target domain. However, these methods suffer from pseudo-label bias in the
form of error accumulation. We propose a method that removes the need for
explicit optimization of model parameters from pseudo-labels directly. Instead,
we present a sampling-based implicit alignment approach, where the sample
selection procedure is implicitly guided by the pseudo-labels. Theoretical
analysis reveals the existence of a domain-discriminator shortcut in misaligned
classes, which is addressed by the proposed implicit alignment approach to
facilitate domain-adversarial learning. Empirical results and ablation studies
confirm the effectiveness of the proposed approach, especially in the presence
of within-domain class imbalance and between-domain class distribution shift.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 00:20:21 GMT""}]","2020-06-11"
"2006.04997","Paul M. Terwilliger","Paul Terwilliger","The Norton algebra of a $Q$-polynomial distance-regular graph","11 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Norton algebra associated with a $Q$-polynomial primitive
idempotent of the adjacency matrix for a distance-regular graph. We obtain a
formula for the Norton algebra product that we find attractive.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 00:24:50 GMT""}]","2020-06-11"
"2006.04998","Shikha Chaganti","Eduardo Jose Mortani Barbosa Jr., Bogdan Georgescu, Shikha Chaganti,
  Gorka Bastarrika Aleman, Jordi Broncano Cabrero, Guillaume Chabin, Thomas
  Flohr, Philippe Grenier, Sasa Grbic, Nakul Gupta, Fran\c{c}ois Mellot, Savvas
  Nicolaou, Thomas Re, Pina Sanelli, Alexander W. Sauter, Youngjin Yoo,
  Valentin Ziebandt, Dorin Comaniciu","Machine Learning Automatically Detects COVID-19 using Chest CTs in a
  Large Multicenter Cohort",,,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Objectives: To investigate machine-learning classifiers and interpretable
models using chest CT for detection of COVID-19 and differentiation from other
pneumonias, ILD and normal CTs.
  Methods: Our retrospective multi-institutional study obtained 2096 chest CTs
from 16 institutions (including 1077 COVID-19 patients). Training/testing
cohorts included 927/100 COVID-19, 388/33 ILD, 189/33 other pneumonias, and
559/34 normal (no pathologies) CTs. A metric-based approach for classification
of COVID-19 used interpretable features, relying on logistic regression and
random forests. A deep learning-based classifier differentiated COVID-19 via 3D
features extracted directly from CT attenuation and probability distribution of
airspace opacities.
  Results: Most discriminative features of COVID-19 are percentage of airspace
opacity and peripheral and basal predominant opacities, concordant with the
typical characterization of COVID-19 in the literature. Unsupervised
hierarchical clustering compares feature distribution across COVID-19 and
control cohorts. The metrics-based classifier achieved AUC=0.83,
sensitivity=0.74, and specificity=0.79 of versus respectively 0.93, 0.90, and
0.83 for the DL-based classifier. Most of ambiguity comes from non-COVID-19
pneumonia with manifestations that overlap with COVID-19, as well as mild
COVID-19 cases. Non-COVID-19 classification performance is 91% for ILD, 64% for
other pneumonias and 94% for no pathologies, which demonstrates the robustness
of our method against different compositions of control groups.
  Conclusions: Our new method accurately discriminates COVID-19 from other
types of pneumonia, ILD, and no pathologies CTs, using quantitative imaging
features derived from chest CT, while balancing interpretability of results and
classification performance, and therefore may be useful to facilitate diagnosis
of COVID-19.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 00:40:35 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 13:24:04 GMT""},{""version"":""v3"",""created"":""Sat, 10 Oct 2020 00:53:14 GMT""}]","2020-10-13"
"2006.04999","Anna Ijjas","Anna Ijjas, William G. Cook, Frans Pretorius, Paul J. Steinhardt and
  Elliot Y. Davies","Robustness of slow contraction to cosmic initial conditions","41 pages, 18 figures; accepted for publication in JCAP","JCAP 08 (2020) 030","10.1088/1475-7516/2020/08/030",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present numerical relativity simulations of cosmological scenarios in
which the universe is smoothed and flattened by undergoing a phase of slow
contraction and test their sensitivity to a wide range of initial conditions.
Our numerical scheme enables the variation of all freely specifiable physical
quantities that characterize the initial spatial hypersurface, such as the
initial shear and spatial curvature contributions as well as the initial field
and velocity distributions of the scalar that drives the cosmological
evolution. In particular, we include initial conditions that are far outside
the perturbative regime of the well-known attractor scaling solution. We
complement our numerical results by analytically performing a complete
dynamical systems analysis and show that the two approaches yield consistent
results.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 00:55:53 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 12:50:26 GMT""}]","2020-08-14"
"2006.05000","Chandralekha Singh","Emily Marshman, Christof Keebaugh, and Chandralekha Singh","Student difficulties with the corrections to the energy spectrum of the
  hydrogen atom for the intermediate field Zeeman effect","Physics Education Research Conference Proceedings",,"10.1119/perc.2018.pr.Marshman",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss an investigation of student difficulties with the corrections to
the energy spectrum of the hydrogen atom for the intermediate field Zeeman
effect using the degenerate perturbation theory. The investigation was carried
out in advanced quantum mechanics courses by administering free-response and
multiple-choice questions and conducting individual interviews with students.
We find that students share many common difficulties related to relevant
physics concepts. In particular, students often struggled with mathematical
sense-making in this context of quantum mechanics which requires interpretation
of the implications of degeneracy in the unperturbed energy spectrum and how
the Zeeman perturbation will impact the splitting of the energy levels. We
discuss how the common difficulties often arise from the fact that applying
linear algebra concepts correctly in this context with degeneracy in the energy
spectrum is challenging for students.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:07:54 GMT""}]","2020-06-11"
"2006.05001","Saman Fahandezh-Saadi","Saman Fahandezh-Saadi, Masayoshi Tomizuka","In Proximity of ReLU DNN, PWA Function, and Explicit MPC","Submitted to Conference on Decision and Control (CDC) 2020",,,,"cs.LG cs.SY eess.SY stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rectifier (ReLU) deep neural networks (DNN) and their connection with
piecewise affine (PWA) functions is analyzed. The paper is an effort to find
and study the possibility of representing explicit state feedback policy of
model predictive control (MPC) as a ReLU DNN, and vice versa. The complexity
and architecture of DNN has been examined through some theorems and
discussions. An approximate method has been developed for identification of
input-space in ReLU net which results a PWA function over polyhedral regions.
Also, inverse multiparametric linear or quadratic programs (mp-LP or mp-QP) has
been studied which deals with reconstruction of constraints and cost function
given a PWA function.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:11:27 GMT""},{""version"":""v2"",""created"":""Thu, 5 Nov 2020 14:57:32 GMT""}]","2020-11-06"
"2006.05002","Ruoyu Wang","Ruoyu Wang and Qihua Wang","Determination and estimation of optimal quarantine duration for
  infectious diseases with application to data analysis of COVID-19",,"biometrics,2021",,,"stat.AP q-bio.PE stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quarantine measure is a commonly used non-pharmaceutical intervention during
the outbreak of infectious diseases. A key problem for implementing quarantine
measure is to determine the duration of quarantine. In this paper, a policy
with optimal quarantine duration is developed. The policy suggests different
quarantine durations for every individual with different characteristic. The
policy is optimal in the sense that it minimizes the average quarantine
duration of uninfected people with the constraint that the probability of
symptom presentation for infected people attains the given value closing to 1.
The optimal solution for the quarantine duration is obtained and estimated by
some statistic methods with application to analyzing COVID-19 data.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:11:51 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jul 2020 10:03:38 GMT""},{""version"":""v3"",""created"":""Wed, 28 Apr 2021 07:41:44 GMT""}]","2021-04-29"
"2006.05003","Satish Mylapore","Satish Mylapore, Ryan Quincy Paul, Joshua Yi, and Robert D. Slater","Universal Vector Neural Machine Translation With Effective Attention","15pages, 3 figures","SMU Data Science Review: Vol. 3 : No. 1 , Article 10. Available
  at: https://scholar.smu.edu/datasciencereview/vol3/iss1/10 Year March 2020",,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Neural Machine Translation (NMT) leverages one or more trained neural
networks for the translation of phrases. Sutskever introduced a sequence to
sequence based encoder-decoder model which became the standard for NMT based
systems. Attention mechanisms were later introduced to address the issues with
the translation of long sentences and improving overall accuracy. In this
paper, we propose a singular model for Neural Machine Translation based on
encoder-decoder models. Most translation models are trained as one model for
one translation. We introduce a neutral/universal model representation that can
be used to predict more than one language depending on the source and a
provided target. Secondly, we introduce an attention model by adding an overall
learning vector to the multiplicative model. With these two changes, by using
the novel universal model the number of models needed for multiple language
translation applications are reduced.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:13:57 GMT""}]","2020-06-11"
"2006.05004","Yuzhu Han","Yuzhu Han","Global asymptotic behavior of solutions to a class of Kirchhoff
  equations",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a parabolic type Kirchhoff equation and its stationary
counterpart are considered. For the evolution problem, the precise decay rates
of the weak solution and of the corresponding energy functional are derived.
For the stationary problem, a ground-state solution is obtained by applying
Lagrange multiplier method. Moreover, the asymptotic behaviors of the general
global solutions are also described. These results extend some recent ones
obtained in [Threshold results for the existence of global and blow-up
solutions to Kirchhoff equations with arbitrary initial energy, Computers and
Mathematics with Applications, 75(2018), 3283-3297] by Han and Li.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:17:00 GMT""}]","2020-06-11"
"2006.05005","Yuzhu Han","Yuzhu Han","Blow-up phenomena for a reaction diffusion equation with special
  diffusion process",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with the blow-up property of solutions to an initial
boundary value problem for a reaction diffusion equation with special diffusion
processes. It is shown, under certain conditions on the initial data, that the
solutions to this problem blow up in finite time, by combining Hardy
inequality, ""moving"" potential well methods with some differential
inequalities. Moreover, the upper and lower bounds for the blow-up time are
also derived when blow-up occurs.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:36:32 GMT""}]","2020-06-11"
"2006.05006","Yuzhu Han","Yuzhu Han, Qi Li","Lifespan of solutions to a damped fourth-order wave equation with
  logarithmic nonlinearity",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is devoted to the lifespan of solutions to a damped fourth-order
wave equation with logarithmic nonlinearity $$u_{tt}+\Delta^2u-\Delta
u-\omega\Delta u_t+\alpha(t)u_t=|u|^{p-2}u\ln|u|.$$ Finite time blow-up
criteria for solutions at both lower and high initial energy levels are
established, and an upper bound for the blow-up time is given for each case.
Moreover, by constructing a new auxiliary functional and making full use of the
strong damping term, a lower bound for the blow-up time is also derived.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:39:20 GMT""}]","2020-06-11"
"2006.05007","Marco Buongiorno Nardelli","Marco Buongiorno Nardelli","The Hitchhiker's Guide to the All-Interval 12-Tone Rows","15 pages",,,,"cs.SD cs.SI eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article revisits the generation, classification and categorization of
all-intervals 12-tone series (AIS). Inspired by the seminal work of Morris and
Starr in 1974 (Morris and Starr, The Structure of All-Interval Series 1974), it
expands their analysis using complex network theory and provides composers and
theorists with the re-ordering scheme that links all AISs together by chains of
relations.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:40:57 GMT""}]","2020-06-11"
"2006.05008","Chrysoula Tsogka","Tom\'a\v{s} Roub\'i\v{c}ek and Chrysoula Tsogka","Staggered explicit-implicit time-discretization for elastodynamics with
  dissipative internal variables","arXiv admin note: substantial text overlap with arXiv:1903.11654",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An extension of the two-step staggered time discretization of linear
elastodynamics in stress-velocity form to systems involving internal variables
subjected to a possibly non-linear dissipative evolution is proposed. The
original scheme is thus enhanced by another step for the internal variables
which, in general, is implicit, although even this step might be explicit if no
spatial gradients of the internal variables are involved. Using an abstract
Banach-space formulation, a-priori estimates and convergence are proved under a
CFL condition. The developed three-step scheme finds applications in various
problems of continuum mechanics at small strain. Here, we consider in
particular plasticity, viscoelasticity (creep), diffusion in poroelastic media,
and damage.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:44:46 GMT""}]","2020-06-11"
"2006.05009","Jiahua Liu","Shi Yu, Jiahua Liu, Jingqin Yang, Chenyan Xiong, Paul Bennett,
  Jianfeng Gao, Zhiyuan Liu","Few-Shot Generative Conversational Query Rewriting","Accepted by SIGIR 2020",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conversational query rewriting aims to reformulate a concise conversational
query to a fully specified, context-independent query that can be effectively
handled by existing information retrieval systems. This paper presents a
few-shot generative approach to conversational query rewriting. We develop two
methods, based on rules and self-supervised learning, to generate weak
supervision data using large amounts of ad hoc search sessions, and to
fine-tune GPT-2 to rewrite conversational queries. On the TREC Conversational
Assistance Track, our weakly supervised GPT-2 rewriter improves the
state-of-the-art ranking accuracy by 12%, only using very limited amounts of
manual query rewrites. In the zero-shot learning setting, the rewriter still
gives a comparable result to previous state-of-the-art systems. Our analyses
reveal that GPT-2 effectively picks up the task syntax and learns to capture
context dependencies, even for hard cases that involve group references and
long-turn dependencies.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:47:58 GMT""}]","2020-06-11"
"2006.05010","Qianyu Liu","Qianyu Liu, Chiew Foong Kwong, Sun Wei, Sijia Zhou, Lincan Li","Reinforcement Learning-Based Joint Self-Optimisation Method for the
  Fuzzy Logic Handover Algorithm in 5G HetNets",,,,,"cs.NI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  5G heterogeneous networks (HetNets) can provide higher network coverage and
system capacity to the user by deploying massive small base stations (BSs)
within the 4G macro system. However, the large-scale deployment of small BSs
significantly increases the complexity and workload of network maintenance and
optimisation. The current handover (HO) triggering mechanism A3 event was
designed only for mobility management in the macro system. Directly
implementing A3 in 5G-HetNets may degrade the user mobility robustness.
Motivated by the concept of self-organisation networks (SON), this study
developed a self-optimised triggering mechanism to enable automated network
maintenance and enhance user mobility robustness in 5G-HetNets. The proposed
method integrates the advantages of subtractive clustering and Q-learning
frameworks into the conventional fuzzy logic-based HO algorithm (FLHA).
Subtractive clustering is first adopted to generate a membership function (MF)
for the FLHA to enable FLHA with the self-configuration feature. Subsequently,
Q-learning is utilised to learn the optimal HO policy from the environment as
fuzzy rules that empower the FLHA with a self-optimisation function. The FLHA
with SON functionality also overcomes the limitations of the conventional FLHA
that must rely heavily on professional experience to design. The simulation
results show that the proposed self-optimised FLHA can effectively generate MF
and fuzzy rules for the FLHA. By comparing with conventional triggering
mechanisms, the proposed approach can decrease the HO, ping-pong HO, and HO
failure ratios by approximately 91%, 49%, and 97.5% while improving network
throughput and latency by 8% and 35%, respectively.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:52:57 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 04:31:20 GMT""},{""version"":""v3"",""created"":""Sat, 27 Feb 2021 07:26:07 GMT""}]","2021-03-02"
"2006.05011","Etienne Dubeau","Etienne Dubeau, Mathieu Garon, Benoit Debaque, Raoul de Charette,
  Jean-Fran\c{c}ois Lalonde","RGB-D-E: Event Camera Calibration for Fast 6-DOF Object Tracking","9 pages, 9 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Augmented reality devices require multiple sensors to perform various tasks
such as localization and tracking. Currently, popular cameras are mostly
frame-based (e.g. RGB and Depth) which impose a high data bandwidth and power
usage. With the necessity for low power and more responsive augmented reality
systems, using solely frame-based sensors imposes limits to the various
algorithms that needs high frequency data from the environement. As such,
event-based sensors have become increasingly popular due to their low power,
bandwidth and latency, as well as their very high frequency data acquisition
capabilities. In this paper, we propose, for the first time, to use an
event-based camera to increase the speed of 3D object tracking in 6 degrees of
freedom. This application requires handling very high object speed to convey
compelling AR experiences. To this end, we propose a new system which combines
a recent RGB-D sensor (Kinect Azure) with an event camera (DAVIS346). We
develop a deep learning approach, which combines an existing RGB-D network
along with a novel event-based network in a cascade fashion, and demonstrate
that our approach significantly improves the robustness of a state-of-the-art
frame-based 6-DOF object tracker using our RGB-D-E pipeline.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:55:48 GMT""},{""version"":""v2"",""created"":""Wed, 5 Aug 2020 20:41:29 GMT""}]","2020-08-07"
"2006.05012","Rasha Abbasi Dr.","R.U. Abbasi, M. Abe, T. Abu-Zayyad, M. Allen, R. Azuma, E.
  Barcikowski, J.W. Belz, D.R. Bergman, S.A. Blake, R. Cady, B.G. Cheon, J.
  Chiba, M. Chikawa, A. di Matteo, T. Fujii, K. Fujisue, K. Fujita, R.
  Fujiwara, M. Fukushima, G. Furlich, W. Hanlon, M. Hayashi, N. Hayashida, K.
  Hibino, R. Higuchi, K. Honda, D. Ikeda, T. Inadomi, N. Inoue, T. Ishii, R.
  Ishimori, H. Ito, D. Ivanov, H. Iwakura, H.M. Jeong, S. Jeong, C.C.H. Jui, K.
  Kadota, F. Kakimoto, O. Kalashev, K. Kasahara, S. Kasami, H. Kawai, S.
  Kawakami, S. Kawana, K. Kawata, E. Kido, H.B. Kim, J.H. Kim, J.H. Kim, M.H.
  Kim, S.W. Kim, S. Kishigami, V. Kuzmin, M. Kuznetsov, Y.J. Kwon, K.H. Lee, B.
  Lubsandorzhiev, J.P. Lundquist, K. Machida, H. Matsumiya, T. Matsuyama, J.N.
  Matthews, R. Mayta, M. Minamino, K. Mukai, I. Myers, S. Nagataki, K. Nakai,
  R. Nakamura, T. Nakamura, Y. Nakamura, Y. Nakamura, T. Nonaka, H. Oda, S.
  Ogio, M. Ohnishi, H. Ohoka, Y. Oku, T. Okuda, Y. Omura, M. Ono, R. Onogi, A.
  Oshima, S. Ozawa, I.H. Park, M.S. Pshirkov, J. Remington, D.C. Rodriguez, G.
  Rubtsov, D. Ryu, H. Sagawa, R. Sahara, Y. Saito, N. Sakaki, T. Sako, N.
  Sakurai, K. Sano, T. Seki, K. Sekino, P.D. Shah, F. Shibata, T. Shibata, H.
  Shimodaira, B.K. Shin, H.S. Shin, J.D. Smith, P. Sokolsky, N. Sone, B.T.
  Stokes, T.A. Stroman, T. Suzawa, Y. Takagi, Y. Takahashi, M. Takamura, M.
  Takeda, R. Takeishi, A. Taketa, M. Takita, Y. Tameda, H. Tanaka, K. Tanaka,
  M. Tanaka, Y. Tanoue, S.B. Thomas, G.B. Thomson, P. Tinyakov, I. Tkachev, H.
  Tokuno, T. Tomida, S. Troitsky, Y. Tsunesada, Y. Uchihori, S. Udo, T. Uehama,
  F. Urban, T. Wong, K. Yada, M. Yamamoto, K. Yamazaki, J. Yang, K. Yashiro, M.
  Yosei, Y. Zhezher, Z. Zundel","Measurement of the Proton-Air Cross Section with Telescope Array's Black
  Rock Mesa and Long Ridge Fluorescence Detectors, and Surface Array in Hybrid
  Mode",,"Phys. Rev. D 102, 062004 (2020)","10.1103/PhysRevD.102.062004",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultra high energy cosmic rays provide the highest known energy source in the
universe to measure proton cross sections. Though conditions for collecting
such data are less controlled than an accelerator environment, current
generation cosmic ray observatories have large enough exposures to collect
significant statistics for a reliable measurement for energies above what can
be attained in the lab. Cosmic ray measurements of cross section use
atmospheric calorimetry to measure depth of air shower maximum
($X_{\mathrm{max}}$), which is related to the primary particle's energy and
mass. The tail of the $X_{\mathrm{max}}$ distribution is assumed to be
dominated by showers generated by protons, allowing measurement of the
inelastic proton-air cross section. In this work the proton-air inelastic cross
section measurement, $\sigma^{\mathrm{inel}}_{\mathrm{p-air}}$, using data
observed by Telescope Array's Black Rock Mesa and Long Ridge fluorescence
detectors and surface detector array in hybrid mode is presented.
$\sigma^{\mathrm{inel}}_{\mathrm{p-air}}$ is observed to be $520.1 \pm
35.8$[Stat.] $^{+25.0}_{-40}$[Sys.]~mb at $\sqrt{s} = 73$ TeV. The total
proton-proton cross section is subsequently inferred from Glauber formalism and
is found to be $\sigma^{\mathrm{tot}}_{\mathrm{pp}} = 139.4 ^{+23.4}_{-21.3}$
[Stat.]$ ^{+15.0}_{-24.0}$[Sys.]~mb.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:01:17 GMT""}]","2020-09-23"
"2006.05013","Zhenyu Liao","Zhenyu Liao, Romain Couillet, Michael W. Mahoney","A Random Matrix Analysis of Random Fourier Features: Beyond the Gaussian
  Kernel, a Precise Phase Transition, and the Corresponding Double Descent","NeurIPS 2020","Advances in Neural Information Processing Systems (NeurIPS 2020)
  33:13939-13950; Journal of Statistical Mechanics: Theory and Experiment,
  Volume 2021, December 2021","10.1088/1742-5468/ac3a77",,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article characterizes the exact asymptotics of random Fourier feature
(RFF) regression, in the realistic setting where the number of data samples
$n$, their dimension $p$, and the dimension of feature space $N$ are all large
and comparable. In this regime, the random RFF Gram matrix no longer converges
to the well-known limiting Gaussian kernel matrix (as it does when $N \to
\infty$ alone), but it still has a tractable behavior that is captured by our
analysis. This analysis also provides accurate estimates of training and test
regression errors for large $n,p,N$. Based on these estimates, a precise
characterization of two qualitatively different phases of learning, including
the phase transition between them, is provided; and the corresponding double
descent test error curve is derived from this phase transition behavior. These
results do not depend on strong assumptions on the data distribution, and they
perfectly match empirical results on real-world data sets.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:05:40 GMT""},{""version"":""v2"",""created"":""Sat, 19 Dec 2020 06:28:07 GMT""}]","2022-01-11"
"2006.05014","Adewale Akinfaderin","Adewale Akinfaderin","HausaMT v1.0: Towards English-Hausa Neural Machine Translation","Accepted at 4th Widening NLP Workshop, Annual Meeting of the
  Association for Computational Linguistics, ACL 2020",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Neural Machine Translation (NMT) for low-resource languages suffers from low
performance because of the lack of large amounts of parallel data and language
diversity. To contribute to ameliorating this problem, we built a baseline
model for English-Hausa machine translation, which is considered a task for
low-resource language. The Hausa language is the second largest Afro-Asiatic
language in the world after Arabic and it is the third largest language for
trading across a larger swath of West Africa countries, after English and
French. In this paper, we curated different datasets containing Hausa-English
parallel corpus for our translation. We trained baseline models and evaluated
the performance of our models using the Recurrent and Transformer
encoder-decoder architecture with two tokenization approaches: standard
word-level tokenization and Byte Pair Encoding (BPE) subword tokenization.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:08:03 GMT""},{""version"":""v2"",""created"":""Sun, 14 Jun 2020 04:35:37 GMT""}]","2020-06-16"
"2006.05015","Weixing Liu","Weixing Liu, Jun Liu and Bin Luo","Can Synthetic Data Improve Object Detection Results for Remote Sensing
  Images?","5 pages, 5 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning approaches require enough training samples to perform well, but
it is a challenge to collect enough real training data and label them manually.
In this letter, we propose the use of realistic synthetic data with a wide
distribution to improve the performance of remote sensing image aircraft
detection. Specifically, to increase the variability of synthetic data, we
randomly set the parameters during rendering, such as the size of the instance
and the class of background images. In order to make the synthetic images more
realistic, we then refine the synthetic images at the pixel level using
CycleGAN with real unlabeled images. We also fine-tune the model with a small
amount of real data, to obtain a higher accuracy. Experiments on NWPU VHR-10,
UCAS-AOD and DIOR datasets demonstrate that the proposed method can be applied
for augmenting insufficient real data.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:23:22 GMT""}]","2020-06-11"
"2006.05016","Peter Vaillancourt","Peter Vaillancourt, Bennett Wineholt, Brandon Barker, Plato
  Deliyannis, Jackie Zheng, Akshay Suresh, Adam Brazier, Rich Knepper, Rich
  Wolski","Reproducible and Portable Workflows for Scientific Computing and HPC in
  the Cloud","Accepted for publication in the ACM conference proceedings for
  Practice and Experience in Advanced Research Computing (PEARC '20)",,"10.1145/3311790.3396659",,"cs.DC cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increasing availability of cloud computing services for science has
changed the way scientific code can be developed, deployed, and run. Many
modern scientific workflows are capable of running on cloud computing
resources. Consequently, there is an increasing interest in the scientific
computing community in methods, tools, and implementations that enable moving
an application to the cloud and simplifying the process, and decreasing the
time to meaningful scientific results. In this paper, we have applied the
concepts of containerization for portability and multi-cloud automated
deployment with industry-standard tools to three scientific workflows. We show
how our implementations provide reduced complexity to portability of both the
applications themselves, and their deployment across private and public clouds.
Each application has been packaged in a Docker container with its dependencies
and necessary environment setup for production runs. Terraform and Ansible have
been used to automate the provisioning of compute resources and the deployment
of each scientific application in a Multi-VM cluster. Each application has been
deployed on the AWS and Aristotle Cloud Federation platforms. Variation in data
management constraints, Multi-VM MPI communication, and embarrassingly parallel
instance deployments were all explored and reported on. We thus present a
sample of scientific workflows that can be simplified using the tools and our
proposed implementation to deploy and run in a variety of cloud environments.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:29:53 GMT""}]","2020-06-11"
"2006.05017","Youssef Moulane","Y. Moulane, E. Jehin, P. Rousselot, J. Manfroid, Y. Shinnaka, F. J.
  Pozuelos, D. Hutsem\'ekers, C. Opitom, B. Yang, and Z. Benkhaldoun","Photometry and high-resolution spectroscopy of comet
  21P/Giacobini-Zinner during its 2018 apparition","14 pages, 11 figures, Accepted for publication in A&A","A&A 640, A54 (2020)","10.1051/0004-6361/202037997",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on photometry and high resolution spectroscopy of the chemically
peculiar Jupiter-family Comet (hereafter JFC) 21P/Giacobini-Zinner. Comet 21P
is a well known member of the carbon-chain depleted family but displays also a
depletion of amines. We monitored continuously the comet over more than seven
months with the two TRAPPIST telescopes (TN and TS), covering a large
heliocentric distance range from 1.60 au inbound to 2.10 au outbound with a
perihelion at 1.01 au on September 10, 2018. We computed and followed the
evolution of the dust (represented by Af$\rho$) and gas production rates of the
daughter species OH, NH, CN, C$_3$, and C$_2$ and their relative abundances to
OH and to CN over the comet orbit. We compared them to those measured in the
previous apparitions. The activity of the comet and its water production rate
reached a maximum of (3.72$\pm$0.07)$\times$10$^{28}$ molec/s on August 17,
2018 (r$_h$=1.07 au), 24 days before perihelion. The peak value of A(0)f$\rho$
was reached on the same date (1646$\pm$13) cm in the red filter. The abundance
ratios of the various species are remarkably constant over a large range of
heliocentric distances, before and after perihelion, showing a high level of
homogeneity of the ices in the surface of the nucleus. The behaviour and level
of the activity of the comet is also remarkably similar over the last five
orbits. About the coma dust colour, 21P shows reflectively gradients similar to
JFCs. We obtained a high resolution spectrum of 21P with UVES at ESO VLT one
week after perihelion. Using the CN B-X (0,0) violet band, we measured
$^{12}$C/$^{13}$C and $^{14}$N/$^{15}$N isotopic ratios of 100$\pm$10 and
145$\pm$10, respectively, both in very good agreement with what is usually
found in comets.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:36:38 GMT""}]","2020-08-12"
"2006.05018","Xukun Li","Wei Wu, Yu Shi, Xukun Li, Yukun Zhou, Peng Du, Shuangzhi Lv, Tingbo
  Liang, Jifang Sheng","Deep learning to estimate the physical proportion of infected region of
  lung for COVID-19 pneumonia with CT image set",,,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Utilizing computed tomography (CT) images to quickly estimate the severity of
cases with COVID-19 is one of the most straightforward and efficacious methods.
Two tasks were studied in this present paper. One was to segment the mask of
intact lung in case of pneumonia. Another was to generate the masks of regions
infected by COVID-19. The masks of these two parts of images then were
converted to corresponding volumes to calculate the physical proportion of
infected region of lung. A total of 129 CT image set were herein collected and
studied. The intrinsic Hounsfiled value of CT images was firstly utilized to
generate the initial dirty version of labeled masks both for intact lung and
infected regions. Then, the samples were carefully adjusted and improved by two
professional radiologists to generate the final training set and test
benchmark. Two deep learning models were evaluated: UNet and 2.5D UNet. For the
segment of infected regions, a deep learning based classifier was followed to
remove unrelated blur-edged regions that were wrongly segmented out such as air
tube and blood vessel tissue etc. For the segmented masks of intact lung and
infected regions, the best method could achieve 0.972 and 0.757 measure in mean
Dice similarity coefficient on our test benchmark. As the overall proportion of
infected region of lung, the final result showed 0.961 (Pearson's correlation
coefficient) and 11.7% (mean absolute percent error). The instant proportion of
infected regions of lung could be used as a visual evidence to assist clinical
physician to determine the severity of the case. Furthermore, a quantified
report of infected regions can help predict the prognosis for COVID-19 cases
which were scanned periodically within the treatment cycle.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:38:40 GMT""}]","2020-06-11"
"2006.05019","Ekram Hossain","Mohammad Salehi and Ekram Hossain","Handover Rate and Sojourn Time Analysis in Mobile Drone-Assisted
  Cellular Networks",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To improve capacity and overcome some of the limitations of cellular wireless
networks, drones with aerial base stations can be deployed to assist the
terrestrial cellular wireless networks. The mobility of drones allows flexible
network reconfiguration to adapt to dynamic traffic and channel conditions.
However, this is achieved at the expense of more handovers since even a static
user may experience a handover when the drones are mobile. In this letter, we
provide an exact analysis of the handover rate and sojourn time (time between
two subsequent handovers) for a network of drone base stations. We also show
that among different speed distributions with the same mean, the handover rate
is minimum when all drone base stations move with same speed.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:42:58 GMT""}]","2020-06-11"
"2006.05020","Drew Yarger","Drew Yarger, Stilian Stoev, Tailen Hsing","A functional-data approach to the Argo data",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Argo data is a modern oceanography dataset that provides unprecedented
global coverage of temperature and salinity measurements in the upper 2,000
meters of depth of the ocean. We study the Argo data from the perspective of
functional data analysis (FDA). We develop spatio-temporal functional kriging
methodology for mean and covariance estimation to predict temperature and
salinity at a fixed location as a smooth function of depth. By combining tools
from FDA and spatial statistics, including smoothing splines, local regression,
and multivariate spatial modeling and prediction, our approach provides
advantages over current methodology that consider pointwise estimation at fixed
depths. Our approach naturally leverages the irregularly-sampled data in space,
time, and depth to fit a space-time functional model for temperature and
salinity. The developed framework provides new tools to address fundamental
scientific problems involving the entire upper water column of the oceans such
as the estimation of ocean heat content, stratification, and thermohaline
oscillation. For example, we show that our functional approach yields more
accurate ocean heat content estimates than ones based on discrete integral
approximations in pressure. Further, using the derivative function estimates,
we obtain a new product of a global map of the mixed layer depth, a key
component in the study of heat absorption and nutrient circulation in the
oceans. The derivative estimates also reveal evidence for density inversions in
areas distinguished by mixing of particularly different water masses.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:43:17 GMT""},{""version"":""v2"",""created"":""Sun, 9 May 2021 23:22:33 GMT""}]","2021-05-11"
"2006.05021","Tirthankar Dasgupta","Mert Y. Sengul, Yao Song, Linglin He, Adri C. T. van Duin, Ying Hung
  and Tirthankar Dasgupta","CLAIMED: A CLAssification-Incorporated Minimum Energy Design to explore
  a multivariate response surface with feasibility constraints",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the problem of optimization of force-field systems in physics
using large-scale computer simulations, we consider exploration of a
deterministic complex multivariate response surface. The objective is to find
input combinations that generate output close to some desired or ""target""
vector. In spite of reducing the problem to exploration of the input space with
respect to a one-dimensional loss function, the search is nontrivial and
challenging due to infeasible input combinations, high dimensionalities of the
input and output space and multiple ""desirable"" regions in the input space and
the difficulty of emulating the objective function well with a surrogate model.
We propose an approach that is based on combining machine learning techniques
with smart experimental design ideas to locate multiple good regions in the
input space.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:44:31 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 03:55:30 GMT""}]","2021-09-15"
"2006.05022","Qinqing Zheng","Arun Kumar Kuchibhotla and Qinqing Zheng","Near-Optimal Confidence Sequences for Bounded Random Variables","Accepted to ICML 2021",,,,"math.ST cs.AI cs.LG stat.AP stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many inference problems, such as sequential decision problems like A/B
testing, adaptive sampling schemes like bandit selection, are often online in
nature. The fundamental problem for online inference is to provide a sequence
of confidence intervals that are valid uniformly over the growing-into-infinity
sample sizes. To address this question, we provide a near-optimal confidence
sequence for bounded random variables by utilizing Bentkus' concentration
results. We show that it improves on the existing approaches that use the
Cram{\'e}r-Chernoff technique such as the Hoeffding, Bernstein, and Bennett
inequalities. The resulting confidence sequence is confirmed to be favorable in
both synthetic coverage problems and an application to adaptive stopping
algorithms.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:50:01 GMT""},{""version"":""v2"",""created"":""Sun, 14 Feb 2021 20:35:34 GMT""},{""version"":""v3"",""created"":""Thu, 3 Jun 2021 20:43:21 GMT""}]","2021-06-07"
"2006.05023","Samson Zhou","Jeremiah Blocki, Ben Harsha, Samson Zhou","On the Economics of Offline Password Cracking","IEEE Symposium on Security and Privacy (S&P) 2018",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop an economic model of an offline password cracker which allows us
to make quantitative predictions about the fraction of accounts that a rational
password attacker would crack in the event of an authentication server breach.
We apply our economic model to analyze recent massive password breaches at
Yahoo!, Dropbox, LastPass and AshleyMadison. All four organizations were using
key-stretching to protect user passwords. In fact, LastPass' use of
PBKDF2-SHA256 with $10^5$ hash iterations exceeds 2017 NIST minimum
recommendation by an order of magnitude. Nevertheless, our analysis paints a
bleak picture: the adopted key-stretching levels provide insufficient
protection for user passwords. In particular, we present strong evidence that
most user passwords follow a Zipf's law distribution, and characterize the
behavior of a rational attacker when user passwords are selected from a Zipf's
law distribution. We show that there is a finite threshold which depends on the
Zipf's law parameters that characterizes the behavior of a rational attacker --
if the value of a cracked password (normalized by the cost of computing the
password hash function) exceeds this threshold then the adversary's optimal
strategy is always to continue attacking until each user password has been
cracked. In all cases (Yahoo!, Dropbox, LastPass and AshleyMadison) we find
that the value of a cracked password almost certainly exceeds this threshold
meaning that a rational attacker would crack all passwords that are selected
from the Zipf's law distribution (i.e., most user passwords). This prediction
holds even if we incorporate an aggressive model of diminishing returns for the
attacker (e.g., the total value of $500$ million cracked passwords is less than
$100$ times the total value of $5$ million passwords).
  See paper for full abstract.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 02:53:13 GMT""}]","2020-06-11"
"2006.05024","Pin-Jui Hsu","Guan-Yu Chen, Angus Huang, Yen-Hui Lin, Chia-Ju Chen, Deng-Sung Lin,
  Po-Yao Chang, Horng-Tay Jeng, Gustav Bihlmayer and Pin-Jui Hsu","Orbital-enhanced Warping Effect in
  P\textsubscript{x},P\textsubscript{y}-derived Rashba Spin Splitting of
  Monatomic Bismuth Surface Alloy Surface Alloy",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spin-split Rashba bands have been exploited to efficiently control the spin
degree of freedom of moving electrons, which possesses a great potential in
frontier applications of designing spintronic devices and processing spin-based
information. Given that intrinsic breaking of inversion symmetry and sizeable
spin-orbit interaction, two-dimensional (2D) surface alloys formed by heavy
metal elements exhibit a pronounced Rashba-type spin splitting of the surface
states. Here, we have revealed the essential role of atomic orbital symmetry in
the hexagonally warped Rashba spin-split surface state of
$\sqrt{3}\times\sqrt{3} R30^{\circ}$ BiCu$_{2}$ monatomic alloy by scanning
tunneling spectroscopy (STS) and density functional theory (DFT). From
$\mathrm{d}I/\mathrm{d}U$ spectra and calculated band structures, three
hole-like Rashba-split bands hybridized from distinct orbital symmetries have
been identified in the unoccupied energy region. Because of the hexagonally
deformed Fermi surface, quasi-particle interference (QPI) mappings have
resolved scattering channels opened from interband transitions of
\textit{p$_{x},$p$_{y}$}($m_{j}=1/2$) band. In contrast to the
\textit{s,p$_{z}$}-derived band, the hexagonal warping predominately is
accompanied by substantial out-of-plane spin polarization $S_{z}$ up to 24\% in
the dispersion of \textit{p$_{x}$,p$_{y}$}($m_{j}=1/2$) band with an in-plane
orbital symmetry.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:02:00 GMT""}]","2020-06-11"
"2006.05025","Yucai Hu","Yucai Hu, Haiyi Liang","Folding Simulation of Rigid Origami with Lagrange Multiplier Method",,,,,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Origami crease patterns are folding paths that transform flat sheets into
spatial objects. Origami patterns with a single degree of freedom (DOF) have
creases that fold simultaneously. More often, several substeps are required to
sequentially fold origami of multiple DOFs, and at each substep some creases
fold and the rest remain fixed. In this study, we combine the loop closure
constraint with Lagrange multiplier method to account for the sequential
folding of rigid origami of multiple DOFs, by controlling the rotation of
different sets of creases during successive substeps. This strategy is also
applicable to model origami-inspired devices, where creases may be equipped
with rotational springs and the folding process involves elastic energy.
Several examples are presented to verify the proposed algorithms in tracing the
sequential folding process as well as searching the equilibrium configurations
of origami with rotational springs.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:02:34 GMT""}]","2020-06-11"
"2006.05026","Cong Shen","Cong Shen, Zhiyang Wang, Sofia S. Villar, and Mihaela van der Schaar","Learning for Dose Allocation in Adaptive Clinical Trials with Safety
  Constraints","Accepted to the 37th International Conference on Machine Learning
  (ICML 2020)",,,,"cs.LG stat.AP stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phase I dose-finding trials are increasingly challenging as the relationship
between efficacy and toxicity of new compounds (or combination of them) becomes
more complex. Despite this, most commonly used methods in practice focus on
identifying a Maximum Tolerated Dose (MTD) by learning only from toxicity
events. We present a novel adaptive clinical trial methodology, called Safe
Efficacy Exploration Dose Allocation (SEEDA), that aims at maximizing the
cumulative efficacies while satisfying the toxicity safety constraint with high
probability. We evaluate performance objectives that have operational meanings
in practical clinical trials, including cumulative efficacy,
recommendation/allocation success probabilities, toxicity violation
probability, and sample efficiency. An extended SEEDA-Plateau algorithm that is
tailored for the increase-then-plateau efficacy behavior of molecularly
targeted agents (MTA) is also presented. Through numerical experiments using
both synthetic and real-world datasets, we show that SEEDA outperforms
state-of-the-art clinical trial designs by finding the optimal dose with higher
success rate and fewer patients.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:06:45 GMT""},{""version"":""v2"",""created"":""Mon, 15 Jun 2020 16:41:45 GMT""}]","2020-06-16"
"2006.05027","Sanket Kalamkar","Sanket S. Kalamkar and Fuad M. Abinader Jr. and Fran\c{c}ois Baccelli
  and Andrea S. Marcano Fani and and Luis G. Uzeda Garcia","Stochastic Geometry-Based Modeling and Analysis of Beam Management in 5G","This is a work in progress. Your comments are welcome. 9 pages, 6
  figures",,,,"cs.IT cs.NI math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Beam management is central in the operation of dense 5G cellular networks.
Focusing the energy radiated to mobile terminals (MTs) by increasing the number
of beams per cell increases signal power and decreases interference, and has
hence the potential to bring major improvements on area spectral efficiency
(ASE). This benefit, however, comes with unavoidable overheads that increase
with the number of beams and the MT speed. This paper proposes a first
system-level stochastic geometry model encompassing major aspects of the beam
management problem: frequencies, antennas, and propagation; physical layer,
wireless links, and coding; network geometry, interference, and resource
sharing; sensing, signaling, and mobility management. This model leads to a
simple analytical expression for the effective ASE that the typical user gets
in this context. This in turn allows one to find, for a wide variety of 5G
network scenarios including millimeter wave (mmWave) and sub-6 GHz, the number
of beams per cell that offers the best global trade-off between these benefits
and costs. We finally provide numerical results that discuss the effects of
different systemic trade-offs and performances of mmWave and sub-6 GHz 5G
deployments.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:10:05 GMT""},{""version"":""v2"",""created"":""Mon, 14 Sep 2020 15:56:28 GMT""}]","2020-09-15"
"2006.05028","Slobodan Mitrovi\'c","Piotr Indyk, Frederik Mallmann-Trenn, Slobodan Mitrovi\'c, Ronitt
  Rubinfeld","Online Page Migration with ML Advice",,,,,"cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider online algorithms for the {\em page migration problem} that use
predictions, potentially imperfect, to improve their performance. The best
known online algorithms for this problem, due to Westbrook'94 and Bienkowski et
al'17, have competitive ratios strictly bounded away from 1. In contrast, we
show that if the algorithm is given a prediction of the input sequence, then it
can achieve a competitive ratio that tends to $1$ as the prediction error rate
tends to $0$. Specifically, the competitive ratio is equal to $1+O(q)$, where
$q$ is the prediction error rate. We also design a ``fallback option'' that
ensures that the competitive ratio of the algorithm for {\em any} input
sequence is at most $O(1/q)$. Our result adds to the recent body of work that
uses machine learning to improve the performance of ``classic'' algorithms.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:15:34 GMT""}]","2020-06-11"
"2006.05029","Eddy Keming Chen","Eddy Keming Chen","From Time Asymmetry to Quantum Entanglement: The Humean Unification","Forthcoming in No\^us. This is the penultimate version","No\^us, first published on 23 September 2020","10.1111/nous.12355",,"physics.hist-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  Two of the most difficult problems in the foundations of physics are (1) what
gives rise to the arrow of time and (2) what the ontology of quantum mechanics
is. I propose a unified 'Humean' solution to the two problems. Humeanism allows
us to incorporate the Past Hypothesis and the Statistical Postulate into the
best system, which we then use to simplify the quantum state of the universe.
This enables us to confer the nomological status to the quantum state in a way
that adds no significant complexity to the best system and solves the
""supervenient-kind problem"" facing the original version of the Past Hypothesis.
We call the resultant theory the Humean unification. It provides a unified
explanation of time asymmetry and quantum entanglement. On this theory, what
gives rise to time's arrow is also responsible for quantum phenomena. The new
theory has a separable mosaic, a best system that is simple and non-vague, less
tension between quantum mechanics and special relativity, and a higher degree
of theoretical and dynamical unity. The Humean unification leads to new
insights that can be useful to Humeans and non-Humeans alike.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:17:04 GMT""},{""version"":""v2"",""created"":""Fri, 11 Sep 2020 22:30:55 GMT""}]","2021-10-25"
"2006.05030","Mohammad Hamghalam","Mohammad Hamghalam, Baiying Lei, Tianfu Wang","High Tissue Contrast MRI Synthesis Using Multi-Stage Attention-GAN for
  Glioma Segmentation","Will be published in Thirty-Fourth AAAI Conference on Artificial
  Intelligence (AAAI-2020)",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic resonance imaging (MRI) provides varying tissue contrast images of
internal organs based on a strong magnetic field. Despite the non-invasive
advantage of MRI in frequent imaging, the low contrast MR images in the target
area make tissue segmentation a challenging problem. This paper demonstrates
the potential benefits of image-to-image translation techniques to generate
synthetic high tissue contrast (HTC) images. Notably, we adopt a new cycle
generative adversarial network (CycleGAN) with an attention mechanism to
increase the contrast within underlying tissues. The attention block, as well
as training on HTC images, guides our model to converge on certain tissues. To
increase the resolution of HTC images, we employ multi-stage architecture to
focus on one particular tissue as a foreground and filter out the irrelevant
background in each stage. This multi-stage structure also alleviates the common
artifacts of the synthetic images by decreasing the gap between source and
target domains. We show the application of our method for synthesizing HTC
images on brain MR scans, including glioma tumor. We also employ HTC MR images
in both the end-to-end and two-stage segmentation structure to confirm the
effectiveness of these images. The experiments over three competitive
segmentation baselines on BraTS 2018 dataset indicate that incorporating the
synthetic HTC images in the multi-modal segmentation framework improves the
average Dice scores 0.8%, 0.6%, and 0.5% on the whole tumor, tumor core, and
enhancing tumor, respectively, while eliminating one real MRI sequence from the
segmentation procedure.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:21:30 GMT""}]","2020-06-11"
"2006.05031","MohammadNoor Injadat","MohammadNoor Injadat, Abdallah Moubayed, Ali Bou Nassif, Abdallah
  Shami","Multi-split Optimized Bagging Ensemble Model Selection for Multi-class
  Educational Data Mining","29 Pages, 13 Figures, 19 Tables, Accepted in Springer's Applied
  Intelligence",,"10.1007/s10489-020-01776-3",,"cs.CY cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Predicting students' academic performance has been a research area of
interest in recent years with many institutions focusing on improving the
students' performance and the education quality. The analysis and prediction of
students' performance can be achieved using various data mining techniques.
Moreover, such techniques allow instructors to determine possible factors that
may affect the students' final marks. To that end, this work analyzes two
different undergraduate datasets at two different universities. Furthermore,
this work aims to predict the students' performance at two stages of course
delivery (20% and 50% respectively). This analysis allows for properly choosing
the appropriate machine learning algorithms to use as well as optimize the
algorithms' parameters. Furthermore, this work adopts a systematic multi-split
approach based on Gini index and p-value. This is done by optimizing a suitable
bagging ensemble learner that is built from any combination of six potential
base machine learning algorithms. It is shown through experimental results that
the posited bagging ensemble models achieve high accuracy for the target group
for both datasets.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:22:33 GMT""}]","2020-06-11"
"2006.05032","Kangjie Chen","Kangjie Chen, Shangwei Guo, Tianwei Zhang, Xiaofei Xie and Yang Liu","Stealing Deep Reinforcement Learning Models for Fun and Profit",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents the first model extraction attack against Deep
Reinforcement Learning (DRL), which enables an external adversary to precisely
recover a black-box DRL model only from its interaction with the environment.
Model extraction attacks against supervised Deep Learning models have been
widely studied. However, those techniques cannot be applied to the
reinforcement learning scenario due to DRL models' high complexity,
stochasticity and limited observable information. We propose a novel
methodology to overcome the above challenges. The key insight of our approach
is that the process of DRL model extraction is equivalent to imitation
learning, a well-established solution to learn sequential decision-making
policies. Based on this observation, our methodology first builds a classifier
to reveal the training algorithm family of the targeted black-box DRL model
only based on its predicted actions, and then leverages state-of-the-art
imitation learning techniques to replicate the model from the identified
algorithm family. Experimental results indicate that our methodology can
effectively recover the DRL models with high fidelity and accuracy. We also
demonstrate two use cases to show that our model extraction attack can (1)
significantly improve the success rate of adversarial attacks, and (2) steal
DRL models stealthily even they are protected by DNN watermarks. These pose a
severe threat to the intellectual property and privacy protection of DRL
applications.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:24:35 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 08:45:18 GMT""}]","2020-12-23"
"2006.05033","Seongbin Oh","Seongbin Oh, Dongseok Kwon, Gyuho Yeom, Won-Mook Kang, Soochang Lee,
  Sung Yun Woo, Jang Saeng Kim, Min Kyu Park and Jong-Ho Lee","Hardware Implementation of Spiking Neural Networks Using
  Time-To-First-Spike Encoding",,,"10.1109/ACCESS.2022.3149577",,"cs.NE","http://creativecommons.org/licenses/by/4.0/","  Hardware-based spiking neural networks (SNNs) are regarded as promising
candidates for the cognitive computing system due to low power consumption and
highly parallel operation. In this work, we train the SNN in which the firing
time carries information using temporal backpropagation. The temporally encoded
SNN with 512 hidden neurons showed an accuracy of 96.90% for the MNIST test
set. Furthermore, the effect of the device variation on the accuracy in
temporally encoded SNN is investigated and compared with that of the
rate-encoded network. In a hardware configuration of our SNN, NOR-type analog
memory having an asymmetric floating gate is used as a synaptic device. In
addition, we propose a neuron circuit including a refractory period generator
for temporally encoded SNN. The performance of the 2-layer neural network
consisting of synapses and proposed neurons is evaluated through circuit
simulation using SPICE. The network with 128 hidden neurons showed an accuracy
of 94.9%, a 0.1% reduction compared to that of the system simulation of the
MNIST dataset. Finally, the latency and power consumption of each block
constituting the temporal network is analyzed and compared with those of the
rate-encoded network depending on the total time step. Assuming that the total
time step number of the network is 256, the temporal network consumes 15.12
times lower power than the rate-encoded network and can make decisions 5.68
times faster.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:31:15 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 05:56:20 GMT""}]","2022-03-17"
"2006.05034","Erica Graham","E. J. Graham, N. Elhadad, D. Albers","Reduced model for female endocrine dynamics: Validation and functional
  variations",,,,,"q-bio.TO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A normally functioning menstrual cycle requires significant crosstalk between
hormones originating in ovarian and brain tissues. Reproductive hormone
dysregulation may cause abnormal function and sometimes infertility. The
inherent complexity in this endocrine system is a challenge to identifying
mechanisms of cycle disruption, particularly given the large number of unknown
parameters in existing mathematical models. We develop a new endocrine model to
limit model complexity and use simulated distributions of unknown parameters
for model analysis. By employing a comprehensive model evaluation, we identify
a collection of mechanisms that differentiate normal and abnormal phenotypes.
We also discover an intermediate phenotype--displaying relatively normal
hormone levels and cycle dynamics--that is grouped statistically with the
irregular phenotype. Results provide insight into how clinical symptoms
associated with ovulatory disruption may not be detected through hormone
measurements alone.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:34:38 GMT""},{""version"":""v2"",""created"":""Sun, 28 Aug 2022 14:46:53 GMT""}]","2022-08-30"
"2006.05035","Jie Zhao","STAR Collaboration: J. Adam, L. Adamczyk, J. R. Adams, J. K. Adkins,
  G. Agakishiev, M. M. Aggarwal, Z. Ahammed, I. Alekseev, D. M. Anderson, A.
  Aparin, E. C. Aschenauer, M. U. Ashraf, F. G. Atetalla, A. Attri, G. S.
  Averichev, V. Bairathi, K. Barish, A. Behera, R. Bellwied, A. Bhasin, J.
  Bielcik, J. Bielcikova, L. C. Bland, I. G. Bordyuzhin, J. D. Brandenburg, A.
  V. Brandin, J. Butterworth, H. Caines, M. Calder\'on de la Barca S\'anchez,
  D. Cebra, I. Chakaberia, P. Chaloupka, B. K. Chan, F-H. Chang, Z. Chang, N.
  Chankova-Bunzarova, A. Chatterjee, D. Chen, J. H. Chen, X. Chen, Z. Chen, J.
  Cheng, M. Cherney, M. Chevalier, S. Choudhury, W. Christie, X. Chu, H. J.
  Crawford, M. Csan\'ad, M. Daugherity, T. G. Dedovich, I. M. Deppner, A. A.
  Derevschikov, L. Didenko, X. Dong, J. L. Drachenberg, J. C. Dunlop, T.
  Edmonds, N. Elsey, J. Engelage, G. Eppley, R. Esha, S. Esumi, O. Evdokimov,
  A. Ewigleben, O. Eyser, R. Fatemi, S. Fazio, P. Federic, J. Fedorisin, C. J.
  Feng, Y. Feng, P. Filip, E. Finch, Y. Fisyak, A. Francisco, L. Fulek, C. A.
  Gagliardi, T. Galatyuk, F. Geurts, A. Gibson, K. Gopal, D. Grosnick, W.
  Guryn, A. I. Hamad, A. Hamed, S. Harabasz, J. W. Harris, S. He, W. He, X. H.
  He, S. Heppelmann, S. Heppelmann, N. Herrmann, E. Hoffman, L. Holub, Y. Hong,
  S. Horvat, Y. Hu, H. Z. Huang, S. L. Huang, T. Huang, X. Huang, T. J.
  Humanic, P. Huo, G. Igo, D. Isenhower, W. W. Jacobs, C. Jena, A. Jentsch, Y.
  JI, J. Jia, K. Jiang, S. Jowzaee, X. Ju, E. G. Judd, S. Kabana, M. L. Kabir,
  S. Kagamaster, D. Kalinkin, K. Kang, D. Kapukchyan, K. Kauder, H. W. Ke, D.
  Keane, A. Kechechyan, M. Kelsey, Y. V. Khyzhniak, D. P. Kiko{\l}a, C. Kim, B.
  Kimelman, D. Kincses, T. A. Kinghorn, I. Kisel, A. Kiselev, A. Kisiel, M.
  Kocan, L. Kochenda, L. K. Kosarzewski, L. Kramarik, P. Kravtsov, K. Krueger,
  N. Kulathunga Mudiyanselage, L. Kumar, R. Kunnawalkam Elayavalli, J. H.
  Kwasizur, R. Lacey, S. Lan, J. M. Landgraf, J. Lauret, A. Lebedev, R.
  Lednicky, J. H. Lee, Y. H. Leung, C. Li, W. Li, W. Li, X. Li, Y. Li, Y.
  Liang, R. Licenik, T. Lin, Y. Lin, M. A. Lisa, F. Liu, H. Liu, P. Liu, P.
  Liu, T. Liu, X. Liu, Y. Liu, Z. Liu, T. Ljubicic, W. J. Llope, R. S.
  Longacre, N. S. Lukow, S. Luo, X. Luo, G. L. Ma, L. Ma, R. Ma, Y. G. Ma, N.
  Magdy, R. Majka, D. Mallick, S. Margetis, C. Markert, H. S. Matis, J. A.
  Mazer, N. G. Minaev, S. Mioduszewski, B. Mohanty, M. M. Mondal, I. Mooney, Z.
  Moravcova, D. A. Morozov, M. Nagy, J. D. Nam, Md. Nasim, K. Nayak, D. Neff,
  J. M. Nelson, D. B. Nemes, M. Nie, G. Nigmatkulov, T. Niida, L. V. Nogach, T.
  Nonaka, A. S. Nunes, G. Odyniec, A. Ogawa, S. Oh, V. A. Okorokov, B. S. Page,
  R. Pak, A. Pandav, Y. Panebratsev, B. Pawlik, D. Pawlowska, H. Pei, C.
  Perkins, L. Pinsky, R. L. Pint\'er, J. Pluta, J. Porter, M. Posik, N. K.
  Pruthi, M. Przybycien, J. Putschke, H. Qiu, A. Quintero, S. K. Radhakrishnan,
  S. Ramachandran, R. L. Ray, R. Reed, H. G. Ritter, J. B. Roberts, O. V.
  Rogachevskiy, J. L. Romero, L. Ruan, J. Rusnak, N. R. Sahoo, H. Sako, S.
  Salur, J. Sandweiss, S. Sato, W. B. Schmidke, N. Schmitz, B. R. Schweid, F.
  Seck, J. Seger, M. Sergeeva, R. Seto, P. Seyboth, N. Shah, E. Shahaliev, P.
  V. Shanmuganathan, M. Shao, F. Shen, W. Q. Shen, S. S. Shi, Q. Y. Shou, E. P.
  Sichtermann, R. Sikora, M. Simko, J. Singh, S. Singha, N. Smirnov, W. Solyst,
  P. Sorensen, H. M. Spinka, B. Srivastava, T. D. S. Stanislaus, M. Stefaniak,
  D. J. Stewart, M. Strikhanov, B. Stringfellow, A. A. P. Suaide, M. Sumbera,
  B. Summa, X. M. Sun, X. Sun, Y. Sun, Y. Sun, B. Surrow, D. N. Svirida, P.
  Szymanski, A. H. Tang, Z. Tang, A. Taranenko, T. Tarnowsky, J. H. Thomas, A.
  R. Timmins, D. Tlusty, M. Tokarev, C. A. Tomkiel, S. Trentalange, R. E.
  Tribble, P. Tribedy, S. K. Tripathy, O. D. Tsai, Z. Tu, T. Ullrich, D. G.
  Underwood, I. Upsal, G. Van Buren, J. Vanek, A. N. Vasiliev, I. Vassiliev, F.
  Videb{\ae}k, S. Vokal, S. A. Voloshin, F. Wang, G. Wang, J. S. Wang, P. Wang,
  Y. Wang, Y. Wang, Z. Wang, J. C. Webb, P. C. Weidenkaff, L. Wen, G. D.
  Westfall, H. Wieman, S. W. Wissink, R. Witt, Y. Wu, Z. G. Xiao, G. Xie, W.
  Xie, H. Xu, N. Xu, Q. H. Xu, Y. F. Xu, Y. Xu, Z. Xu, Z. Xu, C. Yang, Q. Yang,
  S. Yang, Y. Yang, Z. Yang, Z. Ye, Z. Ye, L. Yi, K. Yip, H. Zbroszczyk, W.
  Zha, D. Zhang, S. Zhang, S. Zhang, X. P. Zhang, Y. Zhang, Y. Zhang, Z. J.
  Zhang, Z. Zhang, Z. Zhang, J. Zhao, C. Zhong, C. Zhou, X. Zhu, Z. Zhu, M.
  Zurek, M. Zyzak","Pair invariant mass to isolate background in the search for the chiral
  magnetic effect in Au+Au collisions at $\sqrt{s_{_{\rm NN}}}$= 200 GeV","PRC published version","Phys. Rev. C 106, 034908 (2022)","10.1103/PhysRevC.106.034908",,"nucl-ex hep-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quark interactions with topological gluon configurations can induce local
chirality imbalance and parity violation in quantum chromodynamics, which can
lead to the chiral magnetic effect (CME) -- an electric charge separation along
the strong magnetic field in relativistic heavy-ion collisions. The
CME-sensitive azimuthal correlator observable ($\Delta\gamma$) is contaminated
by background arising, in part, from resonance decays coupled with elliptic
anisotropy ($v_{2}$). We report here differential measurements of the
correlator as a function of the pair invariant mass ($m_{\rm inv}$) in 20-50\%
centrality Au+Au collisions at $\sqrt{s_{_{\rm NN}}}$= 200 GeV by the STAR
experiment at RHIC. Strong resonance background contributions to $\Delta\gamma$
are observed. At large $m_{\rm inv}$ where this background is significantly
reduced, the $\Delta\gamma$ value is found to be significantly smaller. An
event-shape-engineering technique is deployed to determine the $v_{2}$
background shape as a function of $m_{\rm inv}$. We extract a $v_2$-independent
and $m_{\rm inv}$-averaged signal $\Delta\gamma_{\rm sig}$ = (0.03 $\pm$ 0.06
$\pm$ 0.08) $\times10^{-4}$, or $(2\pm4\pm5)\%$ of the inclusive
$\Delta\gamma(m_{\rm inv}>0.4$ GeV/$c^2$)$ =(1.58 \pm 0.02 \pm 0.02)
\times10^{-4}$, within pion $p_{T}$ = 0.2 - 0.8~\gevc and averaged over
pseudorapidity ranges of $-1 < \eta < -0.05$ and $0.05 < \eta < 1$. This
represents an upper limit of $0.23\times10^{-4}$, or $15\%$ of the inclusive
result, at $95\%$ confidence level for the $m_{\rm inv}$-integrated CME
contribution.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:42:10 GMT""},{""version"":""v2"",""created"":""Sat, 17 Sep 2022 05:18:30 GMT""}]","2022-09-20"
"2006.05036","Selman Ipek","Selman Ipek and Ariel Caticha","The Entropic Dynamics of Quantum Scalar Fields Coupled to Gravity","42 pages. Extended version of work presented at The 39th
  International Workshop on Bayesian Inference and Maximum Entropy Methods in
  Science and Engineering. Additional explanations and corrected typos",,,,"gr-qc quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entropic dynamics (ED) is a general framework for constructing
indeterministic dynamical models based on entropic methods. ED has been used to
derive or reconstruct both non-relativistic quantum mechanics and quantum field
theory in curved space-time. Here we propose a model for a quantum scalar field
propagating in a dynamical space-time. The approach rests on a few key
ingredients: (1) Rather than modelling the dynamics of the fields, ED models
the dynamics of their probabilities. (2) In accordance with the standard
entropic methods of inference the dynamics is dictated by information encoded
in constraints. (3) The choice of the physically relevant constraints is
dictated by principles of symmetry and invariance. The first such principle
imposes the preservation of a symplectic structure which leads to a Hamiltonian
formalism with its attendant Poisson brackets and action principle. The second
symmetry principle is foliation invariance, which following earlier work by
Hojman, Kuchar, and Teitelboim, is implemented as a requirement of path
independence. The result is a hybrid ED model that approaches quantum field
theory in one limit and classical general relativity in another, but is not
fully described by either. A particularly significant prediction of this ED
model is that the coupling of quantum fields to gravity implies violations of
the quantum superposition principle.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:44:36 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jul 2020 20:49:49 GMT""}]","2020-07-14"
"2006.05037","Francisco X. Linares Cede\~no","Francisco X. Linares Cede\~no, Alma X. Gonz\'alez-Morales and L.
  Arturo Ure\~na-L\'opez","Ultralight DM bosons with an Axion-like potential: scale-dependent
  constraints revisited","43 pages, 17 figures. Updated data, new appendix. Matches version
  accepted in JCAP",,"10.1088/1475-7516/2021/01/051",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A scalar field $\phi$ endowed with a trigonometric potential has been
proposed to play the role of Dark Matter. A deep study of the cosmological
evolution of linear perturbations, and its comparison to the Cold Dark Matter
(CDM) and Fuzzy Dark Matter (FDM) cases (scalar field with quadratic
potential), reveals an enhancement in the amplitude of the mass power spectrum
for large wave numbers due to the non-linearity of the axion-like potential.
For the first time, we study the scale-dependence on physical quantities such
as the growth factor $D_k$, the velocity growth factor $f_k$, and $f_k
\sigma_8$. We found that for $z<10$, all these quantities recover the CDM
evolution, whereas for high redshift there is a clear distinction between each
model (FDM case, and axion-like potential) depending on the wavenumber $k$ and
on the decay parameter of the axion-like potential as well. A semi-analytical
Halo Mass Function is also revisited, finding a suppression of the number of
low mass halos, as in the FDM case, but with a small increment in the amplitude
of the variance and halo mass function due to the non-linearity of the
axion-like potential. Finally, we present constraints on the axion mass and the
axion decay parameter by using data of the Planck Collaboration 2018 and
Lyman-$\alpha$ forest.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:58:07 GMT""},{""version"":""v2"",""created"":""Tue, 26 Jan 2021 22:52:46 GMT""}]","2021-02-03"
"2006.05038","Paul Keeler Dr","Bartek B{\l}aszczyszyn, Antoine Brochard, H. Paul Keeler","Coverage probability in wireless networks with determinantal scheduling","8 pages. 2 figures",,,,"cs.NI cs.LG math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new class of algorithms for randomly scheduling network
transmissions. The idea is to use (discrete) determinantal point processes
(subsets) to randomly assign medium access to various {\em repulsive} subsets
of potential transmitters. This approach can be seen as a natural extension of
(spatial) Aloha, which schedules transmissions independently. Under a general
path loss model and Rayleigh fading, we show that, similarly to Aloha, they are
also subject to elegant analysis of the coverage probabilities and transmission
attempts (also known as local delay). This is mainly due to the explicit,
determinantal form of the conditional (Palm) distribution and closed-form
expressions for the Laplace functional of determinantal processes.
Interestingly, the derived performance characteristics of the network are
amenable to various optimizations of the scheduling parameters, which are
determinantal kernels, allowing the use of techniques developed for statistical
learning with determinantal processes. Well-established sampling algorithms for
determinantal processes can be used to cope with implementation issues, which
is is beyond the scope of this paper, but it creates paths for further
research.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:05:50 GMT""}]","2020-06-11"
"2006.05039","Gregory Ashton","Gregory Ashton and Eric Thrane","The astrophysical odds of GW151216","6 pages, 1 figure, 1 table, publised in MNRAS",,"10.1093/mnras/staa2332",,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The gravitational-wave candidate GW151216 is a proposed binary black hole
event from the first observing run of the Advanced LIGO detectors. Not
identified as a bona fide signal by the LIGO--Virgo collaboration, there is
disagreement as to its authenticity, which is quantified by $p_\text{astro}$,
the probability that the event is astrophysical in origin. Previous estimates
of $p_\text{astro}$ from different groups range from 0.18 to 0.71, making it
unclear whether this event should be included in population analyses, which
typically require $p_\text{astro}>0.5$. Whether GW151216 is an astrophysical
signal or not has implications for the population properties of stellar-mass
black holes and hence the evolution of massive stars. Using the astrophysical
odds, a Bayesian method which uses the signal coherence between detectors and a
parameterised model of non-astrophysical detector noise, we find that
$p_\text{astro}=0.03$, suggesting that GW151216 is unlikely to be a genuine
signal. We also analyse GW150914 (the first gravitational-wave detection) and
GW151012 (initially considered to be an ambiguous detection) and find
$p_\text{astro}$ values of 1 and 0.997 respectively. We argue that the
astrophysical odds presented here improve upon traditional methods for
distinguishing signals from noise.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:18:37 GMT""},{""version"":""v2"",""created"":""Fri, 14 Aug 2020 13:09:39 GMT""},{""version"":""v3"",""created"":""Wed, 2 Sep 2020 07:58:26 GMT""}]","2020-09-03"
"2006.05040","Jing Shuang (Lisa) Li","Jing Shuang Li and Dimitar Ho","Separating Controller Design from Closed-Loop Design: A New Perspective
  on System-Level Controller Synthesis","To appear in 2020 IEEE American Control Conference (ACC)",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that given a desired closed-loop response for a system, there exists
an affine subspace of controllers that achieve this response. By leveraging the
existence of this subspace, we are able to separate controller design from
closed-loop design by first synthesizing the desired closed-loop response and
then synthesizing a controller that achieves the desired response. This is a
useful extension to the recently introduced System Level Synthesis framework,
in which the controller and closed-loop response are jointly synthesized and we
cannot enforce controller-specific constraints without subjecting the
closed-loop map to the same constraints. We demonstrate the importance of
separating controller design from closed-loop design with an example in which
communication delay and locality constraints cause standard SLS to be
infeasible. Using our new two-step procedure, we are able to synthesize a
controller that obeys the constraints while only incurring a 3% increase in LQR
cost compared to the optimal LQR controller.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:20:00 GMT""}]","2020-06-11"
"2006.05041","Erlin Qiao","Erlin Qiao, B.F. Liu","The advection-dominated accretion flow for the anti-correlation between
  the X-ray photon index and the X-ray luminosity in neutron star low-mass
  X-ray binaries","12 pages, 12 figures. Accepted for publication by MNRAS",,"10.1093/mnras/staa1671",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observationally, an anti-correlation between the X-ray photon index $\Gamma$
(obtained by fitting the X-ray spectrum between 0.5 and 10 keV with a single
power law) and the X-ray luminosity $L_{\rm 0.5-10keV}$, is found in neutron
star low-mass X-ray binaries (NS-LMXBs) in the range of $L_{\rm 0.5-10keV}\sim
10^{34}-10^{36}\ \rm erg\ s^{-1}$. In this paper, we explain the observed
anti-correlation between $\Gamma$ and $L_{\rm 0.5-10keV}$ within the framework
of the self-similar solution of the advection-dominated accretion flow (ADAF)
around a weakly magnetized NS. The ADAF model intrinsically predicts an
anti-correlation between $\Gamma$ and $L_{\rm 0.5-10keV}$. In the ADAF model,
there is a key parameter, $f_{\rm th}$, which describes the fraction of the
ADAF energy released at the surface of the NS as thermal emission to be
scattered in the ADAF. We test the effect of $f_{\rm th}$ on the
anti-correlation between $\Gamma$ and $L_{\rm 0.5-10keV}$. It is found that the
value of $f_{\rm th}$ can significantly affect the anti-correlation between
$\Gamma$ and $L_{\rm 0.5-10keV}$. Specifically, the anti-correlation between
$\Gamma$ and $L_{\rm 0.5-10keV}$ becomes flatter with decreasing $f_{\rm th}$
as taking $f_{\rm th}=0.1, 0.03, 0.01, 0.005$, $0.003$ and $0$ respectively. By
comparing with a sample of non-pulsating NS-LMXBs with well measured $\Gamma$
and $L_{\rm 0.5-10keV}$, we find that indeed only a small value of
$0.003\lesssim f_{\rm th}\lesssim 0.1$ is needed to match the observed
anti-correlation between $\Gamma$ and $L_{\rm 0.5-10keV}$. Finally, we argue
that the small value of $f_{\rm th}\lesssim 0.1$ derived in this paper further
confirms our previous conclusion that the radiative efficiency of NSs with an
ADAF accretion may not be as high as $\epsilon \sim {\dot M GM\over
R_{*}}/{\dot M c^2}\sim 0.2$.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:22:49 GMT""}]","2020-06-17"
"2006.05042","Chenglu Jin","Priyanka Mahesh, Akash Tiwari, Chenglu Jin, Panganamala R. Kumar, A.
  L. Narasimha Reddy, Satish T.S. Bukkapatanam, Nikhil Gupta, Ramesh Karri","A Survey of Cybersecurity of Digital Manufacturing",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Industry 4.0 concept promotes a digital manufacturing (DM) paradigm that
can enhance quality and productivity, that reduces inventory and the lead-time
for delivering custom, batch-of-one products based on achieving convergence of
Additive, Subtractive, and Hybrid manufacturing machines, Automation and
Robotic Systems, Sensors, Computing, and Communication Networks, Artificial
Intelligence, and Big Data. A DM system consists of embedded electronics,
sensors, actuators, control software, and inter-connectivity to enable the
machines and the components within them to exchange data with other machines,
components therein, the plant operators, the inventory managers, and customers.
This paper presents the cybersecurity risks in the emerging DM context,
assesses the impact on manufacturing, and identifies approaches to secure DM.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:32:49 GMT""},{""version"":""v2"",""created"":""Tue, 29 Sep 2020 12:16:38 GMT""},{""version"":""v3"",""created"":""Thu, 15 Oct 2020 16:35:02 GMT""}]","2020-10-16"
"2006.05043","Tianyu Wang","Tianyu Wang, Vikas Dhiman, Nikolay Atanasov","Learning Navigation Costs from Demonstration with Semantic Observations","Conference on Learning for Dynamics and Control (L4DC 2020). arXiv
  admin note: text overlap with arXiv:2002.11637",,,,"cs.LG cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on inverse reinforcement learning (IRL) for autonomous
robot navigation using semantic observations. The objective is to infer a cost
function that explains demonstrated behavior while relying only on the expert's
observations and state-control trajectory. We develop a map encoder, which
infers semantic class probabilities from the observation sequence, and a cost
encoder, defined as deep neural network over the semantic features. Since the
expert cost is not directly observable, the representation parameters can only
be optimized by differentiating the error between demonstrated controls and a
control policy computed from the cost estimate. The error is optimized using a
closed-form subgradient computed only over a subset of promising states via a
motion planning algorithm. We show that our approach learns to follow traffic
rules in the autonomous driving CARLA simulator by relying on semantic
observations of cars, sidewalks and road lanes.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:35:57 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 01:17:56 GMT""}]","2020-06-12"
"2006.05044","Baocheng Zhu","Baocheng Zhu, Shijun Wang and James Zhang","Neural Physicist: Learning Physical Dynamics from Image Sequences","19 pages, 20 figures",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present a novel architecture named Neural Physicist (NeurPhy) to learn
physical dynamics directly from image sequences using deep neural networks. For
any physical system, given the global system parameters, the time evolution of
states is governed by the underlying physical laws. How to learn meaningful
system representations in an end-to-end way and estimate accurate state
transition dynamics facilitating long-term prediction have been long-standing
challenges. In this paper, by leveraging recent progresses in representation
learning and state space models (SSMs), we propose NeurPhy, which uses
variational auto-encoder (VAE) to extract underlying Markovian dynamic state at
each time step, neural process (NP) to extract the global system parameters,
and a non-linear non-recurrent stochastic state space model to learn the
physical dynamic transition. We apply NeurPhy to two physical experimental
environments, i.e., damped pendulum and planetary orbits motion, and achieve
promising results. Our model can not only extract the physically meaningful
state representations, but also learn the state transition dynamics enabling
long-term predictions for unseen image sequences. Furthermore, from the
manifold dimension of the latent state space, we can easily identify the degree
of freedom (DoF) of the underlying physical systems.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:36:51 GMT""}]","2020-06-11"
"2006.05045","Pankaj Sheoran","Eva Hackmann, Hemwati Nandan, and Pankaj Sheoran","Particle collisions near static spherically symmetric black holes","References and extra discussion added",,"10.1016/j.physletb.2020.135850",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been shown by Ba\~{n}ados, Silk and West (BSW) that the center of mass
energy (E_cm) of test particles starting from rest at infinity and colliding
near the horizon of a Schwarzschild black hole is always finite. In this
communication, we extent the BSW scenario and study two particles with
different energies colliding near the horizon of a static spherically symmetric
black hole. Surprisingly, we find that even for the static spherically
symmetric (i.e., Schwarzschild like) black holes it is possible to obtain an
arbitrarily high E cm from the two test particles colliding near the horizon of
a black hole, if one fine-tunes the parameters of geodesic motion.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:45:30 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 06:27:07 GMT""}]","2020-10-28"
"2006.05046","Ryan Kidd","Ryan A. Kidd, Arghavan Safavi-Naini, Joel F. Corney","Thermalisation in a Bose-Hubbard dimer with modulated tunneling","7 pages, 4 figures","Phys. Rev. A 102, 023330 (2020)","10.1103/PhysRevA.102.023330",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The periodically modulated Bose-Hubbard dimer model offers an experimentally
realizable and highly tunable platform for observing the scrambling of quantum
information and the apparent thermalisation of isolated, interacting quantum
many-body systems. In this work we apply fidelity out-of-time-order correlators
to establish connections between thermalisation in Floquet system, the
exponential growth of FOTOCs as quantified by a non-zero quantum Lyapunov
exponent, and the underlying classical transition from regular to chaotic
dynamics in the dimer. Moreover, we demonstrate that a non-zero quantum
Lyapunov exponent can also be inferred from measures quantifying the
delocalisation of the Floquet modes of the system such as the Shannon entropy,
which approaches unity if the system thermalises to the periodic Gibbs ensemble
prediction.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:48:38 GMT""}]","2020-09-02"
"2006.05047","Zhesi Shen","Sichao Tong, Zhesi Shen, Fuyou Chen, Liying Yang","The novel utilization of paper-level classification system on the
  evaluation of journal impact: An update in CAS Journal Ranking",,,,,"cs.DL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  CAS Journal Ranking, a ranking system of journals based on the bibliometric
indicator of citation impact, has been widely used both in selecting journals
when submitting manuscripts and conducting research evaluation in China since
its first release in 2004. This paper will mainly introduce the upgraded
version of CAS Journal Ranking released in 2020 and the corresponding
improvements. We will discuss the following improvements: (1) the CWTS
paper-level classification system, a more fine-grained classification system,
has been utilized for field normalization, (2) the Field Normalized Citation
Success Index (FNCSI), an indicator which is robust against not only extremely
highly cited publications, but also the wrongly assigned document type, has
been used, and (3) document type difference is considered. In addition, this
paper will present part of the ranking results and an interpretation of the
features of the FNCSI indicator.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:52:07 GMT""},{""version"":""v2"",""created"":""Sat, 13 Aug 2022 14:57:18 GMT""}]","2022-08-16"
"2006.05048","Osonde Osoba Ph.D.","Osonde A. Osoba, Raffaele Vardavas, Justin Grana, Rushil Zutshi, Amber
  Jaycocks","Policy-focused Agent-based Modeling using RL Behavioral Models","This is a more detailed version of a paper (""Modeling Agent Behaviors
  for Policy Analysis via Reinforcement Learning"") accepted to appear in IEEE
  ICMLA 2020. This also corrects an error in Fig. 7 of the original arXiv
  submission. Fig. 7 now specifies the right ABM architecture (""flu"" instead of
  ""tax"")",,,,"cs.LG cs.AI cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Agent-based Models (ABMs) are valuable tools for policy analysis. ABMs help
analysts explore the emergent consequences of policy interventions in
multi-agent decision-making settings. But the validity of inferences drawn from
ABM explorations depends on the quality of the ABM agents' behavioral models.
Standard specifications of agent behavioral models rely either on heuristic
decision-making rules or on regressions trained on past data. Both prior
specification modes have limitations. This paper examines the value of
reinforcement learning (RL) models as adaptive, high-performing, and
behaviorally-valid models of agent decision-making in ABMs. We test the
hypothesis that RL agents are effective as utility-maximizing agents in policy
ABMs. We also address the problem of adapting RL algorithms to handle
multi-agency in games by adapting and extending methods from recent literature.
We evaluate the performance of such RL-based ABM agents via experiments on two
policy-relevant ABMs: a minority game ABM, and an ABM of Influenza
Transmission. We run some analytic experiments on our AI-equipped ABMs e.g.
explorations of the effects of behavioral heterogeneity in a population and the
emergence of synchronization in a population. The experiments show that RL
behavioral models are effective at producing reward-seeking or
reward-maximizing behaviors in ABM agents. Furthermore, RL behavioral models
can learn to outperform the default adaptive behavioral models in the two ABMs
examined.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:55:07 GMT""},{""version"":""v2"",""created"":""Mon, 5 Oct 2020 19:28:48 GMT""},{""version"":""v3"",""created"":""Thu, 5 Nov 2020 20:41:17 GMT""}]","2020-11-09"
"2006.05049","Bo Pang","Bo Pang, Deming Zhai, Junjun Jiang, Xianming Liu","Single Image Deraining via Scale-space Invariant Attention Neural
  Network",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image enhancement from degradation of rainy artifacts plays a critical role
in outdoor visual computing systems. In this paper, we tackle the notion of
scale that deals with visual changes in appearance of rain steaks with respect
to the camera. Specifically, we revisit multi-scale representation by
scale-space theory, and propose to represent the multi-scale correlation in
convolutional feature domain, which is more compact and robust than that in
pixel domain. Moreover, to improve the modeling ability of the network, we do
not treat the extracted multi-scale features equally, but design a novel
scale-space invariant attention mechanism to help the network focus on parts of
the features. In this way, we summarize the most activated presence of feature
maps as the salient features. Extensive experiments results on synthetic and
real rainy scenes demonstrate the superior performance of our scheme over the
state-of-the-arts.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 04:59:26 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 01:35:10 GMT""}]","2020-06-12"
"2006.05050","Daehan Park","Kyeong-Hun Kim, Daehan Park","A Sobolev space theory for the time-fractional stochastic partial
  differential equations driven by Levy processes",,,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an $L_{p}$-theory ($p\geq 2$) for time-fractional stochastic
partial differential equations driven by L\'evy processes of the type $$
\partial^{\alpha}_{t}u=\sum_{i,j=1}^d a^{ij}u_{x^{i}x^{j}}
+f+\sum_{k=1}^{\infty}\partial^{\beta}_{t}\int_{0}^{t} (\sum_{i=1}^d\mu^{ik}
u_{x^i} +g^k) dZ^k_{s} $$ given with nonzero intial data. Here
$\partial^{\alpha}_t$ and $\partial^{\beta}_t$ are the Caputo fractional
derivatives, $\alpha\in (0,2), \beta\in (0,\alpha+1/p)$, and
$\{Z^k_t:k=1,2,\cdots\}$ is a sequence of independent L\'evy processes. The
coefficients are random functions depending on $(t,x)$. We prove the uniqueness
and existence results in Sobolev spaces, and obtain the maximal regularity of
the solution.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:01:45 GMT""},{""version"":""v2"",""created"":""Tue, 10 Nov 2020 03:55:50 GMT""},{""version"":""v3"",""created"":""Tue, 15 Mar 2022 07:26:21 GMT""}]","2022-03-16"
"2006.05051","Thodoris Lykouris","Kiant\'e Brantley, Miroslav Dudik, Thodoris Lykouris, Sobhan
  Miryoosefi, Max Simchowitz, Aleksandrs Slivkins, Wen Sun","Constrained episodic reinforcement learning in concave-convex and
  knapsack settings","The NeurIPS 2020 version of this paper includes a small bug, leading
  to an incorrect dependence on H in Theorem 3.4. This version fixes it by
  adjusting Eq. (9), Theorem 3.4 and the relevant proofs. Changes in the main
  text are noted in red. Changes in the appendix are limited to Appendices B.1,
  B.5, and B.6 and the statement of Lemma F.3",,,,"cs.LG cs.AI cs.DS stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an algorithm for tabular episodic reinforcement learning with
constraints. We provide a modular analysis with strong theoretical guarantees
for settings with concave rewards and convex constraints, and for settings with
hard constraints (knapsacks). Most of the previous work in constrained
reinforcement learning is limited to linear constraints, and the remaining work
focuses on either the feasibility question or settings with a single episode.
Our experiments demonstrate that the proposed algorithm significantly
outperforms these approaches in existing constrained episodic environments.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:02:44 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 03:30:29 GMT""}]","2021-06-08"
"2006.05052","Takahisa Igata","Takahisa Igata","Chaotic particle motion around a homogeneous circular ring","21 pages, 4 figures; v2: minor revision, add references; v3:
  published version","Phys. Rev. D 102, 044019 (2020)","10.1103/PhysRevD.102.044019","KEK-Cosmo-255, KEK-TH-2227","gr-qc astro-ph.EP hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider test particle motion in a gravitational field generated by a
homogeneous circular ring placed in $n$-dimensional Euclidean space. We observe
that there exist no stable stationary orbits in $n=6, 7, \ldots, 10$ but exist
in $n=3, 4, 5$ and clarify the regions in which they appear. In $n=3$, we show
that the separation of variables of the Hamilton-Jacobi equation does not occur
though we find no signs of chaos for stable bound orbits. Since the system is
integrable in $n=4$, no chaos appears. In $n=5$, we find some chaotic stable
bound orbits. Therefore, this system is nonintegrable at least in $n=5$ and
suggests that the timelike geodesic system in the corresponding black ring
spacetimes is nonintegrable.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:06:43 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jul 2020 04:35:29 GMT""},{""version"":""v3"",""created"":""Mon, 17 Aug 2020 01:26:49 GMT""}]","2020-08-18"
"2006.05053","Pieter van Goor","Pieter van Goor, Robert Mahony, Tarek Hamel, Jochen Trumpf","Constructive Observer Design for Visual Simultaneous Localisation and
  Mapping","17 pages, 6 figures. Submitted to Automatica",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual Simultaneous Localisation and Mapping (VSLAM) is a well-known problem
in robotics with a large range of applications. This paper presents a novel
approach to VSLAM by lifting the observer design to a novel Lie group on which
the system output is equivariant. The perspective gained from this analysis
facilitates the design of a non-linear observer with almost semi-globally
asymptotically stable error dynamics. Simulations are provided to illustrate
the behaviour of the proposed observer and experiments on data gathered using a
fixed-wing UAV flying outdoors demonstrate its performance.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:13:51 GMT""}]","2020-06-11"
"2006.05054","Monimoy Bujarbaruah","Monimoy Bujarbaruah, Charlott Vallon, Francesco Borrelli","Learning to Satisfy Unknown Constraints in Iterative MPC","Long version of the final paper for IEEE-CDC 2020. First two authors
  contributed equally",,,,"eess.SY cs.SY stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a control design method for linear time-invariant systems that
iteratively learns to satisfy unknown polyhedral state constraints. At each
iteration of a repetitive task, the method constructs an estimate of the
unknown environment constraints using collected closed-loop trajectory data.
This estimated constraint set is improved iteratively upon collection of
additional data. An MPC controller is then designed to robustly satisfy the
estimated constraint set. This paper presents the details of the proposed
approach, and provides robust and probabilistic guarantees of constraint
satisfaction as a function of the number of executed task iterations. We
demonstrate the safety of the proposed framework and explore the safety vs.
performance trade-off in a detailed numerical example.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:19:40 GMT""},{""version"":""v2"",""created"":""Wed, 9 Sep 2020 18:18:06 GMT""}]","2020-09-11"
"2006.05056","Jean-Philippe Tetienne","A. J. Healey, A. Stacey, B. C. Johnson, D. A. Broadway, T. Teraji, D.
  A. Simpson, J.-P. Tetienne, L. C. L. Hollenberg","Comparison of different methods of nitrogen-vacancy layer formation in
  diamond for widefield quantum microscopy",,"Phys. Rev. Materials 4, 104605 (2020)","10.1103/PhysRevMaterials.4.104605",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thin layers of near-surface nitrogen-vacancy (NV) defects in diamond
substrates are the workhorse of NV-based widefield magnetic microscopy, which
has applications in physics, geology and biology. Several methods exist to
create such NV layers, which generally involve incorporating nitrogen atoms (N)
and vacancies (V) into the diamond through growth and/or irradiation. While
there have been detailed studies of individual methods, a direct side-by-side
experimental comparison of the resulting magnetic sensitivities is still
missing. Here we characterise, at room and cryogenic temperatures, $\approx100$
nm thick NV layers fabricated via three different methods: 1) low-energy carbon
irradiation of N-rich high-pressure high-temperature (HPHT) diamond, 2) carbon
irradiation of $\delta$-doped chemical vapour deposition (CVD) diamond, 3)
low-energy N$^+$ or CN$^-$ implantation into N-free CVD diamond. Despite
significant variability within each method, we find that the best HPHT samples
yield similar magnetic sensitivities (within a factor 2 on average) to our
$\delta$-doped samples, of $<2$~$\mu$T Hz$^{-1/2}$ for DC magnetic fields and
$<100$~nT Hz$^{-1/2}$ for AC fields (for a $400$~nm~$\times~400$~nm pixel),
while the N$^+$ and CN$^-$ implanted samples exhibit an inferior sensitivity by
a factor 2-5, at both room and low temperature. We also examine the crystal
lattice strain caused by the respective methods and discuss the implications
this has for widefield NV imaging. The pros and cons of each method, and
potential future improvements, are discussed. This study highlights that
low-energy irradiation of HPHT diamond, despite its relative simplicity and low
cost, is a competitive method to create thin NV layers for widefield magnetic
imaging.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:20:51 GMT""}]","2020-11-02"
"2006.05057","Jiaqi Ma","Jiaqi Ma, Shuangrui Ding, Qiaozhu Mei","Towards More Practical Adversarial Attacks on Graph Neural Networks","NeurIPS 2020, Code Link Update",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the black-box attacks on graph neural networks (GNNs) under a novel
and realistic constraint: attackers have access to only a subset of nodes in
the network, and they can only attack a small number of them. A node selection
step is essential under this setup. We demonstrate that the structural
inductive biases of GNN models can be an effective source for this type of
attacks. Specifically, by exploiting the connection between the backward
propagation of GNNs and random walks, we show that the common gradient-based
white-box attacks can be generalized to the black-box setting via the
connection between the gradient and an importance score similar to PageRank. In
practice, we find attacks based on this importance score indeed increase the
classification loss by a large margin, but they fail to significantly increase
the mis-classification rate. Our theoretical and empirical analyses suggest
that there is a discrepancy between the loss and mis-classification rate, as
the latter presents a diminishing-return pattern when the number of attacked
nodes increases. Therefore, we propose a greedy procedure to correct the
importance score that takes into account of the diminishing-return pattern.
Experimental results show that the proposed procedure can significantly
increase the mis-classification rate of common GNNs on real-world data without
access to model parameters nor predictions.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:27:39 GMT""},{""version"":""v2"",""created"":""Sat, 24 Oct 2020 00:40:31 GMT""},{""version"":""v3"",""created"":""Wed, 27 Oct 2021 01:26:48 GMT""}]","2021-10-28"
"2006.05058","Ryo Horiuchi","Ryo Horiuchi","On complicial homotopy monoids","References added",,,,"math.AT math.CO math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a Kan complex with a vertex, we have the notion of its simplicial
homotopy groups. In this paper, for a weak complicial set in the sense of
Verity with a vertex, we construct monoids which are a generalization of
simplicial homotopy groups.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:31:49 GMT""},{""version"":""v2"",""created"":""Sat, 13 Jun 2020 04:38:28 GMT""},{""version"":""v3"",""created"":""Wed, 18 Nov 2020 23:45:11 GMT""}]","2020-11-20"
"2006.05059","Mustafa Kishk","Hesham Elsawy, Mustafa A. Kishk, Mohamed-Slim Alouini","Spatial Firewalls: Quarantining Malware Epidemics in Large Scale Massive
  Wireless Networks",,,,,"cs.CR cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Billions of wireless devices are foreseen to participate in big data
aggregation and smart automation in order to interface the cyber and physical
worlds. Such large-scale ultra-dense wireless connectivity is vulnerable to
malicious software (malware) epidemics. Malware worms can exploit multi-hop
wireless connectivity to stealthily diffuse throughout the wireless network
without being noticed to security servers at the core network. Compromised
devices can then be used by adversaries to remotely launch cyber attacks that
cause large-scale critical physical damage and threaten public safety. This
article overviews the types, threats, and propagation models for malware
epidemics in large-scale wireless networks (LSWN). Then, the article proposes a
novel and cost efficient countermeasure against malware epidemics in LSWN,
denoted as spatial firewalls. It is shown that equipping a strategically
selected small portion (i.e., less than 10\%) of the devices with
state-of-the-art security mechanisms is sufficient to create spatially secured
zones that quarantine malware epidemics. Quarantined infected devices are then
cured by on-demand localized software patching. To this end, several firewall
deployment strategies are discussed and compared.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:32:14 GMT""},{""version"":""v2"",""created"":""Fri, 12 Jun 2020 08:30:04 GMT""}]","2020-06-15"
"2006.05060","Shrikanth N.C.","N.C. Shrikanth, William Nichols, Fahmid Morshed Fahid, Tim Menzies","Assessing Practitioner Beliefs about Software Engineering","32 pages, published
  https://link.springer.com/article/10.1007/s10664-021-09957-5",,"10.1007/s10664-021-09957-5",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Software engineering is a highly dynamic discipline. Hence, as times change,
so too might our beliefs about core processes in this field. This paper checks
some five beliefs that originated in the past decades that comment on the
relationships between (i) developer productivity; (ii) software quality and
(iii) years of developer experience. Using data collected from 1,356 developers
in the period 1995 to 2006, we found support for only one of the five beliefs
titled ""Quality entails productivity"". We found no clear support for four other
beliefs based on programming languages and software developers. However, from
the sporadic evidence of the four other beliefs we learned that a narrow scope
could delude practitioners in misinterpreting certain effects to hold in their
day to day work. Lastly, through an aggregated view of assessing the five
beliefs, we find programming languages act as a confounding factor for
developer productivity and software quality. Thus the overall message of this
work is that it is both important and possible to revisit old beliefs in SE.
Researchers and practitioners should routinely retest old beliefs.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:35:40 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 15:18:13 GMT""},{""version"":""v3"",""created"":""Sun, 20 Dec 2020 12:33:58 GMT""},{""version"":""v4"",""created"":""Mon, 24 May 2021 22:23:48 GMT""}]","2021-05-26"
"2006.05061","Xueying Tang","Xueying Tang, Susu Zhang, Zhi Wang, Jingchen Liu, Zhiliang Ying","ProcData: An R Package for Process Data Analysis",,,,,"stat.CO cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Process data refer to data recorded in the log files of computer-based items.
These data, represented as timestamped action sequences, keep track of
respondents' response processes of solving the items. Process data analysis
aims at enhancing educational assessment accuracy and serving other assessment
purposes by utilizing the rich information contained in response processes. The
R package ProcData presented in this article is designed to provide tools for
processing, describing, and analyzing process data. We define an S3 class
""proc"" for organizing process data and extend generic methods summary and print
for class ""proc"". Two feature extraction methods for process data are
implemented in the package for compressing information in the irregular
response processes into regular numeric vectors. ProcData also provides
functions for fitting and making predictions from a neural-network-based
sequence model. These functions call relevant functions in package keras for
constructing and training neural networks. In addition, several response
process generators and a real dataset of response processes of the climate
control item in the 2012 Programme for International Student Assessment are
included in the package.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:44:57 GMT""}]","2020-06-11"
"2006.05062","Hung  Viet Chu Mr","Hung Viet Chu","Visualize Geometric Series","6 pages, 5 figures",,,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review some ""proofs without words"" for the formula for geometric series
and find a common theme lurking behind them. We also answer negatively the
question raised by Edgar on the existence of other proofs similar to Mabry's
and his.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:52:00 GMT""}]","2020-06-11"
"2006.05063","Sergey Sazonov","S. Sazonov, A. Paizis, A. Bazzano, I. Chelovekov, I. Khabibullin, K.
  Postnov, I. Mereminskiy, M. Fiocchi, G. B\'elanger, A.J. Bird, E. Bozzo, J.
  Chenevez, M. Del Santo, M. Falanga, R. Farinelli, C. Ferrigno, S. Grebenev,
  R. Krivonos, E. Kuulkers, N. Lund, C. Sanchez-Fernandez, A. Tarana, P.
  Ubertini, J. Wilms","The Galactic LMXB Population and the Galactic Centre Region","60 pages, 26 figures, 2 tables, accepted for publication in New
  Astronomy Reviews",,"10.1016/j.newar.2020.101536",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Seventeen years of hard X-ray observations with the instruments of the
INTEGRAL observatory, with a focus on the Milky Way and in particular on the
Galactic Centre region, have provided a unique database for exploration of the
Galactic population of low-mass X-ray binaries (LMXBs). Our understanding of
the diverse energetic phenomena associated with accretion of matter onto
neutron stars and black holes has greatly improved. We review the large variety
of INTEGRAL based results related to LMXBs. In particular, we discuss the
spatial distribution of LMXBs over the Galaxy and their X-ray luminosity
function as well as various physical phenomena associated with Atoll and Z
sources, bursters, symbiotic X-ray binaries, ultracompact X-ray binaries and
persistent black hole LMXBs. We also present an up-to-date catalogue of
confirmed LMXBs detected by INTEGRAL, which comprises 166 objects. Last but not
least, the long-term monitoring of the Galactic Centre with INTEGRAL has shed
light on the activity of Sgr A* in the recent past, confirming previous
indications that our supermassive black hole experienced a major accretion
episode just ~100 years ago. This exciting topic is covered in this review too.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 05:52:03 GMT""}]","2020-09-02"
"2006.05064","Benjamin Lehmann","Wolfgang Altmannshofer, Benjamin V. Lehmann, Stefano Profumo","Cosmological implications of the KOTO excess","43 pages, 10 figures. Matched published version","Phys. Rev. D 102, 083527 (2020)","10.1103/PhysRevD.102.083527",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The KOTO experiment has reported an excess of $K_L\to\pi^0\nu\bar\nu$ events
above the Standard Model prediction, in tension with the Grossman-Nir (GN)
bound. The GN bound heavily constrains new physics interpretations of an excess
in this channel, but another possibility is that the observed events originate
from a different process entirely: a decay of the form $K_L\to\pi^0X$, where
$X$ denotes one or more new invisible species. We introduce a class of models
to study this scenario with two light scalars playing the role of $X$, and we
examine the possibility that the lighter of the two new states may also account
for cosmological dark matter (DM). We show that this species can be produced
thermally in the presence of additional interactions apart from those needed to
account for the KOTO excess. Conversely, in the minimal version of the model,
DM must be produced nonthermally. In this case, avoiding overproduction imposes
constraints on the structure of the low-energy theory. Moreover, this
requirement carries significant implications for the scale of reheating in the
early Universe, generically preferring a low but observationally permitted
reheating temperature of O(10 MeV). We discuss astrophysical and terrestrial
signatures that will allow further tests of this paradigm in the coming years.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:01:46 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 07:15:45 GMT""}]","2020-10-23"
"2006.05065","Zhilu Zhang","Zhilu Zhang and Mert R. Sabuncu","Self-Distillation as Instance-Specific Label Smoothing",,"34th Conference on Neural Information Processing Systems (NeurIPS
  2020)",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been recently demonstrated that multi-generational self-distillation
can improve generalization. Despite this intriguing observation, reasons for
the enhancement remain poorly understood. In this paper, we first demonstrate
experimentally that the improved performance of multi-generational
self-distillation is in part associated with the increasing diversity in
teacher predictions. With this in mind, we offer a new interpretation for
teacher-student training as amortized MAP estimation, such that teacher
predictions enable instance-specific regularization. Our framework allows us to
theoretically relate self-distillation to label smoothing, a commonly used
technique that regularizes predictive uncertainty, and suggests the importance
of predictive diversity in addition to predictive uncertainty. We present
experimental results using multiple datasets and neural network architectures
that, overall, demonstrate the utility of predictive diversity. Finally, we
propose a novel instance-specific label smoothing technique that promotes
predictive diversity without the need for a separately trained teacher model.
We provide an empirical evaluation of the proposed method, which, we find,
often outperforms classical label smoothing.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:06:30 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 03:23:39 GMT""}]","2020-10-23"
"2006.05066","Woochul Kang","Woochul Kang, Daeyeon Kim","Deeply Shared Filter Bases for Parameter-Efficient Convolutional Neural
  Networks",,,,,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  Modern convolutional neural networks (CNNs) have massive identical
convolution blocks, and, hence, recursive sharing of parameters across these
blocks has been proposed to reduce the amount of parameters. However, naive
sharing of parameters poses many challenges such as limited representational
power and the vanishing/exploding gradients problem of recursively shared
parameters. In this paper, we present a recursive convolution block design and
training method, in which a recursively shareable part, or a filter basis, is
separated and learned while effectively avoiding the vanishing/exploding
gradients problem during training. We show that the unwieldy
vanishing/exploding gradients problem can be controlled by enforcing the
elements of the filter basis orthonormal, and empirically demonstrate that the
proposed orthogonality regularization improves the flow of gradients during
training. Experimental results on image classification and object detection
show that our approach, unlike previous parameter-sharing approaches, does not
trade performance to save parameters and consistently outperforms
overparameterized counterpart networks. This superior performance demonstrates
that the proposed recursive convolution block design and the orthogonality
regularization not only prevent performance degradation, but also consistently
improve the representation capability while a significant amount of parameters
are recursively shared.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:09:42 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 06:04:54 GMT""},{""version"":""v3"",""created"":""Thu, 22 Jul 2021 02:27:18 GMT""},{""version"":""v4"",""created"":""Sun, 21 Nov 2021 09:53:04 GMT""}]","2021-11-23"
"2006.05067","Jiaqi Ma","Jiaqi Ma, Xinyang Yi, Weijing Tang, Zhe Zhao, Lichan Hong, Ed H. Chi,
  Qiaozhu Mei","Learning-to-Rank with Partitioned Preference: Fast Estimation for the
  Plackett-Luce Model",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the Plackett-Luce (PL) model based listwise learning-to-rank
(LTR) on data with partitioned preference, where a set of items are sliced into
ordered and disjoint partitions, but the ranking of items within a partition is
unknown. Given $N$ items with $M$ partitions, calculating the likelihood of
data with partitioned preference under the PL model has a time complexity of
$O(N+S!)$, where $S$ is the maximum size of the top $M-1$ partitions. This
computational challenge restrains most existing PL-based listwise LTR methods
to a special case of partitioned preference, top-$K$ ranking, where the exact
order of the top $K$ items is known. In this paper, we exploit a random utility
model formulation of the PL model, and propose an efficient numerical
integration approach for calculating the likelihood and its gradients with a
time complexity $O(N+S^3)$. We demonstrate that the proposed method outperforms
well-known LTR baselines and remains scalable through both simulation
experiments and applications to real-world eXtreme Multi-Label classification
tasks.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:11:21 GMT""},{""version"":""v2"",""created"":""Mon, 26 Oct 2020 03:46:29 GMT""},{""version"":""v3"",""created"":""Fri, 26 Feb 2021 00:58:44 GMT""}]","2021-03-01"
"2006.05068","Amrita Mukherjee","Amrita Mukherjee, Atanu Nandy, Shreekantha Sil, and Arunava
  Chakrabarti","Engineering topological phase transition and Aharonov-Bohm caging in a
  flux-staggered lattice","13 pages, 11 figures","J. Phys.: Condens. Matter 33 035502 (2020)","10.1088/1361-648X/abbc9a",,"cond-mat.mes-hall cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A tight binding network of diamond shaped unit cells trapping a staggered
magnetic flux distribution is shown to exhibit a topological phase transition
under a controlled variation of the flux trapped in a cell. A simple real space
decimation technique maps a binary flux staggered network into an equivalent
Su-Shrieffer-Heeger (SSH) model. In this way, dealing with a subspace of the
full degrees of freedom, we show that a topological phase transition can be
initiated by tuning the applied magnetic field that eventually simulates an
engineering of the numerical values of the overlap integrals in the
paradigmatic SSH model. Thus one can use an external agent, rather than
monitoring the intrinsic property of a lattice to control the topological
properties. This is advantageous from an experimental point of view. We also
provide an in-depth description and analysis of the topologically protected
edge states, and discuss how, by tuning the flux from outside one can enhance
the spatial extent of the Aharonov-Bohm caging of single particle states for
any arbitrary period of staggering. This feature can be useful for the study of
transport of quantum information. Our results are exact.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:19:40 GMT""}]","2020-10-23"
"2006.05069","Pintu Bhunia","Aniket Bhanja, Pintu Bhunia and Kallol Paul","On generalized Davis-Wielandt radius inequalities of semi-Hilbertian
  space operators","19 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $A$ be a positive (semidefinite) operator on a complex Hilbert space
$\mathcal{H}$ and let $\mathbb{A}=\left(\begin{array}{cc}
  A & O
  O & A
  \end{array}\right).$ We obtain upper and lower bounds for the
$A$-Davis-Wielandt radius of semi-Hilbertian space operators, which generalize
and improve on the existing ones. We also obtain upper bounds for the
$\mathbb{A}$-Davis-Wielandt radius of $2 \times 2$ operator matrices. Finally,
we determine the exact value for the $\mathbb{A}$-Davis-Wielandt radius of two
operator matrices $\left(\begin{array}{cc} I & X\\ 0 & 0 \end{array}\right)$
and $\left(\begin{array}{cc} 0 & X\\ 0 & 0 \end{array}\right)$, where $X $ is a
semi-Hilbertian space operator.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:32:00 GMT""}]","2020-06-11"
"2006.05070","Yu Nakayama","Yu Nakayama","Conformal invariance from scale invariance in non-linear sigma models","14 pages","Phys. Rev. D 102, 065018 (2020)","10.1103/PhysRevD.102.065018","RUP-20-20","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There exists a certain argument that in even dimensions, scale invariant
quantum field theories are conformal invariant. We may try to extend the
argument in $2n + \epsilon$ dimensions, but the naive extension has a small
loophole, which indeed shows an obstruction in non-linear sigma models in
$2+\epsilon$ dimensions. Even though it could have failed due to the loophole,
we show that scale invariance does imply conformal invariance of non-linear
sigma models in $2+\epsilon$ dimension from the seminal work by Perelman on the
Ricci flow.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:34:25 GMT""}]","2020-09-30"
"2006.05071","Majid Mirbagheri","Majid Mirbagheri, Bardia Doosti","C-SL: Contrastive Sound Localization with Inertial-Acoustic Sensors",,,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human brain employs perceptual information about the head and eye movements
to update the spatial relationship between the individual and the surrounding
environment. Based on this cognitive process known as spatial updating, we
introduce contrastive sound localization (C-SL) with mobile inertial-acoustic
sensor arrays of arbitrary geometry. C-SL uses unlabeled multi-channel audio
recordings and inertial measurement unit (IMU) readings collected during free
rotational movements of the array to learn mappings from acoustical
measurements to an array-centered direction-of-arrival (DOA) in a
self-supervised manner. Contrary to conventional DOA estimation methods that
require the knowledge of either the array geometry or source locations in the
calibration stage, C-SL is agnostic to both, and can be trained on data
collected in minimally constrained settings. To achieve this capability, our
proposed method utilizes a customized contrastive loss measuring the spatial
contrast between source locations predicted for disjoint segments of the input
to jointly update estimated DOAs and the acoustic-spatial mapping in linear
time. We provide quantitative and qualitative evaluations of C-SL comparing its
performance with baseline DOA estimation methods in a wide range of conditions.
We believe the relaxed calibration process offered by C-SL paves the way toward
truly personalized augmented hearing applications.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:36:44 GMT""}]","2020-06-11"
"2006.05072","Christian Jirauschek","Christian Jirauschek, Michael Riesch and Petar Tzenov (Department of
  Electrical and Computer Engineering, Technical University of Munich, Munich,
  Germany)","Optoelectronic device simulations based on macroscopic Maxwell-Bloch
  equations","54 pages, 23 figures","Adv. Theory Simul. 2, 1900018 (2019)","10.1002/adts.201900018",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to their intuitiveness, flexibility and relative numerical efficiency,
the macroscopic Maxwell-Bloch (MB) equations are a widely used semiclassical
and semi-phenomenological model to describe optical propagation and coherent
light-matter interaction in media consisting of discrete-level quantum systems.
This review focuses on the application of this model to advanced optoelectronic
devices, such as quantum cascade and quantum dot lasers. The Bloch equations
are here treated as a density matrix model for driven quantum systems with two
or multiple discrete energy levels, where dissipation is included by Lindblad
terms. Furthermore, the one-dimensional MB equations for semiconductor
waveguide structures and optical fibers are rigorously derived. Special
analytical solutions and suitable numerical methods are presented. Due to the
importance of the MB equations in computational electrodynamics, an emphasis is
placed on the comparison of different numerical schemes, both with and without
the rotating wave approximation. The implementation of additional effects which
can become relevant in semiconductor structures, such as spatial hole burning,
inhomogeneous broadening and local-field corrections, is discussed. Finally,
links to microscopic models and suitable extensions of the Lindblad formalism
are briefly addressed.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:41:32 GMT""}]","2020-06-11"
"2006.05073","Buyang Li","Xiaobing Feng, Buyang Li, Shu Ma","High-order mass- and energy-conserving SAV-Gauss collocation finite
  element methods for the nonlinear Schr\""odinger equation",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A family of arbitrarily high-order fully discrete space-time finite element
methods are proposed for the nonlinear Schr\""odinger equation based on the
scalar auxiliary variable formulation, which consists of a Gauss collocation
temporal discretization and the finite element spatial discretization. The
proposed methods are proved to be well-posed and conserving both mass and
energy at the discrete level. An error bound of the form $O(h^p+\tau^{k+1})$ in
the $L^\infty(0,T;H^1)$-norm is established, where $h$ and $\tau$ denote the
spatial and temporal mesh sizes, respectively, and $(p,k)$ is the degree of the
space-time finite elements. Numerical experiments are provided to validate the
theoretical results on the convergence rates and conservation properties. The
effectiveness of the proposed methods in preserving the shape of a soliton wave
is also demonstrated by numerical results.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:43:22 GMT""},{""version"":""v2"",""created"":""Fri, 1 Jan 2021 03:51:16 GMT""}]","2021-01-05"
"2006.05074","Christian Rathgeb","Christian Rathgeb, Pawel Drozdowski, Christoph Busch","Detection of Makeup Presentation Attacks based on Deep Face
  Representations","published at 25th International Conference on Pattern Recognition
  (ICPR'2020)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Facial cosmetics have the ability to substantially alter the facial
appearance, which can negatively affect the decisions of a face recognition. In
addition, it was recently shown that the application of makeup can be abused to
launch so-called makeup presentation attacks. In such attacks, the attacker
might apply heavy makeup in order to achieve the facial appearance of a target
subject for the purpose of impersonation. In this work, we assess the
vulnerability of a COTS face recognition system to makeup presentation attacks
employing the publicly available Makeup Induced Face Spoofing (MIFS) database.
It is shown that makeup presentation attacks might seriously impact the
security of the face recognition system. Further, we propose an attack
detection scheme which distinguishes makeup presentation attacks from genuine
authentication attempts by analysing differences in deep face representations
obtained from potential makeup presentation attacks and corresponding target
face images. The proposed detection system employs a machine learning-based
classifier, which is trained with synthetically generated makeup presentation
attacks utilizing a generative adversarial network for facial makeup transfer
in conjunction with image warping. Experimental evaluations conducted using the
MIFS database reveal a detection equal error rate of 0.7% for the task of
separating genuine authentication attempts from makeup presentation attacks.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:53:58 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 11:19:14 GMT""}]","2021-01-20"
"2006.05075","Shashikant Ilager Mr","Shashikant Ilager, Rajeev Muralidhar and Rajkumar Buyya","Artificial Intelligence (AI)-Centric Management of Resources in Modern
  Distributed Computing Systems","Presented at IEEE cloud summit, 2020",,,,"cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contemporary Distributed Computing Systems (DCS) such as Cloud Data Centres
are large scale, complex, heterogeneous, and distributed across multiple
networks and geographical boundaries. On the other hand, the Internet of Things
(IoT)-driven applications are producing a huge amount of data that requires
real-time processing and fast response. Managing these resources efficiently to
provide reliable services to end-users or applications is a challenging task.
The existing Resource Management Systems (RMS) rely on either static or
heuristic solutions inadequate for such composite and dynamic systems. The
advent of Artificial Intelligence (AI) due to data availability and processing
capabilities manifested into possibilities of exploring data-driven solutions
in RMS tasks that are adaptive, accurate, and efficient. In this regard, this
paper aims to draw the motivations and necessities for data-driven solutions in
resource management. It identifies the challenges associated with it and
outlines the potential future research directions detailing where and how to
apply the data-driven techniques in the different RMS tasks. Finally, it
provides a conceptual data-driven RMS model for DCS and presents the two
real-time use cases (GPU frequency scaling and data centre resource management
from Google Cloud and Microsoft Azure) demonstrating AI-centric approaches'
feasibility.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:54:07 GMT""},{""version"":""v2"",""created"":""Sat, 7 Nov 2020 01:47:18 GMT""}]","2020-11-10"
"2006.05076","Kun Kuang","Kun Kuang, Bo Li, Peng Cui, Yue Liu, Jianrong Tao, Yueting Zhuang and
  Fei Wu","Stable Prediction via Leveraging Seed Variable",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we focus on the problem of stable prediction across unknown
test data, where the test distribution is agnostic and might be totally
different from the training one. In such a case, previous machine learning
methods might exploit subtly spurious correlations in training data induced by
non-causal variables for prediction. Those spurious correlations are changeable
across data, leading to instability of prediction across data. By assuming the
relationships between causal variables and response variable are invariant
across data, to address this problem, we propose a conditional independence
test based algorithm to separate those causal variables with a seed variable as
priori, and adopt them for stable prediction. By assuming the independence
between causal and non-causal variables, we show, both theoretically and with
empirical experiments, that our algorithm can precisely separate causal and
non-causal variables for stable prediction across test data. Extensive
experiments on both synthetic and real-world datasets demonstrate that our
algorithm outperforms state-of-the-art methods for stable prediction.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:56:31 GMT""}]","2020-06-11"
"2006.05077","Yafei Song","Yafei Song, Ling Cai, Jia Li, Yonghong Tian, Mingyang Li","SEKD: Self-Evolving Keypoint Detection and Description",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Researchers have attempted utilizing deep neural network (DNN) to learn novel
local features from images inspired by its recent successes on a variety of
vision tasks. However, existing DNN-based algorithms have not achieved such
remarkable progress that could be partly attributed to insufficient utilization
of the interactive characters between local feature detector and descriptor. To
alleviate these difficulties, we emphasize two desired properties, i.e.,
repeatability and reliability, to simultaneously summarize the inherent and
interactive characters of local feature detector and descriptor. Guided by
these properties, a self-supervised framework, namely self-evolving keypoint
detection and description (SEKD), is proposed to learn an advanced local
feature model from unlabeled natural images. Additionally, to have performance
guarantees, novel training strategies have also been dedicatedly designed to
minimize the gap between the learned feature and its properties. We benchmark
the proposed method on homography estimation, relative pose estimation, and
structure-from-motion tasks. Extensive experimental results demonstrate that
the proposed method outperforms popular hand-crafted and DNN-based methods by
remarkable margins. Ablation studies also verify the effectiveness of each
critical training strategy. We will release our code along with the trained
model publicly.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:56:50 GMT""}]","2020-06-11"
"2006.05078","Samuel Daulton","Samuel Daulton, Maximilian Balandat, Eytan Bakshy","Differentiable Expected Hypervolume Improvement for Parallel
  Multi-Objective Bayesian Optimization","To appear in Advances in Neural Information Processing Systems 33,
  2020. Code is available at https://github.com/pytorch/botorch","Advances in Neural Information Processing Systems 33, 2020",,,"stat.ML cs.AI cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many real-world scenarios, decision makers seek to efficiently optimize
multiple competing objectives in a sample-efficient fashion. Multi-objective
Bayesian optimization (BO) is a common approach, but many of the
best-performing acquisition functions do not have known analytic gradients and
suffer from high computational overhead. We leverage recent advances in
programming models and hardware acceleration for multi-objective BO using
Expected Hypervolume Improvement (EHVI)---an algorithm notorious for its high
computational complexity. We derive a novel formulation of q-Expected
Hypervolume Improvement (qEHVI), an acquisition function that extends EHVI to
the parallel, constrained evaluation setting. qEHVI is an exact computation of
the joint EHVI of q new candidate points (up to Monte-Carlo (MC) integration
error). Whereas previous EHVI formulations rely on gradient-free acquisition
optimization or approximated gradients, we compute exact gradients of the MC
estimator via auto-differentiation, thereby enabling efficient and effective
optimization using first-order and quasi-second-order methods. Our empirical
evaluation demonstrates that qEHVI is computationally tractable in many
practical scenarios and outperforms state-of-the-art multi-objective BO
algorithms at a fraction of their wall time.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 06:57:47 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 19:41:18 GMT""},{""version"":""v3"",""created"":""Fri, 23 Oct 2020 04:20:57 GMT""}]","2020-11-12"
"2006.05079","Zdravko Kutnjak","B. Asbani, M. El Marssi, J.-L. Dellis, A. Lahmar, Y. Gagou, D.
  Mezzane, M. Amjoud, A. Alimoussa, Z. Kutnjak, R. Pirc, B. Ro\v{z}i\v{c}","Electrocaloric response in Lanthanum-modified lead zirconate titanate
  ceramics",,"J. Appl. Phys. 127, 224101 (2020)","10.1063/5.0005038",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent findings of a large electrocaloric (EC) effect in polymeric and
inorganic ferroelectric materials open a potential possibility of development
of solid-state cooling or heating devices of new generation with better energy
efficiency that may be less harmful for the environment. We investigate by
using direct measurements, the temperature and electric field dependence of the
electrocaloric response in Pb1-xLax(ZryTi1-y)1-x/4O3 bulk ceramics (PLZT) with
x=0.06 and 0.12. Here, the properties of the EC response were probed in a part
of the PLZT composition phase diagram with low y=0.40 composition, in which the
EC effect was not previously studied. Measurement results show the existence of
the sizeable EC response in 12/40/60 PLZT sample with the EC temperature change
({\Delta}TEC) of 2.92 K at 430 K and 80 kV/cm. This value exceeds previously
obtained {\Delta}TEC values in relaxor ferroelectric x/65/35 PLZT compositions
and rivaling the best EC response in lead magnesium niobate-lead titanate
ceramics. The electrocaloric responsivity ({\Delta}T/{\Delta}E) value of
0.41x10-6 Km/V determined at a lower electric field of 20 kV/cm and 410 K is
comparable to those observed in other perovskite ferroelectrics.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:11:51 GMT""}]","2020-06-11"
"2006.05080","Pierre Clairambault","Pierre Clairambault (LIP, PLUME)","Learning to Count up to Symmetry",,,,,"cs.LO cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we develop the theory of how to count, in thin concurrent
games, the configurations of a strategy witnessing that it reaches a certain
configuration of the game. This plays a central role in many recent
developments in concurrent games, whenever one aims to relate concurrent
strategies with weighted relational models. The difficulty, of course, is
symmetry: in the presence of symmetry many configurations of the strategy are,
morally, different instances of the same, only differing on the inessential
choice of copy indices. How do we know which ones to count? The purpose of the
paper is to clarify that, uncovering many strange phenomena and fascinating
pathological examples along the way. To illustrate the results, we show that a
collapse operation to a simple weighted relational model simply counting
witnesses is preserved under composition, provided the strategies involved do
not deadlock.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:19:44 GMT""}]","2020-06-11"
"2006.05081","Davide Faranda","Davide Faranda and Tommaso Alberti","Modelling the second wave of COVID-19 infections in France and Italy via
  a Stochastic SEIR model",,,"10.1063/5.0015943",,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  COVID-19 has forced quarantine measures in several countries across the
world. These measures have proven to be effective in significantly reducing the
prevalence of the virus. To date, no effective treatment or vaccine is
available. In the effort of preserving both public health as well as the
economical and social textures, France and Italy governments have partially
released lockdown measures. Here we extrapolate the long-term behavior of the
epidemics in both countries using a Susceptible-Exposed-Infected-Recovered
(SEIR) model where parameters are stochastically perturbed to handle the
uncertainty in the estimates of COVID-19 prevalence. Our results suggest that
uncertainties in both parameters and initial conditions rapidly propagate in
the model and can result in different outcomes of the epidemics leading or not
to a second wave of infections. Using actual knowledge, asymptotic estimates of
COVID-19 prevalence can fluctuate of order of ten millions units in both
countries.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:20:07 GMT""}]","2020-12-02"
"2006.05082","Xinshi Chen","Xinshi Chen, Hanjun Dai, Yu Li, Xin Gao, Le Song","Learning to Stop While Learning to Predict","Proceedings of the 37th International Conference on Machine Learning",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a recent surge of interest in designing deep architectures based on
the update steps in traditional algorithms, or learning neural networks to
improve and replace traditional algorithms. While traditional algorithms have
certain stopping criteria for outputting results at different iterations, many
algorithm-inspired deep models are restricted to a ``fixed-depth'' for all
inputs. Similar to algorithms, the optimal depth of a deep architecture may be
different for different input instances, either to avoid ``over-thinking'', or
because we want to compute less for operations converged already. In this
paper, we tackle this varying depth problem using a steerable architecture,
where a feed-forward deep model and a variational stopping policy are learned
together to sequentially determine the optimal number of layers for each input
instance. Training such architecture is very challenging. We provide a
variational Bayes perspective and design a novel and effective training
procedure which decomposes the task into an oracle model learning stage and an
imitation stage. Experimentally, we show that the learned deep model along with
the stopping policy improves the performances on a diverse set of tasks,
including learning sparse recovery, few-shot meta learning, and computer vision
tasks.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:22:01 GMT""}]","2020-06-11"
"2006.05083","Bernhard M\""uller","B. M\""uller (Monash University, School of Physics and Astronomy)","Hydrodynamics of core-collapse supernovae and their progenitors","Invited review article for Living Reviews in Computational
  Astrophysics. 100 pages, 15 figures","Living Rev Comput Astrophys 6, 3 (2020)","10.1007/s41115-020-0008-5",,"astro-ph.SR astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-dimensional fluid flow plays a paramount role in the explosions of
massive stars as core-collapse supernovae. In recent years, three-dimensional
(3D) simulations of these phenomena have matured significantly. Considerable
progress has been made towards identifying the ingredients for shock revival by
the neutrino-driven mechanism, and successful explosions have already been
obtained in a number of self-consistent 3D models. These advances also bring
new challenges, however. Prompted by a need for increased physical realism and
meaningful model validation, supernova theory is now moving towards a more
integrated view that connects multi-dimensional phenomena in the late
convective burning stages prior to collapse, the explosion engine, and mixing
instabilities in the supernova envelope. Here we review our current
understanding of multi-D fluid flow in core-collapse supernovae and their
progenitors. We start by outlining specific challenges faced by hydrodynamic
simulations of core-collapse supernovae and of the late convective burning
stages. We then discuss recent advances and open questions in theory and
simulations.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:23:00 GMT""}]","2020-06-11"
"2006.05084","Ibrahim Al-Nahhal Mr","Ibrahim Al-Nahhal, Octavia A. Dobre, and Salama Ikki","Reliable Detection for Spatial Modulation Systems","5 pages, 7 figures, to be appeared on IEEE VTC-Fall 2020",,,,"cs.IT cs.CC math.IT","http://creativecommons.org/licenses/by/4.0/","  Spatial modulation (SM) is a promising multiple-input multiple-output system
used to increase spectral efficiency. The maximum likelihood (ML) decoder
jointly detects the transmitted SM symbol, which is of high complexity. In this
paper, a novel reliable sphere decoder (RSD) algorithm based on tree-search is
proposed for the SM system. The basic idea of the proposed RSD algorithm is to
reduce the size of the tree-search, and then, a smart searching method inside
the reduced tree-search is performed to find the solution. The proposed RSD
algorithm provides a significant reduction in decoding complexity compared to
the ML decoder and existent decoders as well. Moreover, the RSD algorithm
provides a flexible trade-off between the bit error rate (BER) performance and
decoding complexity, so as to be reliable for a wide range of practical
hardware implementations. The BER performance and decoding complexity analysis
for the RSD algorithm are studied, and Monte Carlo simulations are then
provided to demonstrate the findings.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:25:09 GMT""}]","2020-06-11"
"2006.05085","Viktor Iv\'ady","Viktor Iv\'ady, Huijie Zheng, Arne Wickenbrock, Lykourgos Bougas,
  Georgios Chatzidrosos, Kazuo Nakamura, Hitoshi Sumiya, Takeshi Ohshima,
  Junichi Isoya, Dmitry Budker, Igor A. Abrikosov, Adam Gali","Photoluminescence at the ground state level anticrossing of the
  nitrogen-vacancy center in diamond",,"Phys. Rev. B 103, 035307 (2021)","10.1103/PhysRevB.103.035307",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nitrogen-vacancy center (NV center) in diamond at magnetic fields
corresponding to the ground state level anticrossing (GSLAC) region gives rise
to rich photoluminescence (PL) signals due to the vanishing energy gap between
the electron spin states, which enables to have an effect on the NV center's
luminescence for a broad variety of environmental couplings. In this article we
report on the GSLAC photoluminescence signature of NV ensembles in different
spin environments at various external fields. We investigate the effects of
transverse electric and magnetic fields, P1 centers, NV centers, and the
$^{13}$C nuclear spins, each of which gives rise to a unique PL signature at
the GSLAC. The comprehensive analysis of the couplings and related optical
signal at the GSLAC provides a solid ground for advancing various
microwave-free applications at the GSLAC, including but not limited to
magnetometry, spectroscopy, dynamic nuclear polarization (DNP), and nuclear
magnetic resonance (NMR) detection. We demonstrate that not only the most
abundant $^{14}$NV center but the $^{15}$NV can also be utilized in such
applications and that nuclear spins coupled to P1 centers can be polarized
directly by the NV center at the GSLAC, through a giant effective nuclear
$g$-factor arising from the NV center-P1 center-nuclear spin coupling. We
report on new alternative for measuring defect concentration in the vicinity of
NV centers and on the optical signatures of interacting, mutually aligned NV
centers.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:26:03 GMT""},{""version"":""v2"",""created"":""Fri, 19 Jun 2020 08:52:14 GMT""}]","2021-01-27"
"2006.05086","Soumya Chakrabarti","Soumya Chakrabarti and Jackson Levi Said","Geodesic Congruences and a Collapsing Stellar Distribution in f (T )
  Theories","12 pages, 5 Figures, Accepted for Publication in Physical Review D",,"10.1103/PhysRevD.101.124044",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Teleparallel Gravity (TG) describes gravitation as a torsional- rather than
curvature-based effect. As in curvature-based constructions of gravity, several
different formulations can be proposed, one of which is the Teleparallel
equivalent of General Relativity (TEGR) which is dynamically equivalent to GR.
In this work, we explore the evolution of a spatially homogeneous collapsing
stellar body in the context of two important modifications to TEGR, namely f
(T) gravity which is the TG analogue of f (R) gravity, and a nonminimal
coupling with a scalar field which has become popular in TG for its effects in
cosmology. We explore the role of geodesic deviation to study the congruence of
nearby particles in lieu of the Raychaudhuri equation. We find f (T) models
that satisfy the null energy condition and describe interesting collapse
profiles. In the case of a nonminimally coupled scalar field, we also find
potential collapse models with intriguing scalar field evolution profiles.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:26:25 GMT""}]","2020-07-01"
"2006.05087","Giulio Franzese","Giulio Franzese, Rosa Candela, Dimitrios Milios, Maurizio Filippone,
  Pietro Michiardi","Isotropic SGD: a Practical Approach to Bayesian Posterior Sampling",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we define a unified mathematical framework to deepen our
understanding of the role of stochastic gradient (SG) noise on the behavior of
Markov chain Monte Carlo sampling (SGMCMC) algorithms.
  Our formulation unlocks the design of a novel, practical approach to
posterior sampling, which makes the SG noise isotropic using a fixed learning
rate that we determine analytically, and that requires weaker assumptions than
existing algorithms. In contrast, the common traits of existing \sgmcmc
algorithms is to approximate the isotropy condition either by drowning the
gradients in additive noise (annealing the learning rate) or by making
restrictive assumptions on the \sg noise covariance and the geometry of the
loss landscape.
  Extensive experimental validations indicate that our proposal is competitive
with the state-of-the-art on \sgmcmc, while being much more practical to use.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:31:21 GMT""}]","2020-06-11"
"2006.05088","Yuan Cao","Yuan Cao, Yu-Huai Li, Kui-Xing Yang, Yang-Fan Jiang, Shuang-Lin Li,
  Xiao-Long Hu, Maimaiti Abulizi, Cheng-Long Li, Weijun Zhang, Qi-Chao Sun,
  Wei-Yue Liu, Xiao Jiang, Sheng-Kai Liao, Ji-Gang Ren, Hao Li, Lixing You,
  Zhen Wang, Juan Yin, Chao-Yang Lu, Xiang-Bin Wang, Qiang Zhang, Cheng-Zhi
  Peng, and Jian-Wei Pan","Long-distance free-space measurement-device-independent quantum key
  distribution","14 pages, 3 figures","Phys. Rev. Lett. 125, 260503 (2020)","10.1103/PhysRevLett.125.260503",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measurement-device-independent quantum key distribution (MDI-QKD), based on
two-photon interference, is immune to all attacks against the detection system
and allows a QKD network with untrusted relays. Since the MDI-QKD protocol was
proposed, fibre-based implementations have been rapidly developed towards
longer distance, higher key rates, and network verification. However, owing to
the effect of atmospheric turbulence, MDI-QKD over free-space channel remains
experimentally challenging. Here, by developing the robust adaptive optics
system, high precision time synchronization and frequency locking between
independent photon sources located far apart, we realised the first free-space
MDI-QKD over a 19.2-km urban atmospheric channel, which well exceeds the
effective atmospheric thickness. Our experiment takes the first step towards
satellite-based MDI-QKD. Moreover, the technology developed here opens the way
to quantum experiments in free space involving long-distance interference of
independent single photons.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:33:49 GMT""}]","2020-12-29"
"2006.05089","Sachithra Lokuge","Sachithra Lokuge, Darshana Sedera","Enterprise Systems Lifecycle-wide Innovation Readiness",,,,,"cs.CY cs.SY eess.SY","http://creativecommons.org/publicdomain/zero/1.0/","  Enterprise Systems have been touted as a key driver of delivering benefits
through innovation in corporate Information Systems. The advent of such systems
expects to deliver best practices that improve organizational performance. Yet,
most Enterprise System installations struggle to see lifecycle-wide value of
it. Considering that Enterprise Systems deliver lifecycle-wide innovation; we
observe organizational readiness for lifecycle-wide Enterprise Systems
innovation. The A VICTORY apriori model compares contributions of eight
constructs for organizational readiness for continuous Enterprise Systems
innovation. The model is tested responses of both client and implementation
partner. Results indicate that six of the eight constructs of readiness make
significant contributions to organizational readiness for Enterprise Systems
innovation.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:35:11 GMT""}]","2020-06-11"
"2006.05090","Pengcheng Su","Pengcheng Su, Yu Chen, Jiaming Zhang, Yang LI, Chao Yang","Optical System Design of Bionic Compound Eye with Broad Field of View",,,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In nature, many common insects have compound eyes composed of many small eyes
arranged on a curved retina. This kind of vision systems have many advantages,
such as small size, large FOV (field of view) and high sensitivity, which have
attracted extensive attention and research from world-wide researchers. It has
good application prospects in military strikes and mechanical vision. In this
paper, a new type of miniature compound eye system with large FOV is designed,
which contains a micro-lens array and a relay system. Hexagonal micro-lens
array are spliced seamlessly as a curved shell in the designed compound eye
system. The intermediate curved image formed by the curved array is converted
to a planar image by introducing a relay system. After combination and
optimization of the micro-lens array and the relay system, the MTF values at
89.3lp/mm for each FOV within 120.5{\deg} are greater than 0.3, and the
corresponding RMS spot radii less than the radius of the Airy disk, which
proves the good imaging quality for the compound eye. The clear aperture of a
single micro lens is 250{\mu}m with FOV 6{\deg}. After tolerance analysis, the
results show the image quality still holds good enough performance and meets
the requirements of the additive manufacturing process.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:37:40 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jul 2020 20:47:46 GMT""}]","2020-07-13"
"2006.05091","Yuecong Xu","Yuecong Xu, Haozhi Cao, Jianfei Yang, Kezhi Mao, Jianxiong Yin and
  Simon See","PNL: Efficient Long-Range Dependencies Extraction with Pyramid Non-Local
  Module for Action Recognition","Single column, 26 pages, 6 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Long-range spatiotemporal dependencies capturing plays an essential role in
improving video features for action recognition. The non-local block inspired
by the non-local means is designed to address this challenge and have shown
excellent performance. However, the non-local block brings significant increase
in computation cost to the original network. It also lacks the ability to model
regional correlation in videos. To address the above limitations, we propose
Pyramid Non-Local (PNL) module, which extends the non-local block by
incorporating regional correlation at multiple scales through a pyramid
structured module. This extension upscales the effectiveness of non-local
operation by attending to the interaction between different regions. Empirical
results prove the effectiveness and efficiency of our PNL module, which
achieves state-of-the-art performance of 83.09% on the Mini-Kinetics dataset,
with decreased computation cost compared to the non-local block.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:40:23 GMT""}]","2020-06-11"
"2006.05092","Niklas Hartung","Niklas Hartung, Jens Borghardt","A mechanistic framework for a priori pharmacokinetic predictions of
  orally inhaled drugs",,,"10.1371/journal.pcbi.1008466",,"q-bio.TO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fate of orally inhaled drugs is determined by pulmonary pharmacokinetic
(PK) processes such as particle deposition, pulmonary drug dissolution, and
mucociliary clearance. Although each single process has been systematically
investigated, a quantitative understanding on their interaction remains limited
and hence identifying optimal drug and formulation characteristics for orally
inhaled drugs is still challenging. To investigate this complex interplay, the
pulmonary processes can be integrated into mathematical models. However,
existing modeling attempts considerably simplify these processes or are not
systematically evaluated against (clinical) data. In this work, we developed a
mathematical framework based on physiologically-structured population equations
to integrate all relevant pulmonary processes mechanistically. A tailored
numerical resolution strategy was chosen and the mechanistic model was
evaluated systematically against different clinical datasets. Without any
parameter estimation based on individual study data, the developed model
simultaneously predicted (1) lung retention profiles of inhaled insoluble
particles, (2) particle size-dependent PK of inhaled monodisperse particles,
(3) PK differences between inhaled fluticasone propionate and budesonide, and
(4) PK differences between healthy volunteers and asthmatic patients. Finally,
to identify the most impactful optimization criteria for orally inhaled drugs,
we investigated the impact of input parameters on both pulmonary and systemic
exposure. Solubility of the inhaled drug did not have any relevant impact on
local and systemic PK. Instead, pulmonary dissolution rate, particle size,
tissue affinity, and systemic clearance were impactful potential optimization
parameters. In the future, the developed prediction framework should be
considered a powerful tool to identify optimal drug and formulation
characteristics.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:41:24 GMT""}]","2021-01-27"
"2006.05093","Donglai Feng","X. Lou, H. C. Xu, T. L. Yu, Y. H. Song, C. H. P. Wen, W. Z. Wei, A.
  Leithe-Jasper, Z. F. Ding, L. Shu, S. Kirchner, R. Peng, and D. L. Feng","Distinct Kondo Screening Behaviors in Heavy Fermion Filled Skutterudites
  with 4f1 and 4f2 Configurations","6 pages, 4 figures","Phys. Rev. Lett. 126, 136402 (2021)","10.1103/PhysRevLett.126.136402",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Filled-skutterudite heavy fermion (HF) compounds host rich ground states
depending on the f electron configurations. CeOs4Sb12 (COS) with Ce 4f1, and
PrOs4Sb12 (POS) with Pr 4f2 configurations show distinct properties of Kondo
insulating and HF superconductivity, respectivity. We unveiled the underlying
microscopic origin by angle-resolved photoemission spectroscopy studies. Their
eV-scale band structure matches well, representing the common characters of
conduction electrons in ROs4Sb12 systems (R = rare earth). However, f electrons
interact differently with conduction electrons in them. Strong hybridization
between conduction electrons and f electrons is observed in COS with band
dependent hybridization gaps, and the development of Kondo insulating state is
directly revealed. Although the ground state of POS is a singlet, finite but
incoherent hybridization exists due to Kondo scattering with the thermally
excited triplet crystalline electric field (CEF) state. Our results help to
understand the intriguing properties in COS and POS, and provide a clean
demonstration of the microscopic differences in HF systems with 4f1 and 4f2
configurations.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:44:17 GMT""}]","2021-04-07"
"2006.05094","Branislav Kveton","Branislav Kveton, Martin Mladenov, Chih-Wei Hsu, Manzil Zaheer, Csaba
  Szepesvari, and Craig Boutilier","Meta-Learning Bandit Policies by Gradient Ascent",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most bandit policies are designed to either minimize regret in any problem
instance, making very few assumptions about the underlying environment, or in a
Bayesian sense, assuming a prior distribution over environment parameters. The
former are often too conservative in practical settings, while the latter
require assumptions that are hard to verify in practice. We study bandit
problems that fall between these two extremes, where the learning agent has
access to sampled bandit instances from an unknown prior distribution
$\mathcal{P}$ and aims to achieve high reward on average over the bandit
instances drawn from $\mathcal{P}$. This setting is of a particular importance
because it lays foundations for meta-learning of bandit policies and reflects
more realistic assumptions in many practical domains. We propose the use of
parameterized bandit policies that are differentiable and can be optimized
using policy gradients. This provides a broadly applicable framework that is
easy to implement. We derive reward gradients that reflect the structure of
bandit problems and policies, for both non-contextual and contextual settings,
and propose a number of interesting policies that are both differentiable and
have low regret. Our algorithmic and theoretical contributions are supported by
extensive experiments that show the importance of baseline subtraction, learned
biases, and the practicality of our approach on a range problems.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:45:41 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 03:44:39 GMT""}]","2021-01-07"
"2006.05095","Th\'eo Giraudon","Th\'eo Giraudon, Vincent Gripon, Matthias L\""owe, Franck Vermet","Towards an Intrinsic Definition of Robustness for a Classifier","13 pages",,,,"cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The robustness of classifiers has become a question of paramount importance
in the past few years. Indeed, it has been shown that state-of-the-art deep
learning architectures can easily be fooled with imperceptible changes to their
inputs. Therefore, finding good measures of robustness of a trained classifier
is a key issue in the field. In this paper, we point out that averaging the
radius of robustness of samples in a validation set is a statistically weak
measure. We propose instead to weight the importance of samples depending on
their difficulty. We motivate the proposed score by a theoretical case study
using logistic regression, where we show that the proposed score is independent
of the choice of the samples it is evaluated upon. We also empirically
demonstrate the ability of the proposed score to measure robustness of
classifiers with little dependence on the choice of samples in more complex
settings, including deep convolutional neural networks and real datasets.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:47:21 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 12:40:07 GMT""}]","2020-06-12"
"2006.05096","Huaizheng Zhang","Huaizheng Zhang, Yuanming Li, Yizheng Huang, Yonggang Wen, Jianxiong
  Yin and Kyle Guan","MLModelCI: An Automatic Cloud Platform for Efficient MLaaS","4 pages, 4 figures","In Proceedings of the 28th ACM International Conference on
  Multimedia (2020) 4453-4456","10.1145/3394171.3414535",,"cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MLModelCI provides multimedia researchers and developers with a one-stop
platform for efficient machine learning (ML) services. The system leverages
DevOps techniques to optimize, test, and manage models. It also containerizes
and deploys these optimized and validated models as cloud services (MLaaS). In
its essence, MLModelCI serves as a housekeeper to help users publish models.
The models are first automatically converted to optimized formats for
production purpose and then profiled under different settings (e.g., batch size
and hardware). The profiling information can be used as guidelines for
balancing the trade-off between performance and cost of MLaaS. Finally, the
system dockerizes the models for ease of deployment to cloud environments. A
key feature of MLModelCI is the implementation of a controller, which allows
elastic evaluation which only utilizes idle workers while maintaining online
service quality. Our system bridges the gap between current ML training and
serving systems and thus free developers from manual and tedious work often
associated with service deployment. We release the platform as an open-source
project on GitHub under Apache 2.0 license, with the aim that it will
facilitate and streamline more large-scale ML applications and research
projects.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:48:20 GMT""}]","2020-12-16"
"2006.05097","YueFeng Chen","Xiaofeng Mao, Yuefeng Chen, Yuhong Li, Yuan He, Hui Xue","GAP++: Learning to generate target-conditioned adversarial examples","Accepted to IJCAI 2019 AIBS Workshop",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial examples are perturbed inputs which can cause a serious threat
for machine learning models. Finding these perturbations is such a hard task
that we can only use the iterative methods to traverse. For computational
efficiency, recent works use adversarial generative networks to model the
distribution of both the universal or image-dependent perturbations directly.
However, these methods generate perturbations only rely on input images. In
this work, we propose a more general-purpose framework which infers
target-conditioned perturbations dependent on both input image and target
label. Different from previous single-target attack models, our model can
conduct target-conditioned attacks by learning the relations of attack target
and the semantics in image. Using extensive experiments on the datasets of
MNIST and CIFAR10, we show that our method achieves superior performance with
single target attack models and obtains high fooling rates with small
perturbation norms.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:49:49 GMT""}]","2020-06-11"
"2006.05098","Vladimir Zhuravlev","Tsofar Maniv and Vladimir Zhuravlev","Fluctuations superconductivity and giant negative magnetoresistance in a
  gate voltage tuned 2D electron liquid with strong spin-orbit impurity
  scattering","supplemental material included","Phys. Rev. B 104, 054503 (2021)","10.1103/PhysRevB.104.054503",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a quantitative theory of the gate-voltage tuned
superconductor-to-insulator transition (SIT) observed experimentally in the 2D
electron liquid created in the (111) interface between crystalline SrTiO_3 and
LaAlO_3 . Considering two fundamental opposing effects of Cooper-pair
fluctuations; the critical conductivity enhancement, known as
para-conductivity, and its suppression associated with the loss of unpaired
electrons due to Cooper-pairs formation, we employ the standard thermal
fluctuations theory, modified to include quantum fluctuations within a novel
phenomenological approach. Relying on the quantitative agreement found between
our theory and a large body of experimental sheet-resistance data, we conclude
that spin-orbit scatterings, via significant enhancement of the interaction
between fluctuations, strongly enhance the sheet resistance peak at high
fields, and reveal anomalous metallic behavior at low fields, due to mixing of
relatively heavy electron bands with a light electron band near a Lifshitz
point.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:58:06 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 07:46:36 GMT""},{""version"":""v3"",""created"":""Mon, 29 Mar 2021 09:20:58 GMT""}]","2021-08-11"
"2006.05099","Tristan Bice","Tristan Bice and Wieslaw Kubis","Lattice-Free and Point-Free: Vickers Duality for Subbases of Stably
  Locally Compact Spaces",,,,,"math.GN math.CT math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by classic work of Wallman and more recent work of
Jung-Kegelmann-Moshier and Vickers, we show how to encode general subbases of
stably locally compact spaces via certain entailment relations. We further
build this up to a categorical duality encompassing the classic Priestley-Stone
duality and its various extensions to stably locally compact spaces by Shirota,
De Vries, Hofmann-Lawson (in the stable case), Jung-S\""underhauf,
Hansoul-Poussart, Bezhanishvili-Jansana, van Gool and Bice-Starling.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:59:51 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 18:57:19 GMT""},{""version"":""v3"",""created"":""Wed, 12 Apr 2023 16:38:12 GMT""}]","2023-04-13"
"2006.05100","Yanpeng Wang","Yanpeng Wang, Binzhou Xia and Sanming Zhou","Regular sets in Cayley graphs","12 pages",,"10.1007/s10801-022-01181-8.",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a graph $\Gamma$ with vertex set $V$, a subset $C$ of $V$ is called an
$(a,b)$-perfect set if every vertex in $C$ has exactly $a$ neighbors in $C$ and
every vertex in $V\setminus C$ has exactly $b$ neighbors in $C$, where $a$ and
$b$ are nonnegative integers. In the literature $(0,1)$-perfect sets are known
as perfect codes and $(1,1)$-perfect sets are known as total perfect codes. In
this paper we prove that, for any finite group $G$, if a non-trivial normal
subgroup $H$ of $G$ is a perfect code in some Cayley graph of $G$, then it is
also an $(a,b)$-perfect set in some Cayley graph of $G$ for any pair of
integers $a$ and $b$ with $0\leqslant a\leqslant|H|-1$ and $0\leqslant
b\leqslant |H|$ such that $\gcd(2,|H|-1)$ divides $a$. A similar result
involving total perfect codes is also proved in the paper.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:02:48 GMT""},{""version"":""v2"",""created"":""Sat, 8 May 2021 12:58:39 GMT""},{""version"":""v3"",""created"":""Fri, 4 Nov 2022 07:49:19 GMT""}]","2022-11-07"
"2006.05101","Stefan Glock","Stefan Glock","A note on dense bipartite induced subgraphs","3 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This exposition contains a short and streamlined proof of the recent result
of Kwan, Letzter, Sudakov and Tran that every triangle-free graph with minimum
degree $d$ contains an induced bipartite subgraph with average degree
$\Omega(\ln d/\ln\ln d)$.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:07:41 GMT""}]","2020-06-11"
"2006.05102","Wonse Jo","Wonse Jo, Shyam Sundar Kannan, Go-Eum Cha, Ahreum Lee, and Byung-Cheol
  Min","ROSbag-based Multimodal Affective Dataset for Emotional and Cognitive
  States","Accepted for publication in SMC2020, TORONTO, CANADA",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a new ROSbag-based multimodal affective dataset for
emotional and cognitive states generated using Robot Operating System (ROS). We
utilized images and sounds from the International Affective Pictures System
(IAPS) and the International Affective Digitized Sounds (IADS) to stimulate
targeted emotions (happiness, sadness, anger, fear, surprise, disgust, and
neutral), and a dual N-back game to stimulate different levels of cognitive
workload. 30 human subjects participated in the user study; their physiological
data was collected using the latest commercial wearable sensors, behavioral
data was collected using hardware devices such as cameras, and subjective
assessments were carried out through questionnaires. All data was stored in
single ROSbag files rather than in conventional Comma-separated values (CSV)
files. This not only ensures synchronization of signals and videos in a data
set, but also allows researchers to easily analyze and verify their algorithms
by connecting directly to this dataset through ROS. The generated affective
dataset consists of 1,602 ROSbag files, and size of the dataset is about 787GB.
The dataset is made publicly available. We expect that our dataset can be great
resource for many researchers in the fields of affective computing, HCI, and
HRI.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:09:42 GMT""},{""version"":""v2"",""created"":""Tue, 20 Oct 2020 15:47:48 GMT""}]","2020-10-21"
"2006.05103","Sarath Sivaprasad","Sarath Sivaprasad, Ankur Singh, Naresh Manwani, Vineet Gandhi","The Curious Case of Convex Neural Networks","20 pages, accepted at ECML-PKDD",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate a constrained formulation of neural networks
where the output is a convex function of the input. We show that the convexity
constraints can be enforced on both fully connected and convolutional layers,
making them applicable to most architectures. The convexity constraints include
restricting the weights (for all but the first layer) to be non-negative and
using a non-decreasing convex activation function. Albeit simple, these
constraints have profound implications on the generalization abilities of the
network. We draw three valuable insights: (a) Input Output Convex Neural
Networks (IOC-NNs) self regularize and reduce the problem of overfitting; (b)
Although heavily constrained, they outperform the base multi layer perceptrons
and achieve similar performance as compared to base convolutional architectures
and (c) IOC-NNs show robustness to noise in train labels. We demonstrate the
efficacy of the proposed idea using thorough experiments and ablation studies
on standard image classification datasets with three different neural network
architectures.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:16:38 GMT""},{""version"":""v2"",""created"":""Sat, 12 Dec 2020 05:57:08 GMT""},{""version"":""v3"",""created"":""Sat, 10 Jul 2021 10:51:29 GMT""}]","2021-07-13"
"2006.05104","Takaaki Nishimoto","Takaaki Nishimoto and Yasuo Tabei","Optimal-Time Queries on BWT-runs Compressed Indexes",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Indexing highly repetitive strings (i.e., strings with many repetitions) for
fast queries has become a central research topic in string processing, because
it has a wide variety of applications in bioinformatics and natural language
processing. Although a substantial number of indexes for highly repetitive
strings have been proposed thus far, developing compressed indexes that support
various queries remains a challenge. The run-length Burrows-Wheeler transform
(RLBWT) is a lossless data compression by a reversible permutation of an input
string and run-length encoding, and it has received interest for indexing
highly repetitive strings. LF and $\phi^{-1}$ are two key functions for
building indexes on RLBWT, and the best previous result computes LF and
$\phi^{-1}$ in $O(\log \log n)$ time with $O(r)$ words of space for the string
length $n$ and the number $r$ of runs in RLBWT. In this paper, we improve LF
and $\phi^{-1}$ so that they can be computed in a constant time with $O(r)$
words of space. Subsequently, we present OptBWTR (optimal-time queries on
BWT-runs compressed indexes), the first string index that supports various
queries including locate, count, extract queries in optimal time and $O(r)$
words of space.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:21:39 GMT""},{""version"":""v2"",""created"":""Thu, 16 Jul 2020 09:44:44 GMT""},{""version"":""v3"",""created"":""Fri, 16 Apr 2021 04:34:44 GMT""}]","2021-04-19"
"2006.05105","Irina Kmit","Irina Kmit, Natalya Lyul'ko","Finite Time Stabilization of Nonautonomous First Order Hyperbolic
  Systems","30 pages. Corollary 1.9 and Subsections 2.3.1 and 3.4.2 are new",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address nonautonomous initial boundary value problems for decoupled linear
first-order one-dimensional hyperbolic systems, investigating the phenomenon of
finite time stabilization. We establish sufficient and necessary conditions
ensuring that solutions stabilize to zero in a finite time for any initial
$L^2$-data. In the nonautonomous case we give a combinatorial criterion stating
that the robust stabilization occurs if and only if the matrix of reflection
boundary coefficients corresponds to a directed acyclic graph. An equivalent
robust algebraic criterion is that the adjacency matrix of this graph is
nilpotent. In the autonomous case we also provide a spectral stabilization
criterion, which is nonrobust with respect to perturbations of the coefficients
of the hyperbolic system.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:26:39 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 21:13:55 GMT""}]","2021-07-05"
"2006.05106","Tatsuhiro Misumi","Toshiaki Fujimori, Etsuko Itou, Tatsuhiro Misumi, Muneto Nitta,
  Norisuke Sakai","Lattice ${\mathbb C} P^{N-1}$ model with ${\mathbb Z}_{N}$ twisted
  boundary condition: bions, adiabatic continuity and pseudo-entropy","31 pages, 13 figures; (v2) minor corrections, to appear in JHEP","JHEP 08 (2020) 011","10.1007/JHEP08(2020)011",,"hep-th hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the lattice ${\mathbb C} P^{N-1}$ sigma model on
$S_{s}^{1}$(large) $\times$ $S_{\tau}^{1}$(small) with the ${\mathbb Z}_{N}$
symmetric twisted boundary condition, where a sufficiently large ratio of the
circumferences ($L_{s}\gg L_{\tau}$) is taken to approximate ${\mathbb R}
\times S^1$. We find that the expectation value of the Polyakov loop, which is
an order parameter of the ${\mathbb Z}_N$ symmetry, remains consistent with
zero ($|\langle P\rangle|\sim 0$) from small to relatively large inverse
coupling $\beta$ (from large to small $L_{\tau}$). As $\beta$ increases, the
distribution of the Polyakov loop on the complex plane, which concentrates
around the origin for small $\beta$, isotropically spreads and forms a regular
$N$-sided-polygon shape (e.g. pentagon for $N=5$), leading to $|\langle
P\rangle| \sim 0$. By investigating the dependence of the Polyakov loop on
$S_{s}^{1}$ direction, we also verify the existence of fractional instantons
and bions, which cause tunneling transition between the classical $N$ vacua and
stabilize the ${\mathbb Z}_{N}$ symmetry. Even for quite high $\beta$, we find
that a regular-polygon shape of the Polyakov-loop distribution, even if it is
broken, tends to be restored and $|\langle P\rangle|$ gets smaller as the
number of samples increases. To discuss the adiabatic continuity of the vacuum
structure from another viewpoint, we calculate the $\beta$ dependence of
``pseudo-entropy"" density $\propto\langle T_{xx}-T_{\tau\tau}\rangle$. The
result is consistent with the absence of a phase transition between large and
small $\beta$ regions.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:27:17 GMT""},{""version"":""v2"",""created"":""Mon, 3 Aug 2020 08:20:49 GMT""}]","2020-08-14"
"2006.05107","Hiroshi Kimura","Hiroshi Kimura, Koji Wada, Fumi Yoshida, Peng K. Hong, Hiroki Senshu,
  Tomoko Arai, Takayuki Hirai, Masanori Kobayashi, Ko Ishibashi, Manabu Yamada","The tensile strength of dust aggregates consisting of small elastic
  grains: Constraints on the size of condensates in protoplanetary disks","19 pages, 11 figures, published in Monthly Notices of the Royal
  Astronomical Society","MNRAS 496, 1667-1682 (2020)","10.1093/mnras/staa1641",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A consensus view on the formation of planetesimals is now exposed to a
threat, since recent numerical studies on the mechanical properties of dust
aggregates tend to dispute the conceptual picture that submicrometer-sized
grains conglomerate into planetesimals in protoplanetary disks. With the advent
of precise laboratory experiments and extensive computer simulations on the
interaction between elastic spheres comprising dust aggregates, we revisit a
model for the tensile strength of dust aggregates consisting of small elastic
grains. In the framework of contact mechanics and fracture mechanics, we
examine outcomes of computer simulations and laboratory experiments on the
tensile strength of dust aggregates. We provide a novel analytical formula that
explicitly incorporates the volume effect on the tensile strength, namely, the
dependence of tensile strength on the volume of dust aggregates. We find that
our model for the tensile strength of dust aggregates well reproduces results
of computer simulations and laboratory experiments, if appropriate values are
adopted for the elastic parameters used in the model. Moreover, the model with
dust aggregates of submicrometer-sized grains is in good harmony with the
tensile strength of cometary dust and meteoroids derived from astronomical
observations. Therefore, we reaffirm the commonly believed idea that the
formation of planetesimals begins with conglomeration of submicrometer-sized
grains condensed in protoplanetary disks.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:28:39 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 01:14:40 GMT""}]","2020-07-09"
"2006.05108","Thibaut Devolder","T. Devolder, O. Bultynck, P. Bouquin, V. D. Nguyen, S. Rao, D. Wan, B.
  Sor\'ee, I. P. Radu, G. S. Kar, S. Couet","Back-hopping in Spin-Transfer-Torque switching of perpendicularly
  magnetized tunnel junctions","submitted to Phys Rev. B",,"10.1103/PhysRevB.102.184406",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyse the phenomenon of back-hopping in spin-torque induced switching of
the magnetization in perpendicularly magnetized tunnel junctions. The analysis
is based on single-shot time-resolved conductance measurements of the
pulse-induced back-hopping. Studying several material variants reveals that the
back-hopping is a feature of the nominally fixed system of the tunnel junction.
The back-hopping is found to proceed by two sequential switching events that
lead to a final state P' of conductance close to --but distinct from-- that of
the conventional parallel state. The P' state does not exist at remanence. It
generally relaxes to the conventional antiparallel state if the current is
removed. The P' state involves a switching of the sole spin-polarizing part of
the fixed layers. The analysis of literature indicates that back-hopping occurs
only when the spin-polarizing layer is too weakly coupled to the rest of the
fixed system, which justifies a posteriori the mitigation strategies of
back-hopping that were implemented empirically in spin-transfer-torque magnetic
random access memories.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:28:44 GMT""}]","2020-12-02"
"2006.05109","Valerio Perrone","Valerio Perrone, Michele Donini, Muhammad Bilal Zafar, Robin
  Schmucker, Krishnaram Kenthapadi, C\'edric Archambeau","Fair Bayesian Optimization",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given the increasing importance of machine learning (ML) in our lives,
several algorithmic fairness techniques have been proposed to mitigate biases
in the outcomes of the ML models. However, most of these techniques are
specialized to cater to a single family of ML models and a specific definition
of fairness, limiting their adaptibility in practice. We introduce a general
constrained Bayesian optimization (BO) framework to optimize the performance of
any ML model while enforcing one or multiple fairness constraints. BO is a
model-agnostic optimization method that has been successfully applied to
automatically tune the hyperparameters of ML models. We apply BO with fairness
constraints to a range of popular models, including random forests, gradient
boosting, and neural networks, showing that we can obtain accurate and fair
solutions by acting solely on the hyperparameters. We also show empirically
that our approach is competitive with specialized techniques that enforce
model-specific fairness constraints, and outperforms preprocessing methods that
learn fair representations of the input data. Moreover, our method can be used
in synergy with such specialized fairness techniques to tune their
hyperparameters. Finally, we study the relationship between fairness and the
hyperparameters selected by BO. We observe a correlation between regularization
and unbiased models, explaining why acting on the hyperparameters leads to ML
models that generalize well and are fair.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:31:08 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 11:56:24 GMT""},{""version"":""v3"",""created"":""Fri, 18 Jun 2021 19:46:07 GMT""}]","2021-06-22"
"2006.05110","Vincent Bansaye","Vincent Bansaye (CMAP), Maria-Emilia Caballero, Sylvie M\'el\'eard
  (CMAP), Jaime San Martin (UCHILE)","Scaling limits of bisexual Galton-Watson processes",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bisexual Galton-Watson processes are discrete Markov chains where
reproduction events are due to mating of males and females. Owing to this
interaction, the standard branching property of Galton-Watson processes is
lost. We prove tightness for conveniently rescaled bisexual Galton-Watson
processes, based on recent techniques developed by Bansaye, Caballero and
M{\'e}l{\'e}ard. We also identify the possible limits of these rescaled
processes as solutions of a stochastic system, coupling two equations through
singular coefficients in Poisson terms added to square roots as coefficients of
Brownian motions. Under some additional integrability assumptions, pathwise
uniqueness of this limiting system of stochastic differential equations and
convergence of the rescaled processes are obtained. Two examples corresponding
to mutual fidelity are considered.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:31:33 GMT""}]","2020-06-11"
"2006.05111","Kaustav Mukherjee Dr","Kavita Yadav and K. Mukherjee","Effect of partial substitution of iso-valent Mo at Cr-site on electronic
  structure and physical properties of Fe2CrAl",,"Intermetallics 133, 107153 (2021)",,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heusler alloy Fe2CrAl exhibits a ferromagnetic behaviour below Curie
temperature (TC) ~ 202 K along with presence of cluster glass (CG) phase near
freezing temperature (Tf) ~ 3.9 K and Griffiths phase (GP) above 300 K. The
physical properties of this alloy are very sensitive to substitutions and
anti-site disorder. Here, we investigate the effect of partial substitution of
Mo at Cr-site on physical properties of Fe2CrAl. Structural and morphological
analysis confirms the single cubic structure of the substituted alloys.
Increment in Mo concentration shifts the TC towards lower temperature, which is
ascribed to the effect of increased hybridization strength between 3d-4d states
of Fe/Cr/Mo. Additionally, systematic analysis of AC susceptibility, magnetic
memory effect and time dependent magnetization studies confirm the presence of
CG-like phase near (Tf) ~ 3.5 K in Fe2Cr0.95Mo0.05Al. Such feature gets
suppressed towards lower temperature with an increase of Mo concentration, i.e.
below 1.8 K in Fe2Cr0.85Mo0.15Al. The origin of the glassy signature is
ascribed to the decrement in magnetic anisotropy with Mo concentration. A
partial increment in magnetic entropy change is also noted near TC with the
increase in Mo substitution. Interestingly, at high temperatures (above 350 K),
GP phase persists in both the alloys due to the presence of anti-site disorder.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:34:42 GMT""},{""version"":""v2"",""created"":""Fri, 15 Oct 2021 14:50:46 GMT""}]","2021-10-22"
"2006.05112","Yajun Ma","Yajun Ma, Nanqing Ding and Yafeng Zhang","Auslander-Buchweitz Approximation Theory for Extriangulated Categories","Added references. Corrected typos",,,,"math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extriangulated categories were introduced by Nakaoka and Palu as a
simultaneous generalization of exact categories and triangulated categories. In
this paper, we introduce and develop an analogous theory of Auslander-Buchweitz
approximations for extriangulated categories. We establish the existence of
precovers pand preenvelopesq and obtain characterizations of relative
homological dimensions, which are based on certain subcategories under
finiteness of resolutions. Finally, we give a description of cotorsion pairs on
extriangulated categories under some conditions, and provide a characterization
of silting subcategories on stable categories. Keywords: Extriangulated
category; Homological dimension; Cogenerator; Cotorsion pair.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:34:57 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jul 2020 14:42:08 GMT""}]","2020-07-15"
"2006.05113","Lukas Muttenthaler","Lukas Muttenthaler, Nora Hollenstein, Maria Barrett","Human brain activity for machine attention",,,,,"cs.CL cs.LG q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cognitively inspired NLP leverages human-derived data to teach machines about
language processing mechanisms. Recently, neural networks have been augmented
with behavioral data to solve a range of NLP tasks spanning syntax and
semantics. We are the first to exploit neuroscientific data, namely
electroencephalography (EEG), to inform a neural attention model about language
processing of the human brain. The challenge in working with EEG data is that
features are exceptionally rich and need extensive pre-processing to isolate
signals specific to text processing. We devise a method for finding such EEG
features to supervise machine attention through combining theoretically
motivated cropping with random forest tree splits. After this dimensionality
reduction, the pre-processed EEG features are capable of distinguishing two
reading tasks retrieved from a publicly available EEG corpus. We apply these
features to regularise attention on relation classification and show that EEG
is more informative than strong baselines. This improvement depends on both the
cognitive load of the task and the EEG frequency domain. Hence, informing
neural attention models with EEG signals is beneficial but requires further
investigation to understand which dimensions are the most useful across NLP
tasks.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:39:07 GMT""},{""version"":""v2"",""created"":""Fri, 2 Oct 2020 22:06:31 GMT""}]","2020-10-06"
"2006.05114","Remi Carles","Weizhu Bao, Remi Carles (IRMAR), Chunmei Su, Qinglin Tang","Error estimates of local energy regularization for the logarithmic
  Schrodinger equation","31 pages, 10 figures, final version. More explanations and some
  proofs are more detailed",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The logarithmic nonlinearity has been used in many partial differential
equations (PDEs) for modeling problems in various applications.Due to the
singularity of the logarithmic function, it introducestremendous difficulties
in establishing mathematical theories, as well asin designing and analyzing
numerical methods for PDEs with such nonlinearity. Here we take the logarithmic
Schr\""odinger equation (LogSE)as a prototype model. Instead of regularizing
$f(\rho)=\ln \rho$ in theLogSE directly and globally as being done in the
literature, we propose a local energy regularization (LER) for the LogSE
byfirst regularizing $F(\rho)=\rho\ln \rho -\rho$ locally near $\rho=0^+$ with
a polynomial approximation in the energy functional of the LogSE and then
obtaining an energy regularized logarithmic Schr\""odinger equation (ERLogSE)
via energy variation. Linear convergence is established between the solutions
of ERLogSE and LogSE in terms of a small regularization parameter $0<\ep\ll1$.
Moreover, the conserved energy of the ERLogSE converges to that of LogSE
quadratically, which significantly improvesthe linear convergence rate of the
regularization method in the literature. Error estimates are alsopresented for
solving the ERLogSE by using Lie-Trotter splittingintegrators. Numerical
results are reported to confirm our errorestimates of the LER and of the
time-splitting integrators for theERLogSE. Finally our results suggest that the
LER performs better than regularizing the logarithmic nonlinearity in the LogSE
directly.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:43:42 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 08:04:02 GMT""}]","2021-09-07"
"2006.05115","V. A. Yerokhin","Vladimir A. Yerokhin, Vojt\v{e}ch Patk\'o\v{s}, Mariusz Puchalski,
  Krzysztof Pachucki","QED calculation of ionization energies of $1snd$ states in helium",,"Phys. Rev. A 102, 012807 (2020)","10.1103/PhysRevA.102.012807",,"physics.atom-ph hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum electrodynamical (QED) calculations of ionization energies of the
$1snd\,D$ states are performed for the helium atom. We reproduce the previously
known relativistic and QED effects up to order $m\alpha^5$ and extend the
theory by calculating the complete $m\alpha^6$ correction. The total
contribution of the $m\alpha^6$ effects is shown to be much smaller than
previously estimated, due to a large cancelation between the radiative and
non-radiative parts of this correction. As a result of our calculations, we
confirm the previously reported deviations between measured transition energies
and theoretical predictions for the $nD$--$2S$ and $nD$--$2P$ transitions.
Possible reasons for this discrepancy are analyzed.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:43:56 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 09:41:18 GMT""}]","2020-07-14"
"2006.05116","Jean-Louis Verger-Gaugry","Jean-Louis Verger-Gaugry (LAMA, UGA [2016-2019], CNRS), Radhakrishnan
  Nair, Michel Weber (IRMA)","On good universality and the Riemann hypothesis","Advances in Mathematics, Elsevier, 2021",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use subsequence and moving average ergodic theorems applied to Boole's
transformation and its variants and their invariant measures on the real line
to give new characterisations of the Lindelh{\""o}f Hypothesis and the Riemann
hypothesis. These ideas are then used to study the value distribution of
Dirichlet L series, and the zeta functions of Dedekind, Hurwitz and Riemann and
their derivatives. This builds on earlier work of R. L. using Birkhoff's
ergodic theorem and probability theory.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:45:21 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 13:51:44 GMT""}]","2021-04-07"
"2006.05117","Huaizheng Zhang","Huaizheng Zhang, Yuanming Li, Qiming Ai, Yong Luo, Yonggang Wen,
  Yichao Jin and Nguyen Binh Duong Ta","Hysia: Serving DNN-Based Video-to-Retail Applications in Cloud","4 pages, 4 figures","In Proceedings of the 28th ACM International Conference on
  Multimedia (2020) 4457-4460","10.1145/3394171.3414536",,"cs.MM cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Combining \underline{v}ideo streaming and online \underline{r}etailing (V2R)
has been a growing trend recently. In this paper, we provide practitioners and
researchers in multimedia with a cloud-based platform named Hysia for easy
development and deployment of V2R applications. The system consists of: 1) a
back-end infrastructure providing optimized V2R related services including data
engine, model repository, model serving and content matching; and 2) an
application layer which enables rapid V2R application prototyping. Hysia
addresses industry and academic needs in large-scale multimedia by: 1)
seamlessly integrating state-of-the-art libraries including NVIDIA video SDK,
Facebook faiss, and gRPC; 2) efficiently utilizing GPU computation; and 3)
allowing developers to bind new models easily to meet the rapidly changing deep
learning (DL) techniques. On top of that, we implement an orchestrator for
further optimizing DL model serving performance. Hysia has been released as an
open source project on GitHub, and attracted considerable attention. We have
published Hysia to DockerHub as an official image for seamless integration and
deployment in current cloud environments.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:45:53 GMT""}]","2020-12-16"
"2006.05118","Thomas Giletti","Weiwei Ding, Thomas Giletti (IECL)","Admissible speeds in spatially periodic bistable reaction-diffusion
  equations",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spatially periodic reaction-diffusion equations typically admit pulsating
waves which describe the transition from one steady state to another. Due to
the heterogeneity, in general such an equation is not invariant by rotation and
therefore the speed of the pulsating wave may a priori depend on its direction.
However, little is actually known in the literature about whether it truly
does: surprisingly, it is even known in the one-dimensional monostable
Fisher-KPP case that the speed is the same in the opposite directions despite
the lack of symmetry. Here we investigate this issue in the bistable case and
show that the set of admissible speeds is actually rather large, which means
that the shape of propagation may indeed be asymmetrical. More precisely, we
show in any spatial dimension that one can choose an arbitrary large number of
directions , and find a spatially periodic bistable type equation to achieve
any combination of speeds in those directions, provided those speeds have the
same sign. In particular, in spatial dimension 1 and unlike the Fisher-KPP
case, any pair of (either nonnegative or nonpositive) rightward and leftward
wave speeds is admissible. We also show that these variations in the speeds of
bistable pulsating waves lead to strongly asymmetrical situations in the
multistable equations.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:47:02 GMT""}]","2020-06-11"
"2006.05119","Zhijin Li","Zhijin Li","Symmetries of conformal correlation functions","16 pages, no figures; v2: 12 pages, no figures, SO(N)-ization of WZW
  model added, discussion improved, to match the published version",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A program of wide interest in modern conformal bootstrap studies is to
numerically solve general conformal field theories, based on a critical
assumption that the dynamics is encoded in the conformal four-point crossing
equations and positivity condition. In this letter we propose and verify a
novel algebraic property of the crossing equations which provides strong
restriction for this program. We show for various types of symmetries $\cal G$,
the crossing equations can be linearly converted into the $SO(N)$ vector
crossing equations associated with the $SO(N)\rightarrow \cal G$ branching
rules and the transformations satisfy positivity condition. The dynamics
constrained by the $\cal G$-symmetric crossing equations combined with
positivity condition degenerates to the $SO(N)$ symmetric cases, while the
non-$SO(N)$ symmetric theories are not directly solvable without introducing
the $SO(N)$ symmetry breaking assumptions on the spectrum.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:47:03 GMT""},{""version"":""v2"",""created"":""Wed, 20 Apr 2022 15:55:59 GMT""}]","2022-04-21"
"2006.05120","Johanna Barzen","Frank Leymann, Johanna Barzen","Pattern Atlas","10 pages","Next-Gen Digital Services. A Retrospective and Roadmap for Service
  Computing of the Future. Lecture Notes in Computer Science, vol 12521, 2021,
  Springer, Cham","10.1007/978-3-030-73203-5_5",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pattern languages are well-established in the software architecture
community. Many different aspects of creating a software architecture are
addressed by such languages. Thus, several pattern languages have to be
considered when building a particular architecture. But these pattern languages
are isolated, i.e. it is hard to determine the relevant patterns to be applied
from the different pattern languages. Moreover, the sum of patterns from
different languages may be huge, i.e. restriction to relevant patterns is
desirable. In this contribution we envision an encompassing tool, the pattern
atlas, that supports building complex systems based on pattern languages. The
analogy to cartography motivates the name of the tool.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:48:37 GMT""}]","2021-04-21"
"2006.05121","Corentin Kervadec","Corentin Kervadec (LIRIS), Grigory Antipov (Orange), Moez Baccouche
  (Orange), Christian Wolf (LIRIS)","Roses Are Red, Violets Are Blue... but Should Vqa Expect Them To?",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Models for Visual Question Answering (VQA) are notorious for their tendency
to rely on dataset biases, as the large and unbalanced diversity of questions
and concepts involved and tends to prevent models from learning to reason,
leading them to perform educated guesses instead. In this paper, we claim that
the standard evaluation metric, which consists in measuring the overall
in-domain accuracy, is misleading. Since questions and concepts are unbalanced,
this tends to favor models which exploit subtle training set statistics.
Alternatively, naively introducing artificial distribution shifts between train
and test splits is also not completely satisfying. First, the shifts do not
reflect real-world tendencies, resulting in unsuitable models; second, since
the shifts are handcrafted, trained models are specifically designed for this
particular setting, and do not generalize to other configurations. We propose
the GQA-OOD benchmark designed to overcome these concerns: we measure and
compare accuracy over both rare and frequent question-answer pairs, and argue
that the former is better suited to the evaluation of reasoning abilities,
which we experimentally validate with models trained to more or less exploit
biases. In a large-scale study involving 7 VQA models and 3 bias reduction
techniques, we also experimentally demonstrate that these models fail to
address questions involving infrequent concepts and provide recommendations for
future directions of research.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:50:39 GMT""},{""version"":""v2"",""created"":""Tue, 8 Dec 2020 11:19:06 GMT""},{""version"":""v3"",""created"":""Wed, 7 Apr 2021 14:13:35 GMT""}]","2021-04-08"
"2006.05122","Camille Laurent","Camille Laurent (LJLL), Matthieu L\'eautaud (LM-Orsay)","Logarithmic decay for damped hypoelliptic wave and Schr{\""o}dinger
  equations",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider damped wave (resp. Schr{\""o}dinger and plate) equations driven by
a hypoelliptic ""sum of squares"" operator L on a compact manifold and a damping
function b(x). We assume the Chow-Rashevski-H{\""o}rmander condition at rank k
(at most k Lie brackets needed to span the tangent space) together with
analyticity of M and the coefficients of L. We prove decay of the energy at
rate $log(t)^{-1/k}$ (resp. $log(t)^{-2/k}$ ) for data in the domain of the
generator of the associated group. We show that this decay is optimal on a
family of Grushin-type operators. This result follows from a perturbative
argument (of independent interest) showing, in a general abstract setting, that
quantitative approximate observability/controllability results for wave-type
equations imply a priori decay rates for associated damped wave,
Schr{\""o}dinger and plate equations. The adapted quantitative approximate
observability/controllability theorem for hypoelliptic waves is obtained by the
authors in [LL19, LL17].
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:52:55 GMT""}]","2020-06-11"
"2006.05123","Georgia Chalvatzaki","Georgia Chalvatzaki, Nikolaos Gkanatsios, Petros Maragos, Jan Peters","Orientation Attentive Robotic Grasp Synthesis with Augmented Grasp Map
  Representation","7 pages, 4 figures, 5 tables",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inherent morphological characteristics in objects may offer a wide range of
plausible grasping orientations that obfuscates the visual learning of robotic
grasping. Existing grasp generation approaches are cursed to construct
discontinuous grasp maps by aggregating annotations for drastically different
orientations per grasping point. Moreover, current methods generate grasp
candidates across a single direction in the robot's viewpoint, ignoring its
feasibility constraints. In this paper, we propose a novel augmented grasp map
representation, suitable for pixel-wise synthesis, that locally disentangles
grasping orientations by partitioning the angle space into multiple bins.
Furthermore, we introduce the ORientation AtteNtive Grasp synthEsis (ORANGE)
framework, that jointly addresses classification into orientation bins and
angle-value regression. The bin-wise orientation maps further serve as an
attention mechanism for areas with higher graspability, i.e. probability of
being an actual grasp point. We report new state-of-the-art 94.71% performance
on Jacquard, with a simple U-Net using only depth images, outperforming even
multi-modal approaches. Subsequent qualitative results with a real bi-manual
robot validate ORANGE's effectiveness in generating grasps for multiple
orientations, hence allowing planning grasps that are feasible.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:54:54 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 10:26:55 GMT""}]","2021-02-03"
"2006.05124","Hassan Fathivavsari","Hassan Fathivavsari","Deep Learning Prediction of Quasars Broad Ly$\alpha$ Emission Line","Accepted for publication in The Astrophysical Journal (ApJ)",,"10.3847/1538-4357/ab9b7d",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have employed deep neural network, or deep learning to predict the flux
and the shape of the broad Ly$\alpha$ emission lines in the spectra of quasars.
We use 17870 high signal-to-noise ratio (SNR > 15) quasar spectra from the
Sloan Digital Sky Survey (SDSS) Data Release 14 (DR14) to train the model and
evaluate its performance. The SiIV, CIV, and CIII] broad emission lines are
used as the input to the neural network, and the model returns the predicted
Ly$\alpha$ emission line as the output. We found that our neural network model
predicts quasars continua around the Ly$\alpha$ spectral region with $\sim$6 -
12% precision and $\lesssim$1% bias. Our model can be used to estimate the HI
column density of eclipsing and ghostly damped Ly$\alpha$ (DLA) absorbers as
the presence of the DLA absorption in these systems strongly contaminates the
flux and the shape of the quasar continuum around Ly$\alpha$ spectral region.
The model could also be used to study the state of the intergalactic medium
during the epoch of reionization.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:56:50 GMT""}]","2020-08-05"
"2006.05125","Frederique Viard","Fr\'ed\'erique Viard (AD2M), Cynthia Riginos, Nicolas Bierne (UMR
  ISEM)","Anthropogenic Hybridization at Sea: three evolutionary questions
  relevant to invasive species","Philosophical Transactions of the Royal Society of London. Series B,
  Biological Sciences (1934--1990), Royal Society, The, In press",,"10.1098/rstb.2019.0547",,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Species introductions promote secondary contacts between taxa with long
histories of allopatric divergence. Anthropogenic contact zones thus offer
valuable contrasts to speciation studies in natural systems where past spatial
isolations may have been brief or intermittent. Investigations of anthropogenic
hybridization are rare for marine animals, which have high fecundity and high
dispersal ability, characteristics that contrast to most terrestrial animals.
Genomic studies indicate that gene flow can still occur after millions of years
of divergence, as illustrated by invasive mussels and tunicates. In this
context, we highlight three issues: 1) the effects of high propagule pressure
and demographic asymmetries on introgression directionality, 2) the role of
hybridization in preventing introduced species spread, and 3) the importance of
postzygotic barriers in maintaining reproductive isolation. Anthropogenic
contact zones offer evolutionary biologists unprecedented large scale
hybridization experiments. In addition to breaking the highly effective
reproductive isolating barrier of spatial segregation, they allow researchers
to explore unusual demographic contexts with strong asymmetries. The outcomes
are diverse from introgression swamping to strong barriers to gene flow, and
lead to local containment or widespread invasion. These outcomes should not be
neglected in management policies of marine invasive species.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:58:55 GMT""}]","2020-06-11"
"2006.05126","Robert MacKay","Robert S. MacKay","Normal hyperbolicity for non-autonomous oscillators and oscillator
  networks",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This chapter presents a view of a non-autonomous oscillator as a mapping from
input functions of time to a circle of possible solutions (state functions of
time). It indicates how this view encompasses chronotaxic systems and enables
one, at least conceptually, to understand the extent of synchronisation in
networks of oscillators, whether autonomous or not. For the latter a
hierarchical aggregation scheme is introduced. The approach is based on the
theory of normal hyperbolicity.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:59:44 GMT""}]","2020-06-11"
"2006.05127","Wenxi Liu","Yuzhen Niu, Weifeng Shi, Wenxi Liu, Shengfeng He, Jia Pan, Antoni B.
  Chan","Over-crowdedness Alert! Forecasting the Future Crowd Distribution",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, vision-based crowd analysis has been studied extensively due
to its practical applications in real world. In this paper, we formulate a
novel crowd analysis problem, in which we aim to predict the crowd distribution
in the near future given sequential frames of a crowd video without any
identity annotations. Studying this research problem will benefit applications
concerned with forecasting crowd dynamics. To solve this problem, we propose a
global-residual two-stream recurrent network, which leverages the consecutive
crowd video frames as inputs and their corresponding density maps as auxiliary
information to predict the future crowd distribution. Moreover, to strengthen
the capability of our network, we synthesize scene-specific crowd density maps
using simulated data for pretraining. Finally, we demonstrate that our
framework is able to predict the crowd distribution for different crowd
scenarios and we delve into applications including predicting future crowd
count, forecasting high-density region, etc.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:59:54 GMT""}]","2020-06-11"
"2006.05128","Yize Sun","Yize Sun, Lin Chen","Tripartite genuinely entangled states from entanglement-breaking
  subspaces",,,"10.1088/1751-8121/abce20",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The determination of genuine entanglement is a central problem in quantum
information processing. We investigate the tripartite state as the tensor
product of two bipartite entangled states by merging two systems. We show that
the tripartite state is a genuinely entangled state when the range of both
bipartite states are entanglement-breaking subspaces. We further investigate
the tripartite state when one of the two bipartite states has rank two. Our
results provide the latest progress on a conjecture proposed in the paper [Yi
Shen $\textit{et al}$, J. Phys. A 53, 125302 (2020)]. We apply our results to
construct multipartite states whose bipartite reduced density operators have
additive EOF. Further, such states are distillable across every bipartition
under local operations and classical communications.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:00:18 GMT""}]","2021-02-03"
"2006.05129","Bal\'azs Tarj\'an","Bal\'azs Tarj\'an, Gy\""orgy Szasz\'ak, Tibor Fegy\'o, P\'eter Mihajlik","On the Effectiveness of Neural Text Generation based Data Augmentation
  for Recognition of Morphologically Rich Speech","8 pages, 2 figures, accepted for publication at TSD 2020",,"10.1007/978-3-030-58323-1_47",,"eess.AS cs.CL cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advanced neural network models have penetrated Automatic Speech Recognition
(ASR) in recent years, however, in language modeling many systems still rely on
traditional Back-off N-gram Language Models (BNLM) partly or entirely. The
reason for this are the high cost and complexity of training and using neural
language models, mostly possible by adding a second decoding pass (rescoring).
In our recent work we have significantly improved the online performance of a
conversational speech transcription system by transferring knowledge from a
Recurrent Neural Network Language Model (RNNLM) to the single pass BNLM with
text generation based data augmentation. In the present paper we analyze the
amount of transferable knowledge and demonstrate that the neural augmented LM
(RNN-BNLM) can help to capture almost 50% of the knowledge of the RNNLM yet by
dropping the second decoding pass and making the system real-time capable. We
also systematically compare word and subword LMs and show that subword-based
neural text augmentation can be especially beneficial in under-resourced
conditions. In addition, we show that using the RNN-BNLM in the first pass
followed by a neural second pass, offline ASR results can be even significantly
improved.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:01:04 GMT""}]","2020-09-04"
"2006.05130","Bar Light","Bar Light","Concentration inequalities using higher moments information",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we generalize and improve some fundamental concentration
inequalities using information on the random variables' higher moments. In
particular, we improve the classical Hoeffding's and Bennett's inequalities for
the case where there is some information on the random variables' first $p$
moments for every positive integer $p$. Importantly, our generalized
Hoeffding's inequality is tighter than Hoeffding's inequality and is given in a
simple closed-form expression for every positive integer $p$. Hence, the
generalized Hoeffding's inequality is easy to use in applications. To prove our
results, we derive novel upper bounds on the moment-generating function of a
random variable that depend on the random variable's first $p$ moments and show
that these bounds satisfy appropriate convexity properties.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:01:21 GMT""},{""version"":""v2"",""created"":""Sat, 20 Jun 2020 00:29:48 GMT""},{""version"":""v3"",""created"":""Mon, 5 Apr 2021 05:37:52 GMT""},{""version"":""v4"",""created"":""Tue, 6 Apr 2021 04:34:40 GMT""},{""version"":""v5"",""created"":""Sat, 10 Jul 2021 22:48:43 GMT""},{""version"":""v6"",""created"":""Wed, 26 Apr 2023 01:00:11 GMT""}]","2023-04-27"
"2006.05131","Tom\'as Reis","Marcos Marino, Tomas Reis","Resurgence and renormalons in the one-dimensional Hubbard model","37 pages, 4 figures, v3: minor clarifications and corrections","SciPost Phys. 13, 113 (2022)","10.21468/SciPostPhys.13.5.113",,"hep-th cond-mat.quant-gas cond-mat.str-el math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use resurgent analysis to study non-perturbative aspects of the
one-dimensional, multicomponent Hubbard model with an attractive interaction
and arbitrary filling. In the two-component case, we show that the leading
Borel singularity of the perturbative series for the ground-state energy is
determined by the energy gap, as expected for superconducting systems. This
singularity turns out to be of the renormalon type, and we identify a class of
diagrams leading to the correct factorial growth. As a consequence of our
analysis, we propose an explicit expression for the energy gap at weak coupling
in the multi-component Hubbard model, at next-to-leading order in the coupling
constant. In the two-component, half-filled case, we use the Bethe ansatz
solution to determine the full trans-series for the ground state energy, and
the exact form of its Stokes discontinuity.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:03:00 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 09:30:37 GMT""},{""version"":""v3"",""created"":""Wed, 17 Nov 2021 16:24:42 GMT""}]","2022-11-23"
"2006.05132","Xi Li","Abdul Jabbar, Xi Li, and Bourahla Omar","A Survey on Generative Adversarial Networks: Variants, Applications, and
  Training",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Generative Models have gained considerable attention in the field of
unsupervised learning via a new and practical framework called Generative
Adversarial Networks (GAN) due to its outstanding data generation capability.
Many models of GAN have proposed, and several practical applications emerged in
various domains of computer vision and machine learning. Despite GAN's
excellent success, there are still obstacles to stable training. The problems
are due to Nash-equilibrium, internal covariate shift, mode collapse, vanishing
gradient, and lack of proper evaluation metrics. Therefore, stable training is
a crucial issue in different applications for the success of GAN. Herein, we
survey several training solutions proposed by different researchers to
stabilize GAN training. We survey, (I) the original GAN model and its modified
classical versions, (II) detail analysis of various GAN applications in
different domains, (III) detail study about the various GAN training obstacles
as well as training solutions. Finally, we discuss several new issues as well
as research outlines to the topic.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:04:41 GMT""}]","2020-06-11"
"2006.05133","Andrea Aler Tubella","Andrea Aler Tubella, Andreas Theodorou, Virginia Dignum, Loizos
  Michael","Contestable Black Boxes","Accepted at RuleML 2020 as a short paper",,"10.1007/978-3-030-57977-7_12",,"cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The right to contest a decision with consequences on individuals or the
society is a well-established democratic right. Despite this right also being
explicitly included in GDPR in reference to automated decision-making, its
study seems to have received much less attention in the AI literature compared,
for example, to the right for explanation. This paper investigates the type of
assurances that are needed in the contesting process when algorithmic
black-boxes are involved, opening new questions about the interplay of
contestability and explainability. We argue that specialised complementary
methodologies to evaluate automated decision-making in the case of a particular
decision being contested need to be developed. Further, we propose a
combination of well-established software engineering and rule-based approaches
as a possible socio-technical solution to the issue of contestability, one of
the new democratic challenges posed by the automation of decision making.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:09:00 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 14:49:12 GMT""}]","2020-09-18"
"2006.05134","Kevin Wellenzohn","Kevin Wellenzohn, Michael H. B\""ohlen, Sven Helmer","Dynamic Interleaving of Content and Structure for Robust Indexing of
  Semi-Structured Hierarchical Data (Extended Version)",,,"10.14778/3401960.3401963",,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a robust index for semi-structured hierarchical data that supports
content-and-structure (CAS) queries specified by path and value predicates. At
the heart of our approach is a novel dynamic interleaving scheme that merges
the path and value dimensions of composite keys in a balanced way. We store
these keys in our trie-based Robust Content-And-Structure index, which
efficiently supports a wide range of CAS queries, including queries with
wildcards and descendant axes. Additionally, we show important properties of
our scheme, such as robustness against varying selectivities, and demonstrate
improvements of up to two orders of magnitude over existing approaches in our
experimental evaluation.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:21:18 GMT""}]","2020-06-11"
"2006.05135","Sebastian Freund","S. Freund, J. Robrade, P.C. Schneider, J.H.M.M. Schmitt","The X-ray view of the Hyades cluster: updated","Accepted for publication in A&A","A&A 640, A66 (2020)","10.1051/0004-6361/201937304",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the X-ray properties of the main-sequence Hyades members and the
relation between X-ray emission and stellar rotation. As input catalog for
Hyades members, we combined three recent membership lists derived from Gaia DR2
data including the Hyades core and its tidal tails. We searched for X-ray
detections from the ROSAT all-sky survey (RASS) and pointings from ROSAT,
Chandra, and XMM-Newton of the Hyades members and adopted rotation periods
derived from Kepler's K2 mission and other resources. We find an X-ray
detection for 281 of 1066 bona fide main-sequence Hyades members and provide
statistical upper limits for the undetected sources. F- and G-type stars have
the highest detection fraction (72 %), while K- and M-type dwarfs have lower
detection rates (22 %). The X-ray luminosities of the detected members range
from ~$2\times10^{27}$ for late M-type dwarfs to ~$2\times10^{30}$ erg s$^{-1}$
for active binaries. The X-ray luminosity distribution functions formally
differ for the members in the core and tidal tails, which is likely caused by a
larger fraction of field stars in our Hyades tails sample. Compared to previous
studies, our sample is slightly fainter in X-rays due to differences in the
used Hyades membership list, furthermore, we extend the X-ray luminosity
distribution to fainter luminosities. The X-ray activity of F- and G-type stars
is well defined at $F_X/F_bol=10^{-5}$ and increases to later spectral types
reaching the saturation limit for members later than spectral type M3. The
X-ray flux varies by less than a factor of three between epochs for the 104
Hyades members with multiple epoch data. Rotation periods are found for 204
Hyades members, with about half of them being detected in X-rays. The
activity-rotation-relation derived for the coeval Hyades members has properties
very similar to those obtained by other authors investigating stars of
different ages.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:22:19 GMT""}]","2020-08-19"
"2006.05136","Stefano Boccelli","Stefano Boccelli, Thomas Charoi, Alejandro Alvarez-Laguna, Pascal
  Chabert, Anne Bourdon and Thierry E. Magin","Collisionless ion modeling in Hall thrusters: analytical axial velocity
  distribution function and heat flux closures",,,"10.1063/5.0006258",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The genesis of the ion axial velocity distribution function (VDF) is analyzed
for collisionless Hall thruster discharges. An analytical form for the VDF is
obtained from the Vlasov equation, by applying the Tonks-Langmuir theory in the
thruster channel, under the simplifying assumptions of monoenergetic creation
of ions and steady state. The equivalent set of 1D unsteady anisotropic moment
equations is derived from the Vlasov equation, and simple phenomenological
closures are formulated, assuming a polynomial shape for the ions VDF. The
analytical results and the anisotropic moment equations are compared to
collisionless PIC simulations, employing either a zero heat flux (Euler-like
equations) or the polynomial-VDF closure for the heat flux. The analytical ion
VDF and its moments are then compared to experimental measurements.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:22:53 GMT""}]","2020-08-26"
"2006.05137","Hermann Blum","Hermann Blum, Julian Stiefel, Cesar Cadena, Roland Siegwart, Abel
  Gawel","Precise Robot Localization in Architectural 3D Plans",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a localization system for mobile robots enabling precise
localization in inaccurate building models. The approach leverages local
referencing to counteract inherent deviations between as-planned and as-built
data for locally accurate registration. We further fuse a novel image-based
robust outlier detector with LiDAR data to reject a wide range of outlier
measurements from clutter, dynamic objects, and sensor failures. We evaluate
the proposed approach on a mobile robot in a challenging real world building
construction site. It consistently outperforms the traditional ICP-based
alingment, reducing localization error by at least 30%.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:23:43 GMT""}]","2020-06-11"
"2006.05138","Jake Taylor-King","Jake P. Taylor-King, Cristian Regep, Jyothish Soman, Flawnson Tong,
  Catalina Cangea, Charlie Roberts","Sparse Dynamic Distribution Decomposition: Efficient Integration of
  Trajectory and Snapshot Time Series Data","11 pages, 2 figures",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Dynamic Distribution Decomposition (DDD) was introduced in Taylor-King et.
al. (PLOS Comp Biol, 2020) as a variation on Dynamic Mode Decomposition. In
brief, by using basis functions over a continuous state space, DDD allows for
the fitting of continuous-time Markov chains over these basis functions and as
a result continuously maps between distributions. The number of parameters in
DDD scales by the square of the number of basis functions; we reformulate the
problem and restrict the method to compact basis functions which leads to the
inference of sparse matrices only -- hence reducing the number of parameters.
Finally, we demonstrate how DDD is suitable to integrate both trajectory time
series (paired between subsequent time points) and snapshot time series
(unpaired time points). Methods capable of integrating both scenarios are
particularly relevant for the analysis of biomedical data, whereby studies
observe population at fixed time points (snapshots) and individual patient
journeys with repeated follow ups (trajectories).
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:28:52 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 15:25:30 GMT""}]","2020-06-12"
"2006.05139","Eli Simhayev","Eli Simhayev, Gilad Katz, Lior Rokach","PIVEN: A Deep Neural Network for Prediction Intervals with Specific
  Value Prediction","19 pages",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Improving the robustness of neural nets in regression tasks is key to their
application in multiple domains. Deep learning-based approaches aim to achieve
this goal either by improving their prediction of specific values (i.e., point
prediction), or by producing prediction intervals (PIs) that quantify
uncertainty. We present PIVEN, a deep neural network for producing both a PI
and a value prediction. Our loss function expresses the value prediction as a
function of the upper and lower bounds, thus ensuring that it falls within the
interval without increasing model complexity. Moreover, our approach makes no
assumptions regarding data distribution within the PI, making its value
prediction more effective for various real-world problems. Experiments and
ablation tests on known benchmarks show that our approach produces tighter
uncertainty bounds than the current state-of-the-art approaches for producing
PIs, while maintaining comparable performance to the state-of-the-art approach
for value-prediction. Additionally, we go beyond previous work and include
large image datasets in our evaluation, where PIVEN is combined with modern
neural nets.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:29:58 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jan 2021 11:05:15 GMT""},{""version"":""v3"",""created"":""Sun, 20 Jun 2021 13:23:00 GMT""}]","2021-06-22"
"2006.05140","Mario Hoerbe","Mario R. Hoerbe, Paul J. Morris, Garret Cotter, Julia Becker Tjus","On the relative importance of hadronic emission processes along the jet
  axis of Active Galactic Nuclei","19 pages, 7 figures, accepted by MNRAS on 01 June 2020 for
  publication",,"10.1093/mnras/staa1650",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the coincident detection of a gamma-ray flare and a neutrino from the
blazar TXS 0506+056, Active Galactic Nuclei (AGN) have been put into focus as
possible sources of the diffuse neutrino flux. We present a space and
time-resolved model of the high-energy particle emission of a plasmoid assumed
to travel along the axis of an AGN jet at relativistic speed. This was achieved
by modifying the publicly available CRPropa (version 3.1+) propagation
framework which in our work is capable of being applied to source physics on
sub-kpc scales. The propagation of a population of primary protons is modelled
in a purely turbulent magnetic field and we take into account interactions of
these protons with photons scattered from the accretion disc, synchrotron
radiation emitted by ambient relativistic electrons, as well with themselves
and with other ambient matter. Our model produces a PeV-neutrino flare caused
mainly by photo-hadronic interactions of primaries with the accretion disc
field. Secondary high-energy gamma-rays partly attenuate with the ambient
photon fields whose combined optical depths achieve their minimal opacity for
photons of around 10 TeV. Thus, our model is well capable of producing neutrino
flares with a significantly reduced emission of gamma-rays in jets with a
hadronic jet component which in the future can be fit to specific AGN flare
scenarios.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:31:43 GMT""}]","2020-06-24"
"2006.05141","Usha Srinivasan","Usha Srinivasan and Rangachari Kidambi (Computational and Theoretical
  Fluid Dynamics Division, National Aerospace Laboratories, Bengaluru, India)","On the linear evolution of disturbances in plane Poiseuille flow","67 pages 22 figures",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The linear evolution of disturbances due to a ribbon vibrating at frequency
$\omega_0$ in plane Poiseuille flow is computed by solving the associated
initial boundary value problem in the Fourier-Laplace plane, followed by
inversion. A novel algorithm for identifying the temporal modes of the
Orr-Sommerfeld equation (OSE) in the complex wavenumber plane, which are
required in the inversion, is presented. Unlike in many prior studies, the
performance of the Laplace integral first, not only avoids complicated
causality arguments and confusion, in locating upstream and downstream modes,
that is prevalent in literature but also yields a spatio-temporally uniform
solution. It also reveals that the solution consists of a time-periodic part at
$\omega_0$ , associated with the relevant spatial mode (the
Tollmein-Schlichting wave) and a transient wavepacket, associated mainly with
the saddle points of the OSE and is computed by the method of steepest
descents, which can also include contributions from the spatial pole. Which of
these parts dominates depends on the Reynolds number and {\omega}0. A secondary
stability analysis of this dominant part is seen to explain the disturbance
growth observed in the seminal experiments of Nishioka, Iida & Ichikawa (J.
Fluid Mech., vol.72 , 1975, p.731) and Nishioka, Iida & Kanbayashi (NASA
TM-75885, 1981). Threshold amplitudes for instability at a subcritical Reynolds
number Re = 5000 are obtained from the time-averaged three dimensional
disturbances, by combining the secondary base states and the growing Floquet
modes. The observed minima of the threshold amplitude curves in the experiments
are explained in terms of the instabilities of these two base states.
Computations, for another subcritical (4000) and a supercritical (6000)
Reynolds number, are also validated with the experimental data.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:32:40 GMT""}]","2020-06-11"
"2006.05142","David Varas","Carlos Roig and David Varas and Issey Masuda and Juan Carlos Riveiro
  and Elisenda Bou-Balust","Smooth Proxy-Anchor Loss for Noisy Metric Learning","The 4th Workshop on Visual Understanding by Learning from Web Data
  (CVPR 2020)","The 4th Workshop on Visual Understanding by Learning from Web Data
  (CVPR 2020)",,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Many industrial applications use Metric Learning as a way to circumvent
scalability issues when designing systems with a high number of classes.
Because of this, this field of research is attracting a lot of interest from
the academic and non-academic communities. Such industrial applications require
large-scale datasets, which are usually generated with web data and, as a
result, often contain a high number of noisy labels. While Metric Learning
systems are sensitive to noisy labels, this is usually not tackled in the
literature, that relies on manually annotated datasets.
  In this work, we propose a Metric Learning method that is able to overcome
the presence of noisy labels using our novel Smooth Proxy-Anchor Loss. We also
present an architecture that uses the aforementioned loss with a two-phase
learning procedure. First, we train a confidence module that computes sample
class confidences. Second, these confidences are used to weight the influence
of each sample for the training of the embeddings. This results in a system
that is able to provide robust sample embeddings.
  We compare the performance of the described method with current
state-of-the-art Metric Learning losses (proxy-based and pair-based), when
trained with a dataset containing noisy labels. The results showcase an
improvement of 2.63 and 3.29 in Recall@1 with respect to MultiSimilarity and
Proxy-Anchor Loss respectively, proving that our method outperforms the
state-of-the-art of Metric Learning in noisy labeling conditions.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:33:04 GMT""}]","2020-06-11"
"2006.05143","Yury Budkov","Yu.A. Budkov","Statistical field theory of ion-molecular solutions","Paper is accepted for publication in Physical Chemistry Chemical
  Physics",,"10.1039/D0CP02432E",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, I summarize my theoretical developments in the statistical
field theory of salt solutions of zwitterionic and multipolar molecules. Based
on the Hubbard-Stratonovich integral transformation, I represent configuration
integrals of dilute salt solutions of zwitterionic and multipolar molecules in
the form of functional integrals over the space-dependent fluctuating
electrostatic potential. In the mean-field approximation, for both cases, I
derive integro-differential self-consistent field equations for the
electrostatic potential, generated by the external charges in solutions media,
which generalize the classical Poisson-Boltzmann equation. I derive for the
both cases a general expression for the electrostatic potential of a point-like
test ion, expressed through certain screening functions. I derive an analytical
expression for the electrostatic potential of the point-like test ion in a salt
zwitterionic solution, generalizing the well known Debye-Hueckel potential. In
the salt-free solution case, I obtain analytical expressions for the local
dielectric permittivity around the point-like test ion and its effective
solvation radius. For the case of salt solutions of multipolar molecules, I
find a new oscillating behavior of the electrostatic field potential of the
point-like test ion at long distances. I obtain a general expression for the
average quadrupolar length of a multipolar solute. Using the random phase
approximation (RPA), I derive general expressions for the excess free energy of
bulk salt solutions of zwitterionic and multipolar molecules and analyze the
limiting regimes resulting from them. I generalize the salt zwitterionic
solution theory for the case when several kinds of zwitterions are dissolved in
the solution. In this case, within the RPA, I obtain a general expression for
the solvation energy of the test zwitterion.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:33:32 GMT""}]","2020-08-26"
"2006.05144","Sandor Frey","M. Krezinger, S. Frey, T. An, S. Jaiswal, Y. Zhang","J1110+4817 -- a compact symmetric object candidate revisited","8 pages, 4 figures; accepted for publication in the Monthly Notices
  of the Royal Astronomical Society","Monthly Notices of the Royal Astronomical Society, Vol. 496, pp.
  1811-1818 (2020)","10.1093/mnras/staa1669",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compact symmetric objects (CSOs) are radio-emitting active galactic nuclei
(AGNs) typically with a double-lobed radio structure confined to within 1 kpc.
CSOs represent the earliest evolutionary phase of jetted AGNs. Some of them may
eventually evolve into large-scale extended double sources, while others stall
within the host galaxy and die out, depending on the longevity of nuclear
activity, the jet power, and parameters of the surrounding galactic
environment. Studying CSOs is a useful tool for understanding the evolution of
the galaxies and the interactions between the jets and the medium of the host
galaxy. Based on milliarcsec-resolution imaging observations using very long
baseline interferometry (VLBI), it is not always straightforward to distinguish
between a compact double-lobed or a core-jet structure. The quasar J1110+4817
was considered a CSO candidate in the literature earlier, but because of the
lack of clear evidence, it could not be securely classified as a CSO. Here we
present a comprehensive analysis of archival multi-frequency VLBI observations
combined with accurate Gaia optical astrometric information. Lower-frequency
VLBI images reveal an extended radio feature nearly perpendicular to the main
structural axis of the source, apparently emanating from the brighter northern
feature, that is rare among the known CSOs. While the presence of a binary AGN
system cannot be fully excluded, the most plausible explanation is that
J1110+4817 is a CSO.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:35:06 GMT""}]","2020-07-07"
"2006.05145","Brendan O'Donoghue","Brendan O'Donoghue, Tor Lattimore, Ian Osband","Matrix games with bandit feedback",,,,,"cs.LG stat.CO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a version of the classical zero-sum matrix game with unknown payoff
matrix and bandit feedback, where the players only observe each others actions
and a noisy payoff. This generalizes the usual matrix game, where the payoff
matrix is known to the players. Despite numerous applications, this problem has
received relatively little attention. Although adversarial bandit algorithms
achieve low regret, they do not exploit the matrix structure and perform poorly
relative to the new algorithms. The main contributions are regret analyses of
variants of UCB and K-learning that hold for any opponent, e.g., even when the
opponent adversarially plays the best-response to the learner's mixed strategy.
Along the way, we show that Thompson fails catastrophically in this setting and
provide empirical comparison to existing algorithms.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:36:21 GMT""},{""version"":""v2"",""created"":""Sat, 12 Jun 2021 10:23:31 GMT""}]","2021-06-15"
"2006.05146","Timoteo Carletti","Timoteo Carletti and Malbor Asllani and Duccio Fanelli and Vito Latora","Nonlinear walkers and efficient exploration of congested networks",,,,,"cond-mat.stat-mech physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Random walks are the simplest way to explore or search a graph, and have
revealed a very useful tool to investigate and characterize the structural
properties of complex networks from the real world, e.g. they have been used to
identify the modules of a given network, its most central nodes and paths, or
to determine the typical times to reach a target. Although various types of
random walks whose motion is node biased have been proposed, which are still
amenable to analytical solution, most if not all of them rely on the assumption
of linearity and independence of the walkers. We introduce a novel class of
nonlinear stochastic processes describing a system of interacting random
walkers moving over networks with finite node capacities. The transition
probabilities are modulated by nonlinear functions of the available space at
the destination node, with a bias parameter that allows to tune the tendency of
the walkers to avoid nodes occupied by other walkers. Firstly, we derive the
master equation governing the dynamics of the system, and we determine an
analytical expression for the occupation probability of the walkers at
equilibrium in the most general case, and under different level of network
congestions. Then, we study different type of synthetic and real-world
networks, presenting numerical and analytical results for the entropy rate, a
proxy for the network exploration capacities of the walkers.We find that, for
each level of the nonlinear bias, there is an optimal crowding that maximises
the entropy rate in a given network topology. The analysis suggests that a
large fraction of real-world networks are organised in such a way as to favour
exploration under congested conditions. Our work provides a general and
versatile framework to model nonlinear stochastic processes whose transition
probabilities vary in time depending on the current state of the system.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:37:39 GMT""}]","2020-06-11"
"2006.05147","Cunhua Pan","Zhangjie Peng, Zhenkun Zhang, Cunhua Pan, Li Li, and A. Lee
  Swindlehurst","Multiuser Full-Duplex Two-Way Communications via Intelligent Reflecting
  Surface","Accepted by IEEE Transactions on Signal Processing",,"10.1109/TSP.2021.3049652",,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Low-cost passive intelligent reflecting surfaces (IRSs) have recently been
envisioned as a revolutionary technology capable of reconfiguring the wireless
propagation environment through carefully tuning reflection elements. This
paper proposes deploying an IRS to cover the dead zone of cellular multiuser
full-duplex (FD) two-way communication links while suppressing user-side
self-interference (SI) and co-channel interference (CI). Based on information
exchanged by the base station (BS) and all users, this approach can potentially
double the spectral efficiency. To ensure network fairness, we jointly optimize
the precoding matrix of the BS and the reflection coefficients of the IRS to
maximize the weighted minimum rate (WMR) of all users, subject to maximum
transmit power and unit-modulus constraints. We reformulate this non-convex
problem and decouple it into two subproblems. Then the optimization variables
in the equivalent problem are alternately optimized by adopting the block
coordinate descent (BCD) algorithm. In order to further reduce the
computational complexity, we propose the minorization-maximization (MM)
algorithm for optimizing the precoding matrix and the reflection coefficient
vector by defining minorizing functions in the surrogate problems. Finally,
simulation results confirm the convergence and efficiency of our proposed
algorithm, and validate the advantages of introducing IRS to improve coverage
in blind areas.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:41:32 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 14:58:29 GMT""},{""version"":""v3"",""created"":""Mon, 4 Jan 2021 01:11:34 GMT""},{""version"":""v4"",""created"":""Sun, 12 Sep 2021 09:48:30 GMT""}]","2021-09-14"
"2006.05148","Chihoon Hwang","MyungJae Shin, Chihoon Hwang, Joongheon Kim, Jihong Park, Mehdi Bennis
  and Seong-Lyun Kim","XOR Mixup: Privacy-Preserving Data Augmentation for One-Shot Federated
  Learning",,,,,"cs.LG cs.CR eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  User-generated data distributions are often imbalanced across devices and
labels, hampering the performance of federated learning (FL). To remedy to this
non-independent and identically distributed (non-IID) data problem, in this
work we develop a privacy-preserving XOR based mixup data augmentation
technique, coined XorMixup, and thereby propose a novel one-shot FL framework,
termed XorMixFL. The core idea is to collect other devices' encoded data
samples that are decoded only using each device's own data samples. The
decoding provides synthetic-but-realistic samples until inducing an IID
dataset, used for model training. Both encoding and decoding procedures follow
the bit-wise XOR operations that intentionally distort raw samples, thereby
preserving data privacy. Simulation results corroborate that XorMixFL achieves
up to 17.6% higher accuracy than Vanilla FL under a non-IID MNIST dataset.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:43:41 GMT""}]","2020-06-11"
"2006.05149","Corentin Coulais","Aleksi Bossart and David M.J. Dykstra and Jop van der Laan and
  Corentin Coulais","Oligomodal mechanical metamaterials","7 pages, 4 figures, appendix (6 pages and 4 figures)",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mechanical metamaterials are artifical composites that exhibit a wide range
of advanced functionalities such as negative Poisson's ratio, shape-shifting,
topological protection, multistability, and enhanced energy dissipation. To
date, most metamaterials have a single property, e.g. a single shape change, or
are pluripotent, \emph{i.e.} they can have many different responses, but
require complex actuation protocols. Here, we introduce a novel class of
oligomodal metamaterials that encode a few distinct properties that can be
selectively controlled under uniaxial compression. In particular, we realise a
metamaterial that has a negative (positive) Poisson's ratio for low (high)
compression rate. The ability of our oligomodal metamaterials to host multiple
mechanical responses within a single structure makes them an early example of
multi-functional matter and paves the way towards robust and adaptable devices.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:44:33 GMT""}]","2020-06-11"
"2006.05150","Melanie Theilliere","M\'elanie Theilli\`ere","Corrugation Process and $\epsilon$-isometric maps","17 pages, 9 figures",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convex Integration is a theory developed in the '70s by M. Gromov. This
theory allows to solve families of differential problems satisfying some convex
assumptions. From a subsolution, the theory iteratively builds a solution by
applying a series of convex integrations. In a previous paper arXiv:1909.04908,
we proposed to replace the usual convex integration formula by a new one called
Corrugation Process. This new formula is of particular interest when the
differential problem under consideration has the property of being of Kuiper.
In this paper, we consider the differential problem of $\epsilon$-isometric
maps and we prove that it is Kuiper in codimension 1. As an application, we
construct $\epsilon$-isometric maps from a short map having a conical
singularity.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:46:18 GMT""}]","2020-06-11"
"2006.05151","Hans Havlicek","Hans Havlicek, Stefano Pasotti, Silvia Pianta","Characterising Clifford parallelisms among Clifford-like parallelisms","2 Figures",,,,"math.AG math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We recall the notions of Clifford and Clifford-like parallelisms in a
$3$-dimensional projective double space. In a previous paper the authors proved
that the linear part of the full automorphism group of a Clifford parallelism
is the same for all Clifford-like parallelisms which can be associated to it.
In this paper, instead, we study the action of such group on parallel classes
thus achieving our main results on characterisation of the Clifford
parallelisms among Clifford-like ones.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:47:01 GMT""}]","2020-06-11"
"2006.05152","Andrei Boiarov","Andrei Boiarov, Oleg Granichin, Olga Granichina","Simultaneous Perturbation Stochastic Approximation for Few-Shot Learning","Accepted for publication in Proc. of the 2020 European Control
  Conference (ECC)",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Few-shot learning is an important research field of machine learning in which
a classifier must be trained in such a way that it can adapt to new classes
which are not included in the training set. However, only small amounts of
examples of each class are available for training. This is one of the key
problems with learning algorithms of this type which leads to the significant
uncertainty. We attack this problem via randomized stochastic approximation. In
this paper, we suggest to consider the new multi-task loss function and propose
the SPSA-like few-shot learning approach based on the prototypical networks
method. We provide a theoretical justification and an analysis of experiments
for this approach. The results of experiments on the benchmark dataset
demonstrate that the proposed method is superior to the original prototypical
networks.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:47:58 GMT""}]","2020-06-11"
"2006.05153","Minyong Guo","Peng-Cheng Li, Minyong Guo, and Bin Chen","High spin expansion for null geodesics","25pages, 6 figures, nb source is available, typos fixed, accepted in
  CQG",,"10.1088/1361-6382/abd860",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the high spin expansion for the null geodesics in the Kerr
spacetime. We expand the null geodesic equation successively to higher orders
in deviation from extremity. Via the method of matched asymptotic expansion,
the radial integrals are obtained analytically. It turns out that the analytic
expressions are very sensitive to the value of the shifted Carter constant $q$.
We show that for a large $q$, the analytic expressions can be used to study
observational electromagnetic signatures for astrophysical black holes like
M87*. However, for a small $q$, the high spin expansion method can only be
applied to (near-) extreme black holes.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:48:44 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 04:12:03 GMT""},{""version"":""v3"",""created"":""Tue, 5 Jan 2021 12:15:23 GMT""}]","2022-07-27"
"2006.05154","Federica Cuna","F. Cuna, G. Chiarello, A. Corvaglia, N. De Filippis, F. Grancagnolo,
  M. Manta, I. Margjeka, A. Miccoli, M. Panareo, G. F. Tassielli","A 10-3 drift velocity monitoring chamber",,,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The MEG-II experiment searches for the lepton flavor violating decay: mu in
electron and gamma. The reconstruction of the positron trajectory uses a
cylindrical drift chamber operated with a mixture of He and iC4H10 gas. It is
important to provide a stable performance of the detector in terms of its
electron transport parameters, avalanche multiplication, composition and purity
of the gas mixture. In order to have a continuous monitoring of the quality of
gas, we plan to install a small drift chamber, with a simple geometry that
allows to measure very precisely the electron drift velocity in a prompt way.
This monitoring chamber will be supplied with gas coming from the inlet and the
outlet of the detector to determine if gas contaminations originate inside the
main chamber or in the gas supply system. The chamber is a small box with
cathode walls, that define a highly uniform electric field inside two adjacent
drift cells. Along the axis separating the two drift cells, four staggered
sense wires alternated with five guard wires collect the drifting electrons.
The trigger is provided by two 90Sr weak calibration radioactive sources placed
on top of a two thin scintillator tiles telescope. The whole system is designed
to give a prompt response (within a minute) about drift velocity variations at
the 0.001 level.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:49:40 GMT""}]","2020-06-11"
"2006.05155","Nicolas Peretto","N. Peretto, A. Rigby, Ph. Andr\'e, V. K\""onyves, G. Fuller, A.
  Zavagno, F. Schuller, D. Arzoumanian, S. Bontemps, T. Csengeri, P. Didelon,
  A. Duarte-Cabral, P. Palmeirim, S. Pezzuto, V. Rev\'eret, H. Roussel, Y.
  Shimajiri","The accretion history of high-mass stars: An ArT\'eMiS pilot study of
  Infrared Dark Clouds","23 pages, 44 figures, accepted for publication in MNRAS",,"10.1093/mnras/staa1656",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mass growth of protostars is a central element to the determination of
fundamental stellar population properties such as the initial mass function.
Constraining the accretion history of individual protostars is therefore an
important aspect of star formation research. The goal of the study presented
here is to determine whether high-mass (proto)stars gain their mass from a
compact (<0.1pc) fixed-mass reservoir of gas, often referred to as dense cores,
in which they are embedded, or whether the mass growth of high-mass stars is
governed by the dynamical evolution of the parsec-scale clump that typically
surrounds them. To achieve this goal, we performed a 350micron continuum
mapping of 11 infrared dark clouds, along side some of their neighbouring
clumps, with the ArT\'eMiS camera on APEX. By identifying about 200 compact
ArT\'eMiS sources, and matching them with Herschel Hi-GAL 70micron sources, we
have been able to produce mass vs. temperature diagrams. We compare the nature
(i.e. starless or protostellar) and location of the ArT\'eMiS sources in these
diagrams with modelled evolutionary tracks of both core-fed and clump-fed
accretion scenarios. We argue that the latter provide a better agreement with
the observed distribution of high-mass star-forming cores. However, a robust
and definitive conclusion on the question of the accretion history of high-mass
stars requires larger number statistics.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:49:50 GMT""}]","2020-07-22"
"2006.05156","Alessio Mansutti","St\'ephane Demri, \'Etienne Lozes, Alessio Mansutti","A Complete Axiomatisation for Quantifier-Free Separation Logic",,"Logical Methods in Computer Science, Volume 17, Issue 3 (August
  10, 2021) lmcs:8347","10.46298/lmcs-17(3:17)2021",,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  We present the first complete axiomatisation for quantifier-free separation
logic. The logic is equipped with the standard concrete heaplet semantics and
the proof system has no external feature such as nominals/labels. It is not
possible to rely completely on proof systems for Boolean BI as the concrete
semantics needs to be taken into account. Therefore, we present the first
internal Hilbert-style axiomatisation for quantifier-free separation logic. The
calculus is divided in three parts: the axiomatisation of core formulae where
Boolean combinations of core formulae capture the expressivity of the whole
logic, axioms and inference rules to simulate a bottom-up elimination of
separating connectives, and finally structural axioms and inference rules from
propositional calculus and Boolean BI with the magic wand.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:49:52 GMT""},{""version"":""v2"",""created"":""Sun, 28 Feb 2021 13:27:21 GMT""},{""version"":""v3"",""created"":""Mon, 9 Aug 2021 11:05:53 GMT""}]","2021-10-04"
"2006.05157","M\'arton Hablicsek","Ma\""el Denys, M\'arton Hablicsek, Giacomo Negrisolo","Non-Noetherian representation categories of generalized fields","Comments are welcome!",,,,"math.CO math.RA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we show that the categories of finitely generated projective
$\mathbb{B}$-modules and $\mathbb{F}_\infty$-modules with morphisms being
(splittable) injections are not locally Noetherian. This provides another
instance of the fact that these generalized fields have strange homological
behavior.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:51:47 GMT""}]","2020-06-11"
"2006.05158","Liangzu Peng","Liangzu Peng and Manolis C. Tsakiris","Homomorphic Sensing of Subspace Arrangements","18 pages","Applied and Computational Harmonic Analysis, 55, 466-485 (2021)","10.1016/j.acha.2021.06.008",,"cs.LG math.AG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Homomorphic sensing is a recent algebraic-geometric framework that studies
the unique recovery of points in a linear subspace from their images under a
given collection of linear maps. It has been successful in interpreting such a
recovery in the case of permutations composed by coordinate projections, an
important instance in applications known as unlabeled sensing, which models
data that are out of order and have missing values. In this paper, we provide
tighter and simpler conditions that guarantee the unique recovery for the
single-subspace case, extend the result to the case of a subspace arrangement,
and show that the unique recovery in a single subspace is locally stable under
noise. We specialize our results to several examples of homomorphic sensing
such as real phase retrieval and unlabeled sensing. In so doing, in a unified
way, we obtain conditions that guarantee the unique recovery for those
examples, typically known via diverse techniques in the literature, as well as
novel conditions for sparse and unsigned versions of unlabeled sensing.
Similarly, our noise result also implies that the unique recovery in unlabeled
sensing is locally stable.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:52:15 GMT""},{""version"":""v2"",""created"":""Wed, 30 Dec 2020 03:27:36 GMT""},{""version"":""v3"",""created"":""Tue, 1 Jun 2021 06:36:14 GMT""},{""version"":""v4"",""created"":""Mon, 19 Sep 2022 14:13:47 GMT""}]","2022-09-20"
"2006.05159","Albert Dulian","Albert Dulian and John C. Murray","Physically constrained short-term vehicle trajectory forecasting with
  naive semantic maps",,,,,"cs.CV cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Urban environments manifest a high level of complexity, and therefore it is
of vital importance for safety systems embedded within autonomous vehicles
(AVs) to be able to accurately predict the short-term future motion of nearby
agents. This problem can be further understood as generating a sequence of
future coordinates for a given agent based on its past motion data e.g.
position, velocity, acceleration etc, and whilst current approaches demonstrate
plausible results they have a propensity to neglect a scene's physical
constrains. In this paper we propose the model based on a combination of the
CNN and LSTM encoder-decoder architecture that learns to extract a relevant
road features from semantic maps as well as general motion of agents and uses
this learned representation to predict their short-term future trajectories. We
train and validate the model on the publicly available dataset that provides
data from urban areas, allowing us to examine it in challenging and uncertain
scenarios. We show that our model is not only capable of anticipating future
motion whilst taking into consideration road boundaries, but can also
effectively and precisely predict trajectories for a longer time horizon than
initially trained for.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:52:44 GMT""}]","2020-06-11"
"2006.05160","Pawe{\l} Zieli\'nski","Pawel Zielinski (1), Lukasz Wyrzykowski (1), Przemyslaw Mikolajczyk
  (2), Krzysztof Rybicki (1) and Zbigniew Kolaczkowski (2,3,4) (1. Astronomical
  Observatory, University of Warsaw, 2. Astronomical Institute, University of
  Wroclaw, 3. Nicolaus Copernicus Astronomical Center, Polish Academy of
  Sciences, 4. deceased)","Towards an automatic processing of CCD images with CPCS 2.0","4 pages, 1 figure, to appear on the Proceedings of the XXXIX Assembly
  of the Polish Astronomical Society (9-12.09.2019, Olsztyn, Poland)",,,,"astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new automatic tool for time-domain astronomy - the Cambridge
Photometric Calibration Server 2.0 - developed under OPTICON H2020 programme.
It has been designed to respond to the need of automated rapid photometric data
calibration and dissemination for transient events, primarily from Gaia space
mission. CPCS has been in operation since 2013 and has been used to calibrate
around 130 000 observations of hundreds of transients. We present the status of
this tool's development and demonstrate improvements made in the second
version. The tests present the ability to combine CCD imaging data from
multiple telescopes and a whole variety of instruments. New tool provides
science-ready photometric data within minutes from observations in the
automatic manner.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:55:28 GMT""}]","2020-06-11"
"2006.05161","David Hong","Edgar Dobriban, Hamed Hassani, David Hong, Alexander Robey","Provable tradeoffs in adversarially robust classification","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible. 47 pages, 5 figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that machine learning methods can be vulnerable to
adversarially-chosen perturbations of their inputs. Despite significant
progress in the area, foundational open problems remain. In this paper, we
address several key questions. We derive exact and approximate Bayes-optimal
robust classifiers for the important setting of two- and three-class Gaussian
classification problems with arbitrary imbalance, for $\ell_2$ and
$\ell_\infty$ adversaries. In contrast to classical Bayes-optimal classifiers,
determining the optimal decisions here cannot be made pointwise and new
theoretical approaches are needed. We develop and leverage new tools, including
recent breakthroughs from probability theory on robust isoperimetry, which, to
our knowledge, have not yet been used in the area. Our results reveal
fundamental tradeoffs between standard and robust accuracy that grow when data
is imbalanced. We also show further results, including an analysis of
classification calibration for convex losses in certain models, and finite
sample rates for the robust risk.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:58:19 GMT""},{""version"":""v2"",""created"":""Thu, 3 Sep 2020 17:22:08 GMT""},{""version"":""v3"",""created"":""Mon, 26 Oct 2020 03:09:48 GMT""},{""version"":""v4"",""created"":""Thu, 22 Jul 2021 00:41:12 GMT""},{""version"":""v5"",""created"":""Sun, 30 Jan 2022 18:07:32 GMT""}]","2022-02-01"
"2006.05162","Elad Levi","Elad Levi, Tete Xiao, Xiaolong Wang, Trevor Darrell","Rethinking preventing class-collapsing in metric learning with
  margin-based losses",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metric learning seeks perceptual embeddings where visually similar instances
are close and dissimilar instances are apart, but learned representations can
be sub-optimal when the distribution of intra-class samples is diverse and
distinct sub-clusters are present. Although theoretically with optimal
assumptions, margin-based losses such as the triplet loss and margin loss have
a diverse family of solutions. We theoretically prove and empirically show that
under reasonable noise assumptions, margin-based losses tend to project all
samples of a class with various modes onto a single point in the embedding
space, resulting in a class collapse that usually renders the space ill-sorted
for classification or retrieval. To address this problem, we propose a simple
modification to the embedding losses such that each sample selects its nearest
same-class counterpart in a batch as the positive element in the tuple. This
allows for the presence of multiple sub-clusters within each class. The
adaptation can be integrated into a wide range of metric learning losses. The
proposed sampling method demonstrates clear benefits on various fine-grained
image retrieval datasets over a variety of existing losses; qualitative
retrieval results show that samples with similar visual patterns are indeed
closer in the embedding space.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:59:25 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 14:13:34 GMT""}]","2021-08-30"
"2006.05163","Vaishali Pal","Vaishali Pal, Manish Shrivastava and Laurent Besacier","ConfNet2Seq: Full Length Answer Generation from Spoken Questions","Accepted at Text, Speech and Dialogue, 2020","ConfNet2Seq, Text, Speech, and Dialogue - 23rd International
  Conference, {TSD}, Brno, Czech Republic, September 8-11, 2020, Proceedings,
  12284, 2020, 524-531 (2020)","10.1007/978-3-030-58323-1_56",,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conversational and task-oriented dialogue systems aim to interact with the
user using natural responses through multi-modal interfaces, such as text or
speech. These desired responses are in the form of full-length natural answers
generated over facts retrieved from a knowledge source. While the task of
generating natural answers to questions from an answer span has been widely
studied, there has been little research on natural sentence generation over
spoken content. We propose a novel system to generate full length natural
language answers from spoken questions and factoid answers. The spoken sequence
is compactly represented as a confusion network extracted from a pre-trained
Automatic Speech Recognizer. This is the first attempt towards generating
full-length natural answers from a graph input(confusion network) to the best
of our knowledge. We release a large-scale dataset of 259,788 samples of spoken
questions, their factoid answers and corresponding full-length textual answers.
Following our proposed approach, we achieve comparable performance with best
ASR hypothesis.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:04:49 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 08:39:41 GMT""}]","2020-09-24"
"2006.05164","Jae Hyun Lim","Jae Hyun Lim, Aaron Courville, Christopher Pal, Chin-Wei Huang","AR-DAE: Towards Unbiased Neural Entropy Gradient Estimation","accepted in ICML 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entropy is ubiquitous in machine learning, but it is in general intractable
to compute the entropy of the distribution of an arbitrary continuous random
variable. In this paper, we propose the amortized residual denoising
autoencoder (AR-DAE) to approximate the gradient of the log density function,
which can be used to estimate the gradient of entropy. Amortization allows us
to significantly reduce the error of the gradient approximator by approaching
asymptotic optimality of a regular DAE, in which case the estimation is in
theory unbiased. We conduct theoretical and experimental analyses on the
approximation error of the proposed method, as well as extensive studies on
heuristics to ensure its robustness. Finally, using the proposed gradient
approximator to estimate the gradient of entropy, we demonstrate
state-of-the-art performance on density estimation with variational
autoencoders and continuous control with soft actor-critic.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:11:28 GMT""}]","2020-06-11"
"2006.05165","Peng Li","Qiu Ran, Yankai Lin, Peng Li, Jie Zhou","Learning to Recover from Multi-Modality Errors for Non-Autoregressive
  Neural Machine Translation","This work has been accepted for publication at ACL2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-autoregressive neural machine translation (NAT) predicts the entire
target sequence simultaneously and significantly accelerates inference process.
However, NAT discards the dependency information in a sentence, and thus
inevitably suffers from the multi-modality problem: the target tokens may be
provided by different possible translations, often causing token repetitions or
missing. To alleviate this problem, we propose a novel semi-autoregressive
model RecoverSAT in this work, which generates a translation as a sequence of
segments. The segments are generated simultaneously while each segment is
predicted token-by-token. By dynamically determining segment length and
deleting repetitive segments, RecoverSAT is capable of recovering from
repetitive and missing token errors. Experimental results on three widely-used
benchmark datasets show that our proposed model achieves more than 4$\times$
speedup while maintaining comparable performance compared with the
corresponding autoregressive model.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:12:16 GMT""}]","2020-06-11"
"2006.05166","Dr Krishna Kumar Singh","K. K. Singh, P. J. Meintjes","Characterization of Variability in Blazar Light curves","13 Pages, Accepted for Publication in Astronomische Nachrichten
  (Astronomical Notes) Journal",,"10.1002/asna.202013731",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blazars represent dominant population of the extragalactic $\gamma$-ray
sources in the Universe. These sources exhibit some characteristic properties
like strong and non-thermal continuum emission over the entire electromagnetic
spectrum from radio to TeV $\gamma$-rays with rapid variability on all
timescales. The emission at radio and optical wavelengths is highly polarized
with significant variation. The fastest variability in the blazar emission is
observed during the flaring activity which is an important observational
property of blazars. In this paper, we describe various methods to characterize
the temporal variability in the multi-wavelength light curves of blazars. We
also provide a detailed description of the set of statistical parameters which
are used to quantify the level of variability present in the time-series.
Implications of the informations derived from the variability study to probe
the physics of blazars using multi-wavelength observations are also discussed.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:13:25 GMT""}]","2020-10-07"
"2006.05167","Sara Asgari","Sara Asgari and Babak Sadeghiyan","Towards Generating Benchmark Datasets for Worm Infection Studies",,,"10.1109/IST50524.2020.9345845",,"cs.CR cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Worm origin identification and propagation path reconstruction are among the
essential problems in digital forensics. Until now, several methods have been
proposed for this purpose. However, evaluating these methods is a big challenge
because there are no suitable datasets containing both normal background
traffic and worm traffic to evaluate these methods. In this paper, we
investigate different methods of generating such datasets and suggest a
technique for this purpose. ReaSE is a tool for the creation of realistic
simulation environments. However, it needs some modifications to be suitable
for generating the datasets. So we make required modifications to it. Then, we
generate several datasets for Slammer, Code Red I, Code Red II and modified
versions of these worms in different scenarios using our technique and make
them publicly available.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:21:21 GMT""},{""version"":""v2"",""created"":""Sun, 14 Jun 2020 12:17:09 GMT""},{""version"":""v3"",""created"":""Fri, 3 Jul 2020 12:44:30 GMT""},{""version"":""v4"",""created"":""Sat, 30 Jan 2021 16:56:33 GMT""},{""version"":""v5"",""created"":""Sun, 21 Feb 2021 20:07:23 GMT""},{""version"":""v6"",""created"":""Sun, 30 May 2021 17:25:08 GMT""}]","2021-06-01"
"2006.05168","Patrick Rubin-Delanchy Dr","Patrick Rubin-Delanchy","Manifold structure in graph embeddings",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Statistical analysis of a graph often starts with embedding, the process of
representing its nodes as points in space. How to choose the embedding
dimension is a nuanced decision in practice, but in theory a notion of true
dimension is often available. In spectral embedding, this dimension may be very
high. However, this paper shows that existing random graph models, including
graphon and other latent position models, predict the data should live near a
much lower-dimensional set. One may therefore circumvent the curse of
dimensionality by employing methods which exploit hidden manifold structure.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:30:17 GMT""},{""version"":""v2"",""created"":""Wed, 28 Oct 2020 16:21:11 GMT""},{""version"":""v3"",""created"":""Tue, 5 Jan 2021 11:17:07 GMT""}]","2021-01-06"
"2006.05169","Chun Yuan Yuan","Chunyuan Yuan, Jiacheng Li, Wei Zhou, Yijun Lu, Xiaodan Zhang, Songlin
  Hu","DyHGCN: A Dynamic Heterogeneous Graph Convolutional Network to Learn
  Users' Dynamic Preferences for Information Diffusion Prediction","Accepted to the ECML-PKDD 2020",,,,"cs.SI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Information diffusion prediction is a fundamental task for understanding the
information propagation process. It has wide applications in such as
misinformation spreading prediction and malicious account detection. Previous
works either concentrate on utilizing the context of a single diffusion
sequence or using the social network among users for information diffusion
prediction. However, the diffusion paths of different messages naturally
constitute a dynamic diffusion graph. For one thing, previous works cannot
jointly utilize both the social network and diffusion graph for prediction,
which is insufficient to model the complexity of the diffusion process and
results in unsatisfactory prediction performance. For another, they cannot
learn users' dynamic preferences. Intuitively, users' preferences are changing
as time goes on and users' personal preference determines whether the user will
repost the information. Thus, it is beneficial to consider users' dynamic
preferences in information diffusion prediction.
  In this paper, we propose a novel dynamic heterogeneous graph convolutional
network (DyHGCN) to jointly learn the structural characteristics of the social
graph and dynamic diffusion graph. Then, we encode the temporal information
into the heterogeneous graph to learn the users' dynamic preferences. Finally,
we apply multi-head attention to capture the context-dependency of the current
diffusion path to facilitate the information diffusion prediction task.
Experimental results show that DyHGCN significantly outperforms the
state-of-the-art models on three public datasets, which shows the effectiveness
of the proposed model.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:34:41 GMT""}]","2020-06-11"
"2006.05170","Mirko Residori","Lukas Einkemmer, Alexander Ostermann, Mirko Residori","A pseudo-spectral Strang splitting method for linear dispersive problems
  with transparent boundary conditions",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present work proposes a second-order time splitting scheme for a linear
dispersive equation with a variable advection coefficient subject to
transparent boundary conditions. For its spatial discretization, a dual
Petrov--Galerkin method is considered which gives spectral accuracy. The main
difficulty in constructing a second-order splitting scheme in such a situation
lies in the compatibility condition at the boundaries of the sub-problems. In
particular, the presence of an inflow boundary condition in the advection part
results in order reduction. To overcome this issue a modified Strang splitting
scheme is introduced that retains second-order accuracy. For this numerical
scheme a stability analysis is conducted. In addition, numerical results are
shown to support the theoretical derivations.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:35:46 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 13:46:20 GMT""}]","2021-06-09"
"2006.05171","Kiril Borisov","K. Borisov, D. Rieger, P. Winkel, F. Henriques, F. Valenti, A. Ionita,
  M. Wessbecher, M. Spiecker, D. Gusenkova, I. M. Pop, and W. Wernsdorfer","Superconducting granular aluminum resonators resilient to magnetic
  fields up to 1 Tesla","Resolved typos and added data availability statement","Appl. Phys. Lett. 117, 120502 (2020)","10.1063/5.0018012",,"cond-mat.supr-con quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High kinetic inductance materials constitute a valuable resource for
superconducting quantum circuits and hybrid architectures. Superconducting
granular aluminum (grAl) reaches kinetic sheet inductances in the nH/$\square$
range, with proven applicability in superconducting quantum bits and microwave
detectors. Here we show that the single photon internal quality factor
$Q_{\mathrm{i}}$ of grAl microwave resonators exceeds $10^5$ in magnetic fields
up to 1T, aligned in-plane to the grAl films. Small perpendicular magnetic
fields, in the range of 0.5mT, enhance $Q_{\mathrm{i}}$ by approximately 15%,
possibly due to the introduction of quasiparticle traps in the form of fluxons.
Further increasing the perpendicular field deteriorates the resonators' quality
factor. These results open the door for the use of high kinetic inductance grAl
structures in circuit quantum electrodynamics and hybrid architectures with
magnetic field requirements.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:36:13 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 15:23:53 GMT""}]","2021-04-27"
"2006.05172","Mete Sertkan","Mete Sertkan, Julia Neidhardt, Hannes Werthner","Eliciting Touristic Profiles: A User Study on Picture Collections","Accepted at UMAP 2020 (full paper)",,"10.1145/3340631.3394868",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Eliciting the preferences and needs of tourists is challenging, since people
often have difficulties to explicitly express them, especially in the initial
phase of travel planning. Recommender systems employed at the early stage of
planning can therefore be very beneficial to the general satisfaction of a
user. Previous studies have explored pictures as a tool of communication and as
a way to implicitly deduce a traveller's preferences and needs. In this paper,
we conduct a user study to verify previous claims and conceptual work on the
feasibility of modelling travel interests from a selection of a user's
pictures. We utilize fine-tuned convolutional neural networks to compute a
vector representation of a picture, where each dimension corresponds to a
travel behavioural pattern from the traditional Seven-Factor model. In our
study, we followed strict privacy principles and did not save uploaded pictures
after computing their vector representation. We aggregate the representations
of the pictures of a user into a single user representation, i.e., touristic
profile, using different strategies. In our user study with 81 participants, we
let users adjust the predicted touristic profile and confirm the usefulness of
our approach. Our results show that given a collection of pictures the
touristic profile of a user can be determined.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:39:14 GMT""}]","2020-06-11"
"2006.05173","Xudong Gao","Xudong Gao, Karin Lind, Anish M. Amarsi, Sven Buder, Joss
  Bland-Hawthorn, Simon W. Campbell, Martin Asplund, Andrew R. Casey, Gayandhi
  M. De Silva, Ken C. Freeman, Michael R. Hayden, Geraint F. Lewis, Sarah L.
  Martell, Jeffrey D. Simpson, Sanjib Sharma, Daniel B. Zucker, Toma\v{z}
  Zwitter, Jonathan Horner, Ulisse Munari, Thomas Nordlander, Dennis Stello,
  Yuan-Sen Ting, Gregor Traven, Robert A. Wittenmyer and the GALAH
  collaboration","The GALAH Survey: A new constraint on cosmological lithium and Galactic
  lithium evolution from warm dwarf stars","5 pages, 2 figures, Accepted for publication by MNRAS",,"10.1093/mnrasl/slaa109",,"astro-ph.SR astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lithium depletion and enrichment in the cosmos is not yet well understood. To
help tighten constraints on stellar and Galactic evolution models, we present
the largest high-resolution analysis of Li abundances A(Li) to date, with
results for over 100 000 GALAH field stars spanning effective temperatures
$5900\,\mathrm{K} \lesssim \rm{T_{eff}} \lesssim7000\,\mathrm{K}$ and
metallicities $-3 \lesssim \rm[Fe/H] \lesssim +0.5$. We separated these stars
into two groups, on the warm and cool side of the so-called Li-dip, a localised
region of the Kiel diagram wherein lithium is severely depleted. We discovered
that stars in these two groups show similar trends in the A(Li)-[Fe/H] plane,
but with a roughly constant offset in A(Li) of 0.4 dex, the warm group having
higher Li abundances. At $\rm[Fe/H]\gtrsim-0.5$, a significant increasing in Li
abundance with increasing metallicity is evident in both groups, signalling the
onset of significant Galactic production. At lower metallicity, stars in the
cool group sit on the Spite plateau, showing a reduced lithium of around 0.4
dex relative to the primordial value predicted from Big Bang nucleosynthesis
(BBN). However, stars in the warm group between [Fe/H] = -1.0 and -0.5, form an
elevated plateau that is largely consistent with the BBN prediction. This may
indicate that these stars in fact preserve the primordial Li produced in the
early Universe.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:40:42 GMT""}]","2020-06-17"
"2006.05174","Tsung-Han Wu","Tsung-Han Wu, Chun-Chen Hsieh, Yen-Hao Chen, Po-Han Chi, Hung-yi Lee","Input-independent Attention Weights Are Expressive Enough: A Study of
  Attention in Self-supervised Audio Transformers",,,,,"eess.AS cs.CL cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we seek solutions for reducing the computation complexity of
transformer-based models for speech representation learning. We evaluate 10
attention algorithms; then, we pre-train the transformer-based model with those
attention algorithms in a self-supervised fashion and treat them as feature
extractors on downstream tasks, including phoneme classification and speaker
classification. With the assistance of t-SNE, PCA and some observation, the
attention weights in self-supervised audio transformers can be categorized into
four general cases. Based on these cases and some analyses, we are able to use
a specific set of attention weights to initialize the model. Our approach shows
comparable performance to the typical self-attention yet requires 20% less time
in both training and inference.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:40:52 GMT""},{""version"":""v2"",""created"":""Tue, 3 Nov 2020 06:32:17 GMT""}]","2020-11-04"
"2006.05175","Antonios Somarakis","Antonios Somarakis, Marieke E. Ijsselsteijn, Sietse J. Luk, Boyd
  Kenkhuis, Noel F.C.C. de Miranda, Boudewijn P.F. Lelieveldt, and Thomas
  H\""ollt","Visual cohort comparison for spatial single-cell omics-data","11 pages, 10 figures, 2 tables. Revised based on IEEE VIS 2020
  reviewers comments. ACM 2012 CCS - Human-centered computing, Visualization,
  Visualization application domains, Visual analytics. Binary of the presented
  tool is available is our repository: https://doi.org/10.5281/zenodo.3885814","Presented in IEEE Vis 2020. Published in IEEE Transactions on
  Visualization and Computer Graphics (TVCG)","10.1109/TVCG.2020.3030336",,"cs.HC q-bio.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spatially-resolved omics-data enable researchers to precisely distinguish
cell types in tissue and explore their spatial interactions, enabling deep
understanding of tissue functionality. To understand what causes or
deteriorates a disease and identify related biomarkers, clinical researchers
regularly perform large-scale cohort studies, requiring the comparison of such
data at cellular level. In such studies, with little a-priori knowledge of what
to expect in the data, explorative data analysis is a necessity. Here, we
present an interactive visual analysis workflow for the comparison of cohorts
of spatially-resolved omics-data. Our workflow allows the comparative analysis
of two cohorts based on multiple levels-of-detail, from simple abundance of
contained cell types over complex co-localization patterns to individual
comparison of complete tissue images. As a result, the workflow enables the
identification of cohort-differentiating features, as well as outlier samples
at any stage of the workflow. During the development of the workflow, we
continuously consulted with domain experts. To show the effectiveness of the
workflow we conducted multiple case studies with domain experts from different
application areas and with different data modalities.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:47:46 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jul 2020 14:03:12 GMT""}]","2020-11-04"
"2006.05176","Francesco Bonchi","Tommaso Lanciano, Francesco Bonchi, Aristides Gionis","Explainable Classification of Brain Networks via Contrast Subgraphs","To be published at KDD 2020",,,,"cs.SI q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mining human-brain networks to discover patterns that can be used to
discriminate between healthy individuals and patients affected by some
neurological disorder, is a fundamental task in neuroscience. Learning simple
and interpretable models is as important as mere classification accuracy. In
this paper we introduce a novel approach for classifying brain networks based
on extracting contrast subgraphs, i.e., a set of vertices whose induced
subgraphs are dense in one class of graphs and sparse in the other. We formally
define the problem and present an algorithmic solution for extracting contrast
subgraphs. We then apply our method to a brain-network dataset consisting of
children affected by Autism Spectrum Disorder and children Typically Developed.
Our analysis confirms the interestingness of the discovered patterns, which
match background knowledge in the neuroscience literature. Further analysis on
other classification tasks confirm the simplicity, soundness, and high
explainability of our proposal, which also exhibits superior classification
accuracy, to more complex state-of-the-art methods.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:48:55 GMT""}]","2020-06-11"
"2006.05177","Henry Day-Hall","Rachid Benbrik (1), Henry Day-Hall (2)(3), Stefano Moretti (2), Souad
  Semlali (1) ((1) Laboratoire de Physique fondamentale et Appliq\'ee Safi,
  Facult\'e Polydisciplinaire de Safi, Sidi Bouzid, Morocco, (2) School of
  Physics and Astronomy, University of Southampton, United Kingdom, (3)
  Particle Physics Department, Rutherford Appleton Laboratory, United Kingdom)","Mapping $pp\to A\to ZH\to l^+l^-b\bar b$ and $pp\to H\to ZA\to
  l^+l^-b\bar b$ Current and Future Searches onto 2HDM Parameter Spaces","16 pages, 4 figures",,"10.1016/j.physletb.2020.135819",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By borrowing the results from a Large Hadron Collider (LHC) analysis
performed with $36.1~\text{fb}^{-1}$ of Run 2 data intended to search for $A$
production followed by $ZH$ decay in turn yielding $l^+l^-b\bar b$ ($l=e,\mu$)
final states in the context of the standard four Yukawa types of the 2-Higgs
Doublet Model (2HDM), we recast it in terms of sensitivity reaches for the
similar process $pp\to H\to ZA\to l^+l^-b\bar b$. This simple exercise across
the two processes, which is possible because the only kinematic difference
between these are different widths for the Higgs bosons, in turn affecting
minimally the efficiency of an experimental selection, enables us to expand the
region of parameter space that can be tested to the case when $m_H\ge m_A+m_Z$.
Furthermore, we extrapolate our results to full Run 3 data samples. We conclude
that, while the high energy and luminosity stage of the LHC can afford one with
increased sensitivity to the 2HDM in general, the recast analysis does not add
anything to what already probed through the actual one.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:49:04 GMT""}]","2020-10-15"
"2006.05178","Mikolaj Jerzykiewicz","M. Jerzykiewicz, A. Pigulski, G. Handler, A.F.J. Moffat, A. Popowicz,
  G.A. Wade, K. Zwintz and H. Pablo","BRITE-Constellation photometry of $\bpi^5$ Orionis, an ellipsoidal SPB
  variable",,,"10.1093/mnras/staa1665",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Results of an analysis of the BRITE-Constellation photometry of the SB1
system and ellipsoidal variable $\pi^5$ Ori (B2\,III) are presented. In
addition to the orbital light-variation, which can be represented as a
five-term Fourier cosine series with the frequencies $f_{\rm orb}$, $2f_{\rm
orb}$, $3f_{\rm orb}$, $4f_{\rm orb}$ and $6f_{\rm orb}$, where $f_{\rm orb}$
is the system's orbital frequency, the star shows five low-amplitude but
highly-significant sinusoidal variations with frequencies $f_i$ ($i
={}$2,..,5,7) in the range from 0.16 to 0.92~d$^{-1}$. With an accuracy better
than 1$\sigma$, the latter frequencies obey the following relations: $f_2-f_4 =
2f_{\rm orb}$, $f_7 - f_3 = 2f_{\rm orb}$, $f_5 = f_3 - f_4 = f_7 - f_2$. We
interpret the first two relations as evidence that two high-order $\ell = 1, m
= 0$ gravity modes are self-excited in the system's tidally distorted primary
component. The star is thus an ellipsoidal SPB variable. The last relations
arise from the existence of the first-order differential combination term
between the two modes. Fundamental parameters, derived from photometric data in
the literature and the {\em Hipparcos\/} parallax, indicate that the primary
component is close to the terminal stages of its main sequence (MS) evolution.
Extensive Wilson-Devinney modeling leads to the conclusion that best fits of
the theoretical to observed light-curves are obtained for the effective
temperature and mass consistent with the primary's position in the HR diagram
and suggests that the secondary is in an early MS evolutionary stage.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:50:22 GMT""}]","2020-06-17"
"2006.05179","Jinkui Hao","Jinkui Hao, Huazhu Fu, Yanwu Xu, Yan Hu, Fei Li, Xiulan Zhang, Jiang
  Liu, Yitian Zhao","Reconstruction and Quantification of 3D Iris Surface for Angle-Closure
  Glaucoma Detection in Anterior Segment OCT","has been accepted by MICCAI 2020",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Precise characterization and analysis of iris shape from Anterior Segment OCT
(AS-OCT) are of great importance in facilitating diagnosis of
angle-closure-related diseases. Existing methods focus solely on analyzing
structural properties identified from the 2D slice, while accurate
characterization of morphological changes of iris shape in 3D AS-OCT may be
able to reveal in addition the risk of disease progression. In this paper, we
propose a novel framework for reconstruction and quantification of 3D iris
surface from AS-OCT imagery. We consider it to be the first work to detect
angle-closure glaucoma by means of 3D representation. An iris segmentation
network with wavelet refinement block (WRB) is first proposed to generate the
initial shape of the iris from single AS-OCT slice. The 3D iris surface is then
reconstructed using a guided optimization method with Poisson-disk sampling.
Finally, a set of surface-based features are extracted, which are used in
detecting of angle-closure glaucoma. Experimental results demonstrate that our
method is highly effective in iris segmentation and surface reconstruction.
Moreover, we show that 3D-based representation achieves better performance in
angle-closure glaucoma detection than does 2D-based feature.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:56:50 GMT""}]","2020-06-11"
"2006.05180","Naoto Yokoya","Naoto Yokoya, Kazuki Yamanoi, Wei He, Gerald Baier, Bruno Adriano,
  Hiroyuki Miura, Satoru Oishi","Breaking the Limits of Remote Sensing by Simulation and Deep Learning
  for Flood and Debris Flow Mapping",,,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a framework that estimates inundation depth (maximum water level)
and debris-flow-induced topographic deformation from remote sensing imagery by
integrating deep learning and numerical simulation. A water and debris flow
simulator generates training data for various artificial disaster scenarios. We
show that regression models based on Attention U-Net and LinkNet architectures
trained on such synthetic data can predict the maximum water level and
topographic deformation from a remote sensing-derived change detection map and
a digital elevation model. The proposed framework has an inpainting capability,
thus mitigating the false negatives that are inevitable in remote sensing image
analysis. Our framework breaks the limits of remote sensing and enables rapid
estimation of inundation depth and topographic deformation, essential
information for emergency response, including rescue and relief activities. We
conduct experiments with both synthetic and real data for two disaster events
that caused simultaneous flooding and debris flows and demonstrate the
effectiveness of our approach quantitatively and qualitatively.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:59:15 GMT""}]","2020-06-11"
"2006.05181","Miguel de Prado","Miguel de Prado, Andrew Mundy, Rabia Saeed, Maurizio Denna, Nuria
  Pazos and Luca Benini","Automated Design Space Exploration for optimised Deployment of DNN on
  Arm Cortex-A CPUs",,,"10.1109/TCAD.2020.3046568",,"cs.LG cs.CV eess.IV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spread of deep learning on embedded devices has prompted the development
of numerous methods to optimise the deployment of deep neural networks (DNN).
Works have mainly focused on: i) efficient DNN architectures, ii) network
optimisation techniques such as pruning and quantisation, iii) optimised
algorithms to speed up the execution of the most computational intensive layers
and, iv) dedicated hardware to accelerate the data flow and computation.
However, there is a lack of research on cross-level optimisation as the space
of approaches becomes too large to test and obtain a globally optimised
solution. Thus, leading to suboptimal deployment in terms of latency, accuracy,
and memory. In this work, we first detail and analyse the methods to improve
the deployment of DNNs across the different levels of software optimisation.
Building on this knowledge, we present an automated exploration framework to
ease the deployment of DNNs. The framework relies on a Reinforcement Learning
search that, combined with a deep learning inference framework, automatically
explores the design space and learns an optimised solution that speeds up the
performance and reduces the memory on embedded CPU platforms. Thus, we present
a set of results for state-of-the-art DNNs on a range of Arm Cortex-A CPU
platforms achieving up to 4x improvement in performance and over 2x reduction
in memory with negligible loss in accuracy with respect to the BLAS
floating-point implementation.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:00:06 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 19:30:11 GMT""}]","2020-12-29"
"2006.05182","Swati Goswami","Swati Goswami, Nodir Kodirov, Craig Mustard, Ivan Beschastnikh, Margo
  Seltzer","Parking Packet Payload with P4",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network Function (NF) deployments suffer from poor link goodput, because
popular NFs such as firewalls process only packet headers while receiving and
transmitting complete packets. As a result, unnecessary packet payloads
needlessly consume link bandwidth. We introduce PayloadPark, which improves
goodput by temporarily parking packet payloads in the stateful memory of
dataplane programmable switches. PayloadPark forwards only packet headers to NF
servers, thereby saving bandwidth between the switch and the NF server.
PayloadPark is a transparent in-network optimization that complements existing
approaches for optimizing NF performance on end-hosts.
  We prototyped PayloadPark on a Barefoot Tofino ASIC using the P4 language.
Our prototype, when deployed on a top-of-rack switch, can service up to 8 NF
servers using less than 40% of the on-chip memory resources. The prototype
improves goodput by 10- 36% for Firewall and NAT NFs and by 10-26% for a
Firewall -> NAT NF chain without harming latency. The prototype also reduces
PCIe bus load by 2-58% on the NF server thanks to the reduced data transmission
between the switch and the NF server. With workloads that have datacenter
network traffic characteristics, PayloadPark provides a 13% goodput gain with
the Firewall -> NAT -> LB NF chain without latency penalty. In the same setup,
we can further increase the goodput gain to 28% by using packet recirculation.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:02:19 GMT""},{""version"":""v2"",""created"":""Mon, 2 Nov 2020 09:25:29 GMT""}]","2020-11-03"
"2006.05183","Piotr Kawa","Piotr Kawa and Piotr Syga","A Note on Deepfake Detection with Low-Resources",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deepfakes are videos that include changes, quite often substituting face of a
portrayed individual with a different face using neural networks. Even though
the technology gained its popularity as a carrier of jokes and parodies it
raises a serious threat to ones security - via biometric impersonation or
besmearing. In this paper we present two methods that allow detecting Deepfakes
for a user without significant computational power. In particular, we enhance
MesoNet by replacing the original activation functions allowing a nearly 1%
improvement as well as increasing the consistency of the results. Moreover, we
introduced and verified a new activation function - Pish that at the cost of
slight time overhead allows even higher consistency.
  Additionally, we present a preliminary results of Deepfake detection method
based on Local Feature Descriptors (LFD), that allows setting up the system
even faster and without resorting to GPU computation. Our method achieved Equal
Error Rate of 0.28, with both accuracy and recall exceeding 0.7.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:07:08 GMT""}]","2020-06-11"
"2006.05184","Rui Lu","Rui Lu, Qingqing Wu, and Rui Zhang","Pilot Decontamination for Massive MIMO Network with UAVs","6 pages, 3 figures",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This letter studies the pilot contamination (PC) problem for massive
multiple-input multiple-output (MIMO) networks with coexisting terrestrial
users and unmanned aerial vehicles (UAVs). Due to the strong line-of-sight
(LoS) air-to-ground channels between UAVs and base stations (BSs), UAVs usually
cause a more severe PC issue as compared to the traditional terrestrial users.
To mitigate the PC caused by UAVs, we propose a low-complexity distributed
scheme by exploiting the full-dimensional beamforming of massive MIMO BSs and
the angle-dependent LoS channels between them and high-altitude UAVs. Numerical
results show the effectiveness of the proposed pilot decontamination scheme and
the significant signal-to-interference-plus-noise ratio (SINR) gains in both
the uplink and downlink after pilot decontamination.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:10:10 GMT""}]","2020-06-11"
"2006.05185","Tim Morris Prof","Tim R. Morris","The continuum limit of the conformal sector at second order in
  perturbation theory","64 pages, 3 figures. Clarifications added. To be publ in PRD","Phys. Rev. D 103, 086007 (2021)","10.1103/PhysRevD.103.086007",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently a novel perturbative continuum limit for quantum gravity has been
proposed and demonstrated to work at first order. Every interaction monomial
$\sigma$ is dressed with a coefficient function $f^\sigma_\Lambda(\varphi)$ of
the conformal factor field, $\varphi$. Each coefficient function is
parametrised by an infinite number of underlying couplings, and decays at large
$\varphi$ with a characteristic amplitude suppression scale which can be chosen
to be at a common value, $\Lambda_\text{p}$. Although the theory is
perturbative in couplings it is non-perturbative in $\hbar$. At second order in
perturbation theory, one must sum over all melonic Feynman diagrams to obtain
the particular integral. We show that it leads to a well defined renormalized
trajectory and thus continuum limit, provided it is solved by starting at an
arbitrary cutoff scale $\Lambda=\mu$ which lies in the range
$0<\mu<a\Lambda_\text{p}$ ($a$ some non-universal number). If $\mu$ lies above
this range the resulting coefficient functions become singular, and the flow
ceases to exist, before the physical limit is reached. To this one must add a
well-behaved complementary solution, containing irrelevant couplings determined
uniquely by the first-order interactions, and renormalized relevant couplings.
Even though some irrelevant couplings diverge in the limit
$\Lambda_\text{p}\to\infty$, domains for the underlying relevant couplings can
be chosen such that diffeomorphism invariance will be recovered in this limit,
and where the underlying couplings disappear to be replaced by effective
diffeomorphism invariant couplings.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:10:45 GMT""},{""version"":""v2"",""created"":""Sun, 21 Mar 2021 12:12:55 GMT""}]","2021-04-21"
"2006.05186","Daniel Seibel","Daniel Seibel","Boundary Element Methods for the Wave Equation based on Hierarchical
  Matrices and Adaptive Cross Approximation","40 pages, 15 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time-domain Boundary Element Methods (BEM) have been successfully used in
acoustics, optics and elastodynamics to solve transient problems numerically.
However, the storage requirements are immense, since the fully populated system
matrices have to be computed for a large number of time steps or frequencies.
In this article, we propose a new approximation scheme for the Convolution
Quadrature Method (CQM) powered BEM, which we apply to scattering problems
governed by the wave equation. We use $\mathcal{H}^2$-matrix compression in the
spatial domain and employ an adaptive cross approximation (ACA) algorithm in
the frequency domain. In this way, the storage and computational costs are
reduced significantly, while the accuracy of the method is preserved.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:12:43 GMT""}]","2020-06-11"
"2006.05187","Qingdong He","Qingdong He, Zhengning Wang, Hao Zeng, Yijun Liu, Shuaicheng Liu, Bing
  Zeng","Stereo RGB and Deeper LIDAR Based Network for 3D Object Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D object detection has become an emerging task in autonomous driving
scenarios. Previous works process 3D point clouds using either projection-based
or voxel-based models. However, both approaches contain some drawbacks. The
voxel-based methods lack semantic information, while the projection-based
methods suffer from numerous spatial information loss when projected to
different views. In this paper, we propose the Stereo RGB and Deeper LIDAR
(SRDL) framework which can utilize semantic and spatial information
simultaneously such that the performance of network for 3D object detection can
be improved naturally. Specifically, the network generates candidate boxes from
stereo pairs and combines different region-wise features using a deep fusion
scheme. The stereo strategy offers more information for prediction compared
with prior works. Then, several local and global feature extractors are stacked
in the segmentation module to capture richer deep semantic geometric features
from point clouds. After aligning the interior points with fused features, the
proposed network refines the prediction in a more accurate manner and encodes
the whole box in a novel compact method. The decent experimental results on the
challenging KITTI detection benchmark demonstrate the effectiveness of
utilizing both stereo images and point clouds for 3D object detection.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:19:24 GMT""}]","2021-03-26"
"2006.05188","Jeremias Knoblauch","Jeremias Knoblauch, Hisham Husain, Tom Diethe","Optimal Continual Learning has Perfect Memory and is NP-hard","Accepted for publication at ICML (International Conference on Machine
  Learning) 2020; 13 pages, 8 Figures",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continual Learning (CL) algorithms incrementally learn a predictor or
representation across multiple sequentially observed tasks. Designing CL
algorithms that perform reliably and avoid so-called catastrophic forgetting
has proven a persistent challenge. The current paper develops a theoretical
approach that explains why. In particular, we derive the computational
properties which CL algorithms would have to possess in order to avoid
catastrophic forgetting. Our main finding is that such optimal CL algorithms
generally solve an NP-hard problem and will require perfect memory to do so.
The findings are of theoretical interest, but also explain the excellent
performance of CL algorithms using experience replay, episodic memory and core
sets relative to regularization-based approaches.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:20:38 GMT""}]","2020-06-11"
"2006.05189","Souradeep Bhattacharya","Kaushar Vaidya, Khushboo K. Rao, Manan Agarwal and Souradeep
  Bhattacharya","Blue Straggler Populations of Seven Open Clusters with Gaia DR2","22 pages, 15 figures, 5 tables, Accepted for publication in MNRAS",,"10.1093/mnras/staa1667",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blue straggler stars (BSS) are well studied in globular clusters but their
systematic study with secure membership determination is lacking in open
clusters. We use Gaia DR2 data to determine accurate stellar membership for
four intermediate-age open clusters, Melotte 66, NGC 2158, NGC 2506 and NGC
6819, and three old open clusters, Berkeley 39, NGC 188 and NGC 6791, to
subsequently study their BSS populations. The BSS radial distributions of five
clusters, Melotte 66, NGC 188, NGC 2158, NGC 2506, and NGC 6791, show bimodal
distributions, placing them with Family II globular clusters which are of
intermediate dynamical ages. The location of minima, $r_\mathrm{{min}}$, in the
bimodal BSS radial distributions, varies from 1.5$r_c$ to 4.0$r_c$, where $r_c$
is the core radius of the clusters. We find a positive correlation between
$r_\mathrm{{min}}$ and $N_{\mathrm{relax}}$, the ratio of cluster age to the
current central relaxation time of the cluster. We further report that this
correlation is consistent in its slope, within the errors, to the slope of the
globular cluster correlation between the same quantities, but with a slightly
higher intercept. This is the first example in open clusters that shows BSS
radial distributions as efficient probes of dynamical age. The BSS radial
distributions of the remaining two clusters, Berkeley 39 and NGC 6819, are
flat. The estimated $N_{\mathrm{relax}}$ values of these two clusters, however,
indicate that they are dynamically evolved. Berkeley 39 especially has its
entire BSS population completely segregated to the inner regions of the
cluster.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:23:13 GMT""}]","2020-06-17"
"2006.05190","Vivek Kumar","Vivek Kumar, Nitesh Kumar, Manfred Reehuis, Jacob Gayles, A. S.
  Sukhanov, Andreas Hoser, Fran\c{c}oise Damay, Chandra Shekhar, Peter Adler,
  and Claudia Felser","Detection of antiskyrmions by topological Hall effect in Heusler
  compounds",,"Phys. Rev. B, 101, 014424 (2020)","10.1103/PhysRevB.101.014424",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heusler compounds having $\textit{D}$${}_{2d}$ crystal symmetry gained much
attention recently due to the stabilization of a vortex-like spin texture
called antiskyrmions in thin lamellae of Mn${}_{1.4}$Pt${}_{0.9}$Pd${}_{0.1}$Sn
as reported in the work of Nayak $\textit{et al.}$ [Nature (London) 548, 561
(2017)]. Here we show that bulk Mn${}_{1.4}$Pt${}_{0.9}$Pd${}_{0.1}$Sn
undergoes a spin-reorientation transition from a collinear ferromagnetic to a
noncollinear configuration of Mn moments below 135 K, which is accompanied by
the emergence of a topological Hall effect. We tune the topological Hall effect
in Pd and Rh substituted Mn${}_{1.4}$PtSn Heusler compounds by changing the
intrinsic magnetic properties and spin textures. A unique feature of the
present system is the observation of a zero-field topological Hall resistivity
with a sign change which indicates the robust formation of antiskyrmions.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:29:54 GMT""}]","2020-06-11"
"2006.05191","Heiko B. Weber","Matthias A. Popp, Andr\'e Erpenbeck, Heiko B. Weber","Thermoelectricity of near-resonant tunnel junctions and their
  near-Carnot efficiency",,,"10.1038/s41598-021-81466-3",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The resonant tunneling model is the simplest model for describing electronic
transport through nanoscale objects like individual molecules. A complete
understanding includes not only charge transport but also thermal transport and
their intricate interplay. Key linear response observables are the electrical
conductance G and the Seebeck coefficient S. Here we present experiments on
unspecified resonant tunnel junctions and molecular junctions that uncover
correlations between $G$ and $S$, in particular rigid boundaries for $S(G)$. We
find that these correlations can be consistently understood by the single-level
resonant tunneling model, with excellent match to experiments. In this
framework, measuring $I(V)$ and $S$ for a given junction provides access to the
full thermoelectric characterization of the electronic system. A remarkable
result is that without targeted chemical design, molecular junctions can expose
thermoelectric conversion efficiencies which are close to the Carnot limit.
This insight allows to provide design rules for optimized thermoelectric
efficiency.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:36:57 GMT""}]","2021-01-25"
"2006.05192","Alex Suzdaltsev","Alex Suzdaltsev","An Optimal Distributionally Robust Auction","Updated literature review and exposition; results unchanged",,,,"econ.TH cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An indivisible object may be sold to one of $n$ agents who know their
valuations of the object. The seller would like to use a revenue-maximizing
mechanism but her knowledge of the valuations' distribution is scarce: she
knows only the means (which may be different) and an upper bound for
valuations. Valuations may be correlated.
  Using a constructive approach based on duality, we prove that a mechanism
that maximizes the worst-case expected revenue among all deterministic
dominant-strategy incentive compatible, ex post individually rational
mechanisms is such that the object should be awarded to the agent with the
highest linear score provided it is nonnegative. Linear scores are
bidder-specific linear functions of bids. The set of optimal mechanisms
includes other mechanisms but all those have to be close to the optimal linear
score auction in a certain sense. When means are high, all optimal mechanisms
share the linearity property. Second-price auction without a reserve is an
optimal mechanism when the number of symmetric bidders is sufficiently high.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:37:13 GMT""},{""version"":""v2"",""created"":""Wed, 26 Aug 2020 14:55:28 GMT""}]","2020-08-27"
"2006.05193","Sascha Kurz","Sascha Kurz","A note on the growth of the dimension in complete simple games","9 pages",,"10.1016/j.mathsocsci.2021.01.001",,"cs.GT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The remoteness from a simple game to a weighted game can be measured by the
concept of the dimension or the more general Boolean dimension. It is known
that both notions can be exponential in the number of voters. For complete
simple games it was only recently shown that the dimension can also be
exponential. Here we show that this is also the case for complete simple games
with two types of voters and for the Boolean dimension of general complete
simple games, which was posed as an open problem.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:39:43 GMT""}]","2021-01-26"
"2006.05194","Akiva Bruno Melka","Akiva B. Melka and Yoram Louzoun","Evaluation of the number of undiagnosed infected in an outbreak using
  source of infection measurements",,"Sci Rep 11, 3601 (2021)","10.1038/s41598-021-82691-6",,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In times of outbreaks, an essential requirement for better monitoring is the
evaluation of the number of undiagnosed infected individuals. An accurate
estimate of this fraction is crucial for the assessment of the situation and
the establishment of protective measures. In most current studies using
epidemics models, the total number of infected is either approximated by the
number of diagnosed individuals or is dependent on the model parameters and
assumptions, which are often debated. We here study the relationship between
the fraction of diagnosed infected out of all infected, and the fraction of
infected with known contaminator out of all diagnosed infected. We show that
those two are approximately the same in exponential models and across most
models currently used in the study of epidemics, independently of the model
parameters. As an application, we compute an estimate of the effective number
of infected by the SARS-CoV-2 virus in various countries.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:43:13 GMT""},{""version"":""v2"",""created"":""Sun, 14 Jun 2020 10:00:49 GMT""},{""version"":""v3"",""created"":""Wed, 2 Sep 2020 09:43:14 GMT""},{""version"":""v4"",""created"":""Sun, 14 Mar 2021 11:45:07 GMT""},{""version"":""v5"",""created"":""Tue, 16 Mar 2021 08:26:25 GMT""}]","2021-03-17"
"2006.05195","David Wallis","David Wallis, Lars N. Hansen, Angus J. Wilkinson, Ricardo A. Lebensohn","Dislocation interactions in olivine control postseismic creep of the
  upper mantle","17 pages, 5 figures, 2 tables",,"10.1038/s41467-021-23633-8",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Changes in stress applied to mantle rocks, such as those imposed by
earthquakes, induce a period of evolution in viscosity and microstructure. This
transient creep is often modelled based on stress transfer among slip systems
due to grain interactions. However, recent experiments have demonstrated that
the intragranular accumulation of stresses among dislocations is the dominant
cause of strain hardening in olivine at low temperatures, raising the question
of whether the same process contributes to transient creep at higher
temperatures. Here, we demonstrate that olivine samples deformed at 25{\deg}C
or 1150 to 1250{\deg}C both contain stress heterogeneities of ~1 GPa that are
imparted by dislocations and have correlation lengths of ~1 micrometre. The
similar stress distributions formed in both temperature regimes indicate that
accumulation of stresses among dislocations also provides a contribution to
transient creep at high temperatures. The results motivate a new generation of
models that capture these intragranular processes and may refine predictions of
evolving mantle viscosity over the earthquake cycle.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:43:44 GMT""}]","2021-07-14"
"2006.05196","Jin Keong","Jin Keong, Xingbo Dong, Zhe Jin, Khawla Mallat, Jean-Luc Dugelay","Multi-spectral Facial Landmark Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal face image analysis is favorable for certain circumstances. For
example, illumination-sensitive applications, like nighttime surveillance; and
privacy-preserving demanded access control. However, the inadequate study on
thermal face image analysis calls for attention in responding to the industry
requirements. Detecting facial landmark points are important for many face
analysis tasks, such as face recognition, 3D face reconstruction, and face
expression recognition. In this paper, we propose a robust neural network
enabled facial landmark detection, namely Deep Multi-Spectral Learning (DMSL).
Briefly, DMSL consists of two sub-models, i.e. face boundary detection, and
landmark coordinates detection. Such an architecture demonstrates the
capability of detecting the facial landmarks on both visible and thermal
images. Particularly, the proposed DMSL model is robust in facial landmark
detection where the face is partially occluded, or facing different directions.
The experiment conducted on Eurecom's visible and thermal paired database shows
the superior performance of DMSL over the state-of-the-art for thermal facial
landmark detection. In addition to that, we have annotated a thermal face
dataset with their respective facial landmark for the purpose of
experimentation.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:43:46 GMT""}]","2020-06-11"
"2006.05197","Abdo Y. Alfakih","A. Y. Alfakih","On the Colin de Verdiere graph number and penny graphs","v1",,,,"math.MG math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Colin de Verdiere number of graph G, denoted by \mu(G), is a spectral
invariant of G that is related to some of its topological properties. For
example, \mu(G) \leq 3 iff G is planar. A penny graph is the contact graph of
equal-radii disks with disjoint interiors in the plane. In this note we prove
lower bounds on \mu(G) when the complement \bar{G} is a penny graph.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:45:09 GMT""}]","2020-06-11"
"2006.05198","Michael F. Sterzik","Michael F. Sterzik, Stefano Bagnulo, Claudia Emde and Mihail Manev","The cloudbow of planet Earth observed in polarisation","13 pages, 7 figures","A&A 639, A89 (2020)","10.1051/0004-6361/202038270",,"astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Scattering processes in the atmospheres of planets cause characteristic
features that can be particularly well observed in polarisation. For planet
Earth, both molecular and scattering by small particles imprint specific
signatures in its phase curve. An unequivocal prediction of a
liquid-water-loaded atmosphere is the existence of a rainbow feature at a
scattering angle of around 138-144deg. Earthshine allows us to observe the
primary rainbow in linear polarisation. We observed polarisation spectra of
Earthshine using FORS2 at the Very Large Telescope for phase angles from 33deg
to 65deg (Sun--Earth--Moon angle). The spectra were used to derive the degree
of polarisation in the B, V, R, and I passbands and the phase curve from 33deg
to 136deg . The new observations extend to the smallest phases that can be
observed from the ground. The degree of polarisation of planet Earth is
increasing for decreasing phase angles downwards of 45deg. From comparison of
the phase curve observed with models of an Earth-type atmosphere we are able to
determine the refractive index of water and to constrain the mean water droplet
sizes to 6-7 mum. Furthermore, we can retrieve the mean cloud fraction of
liquid water clouds to 0.3, and the mean optical depth of the water clouds to
values between 10 and 20. Our observations allow us to discern two
fundamentally different scattering mechanisms of the atmosphere of planet
Earth: molecular and particle scattering. The physical and chemical properties
can be retrieved with high fidelity through suitable inversion of the phase
curve. Observations of polarimetric phase curves of planets beyond the Solar
System shall be extremely valuable for a thorough characterisation of their
atmospheres.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:48:12 GMT""}]","2020-07-15"
"2006.05199","Jean Michel Loubes","Eustasio del Barrio and Jean-Michel Loubes","The statistical effect of entropic regularization in optimal
  transportation",,,,,"math.ST cs.LG math.OC stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose to tackle the problem of understanding the effect of
regularization in Sinkhorn algotihms. In the case of Gaussian distributions we
provide a closed form for the regularized optimal transport which enables to
provide a better understanding of the effect of the regularization from a
statistical framework.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:48:37 GMT""},{""version"":""v2"",""created"":""Mon, 15 Jun 2020 12:49:28 GMT""}]","2020-06-16"
"2006.05200","Dmitry Svintsov","Egor Nikulin, Denis Bandurin, Dmitry Svintsov","Edge diffraction and plasmon launching in two-dimensional electron
  systems",,"Phys. Rev. B 103, 085306 (2021)","10.1103/PhysRevB.103.085306",,"cond-mat.mes-hall physics.optics physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffraction of light at lateral inhomogenities is a central process in the
near-field studies of nanoscale phenomena, especially the propagation of
surface waves. Theoretical description of this process is extremely challenging
due to breakdown of plane-wave methods. Here, we present and analyze an exact
solution for electromagnetic wave diffraction at the linear junction between
two-dimensional electron systems (2DES) with dissimilar surface conductivities.
The field at the junction is a combination of three components with different
spatial structure: free-field component, non-resonant edge component, and
surface plasmon-polariton (SPP). We find closed-form expressions for efficiency
of photon-to-plasmon conversion by the edge being the ratio of electric fields
in SPP and incident wave. Particularly, the conversion efficiency can
considerably exceed unity for the contact between metal and 2DES with large
impedance. Our findings can be considered as a first step toward quantitative
near-field microscopy of inhomogeneous systems and polaritonic interferometry.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:49:29 GMT""}]","2021-02-24"
"2006.05201","Antoine Rondelet","Antoine Rondelet","A note on anonymous credentials using BLS signatures",,,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  In this note, we remark that the aggregation property of the BLS signature
scheme yields an efficient Content Extraction Signature (CES). This
construction can be used to build digital credentials that support selective
disclosure in various settings. Interestingly, this construction is efficient
and well suited to build credential issuance schemes with various applications
in the client-server or in the distributed ledger models. Finally, we sketch a
protocol that combines the CES with the use of a NIZK which allows to prove
predicate satisfaction on claims extracted from a credential, while keeping the
data secret.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:54:41 GMT""}]","2020-06-11"
"2006.05202","Hui-Ming Wang","Hui-Ming Wang and Xu Zhang","UAV Secure Downlink NOMA Transmissions: A Secure Users Oriented
  Perspective","15 pages, 7 figures, accepted by IEEE Transactions on Communications
  for future publication",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a secure downlink multi-user transmission scheme enabled
by a flexible unmanned aerial vehicle base station (UAV-BS) and non-orthogonal
multiple access (NOMA). According to their heterogeneous service requirements,
multiple legitimate users are categorized as security-required users (SUs) and
quality of service (QoS)-required users (QUs), while these QUs can potentially
act as internal eavesdroppers which are curious about the secrecy transmissions
of SUs. In such a context, our goal is to maximize the achievable minimum
secrecy rate among SUs through the joint optimization of user scheduling, power
allocation, and trajectory design, subject to the QoS requirements of QUs and
the mobility constraint of UAV-BS. Due to the non-convexity of the problem, an
efficient iterative algorithm is firstly proposed, based on the alternative
optimization (AO) and successive convex approximation (SCA) methods and along
with a penalty-based algorithm to deal with the introduced binary integer
variables, to obtain a sub-optimal solution. Then, we propose an SUs-oriented
low-complexity algorithm by taking advantage of the inherent characteristics of
the optimization problem, which can efficiently reduce the computational
complexity and can act as a reasonable initial solution for the previous
iterative algorithm to achieve better performance. Finally, the superiority of
our proposed scheme compared with the conventional orthogonal multiple access
(OMA) one is validated by numerical simulation results.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:58:42 GMT""}]","2020-06-11"
"2006.05203","Travis LaCroix","Travis LaCroix and Aydin Mohseni","The Tragedy of the AI Commons","40 Pages, 5 Figures",,,,"cs.CY cs.AI cs.GT cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Policy and guideline proposals for ethical artificial-intelligence research
have proliferated in recent years. These are supposed to guide the
socially-responsible development of AI for the common good. However, there
typically exist incentives for non-cooperation (i.e., non-adherence to such
policies and guidelines); and, these proposals often lack effective mechanisms
to enforce their own normative claims. The situation just described constitutes
a social dilemma; namely, a situation where no one has an individual incentive
to cooperate, though mutual cooperation would lead to the best outcome for all
involved. In this paper, we use stochastic evolutionary game dynamics to model
this social dilemma in the context of the ethical development of artificial
intelligence. This formalism allows us to isolate variables that may be
intervened upon, thus providing actionable suggestions for increased
cooperation amongst numerous stakeholders in AI. Our results show how
stochastic effects can help make cooperation viable in such a scenario. They
suggest that coordination for a common good should be attempted in smaller
groups in which the cost for cooperation is low, and the perceived risk of
failure is high. This provides insight into the conditions under which we
should expect such ethics proposals to be successful with regard to their
scope, scale, and content.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:01:01 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jan 2021 19:07:13 GMT""}]","2021-01-20"
"2006.05204","Dmitry Rokhlin B.","Dmitry B. Rokhlin","Relative utility bounds for empirically optimal portfolios","20 pages, 2 figures",,,,"q-fin.PM q-fin.ST","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a single-period portfolio selection problem for an investor,
maximizing the expected ratio of the portfolio utility and the utility of a
best asset taken in hindsight. The decision rules are based on the history of
stock returns with unknown distribution. Assuming that the utility function is
Lipschitz or H\""{o}lder continuous (the concavity is not required), we obtain
high probability utility bounds under the sole assumption that the returns are
independent and identically distributed. These bounds depend only on the
utility function, the number of assets and the number of observations. For
concave utilities similar bounds are obtained for the portfolios produced by
the exponentiated gradient method. Also we use statistical experiments to study
risk and generalization properties of empirically optimal portfolios. Herein we
consider a model with one risky asset and a dataset, containing the stock
prices from NYSE.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:03:38 GMT""}]","2020-06-11"
"2006.05205","Uri Alon","Uri Alon, Eran Yahav","On the Bottleneck of Graph Neural Networks and its Practical
  Implications","Accepted to ICLR'2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since the proposal of the graph neural network (GNN) by Gori et al. (2005)
and Scarselli et al. (2008), one of the major problems in training GNNs was
their struggle to propagate information between distant nodes in the graph. We
propose a new explanation for this problem: GNNs are susceptible to a
bottleneck when aggregating messages across a long path. This bottleneck causes
the over-squashing of exponentially growing information into fixed-size
vectors. As a result, GNNs fail to propagate messages originating from distant
nodes and perform poorly when the prediction task depends on long-range
interaction. In this paper, we highlight the inherent problem of over-squashing
in GNNs: we demonstrate that the bottleneck hinders popular GNNs from fitting
long-range signals in the training data; we further show that GNNs that absorb
incoming edges equally, such as GCN and GIN, are more susceptible to
over-squashing than GAT and GGNN; finally, we show that prior work, which
extensively tuned GNN models of long-range problems, suffers from
over-squashing, and that breaking the bottleneck improves their
state-of-the-art results without any tuning or additional weights. Our code is
available at https://github.com/tech-srl/bottleneck/ .
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:04:50 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jan 2021 14:30:23 GMT""},{""version"":""v3"",""created"":""Sat, 6 Mar 2021 20:04:10 GMT""},{""version"":""v4"",""created"":""Tue, 9 Mar 2021 11:53:06 GMT""}]","2021-03-10"
"2006.05206","Jayden Macklin-Cordes","Jayden L. Macklin-Cordes, Erich R. Round","Re-evaluating phoneme frequencies","29pp (3 figures, 3 tables). This article has been provisionally
  accepted for publication (Frontiers in Psychology, Language Sciences).
  Supplementary information, data and code available at
  http://doi.org/10.5281/zenodo.3886212",,"10.3389/fpsyg.2020.570895",,"cs.CL physics.soc-ph stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Causal processes can give rise to distinctive distributions in the linguistic
variables that they affect. Consequently, a secure understanding of a
variable's distribution can hold a key to understanding the forces that have
causally shaped it. A storied distribution in linguistics has been Zipf's law,
a kind of power law. In the wake of a major debate in the sciences around
power-law hypotheses and the unreliability of earlier methods of evaluating
them, here we re-evaluate the distributions claimed to characterize phoneme
frequencies. We infer the fit of power laws and three alternative distributions
to 166 Australian languages, using a maximum likelihood framework. We find
evidence supporting earlier results, but also nuancing them and increasing our
understanding of them. Most notably, phonemic inventories appear to have a
Zipfian-like frequency structure among their most-frequent members (though
perhaps also a lognormal structure) but a geometric (or exponential) structure
among the least-frequent. We compare these new insights the kinds of causal
processes that affect the evolution of phonemic inventories over time, and
identify a potential account for why, despite there being an important role for
phonetic substance in phonemic change, we could still expect inventories with
highly diverse phonetic content to share similar distributions of phoneme
frequencies. We conclude with priorities for future work in this promising
program of research.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:05:10 GMT""},{""version"":""v2"",""created"":""Tue, 27 Oct 2020 03:56:14 GMT""}]","2021-01-01"
"2006.05207","Engin Keles","Engin Keles, John Lee Grenfell, Mareike Godolt, Barbara Stracke, Heike
  Rauer","The effect of varying atmospheric pressure upon habitability and
  biosignatures of Earth-like planets",,"Astrobiology, Volume 18, Issue 2, 2018, pp.116-132","10.1089/ast.2016.1632",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the possible climatic conditions on rocky extrasolar planets,
and thereby their potential habitability, is one of the major subjects of
exoplanet research. Determining how the climate, as well as potential
atmospheric biosignatures, change under different conditions is a key aspect
when studying Earth-like exoplanets. One important property is the atmospheric
mass hence pressure and its influence on the climatic conditions. Therefore,
the aim of the present study is to understand the influence of atmospheric mass
on climate, hence habitability, and the spectral appearance of planets with
Earth-like, that is, N2-O2 dominated, atmospheres orbiting the Sun at 1
Astronomical Unit. This work utilizes a 1D coupled, cloud-free,
climate-photochemical atmospheric column model; varies atmospheric surface
pressure from 0.5 bar to 30 bar; and investigates temperature and key species
profiles, as well as emission and brightness temperature spectra in a range
between 2{\mu}m - 20{\mu}m. Increasing the surface pressure up to 4 bar leads
to an increase in the surface temperature due to increased greenhouse warming.
Above this point, Rayleigh scattering dominates and the surface temperature
decreases, reaching surface temperatures below 273K (approximately at ~34 bar
surface pressure). For ozone, nitrous oxide, water, methane, and carbon
dioxide, the spectral response either increases with surface temperature or
pressure depending on the species. Masking effects occur, for example, for the
bands of the biosignatures ozone and nitrous oxide by carbon dioxide, which
could be visible in low carbon dioxide atmospheres.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:05:24 GMT""}]","2020-06-11"
"2006.05208","Simone De Liberato","C. R. Gubbin and S. De Liberato","Nonlocal Response of Polar Nanostructures",,,,,"cond-mat.mes-hall physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polar dielectric nanoresonators can support hybrid photon-phonon modes termed
surface phonon polaritons with lengthscales below the diffraction limit. In the
deep sub-wavelength regime the optical response of these systems was recently
shown to diverge from that predicted through a standard dielectric description.
Recently we developed an analytical, dielectric approach and applied it to
spheres and planar heterostructures, reproducing anomalous features observed in
experiment and microscopic calculations. In this Letter we develop tools to
describe the nonlocal response of polar nanoresonators of arbitrary symmetry.
Their validity is verified by comparison to our previous analytical work,
before application to new systems. We show that nonlocal energy transfer into
matter-like modes in the dielectric diminish field enhancement in nanoscale
dimers and that strong nonlocal frequency shifts are possible in macroscopic
systems comprised of nanoscopic layers.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:08:12 GMT""}]","2020-06-11"
"2006.05209","Mark Powell","Mark Powell, Arunima Ray, and Peter Teichner","The 4-dimensional disc embedding theorem and dual spheres","32 pages, 20 figures. Version 2: Added citations to Sato, removed
  previous Section 9, and added Remark 1.5",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We modify the proof of the disc embedding theorem for 4-manifolds, which
appeared as Theorem 5.1A in the book ""Topology of 4-manifolds"" by Freedman and
Quinn, in order to construct geometrically dual spheres. These were claimed in
the statement but not constructed in the proof.
  Fundamental results in 4-manifold topology such as the existence and
exactness of the surgery sequence, the s-cobordism theorem, and thence the
classification of closed, simply connected topological 4-manifolds up to
homeomorphism, rely on a closely related sphere embedding theorem with
geometrically dual spheres, which is proven using the disc embedding theorem.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:10:02 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 13:23:00 GMT""}]","2021-06-30"
"2006.05210","Xichuan Zhou","Xichuan Zhou, Kui Liu, Cong Shi, Haijun Liu, Ji Liu","Neural Network Activation Quantization with Bitwise Information
  Bottlenecks",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent researches on information bottleneck shed new light on the continuous
attempts to open the black box of neural signal encoding. Inspired by the
problem of lossy signal compression for wireless communication, this paper
presents a Bitwise Information Bottleneck approach for quantizing and encoding
neural network activations. Based on the rate-distortion theory, the Bitwise
Information Bottleneck attempts to determine the most significant bits in
activation representation by assigning and approximating the sparse coefficient
associated with each bit. Given the constraint of a limited average code rate,
the information bottleneck minimizes the rate-distortion for optimal activation
quantization in a flexible layer-by-layer manner. Experiments over ImageNet and
other datasets show that, by minimizing the quantization rate-distortion of
each layer, the neural network with information bottlenecks achieves the
state-of-the-art accuracy with low-precision activation. Meanwhile, by reducing
the code rate, the proposed method can improve the memory and computational
efficiency by over six times compared with the deep neural network with
standard single-precision representation. Codes will be available on GitHub
when the paper is accepted \url{https://github.com/BitBottleneck/PublicCode}.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:10:04 GMT""}]","2020-06-11"
"2006.05211","Eva Vidlickova","Yoshihito Kazashi, Fabio Nobile, Eva Vidli\v{c}kov\'a","Stability properties of a projector-splitting scheme for dynamical low
  rank approximation of random parabolic equations","48 pages, 14 figures","Numerische Mathematik volume 149, pages 973--1024 (2021)","10.1007/s00211-021-01241-4",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Dynamical Low Rank (DLR) approximation of random parabolic
equations and propose a class of fully discrete numerical schemes. Similarly to
the continuous DLR approximation, our schemes are shown to satisfy a discrete
variational formulation. By exploiting this property, we establish stability of
our schemes: we show that our explicit and semi-implicit versions are
conditionally stable under a parabolic type CFL condition which does not depend
on the smallest singular value of the DLR solution; whereas our implicit scheme
is unconditionally stable. Moreover, we show that, in certain cases, the
semi-implicit scheme can be unconditionally stable if the randomness in the
system is sufficiently small. Furthermore, we show that these schemes can be
interpreted as projector-splitting integrators and are strongly related to the
scheme proposed by Lubich et al. [BIT Num. Math., 54:171-188, 2014; SIAM J. on
Num. Anal., 53:917-941, 2015], to which our stability analysis applies as well.
The analysis is supported by numerical results showing the sharpness of the
obtained stability conditions.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:12:52 GMT""},{""version"":""v2"",""created"":""Mon, 10 Aug 2020 08:32:05 GMT""},{""version"":""v3"",""created"":""Wed, 30 Sep 2020 13:49:06 GMT""},{""version"":""v4"",""created"":""Thu, 4 Nov 2021 14:56:52 GMT""}]","2022-01-25"
"2006.05212","Nicolas Pilia","Nicolas Pilia, Cristiana Corsi, Stefano Severi, Olaf D\""ossel and Axel
  Loewe","Reconstruction of Potassium Concentrations with the ECG on Imbalanced
  Datasets","Non-peer-reviewed submission to ""Workshop Biosignale 2020"" Kiel;
  2-page paper-like abstract",,,,"eess.SP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  End-stage chronic kidney disease (CKD) patients are facing a 30% rise for the
risk of lethal cardiac events (LCE) compared to non-CKD patients. At the same
time, these patients undergoing dialysis experience shifts in the potassium
concentrations. The increased risk of LCE paired with the concentration changes
suggest a connection between LCE and concentration disbalances. To prove this
link, a continuous monitoring device for the ionic concentrations, e.g. the
ECG, is needed. In this work, we want to answer if an optimised signal
processing chain can improve the result quantify the influence of a disbalanced
training dataset on the final estimation result. The study was performed on a
dataset consisting of 12-lead ECGs recorded during dialysis sessions of 32
patients. We selected three features to find a mapping from ECG features to
[K+]o: T-wave ascending slope, T-wave descending slope and T-wave amplitude. A
polynomial model of 3rd order was used to reconstruct the concentrations from
these features. We solved a regularised weighted least squares problem with a
weighting matrix dependent on the frequency of each concentration in the
dataset (frequent concentration weighted less). By doing so, we tried to
generate a model being suitable for the whole range of the concentrations.With
weighting, errors are increasing for the whole dataset. For the data partition
with [K+]o<5 mmol/l, errors are increasing, for [K+]o$\geq$5 mmol/l, errors are
decreasing. However, and apart from the exact reconstruction results, we can
conclude that a model being valid for all patients and not only the majority,
needs to be learned with a more homogeneous dataset. This can be achieved by
leaving out data points or by weighting the errors during the model fitting.
With increasing weighting, we increase the performance on the part of the [K+]o
that are less frequent which was desired in our case.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:13:41 GMT""}]","2020-06-11"
"2006.05213","Sanghyun Yoo","Sanghyun Yoo, Young-Seok Kim, Kang Hyun Lee, Kuhwan Jeong, Junhwi
  Choi, Hoshik Lee, Young Sang Choi","Graph-Aware Transformer: Is Attention All Graphs Need?",,,,,"cs.LG cs.CL stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphs are the natural data structure to represent relational and structural
information in many domains. To cover the broad range of graph-data
applications including graph classification as well as graph generation, it is
desirable to have a general and flexible model consisting of an encoder and a
decoder that can handle graph data. Although the representative encoder-decoder
model, Transformer, shows superior performance in various tasks especially of
natural language processing, it is not immediately available for graphs due to
their non-sequential characteristics. To tackle this incompatibility, we
propose GRaph-Aware Transformer (GRAT), the first Transformer-based model which
can encode and decode whole graphs in end-to-end fashion. GRAT is featured with
a self-attention mechanism adaptive to the edge information and an
auto-regressive decoding mechanism based on the two-path approach consisting of
sub-graph encoding path and node-and-edge generation path for each decoding
step. We empirically evaluated GRAT on multiple setups including encoder-based
tasks such as molecule property predictions on QM9 datasets and
encoder-decoder-based tasks such as molecule graph generation in the organic
molecule synthesis domain. GRAT has shown very promising results including
state-of-the-art performance on 4 regression tasks in QM9 benchmark.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:13:56 GMT""}]","2020-06-11"
"2006.05214","Claire Lestringant","Claire Lestringant and Basile Audoly","A one-dimensional model for elasto-capillary necking",,,"10.1098/rspa.2020.0337",,"cond-mat.soft physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive a non-linear one-dimensional (1d) strain gradient model predicting
the necking of soft elastic cylinders driven by surface tension, starting from
3d finite-strain elasticity. It is asymptotically correct: the microscopic
displacement is identified by an energy method. The 1d model can predict the
bifurcations occurring in the solutions of the 3d elasticity problem when the
surface tension is increased, leading to a localization phenomenon akin to
phase separation. Comparisons with finite-element simulations reveal that the
1d model resolves the interface separating two phases accurately, including
well into the localized regime, and that it has a vastly larger domain of
validity than 1d model proposed so far.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:14:06 GMT""}]","2021-03-17"
"2006.05215","Ramesh Koirala","IceCube Collaboration","Cosmic Ray Spectrum from 250 TeV to 10 PeV using IceTop","21 pages, 17 captioned figures, 8 tables","Phys.Rev.D 102 (2020) 12, 122001","10.1103/PhysRevD.102.122001",,"astro-ph.HE hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report here an extension of the measurement of the all-particle cosmic-ray
spectrum with IceTop to lower energy. The new measurement gives full coverage
of the knee region of the spectrum and reduces the gap in energy between
previous IceTop and direct measurements. With a new trigger that selects events
in closely spaced detectors in the center of the array, the IceTop energy
threshold is lowered by almost an order of magnitude below its previous
threshold of 2 PeV. In this paper, we explain how the new trigger is
implemented, and we describe the new machine-learning method developed to deal
with events with very few detectors hit. We compare the results with previous
measurements by IceTop and others that overlap at higher energy and with HAWC
and Tibet in the 100 TeV range.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:15:52 GMT""}]","2020-12-15"
"2006.05216","Yassir Dinar I","Yassir Dinar and Zainab Al-Maamari","Dicyclic groups and Frobenius manifolds",,,,,"math.DG math-ph math.AC math.AG math.MP math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The orbits space of an irreducible representation of a finite group is a
variety whose coordinate ring is finitely generated by homogeneous invariant
polynomials. Boris Dubrovin showed that the orbits spaces of the reflection
groups acquire the structure of polynomial Frobenius manifolds. Dubrovin's
method to construct examples of Frobenius manifolds on orbits spaces was
carried for other linear representations of discrete groups which have in
common that the coordinate rings of the the orbits spaces are polynomial rings.
In this article, we show that the orbits space of an irreducible representation
of a Dicyclic group acquire two structures of Frobenius manifolds. The
coordinate ring of this orbits space is not a polynomial ring.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:25:15 GMT""},{""version"":""v2"",""created"":""Wed, 5 Aug 2020 09:00:00 GMT""}]","2020-08-06"
"2006.05217","Jun Xu","Jun Xu, Jia Zhou, Zhen Zhang, Wen-Jie Xie, and Bao-An Li","Constraining isovector nuclear interactions with giant resonances within
  a Bayesian approach","5 pages, 5 figures","Phys. Lett. B 810, 135820 (2020)","10.1016/j.physletb.2020.135820",,"nucl-th nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We put a stringent constraint on the isovector nuclear interactions in the
Skyrme-Hartree-Fock model from the centroid energy $E_{-1}$ of the isovector
giant dipole resonance in $^{208}$Pb as well as its electric polarizability
$\alpha_D$. Using the Bayesian analysis method, $E_{-1}$ and $\alpha_D$ are
found to be mostly determined by the nuclear symmetry energy $E_{sym}$ at about
$\rho^\star=0.05$ fm$^{-3}$ and the isovector nucleon effective mass
$m_v^\star$ at the saturation density. At $90\%$ confidence level, we obtain
$E_{sym}(\rho^\star) = 16.4 ^{+1.0}_{-0.9}$ MeV and $m_v^\star/m = 0.79
^{+0.06}_{-0.06}$.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:26:46 GMT""},{""version"":""v2"",""created"":""Fri, 25 Sep 2020 08:30:26 GMT""}]","2020-10-07"
"2006.05218","Ioannis Gatopoulos","Ioannis Gatopoulos, Maarten Stol, Jakub M. Tomczak","Super-resolution Variational Auto-Encoders","13 pages, 11 figures, 3 tables. Code available at:
  https://github.com/ioangatop/srVAE",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The framework of variational autoencoders (VAEs) provides a principled method
for jointly learning latent-variable models and corresponding inference models.
However, the main drawback of this approach is the blurriness of the generated
images. Some studies link this effect to the objective function, namely, the
(negative) log-likelihood. Here, we propose to enhance VAEs by adding a random
variable that is a downscaled version of the original image and still use the
log-likelihood function as the learning objective. Further, by providing the
downscaled image as an input to the decoder, it can be used in a manner similar
to the super-resolution. We present empirically that the proposed approach
performs comparably to VAEs in terms of the negative log-likelihood, but it
obtains a better FID score in data synthesis.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:32:16 GMT""},{""version"":""v2"",""created"":""Tue, 30 Jun 2020 13:06:43 GMT""}]","2020-07-01"
"2006.05219","Amir Ahooye Atashin","Majid Mohammadi, Amir Ahooye Atashin, Wout Hofman, Yao-Hua Tan","SANOM Results for OAEI 2019",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simulated annealing-based ontology matching (SANOM) participates for the
second time at the ontology alignment evaluation initiative (OAEI) 2019. This
paper contains the configuration of SANOM and its results on the anatomy and
conference tracks. In comparison to the OAEI 2017, SANOM has improved
significantly, and its results are competitive with the state-of-the-art
systems. In particular, SANOM has the highest recall rate among the
participated systems in the conference track, and is competitive with AML, the
best performing system, in terms of F-measure. SANOM is also competitive with
LogMap on the anatomy track, which is the best performing system in this track
with no usage of particular biomedical background knowledge. SANOM has been
adapted to the HOBBIT platfrom and is now available for the registered users.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:33:47 GMT""}]","2020-06-11"
"2006.05220","Xiaolin Zhang","Xiaolin Zhang, Yunchao Wei, Yi Yang, Fei Wu","Rethinking Localization Map: Towards Accurate Object Perception with
  Self-Enhancement Maps",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, remarkable progress has been made in weakly supervised object
localization (WSOL) to promote object localization maps. The common practice of
evaluating these maps applies an indirect and coarse way, i.e., obtaining tight
bounding boxes which can cover high-activation regions and calculating
intersection-over-union (IoU) scores between the predicted and ground-truth
boxes. This measurement can evaluate the ability of localization maps to some
extent, but we argue that the maps should be measured directly and delicately,
i.e., comparing the maps with the ground-truth object masks pixel-wisely. To
fulfill the direct evaluation, we annotate pixel-level object masks on the
ILSVRC validation set. We propose to use IoU-Threshold curves for evaluating
the real quality of localization maps. Beyond the amended evaluation metric and
annotated object masks, this work also introduces a novel self-enhancement
method to harvest accurate object localization maps and object boundaries with
only category labels as supervision. We propose a two-stage approach to
generate the localization maps by simply comparing the similarity of point-wise
features between the high-activation and the rest pixels. Based on the
predicted localization maps, we explore to estimate object boundaries on a very
large dataset. A hard-negative suppression loss is proposed for obtaining fine
boundaries. We conduct extensive experiments on the ILSVRC and CUB benchmarks.
In particular, the proposed Self-Enhancement Maps achieve the state-of-the-art
localization accuracy of 54.88% on ILSVRC. The code and the annotated masks are
released at https://github.com/xiaomengyc/SEM.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:35:55 GMT""},{""version"":""v2"",""created"":""Sat, 13 Jun 2020 04:13:23 GMT""}]","2020-06-16"
"2006.05221","Minoru Yamashita Dr.","Minoru Yamashita, Shiori Sugiura, Akira Ueda, Shun Dekura, Taichi
  Terashima, Shinya Uji, Yoshiya Sunairi, Hatsumi Mori, Elena I. Zhilyaeva,
  Svetlana A. Torunova, Rimma N. Lyubovskaya, Natalia Drichko, and Chisa Hotta","Ferromagnetism out of charge fluctuation of strongly correlated
  electrons in $\kappa$-(BEDT-TTF)$_2$Hg(SCN)$_2$Br","9 pages, 5 figures, Supplementary Material attached","npj Quantum Materials volume 6, 87 (2021)","10.1038/s41535-021-00387-6",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform magnetic susceptibility and magnetic torque measurements on the
organic $\kappa$-(BEDT-TTF)$_2$Hg(SCN)$_2$Br, which is recently suggested to
host an exotic quantum dipole-liquid in its low-temperature insulating phase.
Below the metal-insulator transition temperature, the magnetic susceptibility
follows a Curie-Weiss law with a positive Curie-Weiss temperature, and a
particular $M\propto \sqrt{H}$ curve is observed. The emergent
ferromagnetically interacting spins amount to about 1/6 of the full spin moment
of localized charges. Taking account of the possible inhomogeneous
quasi-charge-order that forms a dipole-liquid, we construct a model of
antiferromagnetically interacting spin chains in two adjacent charge-ordered
domains, which are coupled via fluctuating charges on a Mott-dimer at the
boundary. We find that the charge fluctuations can draw a weak ferromagnetic
moment out of the spin singlet domains.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:40:52 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 00:27:02 GMT""}]","2021-10-11"
"2006.05222","Peter Lundqvist","P. Lundqvist, N. Lundqvist, C. Vlahakis, C.-I. Bj\""ornsson, J. R.
  Dickel, M. Matsuura, Yu. A. Shibanov, D. A. Zyuzin, G. Olofsson","Atacama Compact Array Observations of the Pulsar-Wind Nebula of SNR
  0540-69.3","MNRAS, accepted",,"10.1093/mnras/staa1675",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present observations of the pulsar-wind nebula (PWN) region ofSNR
0540-69.3. The observations were made with the Atacama Compact Array (ACA) in
Bands 4 and 6. We also add radio observations from the Australia Compact Array
(ATCA) at 3 cm. For 1.449 - 233.50 GHz we obtain a synchrotron spectrum
$F_{\nu} \propto \nu^{-\alpha_{\nu}}$, with the spectral index $\alpha_{\nu} =
0.17\pm{0.02}$. To conclude how this joins the synchrotron spectrum at higher
frequencies we include hitherto unpublished AKARI mid-infrared data, and
evaluate published data in the ultraviolet (UV), optical and infrared (IR). In
particular, some broad-band filter data in the optical must be discarded from
our analysis due to contamination by spectral line emission. For the UV/IR part
of the synchrotron spectrum, we arrive at $\alpha_{\nu} =
0.87^{+0.08}_{-0.10}$. There is room for $2.5\times10^{-3}$ solar masses of
dust with temperature $\sim 55$ K if there are dual breaks in the synchrotron
spectrum, one around $\sim 9\times10^{10}$ Hz, and another at $\sim
2\times10^{13}$ Hz. The spectral index then changes at $\sim 9\times10^{10}$ Hz
from $\alpha_{\nu} = 0.14\pm0.07$ in the radio, to $\alpha_{\nu} =
0.35^{-0.07}_{+0.05}$ in the millimetre to far-IR range. The ACA Band 6 data
marginally resolves the PWN. In particular, the strong emission 1.5"" south-west
of the pulsar, seen at other wavelengths, and resolved in the 3-cm data with
its 0.8"" spatial resolution, is also strong in the millimeter range. The ACA
data clearly reveal the supernova remnant shell 20-35 arcsec west of the
pulsar, and for the shell we derive $\alpha_{\nu} = 0.64\pm{0.05}$ for the
range $8.6-145$~GHz.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:48:08 GMT""}]","2020-06-24"
"2006.05223","Andrei Chelpanov","Andrei Chelpanov and Nikolai Kobanov","Multilevel Observations of the Oscillations in the First Active Region
  of the New Cycle",,,"10.1007/s11207-020-01664-6",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the first time, a multi-wave research of oscillation dynamics in a solar
facula from its birth to decay was carried out. We performed spectral
observations of active region NOAA 12744 at Horizontal Solar Telescope of the
Sayan Solar Observatory in the H$\alpha$, He I 10830 A, and Si I 10827 A lines.
We used Solar Dynamics Observatory (SDO) line-of-sight magnetic field data and
the 1600 A, 304 A, and 171 A UV channels. At the early stages of the facula
evolution, we observed low-frequency (1-2 mHz) oscillations concentrate in the
central part of the facula. In the lower solar atmosphere, this is registered
in the intensity, line-of-sight velocity, and magnetic field signals. These
frequencies were also observed in the transition region and corona (304 A and
171 A channels). At the maximal development phase of the facula evolution, the
low frequency oscillations closely reproduce the coronal loop structures
forming above the active region. At the decay phase, the spatial distributions
of the observed frequencies resemble those found in and above the undisturbed
chromosphere network. Our results indicate a direct relation of the low
frequency oscillations observed in the lower solar atmosphere with the
oscillations in the coronal loops, which is probably implemented through the
loop footpoints.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:52:21 GMT""}]","2020-08-26"
"2006.05224","Toon Verstraelen","Ruben Goeminne, Toon Verstraelen","Accurate transferable polarization model derived from the monomer
  electron density","Minor improvements after feedback at the TSRC meeting ""Many-Body
  Interactions: From Quantum Mechanics to Force Fields""
  (https://www.telluridescience.org/meetings/workshop-details?wid=800):
  formatting improvements and improved terminology in figure 3",,,,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Force field have for decades proven to be an indispensable tool for molecular
simulations which are out of reach for ab-initio methods. Recent efforts to
improve the accuracy of these simulations have focused on the inclusion of
many-body interactions in force fields. In this regard, we propose a
transferable inducible dipole model which requires only the monomer electron
density as input, without the need for atom type specific parameters. Slater
dipoles are introduced, the widths of which are derived from the ab-initio
monomer density. An additional exchange-repulsion interaction is introduced in
our model, originating from the overlap of the delocalized dipoles with other
dipoles and the ground state electron density. This interaction has previously
been neglected in point dipole models, as the lack of spatial extent of the
dipoles prevents the inclusion of an overlap term. The inclusion of this
interaction is shown to significantly improve the prediction of three-body
energies. Our model is incorporated in a previously proposed non-covalent force
field and is benchmarked on interaction energies of dimers contained in the hsg
and hbc6 datasets. Furthermore, we demonstrate the transferability of our model
to the condensed phase of water, and to the interaction of CO$_2$ and H$_2$O
molecules with the ZIF-8 metal-organic framework. The inherent transferability
of our model makes it widely applicable to systems like the aforementioned
metal-organic frameworks, where no specifically fitted parameters for
polarization models are available in the literature.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:53:43 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 09:45:17 GMT""}]","2020-06-26"
"2006.05225","Andreas H\""oring","Andreas H\""oring, Thomas Peternell","A Nonvanishing Conjecture for Cotangent Bundles","30 pages",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the positivity of the cotangent bundle of projective
manifolds. We conjecture that the cotangent bundle is pseudoeffective if and
only the manifold has non-zero symmetric differentials. We confirm this
conjecture for most projective surfaces that are not of general type.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:56:17 GMT""}]","2020-06-11"
"2006.05226","Henrik Koch","Sarai D. Folkestad, Eirik F. Kj{\o}nstad, Linda Goletto, and Henrik
  Koch","Multilevel CC2 and CCSD in reduced orbital spaces: electronic
  excitations in large molecular systems","42 pages, 9 figures",,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present efficient implementations of the multilevel CC2 (MLCC2) and
multilevel CCSD (MLCCSD) models. As the system size increases, MLCC2 and MLCCSD
exhibit the scaling of the lower level coupled cluster model. In order to treat
large systems, we combine MLCC2 and MLCCSD with a reduced orbital space
approach where the multilevel coupled cluster calculation is performed in a
significantly truncated molecular orbital basis. The truncation scheme is based
on the selection of an active region of the molecular system and the subsequent
construction of localized Hartree-Fock orbitals. These orbitals are used in the
multilevel coupled cluster calculation. The electron repulsion integrals are
Cholesky decomposed using a screening protocol that guarantees accuracy in the
truncated molecular orbital basis. The Cholesky factors are constructed
directly in the truncated basis, ensuring low storage requirements. Even larger
systems can be treated by using a multilevel Hartree-Fock reference. With the
reduced space approach, we can handle systems with more than a thousand atoms.
This is demonstrated for paranitroaniline in aqueous solution.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:56:55 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jul 2020 10:40:53 GMT""},{""version"":""v3"",""created"":""Tue, 24 Nov 2020 16:46:09 GMT""}]","2020-11-25"
"2006.05227","Huy The Nguyen","Stephen Lynch and Huy The Nguyen","Convexity Estimates for High Codimension Mean Curvature Flow",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the evolution by mean curvature of smooth $n$-dimensional
submanifolds in $\mathbb{R}^{n+k}$ which are compact and quadratically pinched.
We will be primarily interested in flows of high codimension, the case $k\geq
2$. We prove that our submanifold is asymptotically convex, that is the first
eigenvalue of the second fundamental form in the principal mean curvature
direction blows up at a strictly slower rate than the mean curvature vector. We
use this convexity estimate to show that at a singular time of the flow, there
exists a rescaling that converges to a smooth codimension-one limiting flow
which is convex and moves by translation.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:58:59 GMT""}]","2020-06-11"
"2006.05228","Antoine Maillard","Antoine Maillard, Bruno Loureiro, Florent Krzakala, Lenka Zdeborov\'a","Phase retrieval in high dimensions: Statistical and computational phase
  transitions","12 pages (main text and references), 26 pages of supplementary
  material. v2 matches the final version accepted at NeurIPS 2021","Advances in Neural Information Processing Systems, v33, pages
  11071--11082, 2020",,,"math.ST cond-mat.dis-nn cs.IT cs.LG math.IT math.PR stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the phase retrieval problem of reconstructing a $n$-dimensional
real or complex signal $\mathbf{X}^{\star}$ from $m$ (possibly noisy)
observations $Y_\mu = | \sum_{i=1}^n \Phi_{\mu i} X^{\star}_i/\sqrt{n}|$, for a
large class of correlated real and complex random sensing matrices
$\mathbf{\Phi}$, in a high-dimensional setting where $m,n\to\infty$ while
$\alpha = m/n=\Theta(1)$. First, we derive sharp asymptotics for the lowest
possible estimation error achievable statistically and we unveil the existence
of sharp phase transitions for the weak- and full-recovery thresholds as a
function of the singular values of the matrix $\mathbf{\Phi}$. This is achieved
by providing a rigorous proof of a result first obtained by the replica method
from statistical mechanics. In particular, the information-theoretic transition
to perfect recovery for full-rank matrices appears at $\alpha=1$ (real case)
and $\alpha=2$ (complex case). Secondly, we analyze the performance of the
best-known polynomial time algorithm for this problem -- approximate
message-passing -- establishing the existence of a statistical-to-algorithmic
gap depending, again, on the spectral properties of $\mathbf{\Phi}$. Our work
provides an extensive classification of the statistical and algorithmic
thresholds in high-dimensional phase retrieval for a broad class of random
matrices.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:03:29 GMT""},{""version"":""v2"",""created"":""Fri, 23 Oct 2020 15:27:51 GMT""}]","2021-02-18"
"2006.05229","Dong-Po Song","Xi Chen, Xiao Yang, DongPo Song and Yuesheng Li","Organized Self-Emulsification toward Structural Color","5 pages, 4 figures",,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The formation of water-in-oil-in-water (W/O/W) double emulsions can be
well-controlled through an organized self-emulsification mechanism in the
presence of rigid bottlebrush amphiphilic block copolymers. Nanoscale water
droplets with well-controlled diameters form ordered spatial arrangements
within the micron-scale oil droplets. Upon solvent evaporation, solid
microspheres with hexagonal close packed nanopore arrays are obtained resulting
in bright structural colors. The reflected color is precisely tunable across
the whole visible light range through tailoring contour length of the
bottlebrush molecule. In-situ observation of the W/O interface using confocal
laser scanning microscopy provides insights into the mechanism of the organized
self-emulsification. This work provides a powerful strategy for the fabrication
of structural colored materials in an easy and scalable manner.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:03:53 GMT""}]","2020-06-11"
"2006.05230","Gianni Jacucci","Gianni Jacucci, Silvia Vignolini, Lukas Schertel","Colors from correlated disordered photonic systems -- can we outperform
  nature?",,"PNAS September 22, 2020 117 (38) 23345-23349","10.1073/pnas.2010486117",,"physics.optics physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Living organisms have developed a wide range of appearances from iridescent
to matt textures. Interestingly, angular independent structural colors, where
isotropy in the scattering structure is present, only produce coloration in the
blue wavelength region of the visible spectrum. One might, therefore, wonder if
such observation is a limitation of the architecture of the palette of
materials available in nature. Here, by exploiting numerical modeling, we
discuss the origin of isotropic structural colors without restriction to a
specific light scattering regime. We show that high color purity and color
saturation cannot be reached in isotropic short-range order structures for red
hues. This conclusion holds even in the case of advanced scatterer
morphologies, such as core-shell particles or inverse photonic glasses -
explaining recent experimental findings reporting very poor performances of
visual appearance for such systems.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:04:14 GMT""}]","2020-10-13"
"2006.05231","P\'eter N\'andori","Margaret Brown and P\'eter N\'andori","Statistical properties of type D dispersing billiards",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider dispersing billiard tables whose boundary is piecewise smooth and
the free flight function is unbounded. We also assume there are no cusps. Such
billiard tables are called type D in the monograph of Chernov and Markarian.
For a class of non-degenerate type D dispersing billiards, we prove exponential
decay of correlation and several other statistical properties.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:07:09 GMT""}]","2020-06-11"
"2006.05232","Edward Laurence","Edward Laurence, Charles Murphy, Guillaume St-Onge, Xavier
  Roy-Pomerleau, and Vincent Thibeault","Detecting structural perturbations from time series with deep learning","Main paper:10 pages, 5 figures | Supplementary material: 8 pages, 2
  figures, 2 tables",,,,"physics.soc-ph cs.LG stat.AP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Small disturbances can trigger functional breakdowns in complex systems. A
challenging task is to infer the structural cause of a disturbance in a
networked system, soon enough to prevent a catastrophe. We present a graph
neural network approach, borrowed from the deep learning paradigm, to infer
structural perturbations from functional time series. We show our data-driven
approach outperforms typical reconstruction methods while meeting the accuracy
of Bayesian inference. We validate the versatility and performance of our
approach with epidemic spreading, population dynamics, and neural dynamics, on
various network structures: random networks, scale-free networks, 25 real
food-web systems, and the C. Elegans connectome. Moreover, we report that our
approach is robust to data corruption. This work uncovers a practical avenue to
study the resilience of real-world complex systems.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:08:40 GMT""}]","2020-06-11"
"2006.05233","Muhammed Shifas Pv","Muhammed PV Shifas, Santelli Claudio, Vassilis Tsiaras, Yannis
  Stylianou","A fully recurrent feature extraction for single channel speech
  enhancement","5 pages",,,,"eess.AS cs.SD","http://creativecommons.org/licenses/by-sa/4.0/","  Convolutional neural network (CNN) modules are widely being used to build
high-end speech enhancement neural models. However, the feature extraction
power of vanilla CNN modules has been limited by the dimensionality constraint
of the convolution kernels that are integrated - thereby, they have limitations
to adequately model the noise context information at the feature extraction
stage. To this end, adding recurrency factor into the feature extracting CNN
layers, we introduce a robust context-aware feature extraction strategy for
single-channel speech enhancement. As shown, adding recurrency results in
capturing the local statistics of noise attributes at the extracted features
level and thus, the suggested model is effective in differentiating speech cues
even at very noisy conditions. When evaluated against enhancement models using
vanilla CNN modules, in unseen noise conditions, the suggested model with
recurrency in the feature extraction layers has produced a segmental SNR (SSNR)
gain of up to 1.5 dB, an improvement of 0.4 in subjective quality in the Mean
Opinion Score scale, while the parameters to be optimized are reduced by 25%.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:11:04 GMT""},{""version"":""v2"",""created"":""Mon, 3 Aug 2020 08:51:39 GMT""},{""version"":""v3"",""created"":""Thu, 6 Aug 2020 07:50:31 GMT""},{""version"":""v4"",""created"":""Mon, 10 Aug 2020 13:44:53 GMT""},{""version"":""v5"",""created"":""Sun, 30 Aug 2020 17:22:40 GMT""},{""version"":""v6"",""created"":""Tue, 15 Dec 2020 07:13:26 GMT""},{""version"":""v7"",""created"":""Thu, 3 Jun 2021 15:16:28 GMT""}]","2021-06-07"
"2006.05234","David Towers","David A. Towers and Zekiye Ciloglu","Weak c-ideals of Lie algebras","arXiv admin note: substantial text overlap with arXiv:0811.2689",,,,"math.RA math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A subalgebra B of a Lie algebra L is called a weak c-ideal of L if there is a
subideal C of L such that L = B+C and B\cap C \subseteq B_L where B_L is the
largest ideal of L contained in B. This is analogous to the concept of weakly
c- normal subgroups, which has been studied by a number of authors. We obtain
some properties of weak c-ideals and use them to give some characterisations of
solvable and supersolvable Lie algebras. We also note that one-dimensional weak
c-ideals are c-ideals.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:11:30 GMT""}]","2020-06-11"
"2006.05235","David Mu\~noz-Rojas","Cesar Arturo Masse de la Huerta, Viet H. Nguyen, Abderrahime Sekkat,
  Chiara Crivello, Fidel Toldra-Reig, Pedro Veiga, Carmen Jimenez, Serge
  Quessada, David Mu\~noz-Rojas","Facile patterning of functional materials via gas-phase 3D printing","20 pages, 4 figures",,,,"cond-mat.mtrl-sci physics.app-ph physics.ins-det","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Spatial Atomic Layer Deposition (SALD) is a recent approach that is up to two
orders of magnitude faster than conventional ALD, and that can be performed at
atmospheric pressure and even in the open air. Previous works have exploited
these assets to focus on the possibility of high-rate, large-area deposition
for scaling up into mass production. Conversely, here we show that SALD indeed
represents an ideal platform for the selective deposition of functional
materials by proper design and miniaturization of SALD close-proximity heads.
In particular, we have used the potential offered by 3D printing to fabricate
custom close-proximity SALD injection heads. By using 3D printing, the heads
can be easily designed and readily modified to obtain different deposition
areas, free-form patterns, and even complex multimaterial structures. The heads
can be printed in different materials to adjust to the chemistry of the
precursors and the deposition conditions used. Polymeric heads can be used as
cheap (even disposable) heads that are both used for performing deposition and
for prototyping and optimization purposes. Finally, by designing a miniaturized
head with circular concentric gas channels, 3D printing of functional materials
can be performed with nanometric resolution in Z. This constitutes a new 3D
printing approach based on gaseous precursors. Because the selective deposition
strategies presented here are based on the SALD process, conformal and
continuous thin films of functional materials can be printed at low
temperatures and with high deposition rate in the open air. Our approach
represents a new versatile way of printing functional materials and devices
with spatial and topological control, thus extending the potential of SALD and
ALD in general, and opening a new avenue in the field of area-selective
deposition of functional materials.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:11:34 GMT""}]","2020-06-11"
"2006.05236","Manraj Singh Grover","Manraj Singh Grover, Pakhi Bamdev, Ratin Kumar Brala, Yaman Kumar,
  Mika Hama, Rajiv Ratn Shah","audino: A Modern Annotation Tool for Audio and Speech",,,,,"cs.SD cs.CL eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a collaborative and modern annotation tool for
audio and speech: audino. The tool allows annotators to define and describe
temporal segmentation in audios. These segments can be labelled and transcribed
easily using a dynamically generated form. An admin can centrally control user
roles and project assignment through the admin dashboard. The dashboard also
enables describing labels and their values. The annotations can easily be
exported in JSON format for further analysis. The tool allows audio data and
their corresponding annotations to be uploaded and assigned to a user through a
key-based API. The flexibility available in the annotation tool enables
annotation for Speech Scoring, Voice Activity Detection (VAD), Speaker
Diarisation, Speaker Identification, Speech Recognition, Emotion Recognition
tasks and more. The MIT open source license allows it to be used for academic
and commercial projects.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:12:44 GMT""},{""version"":""v2"",""created"":""Sun, 28 Nov 2021 09:02:34 GMT""}]","2021-11-30"
"2006.05237","Viktor Abramov","Viktor Abramov","Ternary algebras associated with irreducible tensor representations of
  SO(3) and quark model",,,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that each irreducible tensor representation of weight 2 of the
rotation group of three-dimensional space in the space of rank 3 covariant
tensors gives rise to an associative algebra with unity. We find the algebraic
relations that the generators of these algebras must satisfy. Part of these
relations has a form of binary relations and another part has a form of ternary
relations. The structure of ternary relations is based on the cyclic group Z_3
and the primitive cubic root of unity q=\exp(2\pi i/3). The subspace of each
algebra spanned by the triple products of generators is 5-dimensional and it is
the space of an irreducible tensor representation of weight 2 of the rotation
group SO(3). We define a Hermitian scalar product in this 5-dimensional
subspace and construct an orthonormal basis for it. Then we find the
representation matrix of an infinitesimal rotation. We show that constructed
algebras with binary and ternary relations can have applications in the quark
model and Grand Unification Theories.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:14:17 GMT""}]","2020-06-11"
"2006.05238","Saehyun Ahn","Saehyun Ahn, Jung-Woo Chang, and Suk-Ju Kang","An Efficient Accelerator Design Methodology for Deformable Convolutional
  Networks","IEEE International Conference on Image Processing (ICIP) 2020",,,,"cs.DC cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deformable convolutional networks have demonstrated outstanding performance
in object recognition tasks with an effective feature extraction. Unlike
standard convolution, the deformable convolution decides the receptive field
size using dynamically generated offsets, which leads to an irregular memory
access. Especially, the memory access pattern varies both spatially and
temporally, making static optimization ineffective. Thus, a naive
implementation would lead to an excessive memory footprint. In this paper, we
present a novel approach to accelerate deformable convolution on FPGA. First,
we propose a novel training method to reduce the size of the receptive field in
the deformable convolutional layer without compromising accuracy. By optimizing
the receptive field, we can compress the maximum size of the receptive field by
12.6 times. Second, we propose an efficient systolic architecture to maximize
its efficiency. We then implement our design on FPGA to support the optimized
dataflow. Experimental results show that our accelerator achieves up to 17.25
times speedup over the state-of-the-art accelerator.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:16:44 GMT""},{""version"":""v2"",""created"":""Sat, 13 Jun 2020 10:40:25 GMT""}]","2020-06-16"
"2006.05239","Vincent Kurtz","Yann Gilpin, Vince Kurtz, and Hai Lin","A Smooth Robustness Measure of Signal Temporal Logic for Symbolic
  Control","Accepted to L-CSS",,,,"eess.SY cs.RO cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent years have seen an increasing use of Signal Temporal Logic (STL) as a
formal specification language for symbolic control, due to its expressiveness
and closeness to natural language. Furthermore, STL specifications can be
encoded as cost functions using STL's robust semantics, transforming the
synthesis problem into an optimization problem. Unfortunately, these cost
functions are non-smooth and non-convex, and exact solutions using
mixed-integer programming do not scale well. Recent work has focused on using
smooth approximations of robustness, which enable faster gradient-based methods
to find local maxima, at the expense of soundness and/or completeness. We
propose a novel robustness approximation that is smooth everywhere, sound, and
asymptotically complete. Our approach combines the benefits of existing
approximations, while enabling an explicit tradeoff between conservativeness
and completeness.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:21:35 GMT""}]","2020-06-11"
"2006.05240","Pierre Laforgue","Pierre Laforgue, Guillaume Staerman, Stephan Cl\'emen\c{c}on","Generalization Bounds in the Presence of Outliers: a Median-of-Means
  Study",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In contrast to the empirical mean, the Median-of-Means (MoM) is an estimator
of the mean $\theta$ of a square integrable r.v. $Z$, around which accurate
nonasymptotic confidence bounds can be built, even when $Z$ does not exhibit a
sub-Gaussian tail behavior. Thanks to the high confidence it achieves on
heavy-tailed data, MoM has found various applications in machine learning,
where it is used to design training procedures that are not sensitive to
atypical observations. More recently, a new line of work is now trying to
characterize and leverage MoM's ability to deal with corrupted data. In this
context, the present work proposes a general study of MoM's concentration
properties under the contamination regime, that provides a clear understanding
of the impact of the outlier proportion and the number of blocks chosen. The
analysis is extended to (multisample) $U$-statistics, i.e. averages over tuples
of observations, that raise additional challenges due to the dependence
induced. Finally, we show that the latter bounds can be used in a
straightforward fashion to derive generalization guarantees for pairwise
learning in a contaminated setting, and propose an algorithm to compute
provably reliable decision functions.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:21:39 GMT""},{""version"":""v2"",""created"":""Sun, 7 Feb 2021 10:58:29 GMT""}]","2021-02-09"
"2006.05242","W{\l}odzimierz Piechocki","W{\l}odzimierz Piechocki","Generic singularity of general relativity and its quantum fate","9 pages, no figures, extended version of essay",,,,"gr-qc hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Belinski-Khalatnikov-Lifshitz scenario concerns the existence of generic
singularity of general relativity. At the singularity, there is a breakdown of
all known laws of physics. Quantization of this scenario leads, however, to
regular quantum evolution. The singularity is avoided by a quantum bounce. It
is fairly probable that quantum general relativity, to be constructed, would be
free from singularities. Thus, it could be used to address issues such as the
quantum fates of cosmological and black holes singularities.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:27:59 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jul 2020 04:27:12 GMT""}]","2020-07-20"
"2006.05244","Mantong Zhou","Mantong Zhou, Zhouxing Shi, Minlie Huang, Xiaoyan Zhu","Knowledge-Aided Open-Domain Question Answering",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Open-domain question answering (QA) aims to find the answer to a question
from a large collection of documents.Though many models for single-document
machine comprehension have achieved strong performance, there is still much
room for improving open-domain QA systems since document retrieval and answer
reranking are still unsatisfactory. Golden documents that contain the correct
answers may not be correctly scored by the retrieval component, and the correct
answers that have been extracted may be wrongly ranked after other candidate
answers by the reranking component. One of the reasons is derived from the
independent principle in which each candidate document (or answer) is scored
independently without considering its relationship to other documents (or
answers). In this work, we propose a knowledge-aided open-domain QA (KAQA)
method which targets at improving relevant document retrieval and candidate
answer reranking by considering the relationship between a question and the
documents (termed as question-document graph), and the relationship between
candidate documents (termed as document-document graph). The graphs are built
using knowledge triples from external knowledge resources. During document
retrieval, a candidate document is scored by considering its relationship to
the question and other documents. During answer reranking, a candidate answer
is reranked using not only its own context but also the clues from other
documents. The experimental results show that our proposed method improves
document retrieval and answer reranking, and thereby enhances the overall
performance of open-domain question answering.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:28:57 GMT""}]","2020-06-11"
"2006.05245","Delong Chen","Delong Chen, Shunhui Ji, Fan Liu, Zewen Li, Xinyu Zhou","A Review of Automated Diagnosis of COVID-19 Based on Scanning Images","In ICRAI 2020: 2020 6th International Conference on Robotics and
  Artificial Intelligence",,"10.1145/3449301.3449778",,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  The pandemic of COVID-19 has caused millions of infections, which has led to
a great loss all over the world, socially and economically. Due to the
false-negative rate and the time-consuming of the conventional Reverse
Transcription Polymerase Chain Reaction (RT-PCR) tests, diagnosing based on
X-ray images and Computed Tomography (CT) images has been widely adopted.
Therefore, researchers of the computer vision area have developed many
automatic diagnosing models based on machine learning or deep learning to
assist the radiologists and improve the diagnosing accuracy. In this paper, we
present a review of these recently emerging automatic diagnosing models. 70
models proposed from February 14, 2020, to July 21, 2020, are involved. We
analyzed the models from the perspective of preprocessing, feature extraction,
classification, and evaluation. Based on the limitation of existing models, we
pointed out that domain adaption in transfer learning and interpretability
promotion would be the possible future directions.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:29:15 GMT""},{""version"":""v2"",""created"":""Sun, 26 Jul 2020 02:20:19 GMT""},{""version"":""v3"",""created"":""Sat, 24 Jul 2021 05:18:17 GMT""}]","2021-07-27"
"2006.05246","Sergey Zelik V.","Anna Kostianko, Chunyou Sun and Sergey Zelik","Reaction-diffusion systems with supercritical nonlinearities revisited",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a comprehensive study of the analytic properties and long-time
behavior of solutions of a reaction-diffusion system in a bounded domain in the
case where the nonlinearity satisfies the standard monotonicity assumption. We
pay the main attention to the supercritical case, where the nonlinearity is not
subordinated to the linear part of the equation trying to put as small as
possible amount of extra restrictions on this nonlinearity. The properties of
such systems in the supercritical case may be very different in comparison with
the standard case of subordinated nonlinearities. We examine the global
existence and uniqueness of weak and strong solutions, various types of
smoothing properties, asymptotic compactness and the existence of global and
exponential attractors.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:30:11 GMT""}]","2020-06-11"
"2006.05247","J.P.W. Diener","J.P.W. Diener, F.G. Scholtz","The spin-polarized ferromagnetic state of a cold Fermi gas","22 Pages, 7 Figures","Phys. Rev. C 102, 055805 (2020)","10.1103/PhysRevC.102.055805",,"nucl-th astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spin-polarized ferromagnetic state of a cold Fermi gas is investigated
for interacting and non-interacting charge-neutral and $\beta$-equilibrated
gases. The standard minimal couplings between the magnetic field and the
fermions' charges and magnetic dipole moments define the fermions' interaction
with the magnetic field. Assuming a variable coupling strength between the
magnetic field and the fermion (baryon) dipole moments, it is shown that a
ferromagnetized state can be achieved that corresponds to a lower energy
spin-polarized state with a magnetic field entirely due to the gas's magnetic
response. We find that, depending on the density, a very large increase in the
baryon dipole moments is needed to achieve this ferromagnetized state. While
the required increase seems unlikely, the induced magnetic field is of the
order $\sim10^{17}$ gauss. Furthermore, while externally magnetized Fermi gases
have an anisotropic pressure, the pressure of the ferromagnetized gas is
completely isotropic and the thermodynamically preferred magnetized state.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:30:53 GMT""},{""version"":""v2"",""created"":""Thu, 19 Nov 2020 08:51:47 GMT""}]","2020-11-25"
"2006.05248","Bo Li","Renjin Jiang and Bo Li","On the Dirichlet problem for the Schr\""odinger equation with boundary
  value in BMO space",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $(X,d,\mu)$ be a metric measure space satisfying a $Q$-doubling
condition, $Q>1$, and an $L^2$-Poincar\'{e} inequality. Let
$\mathscr{L}=\mathcal{L}+V$ be a Schr\""odinger operator on $X$, where
$\mathcal{L}$ is a non-negative operator generalized by a Dirichlet form, and
$V$ is a non-negative Muckenhoupt weight that satisfies a reverse H\""older
condition $RH_q$ for some $q\ge (Q+1)/2$. We show that a solution to
$(\mathscr{L}-\partial_t^2)u=0$ on $X\times \mathbb{R}_+$ satisfies the
Carleson condition, $$\sup_{B(x_B,r_B)}\frac{1}{\mu(B(x_B,r_B))} \int_{0}^{r_B}
\int_{B(x_B,r_B)} |t\nabla u(x,t)|^2 \frac{\mathrm{d}\mu\mathrm{d}
t}{t}<\infty,$$ if and only if, $u$ can be represented as the Poisson integral
of the Schr\""odinger operator $\mathscr{L}$ with trace in the BMO space
associated with $\mathscr{L}$.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:31:50 GMT""},{""version"":""v2"",""created"":""Sun, 28 Jun 2020 09:55:01 GMT""}]","2020-06-30"
"2006.05249","Daniel Harari","Hanna Benoni, Daniel Harari and Shimon Ullman","What takes the brain so long: Object recognition at the level of minimal
  images develops for up to seconds of presentation time","7 pages, 2 figures, 1 table",,,,"q-bio.NC cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rich empirical evidence has shown that visual object recognition in the brain
is fast and effortless, with relevant brain signals reported to start as early
as 80 ms. Here we study the time trajectory of the recognition process at the
level of minimal recognizable images (termed MIRC). These are images that can
be recognized reliably, but in which a minute change of the image (reduction by
either size or resolution) has a drastic effect on recognition. Subjects were
assigned to one of nine exposure conditions: 200, 500, 1000, 2000 ms with or
without masking, as well as unlimited time. The subjects were not limited in
time to respond after presentation. The results show that in the masked
conditions, recognition rates develop gradually over an extended period, e.g.
average of 18% for 200 ms exposure and 45% for 500 ms, increasing significantly
with longer exposure even above 2 secs. When presented for unlimited time
(until response), MIRC recognition rates were equivalent to the rates of
full-object images presented for 50 ms followed by masking. What takes the
brain so long to recognize such images? We discuss why processes involving
eye-movements, perceptual decision-making and pattern completion are unlikely
explanations. Alternatively, we hypothesize that MIRC recognition requires an
extended top-down process complementing the feed-forward phase.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:33:04 GMT""}]","2020-06-11"
"2006.05251","Elisabetta Cornacchia","Elisabetta Cornacchia, Neta Singer, Emmanuel Abbe","Polarization in Attraction-Repulsion Models",,,,,"cs.MA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a model for opinion dynamics, where at each time step,
randomly selected agents see their opinions - modeled as scalars in [0,1] -
evolve depending on a local interaction function. In the classical Bounded
Confidence Model, agents opinions get attracted when they are close enough. The
proposed model extends this by adding a repulsion component, which models the
effect of opinions getting further pushed away when dissimilar enough. With
this repulsion component added, and under a repulsion-attraction cleavage
assumption, it is shown that a new stable configuration emerges beyond the
classical consensus configuration, namely the polarization configuration. More
specifically, it is shown that total consensus and total polarization are the
only two possible limiting configurations. The paper further provides an
analysis of the infinite population regime in dimension 1 and higher, with a
phase transition phenomenon conjectured and backed heuristically.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:33:40 GMT""}]","2020-06-11"
"2006.05252","Nicolas Vecoven","Nicolas Vecoven and Damien Ernst and Guillaume Drion","A bio-inspired bistable recurrent cell allows for long-lasting memory",,,"10.1371/journal.pone.0252676",,"cs.NE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recurrent neural networks (RNNs) provide state-of-the-art performances in a
wide variety of tasks that require memory. These performances can often be
achieved thanks to gated recurrent cells such as gated recurrent units (GRU)
and long short-term memory (LSTM). Standard gated cells share a layer internal
state to store information at the network level, and long term memory is shaped
by network-wide recurrent connection weights. Biological neurons on the other
hand are capable of holding information at the cellular level for an arbitrary
long amount of time through a process called bistability. Through bistability,
cells can stabilize to different stable states depending on their own past
state and inputs, which permits the durable storing of past information in
neuron state. In this work, we take inspiration from biological neuron
bistability to embed RNNs with long-lasting memory at the cellular level. This
leads to the introduction of a new bistable biologically-inspired recurrent
cell that is shown to strongly improves RNN performance on time-series which
require very long memory, despite using only cellular connections (all
recurrent connections are from neurons to themselves, i.e. a neuron state is
not influenced by the state of other neurons). Furthermore, equipping this cell
with recurrent neuromodulation permits to link them to standard GRU cells,
taking a step towards the biological plausibility of GRU.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:36:31 GMT""}]","2021-07-14"
"2006.05253","El Hassan Benabdi","El Hassan Benabdi and Mohamed Barraa","The Spectral Theorem for Quaternionic Normal Operators",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  Let $\mathcal{H}$ be a right quaternionic Hilbert space and let $T$ be a
bounded normal right quaternionic linear operator on $\mathcal{H}$. In this
paper, we prove that there exists a unique spectral measure $E$ in
$\mathcal{H}$ such that $$T=\int_{\sigma_S(T)}\lambda dE_\lambda,$$ where
$\sigma_S(T)$ denotes the spherical spectrum of $T$.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:37:07 GMT""}]","2020-06-11"
"2006.05254","Ugo Tanielian","Ugo Tanielian, Maxime Sangnier, Gerard Biau","Approximating Lipschitz continuous functions with GroupSort neural
  networks","16 pages",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in adversarial attacks and Wasserstein GANs have advocated
for use of neural networks with restricted Lipschitz constants. Motivated by
these observations, we study the recently introduced GroupSort neural networks,
with constraints on the weights, and make a theoretical step towards a better
understanding of their expressive power. We show in particular how these
networks can represent any Lipschitz continuous piecewise linear functions. We
also prove that they are well-suited for approximating Lipschitz continuous
functions and exhibit upper bounds on both the depth and size. To conclude, the
efficiency of GroupSort networks compared with more standard ReLU networks is
illustrated in a set of synthetic experiments.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:37:43 GMT""},{""version"":""v2"",""created"":""Mon, 8 Feb 2021 18:17:50 GMT""}]","2021-02-09"
"2006.05255","\'Angel Gonz\'alez-Prieto","Jes\'us Bobadilla, Ra\'ul Lara-Cabrera, \'Angel Gonz\'alez-Prieto,
  Fernando Ortega","DeepFair: Deep Learning for Improving Fairness in Recommender Systems","18 pages, 9 figures, 4 tables","International Journal of Interactive Multimedia and Artificial
  Intelligence, 2020","10.9781/ijimai.2020.11.001",,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The lack of bias management in Recommender Systems leads to minority groups
receiving unfair recommendations. Moreover, the trade-off between equity and
precision makes it difficult to obtain recommendations that meet both criteria.
Here we propose a Deep Learning based Collaborative Filtering algorithm that
provides recommendations with an optimum balance between fairness and accuracy
without knowing demographic information about the users. Experimental results
show that it is possible to make fair recommendations without losing a
significant proportion of accuracy.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:39:38 GMT""}]","2020-12-22"
"2006.05256","Daniele Gammelli","Daniele Gammelli and Filipe Rodrigues","Recurrent Flow Networks: A Recurrent Latent Variable Model for Density
  Modelling of Urban Mobility","16 pages, 6 figures",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mobility-on-demand (MoD) systems represent a rapidly developing mode of
transportation wherein travel requests are dynamically handled by a coordinated
fleet of vehicles. Crucially, the efficiency of an MoD system highly depends on
how well supply and demand distributions are aligned in spatio-temporal space
(i.e., to satisfy user demand, cars have to be available in the correct place
and at the desired time). To do so, we argue that predictive models should aim
to explicitly disentangle between temporal} and spatial variability in the
evolution of urban mobility demand. However, current approaches typically
ignore this distinction by either treating both sources of variability jointly,
or completely ignoring their presence in the first place. In this paper, we
propose recurrent flow networks (RFN), where we explore the inclusion of (i)
latent random variables in the hidden state of recurrent neural networks to
model temporal variability, and (ii) normalizing flows to model the spatial
distribution of mobility demand. We demonstrate how predictive models
explicitly disentangling between spatial and temporal variability exhibit
several desirable properties, and empirically show how this enables the
generation of distributions matching potentially complex urban topologies.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:44:08 GMT""},{""version"":""v2"",""created"":""Wed, 4 May 2022 16:02:28 GMT""}]","2022-05-05"
"2006.05257","Sanket Shah","Gurunath Reddy Madhumani, Sanket Shah, Basil Abraham, Vikas Joshi,
  Sunayana Sitaram","Learning not to Discriminate: Task Agnostic Learning for Improving
  Monolingual and Code-switched Speech Recognition","5 pages (4 pages + 1 reference), 3 tables, 2 figures",,,,"eess.AS cs.CL cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recognizing code-switched speech is challenging for Automatic Speech
Recognition (ASR) for a variety of reasons, including the lack of code-switched
training data. Recently, we showed that monolingual ASR systems fine-tuned on
code-switched data deteriorate in performance on monolingual speech
recognition, which is not desirable as ASR systems deployed in multilingual
scenarios should recognize both monolingual and code-switched speech with high
accuracy. Our experiments indicated that this loss in performance could be
mitigated by using certain strategies for fine-tuning and regularization,
leading to improvements in both monolingual and code-switched ASR. In this
work, we present further improvements over our previous work by using domain
adversarial learning to train task agnostic models. We evaluate the
classification accuracy of an adversarial discriminator and show that it can
learn shared layer parameters that are task agnostic. We train end-to-end ASR
systems starting with a pooled model that uses monolingual and code-switched
data along with the adversarial discriminator. Our proposed technique leads to
reductions in Word Error Rates (WER) in monolingual and code-switched test sets
across three language pairs.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:45:30 GMT""}]","2020-06-11"
"2006.05259","David W. Romero","David W. Romero, Erik J. Bekkers, Jakub M. Tomczak, Mark Hoogendoorn","Wavelet Networks: Scale Equivariant Learning From Raw Waveforms",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inducing symmetry equivariance in deep neural architectures has resolved into
improved data efficiency and generalization. In this work, we utilize the
concept of scale and translation equivariance to tackle the problem of learning
on time-series from raw waveforms. As a result, we obtain representations that
largely resemble those of the wavelet transform at the first layer, but that
evolve into much more descriptive ones as a function of depth. Our empirical
results support the suitability of our Wavelet Networks which with a simple
architecture design perform consistently better than CNNs on raw waveforms and
on par with spectrogram-based methods.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:50:34 GMT""}]","2020-06-11"
"2006.05260","Joseph Jerome","Martin Herdegen, David Hobson, Joseph Jerome","An elementary approach to the Merton problem",,,,,"q-fin.MF q-fin.PM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we consider the infinite-horizon Merton
investment-consumption problem in a constant-parameter Black - Scholes - Merton
market for an agent with constant relative risk aversion R. The classical
primal approach is to write down a candidate value function and to use a
verification argument to prove that this is the solution to the problem.
However, features of the problem take it outside the standard settings of
stochastic control, and the existing primal verification proofs rely on
parameter restrictions (especially, but not only, R<1), restrictions on the
space of admissible strategies, or intricate approximation arguments.
  The purpose of this paper is to show that these complications can be overcome
using a simple and elegant argument involving a stochastic perturbation of the
utility function.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:51:41 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 14:28:20 GMT""}]","2021-03-31"
"2006.05261","Gian Luca Raselli","B. Ali-Mohammadzadeh, M. Babicz, W. Badgett, L. Bagby, V. Bellini, R.
  Benocci, M. Bonesini, A. Braggiotti, S. Centro, A. Chatterjee, A.G. Cocco, M.
  Diwan, A. Falcone, C. Farnese, A. Fava, D. Gibin, A. Guglielmi, W. Ketchum,
  U. Kose, A. Menegolli, G. Meng, C. Montanari, M. Nessi, F. Pietropaolo, A.
  Rappoldi, G.L. Raselli, M. Rossella, C. Rubbia, P. Sala, A. Scaramelli, F.
  Sergiampietri, M. Spanu, D. Torretta, M. Torti, F. Tortorici, F. Varanini, S.
  Ventura, C. Vignoli, A. Zhang, A. Zani","Design and implementation of the new scintillation light detection
  system of ICARUS T600",,,"10.1088/1748-0221/15/10/T10007","FERMILAB-PUB-20-230-ND","physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  ICARUS T600 is the far detector of the Short Baseline Neutrino program at
Fermilab(USA), which foresees three Liquid Argon Time Projection Chambers along
the Booster Neutrino Beam line to search for LSND-like sterile neutrino signal.
The T600 detector underwent a significant overhauling process at CERN,
introducing new technological developments while maintaining the already
achieved performances. The realization of a new liquid argon scintillation
light detection system is a primary task of the detector overhaul. As the
detector will be subject to a huge flux of cosmic rays, the light detection
system should allow the 3D reconstruction of events contributing to the
identification of neutrino interactions in the beam spill gate. The design and
implementationof the new scintillation light detection system of ICARUS T600 is
described.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:56:15 GMT""},{""version"":""v2"",""created"":""Tue, 1 Sep 2020 10:12:43 GMT""}]","2020-12-30"
"2006.05263","Goutam Paul","Nayana Das and Goutam Paul","Improving the Security of ""Measurement-Device-Independent Quantum
  Communication without Encryption""",,"Science Bulletin, Volume 65, Issue 24, 30 December 2020, Pages
  2048-2049","10.1016/j.scib.2020.09.015",,"quant-ph cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recently in 2018, Niu et al. proposed a measurement-device-independent
quantum secure direct communication protocol using Einstein-Podolsky-Rosen
pairs and generalized it to a quantum dialogue protocol (Niu et al., Science
bulletin 63.20, 2018). By analyzing these protocols we find some security
issues in both these protocols. In this work, we show that both the protocols
are not secure against information leakage, and a third party can get half of
the secret information without any active attack. We also propose suitable
modifications of these protocols to improve the security.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:56:46 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 15:15:43 GMT""}]","2021-02-02"
"2006.05270","Eric D'Hoker","Eric D'Hoker, Carlos R. Mafra, Boris Pioline and Oliver Schlotterer","Two-loop superstring five-point amplitudes I: Construction via chiral
  splitting and pure spinors","97 pages; minor typos corrected and minor edits in version 2",,,"UUITP-16/20","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The full two-loop amplitudes for five massless states in Type~II and
Heterotic superstrings are constructed in terms of convergent integrals over
the genus-two moduli space of compact Riemann surfaces and integrals of Green
functions and Abelian differentials on the surface. The construction combines
elements from the BRST cohomology of the pure spinor formulation and from
chiral splitting with the help of loop momenta and homology invariance. The
$\alpha' \to 0$ limit of the resulting superstring amplitude is shown to be in
perfect agreement with the previously known amplitude computed in Type~II
supergravity. Investigations of the $\alpha'$ expansion of the Type~II
amplitude and comparisons with predictions from S-duality are relegated to a
first companion paper. A construction from first principles in the RNS
formulation of the genus-two amplitude with five external NS states is
relegated to a second companion paper.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:00:14 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jul 2020 15:22:17 GMT""}]","2020-07-06"
"2006.05272","Hamid Nazari","Hamid Nazari, Yuyuan Ouyang","Backtracking linesearch for conditional gradient sliding",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a modification of the conditional gradient sliding (CGS) method
that was originally developed in \cite{lan2016conditional}. While the CGS
method is a theoretical breakthrough in the theory of projection-free
first-order methods since it is the first that reaches the theoretical
performance limit, in implementation it requires the knowledge of the Lipschitz
constant of the gradient of the objective function $L$ and the number of total
gradient evaluations $N$. Such requirements imposes difficulties in the actual
implementation, not only because that it can be difficult to choose proper
values of $L$ and $N$ that satisfies the conditions for convergence, but also
since conservative choices of $L$ and $N$ can deteriorate the practical
numerical performance of the CGS method. Our proposed method, called the
conditional gradient sliding method with linesearch (CGS-ls), does not require
the knowledge of either $L$ and $N$, and is able to terminate early before the
theoretically required number of iterations. While more practical in numerical
implementation, the theoretical performance of our proposed CGS-ls method is
still as good as that of the CGS method. We present numerical experiments to
show the efficiency of our proposed method in practice.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:00:55 GMT""}]","2020-06-11"
"2006.05275","Lorenzo Clemente","Lorenzo Clemente","On the complexity of the universality and inclusion problems for
  unambiguous context-free grammars (technical report)","full technical report of a paper to appear in VPT 2020",,,,"cs.FL","http://creativecommons.org/licenses/by/4.0/","  We study the computational complexity of universality and inclusion problems
for unambiguous finite automata and context-free grammars. We observe that
several such problems can be reduced to the universality problem for
unambiguous context-free grammars. The latter problem has long been known to be
decidable and we propose a PSPACE algorithm that works by reduction to the
zeroness problem of recurrence equations with convolution. We are not aware of
any non-trivial complexity lower bounds. However, we show that computing the
coin-flip measure of an unambiguous context-free language, a quantitative
generalisation of universality, is hard for the long-standing open problem
SQRTSUM.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:04:46 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 05:38:02 GMT""}]","2020-06-12"
"2006.05276","Shayan Fazeli","Shayan Fazeli, Majid Sarrafzadeh","A Flexible and Intelligent Framework for Remote Health Monitoring
  Dashboards",,,,,"cs.SE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Developing and maintaining monitoring panels is undoubtedly the main task in
the remote patient monitoring (RPM) systems. Due to the significant variations
in desired functionalities, data sources, and objectives, designing an
efficient dashboard that responds to the various needs in an RPM project is
generally a cumbersome task to carry out. In this work, we present ViSierra, a
framework for designing data monitoring dashboards in RPM projects. The
abstractions and different components of this open-source project are
explained, and examples are provided to support our claim concerning the
effectiveness of this framework in preparing fast, efficient, and accurate
monitoring platforms with minimal coding. These platforms will cover all the
necessary aspects in a traditional RPM project and combine them with novel
functionalities such as machine learning solutions and provide better data
analysis instruments for the experts to track the information.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:07:45 GMT""}]","2020-06-11"
"2006.05277","Yevheniya Nosyk","Yevheniya Nosyk, Maciej Korczy\'nski, Qasim Lone, Marcin Skwarek,
  Baptiste Jonglez and Andrzej Duda","The Closed Resolver Project: Measuring the Deployment of Source Address
  Validation of Inbound Traffic",,"IEEE/ACM Transactions on Networking (2023)","10.1109/TNET.2023.3257413",,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Source Address Validation (SAV) is a standard aimed at discarding packets
with spoofed source IP addresses. The absence of SAV for outgoing traffic has
been known as a root cause of Distributed Denial-of-Service (DDoS) attacks and
received widespread attention. While less obvious, the absence of inbound
filtering enables an attacker to appear as an internal host of a network and
may reveal valuable information about the network infrastructure. Inbound IP
spoofing may amplify other attack vectors such as DNS cache poisoning or the
recently discovered NXNSAttack. In this paper, we present the preliminary
results of the Closed Resolver Project that aims at mitigating the problem of
inbound IP spoofing. We perform the first Internet-wide active measurement
study to enumerate networks that filter or do not filter incoming packets by
their source address, for both the IPv4 and IPv6 address spaces. To achieve
this, we identify closed and open DNS resolvers that accept spoofed requests
coming from the outside of their network. The proposed method provides the most
complete picture of inbound SAV deployment by network providers. Our
measurements cover over 55 % IPv4 and 27 % IPv6 Autonomous Systems (AS) and
reveal that the great majority of them are fully or partially vulnerable to
inbound spoofing. By identifying dual-stacked DNS resolvers, we additionally
show that inbound filtering is less often deployed for IPv6 than it is for
IPv4. Overall, we discover 13.9 K IPv6 open resolvers that can be exploited for
amplification DDoS attacks - 13 times more than previous work. Furthermore, we
enumerate uncover 4.25 M IPv4 and 103 K IPv6 vulnerable closed resolvers that
could only be detected thanks to our spoofing technique, and that pose a
significant threat when combined with the NXNSAttack.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:07:58 GMT""},{""version"":""v2"",""created"":""Wed, 15 Mar 2023 11:47:14 GMT""}]","2023-03-29"
"2006.05278","Yassine Ouali","Yassine Ouali, C\'eline Hudelot, Myriam Tami","An Overview of Deep Semi-Supervised Learning","Preprint",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks demonstrated their ability to provide remarkable
performances on a wide range of supervised learning tasks (e.g., image
classification) when trained on extensive collections of labeled data (e.g.,
ImageNet). However, creating such large datasets requires a considerable amount
of resources, time, and effort. Such resources may not be available in many
practical cases, limiting the adoption and the application of many deep
learning methods. In a search for more data-efficient deep learning methods to
overcome the need for large annotated datasets, there is a rising research
interest in semi-supervised learning and its applications to deep neural
networks to reduce the amount of labeled data required, by either developing
novel methods or adopting existing semi-supervised learning frameworks for a
deep learning setting. In this paper, we provide a comprehensive overview of
deep semi-supervised learning, starting with an introduction to the field,
followed by a summarization of the dominant semi-supervised approaches in deep
learning.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:08:03 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jul 2020 17:38:19 GMT""}]","2020-07-07"
"2006.05279","Sarath Menon","Sarath Menon, Grisell D\'iaz Leines, Ralf Drautz and Jutta Rogal","Role of pre-ordered liquid in the selection mechanism of crystal
  polymorphs during nucleation",,,"10.1063/5.0017575",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the atomistic mechanism of homogeneous nucleation during
solidification in molybdenum employing transition path sampling. The mechanism
is characterized by the formation of a pre-structured region of high
bond-orientational order in the supercooled liquid followed by the nucleation
of the crystalline bulk phase within the center of the growing solid cluster.
This precursor plays a crucial role in the process, as it provides a diffusive
interface between the liquid and crystalline core, which lowers the interfacial
free energy and facilitates the nucleation of the bulk phase. Furthermore, the
structural features of the pre-ordered regions are distinct from the liquid and
solid phases, and preselect the specific polymorph that nucleates. The
similarity in the nucleation mechanism of Mo with that of metals that exhibit
different crystalline bulk phases indicates that the formation of a precursor
is a general feature observed in these materials. The strong influence of the
structural characteristics of the precursors on the final crystalline bulk
phase demonstrates that for the investigated system polymorph selection takes
place in the very early stages of nucleation.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:14:12 GMT""}]","2020-10-16"
"2006.05280","Andrea Marinucci","A. Marinucci, S. Bianchi, V. Braito, B. De Marco, G. Matt, R. Middei,
  E. Nardini, J. N. Reeves","The lively accretion disk in NGC 2992. I. Transient iron K emission
  lines in the high flux state","12 pages, 12 figures, 1 table. Accepted for publication in MNRAS",,"10.1093/mnras/staa1683",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on one of the brightest flux levels of the Seyfert 2 galaxy NGC
2992 ever observed in X-rays, on May 2019. The source has been monitored every
few days from March 26, 2019 to December 14, 2019 by Swift-XRT, and
simultaneous XMM-Newton (250 ks) and NuSTAR (120 ks) observations were
triggered on May 6, 2019. The high count rate of the source (its 2-10 keV flux
ranged between 0.7 and $1.0\times10^{-10}$ erg cm$^{-2}$ s$^{-1}$) allows us to
perform a time-resolved spectroscopy, probing spatial scales of tens of
gravitational radii from the central black hole. By constructing a map of the
excess emission over the primary continuum, we find several emission structures
in the 5.0-7.2 keV energy band. From fitting the 50 EPIC pn spectral slices of
$\sim$5 ks duration, we interpret them as a constant narrow iron K$\alpha$ line
and three variable components in the iron K complex. When a self-consistent
model accounting for the accretion disk emission is considered (KYNrline), two
of these features (in the 5.0-5.8 keV and 6.8-7.2 keV bands) can be ascribed to
a flaring region of the accretion disk located at ${r_{in}}\simeq15$-40
r$_{g\rm }$ from the black hole. The third one (6.5-6.8 keV) is likely produced
at much larger radii ($r_{in}>50$ r$_{g\rm }$). The inner radius and the
azimuthal extension retrieved from the coadded spectra of the flaring states
are ${ r_{in}}=15\pm3$ r$_{g\rm }$ and $\phi=165^{\circ}-330^{\circ}$,
suggesting that the emitting region responsible for the broad iron K component
is a relatively compact annular sector within the disk. Our findings support a
physical scenario in which the accretion disk in NGC 2992 becomes more active
at high accretion rates ($L_{\rm bol}/L_{\rm Edd}\geq4\%$).
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:14:52 GMT""}]","2020-06-24"
"2006.05281","Isar Nejadgholi","Isar Nejadgholi, Kathleen C. Fraser and Berry De Bruijn","Extensive Error Analysis and a Learning-Based Evaluation of Medical
  Entity Recognition Systems to Approximate User Experience","to appear at BioNLP2020",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When comparing entities extracted by a medical entity recognition system with
gold standard annotations over a test set, two types of mismatches might occur,
label mismatch or span mismatch. Here we focus on span mismatch and show that
its severity can vary from a serious error to a fully acceptable entity
extraction due to the subjectivity of span annotations. For a domain-specific
BERT-based NER system, we showed that 25% of the errors have the same labels
and overlapping span with gold standard entities. We collected expert judgement
which shows more than 90% of these mismatches are accepted or partially
accepted by the user. Using the training set of the NER system, we built a fast
and lightweight entity classifier to approximate the user experience of such
mismatches through accepting or rejecting them. The decisions made by this
classifier are used to calculate a learning-based F-score which is shown to be
a better approximation of a forgiving user's experience than the relaxed
F-score. We demonstrated the results of applying the proposed evaluation metric
for a variety of deep learning medical entity recognition models trained with
two datasets.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:15:33 GMT""}]","2020-06-11"
"2006.05282","Aurelian Bejancu","Aurelian Bejancu","Wiener-Hopf difference equations and semi-cardinal interpolation with
  integrable convolution kernels","40 pages",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $H\subset\mathbb{Z}^d$ be a half-space lattice, defined either relative
to a fixed coordinate (e.g.\ $H = \mathbb{Z}^{d-1}\!\times\!\mathbb{Z}_+$), or
relative to a linear order $\preceq$ on $\mathbb{Z}^d$, i.e.\ $H =
\{j\in\mathbb{Z}^d : 0\preceq j\}$. We consider the problem of interpolation at
the points of $H$ from the space of series expansions in terms of the
$H$-shifts of a decaying kernel $\phi$. Using the Wiener-Hopf factorization of
the symbol for cardinal interpolation with $\phi$ on $\mathbb{Z}^d$, we derive
some essential properties of semi-cardinal interpolation on $H$, such as
existence and uniqueness, Lagrange series representation, variational
characterization, and convergence to cardinal interpolation. Our main results
prove that specific algebraic or exponential decay of the kernel $\phi$ is
transferred to the Lagrange functions for interpolation on $H$, as in the case
of cardinal interpolation. These results are shown to apply to a variety of
examples, including the Gaussian, Mat\'{e}rn, generalized inverse multiquadric,
box-spline, and polyharmonic B-spline kernels.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:15:47 GMT""}]","2020-06-11"
"2006.05283","Swee K. Goh","Q. Niu, W. Zhang, Y. T. Chan, E. C. T. O'Farrell, R. Doganov, K. Y.
  Yip, Kwing To Lai, W. C. Yu, B. Ozyilmaz, G. R. Stewart, J. S. Kim, and Swee
  K. Goh","Stabilization of antiferromagnetism in 1T-Fe$_{0.05}$TaS$_2$","Q. Niu and W. Zhang contributed equally to this work. 7 pages, 5
  figures","Phys. Rev. Research 2, 023297 (2020)","10.1103/PhysRevResearch.2.023297",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  1T-TaS$_2$ is a prototypical charge-density-wave (CDW) system with a Mott
insulating ground state. Usually, a Mott insulator is accompanied by an
antiferromagnetic state. However, the antiferromagnetic order had never been
observed in 1T-TaS$_2$. Here, we report the stabilization of the
antiferromagnetic order by the intercalation of a small amount of Fe into the
van der Waals gap of 1T-TaS$_2$, i.e. forming 1T-Fe$_{0.05}$TaS$_2$. Upon
cooling from 300~K, the electrical resistivity increases with a decreasing
temperature before reaching a maximum value at around 15~K, which is close to
the Neel temperature determined from our magnetic susceptibility measurement.
The antiferromagnetic state can be fully suppressed when the sample thickness
is reduced, indicating that the antiferromagnetic order in Fe$_{0.05}$TaS$_2$
has a non-negligible three-dimensional character. For the bulk
Fe$_{0.05}$TaS$_2$, a comparison of our high pressure electrical transport data
with that of 1T-TaS$_2$ indicates that, at ambient pressure, Fe$_{0.05}$TaS$_2$
is in the nearly commensurate charge-density-wave (NCCDW) phase near the border
of the Mott insulating state. The temperature-pressure phase diagram thus
reveals an interesting decoupling of the antiferromagnetism from the Mott
insulating state.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:16:21 GMT""}]","2020-06-11"
"2006.05284","Yvain Bruned","Yvain Bruned, Kurusch Ebrahimi-Fard","Bogoliubov type recursions for renormalisation in regularity structures","28 pages",,,,"math.PR math-ph math.AP math.MP math.RA","http://creativecommons.org/licenses/by/4.0/","  Hairer's regularity structures transformed the solution theory of singular
stochastic partial differential equations. The notions of positive and negative
renormalisation are central and the intricate interplay between these two
renormalisation procedures is captured through the combination of cointeracting
bialgebras and an algebraic Birkhoff-type decomposition of bialgebra morphisms.
This work revisits the latter by defining Bogoliubov-type recursions similar to
Connes and Kreimer's formulation of BPHZ renormalisation. We then apply our
approach to the renormalisation problem for SPDEs.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 17:02:36 GMT""},{""version"":""v2"",""created"":""Wed, 9 Mar 2022 15:13:51 GMT""},{""version"":""v3"",""created"":""Wed, 28 Sep 2022 08:48:48 GMT""}]","2022-09-29"
"2006.05285","Anneleen De Schepper","Anneleen De Schepper","A geometric characterisation of subvarieties of the standard E_6-variety
  related to the ternions, degenerate split quaternions and sextonions over
  arbitrary fields","54 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main achievement of this paper is a geometric characterisation of certain
subvarieties of the Cartan variety (the standard projective variety associated
to the split exceptional group of Lie type E_6) over an arbitrary field K. The
characterised varieties arise as Veronese representations of certain ring
projective planes over quadratic subalgebras of the split octonions over K
(among which the sextonions, a 6-dimensional non-associative algebra). We
describe how these varieties are linked to the Freudenthal-Tits magic square,
and discuss how they would even fit in, when also allowing the sextonions and
other ""degenerate composition algebras"" as the algebras used to construct the
square.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:24:40 GMT""}]","2020-06-11"
"2006.05286","Fekadu Tolessa Gedefa","Fekadu Tolessa Gedefa","On The Log-Concavity of Polygonal Figurate Number Sequences","8 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  This paper presents the log-concavity of the $m$-gonal figurate number
sequences. The author gives and proves the recurrence formula for $m$-gonal
figurate number sequences and its corresponding quotient sequences which are
found to be bounded. Finally, the author also show that for $m\geq 3$, the
sequence $\big \{S_n(m)\big\}_{n\geq 1}$ of $m$-gonal figurate numbers is a
log-concave.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:29:59 GMT""}]","2020-06-11"
"2006.05287","Nikolay Fimin N","Victor Vedenyapin, Nikolay Fimin and Valery Chechetkin","The properties of Vlasov-Maxwell-Einstein equations and its applications
  to cosmological models",,"European Physical Journal Plus (2020) 135: 400","10.1140/epjp/s13360-020-00412-w",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The method of obtaining of Vlasov-type equations for systems of interacting
massive charged particles from the general relativistic Einstein-Hilbert action
is considered. An effective approach to synchronizing the proper times of
various particles of a many-particle system is proposed. Based on the resulting
expressions for the relativistic actions, an analysis of composite structure of
cosmological term in Einstein's equations is performed.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:30:17 GMT""}]","2020-06-11"
"2006.05289","Nikhil Churamani","Indu P. Bodala, Nikhil Churamani and Hatice Gunes","Creating a Robot Coach for Mindfulness and Wellbeing: A Longitudinal
  Study","11 pages. Corrected Typos",,,,"cs.HC cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social robots are starting to become incorporated into daily lives by
assisting in the promotion of physical and mental wellbeing. This paper
investigates the use of social robots for delivering mindfulness sessions. We
created a teleoperated robotic platform that enables an experienced human coach
to conduct the sessions in a virtual manner by replicating upper body and head
pose in real time. The coach is also able to view the world from the robot's
perspective and make a conversation with participants by talking and listening
through the robot. We studied how participants interacted with a teleoperated
robot mindfulness coach over a period of 5 weeks and compared with the
interactions another group of participants had with a human coach. The
mindfulness sessions delivered by both types of coaching invoked positive
responses from the participants for all the sessions. We found that the
participants rated the interactions with human coach consistently high in all
aspects. However, there is a longitudinal change in the ratings for the
interaction with the teleoperated robot for the aspects of motion and
conversation. We also found that the participants' personality traits --
conscientiousness and neuroticism influenced the perceptions of the robot
coach.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:31:32 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 09:59:45 GMT""}]","2020-06-12"
"2006.05290","Anna Paola Todino","Claudio Macci, Maurizia Rossi, Anna Paola Todino","Moderate Deviation estimates for Nodal Lengths of Random Spherical
  Harmonics","Revised according to referee's comments. To appear in ALEA",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove Moderate Deviation estimates for nodal lengths of random spherical
harmonics both on the whole sphere and on shrinking spherical domains. Central
Limit Theorems for the latter were recently established in Marinucci, Rossi and
Wigman (2020) and Todino (2020) respectively. Our proofs are based on the
combination of a Moderate Deviation Principle by Schulte and Th\""ale (2016) for
sequences of random variables living in a fixed Wiener chaos with a well-known
result based on the concept of exponential equivalence.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:33:46 GMT""},{""version"":""v2"",""created"":""Thu, 29 Oct 2020 17:19:42 GMT""}]","2020-10-30"
"2006.05291","Mohamed A. Suliman","Mohamed A. Suliman, Wei Dai","Mathematical Theory of Atomic Norm Denoising In Blind Two-Dimensional
  Super-Resolution (Extended Version)","22 pages",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops a new mathematical framework for denoising in blind
two-dimensional (2D) super-resolution upon using the atomic norm. The framework
denoises a signal that consists of a weighted sum of an unknown number of
time-delayed and frequency-shifted unknown waveforms from its noisy
measurements. Moreover, the framework also provides an approach for estimating
the unknown parameters in the signal. We prove that when the number of the
observed samples satisfies certain lower bound that is a function of the system
parameters, we can estimate the noise-free signal, with very high accuracy,
upon solving a regularized least-squares atomic norm minimization problem. We
derive the theoretical mean-squared error of the estimator, and we show that it
depends on the noise variance, the number of unknown waveforms, the number of
samples, and the dimension of the low-dimensional space where the unknown
waveforms lie. Finally, we verify the theoretical findings of the paper by
using extensive simulation experiments.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:33:55 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 11:02:52 GMT""}]","2021-05-19"
"2006.05292","Colm Talbot","Colm Talbot, Eric Thrane","Gravitational-wave astronomy with an uncertain noise power spectral
  density","12 pages, 7 figures",,,,"astro-ph.IM astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to extract information about the properties of compact binaries, we
must estimate the noise power spectral density of gravitational-wave data,
which depends on the properties of the gravitational-wave detector. In
practice, it is not possible to know this perfectly, only to estimate it from
the data. Multiple estimation methods are commonly used and each has a
corresponding statistical uncertainty. However, this uncertainty is widely
ignored when measuring the physical parameters describing compact binary
coalescences, and the appropriate likelihoods which account for the uncertainty
are not well known. In order to perform increasingly precise astrophysical
inference and model selection, it will be essential to account for this
uncertainty. In this work, we derive the correct likelihood for one of the most
widely used estimation methods in gravitational-wave transient analysis, the
median average. We demonstrate that simulated Gaussian noise follows the
predicted distributions. We then examine real gravitational-wave data at and
around the time of GW151012, a relatively low-significance binary black hole
merger event. We show that the data are well described by stationary-Gaussian
noise and explore the impact of different noise power spectral density
estimation methods on the astrophysical inferences we draw about GW151012.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:34:24 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 19:21:23 GMT""}]","2020-06-18"
"2006.05293","Youshan Tao","Youshan Tao, Michael Winkler","Asymptotic stability of spatial homogeneity in a haptotxis model for
  oncolytic virotherapy","21 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work considers a model for oncolytic virotherapy, as given by the
reaction-diffusion-taxis system $$ \left\{ \begin{array}{l} u_t = \Delta u -
\nabla \cdot (u\nabla v)-\rho uz, \\[1mm] v_t = - (u+w)v, \\[1mm] w_t = D_w
\Delta w - w + uz, \\[1mm] z_t = D_z \Delta z - z - uz + \beta w, \end{array}
\right.
  $$ in a smoothly bounded domain $\Omega\subset\mathbb{R}^2$, with parameters
$D_w>0, D_z>0, \beta>0$ and $\rho\ge 0$.\\ % Previous analysis has asserted
that for all reasonably regular initial data, an associated no-flux type
initial-boundary value problem admits a global classical solution, and that
this solution is bounded if $\beta<1$, whereas whenever $\beta>1$ and
$\frac{1}{|\Omega|}\int_{\Omega} u(\cdot,0)>\frac{1}{\beta-1}$, infinite-time
blow-up occurs at least in the particular case when $\rho=0$.\abs %
  In order to provide an appropriate complement to this, the present work
reveals that for any $\rho\ge 0$ and arbitrary $\beta>0$, at each prescribed
level $\gamma\in (0,\frac{1}{(\beta-1)_+})$ one can identify an
$L^\infty$-neighborhood of the homogeneous distribution $(u,v,w,z)\equiv
(\gamma,0,0,0)$ within which all initial data lead to globally bounded
solutions that stabilize toward the constant equilibrium $(u_\infty,0,0,0)$
with some $u_\infty>0$.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:34:38 GMT""}]","2020-06-11"
"2006.05297","Kasia Jankiewicz","Kasia Jankiewicz and Daniel T. Wise","A curiously cubulated group","3 pages, to appear in Geom. Ded","Geom. Dedicata 212 (2021), 17-19",,,"math.GR math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a finitely generated 2-dimensional group that acts properly on a
locally finite CAT(0) cube complex but does not act properly on a finite
dimensional CAT(0) cube complex.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:13:26 GMT""}]","2021-09-21"
"2006.05301","Mark Collier","Mark Collier, Alfredo Nazabal and Christopher K.I. Williams","VAEs in the Presence of Missing Data","Accepted to ICML Workshop on the Art of Learning with Missing Values
  (Artemiss), 17 July 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real world datasets often contain entries with missing elements e.g. in a
medical dataset, a patient is unlikely to have taken all possible diagnostic
tests. Variational Autoencoders (VAEs) are popular generative models often used
for unsupervised learning. Despite their widespread use it is unclear how best
to apply VAEs to datasets with missing data. We develop a novel latent variable
model of a corruption process which generates missing data, and derive a
corresponding tractable evidence lower bound (ELBO). Our model is
straightforward to implement, can handle both missing completely at random
(MCAR) and missing not at random (MNAR) data, scales to high dimensional inputs
and gives both the VAE encoder and decoder principled access to indicator
variables for whether a data element is missing or not. On the MNIST and SVHN
datasets we demonstrate improved marginal log-likelihood of observed data and
better missing data imputation, compared to existing approaches.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:40:00 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 13:39:59 GMT""},{""version"":""v3"",""created"":""Sun, 21 Mar 2021 11:42:08 GMT""}]","2021-03-23"
"2006.05302","Gholamhossein Haghighat","Gholamhossein Haghighat, Daruosh Haji Raissi, Mojtaba Mohammadi
  Najafabadi","New Collider Searches for Axion-like Particles Coupling to Gluons","20 pages, 6 figures","Phys. Rev. D 102, 115010 (2020)","10.1103/PhysRevD.102.115010",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Axion-like particles (ALPs) are pseudo Nambu-Goldstone bosons associated with
spontaneously broken global symmetries emerging in many extensions of the
Standard Model. Assuming the most general effective Lagrangian up to
dimension-5 operators for an ALP interacting with the SM fields, we investigate
for the first time the sensitivity of the LHC13 to the ALP production in
association with a di-jet. This study is focused on light ALPs which appear as
invisible particles at the detector. Performing a realistic detector simulation
and deploying a multivariate technique to best discriminate the signal from
backgrounds, we set expected upper bounds on the ALP coupling to gluons. A
comprehensive set of background processes is considered, and it is shown that
this process provides significant sensitivity to the ALP-gluon coupling and the
resulting bound is more stringent than those already obtained at the LHC. We
also present prospects for the HE-LHC27 and FCC-hh100 and show that these
future colliders are able to improve the limits from the LHC by roughly one
order of magnitude.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:41:28 GMT""},{""version"":""v2"",""created"":""Sat, 5 Dec 2020 11:51:23 GMT""}]","2020-12-08"
"2006.05304","Georgios Bakirtzis","Georgios Bakirtzis and Tim Sherburne and Stephen Adams and Barry M.
  Horowitz and Peter A. Beling and Cody H. Fleming","An Ontological Metamodel for Cyber-Physical System Safety, Security, and
  Resilience Coengineering",,,"10.1007/s10270-021-00892-z",,"cs.SE cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  System complexity has become ubiquitous in the design, assessment, and
implementation of practical and useful cyber-physical systems. This increased
complexity is impacting the management of models necessary for designing
cyber-physical systems that are able to take into account a number of
``-ilities'', such that they are safe and secure and ultimately resilient to
disruption of service. We propose an ontological metamodel for system design
that augments an already existing industry metamodel to capture the
relationships between various model elements and safety, security, and
resilient considerations. Employing this metamodel leads to more cohesive and
structured modeling efforts with an overall increase in scalability, usability,
and unification of already existing models. In turn, this leads to a
mission-oriented perspective in designing security defenses and resilience
mechanisms to combat undesirable behaviors. We illustrate this metamodel in an
open-source GraphQL implementation, which can interface with a number of
modeling languages. We support our proposed metamodel with a detailed
demonstration using an oil and gas pipeline model.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:45:01 GMT""}]","2021-06-04"
"2006.05305","Peter Olsson","Yann-Edwin Keta and Peter Olsson","Translational and rotational velocities in shear-driven jamming of
  ellipsoidal particles",,,"10.1103/PhysRevE.102.052905",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study shear-driven jamming of ellipsoidal particles at zero temperature
with a focus on the microscopic dynamics. We find that a change from spherical
particles to ellipsoids with aspect ratio $\alpha=1.02$ gives dramatic changes
of the microscopic dynamics with much lower translational velocities and a new
role for the rotations. Whereas the velocity difference at contacts---and
thereby the dissipation---in collections of spheres is dominated by the
translational velocities and reduced by the rotations, the same quantity is in
collections of ellipsoids instead totally dominated by the rotational
velocities. By also examining the effect of different aspect ratios we find
that the examined quantities show either a peak or a change in slope at
$\alpha\approx1.2$, thus giving evidence for a crossover between different
regions of low and high aspect ratio.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:45:18 GMT""}]","2020-12-30"
"2006.05318","Victor Coppo Leite","Victor Coppo Leite and Elia Merzari","The effect of varying viscosity in turbulent channel flow",,,,,"physics.flu-dyn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we examine channel flow subject to spatially varying
viscosity in the streamwise direction. The Reynolds number is imposed locally
with three different ramps. The setup is reminiscent of transient channel flow,
but with a space dependent viscosity rather than a time dependent viscosity. It
is also relevant to various applications in nuclear engineering and in
particular in test reactors, where the viscosity changes significantly in the
streamwise direction, and there is a severe lack of Direct Numerical Simulation
(DNS) data to benchmark turbulence models in these conditions.
  As part of this work we set up a novel benchmark case: the channel is
extended in the stream-wise direction up to 20p. The viscosity is kept constant
in the first 4p region. This inlet region is used as a cyclic region to obtain
a fully developed flow profile at the beginning of the ramping region. In the
ramping region the Reynolds number is linearly increased along the channel. The
flow is homogenous in the spanwise direction, while it is nonhomogenous in the
stream-wise and wall-normal direction. We perform here Direct Numerical
Simulation (DNS) with Nek5000, a spectral-element computational fluid dynamics
(CFD) code developed at Argonne National Laboratory.
  In this study, specific focus is given to the investigation of turbulence
properties and structures in the near-wall region along the flow direction.
Turbulent statistics are collected and investigated. Similarly to transient
channel flow, the results show that a variation in the Reynolds across a
channel does not cause an immediate change in the size of turbulent structures
in the ramp region and a delay is in fact observed in both wall shear and
friction Reynolds number. The results from the present study are compared with
a correlation available in the literature for the friction velocity and as a
function of the Reynolds number.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:52:54 GMT""}]","2020-06-11"
"2006.05319","Riley Badenbroek","Riley Badenbroek and Etienne de Klerk","An Analytic Center Cutting Plane Method to Determine Complete Positivity
  of a Matrix","16 pages, 1 figure",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an analytic center cutting plane method to determine if a matrix
is completely positive, and return a cut that separates it from the completely
positive cone if not. This was stated as an open (computational) problem by
Berman, D\""ur, and Shaked-Monderer [Electronic Journal of Linear Algebra,
2015]. Our method optimizes over the intersection of a ball and the copositive
cone, where membership is determined by solving a mixed-integer linear program
suggested by Xia, Vera, and Zuluaga [INFORMS Journal on Computing, 2018]. Thus,
our algorithm can, more generally, be used to solve any copositive optimization
problem, provided one knows the radius of a ball containing an optimal
solution. Numerical experiments show that the number of oracle calls (matrix
copositivity checks) for our implementation scales well with the matrix size,
growing roughly like $O(d^2)$ for $d\times d$ matrices. The method is
implemented in Julia, and available at
https://github.com/rileybadenbroek/CopositiveAnalyticCenter.jl.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:54:29 GMT""}]","2020-06-11"
"2006.05320","Jean-Ren\'e Chazottes","J.-R. Chazottes, J. Moles, F. Redig, E. Ugalde","Gaussian concentration and uniqueness of equilibrium states in lattice
  systems","24 pages. Accepted for publication in J. Stat. Phys. (2020). Some
  typos have been corrected. Proposition 2.2 has been strengthened: if a
  Gaussian concentration bound holds then the measure is mixing, not only
  ergodic",,"10.1007/s10955-020-02658-1",,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider equilibrium states (that is, shift-invariant Gibbs measures) on
the configuration space $S^{\mathbb{Z}^d}$ where $d\geq 1$ and $S$ is a finite
set. We prove that if an equilibrium state for a shift-invariant uniformly
summable potential satisfies a Gaussian concentration bound, then it is unique.
Equivalently, if there exist several equilibrium states for a potential, none
of them can satisfy such a bound.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:55:12 GMT""},{""version"":""v2"",""created"":""Thu, 15 Oct 2020 10:23:30 GMT""}]","2020-12-02"
"2006.05321","Kazu Ghalamkari","Kazu Ghalamkari, Mahito Sugiyama","Fast Rank Reduction for Non-negative Matrices via Mean Field Theory","10 pages, 4 figures",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an efficient matrix rank reduction method for non-negative
matrices, whose time complexity is quadratic in the number of rows or columns
of a matrix. Our key insight is to formulate rank reduction as a mean-field
approximation by modeling matrices via a log-linear model on structured sample
space, which allows us to solve the rank reduction as convex optimization. The
highlight of this formulation is that the optimal solution that minimizes the
KL divergence from a given matrix can be analytically computed in a closed
form. We empirically show that our rank reduction method is faster than NMF and
its popular variant, lraNMF, while achieving competitive low rank approximation
error on synthetic and real-world datasets.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:55:47 GMT""},{""version"":""v2"",""created"":""Thu, 4 Mar 2021 09:09:15 GMT""}]","2021-03-05"
"2006.05323","Roberto Rampazzo Dr.","R. Rampazzo, A. Omizzolo, M. Uslenghi, J. Roman, P. Mazzei, L.
  Verdes-Montenegro, A. Marino and M.G. Jones","Morphology and surface photometry of a sample of isolated early-type
  galaxies from deep imaging","31 pages, 10 figures in the text, 10 figures in Appendix A, accepted
  for publication in A&A",,"10.1051/0004-6361/202038156",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Isolated early-type galaxies (iETGs) are evolving in unusually poor
environments for this morphological family, which is typical of cluster
inhabitants. We investigate the mechanisms driving the evolution of these
galaxies. Several studies indicate that interactions, accretions, and merging
episodes leave their signature on the galaxy structure, from the nucleus down
to the faint outskirts. We focus on revealing such signatures, if any, in a
sample of iETGs, and we quantitatively revise their galaxy classification. We
observed 20 (out of 104) iETGs, selected from the AMIGA catalog, with the 4KCCD
camera at the VATT in the SDSS g and r bands. These are the deepest
observations of a sample of iETGs so far. The analysis was performed using the
AIDA package, providing PSF-corrected 2D surface photometry up to the galaxy
outskirts. The package provides a model of the 2D galaxy light distribution,
which after model subtraction enhances the fine and peculiar structures in the
residual image of the galaxies. Our re-classification suggests that the sample
is composed of bona fide ETGs spanning from ellipticals to late-S0s galaxies.
Most of the surface brightness profiles are best fitted with a bulge plus disc
model, suggesting the presence of an underlying disc structure. The residuals
obtained after the model subtraction show the nearly ubiquitous presence of
fine structures, such as shells, stellar fans, rings, and tails. Shell systems
are revealed in about 60% of these galaxies. Because interaction, accretion,
and merging events are widely interpreted as the origin of the fans, ripples,
shells and tails in galaxies, we suggest that most of these iETGs have
experienced such events. Because they are isolated (after 2-3 Gyr), these
galaxies are the cleanest environment in which to study phenomena connected
with events like these.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:58:06 GMT""}]","2020-08-19"
"2006.05324","Bhaskar Mitra","Nick Craswell, Daniel Campos, Bhaskar Mitra, Emine Yilmaz and Bodo
  Billerbeck","ORCAS: 18 Million Clicked Query-Document Pairs for Analyzing Search",,,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Users of Web search engines reveal their information needs through queries
and clicks, making click logs a useful asset for information retrieval.
However, click logs have not been publicly released for academic use, because
they can be too revealing of personally or commercially sensitive information.
This paper describes a click data release related to the TREC Deep Learning
Track document corpus. After aggregation and filtering, including a k-anonymity
requirement, we find 1.4 million of the TREC DL URLs have 18 million
connections to 10 million distinct queries. Our dataset of these queries and
connections to TREC documents is of similar size to proprietary datasets used
in previous papers on query mining and ranking. We perform some preliminary
experiments using the click data to augment the TREC DL training data, offering
by comparison: 28x more queries, with 49x more connections to 4.4x more URLs in
the corpus. We present a description of the dataset's generation process,
characteristics, use in ranking and suggest other potential uses.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:58:21 GMT""},{""version"":""v2"",""created"":""Tue, 18 Aug 2020 14:45:00 GMT""}]","2020-08-19"
"2006.05325","Orhan Akal","Orhan Akal, Zhigang Peng and Gerardo Hermosillo Valadez","ComboNet: Combined 2D & 3D Architecture for Aorta Segmentation","9 pages, 3 figures, 3 tables",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D segmentation with deep learning if trained with full resolution is the
ideal way of achieving the best accuracy. Unlike in 2D, 3D segmentation
generally does not have sparse outliers, prevents leakage to surrounding soft
tissues, at the very least it is generally more consistent than 2D
segmentation. However, GPU memory is generally the bottleneck for such an
application. Thus, most of the 3D segmentation applications handle sub-sampled
input instead of full resolution, which comes with the cost of losing precision
at the boundary. In order to maintain precision at the boundary and prevent
sparse outliers and leakage, we designed ComboNet. ComboNet is designed in an
end to end fashion with three sub-network structures. The first two are
parallel: 2D UNet with full resolution and 3D UNet with four times sub-sampled
input. The last stage is the concatenation of 2D and 3D outputs along with a
full-resolution input image which is followed by two convolution layers either
with 2D or 3D convolutions. With ComboNet we have achieved $92.1\%$ dice
accuracy for aorta segmentation. With Combonet, we have observed up to $2.3\%$
improvement of dice accuracy as opposed to 2D UNet with the full-resolution
input image.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:02:55 GMT""}]","2020-06-11"
"2006.05326","Koen Thas","J. A. Thas and K. Thas","Covers of generalized quadrangles, 2. Kantor-Knuth covers and embedded
  ovoids","18 pages, submitted (March 2020)",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, which is a sequel to \cite{part1}, we proceed with our study
of covers and decomposition laws for geometries related to generalized
quadrangles. In particular, we obtain a higher decomposition law for all
Kantor-Knuth generalized quadrangles which generalizes one of the main results
in \cite{part1}. In a second part of the paper, we study the set of all
Kantor-Knuth ovoids (with given parameter) in a fixed finite parabolic
quadrangle, and relate this set to embeddings of parabolic quadrangles into
Kantor-Knuth quadrangles. This point of view gives rise to an answer of a
question posed in \cite{JATSEP}.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:03:53 GMT""}]","2020-06-11"
"2006.05327","Roberto Daza","Roberto Daza, Aythami Morales, Julian Fierrez, Ruben Tolosana","mEBAL: A Multimodal Database for Eye Blink Detection and Attention Level
  Estimation",,,,,"cs.CV cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents mEBAL, a multimodal database for eye blink detection and
attention level estimation. The eye blink frequency is related to the cognitive
activity and automatic detectors of eye blinks have been proposed for many
tasks including attention level estimation, analysis of neuro-degenerative
diseases, deception recognition, drive fatigue detection, or face
anti-spoofing. However, most existing databases and algorithms in this area are
limited to experiments involving only a few hundred samples and individual
sensors like face cameras. The proposed mEBAL improves previous databases in
terms of acquisition sensors and samples. In particular, three different
sensors are simultaneously considered: Near Infrared (NIR) and RGB cameras to
capture the face gestures and an Electroencephalography (EEG) band to capture
the cognitive activity of the user and blinking events. Regarding the size of
mEBAL, it comprises 6,000 samples and the corresponding attention level from 38
different students while conducting a number of e-learning tasks of varying
difficulty. In addition to presenting mEBAL, we also include preliminary
experiments on: i) eye blink detection using Convolutional Neural Networks
(CNN) with the facial images, and ii) attention level estimation of the
students based on their eye blink frequency.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:05:08 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 11:11:33 GMT""}]","2020-10-23"
"2006.05328","Hong-Bin Chen","Hong-Bin Chen","Hamilton-Jacobi equations for nonsymmetric matrix inference",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the high-dimensional limit of the free energy associated with the
inference problem of a rank-one nonsymmetric matrix. The matrix is expressed as
the outer product of two vectors, not necessarily independent. The
distributions of the two vectors are only assumed to have scaled bounded
supports. We bound the difference between the free energy and the solution to a
suitable Hamilton-Jacobi equation in terms of two much simpler quantities:
concentration rate of this free energy, and the convergence rate of a simpler
free energy in a decoupled system. To demonstrate the versatility of this
approach, we apply our result to the i.i.d. case and the spherical case. By
plugging in estimates of the two simpler quantities, we identify the limits and
obtain convergence rates.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:05:56 GMT""},{""version"":""v2"",""created"":""Wed, 17 Jun 2020 08:47:59 GMT""}]","2020-06-18"
"2006.05330","Sascha Kurz","Sascha Kurz","Are weighted games sufficiently good for binary voting?","7 pages, 2 tables; typos corrected",,"10.1007/s41412-021-00111-6",,"cs.GT econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Binary yes-no decisions in a legislative committee or a shareholder meeting
are commonly modeled as a weighted game. However, there are noteworthy
exceptions. E.g., the voting rules of the European Council according to the
Treaty of Lisbon use a more complicated construction. Here we want to study the
question if we lose much from a practical point of view, if we restrict
ourselves to weighted games. To this end, we invoke power indices that measure
the influence of a member in binary decision committees. More precisely, we
compare the achievable power distributions of weighted games with those from a
reasonable superset of weighted games. It turns out that the deviation is
relatively small.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:10:57 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 15:30:23 GMT""},{""version"":""v3"",""created"":""Fri, 16 Jul 2021 11:21:13 GMT""}]","2021-08-11"
"2006.05333","Dejan Govc","Dejan Govc","Computing Homotopy Types of Directed Flag Complexes","28 pages, 3 figures; supplementary material available at
  https://github.com/DejanGovc/HomotopyTypes",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Combinatorially and stochastically defined simplicial complexes often have
the homotopy type of a wedge of spheres. A prominent conjecture of Kahle
quantifies this precisely for the case of random flag complexes. We explore
whether such properties might extend to graphs arising from nature. We consider
the brain network (as reconstructed by Varshney & al.) of the Caenorhabditis
elegans nematode, an important model organism in biology. Using an iterative
computational procedure based on elementary methods of algebraic topology,
namely homology, simplicial collapses and coning operations, we show that its
directed flag complex is homotopy equivalent to a wedge of spheres, completely
determining, for the first time, the homotopy type of a flag complex
corresponding to a brain network.
  We also consider the corresponding flag tournaplex and show that torsion can
be found in the homology of its local directionality filtration. As a toy
example, directed flag complexes of tournaments from McKay's collection are
classified up to homotopy. Moore spaces other than spheres occur in this
classification. As a tool, we prove that the fundamental group of the directed
flag complex of any tournament is free by considering its cell structure.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:15:47 GMT""}]","2020-06-11"
"2006.05334","Koen Thas","Koen Thas","Two questions of Moorhouse on indiscernible locally finite generalized
  quadrangles","9 pages (Submitted May 2023)",,,,"math.CO math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We settle two questions posed by G. Eric Moorhouse on the existence of
locally finite generalized quadrangles with indiscernible ovoids or spreads.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:16:30 GMT""},{""version"":""v2"",""created"":""Wed, 17 May 2023 13:06:49 GMT""}]","2023-05-18"
"2006.05335","Diego A. Souza","Raul K. C. Ara\'ujo, Enrique Fern\'andez-Cara, Diego A. Souza","On the Uniform Controllability of the Inviscid and Viscous
  Burgers-$\alpha$ Systems","25 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work is devoted to prove the global uniform exact controllability of the
inviscid and viscous Burgers-$\alpha$ systems. The state $y$ is the solution to
a regularized Burgers equation, where the transport velocity $z$ consists of a
filtered version of $y$ - specifically $z=(Id-\alpha^2\partial^2_ {xx})^{-1}y$
with $\alpha>0$ being a small parameter - in place of $y$. First, a global
uniform exact controllability result for the nonviscous Burgers-$\alpha$ system
with three scalar controls is obtained, using the return method. Then, global
exact controllability to constant states of the viscous system is deduced from
a local exact controllability result and a global approximate controllability
result for smooth initial and target states.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:16:45 GMT""}]","2020-06-11"
"2006.05336","Yigitcan Kaya","Yigitcan Kaya, Sanghyun Hong, Tudor Dumitras","On the Effectiveness of Regularization Against Membership Inference
  Attacks","Pre-print. 10 pages, 1 figure, 8 tables",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning models often raise privacy concerns as they leak information
about their training data. This enables an adversary to determine whether a
data point was in a model's training set by conducting a membership inference
attack (MIA). Prior work has conjectured that regularization techniques, which
combat overfitting, may also mitigate the leakage. While many regularization
mechanisms exist, their effectiveness against MIAs has not been studied
systematically, and the resulting privacy properties are not well understood.
We explore the lower bound for information leakage that practical attacks can
achieve. First, we evaluate the effectiveness of 8 mechanisms in mitigating two
recent MIAs, on three standard image classification tasks. We find that certain
mechanisms, such as label smoothing, may inadvertently help MIAs. Second, we
investigate the potential of improving the resilience to MIAs by combining
complementary mechanisms. Finally, we quantify the opportunity of future MIAs
to compromise privacy by designing a white-box `distance-to-confident' (DtC)
metric, based on adversarial sample crafting. Our metric reveals that, even
when existing MIAs fail, the training samples may remain distinguishable from
test samples. This suggests that regularization mechanisms can provide a false
sense of privacy, even when they appear effective against existing MIAs.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:17:21 GMT""}]","2020-06-11"
"2006.05337","Shaaban M. Shaaban","M.A. Rehman, S.M. Shaaban, P.H. Yoon, M. Lazar, S. Poedts","Electromagnetic instabilities of low-beta alpha/proton beams in space
  plasmas","Accepted for publication at Astrophysics and Space Science",,"10.1007/s10509-020-03823-4",,"physics.space-ph astro-ph.SR physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Relative drifts between different species or particle populations are
characteristic to solar plasma outflows, e.g., in the fast streams of the solar
winds, coronal mass ejections and interplanetary shocks. This paper
characterizes the dispersion and stability of the low-beta alpha/proton drifts
in the absence of any intrinsic thermal anisotropies, which are usually invoked
in order to stimulate various instabilities. The dispersion relations derived
here describe the full spectrum of instabilities and their variations with the
angle of propagation and plasma parameters. The results unveil a potential
competition between instabilities of the electromagnetic proton cyclotron and
alpha cyclotron modes. For conditions specific to a low-beta solar wind, e.g.,
at low heliocentric distances in the outer corona, the instability operates on
the alpha cyclotron branch. The growth rates of the alpha cyclotron mode are
systematically stimulated by the (parallel) plasma beta and/or the alpha-proton
temperature ratio. One can therefore expect that this instability develops even
in the absence of temperature anisotropies, with potential to contribute to a
self-consistent regulation of the observed drift of alpha particles.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:17:43 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 22:29:47 GMT""}]","2020-07-01"
"2006.05338","Ngoc-Trung Tran","Ngoc-Trung Tran, Viet-Hung Tran, Ngoc-Bao Nguyen, Trung-Kien Nguyen,
  Ngai-Man Cheung","On Data Augmentation for GAN Training","Accepted in IEEE Transactions on Image Processing",,"10.1109/TIP.2021.3049346",,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent successes in Generative Adversarial Networks (GAN) have affirmed the
importance of using more data in GAN training. Yet it is expensive to collect
data in many domains such as medical applications. Data Augmentation (DA) has
been applied in these applications. In this work, we first argue that the
classical DA approach could mislead the generator to learn the distribution of
the augmented data, which could be different from that of the original data. We
then propose a principled framework, termed Data Augmentation Optimized for GAN
(DAG), to enable the use of augmented data in GAN training to improve the
learning of the original distribution. We provide theoretical analysis to show
that using our proposed DAG aligns with the original GAN in minimizing the
Jensen-Shannon (JS) divergence between the original distribution and model
distribution. Importantly, the proposed DAG effectively leverages the augmented
data to improve the learning of discriminator and generator. We conduct
experiments to apply DAG to different GAN models: unconditional GAN,
conditional GAN, self-supervised GAN and CycleGAN using datasets of natural
images and medical images. The results show that DAG achieves consistent and
considerable improvements across these models. Furthermore, when DAG is used in
some GAN models, the system establishes state-of-the-art Frechet Inception
Distance (FID) scores. Our code is available.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:19:26 GMT""},{""version"":""v2"",""created"":""Tue, 25 Aug 2020 14:00:58 GMT""},{""version"":""v3"",""created"":""Thu, 31 Dec 2020 08:34:10 GMT""}]","2021-02-24"
"2006.05342","Mikhail Mikhasenko","G.D. Alexeev, M.G. Alexeev, A. Amoroso, V. Andrieux, V. Anosov, A.
  Antoshkin, K. Augsten, W. Augustyniak, C.D.R. Azevedo, B. Badelek, F.
  Balestra, M. Ball, J. Barth, R. Beck, Y. Bedfer, J. Berenguer Antequera, J.
  Bernhard, M. Bodlak, F. Bradamante, A. Bressan, V.E. Burtsev, W.-C. Chang, C.
  Chatterjee, M. Chiosso, A.G. Chumakov, S.-U. Chung, A. Cicuttin, P.M.M.
  Correia, M.L. Crespo, D. D'Ago, S. Dalla Torre, S.S. Dasgupta, S. Dasgupta,
  I. Denisenko, O.Yu. Denisov, S.V. Donskov, N. Doshita, Ch. Dreisbach, W.
  Duennweber, R.R. Dusaev, A. Efremov, P.D. Eversheim, P. Faccioli, M.
  Faessler, M. Finger, M. Finger jr., H. Fischer, C. Franco, J.M. Friedrich, V.
  Frolov, F. Gautheron, O.P. Gavrichtchouk, S. Gerassimov, J. Giarra, I. Gnesi,
  M. Gorzellik, A. Grasso, A. Gridin, M. Grosse Perdekamp, B. Grube, A. Guskov,
  D. von Harrach, R. Heitz, F. Herrmann, N. Horikawa, N. d'Hose, C.-Y. Hsieh,
  S. Huber, S. Ishimoto, A. Ivanov, T. Iwata, M. Jandek, T. Jary, R. Joosten,
  P. Joerg, E. Kabuss, F. Kaspar, A. Kerbizi, B. Ketzer, G.V. Khaustov, Yu.A.
  Khokhlov, Yu. Kisselev, F. Klein, J.H. Koivuniemi, V.N. Kolosov, K. Kondo, I.
  Konorov, V.F. Konstantinov, A.M. Kotzinian, O.M. Kouznetsov, A. Koval, Z.
  Kral, F. Krinner, Y. Kulinich, F. Kunne, K. Kurek, R.P. Kurjata, A. Kveton,
  K. Lavickova, S. Levorato, Y.-S. Lian, J. Lichtenstadt, P.-J. Lin, R. Longo,
  V.E. Lyubovitskij, A. Maggiora, A. Magnon, N. Makins, N. Makke, G.K. Mallot,
  A. Maltsev, S.A. Mamon, B. Marianski, A. Martin, J. Marzec, J. Matousek, T.
  Matsuda, G. Mattson, G.V. Meshcheryakov, M. Meyer, W. Meyer, Yu.V. Mikhailov,
  M. Mikhasenko, E. Mitrofanov, N. Mitrofanov, Y. Miyachi, A. Moretti, A.
  Nagaytsev, C. Naim, D. Neyret, J. Novy, W.-D. Nowak, G. Nukazuka, A.S. Nunes,
  A.G. Olshevskiy, M. Ostrick, D. Panzieri, B. Parsamyan, S. Paul, H. Pekeler,
  J.-C. Peng, M. Pesek, D.V. Peshekhonov, M. Peskova, N. Pierre, S. Platchkov,
  J. Pochodzalla, V.A. Polyakov, J. Pretz, M. Quaresma, C. Quintans, G.
  Reicherz, C. Riedl, T. Rudnicki, D.I. Ryabchikov, A. Rybnikov, A. Rychter,
  V.D. Samoylenko, A. Sandacz, S. Sarkar, I.A. Savin, G. Sbrizzai, H.
  Schmieden, A. Selyunin, L. Sinha, M. Slunecka, J. Smolik, A. Srnka, D.
  Steffen, M. Stolarski, O. Subrt, M. Sulc, H. Suzuki, P. Sznajder, S. Tessaro,
  F. Tessarotto, A. Thiel, J. Tomsa, F. Tosello, A. Townsend, V. Tskhay, S.
  Uhl, B.I. Vasilishin, A. Vauth, B.M. Veit, J. Veloso, B. Ventura, A.Vidon, M.
  Virius, M. Wagner, S. Wallner, K. Zaremba, P. Zavada, M. Zavertyaev, M.
  Zemko, E. Zemlyanichkina, Y. Zhao, M. Ziembicki","Triangle Singularity as the Origin of the $a_1(1420)$","7 pages, 5 figures","Phys. Rev. Lett. 127, 082501 (2021)","10.1103/PhysRevLett.127.082501","CERN-EP-2020-104","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  The COMPASS experiment recently discovered a new isovector resonance-like
signal with axial-vector quantum numbers, the $a_1(1420)$, decaying to
$f_0(980)\pi$. With a mass too close to and a width smaller than the
axial-vector ground state $a_1(1260)$, it was immediately interpreted as a new
light exotic meson, similar to the $X$, $Y$, $Z$ states in the hidden-charm
sector. We show that a resonance-like signal fully matching the experimental
data is produced by the decay of the $a_1(1260)$ resonance into $K^\ast(\to
K\pi)\bar{K}$ and subsequent rescattering through a triangle singularity into
the coupled $f_0(980)\pi$ channel. The amplitude for this process is calculated
using a new approach based on dispersion relations. The triangle-singularity
model is fitted to the partial-wave data of the COMPASS experiment. Despite
having less parameters, this fit shows a slightly better quality than the one
using a resonance hypothesis and thus eliminates the need for an additional
resonance in order to describe the data. We thereby demonstrate for the first
time in the light-meson sector that a resonance-like structure in the
experimental data can be described by rescattering through a triangle
singularity, providing evidence for a genuine three-body effect.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:22:03 GMT""},{""version"":""v2"",""created"":""Sat, 2 Oct 2021 23:55:56 GMT""},{""version"":""v3"",""created"":""Fri, 10 Dec 2021 16:06:36 GMT""}]","2021-12-13"
"2006.05345","Jonas Krampe","Jonas Krampe and Efstathios Paparoditis","Statistical Estimation of High-Dimensional Vector Autoregressive Models",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-dimensional vector autoregressive (VAR) models are important tools for
the analysis of multivariate time series. This paper focuses on
high-dimensional time series and on the different regularized estimation
procedures proposed for fitting sparse VAR models to such time series.
Attention is paid to the different sparsity assumptions imposed on the VAR
parameters and how these sparsity assumptions are related to the particular
consistency properties of the estimators established. A sparsity scheme for
high-dimensional VAR models is proposed which is found to be more appropriate
for the time series setting considered. Furthermore, it is shown that, under
this sparsity setting, threholding extents the consistency properties of
regularized estimators to a wide range of matrix norms. Among other things,
this enables application of the VAR parameters estimators to different
inference problems, like forecasting or estimating the second-order
characteristics of the underlying VAR process. Extensive simulations compare
the finite sample behavior of the different regularized estimators proposed
using a variety of performance criteria.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:25:20 GMT""}]","2020-06-11"
"2006.05346","Che-Ming Li","Shih-Hsuan Chen, Meng-Lok Ng, Che-Ming Li","Quantifying entanglement preservability of experimental processes",,"Phys. Rev. A 104, 032403 (2021)","10.1103/PhysRevA.104.032403",,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Preserving entanglement is a crucial dynamical process for entanglement-based
quantum computation and quantum-information processes, such as one-way quantum
computing and quantum key distribution. However, the problem of quantifying the
ability of an experimental process to preserve two-qubit entanglement in
experimentally feasible ways is not well understood. Accordingly, herein, we
consider the use of two measures, namely composition and robustness, for
quantitatively characterizing the ability of a process to preserve
entanglement, referred to henceforth as entanglement preservability. A fidelity
benchmark is additionally derived to identify the ability of a process to
preserve entanglement. We show that the measures and introduced benchmark are
experimentally feasible and require only local measurements on single qubits
and preparations of separable states. Moreover, they are applicable to all
physical processes that can be described using the general theory of quantum
operations, e.g., qubit dynamics in photonic and superconducting systems. Our
method extends the existing tools for analyzing channels, e.g., channel
resource theory, to quantify entanglement preservability for
non-trace-preserving quantum processes. The results are of significant interest
for applications in quantum-information processing in which entanglement
preservation is required.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:28:30 GMT""},{""version"":""v2"",""created"":""Sat, 25 Jul 2020 13:19:43 GMT""},{""version"":""v3"",""created"":""Mon, 19 Jul 2021 06:48:18 GMT""},{""version"":""v4"",""created"":""Thu, 9 Sep 2021 06:39:00 GMT""}]","2021-09-10"
"2006.05347","Cunhua Pan","Gui Zhou, Cunhua Pan, Hong Ren, Kezhi Wang, Kok Keong Chai, and
  Kai-Kit Wong","User Cooperation for IRS-aided Secure SWIPT MIMO Systems","Intelligent reflecting surface (IRS), reconfigurable intelligent
  surface (RIS), robust design, energy harvesting, physical layer security",,,,"eess.SP cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, intelligent reflecting surface (IRS) is proposed to enhance
the physical layer security in the Rician fading channel where the angular
direction of the eavesdropper is aligned with a legitimate user. In this
scenario, we consider a two-phase communication system under the active attacks
and passive eavesdropping. Particularly, in the first phase, the base station
avoids direct transmission to the attacked user. While, in the second phase,
other users cooperate to forward signals to the attacked user with the help of
IRS and energy harvesting technology. Under the active attacks, we investigate
an outage constrained beamforming design problem under the statistical cascaded
channel error model, which is solved by using the Bernstein-type inequality. As
for the passive eavesdropping, an average secrecy rate maximization problem is
formulated, which is addressed by a low complexity algorithm. Numerical results
show that the negative effect of the eavesdropper's channel error is greater
than that of the legitimate user.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:28:31 GMT""},{""version"":""v2"",""created"":""Mon, 15 Jun 2020 01:58:00 GMT""},{""version"":""v3"",""created"":""Mon, 28 Jun 2021 08:18:00 GMT""}]","2021-06-29"
"2006.05351","Hao Yang","Hao Yang, Zi-Qiang Chen and Cong-Feng Qiao","NLO QCD corrections to $J/\psi$ pair production in photon-photon
  collision",,,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate the next-to-leading order (NLO) quantum chromodynamics (QCD)
correction to the exclusive process $\gamma+\gamma\to J/\psi+J/\psi$ in the
framework of non-relativistic QCD (NRQCD) factorization formalism. The cross
sections at the SuperKEKB electron-positron collider, as well as at the future
colliders, like the Circular Electron Positron Collider (CEPC) and the
International Linear Collider (ILC), are evaluated. Numerical result indicates
that the process will be hopefully to be seen by the Belle II detector within
the next decade.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:31:13 GMT""}]","2020-06-11"
"2006.05352","Alireza Khadem","Alireza Khadem","Design Challenges of Neural Network Acceleration Using Stochastic
  Computing",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The enormous and ever-increasing complexity of state-of-the-art neural
networks (NNs) has impeded the deployment of deep learning on resource-limited
devices such as the Internet of Things (IoTs). Stochastic computing exploits
the inherent amenability to approximation characteristic of NNs to reduce their
energy and area footprint, two critical requirements of small embedded devices
suitable for the IoTs. This report evaluates and compares two recently proposed
stochastic-based NN designs, referred to as BISC (Binary Interfaced Stochastic
Computing) by Sim and Lee, 2017, and ESL (Extended Stochastic Logic) by Canals
et al., 2016. Using analysis and simulation, we compare three distinct
implementations of these designs in terms of performance, power consumption,
area, and accuracy. We also discuss the overall challenges faced in adopting
stochastic computing for building NNs. We find that BISC outperforms the other
architectures when executing the LeNet-5 NN model applied to the MNIST digit
recognition dataset. Our analysis and simulation experiments indicate that this
architecture is around 50X faster, occupies 5.7X and 2.9X less area, and
consumes 7.8X and 1.8X less power than the two ESL architectures.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:06:56 GMT""}]","2020-06-11"
"2006.05353","Alon Lahav","Alon Lahav, Ayellet Tal","MeshWalker: Deep Mesh Understanding by Random Walks",,,,,"cs.CV cs.CG cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most attempts to represent 3D shapes for deep learning have focused on
volumetric grids, multi-view images and point clouds. In this paper we look at
the most popular representation of 3D shapes in computer graphics - a
triangular mesh - and ask how it can be utilized within deep learning. The few
attempts to answer this question propose to adapt convolutions & pooling to
suit Convolutional Neural Networks (CNNs). This paper proposes a very different
approach, termed MeshWalker, to learn the shape directly from a given mesh. The
key idea is to represent the mesh by random walks along the surface, which
""explore"" the mesh's geometry and topology. Each walk is organized as a list of
vertices, which in some manner imposes regularity on the mesh. The walk is fed
into a Recurrent Neural Network (RNN) that ""remembers"" the history of the walk.
We show that our approach achieves state-of-the-art results for two fundamental
shape analysis tasks: shape classification and semantic segmentation.
Furthermore, even a very small number of examples suffices for learning. This
is highly important, since large datasets of meshes are difficult to acquire.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:35:41 GMT""},{""version"":""v2"",""created"":""Wed, 30 Sep 2020 05:39:22 GMT""},{""version"":""v3"",""created"":""Thu, 10 Dec 2020 15:39:51 GMT""}]","2020-12-11"
"2006.05354","Vladislav Tretyak","Vladislav Tretyak, Denis Stepanov","Combination of abstractive and extractive approaches for summarization
  of long scientific texts","11 pages, 2 figures, 3 table, submitted to 23rd International
  Conference on Discovery Science. Fixed authors list",,,,"cs.CL","http://creativecommons.org/publicdomain/zero/1.0/","  In this research work, we present a method to generate summaries of long
scientific documents that uses the advantages of both extractive and
abstractive approaches. Before producing a summary in an abstractive manner, we
perform the extractive step, which then is used for conditioning the abstractor
module. We used pre-trained transformer-based language models, for both
extractor and abstractor. Our experiments showed that using extractive and
abstractive models jointly significantly improves summarization results and
ROUGE scores.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:38:21 GMT""},{""version"":""v2"",""created"":""Fri, 12 Jun 2020 11:25:21 GMT""}]","2020-06-15"
"2006.05355","Erdem Akag\""und\""uz","Alper Kaplan and Erdem Akagunduz","A Hybrid Framework for Matching Printing Design Files to Product Photos",,"published in Balkan Journal of Electrical and Computer
  Engineering, Volume 8 - Issue 2 - Apr 30, 2020",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a real-time image matching framework, which is hybrid in the sense
that it uses both hand-crafted features and deep features obtained from a
well-tuned deep convolutional network. The matching problem, which we
concentrate on, is specific to a certain application, that is, printing design
to product photo matching. Printing designs are any kind of template image
files, created using a design tool, thus are perfect image signals. However,
photographs of a printed product suffer many unwanted effects, such as
uncontrolled shooting angle, uncontrolled illumination, occlusions, printing
deficiencies in color, camera noise, optic blur, et cetera. For this purpose,
we create an image set that includes printing design and corresponding product
photo pairs with collaboration of an actual printing facility. Using this image
set, we benchmark various hand-crafted and deep features for matching
performance and propose a framework in which deep learning is utilized with
highest contribution, but without disabling real-time operation using an
ordinary desktop computer.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:39:14 GMT""}]","2020-06-11"
"2006.05356","Sattar Vakili","Sattar Vakili, Henry Moss, Artem Artemev, Vincent Dutordoir, Victor
  Picheny","Scalable Thompson Sampling using Sparse Gaussian Process Models",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Thompson Sampling (TS) from Gaussian Process (GP) models is a powerful tool
for the optimization of black-box functions. Although TS enjoys strong
theoretical guarantees and convincing empirical performance, it incurs a large
computational overhead that scales polynomially with the optimization budget.
Recently, scalable TS methods based on sparse GP models have been proposed to
increase the scope of TS, enabling its application to problems that are
sufficiently multi-modal, noisy or combinatorial to require more than a few
hundred evaluations to be solved. However, the approximation error introduced
by sparse GPs invalidates all existing regret bounds. In this work, we perform
a theoretical and empirical analysis of scalable TS. We provide theoretical
guarantees and show that the drastic reduction in computational complexity of
scalable TS can be enjoyed without loss in the regret performance over the
standard TS. These conceptual claims are validated for practical
implementations of scalable TS on synthetic benchmarks and as part of a
real-world high-throughput molecular design task.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:42:10 GMT""},{""version"":""v2"",""created"":""Mon, 24 Aug 2020 15:41:43 GMT""},{""version"":""v3"",""created"":""Mon, 7 Jun 2021 22:30:05 GMT""},{""version"":""v4"",""created"":""Fri, 5 Nov 2021 12:08:31 GMT""}]","2021-11-08"
"2006.05357","Tomas Veloz","Tomas Veloz, Pedro Maldonado, Samuel Ropert, Cesar Ravello, Soraya
  Mora, Alejandra Barrios, Tomas Villaseca, Cesar Valdenegro, Tomas Perez-Acle","On the interplay between mobility and hospitalization capacity during
  the COVID-19 pandemic: The SEIRHUD model",,,,,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measures to reduce the impact of the COVID-19 pandemic require a mix of
logistic, political and social capacity. Depending on the country, different
approaches to increase hospitalization capacity or to properly apply lock-downs
are observed. In order to better understand the impact of these measures we
have developed a compartmental model which, on the one hand allows to calibrate
the reduction of movement of people within and among different areas, and on
the other hand it incorporates a hospitalization dynamics that differentiates
the available kinds of treatment that infected people can receive. By bounding
the hospitalization capacity, we are able to study in detail the interplay
between mobility and hospitalization capacity.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:42:51 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 02:34:19 GMT""}]","2020-06-12"
"2006.05358","Guido Martinelli","A. Desiderio, R. Frezzotti, M.Garofalo, D. Giusti, M. Hansen, V.
  Lubicz, G.Martinelli, C.T. Sachrajda, F. Sanfilippo, S.Simula, N.Tantalo","First lattice calculation of radiative leptonic decay rates of
  pseudoscalar mesons","46 pages, 12 figures","Phys. Rev. D 103, 014502 (2021)","10.1103/PhysRevD.103.014502",,"hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a non-perturbative lattice calculation of the form factors which
contribute to the amplitudes for the radiative decays $P\to \ell \bar \nu_\ell
\gamma$, where $P$ is a pseudoscalar meson and $\ell$ is a charged lepton.
Together with the non-perturbative determination of the corrections to the
processes $P\to \ell \bar \nu_\ell$ due to the exchange of a virtual photon,
this allows accurate predictions at $O(\alpha_{em})$ to be made for leptonic
decay rates for pseudoscalar mesons ranging from the pion to the $D_s$ meson.
We are able to separate unambiguously and non-pertubatively the point-like
contribution, from the structure-dependent, infrared-safe, terms in the
amplitude. The fully non-perturbative $O(a)$ improved calculation of the
inclusive leptonic decay rates will lead to the determination of the
corresponding Cabibbo-Kobayashi-Maskawa (CKM) matrix elements also at
$O(\alpha_{em})$. Prospects for a precise evaluation of leptonic decay rates
with emission of a hard photon are also very interesting, especially for the
decays of heavy $D$ and $B$ mesons for which currently only model-dependent
predictions are available to compare with existing experimental data.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:46:00 GMT""}]","2021-01-13"
"2006.05359","Carlos Maciel","C. Maciel-Escudero, Andrea Kone\v{c}n\'a, Rainer Hillenbrand, Javier
  Aizpurua","Probing and steering bulk and surface phonon polaritons in uniaxial
  materials using fast electrons: hexagonal boron nitride",,"Phys. Rev. B 102, 115431 (2020)","10.1103/PhysRevB.102.115431",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically describe how fast electrons couple to polaritonic modes in
uniaxial materials by analyzing the electron energy loss (EEL) spectra. We show
that in the case of an uniaxial medium with hyperbolic dispersion, bulk and
surface modes can be excited by a fast electron traveling through the volume or
along an infinite interface between the material and vacuum. Interestingly, and
in contrast to the excitations in isotropic materials, bulk modes can be
excited by fast electrons traveling outside the uniaxial medium. We demonstrate
our findings with the representative uniaxial material hexagonal boron nitride.
We show that the excitation of bulk and surface phonon polariton modes is
strongly related to the electron velocity and highly dependent on the angle
between the electron beam trajectory and the optical axis of the material. Our
work provides a systematic study for understanding bulk and surface polaritons
excited by a fast electron beam in hyperbolic materials and sets a way to steer
and control the propagation of the polaritonic waves by changing the electron
velocity and its direction.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:46:01 GMT""}]","2020-09-30"
"2006.05360","Alisa Rupenyan","Markus Maier, Alisa Rupenyan, Christian Bobst, and Konrad Wegener","Self-Optimizing Grinding Machines using Gaussian Process Models and
  Constrained Bayesian Optimization","12 pages, 10 figures, accepted in The International Journal of
  Advanced Manufacturing Technology, 2020",,"10.1007/s00170-020-05369-9",,"eess.SY cs.SY physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, self-optimization of a grinding machine is demonstrated with
respect to production costs, while fulfilling quality and safety constraints.
The quality requirements of the final workpiece are defined with respect to
grinding burn and surface roughness, and the safety constraints are defined
with respect to the temperature at the grinding surface. Grinding temperature
is measured at the contact zone between the grinding wheel and workpiece using
a pyrometer and an optical fiber, which is embedded inside the rotating
grinding wheel. Constrained Bayesian optimization combined with Gaussian
process models is applied to determine the optimal feed rate and cutting speed
of a cup wheel grinding machine manufacturing tungsten carbide cutting inserts.
The approach results in the determination of optimal parameters for unknown
workpiece and tool combinations after only a few grinding trials. It also
incorporates the uncertainty of the constraints in the prediction of optimal
parameters by using stochastic process models.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:47:03 GMT""}]","2020-06-11"
"2006.05361","Francesco De Vita","Francesco De Vita and Filippo De Lillo and Roberto Verzicco and Miguel
  Onorato","A fully Eulerian solver for the simulation of multiphase flows with
  solid bodies: application to surface gravity waves",,,"10.1016/j.jcp.2021.110355",,"physics.flu-dyn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper a fully Eulerian solver for the study of multiphase flows for
simulating the propagation of surface gravity waves over submerged bodies is
presented. We solve the incompressible Navier-Stokes equations coupled with the
volume of fluid technique for the modeling of the liquid phases with the
interface, an immersed body method for the solid bodies and an iterative
strong-coupling procedure for the fluid-structure interaction. The flow
incompressibility is enforced via the solution of a Poisson equation which,
owing to the density jump across the interfaces of the liquid phases, has to
resort to the splitting procedure of Dodd & Ferrante [12]. The solver is
validated through comparisons against classical test cases for fluid-structure
interaction like migration of particles in pressure-driven channel, multiphase
flows, water exit of a cylinder and a good agreement is found for all tests.
Furthermore, we show the application of the solver to the case of a surface
gravity wave propagating over a submerged reversed pendulum and verify that the
solver can reproduce the energy exchange between the wave and the pendulum.
Finally the three-dimensional spilling breaking of a wave induced by a
submerged sphere is considered.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:49:20 GMT""}]","2021-06-02"
"2006.05362","Manuel Rivera","Manuel Rivera, Felix Wierstra, Mahmoud Zeinalian","The simplicial coalgebra of chains determines homotopy types rationally
  and one prime at a time","Minor revisions were made to this version to improve the
  presentation. To appear in Transactions of the American Mathematical Society",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the simplicial cocommutative coalgebra of singular chains on a
connected topological space determines the homotopy type rationally and one
prime at a time, without imposing any restriction on the fundamental group. In
particular, the fundamental group and the homology groups with coefficients in
arbitrary local systems of vector spaces are completely determined by the
natural algebraic structure of the chains. The algebraic structure is presented
as the class of the simplicial cocommutative coalgebra of chains under a notion
of weak equivalence induced by a functor from coalgebras to algebras coined by
Adams as the cobar construction. The fundamental group is determined by a
quadratic equation on the zeroth homology of the cobar construction of the
normalized chains which involves Steenrod's chain homotopies for
cocommutativity of the coproduct. The homology groups with local coefficients
are modeled by an algebraic analog of the universal cover which is invariant
under our notion of weak equivalence. We conjecture that the integral homotopy
type is also determined by the simplicial coalgebra of integral chains, which
we prove when the universal cover is of finite type.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:49:21 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 15:06:31 GMT""},{""version"":""v3"",""created"":""Thu, 7 Oct 2021 04:01:05 GMT""}]","2021-10-08"
"2006.05363","Nikita Kondratiev","Ramzil R. Galiev and Nikita M. Kondratiev and Valery E. Lobanov and
  Andrey B. Matsko and Igor A. Bilenko","Optimization of laser stabilization via self-injection locking to WGM
  microresonator",,"Phys. Rev. Applied 14, 014036 (2020)","10.1103/PhysRevApplied.14.014036",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-injection locking is a dynamic phenomenon representing stabilization of
the emission frequency of an oscillator with a passive cavity enabling
frequency filtered coherent feedback to the oscillator cavity. For instance,
self-injection locking of a semiconductor laser to a high-quality-factor
(high-Q) whispering gallery mode (WGM) microresonator can result in multiple
orders of magnitude reduction of the laser linewidth. The phenomenon was
broadly studied in experiments, but its detailed theoretical model allowing
improving the stabilization performance does not exist. In this paper we
develop such a theory. We introduce five parameters identifying efficiency of
the self-injection locking in an experiment, comprising back-scattering
efficiency, phase delay between the laser and the high-Q cavities, frequency
detuning between the laser and the high-Q cavities, the pump coupling
efficiency, the optical path length between the laser and the microresonator.
Our calculations show that the laser linewidth can be improved by two orders of
magnitude compared with the case of not optimal self-injection locking. We
present recommendations on the experimental realization of the optimal
self-injection locking regime. The theoretical model provides deeper
understanding of the self-injection locking and benefits multiple practical
applications of self-injection locked oscillators.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:50:19 GMT""}]","2020-07-22"
"2006.05364","Ossi Niemim\""aki","Ossi Niemim\""aki","Current Groups and the Hamiltonian Anomaly","104 pages. Doctoral dissertation presented to the Faculty of Science
  of the University of Helsinki. The University of Helsinki digital copy
  available here: http://urn.fi/URN:ISBN:978-951-51-5977-9",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gauge symmetry invariance is an indispensable aspect of the field-theoretic
models in classical and quantum physics. Geometrically this symmetry is often
modelled with current groups and current algebras, which are used to capture
both the idea of gauge invariance and the algebraic structure of gauge currents
related to the symmetry.
  The Hamiltonian anomaly is a well-known problem in the quantisation of
massless fermion fields, originally manifesting as additional terms in current
algebra commutators. The appearance of these anomalous terms is a signal of two
things: that the gauge invariance of quantised Hamiltonian operators is broken,
and that consequently it is not possible to coherently define a vacuum state
over the physical configuration space of equivalent gauge connections.
  In this thesis we explore the geometric and topological origins of the
Hamiltonian anomaly, emphasising the usefulness of higher geometric structures.
Given this context we also discuss higher versions of the gauge-theoretic
current groups. These constructions are partially motivated by the $2$-group
models of the abstract string group, and we extend some of these ideas to
current groups on the three-sphere $S^3$.
  The study of the Hamiltonian anomaly utilises a wide variety of tools from
such fields as differential geometry, group cohomology, and operator K-theory.
We gather together many of these approaches and apply them in the standard case
involving the time components of the gauge currents. We then proceed to extend
the analysis to the general case with all space-time components. We show how
the anomaly terms for these generalised current algebra commutators are derived
from the same topological foundations; namely, from the Dixmier-Douady class of
the anomalous bundle gerbe. As an example we then compute the full set of
anomalous commutators for the three-sphere $S^3$ as the physical space.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:50:43 GMT""}]","2020-06-11"
"2006.05365","Rachid Riad","Rachid Riad and Hadrien Titeux and Laurie Lemoine and Justine
  Montillot and Jennifer Hamet Bagnou and Xuan Nga Cao and Emmanuel Dupoux and
  Anne-Catherine Bachoud-L\'evi","Vocal markers from sustained phonation in Huntington's Disease","To appear at INTERSPEECH 2020. 1 pages of supplementary material
  appear only in the arxiv version. Code to replicate
  https://github.com/bootphon/sustained-phonation-features",,,,"eess.AS cs.CL cs.SD","http://creativecommons.org/licenses/by/4.0/","  Disease-modifying treatments are currently assessed in neurodegenerative
diseases. Huntington's Disease represents a unique opportunity to design
automatic sub-clinical markers, even in premanifest gene carriers. We
investigated phonatory impairments as potential clinical markers and propose
them for both diagnosis and gene carriers follow-up. We used two sets of
features: Phonatory features and Modulation Power Spectrum Features. We found
that phonation is not sufficient for the identification of sub-clinical
disorders of premanifest gene carriers. According to our regression results,
Phonatory features are suitable for the predictions of clinical performance in
Huntington's Disease.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:51:28 GMT""},{""version"":""v2"",""created"":""Sun, 26 Jul 2020 07:29:55 GMT""},{""version"":""v3"",""created"":""Fri, 31 Jul 2020 13:20:04 GMT""}]","2020-08-03"
"2006.05366","Artemis Chaleplioglou","Artemis Chaleplioglou and Daphne Kyriaki-Manessi","Comparison of Citations Trends between the COVID-19 Pandemic and
  SARS-CoV, MERS-CoV, Ebola, Zika, Avian and Swine Influenza Epidemics","28 pages, 6 figures",,,,"cs.DL physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Objective: The novel coronavirus COVID-19 outbreak rapidly evolved into
pandemic. Global research efforts focus on this topic and with the
collaboration of the scientific journals publication industry produced more
than 16,000 related published articles in PubMed within five months from the
onset of the outbreak. Herein, a comparison of the COVID-19 citations in PubMed
and Web of Science was performed with SARS-CoV, MERS-CoV, Ebola, Zika, avian
and swine influenza epidemics. Methods: The citations were searched and
collected using the disease terms and the date of publication restriction. The
total number of PubMed citations and the HIV associated papers during the same
chronological periods were examined in parallel. The journal category and
country information of the publications were gathered from Web of Science. The
collected data were statistically analyzed and compared. Results: Significant
correlations were found between COVID-19 and MERS (CC=0.988; p=0.003; q=0.006),
Ebola (CC=0.987; p=0.003; q=0.011), and SARS (CC=0.964; p=0.015; q=0.028)
epidemics five-month pick of novel citations in PubMed. However, COVID-19
publications were accumulated earlier and in larger numbers than any other 21st
century major communicable disease outbreak. Conclusion: The acceleration and
the total number of COVID-19 publications represent an unprecedented landmark
event in the medical library history. The immediate adoption of the fast-track
peer-reviewing and publishing as well as the open access publication policies
by the journal publishers are significant contributors to this bibliographic
phenomenon.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:51:35 GMT""}]","2020-06-11"
"2006.05504","Clement de Chaisemartin","Cl\'ement de Chaisemartin, Luc de Chaisemartin","BCG vaccination in infancy does not protect against COVID-19. Evidence
  from a natural experiment in Sweden",,,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Bacille Calmette-Gu\'erin (BCG) tuberculosis vaccine has immunity
benefits against respiratory infections. Accordingly, it has been hypothesized
that it may have a protective effect against COVID-19. Recent research found
that countries with universal Bacillus Calmette-Gu\'erin (BCG) childhood
vaccination policies tend to be less affected by the COVID-19 pandemic.
However, such ecological studies are biased by numerous confounders. Instead,
this paper takes advantage of a rare nationwide natural experiment that took
place in Sweden in 1975, where discontinuation of newborns BCG vaccination led
to a dramatic fall of the BCG coverage rate from 92% to 2% , thus allowing us
to estimate the BCG's effect without all the biases associated with
cross-country comparisons. Numbers of COVID-19 cases and hospitalizations were
recorded for birth cohorts born just before and just after that change,
representing 1,026,304 and 1,018,544 individuals, respectively. We used
regression discontinuity to assess the effect of BCG vaccination on Covid-19
related outcomes. This method used on such a large population allows for a high
precision that would be hard to achieve using a classical randomized controlled
trial. The odds ratio for Covid-19 cases and Covid-19 related hospitalizations
were 0.9997 (CI95: [0.8002-1.1992]) and 1.1931 (CI95: [0.7558-1.6304]),
respectively. We can thus reject with 95\% confidence that universal BCG
vaccination reduces the number of cases by more than 20% and the number of
hospitalizations by more than 24%. While the effect of a recent vaccination
must be evaluated, we provide strong evidence that receiving the BCG vaccine at
birth does not have a protective effect against COVID-19.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:41:13 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 23:50:43 GMT""}]","2020-06-24"
"2006.06433","Boris Sauterey","Boris Sauterey, Benjamin Charnay, Antonin Affholder, St\'ephane
  Mazevet, R\'egis Ferri\`ere","Coevolution of primitive methane cycling ecosystems and early Earth
  atmosphere and climate","32 pages, 5 figures, 1 tables, 12 Supplementary figures, published in
  Nature Communications","Nat. Commun. 11, 2705 (2020)","10.1038/s41467-020-16374-7",,"q-bio.PE astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The history of the Earth has been marked by major ecological transitions,
driven by metabolic innovation, that radically reshaped the composition of the
oceans and atmosphere. The nature and magnitude of the earliest transitions,
hundreds of million years before photosynthesis evolved, remain poorly
understood. Using a novel ecosystem-planetary model, we find that
pre-photosynthetic methane-cycling microbial ecosystems are much less
productive than previously thought. In spite of their low productivity, the
evolution of methanogenic metabolisms strongly modifies the atmospheric
composition, leading to a warmer but less resilient climate. As the abiotic
carbon cycle responds, further metabolic evolution (anaerobic methanotrophy)
may feed back to the atmosphere and destabilize the climate, triggering a
transient global glaciation. Although early metabolic evolution may cause
strong climatic instability, a low CO:CH4 atmospheric ratio emerges as a robust
signature of simple methane-cycling ecosystems on a globally reduced planet
such as the late Hadean/early Archean Earth.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:02:55 GMT""}]","2020-06-12"
"2006.06435","Pietro Barbiero","Pietro Barbiero and Pietro Li\'o","The Computational Patient has Diabetes and a COVID","37 pages",,,,"cs.CE q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Medicine is moving from a curative discipline to a preventative discipline
relying on personalised and precise treatment plans. The complex and multi
level pathophysiological patterns of most diseases require a systemic medicine
approach and are challenging current medical therapies. On the other hand,
computational medicine is a vibrant interdisciplinary field that could help
move from an organ-centered approach to a process-oriented approach. The ideal
computational patient would require an international interdisciplinary effort,
of larger scientific and technological interdisciplinarity than the Human
Genome Project. When deployed, such a patient would have a profound impact on
how healthcare is delivered to patients. Here we present a computational
patient model that integrates, refines and extends recent mechanistic or
phenomenological models of cardiovascular, RAS and diabetic processes. Our aim
is twofold: analyse the modularity and composability of the model-building
blocks of the computational patient and to study the dynamical properties of
well-being and disease states in a broader functional context. We present
results from a number of experiments among which we characterise the dynamic
impact of COVID-19 and type-2 diabetes (T2D) on cardiovascular and inflammation
conditions. We tested these experiments under different exercise, meal and drug
regimens. We report results showing the striking importance of transient
dynamical responses to acute state conditions and we provide guidelines for
system design principles for the inter-relationship between modules and
components in systemic medicine. Finally this initial computational Patient can
be used as a toolbox for further modifications and extensions.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 07:08:07 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 08:33:14 GMT""},{""version"":""v3"",""created"":""Sat, 18 Jul 2020 19:41:34 GMT""}]","2020-07-21"
"2006.06444","Caelan Garrett","Zi Wang, Caelan Reed Garrett, Leslie Pack Kaelbling, and Tom\'as
  Lozano-P\'erez","Learning compositional models of robot skills for task and motion
  planning","First two authors contributed equally. arXiv admin note: text overlap
  with arXiv:1803.00967","The International Journal of Robotics Research (IJRR), 2020",,,"cs.RO cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The objective of this work is to augment the basic abilities of a robot by
learning to use sensorimotor primitives to solve complex long-horizon
manipulation problems. This requires flexible generative planning that can
combine primitive abilities in novel combinations and thus generalize across a
wide variety of problems. In order to plan with primitive actions, we must have
models of the actions: under what circumstances will executing this primitive
successfully achieve some particular effect in the world?
  We use, and develop novel improvements on, state-of-the-art methods for
active learning and sampling. We use Gaussian process methods for learning the
constraints on skill effectiveness from small numbers of expensive-to-collect
training examples. Additionally, we develop efficient adaptive sampling methods
for generating a comprehensive and diverse sequence of continuous candidate
control parameter values (such as pouring waypoints for a cup) during planning.
These values become end-effector goals for traditional motion planners that
then solve for a full robot motion that performs the skill. By using learning
and planning methods in conjunction, we take advantage of the strengths of each
and plan for a wide variety of complex dynamic manipulation tasks. We
demonstrate our approach in an integrated system, combining traditional
robotics primitives with our newly learned models using an efficient robot task
and motion planner. We evaluate our approach both in simulation and in the real
world through measuring the quality of the selected primitive actions. Finally,
we apply our integrated system to a variety of long-horizon simulated and
real-world manipulation problems.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:45:34 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 03:00:32 GMT""}]","2021-05-06"
"2006.06445","Stephane Ouvry","St\'ephane Ouvry and Alexios Polychronakos","Lattice walk area combinatorics, some remarkable trigonometric sums and
  Ap\'ery-like numbers","31 pages, 4 figures",,,,"math-ph cond-mat.stat-mech hep-th math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Explicit algebraic area enumeration formulae are derived for various lattice
walks generalizing the canonical square lattice walk, and in particular for the
triangular lattice chiral walk recently introduced by the authors. A key
element in the enumeration is the derivation of some remarkable identities
involving trigonometric sums --which are also important building blocks of non
trivial quantum models such as the Hofstadter model-- and their explicit
rewriting in terms of multiple binomial sums. An intriguing connection is also
made with number theory and some classes of Ap\'ery-like numbers, the cousins
of the Ap\'ery numbers which play a central role in irrationality
considerations for {\zeta}(2) and {\zeta}(3).
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:01 GMT""}]","2020-06-15"
"2006.06446","Nicola Perra","Nicol\`o Gozzi, Michele Tizzani, Michele Starnini, Fabio Ciulla,
  Daniela Paolotti, Andr\'e Panisson, Nicola Perra","Collective response to the media coverage of COVID-19 Pandemic on Reddit
  and Wikipedia",,,,,"cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exposure and consumption of information during epidemic outbreaks may
alter risk perception, trigger behavioural changes, and ultimately affect the
evolution of the disease. It is thus of the uttermost importance to map
information dissemination by mainstream media outlets and public response.
However, our understanding of this exposure-response dynamic during COVID-19
pandemic is still limited. In this paper, we provide a characterization of
media coverage and online collective attention to COVID-19 pandemic in four
countries: Italy, United Kingdom, United States, and Canada. For this purpose,
we collect an heterogeneous dataset including 227,768 online news articles and
13,448 Youtube videos published by mainstream media, 107,898 users posts and
3,829,309 comments on the social media platform Reddit, and 278,456,892 views
to COVID-19 related Wikipedia pages. Our results show that public attention,
quantified as users activity on Reddit and active searches on Wikipedia pages,
is mainly driven by media coverage and declines rapidly, while news exposure
and COVID-19 incidence remain high. Furthermore, by using an unsupervised,
dynamical topic modeling approach, we show that while the attention dedicated
to different topics by media and online users are in good accordance,
interesting deviations emerge in their temporal patterns. Overall, our findings
offer an additional key to interpret public perception/response to the current
global health emergency and raise questions about the effects of attention
saturation on collective awareness, risk perception and thus on tendencies
towards behavioural changes.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:10:13 GMT""}]","2020-06-12"
"2006.06480","Bilge Celik","Bilge Celik and Joaquin Vanschoren","Adaptation Strategies for Automated Machine Learning on Evolving Data","12 pages, 7 figures (14 counting subfigures), submitted to TPAMI -
  AutoML Special Issue",,"10.1109/TPAMI.2021.3062900",,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automated Machine Learning (AutoML) systems have been shown to efficiently
build good models for new datasets. However, it is often not clear how well
they can adapt when the data evolves over time. The main goal of this study is
to understand the effect of data stream challenges such as concept drift on the
performance of AutoML methods, and which adaptation strategies can be employed
to make them more robust. To that end, we propose 6 concept drift adaptation
strategies and evaluate their effectiveness on different AutoML approaches. We
do this for a variety of AutoML approaches for building machine learning
pipelines, including those that leverage Bayesian optimization, genetic
programming, and random search with automated stacking. These are evaluated
empirically on real-world and synthetic data streams with different types of
concept drift. Based on this analysis, we propose ways to develop more
sophisticated and robust AutoML techniques.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:29:16 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jan 2021 13:07:27 GMT""},{""version"":""v3"",""created"":""Tue, 10 May 2022 08:52:36 GMT""}]","2022-05-11"
"2006.06523","Nazim Medzhidov","Romeo Cozac (1), Nazim Medzhidov (1) and Shinya Yuki (1) ((1) Elix,
  Inc., Tokyo, Japan)","Predicting inhibitors for SARS-CoV-2 RNA-dependent RNA polymerase using
  machine learning and virtual screening","12 pages, 5 tables",,,,"q-bio.QM q-bio.BM","http://creativecommons.org/licenses/by/4.0/","  Global coronavirus disease pandemic (COVID-19) caused by newly identified
SARS- CoV-2 coronavirus continues to claim the lives of thousands of people
worldwide. The unavailability of specific medications to treat COVID-19 has led
to drug repositioning efforts using various approaches, including computational
analyses. Such analyses mostly rely on molecular docking and require the 3D
structure of the target protein to be available. In this study, we utilized a
set of machine learning algorithms and trained them on a dataset of
RNA-dependent RNA polymerase (RdRp) inhibitors to run inference analyses on
antiviral and anti-inflammatory drugs solely based on the ligand information.
We also performed virtual screening analysis of the drug candidates predicted
by machine learning models and docked them against the active site of SARS-
CoV-2 RdRp, a key component of the virus replication machinery. Based on the
ligand information of RdRp inhibitors, the machine learning models were able to
identify candidates such as remdesivir and baloxavir marboxil, molecules with
documented activity against RdRp of the novel coronavirus. Among the other
identified drug candidates were beclabuvir, a non-nucleoside inhibitor of the
hepatitis C virus (HCV) RdRp enzyme, and HCV protease inhibitors paritaprevir
and faldaprevir. Further analysis of these candidates using molecular docking
against the SARS-CoV-2 RdRp revealed low binding energies against the enzyme
active site. Our approach also identified anti-inflammatory drugs lupeol,
lifitegrast, antrafenine, betulinic acid, and ursolic acid to have potential
activity against SARS-CoV-2 RdRp. We propose that the results of this study are
considered for further validation as potential therapeutic options against
COVID-19.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 11:58:22 GMT""}]","2020-06-12"
"2006.06530","Rodrigo Veiga","Rodrigo Veiga, Rodrigo Murta, Renato Vicente","Age-structured estimation of COVID-19 ICU demand from low quality data","6 pages, 3 figures, 4 tables. Code available at
  https://github.com/rodsveiga/ICU_demand",,,,"physics.soc-ph q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We sample aggravated cases following age-structured probabilities from
confirmed cases and use ICU occupation data to find a subnotification factor. A
logistic fit is then employed to project the progression of the COVID-19
epidemic with plateau scenarios taken from locations that have reached this
stage. Finally, the logistic curve found is corrected by the subnotification
factor and sampled to project the future demand for ICU beds.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:39:20 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 00:22:41 GMT""}]","2020-06-17"
"2006.06531","Abtin Riasatian","Abtin Riasatian, Maral Rasoolijaberi, Morteza Babaei, H.R. Tizhoosh","A Comparative Study of U-Net Topologies for Background Removal in
  Histopathology Images","Accepted at International Joint Conference on Neural Networks
  (IJCNN), 2020",,,,"eess.IV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the last decade, the digitization of pathology has gained considerable
momentum. Digital pathology offers many advantages including more efficient
workflows, easier collaboration as well as a powerful venue for telepathology.
At the same time, applying Computer-Aided Diagnosis (CAD) on Whole Slide Images
(WSIs) has received substantial attention as a direct result of the
digitization. The first step in any image analysis is to extract the tissue.
Hence, background removal is an essential prerequisite for efficient and
accurate results for many algorithms. In spite of the obvious discrimination
for human operators, the identification of tissue regions in WSIs could be
challenging for computers, mainly due to the existence of color variations and
artifacts. Moreover, some cases such as alveolar tissue types, fatty tissues,
and tissues with poor staining are difficult to detect. In this paper, we
perform experiments on U-Net architecture with different network backbones
(different topologies) to remove the background as well as artifacts from WSIs
in order to extract the tissue regions. We compare a wide range of backbone
networks including MobileNet, VGG16, EfficientNet-B3, ResNet50, ResNext101 and
DenseNet121. We trained and evaluated the network on a manually labeled subset
of The Cancer Genome Atlas (TCGA) Dataset. EfficientNet-B3 and MobileNet by
almost 99% sensitivity and specificity reached the best results.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:41:44 GMT""}]","2020-06-12"
"2006.06538","Cherry Ng","C. Ng, A. Pandhi, A. Naidu, E. Fonseca, V. M. Kaspi, K. W. Masui, R.
  Mckinven, A. Renard, P. Scholz, I. H. Stairs, S. P. Tendulkar, K. Vanderlinde","Faraday rotation measures of northern-hemisphere pulsars using
  CHIME/Pulsar","13 pages, 7 figures, accepted by MNRAS",,"10.1093/mnras/staa1658",,"astro-ph.IM astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using commissioning data from the first year of operation of the Canadian
Hydrogen Intensity Mapping Experiment's (CHIME) Pulsar backend system, we
conduct a systematic analysis of the Faraday Rotation Measure (RM) of the
northern hemisphere pulsars detected by CHIME. We present 55 new RMs as well as
obtain improved RM uncertainties for 25 further pulsars. CHIME's low observing
frequency and wide bandwidth between 400-800 MHz contribute to the precision of
our measurements, whereas the high cadence observation provide extremely high
signal-to-noise co-added data. Our results represent a significant increase of
the pulsar RM census, particularly regarding the northern hemisphere. These new
RMs are for sources that are located in the Galactic plane out to 10 kpc, as
well as off the plane to a scale height of ~16 kpc. This improved knowledge of
the Faraday sky will contribute to future Galactic large-scale magnetic
structure and ionosphere modelling.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:00:03 GMT""}]","2020-06-17"
"2006.06580","Baihan Lin","Baihan Lin, Djallel Bouneffouf, Guillermo Cecchi","Online Learning in Iterated Prisoner's Dilemma to Mimic Human Behavior","Proceeding of PRICAI 2022. To the best of our knowledge, this is the
  first attempt to explore the full spectrum of reinforcement learning agents
  (multi-armed bandits, contextual bandits and reinforcement learning) in the
  sequential social dilemma. Codes at https://github.com/doerlbh/dilemmaRL",,,,"cs.GT cs.AI cs.LG cs.MA q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As an important psychological and social experiment, the Iterated Prisoner's
Dilemma (IPD) treats the choice to cooperate or defect as an atomic action. We
propose to study the behaviors of online learning algorithms in the Iterated
Prisoner's Dilemma (IPD) game, where we investigate the full spectrum of
reinforcement learning agents: multi-armed bandits, contextual bandits and
reinforcement learning. We evaluate them based on a tournament of iterated
prisoner's dilemma where multiple agents can compete in a sequential fashion.
This allows us to analyze the dynamics of policies learned by multiple
self-interested independent reward-driven agents, and also allows us study the
capacity of these algorithms to fit the human behaviors. Results suggest that
considering the current situation to make decision is the worst in this kind of
social dilemma game. Multiples discoveries on online learning behaviors and
clinical validations are stated, as an effort to connect artificial
intelligence algorithms with human behaviors and their abnormal states in
neuropsychiatric conditions.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 15:58:32 GMT""},{""version"":""v2"",""created"":""Thu, 10 Sep 2020 14:17:09 GMT""},{""version"":""v3"",""created"":""Sat, 27 Aug 2022 02:50:31 GMT""}]","2022-08-30"
"2006.06582","Prasanth Shyamsundar","Konstantin T. Matchev, Alexander Roman, Prasanth Shyamsundar","Finding Wombling Boundaries in LHC Data with Voronoi and Delaunay
  Tessellations","54 pages. New figure 13 and appendix A added. Conclusions unchanged.
  Matches published version","J. High Energ. Phys. 12 (2020), 137","10.1007/JHEP12(2020)137",,"hep-ph hep-ex physics.comp-ph physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of finding a wombling boundary in point data generated
by a general Poisson point process, a specific example of which is an LHC event
sample distributed in the phase space of a final state signature, with the
wombling boundary created by some new physics. We discuss the use of Voronoi
and Delaunay tessellations of the point data for estimating the local gradients
and investigate methods for sharpening the boundaries by reducing the
statistical noise. The outcome from traditional wombling algorithms is a set of
boundary cell candidates with relatively large gradients, whose spatial
properties must then be scrutinized in order to construct the boundary and
evaluate its significance. Here we propose an alternative approach where we
simultaneously form and evaluate the significance of all possible boundaries in
terms of the total gradient flux. We illustrate our method with several toy
examples of both straight and curved boundaries with varying amounts of signal
present in the data.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 22:23:42 GMT""},{""version"":""v2"",""created"":""Sun, 10 Jan 2021 17:25:39 GMT""}]","2021-01-12"
"2006.06673","Mohammad Mousavi","Mohammad Mousavi, Meng Wu","A DSO Framework for Comprehensive Market Participation of DER
  Aggregators",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a distribution system operator (DSO) framework is proposed to
optimally coordinate distributed energy resources (DER) aggregators'
comprehensive participation in retail energy market as well as wholesale energy
and regulation markets. Various types of DER aggregators, including energy
storage aggregators (ESAGs), dispatchable distributed generation aggregators
(DDGAGs), electric vehicles charging stations (EVCSs), and demand response
aggregators (DRAGs), are modeled in the proposed DSO framework. Distribution
network constraints are considered by using a linearized power flow. The
problem is modeled using mixed-integer linear programming (MILP) which can be
solved by commercial solvers. Case studies are performed to analyze the
interactions between DER aggregators and wholesale/retail electricity markets.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:08:34 GMT""}]","2020-06-15"
"2006.06825","Andreas Varga","Andreas Varga","On Computing the Kronecker Structure of Polynomial and Rational Matrices
  using Julia","28 pages",,,,"math.NA cs.MS cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we discuss the mathematical background and the computational
aspects which underly the implementation of a collection of Julia functions in
the MatrixPencils package for the determination of structural properties of
polynomial and rational matrices. We primarily focus on the computation of the
finite and infinite spectral structures (e.g., eigenvalues, zeros, poles) as
well as the left and right singular structures (e.g., Kronecker indices), which
play a fundamental role in the structure of the solution of many problems
involving polynomial and rational matrices. The basic analysis tool is the
determination of the Kronecker structure of linear matrix pencils using
numerically reliable algorithms, which is used in conjunction with several
linearization techniques of polynomial and rational matrices. Examples of
polynomial and rational matrices, which exhibit all relevant structural
features, are considered to illustrate the main mathematical concepts and the
capabilities of implemented tools.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:36:42 GMT""},{""version"":""v2"",""created"":""Sun, 6 Sep 2020 11:44:24 GMT""}]","2020-09-08"
"2006.07144","Chandralekha Singh","Emily Marshman, Christof Keebaugh and Chandralekha Singh","Student difficulties with finding the corrections to the energy spectrum
  of the hydrogen atom for the strong and weak field Zeeman effects using
  degenerate perturbation theory","Physics Education Research Conference Proceedings. arXiv admin note:
  text overlap with arXiv:2006.05000",,"10.1119/perc.2017.pr.060",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss an investigation of student difficulties with the corrections to
the energy spectrum of the hydrogen atom for the strong and weak field Zeeman
effects using degenerate perturbation theory. This investigation was carried
out in advanced quantum mechanics courses by administering written
free-response and multiple-choice questions and conducting individual
interviews with students. We discuss the common student difficulties related to
these concepts which can be used as a guide for creating learning tools to help
students develop a functional understanding of concepts involving the
corrections to the energy spectrum due to the Zeeman effect.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:16:16 GMT""}]","2020-06-15"
"2006.07145","Chandralekha Singh","Paul Justice, Emily Marshman, and Chandralekha Singh","Development and validation of a sequence of clicker questions for
  helping students learn addition of angular momentum in quantum mechanics","Physics Education Research Conference Proceedings. arXiv admin note:
  text overlap with arXiv:2006.05341",,"10.1103/physrevstper.9.010101",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Engaging students with well-designed clicker questions is one of the commonly
used research-based instructional strategy in physics courses partly because it
has a relatively low barrier to implementation [1]. Moreover, validated robust
sequences of clicker questions are likely to provide better scaffolding support
and guidance to help students build a good knowledge structure of physics than
an individual clicker question on a particular topic. Here we discuss the
development, validation and in-class implementation of a clicker question
sequence (CQS) for helping advanced undergraduate students learn about addition
of angular momentum, which takes advantage of the learning goals and
inquiry-based guided learning sequences in a previously validated Quantum
Interactive Learning Tutorial (QuILT). The in-class evaluation of the CQS using
peer instruction is discussed by comparing upper-level undergraduate student
performance after engaging with the CQS with previous published data from the
QuILT pertaining to these concepts.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 00:32:08 GMT""}]","2020-06-15"
"2006.07147","Murat Uzunca","B\""ulent Karas\""ozen, G\""ulden M\""ulayim, Murat Uzunca and S\""uleyman
  Y{\i}ld{\i}z","Reduced order modelling of nonlinear cross-diffusion systems","To appear in Applied Mathematics and Computation","Applied Mathematics and Computation, 401, 126058 (2021)","10.1016/j.amc.2021.126058",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present a reduced-order model for a nonlinear
cross-diffusion problem from population dynamics, for the
Shigesada-Kawasaki-Teramoto (SKT) equation with Lotka-Volterra kinetics. The
finite-difference discretization of the SKT equation in space results in a
system of linear--quadratic ordinary differential equations (ODEs). The reduced
order model (ROM) has the same linear-quadratic structure as the full order
model (FOM). Using the linear-quadratic structure of the ROM, the reduced-order
solutions are computed independent of the full solutions with the proper
orthogonal decomposition (POD). The computation of the reduced solutions is
further accelerated by applying tensorial POD. The formation of the patterns of
the SKT equation consists of a fast transient phase and a long steady-state
phase. Reduced order solutions are computed by separating the time, into
two-time intervals. In numerical experiments, we show for one-and
two-dimensional SKT equations with pattern formation, the reduced-order
solutions obtained in the time-windowed form, i.e., principal decomposition
framework (P-POD), are more accurate than the global POD solutions (G-POD)
obtained in the whole time interval. Furthermore, we show the decrease of the
entropy numerically by the reduced solutions, which is important for the global
existence of nonlinear cross-diffusion equations such as the SKT equation.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:19:18 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 08:47:41 GMT""},{""version"":""v3"",""created"":""Mon, 8 Feb 2021 09:32:01 GMT""}]","2021-03-04"
"2006.07150","Ciro Javier Diaz Penedo","Juan Galvis, Eduardo Abreu, Ciro Diaz and Jonh Perez","On the conservation properties in multiple scale coupling and simulation
  for Darcy flow with hyperbolic-transport in complex flows",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present and discuss a novel approach to deal with conservation properties
for the simulation of nonlinear complex porous media flows in the presence of:
1) multiscale heterogeneity structures appearing in the
elliptic-pressure-velocity and in the rock geology model, and 2) multiscale
wave structures resulting from shock waves and rarefaction interactions from
the nonlinear hyperbolic-transport model. For the pressure-velocity Darcy flow
problem, we revisit a recent high-order and volumetric residual-based Lagrange
multipliers saddle point problem to impose local mass conservation on convex
polygons. We clarify and improve conservation properties on applications.For
the hyperbolic-transport problem we introduce a newlocally conservative
Lagrangian-Eulerian finite volume method. For the purpose of this work, we
recast our method within the Crandall and Majda treatment of the stability and
convergence properties of conservation-form, monotone difference, in which the
scheme converges to the physical weak solution satisfying the entropy
condition. This multiscale coupling approach was applied to several nontrivial
examples to show that we are computing qualitatively correct reference
solutions. We combine these procedures for the simulation of the fundamental
two-phase flow problem with high-contrast multiscale porous medium, but
recalling state-of-the-art paradigms on the of notion of solution in related
multiscale applications. This is a first step to deal with out-of-reach
multiscale systems with traditional techniques. We provide robust numerical
examples for verifying the theory and illustrating the capabilities of the
approach being presented.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 01:38:00 GMT""}]","2020-06-15"
"2006.07467","Kamil Dulski","K. Dulski, S.D. Bass, J. Chhokar, N. Chug, C. Curceanu, E.
  Czerwi\'nski, M. Dadgar, J. Gajewski, A. Gajos, M. Gorgol, R. Del Grande,
  B.C. Hiesmayr, B. Jasi\'nska, K. Kacprzak, {\L}. Kap{\l}on, H. Karimi, D.
  Kisielewska, K. Klimaszewski, P. Kopka, G. Korcyl, P. Kowalski, T. Kozik, N.
  Krawczyk, W. Krzemie\'n, E. Kubicz, P. Ma{\l}czak, M. Mohammed, Sz.
  Nied\'zwiecki, M. Pa{\l}ka, M. Pawlik-Nied\'zwiecka, M. P\k{e}dziwiatr, L.
  Raczy\'nski7, J. Raj, A. Ruci\'nski4, S. Sharma, Shivani, R.Y. Shopa, M.
  Silarski, M. Skurzok, E. {\L}. St\k{e}pie\'n, F. Tayefi, W. Wi\'slicki, B.
  Zgardzi\'nska, P. Moskal","The J-PET detector -- a tool for precision studies of ortho-positronium
  decays","12 pages, 7 figures",,"10.1016/j.nima.2021.165452",,"physics.ins-det nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The J-PET tomograph is constructed from plastic scintillator strips arranged
axially in concentric cylindrical layers. It enables investigations of
positronium decays by measurement of the time, position, polarization and
energy deposited by photons in the scintillators, in contrast to studies
conducted so far with crystal and semiconductor based detection systems where
the key selection of events is based on the measurement of the photons
energies. In this article we show that the J-PET tomograph system is capable of
exclusive measurements of the decays of ortho-positronium atoms. We present the
first positronium production results, its lifetime distribution measurements
and discuss estimation of the influence of various background sources. The
tomograph s performance demonstrated here makes it suitable for precision
studies of positronium decays including entanglement of the final state
photons, positron annihilation lifetime spectroscopy plus molecular imaging
diagnostics.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:15:08 GMT""},{""version"":""v2"",""created"":""Mon, 14 Sep 2020 12:33:23 GMT""},{""version"":""v3"",""created"":""Tue, 25 May 2021 11:24:43 GMT""}]","2021-05-26"
"2006.08327","Raphael Kramer","Raphael Kramer and Arthur Kramer","Exact and heuristic methods for the discrete parallel machine scheduling
  location problem","25 pages, 5 figures, 7 tables",,,,"cs.AI math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The discrete parallel machine makespan scheduling location (ScheLoc) problem
is an integrated combinatorial optimization problem that combines facility
location and job scheduling. The problem consists in choosing the locations of
$p$ machines among a finite set of candidates and scheduling a set of jobs on
these machines, aiming to minimize the makespan. Depending on the machine
location, the jobs may have different release dates, and thus the location
decisions have a direct impact on the scheduling decisions. To solve the
problem, it is proposed a new arc-flow formulation, a column generation and
three heuristic procedures that are evaluated through extensive computational
experiments. By embedding the proposed procedures into a framework algorithm,
we are able to find proven optimal solutions for all benchmark instances from
the related literature and to obtain small percentage gaps for a new set of
challenging instances.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 00:10:18 GMT""}]","2020-06-16"
"2006.08344","Tim Z. Xiao","Tim Z. Xiao, Aidan N. Gomez, Yarin Gal","Wat zei je? Detecting Out-of-Distribution Translations with Variational
  Transformers","19 pages, 9 figures",,,,"cs.CL cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We detect out-of-training-distribution sentences in Neural Machine
Translation using the Bayesian Deep Learning equivalent of Transformer models.
For this we develop a new measure of uncertainty designed specifically for long
sequences of discrete random variables -- i.e. words in the output sentence.
Our new measure of uncertainty solves a major intractability in the naive
application of existing approaches on long sentences. We use our new measure on
a Transformer model trained with dropout approximate inference. On the task of
German-English translation using WMT13 and Europarl, we show that with dropout
uncertainty our measure is able to identify when Dutch source sentences,
sentences which use the same word types as German, are given to the model
instead of German.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 20:00:36 GMT""}]","2020-06-16"
"2006.08368","Guillermo Gallego","Anko B\""orner, Heinz-Wilhelm H\""ubers, Odej Kao, Florian Schmidt,
  S\""oren Becker, Joachim Denzler, Daniel Matolin, David Haber, Sergio Lucia,
  Wojciech Samek, Rudolph Triebel, Sascha Eichst\""adt, Felix Biessmann, Anna
  Kruspe, Peter Jung, Manon Kok, Guillermo Gallego, Ralf Berger","Sensor Artificial Intelligence and its Application to Space Systems -- A
  White Paper","4 pages. 1st Workshop on Sensor Artificial Intelligence, Apr. 2020,
  Berlin, Germany",,,,"cs.CY eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Information and communication technologies have accompanied our everyday life
for years. A steadily increasing number of computers, cameras, mobile devices,
etc. generate more and more data, but at the same time we realize that the data
can only partially be analyzed with classical approaches. The research and
development of methods based on artificial intelligence (AI) made enormous
progress in the area of interpretability of data in recent years. With growing
experience, both, the potential and limitations of these new technologies are
increasingly better understood. Typically, AI approaches start with the data
from which information and directions for action are derived. However, the
circumstances under which such data are collected and how they change over time
are rarely considered. A closer look at the sensors and their physical
properties within AI approaches will lead to more robust and widely applicable
algorithms. This holistic approach which considers entire signal chains from
the origin to a data product, ""Sensor AI"", is a highly relevant topic with
great potential. It will play a decisive role in autonomous driving as well as
in areas of automated production, predictive maintenance or space research. The
goal of this white paper is to establish ""Sensor AI"" as a dedicated research
topic. We want to exchange knowledge on the current state-of-the-art on Sensor
AI, to identify synergies among research groups and thus boost the
collaboration in this key technology for science and industry.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 14:10:35 GMT""}]","2020-06-16"
"2006.08369","Junhua Liu","Junhua Liu, Trisha Singhal, Lucienne T.M. Blessing, Kristin L. Wood
  and Kwan Hui Lim","EPIC30M: An Epidemics Corpus Of Over 30 Million Relevant Tweets",,,,,"cs.SI cs.CL cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since the start of COVID-19, several relevant corpora from various sources
are presented in the literature that contain millions of data points. While
these corpora are valuable in supporting many analyses on this specific
pandemic, researchers require additional benchmark corpora that contain other
epidemics to facilitate cross-epidemic pattern recognition and trend analysis
tasks. During our other efforts on COVID-19 related work, we discover very
little disease related corpora in the literature that are sizable and rich
enough to support such cross-epidemic analysis tasks. In this paper, we present
EPIC30M, a large-scale epidemic corpus that contains 30 millions micro-blog
posts, i.e., tweets crawled from Twitter, from year 2006 to 2020. EPIC30M
contains a subset of 26.2 millions tweets related to three general diseases,
namely Ebola, Cholera and Swine Flu, and another subset of 4.7 millions tweets
of six global epidemic outbreaks, including 2009 H1N1 Swine Flu, 2010 Haiti
Cholera, 2012 Middle-East Respiratory Syndrome (MERS), 2013 West African Ebola,
2016 Yemen Cholera and 2018 Kivu Ebola. Furthermore, we explore and discuss the
properties of the corpus with statistics of key terms and hashtags and trends
analysis for each subset. Finally, we demonstrate the value and impact that
EPIC30M could create through a discussion of multiple use cases of
cross-epidemic research topics that attract growing interest in recent years.
These use cases span multiple research areas, such as epidemiological modeling,
pattern recognition, natural language understanding and economical modeling.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:23:00 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 17:08:45 GMT""}]","2020-06-23"
"2006.08370","Huanyang Chen","Shiming Chen, Yangyang Zhou, Zhenyu Wang, and Huanyang Chen","Ancient Luoyang Bridge reveals a simple metagrating model in optics","6 pages, 6 figures",,"10.1017/S174392131900869X",,"physics.pop-ph physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ancient Chinese bridge, Luoyang Bridge, has been revealed to obey similar
laws to diminish waves, like an optical model, metagrating. Numerical
simulations have been performed to verify this finding.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 12:35:26 GMT""}]","2020-06-24"
"2006.08711","Mor Sinay","Mor Sinay, Elad Sarafian, Yoram Louzoun, Noa Agmon, Sarit Kraus","Explicit Gradient Learning",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Black-Box Optimization (BBO) methods can find optimal policies for systems
that interact with complex environments with no analytical representation. As
such, they are of interest in many Artificial Intelligence (AI) domains. Yet
classical BBO methods fall short in high-dimensional non-convex problems. They
are thus often overlooked in real-world AI tasks. Here we present a BBO method,
termed Explicit Gradient Learning (EGL), that is designed to optimize
high-dimensional ill-behaved functions. We derive EGL by finding weak-spots in
methods that fit the objective function with a parametric Neural Network (NN)
model and obtain the gradient signal by calculating the parametric gradient.
Instead of fitting the function, EGL trains a NN to estimate the objective
gradient directly. We prove the convergence of EGL in convex optimization and
its robustness in the optimization of integrable functions. We evaluate EGL and
achieve state-of-the-art results in two challenging problems: (1) the COCO test
suite against an assortment of standard BBO methods; and (2) in a
high-dimensional non-convex image generation task.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:56:24 GMT""}]","2020-06-17"
"2006.09473","Kewen Meng","Kewen Meng and Boyana Norris","Guiding Optimizations with Meliora: A Deep Walk down Memory Lane",,,,,"cs.DC cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Performance models can be very useful for understanding the behavior of
applications and hence can help guide design and optimization decisions.
Unfortunately, performance modeling of nontrivial computations typically
requires significant expertise and human effort. Moreover, even when performed
by experts, it is necessarily limited in scope, accuracy, or both. However,
since models are not typically available, programmers, compilers or autotuners
cannot use them easily to guide optimizations and are limited to
heuristic-based methods that potentially take a lot of time to perform
unnecessary transformations. We believe that streamlining model generation and
making it scalable (both in terms of human effort and code size) would enable
dramatic improvements in compilation techniques, as well as manual optimization
and autotuning. To that end, we are building the Meliora code analysis
infrastructure for machine learning-based performance model generation of
arbitrary codes based on static analysis of intermediate language
representations. We demonstrate good accuracy in matching known codes and show
how Meliora can be used to optimize new codes though reusing optimization
knowledge, either manually or in conjunction with an autotuner. When
autotuning, Meliora eliminates or dramatically reduces the empirical search
space, while generally achieving competitive performance.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:59:31 GMT""}]","2020-06-18"
"2006.09979","Barbara Rychalska","Barbara Rychalska, Dominika Basaj, Jacek D\k{a}browski, Micha{\l}
  Daniluk","I know why you like this movie: Interpretable Efficient Multimodal
  Recommender",,,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the Efficient Manifold Density Estimator (EMDE) model has been
introduced. The model exploits Local Sensitive Hashing and Count-Min Sketch
algorithms, combining them with a neural network to achieve state-of-the-art
results on multiple recommender datasets. However, this model ingests a
compressed joint representation of all input items for each user/session, so
calculating attributions for separate items via gradient-based methods seems
not applicable. We prove that interpreting this model in a white-box setting is
possible thanks to the properties of EMDE item retrieval method. By exploiting
multimodal flexibility of this model, we obtain meaningful results showing the
influence of multiple modalities: text, categorical features, and images, on
movie recommendation output.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 09:59:28 GMT""}]","2020-06-18"
"2006.10134","Tianheng Zhao","Tianheng H. Zhao, Gianni Jacucci, Xi Chen, Dong-Po Song, Silvia
  Vignolini, Richard M. Parker","Angular Independent Photonic Pigments via the Controlled Micellization
  of Amphiphilic Bottlebrush Block Copolymers","32 pages, 18 figures, 1 table","Advanced Materials, Volume 32, Issue 47 November 26, 2020 2002681","10.1002/adma.202002681",,"cond-mat.soft physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photonic materials with angular independent structural colour are highly
desirable because they offer the broad viewing angles required for application
as colorants in paints, cosmetics, textiles or displays. However, they are
challenging to fabricate as they require isotropic nanoscale architectures with
only short-range correlation. In this article, porous microparticles with such
a structure are produced in a single, scalable step from an amphiphilic
bottlebrush block copolymer. This is achieved by exploiting a novel controlled
micellization self-assembly mechanism within emulsified toluene-in-water
droplets. By restricting water permeation through the droplet interface, the
size of the pores can be precisely addressed, resulting in structurally
coloured pigments. Furthermore, the reflected colour can be tuned to reflect
across the full visible spectrum using only a single polymer (Mn = 290 kDa) by
altering the initial emulsification conditions. Such photonic pigments have
several key advantages over their crystalline analogues, as they provide
isotropic structural coloration that suppresses iridescence and improves colour
purity without the need for either refractive index matching or the inclusion
of a broadband absorber.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:06:39 GMT""},{""version"":""v2"",""created"":""Tue, 15 Sep 2020 20:11:42 GMT""}]","2022-02-23"
"2006.10532","Petr\^onio Silva C. L.","Petr\^onio C. L. Silva, Paulo V. C. Batista, H\'elder S. Lima, Marcos
  A. Alves, Frederico G. Guimar\~aes, Rodrigo C. P. Silva","COVID-ABS: An Agent-Based Model of COVID-19 Epidemic to Simulate Health
  and Economic Effects of Social Distancing Interventions","37 pages, 17 figures","Chaos, Solitons & Fractals (2020)","10.1016/j.chaos.2020.110088",,"cs.AI physics.soc-ph","http://creativecommons.org/licenses/by-sa/4.0/","  The COVID-19 pandemic due to the SARS-CoV-2 coronavirus has directly impacted
the public health and economy worldwide. To overcome this problem, countries
have adopted different policies and non-pharmaceutical interventions for
controlling the spread of the virus. This paper proposes the COVID-ABS, a new
SEIR (Susceptible-Exposed-Infected-Recovered) agent-based model that aims to
simulate the pandemic dynamics using a society of agents emulating people,
business and government. Seven different scenarios of social distancing
interventions were analyzed, with varying epidemiological and economic effects:
(1) do nothing, (2) lockdown, (3) conditional lockdown, (4) vertical isolation,
(5) partial isolation, (6) use of face masks, and (7) use of face masks
together with 50% of adhesion to social isolation. In the impossibility of
implementing scenarios with lockdown, which present the lowest number of deaths
and highest impact on the economy, scenarios combining the use of face masks
and partial isolation can be the more realistic for implementation in terms of
social cooperation. The COVID-ABS model was implemented in Python programming
language, with source code publicly available. The model can be easily extended
to other societies by changing the input parameters, as well as allowing the
creation of a multitude of other scenarios. Therefore, it is a useful tool to
assist politicians and health authorities to plan their actions against the
COVID-19 epidemic.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 03:44:48 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jul 2020 23:12:59 GMT""}]","2020-07-10"
"2006.10533","Thomas Jaki","Lori E Dodd, Dean Follmann, Jing Wang, Franz Koenig, Lisa L Korn,
  Christian Schoergenhofer, Michael Proschan, Sally Hunsberger, Tyler Bonnett,
  Mat Makowski, Drifa Belhadi, Yeming Wang, Bin Cao, France Mentre, Thomas Jaki","Endpoints for randomized controlled clinical trials for COVID-19
  treatments",,,,,"stat.ME q-bio.PE q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Introduction: Endpoint choice for randomized controlled trials of treatments
for COVID-19 is complex. A new disease brings many uncertainties, but trials
must start rapidly. COVID-19 is heterogeneous, ranging from mild disease that
improves within days to critical disease that can last weeks and can end in
death. While improvement in mortality would provide unquestionable evidence
about clinical significance of a treatment, sample sizes for a study evaluating
mortality are large and may be impractical. Furthermore, patient states in
between ""cure"" and ""death"" represent meaningful distinctions. Clinical severity
scores have been proposed as an alternative. However, the appropriate summary
measure for severity scores has been the subject of debate, particularly in
relating to the uncertainty about the time-course of COVID-19. Outcomes
measured at fixed time-points may risk missing the time of clinical benefit. An
endpoint such as time-to-improvement (or recovery), avoids the timing problem.
However, some have argued that power losses will result from reducing the
ordinal scale to a binary state of ""recovered"" vs ""not recovered.""
  Methods: We evaluate statistical power for possible trial endpoints for
COVID-19 treatment trials using simulation models and data from two recent
COVID-19 treatment trials.
  Results: Power for fixed-time point methods depends heavily on the time
selected for evaluation. Time-to-improvement (or recovery) analyses do not
specify a time-point. Time-to-event approaches have reasonable statistical
power, even when compared to a fixed time-point method evaluated at the optimal
time.
  Discussion: Time-to-event analyses methods have advantages in the COVID-19
setting, unless the optimal time for evaluating treatment effect is known in
advance. Even when the optimal time is known, a time-to-event approach may
increase power for interim analyses.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 10:34:40 GMT""}]","2020-06-19"
"2006.11395","Delong Chen","Fan Liu, Delong Chen, Fei Wang, Zewen Li, Feng Xu","Deep Learning Based Single Sample Per Person Face Recognition: A Survey","Published in Artificial Intelligence Review",,"10.1007/s10462-022-10240-2",,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  Face recognition has long been an active research area in the field of
artificial intelligence, particularly since the rise of deep learning in recent
years. In some practical situations, each identity has only a single sample
available for training. Face recognition under this situation is referred to as
single sample face recognition and poses significant challenges to the
effective training of deep models. Therefore, in recent years, researchers have
attempted to unleash more potential of deep learning and improve the model
recognition performance in the single sample situation. While several
comprehensive surveys have been conducted on traditional single sample face
recognition approaches, emerging deep learning based methods are rarely
involved in these reviews. Accordingly, we focus on the deep learning-based
methods in this paper, classifying them into virtual sample methods and generic
learning methods. In the former category, virtual images or virtual features
are generated to benefit the training of the deep model. In the latter one,
additional multi-sample generic sets are used. There are three types of generic
learning methods: combining traditional methods and deep features, improving
the loss function, and improving network structure, all of which are covered in
our analysis. Moreover, we review face datasets that have been commonly used
for evaluating single sample face recognition models and go on to compare the
results of different types of models. Additionally, we discuss problems with
existing single sample face recognition methods, including identity information
preservation in virtual sample methods, domain adaption in generic learning
methods. Furthermore, we regard developing unsupervised methods is a promising
future direction, and point out that the semantic gap as an important issue
that needs to be further considered.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 13:24:27 GMT""},{""version"":""v2"",""created"":""Wed, 10 Aug 2022 05:52:57 GMT""}]","2022-08-11"
"2006.12365","David Benton Dr","David M Benton","Laser detection using liquid crystal polarization modulators",,"Opt. Eng. 59(6), 064106 (2020)","10.1117/1.OE.59.6.064106.",,"eess.SP physics.ins-det physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lasers can be identified by their relatively long coherence lengths using
interferometry. A Mach Zehnder interferometer incorporating liquid crystal
polarization modulators is demonstrated as a means of low cost, robust laser
detection. Temporal modulations, as a signature of coherence can be induced by
modulating polarization changes in liquid crystal modulators, using low
voltages. Sensitivities of less than 10nW can be achieved. The suitability as a
means of laser detection is discussed.
","[{""version"":""v1"",""created"":""Tue, 9 Jun 2020 08:38:21 GMT""}]","2020-06-28"
"2006.13921","Revathi Bhuvaneswari","Revathi Bhuvaneswari, Antonio Segalini","Determining Secondary Attributes for Credit Evaluation in P2P Lending",,,,,"q-fin.GN cs.LG q-fin.RM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There has been an increased need for secondary means of credit evaluation by
both traditional banking organizations as well as peer-to-peer lending
entities. This is especially important in the present technological era where
sticking with strict primary credit histories doesn't help distinguish between
a 'good' and a 'bad' borrower, and ends up hurting both the individual borrower
as well as the investor as a whole. We utilized machine learning classification
and clustering algorithms to accurately predict a borrower's creditworthiness
while identifying specific secondary attributes that contribute to this score.
While extensive research has been done in predicting when a loan would be fully
paid, the area of feature selection for lending is relatively new. We achieved
65% F1 and 73% AUC on the LendingClub data while identifying key secondary
attributes.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 16:12:00 GMT""}]","2020-06-25"
"2006.14053","Natalia Jonard-P\'erez","Natalia Jonard-Perez","Some generalizations on affine invariant points",,,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we prove a more general (and topological) version of
Gr\""unbaum's conjecture about affine invariant points. As an application of our
result we show that, if we consider the action of the group of similarities,
Gr\""unbaum's conjecture remains valid in other families of convex sets (not
necessarily convex bodies).
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 21:26:45 GMT""}]","2020-06-26"
"2007.09143","Tetiana Obikhod Victorovna","Tetiana Obikhod, Ievgenii Petrenko","Searches for heavy Higgs bosons in the framework of 2HDM model","7 pages, 5 figures",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The searches for heavy neutral and charged Higgs bosons are performed through
the calculations of production cross sections using MadGraph5aMC@NLO program
with ansatz of Yukawa coupling and the restricted parameter space connected
with LHC Run 2 data. The searches for heavy resonances are performed in the
framework of 2HDM model over the mass range 0.1 - 1 TeV for the $pp\rightarrow
At\bar{b}$, $pp\rightarrow H^{+}b\bar{t}$ , $pp\rightarrow H^{+}t\bar{t}$ ,
$pp\rightarrow HHZ$ decay modes. The presented data demonstrate the jump in the
production cross section of $H^{+} b\bar{t}$ and $HHZ$ production processes in
the mass range of 100-200 GeV and 100-300 GeV accordingly at energy of 14 TeV.
","[{""version"":""v1"",""created"":""Mon, 8 Jun 2020 18:19:13 GMT""}]","2020-07-20"
