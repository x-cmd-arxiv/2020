"2011.13803","LoÃ¯c Thulliez","L. Thulliez (1), D. Lhuillier (1), F. Cappella (2), N. Casali (2), R.
  Cerulli (3, 4), A. Chalil (1), A. Chebboubi (5), E. Dumonteil (1), A. Erhart
  (6), A. Giuliani (7), F. Gunsing (1), E. Jericha (8), M. Kaznacheeva (6), A.
  Kinast (6), A. Langenk\""amper (6), T. Lasserre (1, 6), A. Letourneau (1), O.
  Litaize (5), P. de Marcillac (7), S. Marnieros (7), T. Materna (1), B. Mauri
  (1), E. Mazzucato (1), C. Nones (1), T. Ortmann (6), L. Pattavina (4, 9),
  D.V. Poda (7), R. Rogly (1), N. Schermer (6), O. Serot (5), G. Soum (1), L.
  Stodolsky (10), R. Strauss (6), M. Vignati (2, 11), M. Vivier (1), V. Wagner
  (6), A. Wex (6) ((1) IRFU, CEA, Universit\'e Paris-Saclay, Gif-sur-Yvette,
  France (2) INFN-Sezione di Roma, Piazzale Aldo Moro, Roma, Italy (3) INFN,
  Sezione di Roma Tor Vergata, Roma, Italy (4) Dipartimento di Fisica,
  Universit\`a di Roma Tor Vergata, Roma, Italy (5) CEA, DES, IRESNE, DER,
  Cadarache, Saint-Paul-Lez-Durance, France (6) Physik-Department, Technische
  Universit\""at M\""unchen, Garching, Germany (7) Universit\'e Paris-Saclay,
  CNRS/IN2P3, IJCLab, Orsay, France (8) TU Wien, Atominstitut, Wien, Austria
  (9) INFN, Laboratori Nazionali del Gran Sasso, Assergi (AQ), Italy (10)
  Max-Planck-Insitut f\""ur Physik, M\""unchen, Germany (11) Sapienza
  Universit\`a di Roma, Dipartimento di Fisica, Roma, Italy)","Calibration of nuclear recoils at the 100 eV scale using neutron capture","21 pages, 8 figures",,"10.1088/1748-0221/16/07/P07032",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The development of low-threshold detectors for the study of coherent elastic
neutrino-nucleus scattering and for the search for light dark matter
necessitates methods of low-energy calibration. We suggest this can be provided
by the nuclear recoils resulting from the $\gamma$ emission following thermal
neutron capture. In particular, several MeV-scale single-$\gamma$ transitions
induce well-defined nuclear recoil peaks in the 100 eV range. Using the
FIFRELIN code, complete schemes of $\gamma$-cascades for various isotopes can
be predicted with high accuracy to determine the continuous background of
nuclear recoils below the calibration peaks. We present a comprehensive
experimental concept for the calibration of CaWO$_4$ and Ge cryogenic detectors
at a research reactor. For CaWO$_4$ the simulations show that two nuclear
recoil peaks at 112.5 eV and 160.3 eV should be visible above background simply
in the spectrum of the cryogenic detector. Then we discuss how the additional
tagging for the associated $\gamma$ increases the sensitivity of the method and
extends its application to a wider energy range and to Ge cryogenic detectors.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:00:41 GMT""},{""version"":""v2"",""created"":""Fri, 9 Apr 2021 12:50:44 GMT""},{""version"":""v3"",""created"":""Sun, 23 May 2021 07:39:07 GMT""}]","2021-08-11"
"2011.13804","Ehsan Abedi","Ehsan Abedi, Simone Carlo Surace, Jean-Pascal Pfister","A Unification of Weighted and Unweighted Particle Filters","23 pages","SIAM Journal on Control and Optimization, Volume 60, Issue 2, pp.
  597-619 (2022)","10.1137/20M1382404",,"math.OC cs.NA math.NA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Particle filters (PFs), which are successful methods for approximating the
solution of the filtering problem, can be divided into two types: weighted and
unweighted PFs. It is well known that weighted PFs suffer from the weight
degeneracy and curse of dimensionality. To sidestep these issues, unweighted
PFs have been gaining attention, though they have their own challenges. The
existing literature on these types of PFs is based on distinct approaches. In
order to establish a connection, we put forward a framework that unifies
weighted and unweighted PFs in the continuous-time filtering problem. We show
that the stochastic dynamics of a particle system described by a pair process,
representing particles and their importance weights, should satisfy two
necessary conditions in order for its distribution to match the solution of the
Kushner--Stratonovich equation. In particular, we demonstrate that the
bootstrap particle filter (BPF), which relies on importance sampling, and the
feedback particle filter (FPF), which is an unweighted PF based on optimal
control, arise as special cases from a broad class and that there is a smooth
transition between the two. The freedom in designing the PF dynamics opens up
potential ways to address the existing issues in the aforementioned algorithms,
namely weight degeneracy in the BPF and gain estimation in the FPF.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:04:26 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 08:01:51 GMT""},{""version"":""v3"",""created"":""Sat, 12 Mar 2022 19:29:53 GMT""}]","2022-03-15"
"2011.13805","Jesus Misrayim Rueda-Becerril","Jes\'us M. Rueda-Becerril, Amanda O. Harrison, Dimitrios Giannios","The blazar sequence revised","6 pages, 3 figures, contribution to the 9th International Workshop on
  Astronomy and Relativistic Astrophysics (IWARA2020 Video Conference)
  conference's proceedings, accepted for publication in Astronomische
  Nachrichten",,"10.1002/asna.202113895",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose and test a fairly simple idea that could account for the blazar
sequence: all jets are launched with similar energy per baryon, independently
of their power. For instance, flat-spectrum radio quasars (FSRQs), the most
powerful jets, manage to accelerate to high bulk Lorentz factor, as observed in
the radio. As a result, the emission region will have a rather modest
magnetization which will induce a steep particle spectra therein and a rather
steep emission spectra in the gamma-rays; particularly in the
\textit{Fermi}-LAT band. For the weaker jets, namely BL Lacertae objects (BL
Lacs), the opposite holds true; i.e., the jet does not achieve a very high bulk
Lorentz factor, leading to more magnetic energy available for non-thermal
particle acceleration and harder emission spectra. Moreover, this model
requires but a handful of parameters. By means of numerical simulations we have
accomplished to reproduce the spectral energy distributions and light-curves
from fiducial sources following the aforementioned model. With the a complete
evolution of the broadband spectra we were able to study in detail the spectral
features at any particular frequency band at any given stage. Finally numerical
results are compared and contrasted with observations.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:05:23 GMT""}]","2021-01-13"
"2011.13806","Cupid Collaboration","The CUPID Interest Group: A. Armatol, E. Armengaud, W. Armstrong, C.
  Augier, F. T. Avignone III, O. Azzolini, I. C. Bandac, A. S. Barabash, G.
  Bari, A. Barresi, D. Baudin, F. Bellini, G. Benato, M. Beretta, L. Berg\'e,
  Ch. Bourgeois, M. Biassoni, J. Billard, V. Boldrini, A. Branca, C. Brofferio,
  C. Bucci, J. M. Calvo-Mozota, J. Camilleri, A. Candela, S. Capelli, L.
  Cappelli, L. Cardani, P. Carniti, N. Casali, A. Cazes, E. Celi, C. Chang, M.
  Chapellier, A. Charrier, D. Chiesa, M. Clemenza, I. Colantoni, F. Collamati,
  S. Copello, F. Cova, O. Cremonesi, R. J. Creswick, A. Cruciani, A. D'Addabbo,
  G. D'Imperio, I. Dafinei, F. A. Danevich, M. de Combarieu, M. De Deo, M. De
  Jesus, P. de Marcillac, S. Dell'Oro, S. Di Domizio, V. Dompe, A. Drobizhev,
  L. Dumoulin, G. Fantini, M. Fasoli, M. Faverzani, E. Ferri, F. Ferri, F.
  Ferroni, E. Figueroa-Feliciano, J. Formaggio, A. Franceschi, C. Fu, S. Fu, B.
  K. Fujikawa, J. Gascon, A. Giachero, L. Gironi, A. Giuliani, P. Gorla, C.
  Gotti, P. Gras, M. Gros, E. Guerard, T. D. Gutierrez, K. Han, E. V. Hansen,
  K. M. Heeger, D. L. Helis, H. Z. Huang, R. G. Huang, A. Ianni, L. Imbert, J.
  Johnston, A. Juillard, G. Karapetrov, G. Keppel, H. Khalife, V. V. Kobychev,
  Yu. G. Kolomensky, S. I. Konovalov, Y. Liu, P. Loaiza, L. Ma, M. Madhukuttan,
  F. Mancarella, R. Mariam, L. Marini, S. Marnieros, M. Martinez, R. H.
  Maruyama, B. Mauri, D. Mayer, Y. Mei, S. Milana, D. Misiak, T. Napolitano, M.
  Nastasi, X.-F. Navick, J. Nikkel, R. Nipoti, S. Nisi, C. Nones, E. B. Norman,
  V. Novosad, I. Nutini, T. O'Donnell, G. Olivier, E. Olivieri, C. Oriol, J. L.
  Ouellet, S. Pagan, C. Pagliarone, L. Pagnanini, P. Pari, L. Pattavina, B.
  Paul, M. Pavan, H. Peng, G. Pessina, V. Pettinacci, C. Pira, S. Pirro, D. V.
  Poda, T. Polakovic, O. G. Polischuk, S. Pozzi, E. Previtali, A. Puiu, A.
  Ressa, D. Reynet, R. Rizzoli, C. Rosenfeld, V. Sanglard, J. A. Scarpaci, B.
  Schmidt, V. Sharma, V. N. Shlegel, V. Singh, M. Sisti, D. Speller, P. T.
  Surukuchi, L. Taffarello, O. Tellier, C. Tomei, V. I. Tretyak, A. Tsymbaliuk,
  A. Vedda, M. Velazquez, K. J. Vetter, S. L. Wagaarachchi, G. Wang, L. Wang,
  B. Welliver, J. Wilson, K. Wilson, L. A. Winslow, M. Xue, L. Yan, J. Yang, V.
  Yefremenko, V. I. Yumatov, M. M. Zarytskyy, J. Zhang, A. S. Zolotarova, S.
  Zucchelli","A CUPID Li$_{2}$$^{100}$MoO$_4$ scintillating bolometer tested in the
  CROSS underground facility","19 pages, 7 figures, 1 table",,"10.1088/1748-0221/16/02/P02037",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A scintillating bolometer based on a large cubic Li$_{2}$$^{100}$MoO$_4$
crystal (45 mm side) and a Ge wafer (scintillation detector) has been operated
in the CROSS cryogenic facility at the Canfranc underground laboratory in
Spain. The dual-readout detector is a prototype of the technology that will be
used in the next-generation $0\nu2\beta$ experiment CUPID. The measurements
were performed at 18 and 12 mK temperature in a pulse tube dilution
refrigerator. This setup utilizes the same technology as the CUORE cryostat
that will host CUPID and so represents an accurate estimation of the expected
performance. The Li$_{2}$$^{100}$MoO$_4$ bolometer shows a high energy
resolution of 6 keV FWHM at the 2615 keV $\gamma$ line. The detection of
scintillation light for each event triggered by the Li$_{2}$$^{100}$MoO$_4$
bolometer allowed for a full separation ($\sim$8$\sigma$) between
$\gamma$($\beta$) and $\alpha$ events above 2 MeV. The Li$_{2}$$^{100}$MoO$_4$
crystal also shows a high internal radiopurity with $^{228}$Th and $^{226}$Ra
activities of less than 3 and 8 $\mu$Bq/kg, respectively. Taking also into
account the advantage of a more compact and massive detector array, which can
be made of cubic-shaped crystals (compared to the cylindrical ones), this test
demonstrates the great potential of cubic Li$_{2}$$^{100}$MoO$_4$ scintillating
bolometers for high-sensitivity searches for the $^{100}$Mo $0\nu2\beta$ decay
in CROSS and CUPID projects.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:08:18 GMT""}]","2021-03-24"
"2011.13807","Sang-Eon Bak","Byoungjoon Ahn, Yongjun Ahn, Sang-Eon Bak, Viktor Jahnke, and
  Keun-Young Kim","Holographic teleportation in higher dimensions","36 pages, 10 figures",,"10.1007/JHEP07(2021)219",,"hep-th gr-qc quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study higher-dimensional traversable wormholes in the context of
Rindler-AdS/CFT. The hyperbolic slicing of a pure AdS geometry can be thought
of as a topological black hole that is dual to a conformal field theory in the
hyperbolic space. The maximally extended geometry contains two exterior regions
(the Rindler wedges of AdS) which are connected by a wormhole. We show that
this wormhole can be made traversable by a double trace deformation that
violates the average null energy condition (ANEC) in the bulk. We find an
analytic formula for the ANEC violation that generalizes Gao-Jafferis-Wall
result to higher-dimensional cases, and we show that the same result can be
obtained using the eikonal approximation. We show that the bound on the amount
of information that can be transferred through the wormhole quickly reduces as
we increase the dimensionality of spacetime. We also compute a two-sided
commutator that diagnoses traversability and show that, under certain
conditions, the information that is transferred through the wormhole propagates
with butterfly speed $v_B = \frac{1}{d-1}$.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:09:10 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 09:26:00 GMT""}]","2021-08-18"
"2011.13808","Franti\v{s}ek \v{S}tampach","Franti\v{s}ek \v{S}tampach","Asymptotic behavior and zeros of the Bernoulli polynomials of the second
  kind","23 pages, 2 figures, accepted for publication in the Journal of
  Approximation Theory",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main aim of this article is a careful investigation of the asymptotic
behavior of zeros of Bernoulli polynomials of the second kind. It is shown that
the zeros are all real and simple. The asymptotic expansions for the small,
large, and the middle zeros are computed in more detail. The analysis is based
on the asymptotic expansions of the Bernoulli polynomials of the second kind in
various regimes.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:10:57 GMT""}]","2020-11-30"
"2011.13809","Benoit Vicedo","Sylvain Lacroix and Benoit Vicedo","Integrable $\mathcal{E}$-Models, 4d Chern-Simons Theory and Affine
  Gaudin Models. I. Lagrangian Aspects",,"SIGMA 17 (2021), 058, 45 pages","10.3842/SIGMA.2021.058","ZMP-HH/20-22","hep-th","http://creativecommons.org/licenses/by-sa/4.0/","  We construct the actions of a very broad family of 2d integrable
$\sigma$-models. Our starting point is a universal 2d action obtained in
[arXiv:2008.01829] using the framework of Costello and Yamazaki based on 4d
Chern-Simons theory. This 2d action depends on a pair of 2d fields $h$ and
$\mathcal{L}$, with $\mathcal{L}$ depending rationally on an auxiliary complex
parameter, which are tied together by a constraint. When the latter can be
solved for $\mathcal{L}$ in terms of $h$ this produces a 2d integrable field
theory for the 2d field $h$ whose Lax connection is given by $\mathcal{L}(h)$.
We construct a general class of solutions to this constraint and show that the
resulting 2d integrable field theories can all naturally be described as
$\mathcal{E}$-models.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:12:30 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 06:10:14 GMT""}]","2021-06-11"
"2011.13810","Stefan Schr\""oder","Stefan Schr\""oder, Katharina Otto, Hannah Scharf, Klaus-Dieter Matz,
  Nicole Schmitz, Frank Scholten, Stefano Mottola, Frank Trauthan, Alexander
  Koncz, Harald Michaelis, Ralf Jaumann, Tra-Mi Ho, Hikaru Yabuta, Seiji Sugita","Spectrophotometric analysis of the Ryugu rock seen by MASCOT: Searching
  for a carbonaceous chondrite analog",,,"10.3847/PSJ/abbb97",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze images of a rock on Ryugu acquired in situ by MASCam, camera of
the MASCOT lander, with the aim of identifying possible carbonaceous chondrite
(CC) analogs. The rock's reflectance ($r_{\rm F} = 0.034 \pm 0.003$ at phase
angle $4.5^\circ \pm 0.1^\circ$) is consistent with Ryugu's average
reflectance, suggesting that the rock is typical for this asteroid. A
spectrophotometric analysis of the rock's inclusions provides clues to CC group
membership. Inclusions are generally brighter than the matrix. The dominant
variation in their color is a change of the visible spectral slope, with many
inclusions being either red or blue. Spectral variation in the red channel
hints at the presence of the 0.7~$\mu$m absorption band linked to hydrated
phyllosilicates. The inclusions are unusually large for a CC; we find that
their size distribution may best match that of the Renazzo (CR2) and Leoville
(CV3) meteorites. The Ryugu rock does not easily fit into any of the CC groups,
consistent with the idea that typical Ryugu-type meteorites are too fragile to
survive atmospheric entry.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:14:06 GMT""}]","2021-03-22"
"2011.13811","George A. Gontcharov","George Gontcharov and Aleksandr Mosenkov","Gaia DR2 giants in the Galactic dust -- II. Application of the reddening
  maps and models","accepted for publication in the Monthly Notices of the Royal
  Astronomical Society",,"10.1093/mnras/staa2728",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We exploit a complete sample of 101\,810 {\it Gaia} DR2 giants, selected in
Paper I in the space cylinder with a radius of 700 pc around the Sun and a
height of $|Z|=1800$ pc, using the {\it Gaia} DR2 parallaxes, $G_\mathrm{BP}$
and $G_\mathrm{RP}$ photometry, and {\it WISE} $W3$ photometry. We explain the
spatial variations of the modes of the observables
$G_\mathrm{BP}-G_\mathrm{RP}$ and $G_\mathrm{RP}-W3$ by the spatial variations
of the corresponding reddenings described in the GM20 3D dust distribution
model. Presented in this paper, GM20 is an advanced version of the model
introduced by Gontcharov in 2009. GM20 proposes two intersecting dust layers,
along the Galactic mid-plane and in the Gould Belt, with exponential vertical
and sinusoidal longitudinal variations of the dust spatial density in each
layer. The Belt layer is an ellipse, oriented nearly between the centre and
anticentre of the Galaxy, and with a semi-major and semi-minor axes of 600 and
146~pc, respectively. $G_\mathrm{BP}-G_\mathrm{RP}$ and $G_\mathrm{RP}-W3$ give
similar solutions, but different equatorial layer scale heights of $150\pm15$
and $180\pm15$~pc, respectively, and
$(G_\mathrm{BP}-G_\mathrm{RP})_0=(1.14\pm0.01)-(0.022\pm0.010)\,|Z|$,
$(G_\mathrm{RP}-W3)_0=(1.44\pm0.01)-(0.015\pm0.010)\,|Z|$, where $Z$ is in kpc.
We compare GM20 with several 3D reddening models and maps in their ability to
predict the observed colour modes. GM20 and the 3D map by Gontcharov appear to
be the best among the models and maps, respectively. However, the most reliable
models and maps mainly disagree only in their estimates of low reddening,
including the reddening across the whole dust layer.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:20:13 GMT""}]","2020-11-30"
"2011.13812","HoseinAli Jafari Abeshoori","HoseinAli Jafari Abeshoori, Seyed Saeed Azadfar","Speed-Up Ramp-Counter ADC Using Locality Principle : A systematic
  analysis","4 pages 3 figures 1 table 17 equations",,,,"eess.SY cs.SY eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work inspects the parameters that affect the conversion rate of a
ramp-counter ADC and propose two small systematical changes to reduce the time
needed to complete a single analog to digital conversion by use of the locality
principle point of view. System full architecture is modeled and simulated by
Matlab script and the results show up to 97% reduction in conversion time for
an electro-cardiograph record.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:20:56 GMT""}]","2020-11-30"
"2011.13813","Hirofumi Takesue","Hirofumi Takesue","A noisy opinion formation model with two opposing mass media","9 pages, 9 figures",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Processes of individual attitude formation and their macroscopic consequences
have become an intriguing research topic, and agent-based models of opinion
formation have been proposed to understand this phenomenon. This study
conducted an agent-based simulation and examined the role of mass media in a
noisy opinion formation process, where opinion heterogeneity is preserved by a
weak intensity of assimilation and errors accompanying opinion modifications.
In a computational model, agents conformed to their neighbours' opinions in
social networks. In addition, each agent tended to be influenced by one of a
two external agents with fixed opinions, that is, mass media that take opposite
positions on an opinion spectrum. The simulation results demonstrated that a
small probability of interactions with mass media reduces opinion heterogeneity
even with extreme mass media position values. However, a large frequency of
interactions with mass media increases opinion heterogeneity. Accordingly,
intermediate assimilation strength achieves the least heterogeneous opinion
distribution. The influence of mass media dampens the effects of network
topology. Our simulation implies that mass media can play qualitatively
different roles depending on their positions and intensity of influence.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:21:06 GMT""}]","2020-11-30"
"2011.13814","Eddy Collin","Ilya Golokolenov, Dylan Cattiaux, Sumit Kumar, Mika Sillanp\""a\""a,
  Laure Mercier de L\'epinay, Andrew Fefferman and Eddy Collin","Microwave single-tone optomechanics in the classical regime","Experimental implementation of arXiv:2007.14438","New J. Phys. Vol. 23, 053008 (2021)","10.1088/1367-2630/abf983",,"cond-mat.mes-hall","http://creativecommons.org/publicdomain/zero/1.0/","  We report on the quantitative experimental illustration of elementary
optomechanics within the classical regime. All measurements are performed in a
commercial dilution refrigerator on a mesoscopic drumhead aluminium resonator
strongly coupled to a microwave cavity, using only strict single-tone schemes.
Sideband asymmetry is reported using in-cavity microwave pumping, along with
noise squashing and back-action effects. Results presented in this paper are
analysed within the simple classical electric circuit theory, emphasizing the
analogous nature of classical features with respect to their usual quantum
description. The agreement with theory is obtained with no fitting parameters.
Besides, based on those results a simple method is proposed for the accurate
measurement of the ratio between microwave internal losses and external
coupling.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:22:31 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 12:11:36 GMT""}]","2021-05-26"
"2011.13815","Fraser Daly","Fraser Daly","Gamma, Gaussian and Poisson approximations for random sums using
  size-biased and generalized zero-biased couplings","19 pages; extended from original version to relax independence
  assumption between summands",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  Let $Y=X_1+\cdots+X_N$ be a sum of a random number of exchangeable random
variables, where the random variable $N$ is independent of the $X_j$, and the
$X_j$ are from the generalized multinomial model introduced by Tallis (1962).
This relaxes the classical assumption that the $X_j$ are independent. We use
zero-biased coupling and its generalizations to give explicit error bounds in
the approximation of $Y$ by a Gaussian random variable in Wasserstein distance
when either the random variables $X_j$ are centred or $N$ has a Poisson
distribution. We further establish an explicit bound for the approximation of
$Y$ by a gamma distribution in stop-loss distance for the special case where
$N$ is Poisson. Finally, we briefly comment on analogous Poisson approximation
results that make use of size-biased couplings. The special case of independent
$X_j$ is given special attention throughout. As well as establishing results
which extend beyond the independent setting, our bounds are shown to be
competitive with known results in the independent case.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:24:29 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 11:02:08 GMT""}]","2021-05-31"
"2011.13816","Lie Ju","Lie Ju, Xin Wang, Xin Zhao, Paul Bonnington, Tom Drummond, Zongyuan Ge","Leveraging Regular Fundus Images for Training UWF Fundus Diagnosis
  Models via Adversarial Learning and Pseudo-Labeling",,,"10.1109/TMI.2021.3056395",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, ultra-widefield (UWF) 200\degree~fundus imaging by Optos cameras
has gradually been introduced because of its broader insights for detecting
more information on the fundus than regular 30 degree - 60 degree fundus
cameras. Compared with UWF fundus images, regular fundus images contain a large
amount of high-quality and well-annotated data. Due to the domain gap, models
trained by regular fundus images to recognize UWF fundus images perform poorly.
Hence, given that annotating medical data is labor intensive and time
consuming, in this paper, we explore how to leverage regular fundus images to
improve the limited UWF fundus data and annotations for more efficient
training. We propose the use of a modified cycle generative adversarial network
(CycleGAN) model to bridge the gap between regular and UWF fundus and generate
additional UWF fundus images for training. A consistency regularization term is
proposed in the loss of the GAN to improve and regulate the quality of the
generated data. Our method does not require that images from the two domains be
paired or even that the semantic labels be the same, which provides great
convenience for data collection. Furthermore, we show that our method is robust
to noise and errors introduced by the generated unlabeled data with the
pseudo-labeling technique. We evaluated the effectiveness of our methods on
several common fundus diseases and tasks, such as diabetic retinopathy (DR)
classification, lesion detection and tessellated fundus segmentation. The
experimental results demonstrate that our proposed method simultaneously
achieves superior generalizability of the learned representations and
performance improvements in multiple tasks.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:25:30 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 03:38:41 GMT""}]","2021-02-03"
"2011.13817","Victor Fragoso","Victor Fragoso, Sudipta Sinha","Generalized Pose-and-Scale Estimation using 4-Point Congruence
  Constraints",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present gP4Pc, a new method for computing the absolute pose of a
generalized camera with unknown internal scale from four corresponding 3D
point-and-ray pairs. Unlike most pose-and-scale methods, gP4Pc is based on
constraints arising from the congruence of shapes defined by two sets of four
points related by an unknown similarity transformation. By choosing a novel
parametrization for the problem, we derive a system of four quadratic equations
in four scalar variables. The variables represent the distances of 3D points
along the rays from the camera centers. After solving this system via Groebner
basis-based automatic polynomial solvers, we compute the similarity
transformation using an efficient 3D point-point alignment method. We also
propose a specialized variant of our solver for the case of coplanar points,
which is computationally very efficient and about 3x faster than the fastest
existing solver. Our experiments on real and synthetic datasets, demonstrate
that gP4Pc is among the fastest methods in terms of total running time when
used within a RANSAC framework, while achieving competitive numerical
stability, accuracy, and robustness to noise.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:30:19 GMT""}]","2020-11-30"
"2011.13818","Sanjib Sharma","Sanjib Sharma, Michael R. Hayden, Joss Bland-Hawthorn, Dennis Stello,
  Sven Buder, Joel C. Zinn, Lorenzo Spina, Thomas Kallinger, Martin Asplund,
  Gayandhi M. De Silva, Valentina D'Orazi, Ken C. Freeman, Janez Kos, Geraint
  F. Lewis, Jane Lin, Karin Lind, Sarah L. Martell, Katharine J. Schlesinger,
  Jeffrey D. Simpson, Daniel B. Zucker, Tomaz Zwitter, Klemen Cotar, Boquan
  Chen, Prajwal R. Kafle, Shourya Khanna, Purmortal Wang, Rob A. Wittenmyer","The GALAH Survey: Dependence of elemental abundances on age and
  metallicity for stars in the Galactic disc","21 pages, 11 Figures",,"10.1093/mnras/stab3341",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using data from the GALAH survey, we explore the dependence of elemental
abundances on stellar age and metallicity among Galactic disc stars. We find
that the abundance of most elements can be predicted from age and [Fe/H] with
an intrinsic scatter of about 0.03 dex. We discuss the possible causes for the
existence of the abundance-age-metallicity relations. Using a stochastic
chemical enrichment scheme based on the size of Supernovae remnants, we show
the intrinsic scatter is expected to be small, about 0.05 dex or even smaller
if there is additional mixing in the ISM. Elemental abundances show trends with
both age and metallicity and the relationship is well described by a simple
model in which the dependence of abundance ([X/Fe]) on age and [Fe/H] are
additively separable. Elements can be grouped based on the direction of their
abundance gradient in the (age,[Fe/H]) plane and different groups can be
roughly associated with three distinct nucleosynthetic production sites, the
exploding massive stars, the exploding white dwarfs and the AGB stars. However,
the abundances of some elements, like Co, La, and Li, show large scatter for a
given age and metallicity, suggesting processes other than simple Galactic
chemical evolution are at play. We also compare the abundance trends of
main-sequence turn-off stars against that of giants, whose ages were estimated
using asteroseismic information from the K2 mission. For most elements, the
trends of main-sequence turn-off stars are similar to that of giants. The
existence of abundance relations implies that we can estimate the age and birth
radius of disc stars, which is important for studying the dynamic and chemical
evolution of the Galaxy.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:31:28 GMT""}]","2021-12-08"
"2011.13819","Nicola Pompeo","Nicola Pompeo, Andrea Alimenti, Kostiantyn Torokhtii, Giulia Sylva,
  Valeria Braccini, Enrico Silva","Pinning, flux flow resistivity and anisotropy of Fe(Se,Te) thin films
  from microwave measurements through a bitonal dielectric resonator","5 pages, 5 figures, conference ASC2020",,,,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the anisotropy of the vortex motion surface impedance of a \fst
thin film grown on a CaF$_2$ substrate. The dependence on the magnetic field
intensity up to 1.2 T and direction, both parallel and perpendicular to the
sample $c$-axis, was explored at fixed temperature at two distinct frequencies,
$\sim16\;$GHz and $\sim27\;$GHz, by means of bitonal dielectric resonator. The
free flux flow resistivity $\rho_{ff}$ was obtained by exploiting standard
models for the high frequency dynamics, whereas the angle dependence was
studied in the framework of the well known and widely used
Blatter-Geshkenbein-Larkin (BGL) scaling theory for anistropic superconductors.
Excellent agreement with the scaling law prescription by the fluxon flux flow
resistivity was obtained. From the scaling analysis, a low-field mass
anisotropy $\sim1.8$ was obtained, well within the value ranges reported in
literature. The angular dependence of the pinning constant suggests that
pinning is dominated by random, isotropic point pins, consistently with
critical current density measurements.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:32:11 GMT""}]","2020-11-30"
"2011.13820","Nikita Nikulsin","Nikita Nikulsin, Matthias Hoelzl, Alessandro Zocco, Karl Lackner,
  Sibylle Guenter","Testing of the new JOREK stellarator-capable model in the tokamak limit","23 pages, 1 table, 7 figures. Submitted to Journal of Plasma Physics","J. Plasma Phys. 87 (2021) 855870301","10.1017/S0022377821000477",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In preparation for extending the JOREK nonlinear MHD code to stellarators, a
hierarchy of stellarator-capable reduced and full MHD models has been derived
and tested. The derivation was presented at the EFTC 2019 conference.
Continuing this line of work, we have implemented the reduced MHD model
(arXiv:1907.12486) as well as an alternative model which was newly derived
using a different set of projection operators for obtaining the scalar momentum
equations from the full MHD vector momentum equation. With the new operators,
the reduced model matches the standard JOREK reduced models for tokamaks in the
tokamak limit and conserves energy exactly, while momentum conservation is less
accurate than in the original model whenever field-aligned flow is present.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:32:21 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 10:43:53 GMT""},{""version"":""v3"",""created"":""Tue, 30 Mar 2021 09:29:21 GMT""}]","2021-07-01"
"2011.13821","Guy Jehu","Ruth Britto, Guy R. Jehu and Andrea Orta","The dimension-shift conjecture for one-loop amplitudes","31 pages excluding citations",,"10.1007/JHEP04(2021)276",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A conjecture made by Bern, Dixon, Dunbar, and Kosower asserts a simple
dimension-shifting relationship between the one-loop structure of N = 4 MHV
amplitudes and all-plus helicity amplitudes in pure Yang-Mills theory. We prove
this conjecture to all orders in dimensional regularisation using unitarity
cuts, and evaluate the form of these simplest one-loop amplitudes using a
generalised D-dimensional unitarity technique which captures the full amplitude
to all multiplicities.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:32:32 GMT""},{""version"":""v2"",""created"":""Tue, 20 Apr 2021 11:48:44 GMT""}]","2021-05-19"
"2011.13822","Marc P. Bellon","Marc P. Bellon and Enrico I. Russo","Resurgent Analysis of Ward-Schwinger-Dyson Equations",,"SIGMA 17 (2021), 075, 18 pages","10.3842/SIGMA.2021.075",,"hep-th hep-ph math-ph math.MP","http://creativecommons.org/licenses/by-sa/4.0/","  Building on our recent derivation of the Ward-Schwinger-Dyson equations for
the cubic interaction model, we present here the first steps of their resurgent
analysis. In our derivation of the WSD equations, we made sure that they had
the properties of compatibility with the renormalisation group equations and
independence from a regularisation procedure which was known to allow for the
comparable studies in the Wess-Zumino model. The interactions between the
transseries terms for the anomalous dimensions of the field and the vertex is
at the origin of unexpected features, for which the effect of higher order
corrections is not precisely known at this stage: we are only at the beginning
of the journey to use resurgent methods to decipher non-perturbative effects in
quantum field theory.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:35:57 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 03:43:22 GMT""}]","2021-08-12"
"2011.13823","Aleix Roca Nonell","Aleix Roca Nonell, Vicen\c{c} Beltran Querol, Sergi Mateo Bellido","Introducing the Task-Aware Storage I/O (TASIO) Library","16 pages, 17 figures, conference","OpenMP: Conquering the Full Hardware Spectrum 15 (2019) 274-288","10.1007/978-3-030-28596-8_19",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Task-based programming models are excellent tools to parallelize and
seamlessly load balance an application workload. However, the integration of
I/O intensive applications and task-based programming models is lacking.
Typically, I/O operations stall the requesting thread until the data is
serviced by the backing device. Because the core where the thread was running
becomes idle, it should be possible to overlap the data query operation with
either computation workloads or even more I/O operations. Nonetheless,
overlapping I/O tasks with other tasks entails an extra degree of complexity
currently not managed by programming models' runtimes. In this work, we focus
on integrating storage I/O into the tasking model by introducing the Task-Aware
Storage I/O (TASIO) library. We test TASIO extensively with a custom benchmark
for a number of configurations and conclude that it is able to achieve speedups
up to 2x depending on the workload, although it might lead to slowdowns if not
used with the right settings.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:41:07 GMT""}]","2020-11-30"
"2011.13824","Kaidi Xu","Kaidi Xu, Huan Zhang, Shiqi Wang, Yihan Wang, Suman Jana, Xue Lin,
  Cho-Jui Hsieh","Fast and Complete: Enabling Complete Neural Network Verification with
  Rapid and Massively Parallel Incomplete Verifiers","Accepted by ICLR 2021",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Formal verification of neural networks (NNs) is a challenging and important
problem. Existing efficient complete solvers typically require the
branch-and-bound (BaB) process, which splits the problem domain into
sub-domains and solves each sub-domain using faster but weaker incomplete
verifiers, such as Linear Programming (LP) on linearly relaxed sub-domains. In
this paper, we propose to use the backward mode linear relaxation based
perturbation analysis (LiRPA) to replace LP during the BaB process, which can
be efficiently implemented on the typical machine learning accelerators such as
GPUs and TPUs. However, unlike LP, LiRPA when applied naively can produce much
weaker bounds and even cannot check certain conflicts of sub-domains during
splitting, making the entire procedure incomplete after BaB. To address these
challenges, we apply a fast gradient based bound tightening procedure combined
with batch splits and the design of minimal usage of LP bound procedure,
enabling us to effectively use LiRPA on the accelerator hardware for the
challenging complete NN verification problem and significantly outperform
LP-based approaches. On a single GPU, we demonstrate an order of magnitude
speedup compared to existing LP-based approaches.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:42:12 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 16:35:00 GMT""}]","2021-03-17"
"2011.13825","Judy Cha","Sajad Yazdani, Joshua V. Pondick, Aakash Kumar, Milad Yarali, John M.
  Woods, David J. Hynek, Diana Y. Qiu, and Judy J. Cha","Heterointerface effects on lithium-induced phase transitions in
  intercalated MoS2","4 figures and 1 table","ACS Applied Materials Interfaces 2021","10.1021/acsami.0c21495",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The intercalation-induced phase transition of MoS2 from the semiconducting 2H
to the semimetallic 1T' phase has been studied in detail for nearly a decade;
however, the effects of a heterointerface between MoS2 and other
two-dimensional (2D) crystals on the phase transition have largely been
overlooked. Here, ab initio calculations show that intercalating Li at a
MoS2-hexagonal boron nitride (hBN) interface stabilizes the 1T phase over the
2H phase of MoS2 by ~ 100 mJ m-2, suggesting that encapsulating MoS2 with hBN
may lower the electrochemical energy needed for the intercalation-induced phase
transition. However, in situ Raman spectroscopy of hBN-MoS2-hBN
heterostructures during electrochemical intercalation of Li+ shows that the
phase transition occurs at the same applied voltage for the heterostructure as
for bare MoS2. We hypothesize that the predicted thermodynamic stabilization of
the 1T'-MoS2-hBN interface is counteracted by an energy barrier to the phase
transition imposed by the steric hindrance of the heterointerface. The phase
transition occurs at lower applied voltages upon heating the heterostructure,
which supports our hypothesis. Our study highlights that interfacial effects of
2D heterostructures can go beyond modulating electrical properties and can
modify electrochemical and phase transition behaviors.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:45:06 GMT""}]","2022-01-06"
"2011.13826","Evgeniy Khain","Varun Nimmagadda, Oleg Kogan, Evgeniy Khain","Path-dependent course of epidemic: are two phases of quarantine better
  than one?","6 pages, 4 figures, accepted to EPL (Europhysics Letters)",,"10.1209/0295-5075/132/28003",,"physics.soc-ph cond-mat.stat-mech q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  The importance of a strict quarantine has been widely debated during the
COVID-19 epidemic even from the purely epidemiological point of view. One
argument against strict lockdown measures is that once the strict quarantine is
lifted, the epidemic comes back, and so the cumulative number of infected
individuals during the entire epidemic will stay the same. We consider an SIR
model on a network and follow the disease dynamics, modeling the phases of
quarantine by changing the node degree distribution. We show that the system
reaches different steady states based on the history: the outcome of the
epidemic is path-dependent despite the same final node degree distribution. The
results indicate that two-phase route to the final node degree distribution (a
strict phase followed by a soft phase) are always better than one phase (the
same soft one) unless all the individuals have the same number of connections
at the end (the same degree); in the latter case, the overall number of
infected is indeed history-independent. The modeling also suggests that the
optimal procedure of lifting the quarantine consists of releasing nodes in the
order of their degree - highest first.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:48:04 GMT""}]","2021-02-03"
"2011.13827","Myong Chol Pak","Sang Jun Cha, Myong Chol Pak, Kwang-Il Kim, and Su Gon Kim","Recrystallization Characteristics of Catalytic Alloy and Graphite in
  Diamond Synthesis","11 pages, 5 figures","J. Superhard Mater. 43 (2021) 336-343","10.3103/S1063457621050026",,"cond-mat.mtrl-sci cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  We first consider the recrystallization characteristics of catalysis alloy
and graphite in the process of diamond synthesis under the condition of super
high pressure and high temperature in catalysis method. In the process of
diamond synthesis catalysis metal is plastically deformed by increase of
pressure and then recrystallized as increasing the temperature. As catalysis
metal is recrystallized, the shape of graphite particle is in spherical shape
in the region contacting with the catalyst but in any shape in the opposite
region. In addition, we calculate the electron charge density distribution and
cohesive energies of cementite structure using the first principle method to
investigate the reciprocal interaction between transient metal elements and
carbon atoms in high-temperature catalyst synthesis. After determination of
lattice constant parameters, we obtain the cohesive energy by subtracting the
total energy of the crystal from the summation of total energies of atoms
composing the crystal and dividing it by the number of atoms. Therefore, the
effect of the catalyst on the diamond synthesis is to be analyzed
theoretically.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:49:01 GMT""}]","2021-11-19"
"2011.13828","Hynek Kovarik","Hynek Kovarik","Heat kernel estimates for two-dimensional relativistic Hamiltonians with
  magnetic field",,,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study semigroups generated by two-dimensional relativistic Hamiltonians
with magnetic field. In particular, for compactly supported radial magnetic
field we show how the long time behaviour of the associated heat kernel depends
on the flux of the field. Similar questions are addressed for Aharonov-Bohm
type magnetic field.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:52:00 GMT""}]","2020-11-30"
"2011.13829","James Juno","James Juno, Gregory G. Howes, Jason M. TenBarge, Lynn B. Wilson III,
  Anatoly Spitkovsky, Damiano Caprioli, Kristopher G. Klein, and Ammar Hakim","A Field-Particle Correlation Analysis of a Perpendicular Magnetized
  Collisionless Shock","49 pages, 20 figures",,"10.1017/S0022377821000623",,"physics.plasm-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the field-particle correlation technique, we examine the particle
energization in a 1D-2V continuum Vlasov--Maxwell simulation of a perpendicular
magnetized collisionless shock. The combination of the field-particle
correlation technique with the high fidelity representation of the particle
distribution function provided by a direct discretization of the Vlasov
equation allows us to ascertain the details of the exchange of energy between
the electromagnetic fields and the particles in phase space. We identify the
velocity-space signatures of shock-drift acceleration of the ions and adiabatic
heating of the electrons due to the perpendicular collisionless shock by
constructing a simplified model with the minimum ingredients necessary to
produce the observed energization signatures in the self-consistent
Vlasov-Maxwell simulation. We are thus able to completely characterize the
energy transfer in the perpendicular collisionless shock considered here and
provide predictions for the application of the field-particle correlation
technique to spacecraft measurements of collisionless shocks.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:55:52 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 15:49:37 GMT""}]","2021-07-21"
"2011.13830","Miruna-Stefana Sorea","Abeer Al Ahmadieh, Mario Kummer, Miruna-Stefana Sorea","A generalization of the space of complete quadrics","Accepted for publication in Le Matematiche","Le Matematiche, Vol. LXXVI (2021) - Issue II, pp. 431 - 446","10.4418/2021.76.2.9",,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To any homogeneous polynomial $h$ we naturally associate a variety $\Omega_h$
which maps birationally onto the graph $\Gamma_h$ of the gradient map $\nabla
h$ and which agrees with the space of complete quadrics when $h$ is the
determinant of the generic symmetric matrix. We give a sufficient criterion for
$\Omega_h$ being smooth which applies for example when $h$ is an elementary
symmetric polynomial. In this case $\Omega_h$ is a smooth toric variety
associated to a certain generalized permutohedron. We also give examples when
$\Omega_h$ is not smooth.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:57:17 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 18:48:34 GMT""}]","2022-01-25"
"2011.13831","Pierre Ablin","Pierre Ablin","Deep orthogonal linear networks are shallow",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of training a deep orthogonal linear network, which
consists of a product of orthogonal matrices, with no non-linearity in-between.
We show that training the weights with Riemannian gradient descent is
equivalent to training the whole factorization by gradient descent. This means
that there is no effect of overparametrization and implicit bias at all in this
setting: training such a deep, overparametrized, network is perfectly
equivalent to training a one-layer shallow network.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:57:19 GMT""}]","2020-11-30"
"2011.13833","Michael A. Fedderke","Michael A. Fedderke, Peter W. Graham, and Surjeet Rajendran","Gravity Gradient Noise from Asteroids","26 pages, 7 figures. Published version","Phys. Rev. D 103, 103017 (2021)","10.1103/PhysRevD.103.103017",,"gr-qc astro-ph.EP astro-ph.HE astro-ph.IM hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The gravitational coupling of nearby massive bodies to test masses in a
gravitational wave (GW) detector cannot be shielded, and gives rise to 'gravity
gradient noise' (GGN) in the detector. In this paper we show that for any GW
detector using local test masses in the Inner Solar System, the GGN from the
motion of the field of $\sim 10^5$ Inner Solar System asteroids presents an
irreducible noise floor for the detection of GW that rises exponentially at low
frequencies. This severely limits prospects for GW detection using local test
masses for frequencies $f_{\text{GW}} \lesssim (\text{few})\times 10^{-7}\,$Hz.
At higher frequencies, we find that the asteroid GGN falls rapidly enough that
detection may be possible; however, the incompleteness of existing asteroid
catalogs with regard to small bodies makes this an open question around
$f_{\text{GW}}\sim \mu$Hz, and further study is warranted. We show that a
detector network placed in the Outer Solar System would not be overwhelmed by
this noise above $\sim 10\,$nHz, and make comments on alternative approaches
that could overcome the limitations of local test masses for GW detection in
the $\sim 10\,$nHz-$\mu$Hz band.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:00:00 GMT""},{""version"":""v2"",""created"":""Sat, 15 May 2021 19:23:07 GMT""}]","2021-05-24"
"2011.13834","Mohan Li","Mohan Li, Catalin Zorila and Rama Doddipatla","Transformer-based Online Speech Recognition with Decoder-end Adaptive
  Computation Steps","7 pages, 1 figure, accepted at SLT 2021",,,,"eess.AS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Transformer-based end-to-end (E2E) automatic speech recognition (ASR) systems
have recently gained wide popularity, and are shown to outperform E2E models
based on recurrent structures on a number of ASR tasks. However, like other E2E
models, Transformer ASR also requires the full input sequence for calculating
the attentions on both encoder and decoder, leading to increased latency and
posing a challenge for online ASR. The paper proposes Decoder-end Adaptive
Computation Steps (DACS) algorithm to address the issue of latency and
facilitate online ASR. The proposed algorithm streams the decoding of
Transformer ASR by triggering an output after the confidence acquired from the
encoder states reaches a certain threshold. Unlike other monotonic attention
mechanisms that risk visiting the entire encoder states for each output step,
the paper introduces a maximum look-ahead step into the DACS algorithm to
prevent from reaching the end of speech too fast. A Chunkwise encoder is
adopted in our system to handle real-time speech inputs. The proposed online
Transformer ASR system has been evaluated on Wall Street Journal (WSJ) and
AIShell-1 datasets, yielding 5.5% word error rate (WER) and 7.1% character
error rate (CER) respectively, with only a minor decay in performance when
compared to the offline systems.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:02:55 GMT""}]","2020-11-30"
"2011.13835","Andrea De Jesus Torres","Andrea de Jesus Torres (1), Luca Sanguinetti (1), Emil Bj\""ornson (2)
  ((1) University of Pisa, (2) Link\""oping University)","Near- and Far-Field Communications with Large Intelligent Surfaces","5 pages, 10 figures, Asilomar Conference on Signals Systems and
  Computers",,,,"eess.SP cs.IT math.IT","http://creativecommons.org/publicdomain/zero/1.0/","  This paper studies the uplink spectral efficiency (SE) achieved by two
single-antenna user equipments (UEs) communicating with a Large Intelligent
Surface (LIS), defined as a planar array consisting of $N$ antennas that each
has area $A$. The analysis is carried out with a deterministic line-of-sight
propagation channel model that captures key fundamental aspects of the
so-called geometric near-field of the array. Maximum ratio (MR) and minimum
mean squared error (MMSE) combining schemes are considered. With both schemes,
the signal and interference terms are numerically analyzed as a function of the
position of the transmitting devices when the width/height $L = \sqrt{NA}$ of
the square-shaped array grows large. The results show that an exact near-field
channel model is needed to evaluate the SE whenever the distance of
transmitting UEs is comparable with the LIS' dimensions. It is shown that, if
$L$ grows, the UEs are eventually in the geometric near-field and the
interference does not vanish. MMSE outperforms MR for an LIS of practically
large size.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:03:38 GMT""}]","2020-11-30"
"2011.13836","Alexey A. Gavrilov","Yulia D. Gordievskaya, Elena Yu. Kramarenko, Alexey A. Gavrilov","The Effect of Explicit Polar Species on Conformational Behavior of a
  Single Polyelectrolyte Chain",,,"10.1039/D1CP03167H",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we investigated the question of how the molecular nature of the
dielectric media and the polymer-solvent dielectric mismatch affect the
collapse of a polyelectrolyte chain in solution by means of dissipative
particle dynamics simulations. First, we studied whether the explicit treatment
of dielectric media as polar beads instead of homogeneous dielectric background
results in a different system behavior. We showed that the explicit treatment
of polar beads facilitates the chain collapse, i.e. it occurs at smaller values
of the electrostatic strength parameter values ${\lambda}^2 \sim
Q^2/({\epsilon}kT)$. We believe that the main reason for such behavior is that
the dielectric response is in fact a collective effect, and the ""effective""
dielectric permittivity is different from the bulk value when the charges are
close to each other and/or the density of the charges is high enough. This
implies that the value of ${\lambda}$ does not have a universal meaning due to
the small-scale effects related to the presence of polar species; therefore,
changing the total unit charge $Q$ or the temperature $kT$ is not equivalent to
changing ${\epsilon}$. Next, we investigated how the difference of the
dielectric permittivities of the polymer chain and solvent affects the
collapse. We showed the polar chain adapts less swollen conformations in the
polyelectrolyte regime and collapses easier compared to the case of non-polar
chain; the possible reasons for such behavior are discussed.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:04:37 GMT""}]","2021-12-15"
"2011.13837","Massimo Bartoletti","Massimo Bartoletti, Letterio Galletta, Maurizio Murgia","A theory of transaction parallelism in blockchains","arXiv admin note: text overlap with arXiv:1905.04366","Logical Methods in Computer Science, Volume 17, Issue 4 (November
  18, 2021) lmcs:8722","10.46298/lmcs-17(4:10)2021",,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Decentralized blockchain platforms have enabled the secure exchange of
crypto-assets without the intermediation of trusted authorities. To this
purpose, these platforms rely on a peer-to-peer network of byzantine nodes,
which collaboratively maintain an append-only ledger of transactions, called
blockchain. Transactions represent the actions required by users, e.g. the
transfer of some units of crypto-currency to another user, or the execution of
a smart contract which distributes crypto-assets according to its internal
logic. Part of the nodes of the peer-to-peer network compete to append
transactions to the blockchain. To do so, they group the transactions sent by
users into blocks, and update their view of the blockchain state by executing
these transactions in the chosen order. Once a block of transactions is
appended to the blockchain, the other nodes validate it, re-executing the
transactions in the same order. The serial execution of transactions does not
take advantage of the multi-core architecture of modern processors, so
contributing to limit the throughput. In this paper we develop a theory of
transaction parallelism for blockchains, which is based on static analysis of
transactions and smart contracts. We illustrate how blockchain nodes can use
our theory to parallelize the execution of transactions. Initial experiments on
Ethereum show that our technique can improve the performance of nodes.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:06:11 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 18:12:31 GMT""},{""version"":""v3"",""created"":""Sun, 3 Oct 2021 12:26:24 GMT""},{""version"":""v4"",""created"":""Wed, 17 Nov 2021 09:20:42 GMT""}]","2021-12-11"
"2011.13838","Dirk Puetzfeld","Peter A. Hogan, Dirk Puetzfeld","Bonnor--Vaidya Charged Point Mass in an External Maxwell Field","14 pages, 2 figures","Phys. Rev. D 103, 044039 (2021)","10.1103/PhysRevD.103.044039",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By introducing external Maxwell and gravitational fields we modify the
Bonnor--Vaidya field of an arbitrarily accelerating charged mass moving
rectilinearly in order to satisfy the vacuum Einstein--Maxwell field equations
approximately, assuming the charge $e$ and the mass $m$ are small of first
order.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:06:38 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 16:58:11 GMT""}]","2021-02-22"
"2011.13839","Mat\v{e}j Dost\'al","J. Ad\'amek, M. Dost\'al and J. Velebil","A categorical view of varieties of ordered algebras",,,,,"math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that classical varieties of $\Sigma$-algebras correspond
bijectively to finitary monads on $\mathsf{Set}$. We present an analogous
result for varieties of ordered $\Sigma$-algebras, i.e., classes presented by
inequations between $\Sigma$-terms. We prove that they correspond bijectively
to strongly finitary monads on $\mathsf{Pos}$. That is, those finitary monads
which preserve reflexive coinserters. We deduce that strongly finitary monads
have a coinserter presentation, analogous to the coequaliser presentation of
finitary monads due to Kelly and Power. We also show that these monads are
liftings of finitary monads on $\mathsf{Set}$.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:07:24 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 20:53:59 GMT""}]","2021-01-07"
"2011.13840","Lei Gao","Fuhui Li, Ligang Huang, Laiyang Dang, Guolu Yin, Lei Gao, Tianyi Lan,
  Yujia Li, Lidan Jiang, Leilei Shi, and Tao Zhu","Self-adaptive single frequency laser assisted by distributed feedbacks",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  High-coherence light sources with an ultra-narrow linewidth are of
considerable research interests in numerous fields, such as laser
interferometer gravitational-wave observatory, laser radio, etc. Herein,
commencing from the in-depth analysis for consumption and replenishment law of
the carriers in the gain-band under excitation of the feedback signal, a
compression idea to compress extremely laser linewidth assisted by distributed
feedback has been proposed. Consequentially, a novel laser configuration is
demonstrated. A cavity mode signal matching with the output wavelength is fed
back into the main cavity by the distributed feedback structure to provide an
excitation signal required for laser gain. Moreover, the corresponding
experimental investigation is conducted based on an on-chip laser system with
distributed feedback. Eventually, an ultra-narrow linewidth laser with a side
mode suppuration ratio of 80 dB, a linewidth of 10 Hz, a Lorentzian linewidth
of sub Hz, and a relative intensity noise (RIN) of -150 dB/Hz is obtained under
normal conditions. The proposed idea is valid in any other gain-types lasers
with diverse wavelengths, which also provides a new perspective for other laser
parameters for extreme modulation.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:07:30 GMT""}]","2020-11-30"
"2011.13841","James Juno","Gregory G. Howes, James Juno, Jason M. TenBarge, Lynn B. Wilson III,
  Damiano Caprioli, and Anatoly Spitkovsky","A Field-Particle Correlation Analysis of a Perpendicular Magnetized
  Collisionless Shock: I. Theory","During the review process, it was requested that 2011.13841 be merged
  with 2011.13829. I have replaced 2011.13829 with the new merged paper and
  would thus like to withdraw this original paper",,,,"physics.plasm-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collisionless shocks play an important role in space and astrophysical
plasmas by irreversibly converting the energy of the incoming supersonic plasma
flows into other forms, including plasma heat, particle acceleration, and
electromagnetic field energy. Here we present the application of the
field-particle correlation technique to an idealized perpendicular magnetized
collisionless shock to understand the transfer of energy from the incoming flow
into ion and electron energy through the structure of the shock. The connection
between a Lagrangian perspective following particle trajectories, and an
Eulerian perspective observing the net energization of the distribution of
particles, illuminates the energy transfer mechanisms. Using the field-particle
correlation analysis, we identify the velocity-space signature of shock-drift
acceleration of the ions in the shock foot, as well as the velocity-space
signature of adiabatic electron heating through the shock ramp.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:08:30 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 15:53:08 GMT""}]","2021-05-27"
"2011.13842","Tanjona Radonirina Rabemananjara","Tanjona R. Rabemananjara","Small-$p_T$ and large-$x$ regions for Higgs transverse momentum
  distributions","5 pages, 3 figures","Nucl.Part.Phys.Proc. 312-317 (2021) 27-31","10.1016/j.nuclphysbps.2021.05.007",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It was shown recently that standard resummation of logarithms of $Q/p_T$ can
be supplemented with the resummation of logarithmic contributions at large
$x=Q^2/s$ in the case of a colourless final state such as Higgs produced via
gluon fusion or the production of a lepton pair via Drell--Yan mechanism. Such
an improved transverse momentum resummation takes into account soft emissions
that are emitted at very small angles. We report on recent phenomenological
studies of a combined threshold-improved $p_T$ and threshold resummation
formalism to the Higgs boson produced at the LHC where small-$p_T$ and
threshold logarithms are resummed up to NNLL and NNLL* respectively. We show
that the effect of the modified $p_T$ resummation yields a faster perturbative
convergence in the small-$p_T$ region while the effect of the threshold one
improves the agreement with fixed-order calculations in the medium and
large-$p_T$ regions.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:15:10 GMT""}]","2021-09-09"
"2011.13843","Elena Burceanu","Elena Burceanu","SFTrack++: A Fast Learnable Spectral Segmentation Approach for
  Space-Time Consistent Tracking","Accepted at Neural Information Processing Systems (NeurIPS) 2020 -
  Pre-registration Workshop and at The International Conference on Computer
  Vision (ICCV) 2021 - Structured Representations for Video Understanding
  Workshop",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an object tracking method, SFTrack++, that smoothly learns to
preserve the tracked object consistency over space and time dimensions by
taking a spectral clustering approach over the graph of pixels from the video,
using a fast 3D filtering formulation for finding the principal eigenvector of
this graph's adjacency matrix. To better capture complex aspects of the tracked
object, we enrich our formulation to multi-channel inputs, which permit
different points of view for the same input. The channel inputs are in our
experiments, the output of multiple tracking methods. After combining them,
instead of relying only on hidden layers representations to predict a good
tracking bounding box, we explicitly learn an intermediate, more refined one,
namely the segmentation map of the tracked object. This prevents the rough
common bounding box approach to introduce noise and distractors in the learning
process. We test our method, SFTrack++, on five tracking benchmarks: OTB, UAV,
NFS, GOT-10k, and TrackingNet, using five top trackers as input. Our
experimental results validate the pre-registered hypothesis. We obtain
consistent and robust results, competitive on the three traditional benchmarks
(OTB, UAV, NFS) and significantly on top of others (by over $1.1\%$ on
accuracy) on GOT-10k and TrackingNet, which are newer, larger, and more varied
datasets.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:15:20 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 11:25:56 GMT""},{""version"":""v3"",""created"":""Thu, 4 Nov 2021 14:04:45 GMT""}]","2021-11-05"
"2011.13844","James Smith","James E. Smith","A Temporal Neural Network Architecture for Online Learning","13 pages, 10 figures",,,,"cs.NE cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A long-standing proposition is that by emulating the operation of the brain's
neocortex, a spiking neural network (SNN) can achieve similar desirable
features: flexible learning, speed, and efficiency. Temporal neural networks
(TNNs) are SNNs that communicate and process information encoded as relative
spike times (in contrast to spike rates). A TNN architecture is proposed, and,
as a proof-of-concept, TNN operation is demonstrated within the larger context
of online supervised classification. First, through unsupervised learning, a
TNN partitions input patterns into clusters based on similarity. The TNN then
passes a cluster identifier to a simple online supervised decoder which
finishes the classification task. The TNN learning process adjusts synaptic
weights by using only signals local to each synapse, and clustering behavior
emerges globally. The system architecture is described at an abstraction level
analogous to the gate and register transfer levels in conventional digital
design. Besides features of the overall architecture, several TNN components
are new to this work. Although not addressed directly, the overall research
objective is a direct hardware implementation of TNNs. Consequently, all the
architecture elements are simple, and processing is done at very low precision.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:15:29 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 22:29:32 GMT""}]","2021-02-24"
"2011.13845","Andrew Aberdein","Andrew Aberdein","Dialogue Types, Argumentation Schemes, and Mathematical Practice:
  Douglas Walton and Mathematics","24 pages","Journal of Applied Logics 8(1), 2021, pp. 159-182",,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Douglas Walton's multitudinous contributions to the study of argumentation
seldom, if ever, directly engage with argumentation in mathematics.
Nonetheless, several of the innovations with which he is most closely
associated lend themselves to improving our understanding of mathematical
arguments. I concentrate on two such innovations: dialogue types ({\S}1) and
argumentation schemes ({\S}2). I argue that both devices are much more
applicable to mathematical reasoning than may be commonly supposed.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:22:29 GMT""}]","2021-02-22"
"2011.13846","Victor Augias","Victor Augias and Daniel M. A. Barreto","Persuading a Wishful Thinker",,,,,"econ.TH","http://creativecommons.org/licenses/by/4.0/","  We analyze a model of persuasion in which Receiver forms wishful non-Bayesian
beliefs. The effectiveness of persuasion depends on Receiver's material stakes:
it is more effective when intended to encourage risky behavior that potentially
lead to a high payoff and less effective when intended to encourage more
cautious behavior. We illustrate this insight with applications showing why
informational interventions are often ineffective in inducing greater
investment in preventive health treatments, how financial advisors might take
advantage of their clients overoptimistic beliefs and why strategic information
disclosure to voters with different partisan preferences can lead to belief
polarization in an electorate.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:25:01 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 08:29:27 GMT""},{""version"":""v3"",""created"":""Wed, 8 Sep 2021 12:50:49 GMT""},{""version"":""v4"",""created"":""Mon, 14 Feb 2022 17:33:26 GMT""}]","2022-02-15"
"2011.13847","Vieri Giuliano Santucci","Vieri Giuliano Santucci and Davide Montella and Bruno Castro da Silva
  and Gianluca Baldassarre","Autonomous learning of multiple, context-dependent tasks",,,,,"cs.RO cs.LG","http://creativecommons.org/licenses/by/4.0/","  When facing the problem of autonomously learning multiple tasks with
reinforcement learning systems, researchers typically focus on solutions where
just one parametrised policy per task is sufficient to solve them. However, in
complex environments presenting different contexts, the same task might need a
set of different skills to be solved. These situations pose two challenges: (a)
to recognise the different contexts that need different policies; (b) quickly
learn the policies to accomplish the same tasks in the new discovered contexts.
These two challenges are even harder if faced within an open-ended learning
framework where an agent has to autonomously discover the goals that it might
accomplish in a given environment, and also to learn the motor skills to
accomplish them. We propose a novel open-ended learning robot architecture,
C-GRAIL, that solves the two challenges in an integrated fashion. In
particular, the architecture is able to detect new relevant contests, and
ignore irrelevant ones, on the basis of the decrease of the expected
performance for a given goal. Moreover, the architecture can quickly learn the
policies for the new contexts by exploiting transfer learning importing
knowledge from already acquired policies. The architecture is tested in a
simulated robotic environment involving a robot that autonomously learns to
reach relevant target objects in the presence of multiple obstacles generating
several different obstacles. The proposed architecture outperforms other models
not using the proposed autonomous context-discovery and transfer-learning
mechanisms.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:25:36 GMT""}]","2020-11-30"
"2011.13848","Refik Mansuroglu","Refik Mansuroglu and Hanno Sahlmann","Kinematics of arbitrary spin matter fields in loop quantum gravity","21 pages v2: Minor changes and rearrangements of the text, removed
  various typos. Version essentially identical to the one published in PRD","Phys. Rev. D 103, 106010 (2021)","10.1103/PhysRevD.103.106010",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  Loop quantum gravity envisions a small scale structure of spacetime that is
markedly different from that of the classical spacetime continuum. This has
ramifications for the excitation of matter fields and for their coupling to
gravity. There is a general understanding of how to formulate scalar fields,
spin $\frac{1}{2}$ fields and gauge fields in the framework of loop quantum
gravity. The goal of the present work is to investigate kinematical aspects of
this coupling. We will study implications of the Gau{\ss} and diffeomorphism
constraint for the quantum theory: We define and study a less ambiguous variant
of the Baez-Krasnov path observables, and investigate symmetry properties of
spin network states imposed by diffeomorphism group averaging. We will do this
in a setting which allows for matter excitations of spin $\frac{1}{2}$ and
higher. In the case of spin $\frac{1}{2}$, we will also discuss extensions of
it by introducing an electromagnetic field and antiparticles. We finally
discuss in how far the picture with matter excitations of higher spin can be
obtained from classical actions for higher spin fields.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:27:50 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 21:29:14 GMT""}]","2021-05-19"
"2011.13850","Miriam Fritsch","BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, S.
  Ahmed, M. Albrecht, M. Alekseev, A. Amoroso, Q. An, Y. Bai, O. Bakina, R.
  Baldini Ferroli, I. Balossino, Y. Ban, K. Begzsuren, J. V. Bennett, N.
  Berger, M. Bertani, D. Bettoni, F. Bianchi, J Biernat, J. Bloms, I. Boyko, R.
  A. Briere, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J.
  Chai, J. F. Chang, W. L. Chang, G. Chelkov, D. Y. Chen, G. Chen, H. S. Chen,
  J. C. Chen, M. L. Chen, S. J. Chen, Y. B. Chen, W. S. Cheng, G. Cibinetto, F.
  Cossio, X. F. Cui, H. L. Dai, J. P. Dai, X. C. Dai, A. Dbeyssi, D. Dedovich,
  Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, Y. Ding, C.
  Dong, J. Dong, L. Y. Dong, M. Y. Dong, Z. L. Dou, S. X. Du, J. Z. Fan, J.
  Fang, S. S. Fang, Y. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C.
  Q. Feng, M. Fritsch, C. D. Fu, Y. Fu, X. L. Gao, Y. Gao, Y. Gao, Y. G. Gao,
  Z. Gao, I. Garzia, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X.
  Gong, W. Gradl, M. Greco, L. M. Gu, M. H. Gu, S. Gu, Y. T. Gu, A. Q. Guo, L.
  B. Guo, R. P. Guo, Y. P. Guo, Y. P. Guo, A. Guskov, S. Han, X. Q. Hao, F. A.
  Harris, N. H\""usken, K. L. He, F. H. Heinsius, T. Held, Y. K. Heng, M.
  Himmelreich, T. Holtmann, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, T. Hu, Y.
  Hu, G. S. Huang, X. T. Huang, X. Z. Huang, Y. P. Huang, T. Hussain, W.
  Ikegami Andersson, W. Imoehl, M. Irshad, S. Jaeger, Q. Ji, Q. P. Ji, X. B.
  Ji, X. L. Ji, H. B. Jiang, X. S. Jiang, X. Y. Jiang, J. B. Jiao, Z. Jiao, D.
  P. Jin, S. Jin, Y. Jin, T. Johansson, N. Kalantar-Nayestanaki, X. S. Kang, R.
  Kappert, M. Kavatsyuk, B. C. Ke, I. K. Keshk, A. Khoukaz, P. Kiese, R.
  Kiuchi, R. Kliemt, L. Koch, O. B. Kolcu, B. Kopf, M. Kuemmel, M. Kuessner, A.
  Kupsc, M. G. Kurth, W. K\""uhn, J. S. Lange, P. Larin, A. Lavania, L. Lavezzi,
  H. Leithoff, T. Lenz, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li,
  J. C. Li, J. W. Li, Ke Li, L. K. Li, Lei Li, P. L. Li, P. R. Li, Q. Y. Li, S.
  Y. Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, X. N. Li, Z. Y. Li, H. Liang,
  H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, J. Libby, C. X.
  Lin, D. X. Lin, B. Liu, B. J. Liu, C. X. Liu, D. Liu, D. Y. Liu, F. H. Liu,
  Fang Liu, Feng Liu, H. B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B.
  Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, Q. Liu, S. B. Liu, T. Liu,
  X. Liu, X. Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q. Liu, Y. F. Long, X. C. Lou, H.
  J. Lu, J. D. Lu, J. G. Lu, Y. Lu, Y. P. Lu, C. L. Luo, M. X. Luo, P. W. Luo,
  T. Luo, X. L. Luo, S. Lusso, X. R. Lyu, F. C. Ma, H. L. Ma, L. L. Ma, M. M.
  Ma, Q. M. Ma, X. N. Ma, X. X. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, M.
  Maggiora, S. Maldaner, S. Malde, A. Mangoni, Y. J. Mao, Z. P. Mao, S.
  Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, J. Min, T. J. Min, R.
  E. Mitchell, X. H. Mo, Y. J. Mo, C. Morales Morales, N. Yu. Muchnoi, H.
  Muramatsu, A. Mustafa, S. Nakhoul, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z.
  Ning, S. Nisar, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, P.
  Patteri, M. Pelizaeus, H. P. Peng, K. Peters, J. Pettersson, J. L. Ping, R.
  G. Ping, A. Pitka, R. Poling, V. Prasad, H. R. Qi, H. R. Qi, M. Qi, T. Y. Qi,
  T. Y. Qi, S. Qian, C. F. Qiao, N. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q.
  Qu, K. Ravindran, C. F. Redmer, M. Richter, A. Rivetti, V. Rodin, M. Rolo, G.
  Rong, Ch. Rosner, M. Rump, A. Sarantsev, Y. Schelhaas, C. Schnier, K.
  Schoenning, W. Shan, X. Y. Shan, M. Shao, C. P. Shen, P. X. Shen, X. Y. Shen,
  H. Y. Sheng, X. Shi, X. D Shi, J. J. Song, Q. Q. Song, X. Y. Song, S. Sosio,
  C. Sowa, S. Spataro, F. F. Sui, G. X. Sun, J. F. Sun, L. Sun, S. S. Sun, Y.
  J. Sun, Y. K. Sun, Y. Z. Sun, Z. J. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G.
  Y. Tang, X. Tang, V. Thoren, I. Uman, B. Wang, B. L. Wang, C. W. Wang, D. Y.
  Wang, K. Wang, L. L. Wang, L. S. Wang, M. Wang, M. Z. Wang, Meng Wang, P. L.
  Wang, W. P. Wang, X. Wang, X. F. Wang, X. L. Wang, Y. Wang, Y. Wang, Y. D.
  Wang, Y. F. Wang, Y. Q. Wang, Z. Wang, Z. G. Wang, Z. Y. Wang, Zongyuan Wang,
  T. Weber, D. H. Wei, P. Weidenkaff, F. Weidner, H. W. Wen, S. P. Wen, U.
  Wiedner, G. Wilkinson, M. Wolke, L. H. Wu, L. J. Wu, Z. Wu, L. Xia, S. Y.
  Xiao, Y. J. Xiao, Z. J. Xiao, Y. G. Xie, Y. H. Xie, T. Y. Xing, X. A. Xiong,
  G. F. Xu, J. J. Xu, Q. J. Xu, W. Xu, X. P. Xu, F. Yan, L. Yan, L. Yan, W. B.
  Yan, W. C. Yan, W. C. Yan, H. J. Yang, H. X. Yang, L. Yang, R. X. Yang, S. L.
  Yang, Y. H. Yang, Y. X. Yang, Yifan Yang, M. Ye, M. H. Ye, J. H. Yin, Z. Y.
  You, B. X. Yu, C. X. Yu, J. S. Yu, T. Yu, C. Z. Yuan, X. Q. Yuan, Y. Yuan, A.
  Yuncu, A. A. Zafar, Y. Zeng, B. X. Zhang, B. Y. Zhang, C. C. Zhang, D. H.
  Zhang, H. H. Zhang, H. Y. Zhang, J. Zhang, J. L. Zhang, J. Q. Zhang, J. Q.
  Zhang, J. W. Zhang, J. Y. Zhang, J. Z. Zhang, K. Zhang, L. Zhang, Lei Zhang,
  S. F. Zhang, T. J. Zhang, X. Y. Zhang, Y. H. Zhang, Y. T. Zhang, Yan Zhang,
  Yao Zhang, Yi Zhang, Yu Zhang, Z. H. Zhang, Z. P. Zhang, Z. Y. Zhang, G.
  Zhao, J. W. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, Q.
  Zhao, S. J. Zhao, T. C. Zhao, Y. B. Zhao, Z. G. Zhao, A. Zhemchugov, B.
  Zheng, J. P. Zheng, Y. Zheng, Y. H. Zheng, B. Zhong, L. Zhou, L. P. Zhou, Q.
  Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu,
  S. H. Zhu, W. J. Zhu, Y. C. Zhu, Y. S. Zhu, Z. A. Zhu, J. Zhuang, B. S. Zou,
  J. H. Zou","Search for the reaction channel $e^+e^- \rightarrow \eta_c\eta
  \pi^+\pi^-$ at center-of-mass energies from 4.23 to 4.60 GeV",,"Phys. Rev. D 103, 032004 (2021)","10.1103/PhysRevD.103.032004",,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using data collected with the BESIII detector operating at the Beijing
Electron Positron Collider, we search for the process $e^+e^-\rightarrow
\eta_c\eta \pi^+\pi^-$. The search is performed using five large data sets
recorded at center-of-mass energies of 4.23, 4.26, 4.36, 4.42, and 4.60 GeV.
The $\eta_c$ meson is reconstructed in 16 exclusive decay modes. No signal is
observed in the $\eta_c$ mass region at any center-of-mass energy. The upper
limits on the reaction cross sections are determined to be 6.2, 10.8, 27.6,
22.6 and 23.7 pb at the 90% confidence level at the center-of-mass energies
listed above.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:29:07 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 08:31:27 GMT""}]","2021-03-16"
"2011.13851","Mahdi Rezaei","Soheil Khatibi, Meisam Teimouri, Mahdi Rezaei","Real-time Active Vision for a Humanoid Soccer Robot Using Deep
  Reinforcement Learning","The paper has been accepted in ICAART 2021",,,,"cs.RO cs.AI cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we present an active vision method using a deep reinforcement
learning approach for a humanoid soccer-playing robot. The proposed method
adaptively optimises the viewpoint of the robot to acquire the most useful
landmarks for self-localisation while keeping the ball into its viewpoint.
Active vision is critical for humanoid decision-maker robots with a limited
field of view. To deal with an active vision problem, several probabilistic
entropy-based approaches have previously been proposed which are highly
dependent on the accuracy of the self-localisation model. However, in this
research, we formulate the problem as an episodic reinforcement learning
problem and employ a Deep Q-learning method to solve it. The proposed network
only requires the raw images of the camera to move the robot's head toward the
best viewpoint. The model shows a very competitive rate of 80% success rate in
achieving the best viewpoint. We implemented the proposed method on a humanoid
robot simulated in Webots simulator. Our evaluations and experimental results
show that the proposed method outperforms the entropy-based methods in the
RoboCup context, in cases with high self-localisation errors.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:29:48 GMT""}]","2020-11-30"
"2011.13852","Julian Kranz","Julian Kranz","The weak containment problem for \'etale groupoids which are strongly
  amenable at infinity","10 pages, added some clarifying comments and Lemma 5.3. To appear in
  J. Oper. Theory",,,,"math.OA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that an \'etale groupoid which is strongly amenable at infinity is
amenable whenever its full and reduced $C^*$-algebras coincide.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:30:14 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 09:19:45 GMT""},{""version"":""v3"",""created"":""Sun, 30 Jan 2022 20:27:31 GMT""}]","2022-02-01"
"2011.13853","Tal Adi","Tal Adi and Ely D. Kovetz","Can Conformally Coupled Modified Gravity Solve The Hubble Tension?","14 pages, 4 figures, 9 tables","Phys. Rev. D 103, 023530 (2021)","10.1103/PhysRevD.103.023530",,"astro-ph.CO hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The discrepancy between early-Universe inferences and direct measurements of
the Hubble constant, known as the Hubble tension, recently became a pressing
subject in high precision cosmology. As a result, a large variety of
theoretical models have been proposed to relieve this tension. In this work we
analyze a conformally-coupled modified gravity (CCMG) model of an evolving
gravitational constant due to the coupling of a scalar field to the Ricci
scalar, which becomes active around matter-radiation equality, as required for
solutions to the Hubble tension based on increasing the sound horizon at
recombination. The model is theoretically advantageous as it has only one free
parameter in addition to the baseline $\Lambda$CDM ones. Inspired by similar
recent analyses of so-called early-dark-energy models, we constrain the CCMG
model using a combination of early and late-Universe cosmological datasets. In
addition to the Planck 2018 cosmic microwave background (CMB) anisotropies and
weak lensing measurements, baryon acoustic oscillations and the Supernova H0
for the Equation of State datasets, we also use large-scale structure (LSS)
datasets such as the Dark Energy Survey year 1 and the full-shape power
spectrum likelihood from the Baryon Oscillation Spectroscopic Survey, including
its recent analysis using effective field theory, to check the effect of the
CCMG model on the (milder) S8 tension between the CMB and LSS. We find that the
CCMG model can slightly relax the Hubble tension, with $H_0 = 69.6 \pm 1.6$
km/s/Mpc at 95% CL, while barely affecting the S8 tension. However, current
data does not exhibit strong preference for CCMG over the standard cosmological
model. Lastly, we show that the planned CMB-S4 experiment will have the
sensitivity required to distinguish between the CCMG model and the more general
class of models involving an evolving gravitational constant.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:30:22 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jan 2021 10:49:26 GMT""}]","2022-09-09"
"2011.13854","Marvin M\""uller","Marvin M. M\""uller, Miriam Kosik, Marta Pelc, Garnett W. Bryant,
  Andr\'es Ayuela, Carsten Rockstuhl, Karolina S{\l}owik","From single-particle-like to interaction-mediated plasmonic resonances
  in graphene nanoantennas","The following article has been submitted to the Journal of Applied
  Physics",,"10.1063/5.0038883",,"physics.optics cond-mat.mes-hall physics.atm-clus","http://creativecommons.org/licenses/by/4.0/","  Plasmonic nanostructures attract tremendous attention as they confine
electromagnetic fields well below the diffraction limit while simultaneously
sustaining extreme local field enhancements. To fully exploit these properties,
the identification and classification of resonances in such nanostructures is
crucial. Recently, a novel figure of merit for resonance classification has
been proposed 1 and its applicability was demonstrated mostly to toy model
systems. This novel measure, the energy-based plasmonicity index (EPI),
characterizes the nature of resonances in molecular nanostructures. The EPI
distinguishes between either a single-particle-like or a plasmonic nature of
resonances based on the energy space coherence dynamics of the excitation. To
advance the further development of this newly established measure, we present
here its exemplary application to characterize the resonances of graphene
nanoantennas. In particular, we focus on resonances in a doped nanoantenna. The
structure is of interest, as a consideration of the electron dynamics in real
space might suggest a plasmonic nature of selected resonances in the low doping
limit but our analysis reveals the opposite. We find that in the undoped and
moderately doped nanoantenna, the EPI classifies all emerging resonances as
predominantly single-particle-like and only after doping the structure heavily,
the EPI observes plasmonic response.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:30:35 GMT""}]","2021-03-31"
"2011.13855","Avery St. Dizier","Karola M\'esz\'aros, Linus Setiabrata, and Avery St. Dizier","An orthodontia formula for Grothendieck polynomials","19 pages; Added additional section in v2",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a new operator formula for Grothendieck polynomials that generalizes
Magyar's Demazure operator formula for Schubert polynomials. Our proofs are
purely combinatorial, contrasting with the geometric and representation
theoretic tools used by Magyar. We apply our formula to prove a necessary
divisibility condition for a monomial to appear in a given Grothendieck
polynomial.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:31:51 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 18:56:55 GMT""}]","2021-01-26"
"2011.13856","Yue Xiu","Yue Xiu, Jun Zhao, Ertugrul Basar, Marco Di Renzo, Wei Sun, Guan Gui
  and Ning Wei","Uplink Achievable Rate Maximization for Reconfigurable Intelligent
  Surface Aided Millimeter Wave Systems with Resolution-Adaptive ADCs",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  In this letter, we investigate the uplink of a reconfigurable intelligent
surface (RIS)-aided millimeter-wave (mmWave) multi-user system. In the
considered system, however, problems with hardware cost and power consumption
arise when massive antenna arrays coupled with power-demanding
analog-to-digital converters (ADCs) are employed. To account for practical
hardware complexity, we consider that the access point (AP) is equipped with
resolution-adaptive analog-to-digital converters (RADCs). We maximize the
achievable rate under hardware constraints by jointly optimizing the ADC
quantization bits, the RIS phase shifts, and the beam selection matrix. Due to
the non-convexity of the feasible set and objective function, the formulated
problem is non-convex and difficult to solve. To efficiently tackle this
problem, a block coordinated descent (BCD)-based algorithm is proposed.
Simulations demonstrate that an RIS can mitigate the hardware loss due to use
of RADCs, and that the proposed BCD-based algorithm outperforms
state-of-the-art algorithms.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:33:45 GMT""}]","2020-11-30"
"2011.13857","Si-Nong Liu","Sumit R. Das, Anurag Kaushal, Sinong Liu, Gautam Mandal, Sandip P.
  Trivedi","Gauge Invariant Target Space Entanglement in D-Brane Holography","53 pages, 4 figures",,"10.1007/JHEP04(2021)225","TIFR-TH/20-48","hep-th cond-mat.stat-mech quant-ph","http://creativecommons.org/licenses/by/4.0/","  It has been suggested in arXiv:2004.00613 that in Dp-brane holography,
entanglement in the target space of the D-brane Yang-Mills theory provides a
precise notion of bulk entanglement in the gravity dual. We expand on this
discussion by providing a gauge invariant characterization of operator
sub-algebras corresponding to such entanglement. This is achieved by finding a
projection operator which imposes a constraint characterizing the target space
region of interest. By considering probe branes in the Coulomb branch we
provide motivation for why the operator sub-algebras we consider are
appropriate for describing a class of measurements carried out with low-energy
probes in the corresponding bulk region of interest. We derive expressions for
the corresponding Renyi entropies in terms of path integrals which can be
directly used in numerical calculations.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:35:04 GMT""},{""version"":""v2"",""created"":""Sun, 17 Jan 2021 02:23:49 GMT""}]","2021-05-12"
"2011.13858","Augustus Porter","Augustus Porter, David Grant, Katherine Blundell, Steven Lee","GG Carinae: orbital parameters and accretion indicators from
  phase-resolved spectroscopy and photometry","23 pages, 26 figures. Accepted for publication in MNRAS",,"10.1093/mnras/staa3749",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  B[\,e\,] supergiants are a rare and unusual class of massive and luminous
stars, characterised by opaque circumstellar envelopes. GG Carinae is a binary
whose primary component is a B[\,e\,] supergiant and whose variability has
remained unsatisfactorily explained. Using photometric data from ASAS, OMC, and
ASAS-SN, and spectroscopic data from the Global Jet Watch and FEROS to study
visible emission lines, we focus on the variability of the system at its
$\sim$31-day orbital period and constrain the stellar parameters of the
primary. There is one photometric minimum per orbital period and, in the
emission line spectroscopy, we find a correlation between the amplitude of
radial velocity variations and the initial energy of the line species. The
spectral behaviour is consistent with the emission lines forming in the
primary's wind, with the variable amplitudes between line species being caused
by the less energetic lines forming at larger radii on average. By modelling
the atmosphere of the primary, we are able to model the radial velocity
variations of the wind lines in order to constrain the orbit of the binary. We
find that the binary is even more eccentric than previously believed
($e=0.5\pm0.03$). Using this orbital solution, the system is brightest at
periastron and dimmest at apastron, and the shape of the photometric variations
at the orbital period can be well described by the variable accretion by the
secondary of the primary's wind. We suggest that the evolutionary history of GG
Carinae may need to be reevaluated in a binary context.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:35:10 GMT""}]","2020-12-03"
"2011.13859","Ronnie Rodgers","S. Prem Kumar, Andy O'Bannon, Anton Pribytok, Ronnie Rodgers","Holographic Coulomb Branch Solitons, Quasinormal Modes, and Black Holes","21 pages + 2 appendices, 16 figure files. v2: version published in
  JHEP",,"10.1007/JHEP05(2021)109",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Four-dimensional $\mathcal{N}=4$ supersymmetric Yang-Mills theory, at a point
on the Coulomb branch where $SU(N)$ gauge symmetry is spontaneously broken to
$SU(N-1)\times U(1)$, admits BPS solitons describing a spherical shell of
electric and/or magnetic charges enclosing a region of unbroken gauge symmetry.
These solitons have been proposed as gauge theory models for certain features
of asymptotically flat extremal black holes. In the 't Hooft large $N$ limit
with large 't Hooft coupling, these solitons are holographically dual to
certain probe D3-branes in the $AdS_5 \times S^5$ solution of type IIB
supergravity. By studying linearised perturbations of these D3-branes, we show
that the solitons support quasinormal modes with a spectrum of frequencies
sharing both qualitative and quantitative features with asymptotically flat
extremal black holes.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:36:43 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 16:45:30 GMT""}]","2021-06-02"
"2011.13860","Mario Kummer","Taylor Brysiewicz, Khazhgali Kozhasov, Mario Kummer","Nodes on quintic spectrahedra",,,"10.4418/2021.76.2.8",,"math.AG cs.NA math.NA math.OC","http://creativecommons.org/licenses/by/4.0/","  We classify transversal quintic spectrahedra by the location of 20 nodes on
the respective real determinantal surface of degree 5. We identify 65 classes
of such surfaces and find an explicit representative in each of them.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:36:58 GMT""}]","2022-10-04"
"2011.13861","Michal Mika","Michal Lukasz Mika, Thomas Joseph Robert Hughes, Dominik Schillinger,
  Peter Wriggers and Ren\'e Rinke Hiemstra","A matrix-free isogeometric Galerkin method for Karhunen-Lo\`eve
  approximation of random fields using tensor product splines, tensor
  contraction and interpolation based quadrature",,,,,"cs.CE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Karhunen-Lo\`eve series expansion (KLE) decomposes a stochastic process
into an infinite series of pairwise uncorrelated random variables and pairwise
$L^2$-orthogonal functions. For any given truncation order of the infinite
series the basis is optimal in the sense that the total mean squared error is
minimized. The orthogonal basis functions are determined as the solution of an
eigenvalue problem corresponding to the homogeneous Fredholm integral equation
of the second kind, which is computationally challenging for several reasons.
Firstly, a Galerkin discretization requires numerical integration over a $2d$
dimensional domain, where $d$, in this work, denotes the spatial dimension.
Secondly, the main system matrix of the discretized weak-form is dense.
Consequently, the computational complexity of classical finite element
formation and assembly procedures as well as the memory requirements of direct
solution techniques become quickly computationally intractable with increasing
polynomial degree, number of elements and degrees of freedom. The objective of
this work is to significantly reduce several of the computational bottlenecks
associated with numerical solution of the KLE. We present a matrix-free
solution strategy, which is embarrassingly parallel and scales favorably with
problem size and polynomial degree. Our approach is based on (1) an
interpolation based quadrature that minimizes the required number of quadrature
points; (2) an inexpensive reformulation of the generalized eigenvalue problem
into a standard eigenvalue problem; and (3) a matrix-free and parallel
matrix-vector product for iterative eigenvalue solvers. Two higher-order
three-dimensional benchmarks illustrate exceptional computational performance
combined with high accuracy and robustness.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:37:58 GMT""},{""version"":""v2"",""created"":""Sun, 21 Feb 2021 21:09:38 GMT""}]","2021-02-23"
"2011.13862","Gr\'egoire Mathys","Alexandre Belin, Diego M. Hofman, Gr\'egoire Mathys, Matthew T.
  Walters","On the Stress Tensor Light-ray Operator Algebra","56 pages + appendices, 9 figures; published version",,"10.1007/JHEP05(2021)033","CERN-TH-2020-200","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study correlation functions involving generalized ANEC operators of the
form $\int dx^- \left(x^-\right)^{n+2} T_{--}(\vec{x})$ in four dimensions. We
compute two, three, and four-point functions involving external scalar states
in both free and holographic Conformal Field Theories. From this information,
we extract the algebra of these light-ray operators. We find a global
subalgebra spanned by $n=\{-2, -1, 0, 1, 2\}$ which annihilate the conformally
invariant vacuum and transform among themselves under the action of the
collinear conformal group that preserves the light-ray. Operators outside this
range give rise to an infinite central term, in agreement with previous
suggestions in the literature. In free theories, even some of the operators
inside the global subalgebra fail to commute when placed at spacelike
separation on the same null-plane. This lack of commutativity is not
integrable, presenting an obstruction to the construction of a well defined
light-ray algebra at coincident $\vec{x}$ coordinates. For holographic CFTs the
behavior worsens and operators with $n \neq -2$ fail to commute at spacelike
separation. We reproduce this result in the bulk of AdS where we present new
exact shockwave solutions dual to the insertions of these (exponentiated)
operators on the boundary.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:38:05 GMT""},{""version"":""v2"",""created"":""Sat, 5 Dec 2020 12:32:25 GMT""},{""version"":""v3"",""created"":""Thu, 11 Mar 2021 08:22:24 GMT""}]","2021-05-19"
"2011.13863","Clemens Hutter","Clemens Hutter, Moritz von Stosch, Mariano Nicolas Cruz Bournazou,
  Alessandro Butt\'e","Knowledge transfer across cell lines using Hybrid Gaussian Process
  models with entity embedding vectors","14 pages, 5 figures",,"10.1002/bit.27907",,"q-bio.QM cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  To date, a large number of experiments are performed to develop a biochemical
process. The generated data is used only once, to take decisions for
development. Could we exploit data of already developed processes to make
predictions for a novel process, we could significantly reduce the number of
experiments needed. Processes for different products exhibit differences in
behaviour, typically only a subset behave similar. Therefore, effective
learning on multiple product spanning process data requires a sensible
representation of the product identity. We propose to represent the product
identity (a categorical feature) by embedding vectors that serve as input to a
Gaussian Process regression model. We demonstrate how the embedding vectors can
be learned from process data and show that they capture an interpretable notion
of product similarity. The improvement in performance is compared to
traditional one-hot encoding on a simulated cross product learning task. All in
all, the proposed method could render possible significant reductions in
wet-lab experiments.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:38:15 GMT""}]","2021-08-04"
"2011.13864","Alexandre Serantes","Michal P. Heller, Alexandre Serantes, Micha{\l} Spali\'nski, Viktor
  Svensson and Benjamin Withers","Transseries for causal diffusive systems","v1: 23 pages + appendices, 16 figures; v2: references added, matches
  version published in JHEP",,"10.1007/JHEP04(2021)192",,"hep-th cond-mat.str-el hep-ph nucl-th physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The large proper-time behaviour of expanding boost-invariant fluids has
provided many crucial insights into quark-gluon plasma dynamics. Here we
formulate and explore the late-time behaviour of nonequilibrium dynamics at the
level of linearized perturbations of equilibrium, but without any special
symmetry assumptions. We introduce a useful quantitative approximation scheme
in which hydrodynamic modes appear as perturbative contributions while
transients are nonperturbative. In this way, solutions are naturally organized
into transseries as they are in the case of boost-invariant flows. We focus our
attention on the ubiquitous telegrapher's equation, the simplest example of a
causal theory with a hydrodynamic sector. In position space we uncover novel
transient contributions as well as Stokes phenomena which change the structure
of the transseries based on the spacetime region or the choice of initial data.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:40:38 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 17:54:26 GMT""}]","2021-05-12"
"2011.13865","Christopher Mittag","Christopher Mittag, Jonne V. Koski, Matija Karalic, Candice Thomas,
  Aymeric Tuaz, Anthony T. Hatke, Geoffrey C. Gardner, Michael J. Manfra,
  Jeroen Danon, Thomas Ihn, Klaus Ensslin","Few-electron Single and Double Quantum Dots in an InAs Two-Dimensional
  Electron Gas",,"PRX Quantum 2, 010321 (2021)","10.1103/PRXQuantum.2.010321",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most proof-of-principle experiments for spin qubits have been performed using
GaAs-based quantum dots because of the excellent control they offer over
tunneling barriers and the orbital and spin degrees of freedom. Here, we
present the first realization of high-quality single and double quantum dots
hosted in an InAs two-dimensional electron gas (2DEG), demonstrating accurate
control down to the few-electron regime, where we observe a clear Kondo effect
and singlet-triplet spin blockade. We measure an electronic $g$-factor of $16$
and a typical magnitude of the random hyperfine fields on the dots of $\sim
0.6\, \mathrm{mT}$. We estimate the spin-orbit length in the system to be $\sim
5-10\, \mu \mathrm{m}$, which is almost two orders of magnitude longer than
typically measured in InAs nanostructures, achieved by a very symmetric design
of the quantum well. These favorable properties put the InAs 2DEG on the map as
a compelling host for studying fundamental aspects of spin qubits. Furthermore,
having weak spin-orbit coupling in a material with a large Rashba coefficient
potentially opens up avenues for engineering structures with spin-orbit
coupling that can be controlled locally in space and/or time.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:40:56 GMT""}]","2021-02-17"
"2011.13866","Dor Verbin","Dor Verbin and Todd Zickler","Field of Junctions: Extracting Boundary Structure at Low SNR","ICCV 2021. Project page with demo, video, and code:
  https://vision.seas.harvard.edu/foj/",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a bottom-up model for simultaneously finding many boundary
elements in an image, including contours, corners and junctions. The model
explains boundary shape in each small patch using a 'generalized M-junction'
comprising M angles and a freely-moving vertex. Images are analyzed using
non-convex optimization to cooperatively find M+2 junction values at every
location, with spatial consistency being enforced by a novel regularizer that
reduces curvature while preserving corners and junctions. The resulting 'field
of junctions' is simultaneously a contour detector, corner/junction detector,
and boundary-aware smoothing of regional appearance. Notably, its unified
analysis of contours, corners, junctions and uniform regions allows it to
succeed at high noise levels, where other methods for segmentation and boundary
detection fail.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:46:08 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 19:46:12 GMT""},{""version"":""v3"",""created"":""Thu, 11 Nov 2021 16:13:54 GMT""}]","2021-11-12"
"2011.13867","Yuichi Itto","Yuichi Itto","Fluctuating diffusivity of RNA-protein particles: Analogy with
  thermodynamics","19 pages, no figures. The discussion developed further and some
  references added. Published version","Entropy 2021, 23, 333","10.3390/e23030333",,"cond-mat.stat-mech physics.bio-ph q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A formal analogy of fluctuating diffusivity to thermodynamics is discussed
for messenger RNA molecules fluorescently fused to a protein in living cells.
Regarding the average value of the fluctuating diffusivity of such RNA-protein
particles as the analog of the internal energy, the analogs of the quantity of
heat and work are identified. The Clausius-like inequality is shown to hold for
the entropy associated with diffusivity fluctuations, which plays a role
analogous to the thermodynamic entropy, and the analog of the quantity of heat.
The change of the statistical fluctuation distribution is also examined from a
geometric perspective. The present discussions may contribute to a deeper
understanding of the fluctuating diffusivity in view of the laws of
thermodynamics.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:47:00 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 01:29:35 GMT""}]","2021-03-17"
"2011.13868","Felix Fiedler","Felix Fiedler, Sergio Lucia","On the relationship between data-enabled predictive control and subspace
  predictive control","Accepted at European Control Conference (ECC) 2021. 8 pages, 3
  figures, 1 table",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Data-enabled predictive control (DeePC) is a recently proposed approach that
combines system identification, estimation and control in a single optimization
problem, for which only recorded input/output data of the examined system is
required. The same premise holds for the subspace predictive control (SPC)
method in which a multi-step prediction model is identified from the same data
as required for DeePC. This model is then used to formulate a similar optimal
control problem. In this work we investigate the relationship between DeePC and
SPC. Our primary contribution is to show that SPC is equivalent to DeePC in the
deterministic case. We also show the equivalence of both methods in a special
case for the non-deterministic formulation. We investigate the advantages and
shortcomings of DeePC as opposed to SPC with and without measurement noise and
illustrate them with a simulation example.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:49:27 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 12:55:38 GMT""},{""version"":""v3"",""created"":""Thu, 1 Apr 2021 14:11:10 GMT""}]","2021-04-02"
"2011.13869","Carolin Gold","Carolin Gold, Beat A. Br\""am, Michael S. Ferguson, Tobias
  Kr\""ahenmann, Andrea Hofmann, Richard Steinacher, Keith R. Fratus, Christian
  Reichl, Werner Wegscheider, Dietmar Weinmann, Klaus Ensslin and Thomas Ihn","Imaging signatures of the local density of states in an electronic
  cavity",,"Phys. Rev. Research 3, 032005 (2021)","10.1103/PhysRevResearch.3.L032005",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use Scanning Gate Microscopy to study electron transport through an open,
gate-defined resonator in a Ga(Al)As heterostructure. Raster-scanning the
voltage-biased metallic tip above the resonator, we observe distinct
conductance modulations as a function of the tip-position and voltage. Quantum
mechanical simulations reproduce these conductance modulations and reveal their
relation to the partial local density of states in the resonator. Our
measurements illustrate the current frontier between possibilities and
limitations in imaging the local density of states in buried electron systems
using scanning gate microscopy.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:50:22 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 18:35:43 GMT""}]","2021-07-14"
"2011.13870","Jakob Salzer","Daniel Grumiller, Jelle Hartong, Stefan Prohazka, Jakob Salzer","Limits of JT gravity","41 pages, 3 figures, 1 table; v2: Matches published version +
  Footnote 11; v3: Corrected typo in Carrollian/Galilean generalized dilaton
  potential","JHEP 02 (2021) 134","10.1007/JHEP02(2021)134","TUW--20--05","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct various limits of JT gravity, including Newton-Cartan and
Carrollian versions of dilaton gravity in two dimensions as well as a theory on
the three-dimensional light cone. In the BF formulation our boundary conditions
relate boundary connection with boundary scalar, yielding as boundary action
the particle action on a group manifold or some Hamiltonian reduction thereof.
After recovering in our formulation the Schwarzian for JT, we show that
AdS-Carroll gravity yields a twisted warped boundary action. We comment on
numerous applications and generalizations.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:50:58 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 11:48:00 GMT""},{""version"":""v3"",""created"":""Fri, 4 Feb 2022 10:47:13 GMT""}]","2022-02-07"
"2011.13871","Ehssan Khanmohammadi","Ehssan Khanmohammadi, Omid Khanmohamadi","From Uniform Boundedness to the Boundary Between Convergence and
  Divergence","Accepted for publication in Mathematics Magazine",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this article we introduce a dual of the uniform boundedness principle
which does not require completeness and gives an indirect means for testing the
boundedness of a set. The dual principle, although known to the analyst and
despite its applications in establishing results such as Hellinger--Toeplitz
theorem, is often missing from elementary treatments of functional analysis. In
Example 1 we indicate a connection between the dual principle and a question in
spirit of du Bois-Reymond regarding the boundary between convergence and
divergence of sequences. This example is intended to illustrate why the
statement of the principle is natural and clarify what the principle claims and
what it does not.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:50:59 GMT""}]","2020-11-30"
"2011.13872","Salim Rostam","Salim Rostam","Identifying Young diagrams among residue multisets","42 pages. v3: minor changes, final version, to appear in Annals of
  Combinatorics",,,,"math.RT math.CO","http://creativecommons.org/licenses/by/4.0/","  To any Young diagram we can associate the multiset of residues of all its
nodes. This paper is concerned with the inverse problem: given a multiset of
elements of Z/eZ, does it comes from a Young diagram? We give a full solution
in level one and a partial answer in higher levels for Young multidiagrams,
using Fayers's notions of core block and weight of a multipartition. We apply
the result in level one to study a shift operation on partitions.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:56:58 GMT""},{""version"":""v2"",""created"":""Wed, 21 Dec 2022 15:20:16 GMT""},{""version"":""v3"",""created"":""Mon, 20 Feb 2023 15:12:23 GMT""}]","2023-02-21"
"2011.13873","Cl\'emence Fontanive","Clemence Fontanive, Luigi R. Bedin and Daniella C. Bardalez Gagliuffi","The Y dwarf population with HST: unlocking the secrets of our coolest
  neighbours -- I. Overview & First astrometric results","Accepted for publication in MNRAS. 6 pages, 2 figures, 2 tables",,"10.1093/mnras/staa3732",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present our project that aims at determining accurate
distances and proper motions for the Y brown dwarf population using the Hubble
Space Telescope. We validate the program with our first results, using a single
new epoch of observations of the Y0pec dwarf WISE J163940.83$-$684738.6. These
new data allowed us to refine its proper motion and improve the accuracy of its
parallax by a factor of three compared to previous determinations, now
constrained to $\varpi = 211.11 \pm 0.56$ mas. This newly derived absolute
parallax corresponds to a distance of $4.737 \pm 0.013$ pc, an exquisite and
unprecedented precision for faint ultracool Y dwarfs.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:57:54 GMT""}]","2020-12-09"
"2011.13874","Tsung-Han Yeh","Tsung-Han Yeh, Keith A. Olive, Brian D. Fields","The Impact of New d(p,\gamma)He3 Rates on Big Bang Nucleosynthesis","28 pages, 12 figures. Comments welcome","Journal of Cosmology and Astroparticle Physics, Issue 03, article
  id. 046 (2021)","10.1088/1475-7516/2021/03/046","UMN--TH--4004/20, FTPI--MINN--20/35","astro-ph.CO hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the effect on Big Bang Nucleosynthesis (BBN) of new measurements
of the $d(p,\gamma){}^3$He cross section by the LUNA Collaboration. These have
an important effect on the primordial abundance of D/H which is also sensitive
to the baryon density at the time of BBN. We have re-evaluated the thermal rate
for this reaction, using a world average of cross section data, which we
describe with model-independent polynomials; our results are in good agreement
with a similar analysis by LUNA. We then perform a full likelihood analysis
combining BBN and Planck cosmic microwave background (CMB) likelihood chains
using the new rate combined with previous measurements and compare with the
results using previous rates. Concordance between BBN and CMB measurements of
the anisotropy spectrum using the old rates was excellent. The predicted
deuterium abundance at the Planck value of the baryon density was $({\rm
D/H})_{\rm BBN+CMB}^{\rm old} = (2.57 \pm 0.13) \times 10^{-5}$ which can be
compared with the value determined from quasar absorption systems $({\rm
D/H})_{\rm obs} = (2.55 \pm 0.03) \times 10^{-5} $. Using the new rates we find
$({\rm D/H})_{\rm BBN+CMB} = (2.51 \pm 0.11) \times 10^{-5}$. We thus find
consistency among BBN theory, deuterium and ${}^4$He observations, and the CMB,
when using reaction rates fit in our data-driven approach. We also find that
the new reaction data tightens the constraints on the number of relativistic
degrees of freedom during BBN, giving the effective number of light neutrino
species $N_\nu = 2.880 \pm 0.144$ in good agreement with the Standard Model of
particle physics. Finally, we note that the observed deuterium abundance
continues to be more precise than the BBN+CMB prediction, whose error budget is
now dominated by $d(d,n){}^3$He and $d(d,p){}^{3}{\rm H}$.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:58:58 GMT""}]","2021-03-23"
"2011.13875","Lisa Glaser","Lisa Glaser","Phase transitions in 2d orders coupled to the Ising model","34 pages, 22 figures, v2 matches journal version, to appear in CQG",,"10.1088/1361-6382/abf1c5",,"gr-qc cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $2$d orders are a sub class of causal sets, which is especially amenable
to computer simulations. Past work has shown that the $2$d orders have a first
order phase transition between a random and a crystalline phase. When coupling
the $2$d orders to the Ising model, this phase transition coincides with the
transition of the Ising model. The coupled system also shows a new phase, at
negative $\beta$, where the Ising model induces the geometric transition. In
this article we examine the phase transitions of the coupled system, to
determine their order, as well as how they scale when the system size is
changed. We find that the transition at positive $\beta$ seems to be of mixed
order, while the two transitions at negative $\beta$ appear continous/ first
order for the Ising model/ the geometry respectively. The scaling of the
observables with the system size on the other hand is fairly simple, and does,
where applicable, agree with that found for the pure $2$d orders. We find that
the location of these transitions has fractional scaling in the system size.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:06:30 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 11:43:01 GMT""}]","2021-03-30"
"2011.13876","Wade Bloomquist","Jessica Appel, Wade Bloomquist, Katie Gravel, Annie Holden","On quotients of congruence subgroups of braid groups","5 pages",,,,"math.GR math.GT","http://creativecommons.org/licenses/by/4.0/","  The integral Burau representation provides a map from the braid group into a
group of integral matrices. This allows for a definition of congruence
subgroups of the braid group as the preimage of the usual principal congruence
subgroups of integral matrices. We explore the structure these congruence
subgroups by examining some of the quotients that may arise in the series
induced by divisibility of levels. We build on the work of Stylianakis on
symmetric quotients of congruence subgroups, which itself generalizes the
quotient of the braid group by the pure braid group. We accomplish this by
utilizing results of Newman on integral matrices and explicitly finding
elements in the preimage of any transposition. Our generalization is made
possible by avoiding the use of a generating set for congruence subgroups. We
find further generalizations based on results of Brendle and Margalit as well
as Kordek and Margalit on the level four congruence subgroup. This gives
families of quotients which are not isomorphic to symmetric groups.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:07:40 GMT""}]","2020-11-30"
"2011.13877","Alicia Moranchel","A. Moranchel-Basurto, F. J. S\'anchez-salcedo, Ra\'ul O. Chametla, P.
  F. Vel\'azquez","Supernova Explosions in Accretion Disks in Active Galactic Nuclei:
  Three-Dimensional Models","15 pages, 16 figures. Accepted for publication in ApJ",,"10.3847/1538-4357/abca88",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supernova (SN) explosions can potentially affect the structure and evolution
of circumnuclear disks in active galactic nuclei (AGN). Some previous studies
have suggested that a relatively low rate of SN explosions can provide an
effective value of alpha viscosity between 0.1 and 1 in AGN accretion disks
within 1 pc scale. In order to test this possibility, we provide some analytic
scalings of the evolution of a SN remnant embedded in a differentially rotating
smooth disk. We calibrate our estimates using three-dimensional hydrodynamical
simulations where the gas is modeled as adiabatic with index $\gamma$. Our
simulations are suited to include the fact that a fraction of the momentum
injected by the SN escapes from the disk into the corona. Based on these
results, we calculate the contribution of SN explosions to the effective alpha
viscosity, denoted by $\alpha_{SNe}$, in a model AGN accretion disk, where
accretion is driven by the local viscosity $\alpha$. We find that for AGN
galaxies with a central black hole of $~ 10^8M_{\cdot}$ and a disk with
viscosity $\alpha=0.1$, the contribution of SN explosions may be as large as
$\alpha_{SNe} \simeq 0.02$, provided that $\alpha \gtrsim 1.1$. On the other
hand, in the momentum conservation limit, which is valid when the push by the
internal pressure of the SN remnant is negligible, we find $\alpha_SNe \lesssim
6\times10^{-4}$.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:08:01 GMT""}]","2021-01-13"
"2011.13878","Edval J. P. Santos PhD","Maria Augusta R. B. L. Fernandes, Edval J. P. Santos","Measurement of $p\!-\!n$-junction diode behavior under large signal and
  high frequency","7 pages, 7 figures, International Symposium on Microelectronics
  Technology and Devices, 2014, Aracaju, Brasil. Proceedings of the SBMicro
  2014, 2014",,,,"physics.app-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measurements of diode dynamic conductance and dynamic capacitance for
frequencies up to $10 \times \tau_{p,n}^{-1}$, and voltage amplitude level up
tp 100 mV was carried out with a precision impedancemeter. The results were
compared with the theoretical expressions obtained with the spectral approach
to the charge carrier transport in $p\!-\!n$-junctions. This experimental
confirmation is of practical interest, as one can use the theory to extract
device parameters, such as: relaxation time $\tau_{p,n}$, and junction
injection coefficient. These experiments were carried to test the extension of
the conventional $p\!-\!n$-junction theory.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:10:41 GMT""}]","2020-11-30"
"2011.13879","Kedron Silsbee","Kedron Silsbee, Alexei V. Ivlev, Munan Gong","Thermal damping of Weak Magnetosonic Turbulence in the Interstellar
  Medium","Accepted to ApJ",,"10.3847/1538-4357/ac1e87",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present a generic mechanism for the thermal damping of compressive waves
in the interstellar medium (ISM), occurring due to radiative cooling. We solve
for the dispersion relation of magnetosonic waves in a two-fluid (ion-neutral)
system in which density- and temperature-dependent heating and cooling
mechanisms are present. We use this dispersion relation, in addition to an
analytic approximation for the nonlinear turbulent cascade, to model
dissipation of weak magnetosonic turbulence. We show that in some ISM
conditions, the cutoff wavelength for magnetosonic turbulence becomes tens to
hundreds of times larger when the thermal damping is added to the regular
ion-neutral damping. We also run numerical simulations which confirm that this
effect has a dramatic impact on cascade of compressive wave modes.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:10:42 GMT""},{""version"":""v2"",""created"":""Wed, 18 Aug 2021 17:14:34 GMT""},{""version"":""v3"",""created"":""Thu, 11 Nov 2021 15:10:37 GMT""}]","2021-11-24"
"2011.13880","Emilio Cartoni","Emilio Cartoni (1), Davide Montella (1), Jochen Triesch (2), Gianluca
  Baldassarre (1) ((1) Institute of Cognitive Sciences and Technologies, (2)
  Frankfurt Institute for Advanced Studies)","REAL-X -- Robot open-Ended Autonomous Learning Architectures: Achieving
  Truly End-to-End Sensorimotor Autonomous Learning Systems","14 pages, 13 figures. Improved version of the REAL baseline including
  better exploration",,,,"cs.RO cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Open-ended learning is a core research field of developmental robotics and AI
aiming to build learning machines and robots that can autonomously acquire
knowledge and skills incrementally as infants and children. The first
contribution of this work is to study the challenges posed by the previously
proposed benchmark `REAL competition' aiming to foster the development of truly
open-ended learning robot architectures. The competition involves a simulated
camera-arm robot that: (a) in a first `intrinsic phase' acquires sensorimotor
competence by autonomously interacting with objects; (b) in a second `extrinsic
phase' is tested with tasks unknown in the intrinsic phase to measure the
quality of knowledge previously acquired. This benchmark requires the solution
of multiple challenges usually tackled in isolation, in particular exploration,
sparse-rewards, object learning, generalisation, task/goal self-generation, and
autonomous skill learning. As a second contribution, we present a set of
`REAL-X' robot architectures that are able to solve different versions of the
benchmark, where we progressively release initial simplifications. The
architectures are based on a planning approach that dynamically increases
abstraction, and intrinsic motivations to foster exploration. REAL-X achieves a
good performance level in very demanding conditions. We argue that the REAL
benchmark represents a valuable tool for studying open-ended learning in its
hardest form.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:12:06 GMT""},{""version"":""v2"",""created"":""Wed, 2 Mar 2022 11:37:18 GMT""}]","2022-03-03"
"2011.13881","Fosco Loregian G.","Fosco Loregian and Emily de Oliveira Santos","Coends of higher arity","produced with codi https://www.ctan.org/pkg/commutative-diagrams",,,,"math.CT","http://creativecommons.org/licenses/by/4.0/","  We specialise a recently introduced notion of generalised dinaturality for
functors $T : (\mathcal{C}^\text{op})^p \times \mathcal{C}^q \to \mathcal{D}$
to the case where the domain (resp., codomain) is constant, obtaining notions
of ends (resp., coends) of higher arity, dubbed herein $(p,q)$-ends (resp.,
$(p,q)$-coends). While higher arity co/ends are particular instances of
""totally symmetrised"" (ordinary) co/ends, they serve an important technical
role in the study of a number of new categorical phenomena, which may be
broadly classified as two new variants of category theory.
  The first of these, weighted category theory, consists of the study of
weighted variants of the classical notions and construction found in ordinary
category theory, besides that of a limit. This leads to a host of varied and
rich notions, such as weighted Kan extensions, weighted adjunctions, and
weighted ends.
  The second, diagonal category theory, proceeds in a different (albeit
related) direction, in which one replaces universality with respect to natural
transformations with universality with respect to dinatural transformations,
mimicking the passage from limits to ends. In doing so, one again encounters a
number of new interesting notions, among which one similarly finds diagonal Kan
extensions, diagonal adjunctions, and diagonal ends.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:12:14 GMT""}]","2023-03-03"
"2011.13882","Hadi Lookzadeh","Hadi Lookzadeh, M. Hosseini","On the non-physical concavity of the quark potentials within the thick
  center vortex model","30 pages,20 figures",,,,"hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lattice gauge theory results show the confinement for the quark potential in
different Yang-Mills theories and even the G(2) gauge theory. LGT calculations
show that quark potential should have the down concavity behavior. Confinement
properties can be explained using the thick center vortex model. However an
upward concavity is seen in the quark potential intervals using this model.
After study the reason of this concavity, it is shown the non physical
concavity can be reduced by taking an arbitrary symmetric vortex flux in the
space time plane of the lattice.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:13:06 GMT""}]","2020-11-30"
"2011.13883","Juste Raimbault","C. Cottineau, J. Raimbault, P.-O. Chasset, H. Commenges, A. Banos and
  D. Pumain","CybergeoNetworks, an interactive application for the geographical and
  semantic analysis of scientific publications","6 pages, 3 figures. Translated from French","In Bouzeghoub M., Mosseri R. (eds.) Les Big Data {\`a}
  d{\'e}couvert, CNRS Editions (EAN: 9782271114648), pp.272-273, 2017",,,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increase in the number of publications has made more difficult for
authors to situate their work within previous literature, especially on
subjects studied from different disciplinary viewpoints. Besides, new data
analysis techniques and new bibliometrics data sources provide an opportunity
to map and navigate scientific landscapes. We introduce here an open-source and
open-access web application designed for the multi-dimensional exploration of a
journal content, including the mapping of geographical, semantic and citations
networks. The application is profiled and implemented for the geography journal
Cybergeo, a generalist geography journal which receives contributions from
multiple sub-disciplines. We suggest that such initiatives are crucial to
promote open science and reflexivity.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:16:46 GMT""}]","2020-11-30"
"2011.13884","Haeran Cho Dr","Haeran Cho, Piotr Fryzlewicz","Multiple change point detection under serial dependence: Wild contrast
  maximisation and gappy Schwarz algorithm",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a methodology for detecting multiple change points in the mean of
an otherwise stationary, autocorrelated, linear time series. It combines
solution path generation based on the wild contrast maximisation principle, and
an information criterion-based model selection strategy termed gappy Schwarz
algorithm. The former is well-suited to separating shifts in the mean from
fluctuations due to serial correlations, while the latter simultaneously
estimates the dependence structure and the number of change points without
performing the difficult task of estimating the level of the noise as
quantified e.g.\ by the long-run variance. We provide modular investigation
into their theoretical properties and show that the combined methodology, named
WCM.gSa, achieves consistency in estimating both the total number and the
locations of the change points. The good performance of WCM.gSa is demonstrated
via extensive simulation studies, and we further illustrate its usefulness by
applying the methodology to London air quality data.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:17:38 GMT""},{""version"":""v2"",""created"":""Fri, 11 Dec 2020 11:00:40 GMT""},{""version"":""v3"",""created"":""Wed, 10 Mar 2021 15:50:49 GMT""},{""version"":""v4"",""created"":""Wed, 8 Dec 2021 13:47:15 GMT""},{""version"":""v5"",""created"":""Tue, 22 Mar 2022 17:48:48 GMT""},{""version"":""v6"",""created"":""Wed, 12 Apr 2023 10:39:43 GMT""}]","2023-04-13"
"2011.13885","Konrad Zolna","Konrad Zolna, Alexander Novikov, Ksenia Konyushkova, Caglar Gulcehre,
  Ziyu Wang, Yusuf Aytar, Misha Denil, Nando de Freitas, Scott Reed","Offline Learning from Demonstrations and Unlabeled Experience","Accepted to Offline Reinforcement Learning Workshop at Neural
  Information Processing Systems (2020)",,,,"cs.LG cs.AI cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Behavior cloning (BC) is often practical for robot learning because it allows
a policy to be trained offline without rewards, by supervised learning on
expert demonstrations. However, BC does not effectively leverage what we will
refer to as unlabeled experience: data of mixed and unknown quality without
reward annotations. This unlabeled data can be generated by a variety of
sources such as human teleoperation, scripted policies and other agents on the
same robot. Towards data-driven offline robot learning that can use this
unlabeled experience, we introduce Offline Reinforced Imitation Learning
(ORIL). ORIL first learns a reward function by contrasting observations from
demonstrator and unlabeled trajectories, then annotates all data with the
learned reward, and finally trains an agent via offline reinforcement learning.
Across a diverse set of continuous control and simulated robotic manipulation
tasks, we show that ORIL consistently outperforms comparable BC agents by
effectively leveraging unlabeled experience.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:20:04 GMT""}]","2020-11-30"
"2011.13886","Ivan Heibi","Ivan Heibi, Silvio Peroni, Luca Pareschi and Paolo Ferri","MITAO: a tool for enabling scholars in the Humanities to use Topic
  Modelling in their studies",,,,,"cs.DL","http://creativecommons.org/licenses/by/4.0/","  Automatic text analysis methods, such as Topic Modelling, are gaining much
attention in Humanities. However, scholars need to have extensive coding skills
to use such methods appropriately. The need of having this technical expertise
prevents the broad adoption of these methods in Humanities research. In this
paper, to help scholars in the Humanities to use Topic Modelling having no or
limited coding skills, we introduce MITAO, a web-based tool that allow the
definition of a visual workflow which embeds various automatic text analysis
operations and allows one to store and share both the workflow and the results
of its execution to other researchers, which enables the reproducibility of the
analysis. We present an example of an application of use of Topic Modelling
with MITAO using a collection of English abstracts of the articles published in
""Umanistica Digitale"". The results returned by MITAO are shown with dynamic
web-based visualizations, which allowed us to have preliminary insights about
the evolution of the topics treated over the time in the articles published in
""Umanistica Digitale"". All the results along with the defined workflows are
published and accessible for further studies.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:20:10 GMT""}]","2020-11-30"
"2011.13887","Ernest Ma","Ernest Ma (UC Riverside)","Gauge Baryon Number and Dibaryonic Dark Matter","10 pages, 1 figure",,"10.1016/j.physletb.2021.136066","UCRHEP-T604 (Nov 2020)","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The minimal standard model of quarks and leptons is extended with a set of
vectorlike fermions to allow baryon number $B$ to become a gauged $U(1)_B$
symmetry. The $B$ assignments of the new particles are determined by
renormalizable interactions with the known quarks through a color triplet
scalar diquark. The spontaneous breaking of $U(1)_B$ by a scalar with $B=3$
results in a conserved residual global $B$ symmetry. A singlet neutral scalar
with $B=2$ is a possible long-lived dark-matter candidate.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:20:18 GMT""}]","2021-01-13"
"2011.13888","Luiz Filipe Guimar\~aes","L. F. Guimar\~aes, F. T. Falciano","Viable Curvaton Models from the $f_{NL}$ Parameter","11 pages, 8 figures","Phys. Rev. D 103, 063530 (2021)","10.1103/PhysRevD.103.063530",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how to build a curvaton inflationary model motivated by
scale-dependent non-Gaussianities of cosmological perturbations. In particular,
we study the change of sign in the $f_{NL}$ parameter as a function of the
curvaton field value at horizon crossing and identify it with the cosmic
microwave background pivot scale. We devise a procedure to recover the curvaton
model that provides the desired $f_{NL}$ parameter. We then present a concrete
example of $f_{NL}$ and construct its parent model. We study the constraints
applied to this model based on considerations taken on $f_{NL}$. We show that
the hemispherical asymmetry can also be used to constrain the scale-dependence
of $f_{NL}$ and the model parameters.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:21:30 GMT""}]","2021-03-31"
"2011.13889","Scott Robertson","Scott Robertson, Aur\'elie Mailliet, Xavier Sarazin, Fran\c{c}ois
  Couchot, Elsa Baynard, Julien Demailly, Moana Pittman, Arache
  Djannati-Ata\""i, Sophie Kazamias, Marcel Urban","The DeLLight experiment to observe an optically-induced change of the
  vacuum index","23 pages, 14 figures Version accepted for publication in Phys. Rev. A","Phys. Rev. A 103, 023524 (2021)","10.1103/PhysRevA.103.023524",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum electrodynamics predicts that the vacuum must behave as a nonlinear
optical medium: the speed of light should be modified when the vacuum is
stressed by intense electromagnetic fields. This optical phenomenon has not yet
been observed. The DeLLight (Deflection of Light by Light) experiment aims to
observe the optically-induced index change of vacuum, a nonlinear effect which
has never been explored. The experiment is installed in the LASERIX facility at
IJCLab, which delivers ultra-short intense laser pulses (2.5 J per pulse, each
of 30 fs duration, with a 10 Hz repetition rate). The proposal is to measure
the refraction of a probe laser pulse when crossing a transverse vacuum index
gradient, produced by a very intense pump pulse. The refraction induces a
transverse shift in the intensity profile of the probe, whose signal is
amplified by a Sagnac interferometer. In this article, we describe the
experimental method and setup, and present the complete theoretical
calculations for the expected signal. With a minimum waist at focus of $5
\,\mu$m (corresponding to a maximum intensity of $\sim 3 \times 10^{20}$
W/cm$^2$), and with the nonlinear vacuum index derived from QED, the expected
refraction angle is 0.13 prad. First results of the interferometer prototype
are presented. It is shown that an extinction factor $\mathcal{F} = 0.4 \times
10^{-5}$ (corresponding to a signal amplification factor of 250) and a spatial
resolution $\sigma_y = 10$ nm are achievable. The expected signal is then about
15 pm, and could be observed at a 5-sigma confidence level with about one month
of collected data.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:21:52 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jan 2021 09:56:25 GMT""}]","2021-03-03"
"2011.13890","Himadri Halder","Molla Basir Ahamed, Vasudevarao Allu, and Himadri Halder","The Bohr Phenomenon for analytic functions on simply connected domains","18 pages",,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the Bohr phenomenon for the class of analytic
functions defined on the simply connected domain
  \begin{equation*}
  \Omega_{\gamma}=\bigg\{z\in\mathbb{C} :
\bigg|z+\frac{\gamma}{1-\gamma}\bigg|<\frac{1}{1-\gamma}\bigg\}\;\;
\text{for}\;\; 0\leq \gamma<1.
  \end{equation*} We study improved Bohr radius, Bohr-Rogosinski radius and
refined Bohr radius for the class of analytic functions defined in $
\Omega_{\gamma} $, and obtain several sharp results.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:27:10 GMT""}]","2020-11-30"
"2011.13891","Cathy Swaenepoel","Cathy Swaenepoel, Arne Winterhof","Additive double character sums over some structured sets and
  applications",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study additive double character sums over two subsets of a finite field.
We show that if there is a suitable rational self-map of small degree of a set
$D$, then this set contains a large subset $U$ for which the standard bound on
the absolute value of the character sum over $U$ and any subset $C$ (which
satisfies some restrictions on its size $|C|$) can be improved. Examples of
such suitable self-maps are inversion and squaring. Then we apply this new
bound to trace products and sum-product equations and improve results of the
first author and of Gyarmati and S\'ark\""ozy.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:27:44 GMT""}]","2020-11-30"
"2011.13892","Liu Erfu","Erfu Liu, Takashi Taniguchi, Kenji Watanabe, Nathaniel M. Gabor,
  Yong-Tao Cui, Chun Hung Lui","Excitonic and valleytronic signatures of correlated states at fractional
  fillings of a moir\'e superlattice",,"Phys. Rev. Lett. 127, 037402 (2021)","10.1103/PhysRevLett.127.037402",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Moir\'e superlattices are excellent platforms to realize strongly correlated
quantum phenomena, such as Mott insulation and superconductivity. In
particular, recent research has revealed stripe phases and generalized Wigner
crystals at fractional fillings of moir\'e superlattices. But these experiments
have not focused on the influence of electronic crystallization on the
excitonic and valleytronic properties of the superlattices. Here we report
excitonic and valleytronic signatures of correlated states at fractional
fillings in a WSe$_2$/WS$_2$ moir\'e superlattice. We observe reflection
spectral modulation of three intralayer moir\'e excitons at filling factors
$\nu$ = 1/3 and 2/3. We also observe luminescence spectral modulation of
interlayer trions at around a dozen fractional filling factors, including $\nu$
= -3/2, 1/4, 1/3, 2/5, 2/3, 6/7, 5/3. In addition, the valley polarization of
interlayer trions is noticeably suppressed at some fractional fillings. These
results demonstrate a new regime of light-matter interactions, in which
electron crystallization significantly modulates the absorption, emission, and
valley dynamics of the excitonic states in a moir\'e superlattice.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:30:17 GMT""}]","2021-07-20"
"2011.13893","Michael Szpakowicz","Michael Muratov, Sachkiran Kaur, Michael Szpakowicz","Convolutional Neural Networks Towards Arduino Navigation of Indoor
  Environments","6 pages",,,,"cs.RO","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper we propose a number of tested ways in which a low-budget demo
car could be made to navigate an indoor environment. Canny Edge Detection,
Supervised Floor Detection and Imitation Learning were used separately and are
contrasted in their effectiveness. The equipment used in this paper
approximated an autonomous robot configured to work with a mobile device for
image processing. This paper does not provide definitive solutions and simply
illustrates the approaches taken to successfully achieve autonomous navigation
of indoor environments. The successes and failures of all approaches were
recorded and elaborated on to give the reader an insight into the construction
of such an autonomous robot.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:35:55 GMT""}]","2020-11-30"
"2011.13894","Victor Fragoso","Marcela Mera-Trujillo, Benjamin Smith, Victor Fragoso","Efficient Scene Compression for Visual-based Localization",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Estimating the pose of a camera with respect to a 3D reconstruction or scene
representation is a crucial step for many mixed reality and robotics
applications. Given the vast amount of available data nowadays, many
applications constrain storage and/or bandwidth to work efficiently. To satisfy
these constraints, many applications compress a scene representation by
reducing its number of 3D points. While state-of-the-art methods use
$K$-cover-based algorithms to compress a scene, they are slow and hard to tune.
To enhance speed and facilitate parameter tuning, this work introduces a novel
approach that compresses a scene representation by means of a constrained
quadratic program (QP). Because this QP resembles a one-class support vector
machine, we derive a variant of the sequential minimal optimization to solve
it. Our approach uses the points corresponding to the support vectors as the
subset of points to represent a scene. We also present an efficient
initialization method that allows our method to converge quickly. Our
experiments on publicly available datasets show that our approach compresses a
scene representation quickly while delivering accurate pose estimates.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:36:06 GMT""}]","2020-11-30"
"2011.13895","Chen Cheng","Qiujiang Guo, Chen Cheng, Hekang Li, Shibo Xu, Pengfei Zhang, Zhen
  Wang, Chao Song, Wuxin Liu, Wenhui Ren, Hang Dong, Rubem Mondaini, and H.
  Wang","Stark many-body localization on a superconducting quantum processor","8 pages, 5 figures; + Supplementary Materials: 12 pages, 11 figures","Phys. Rev. Lett. 127, 240502 (2021)","10.1103/PhysRevLett.127.240502",,"quant-ph cond-mat.dis-nn cond-mat.stat-mech cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Quantum emulators, owing to their large degree of tunability and control,
allow the observation of fine aspects of closed quantum many-body systems, as
either the regime where thermalization takes place or when it is halted by the
presence of disorder. The latter, dubbed many-body localization (MBL)
phenomenon, describes the non-ergodic behavior that is dynamically identified
by the preservation of local information and slow entanglement growth. Here, we
provide a precise observation of this same phenomenology in the case the onsite
energy landscape is not disordered, but rather linearly varied, emulating the
Stark MBL. To this end, we construct a quantum device composed of thirty-two
superconducting qubits, faithfully reproducing the relaxation dynamics of a
non-integrable spin model. Our results describe the real-time evolution at
sizes that surpass what is currently attainable by exact simulations in
classical computers, signaling the onset of quantum advantage, thus bridging
the way for quantum computation as a resource for solving out-of-equilibrium
many-body problems.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:37:01 GMT""}]","2021-12-14"
"2011.13896","Edval J. P. Santos PhD","Anatoly A. Barybin, Edval J. P. Santos","Large-Signal and High--Frequency Analysis of Nonuniformly Doped or
  Shaped PN-Junction Diodes","14 pages, 3 figures","Journal of Applied Physics 109, 114510 (2011)","10.1063/1.3592206",,"physics.app-ph cond-mat.mes-hall physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An analytical theory of non-uniformly doped or shaped PN-junction diodes
submitted to large-signals at high frequencies is presented. The resulting
expressions can be useful to evaluate the performance of semiconductor device
modeling software. The transverse averaging technique is employed to reduce the
three-dimensional charge carrier transport equations into the
quasi-one-dimensional form, with all physical quantities averaged out over the
longitudinally-varying cross section. Although, it is assumed an axial
symmetry, this approach gives rise to useful analytic expressions for the
static current--voltage characteristics, the diffusion conductance, and
diffusion capacitance as a function of the signal amplitude and the cross
section non-uniformity.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:38:11 GMT""}]","2020-11-30"
"2011.13897","Homanga Bharadhwaj","Kevin Xie, Homanga Bharadhwaj, Danijar Hafner, Animesh Garg, Florian
  Shkurti","Latent Skill Planning for Exploration and Transfer","First two authors contributed equally. Published as a conference
  paper in ICLR 2021",,,,"cs.LG cs.AI cs.RO stat.ML","http://creativecommons.org/licenses/by/4.0/","  To quickly solve new tasks in complex environments, intelligent agents need
to build up reusable knowledge. For example, a learned world model captures
knowledge about the environment that applies to new tasks. Similarly, skills
capture general behaviors that can apply to new tasks. In this paper, we
investigate how these two approaches can be integrated into a single
reinforcement learning agent. Specifically, we leverage the idea of partial
amortization for fast adaptation at test time. For this, actions are produced
by a policy that is learned over time while the skills it conditions on are
chosen using online planning. We demonstrate the benefits of our design
decisions across a suite of challenging locomotion tasks and demonstrate
improved sample efficiency in single tasks as well as in transfer from one task
to another, as compared to competitive baselines. Videos are available at:
https://sites.google.com/view/latent-skill-planning/
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:40:03 GMT""},{""version"":""v2"",""created"":""Sun, 2 May 2021 15:53:04 GMT""}]","2021-05-04"
"2011.13898","Corey Jones","Corey Jones","Remarks on anomalous symmetries of C*-algebras",,,"10.1007/s00220-021-04234-4",,"math.OA math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a group $G$ and $\omega\in Z^{3}(G, \text{U}(1))$, an $\omega$-anomalous
action on a C*-algebra $B$ is a $\text{U}(1)$-linear monoidal functor between
2-groups $\text{2-Gr}(G, \text{U}(1), \omega)\rightarrow
\underline{\text{Aut}}(B)$, where the latter denotes the 2-group of
$*$-automorphisms of $B$. The class $[\omega]\in H^{3}(G, \text{U}(1))$ is
called the anomaly of the action. We show for every $n\ge 2$ and every finite
group $G$, every anomaly can be realized on the stabilization of a commutative
C*-algebra $C(M)\otimes \mathcal{K}$ for some closed connected $n$-manifold
$M$. We also show that although there are no anomalous symmetries of Roe
C*-algebras of coarse spaces, for every finite group $G$, every anomaly can be
realized on the Roe corona $C^{*}(X)/\mathcal{K}$ of some bounded geometry
metric space $X$ with property $A$.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:41:06 GMT""},{""version"":""v2"",""created"":""Mon, 7 Dec 2020 13:53:00 GMT""},{""version"":""v3"",""created"":""Tue, 2 Feb 2021 01:53:30 GMT""},{""version"":""v4"",""created"":""Fri, 17 Sep 2021 13:15:24 GMT""}]","2021-10-27"
"2011.13899","Robert Webber","Robert J. Webber, David Aristoff, Gideon Simpson","A splitting method to reduce MCMC variance","30 pages, 9 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore whether splitting and killing methods can improve the accuracy of
Markov chain Monte Carlo (MCMC) estimates of rare event probabilities, and we
make three contributions. First, we prove that ""weighted ensemble"" is the only
splitting and killing method that provides asymptotically consistent estimates
when combined with MCMC. Second, we prove a lower bound on the asymptotic
variance of weighted ensemble's estimates. Third, we give a constructive proof
and numerical examples to show that weighted ensemble can approach this optimal
variance bound, in many cases reducing the variance of MCMC estimates by
multiple orders of magnitude.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:41:53 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 17:15:44 GMT""}]","2020-12-17"
"2011.13900","Mark Whitmeyer","Mark Whitmeyer","Persuasion Produces the (Diamond) Paradox","Update on 7 Dec 2020: fixed minor errors throughout, corrected the
  proofs of several lemmata in Section 2.1 (leaving the results unchanged),
  added in an example (Example 2.7), and removed the final proposition",,,,"econ.TH econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  This paper extends the sequential search model of Wolinsky (1986) by allowing
firms to choose how much match value information to disclose to visiting
consumers. This restores the Diamond paradox (Diamond 1971): there exist no
symmetric equilibria in which consumers engage in active search, so consumers
obtain zero surplus and firms obtain monopoly profits. Modifying the scenario
to one in which prices are advertised, we discover that the no-active-search
result persists, although the resulting symmetric equilibria are ones in which
firms price at marginal cost.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:42:03 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 18:11:32 GMT""},{""version"":""v3"",""created"":""Mon, 7 Dec 2020 18:24:57 GMT""},{""version"":""v4"",""created"":""Sat, 3 Apr 2021 08:43:05 GMT""}]","2021-04-06"
"2011.13901","Tilman Sauer","Tilman Sauer and Tobias Sch\""utz","Einstein on Involutions in Projective Geometry","45pp",,,,"physics.hist-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We discuss Einstein's knowledge of projective geometry. We show that two
pages of Einstein's Scratch Notebook from around 1912 with geometrical sketches
can directly be associated with similar sketches in manuscript pages dating
from his Princeton years. By this correspondence, we show that the sketches are
all related to a common theme, the discussion of involution in a projective
geometry setting with particular emphasis on the infinite point. We offer a
conjecture as to the probable purpose of these geometric considerations.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:42:14 GMT""}]","2020-11-30"
"2011.13902","Roman Pasechnik","Francisco J. de Anda, Alfredo Aranda, Ant\'onio P. Morais and Roman
  Pasechnik","Gauge couplings evolution from the Standard Model, through Pati-Salam
  theory, into $E_8$ unification of families and forces","18 pages, 1 figure and 4 tables",,,,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the potential of ultimate unification of the Standard Model matter
and gauge sectors into a single $E_8$ superfield in ten dimensions via an
intermediate Pati-Salam gauge theory. Through a consistent realisation of a
$\mathbb{T}^6/(\mathbb{Z}_6\times \mathbb{Z}_2)$ orbifolding procedure
accompanied by the Wilson line breaking mechanism and Renormalisation Group
evolution of gauge couplings, we have established several benchmark scenarios
for New Physics that are worth further phenomenological exploration.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:44:03 GMT""}]","2020-11-30"
"2011.13903","Andrew Kobin","Andrew Kobin","A Primer on Zeta Functions and Decomposition Spaces","23 pages; minor changes and additional references added",,,,"math.NT math.AG math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many examples of zeta functions in number theory and combinatorics are
special cases of a construction in homotopy theory known as a decomposition
space. This article aims to introduce number theorists to the relevant concepts
in homotopy theory and lays some foundations for future applications of
decomposition spaces in the theory of zeta functions.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:44:19 GMT""},{""version"":""v2"",""created"":""Mon, 9 May 2022 16:32:58 GMT""}]","2022-05-10"
"2011.13904","Mouhamadou Sy","Mouhamadou Sy and Xueying Yu","Global well-posedness and long-time behavior of the fractional NLS","39 pages",,"10.1007/s40072-021-00210-0",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, our discussion mainly focuses on equations with energy
supercritical nonlinearities. We establish probabilistic global well-posedness
(GWP) results for the cubic Schr\""odinger equation with any fractional power of
the Laplacian in all dimensions. We consider both low and high regularities in
the radial setting, in dimension $\geq 2$. In the high regularity result, an
{\it Inviscid - Infinite dimensional (IID) limit} is employed while in the low
regularity global well-posedness result, we make use of the Skorokhod
representation theorem. The IID limit is presented in details as an independent
approach that applies to a wide range of Hamiltonian PDEs. Moreover we discuss
the adaptation to the periodic settings, in any dimension, for smooth
regularities.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:46:05 GMT""},{""version"":""v2"",""created"":""Wed, 18 Aug 2021 19:00:13 GMT""}]","2021-09-07"
"2011.13905","Iulia Teodora Simion","Iulia T. Simion, Juntai Shen, Sergey E. Koposov, Melissa Ness, Kenneth
  Freeman, Jonathan Bland-Hawthorn and Geraint F. Lewis","Mapping the tilt of the Milky Way bulge velocity ellipsoids with ARGOS
  and $Gaia$ DR2","13 pages, 11 figures",,"10.1093/mnras/stab073",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Until the recent advent of $Gaia$ Data Release 2 (DR2) and deep multi-object
spectroscopy, it has been difficult to obtain 6-D phase space information for
large numbers of stars beyond 4 kpc, in particular towards the Galactic centre,
where dust and crowding effects are significant. In this study we combine
line-of-sight velocities from the Abundances and Radial velocity Galactic
Origins Survey (ARGOS) spectroscopic survey with proper motions from $Gaia$
DR2, to obtain a sample of $\sim$ 7,000 red clump stars with 3-D velocities. We
perform a large scale stellar kinematics study of the Milky Way (MW) bulge to
characterize the bulge velocity ellipsoids. We measure the tilt $l_{v}$ of the
major-axis of the velocity ellipsoid in the radial-longitudinal velocity plane
in 20 fields across the bulge. The tilt or vertex deviation, is characteristic
of non-axisymmetric systems and a significant tilt is a robust indicator of
non-axisymmetry or bar presence. We compare the observations to the predicted
kinematics of an N-body boxy-bulge model formed from dynamical instabilities.
In the model, the $l_{v}$ values are strongly correlated with the angle
($\alpha$) between the bulge major-axis and the Sun-Galactic centre
line-of-sight. We use a maximum likelihood method to obtain an independent
measurement of $\alpha$, from bulge stellar kinematics alone. The most likely
value of $\alpha$ given our model is $\alpha = (29 \pm 3)^{\circ}$. In the
Baade's window, the metal-rich stars display a larger vertex deviation ($l_{v}
= -40^{\circ}$) than the metal-poor stars ($l_{v} = 10^{\circ}$) but we do not
detect significant $l_{v}-$metallicity trends in the other fields.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:47:15 GMT""}]","2021-01-20"
"2011.13906","Thiago Guimar\~aes","T. M. Guimar\~aes, R. de C. Lima, S. H. Pereira","Cosmological inflation driven by a scalar torsion function","8 pages, 2 figures, submitted to EPJC","The European Physical Journal C (2021)","10.1140/epjc/s10052-021-09076-x","81, Article number: 271 (2021)","gr-qc","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A viable model for inflation driven by a torsion function in a Friedmann
background is presented. The scalar spectral index in the interval
$0.92\lesssim n_{s}\lesssim 0.97$ is obtained in order to satisfy the initial
conditions for inflation. The post inflationary phase is also studied, and the
analytical solutions obtained for scale factor and energy density generalizes
that ones for a matter dominated universe, indicating just a small deviation
from the standard model evolution. The same kind of torsion function used also
describes satisfactorily the recent acceleration of the universe, which could
indicate a possible unification of different phases, apart form specific
constants.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:47:16 GMT""}]","2022-09-22"
"2011.13907","Ferdinand Kuemmeth","Ferdinand Kuemmeth and Hendrik Bluhm","Roadmap for gallium arsenide spin qubits","This section is part of a roadmap on quantum technologies and
  comprises 4 pages with 2 figures","Nanotechnology 32, 162003 (2021)","10.1088/1361-6528/abb333","NBI QDEV 2020","cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gate-defined quantum dots in gallium arsenide (GaAs) have been used
extensively for pioneering spin qubit devices due to the relative simplicity of
fabrication and favourable electronic properties such as a single conduction
band valley, a small effective mass, and stable dopants. GaAs spin qubits are
readily produced in many labs and are currently studied for various
applications, including entanglement, quantum non-demolition measurements,
automatic tuning, multi-dot arrays, coherent exchange coupling, and
teleportation. Even while much attention is shifting to other materials, GaAs
devices will likely remain a workhorse for proof-of-concept quantum information
processing and solid-state experiments.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:48:20 GMT""}]","2022-10-19"
"2011.13908","Will Ma","Will Ma, Pan Xu, Yifan Xu","Group-level Fairness Maximization in Online Bipartite Matching",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  We consider the allocation of limited resources to heterogeneous customers
who arrive in an online fashion. We would like to allocate the resources
""fairly"", so that no group of customers is marginalized in terms of their
overall service rate. We study whether this is possible to do so in an online
fashion, and if so, what a good online allocation policy is.
  We model this problem using online bipartite matching under stationary
arrivals, a fundamental model in the literature typically studied under the
objective of maximizing the total number of customers served. We instead study
the objective of maximizing the minimum service rate across all groups, and
propose two notions of fairness: long-run and short-run.
  For these fairness objectives, we analyze how competitive online algorithms
can be, in comparison to offline algorithms which know the sequence of demands
in advance. For long-run fairness, we propose two online heuristics (Sampling
and Pooling) which establish asymptotic optimality in different regimes (no
specialized supplies, no rare demand types, or imbalanced supply/demand). By
contrast, outside all of these regimes, we show that the competitive ratio of
online algorithms is between 0.632 and 0.732. For short-run fairness, we show
for complete bipartite graphs that the competitive ratio of online algorithms
is between 0.863 and 0.942; we also derive a probabilistic rejection algorithm
which is asymptotically optimal in the total demand.
  Depending on the overall scarcity of resources, either our Sampling or
Pooling heuristics could be desirable. The most difficult situation for online
allocation occurs when the total supply is just enough to serve the total
demand.
  We simulate our algorithms on a public ride-hailing dataset, which both
demonstrates the efficacy of our heuristics and validates our managerial
insights.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:48:22 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 04:07:10 GMT""},{""version"":""v3"",""created"":""Fri, 21 May 2021 16:27:27 GMT""}]","2021-05-24"
"2011.13909","Pietro Dona","Pietro Dona, Marco Fanizza, Pierre Martin-Dussaud and Simone Speziale","Asymptotics of $\mathrm{SL}(2,\mathbb{C})$ coherent invariant tensors","29 pages and 3 figures. v2:minor corrections and a subsection added
  to match published version",,"10.1007/s00220-021-04154-3",,"gr-qc hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the semiclassical limit of a class of invariant tensors for
infinite-dimensional unitary representations of $\mathrm{SL}(2,\mathbb{C})$ of
the principal series, corresponding to generalized Clebsch-Gordan coefficients
with $n\geq3$ legs. We find critical configurations of the quantum labels with
a power-law decay of the invariants. They describe 3d polygons that can be
deformed into one another via a Lorentz transformation. This is defined viewing
the edge vectors of the polygons are the electric part of bivectors satisfying
a (frame-dependent) relation between their electric and magnetic parts known as
$\gamma$-simplicity in the loop quantum gravity literature. The frame depends
on the SU(2) spin labelling the basis elements of the invariants. We compute a
saddle point approximation using the critical points and provide a
leading-order approximation of the invariants. The power-law is universal if
the SU(2) spins have their lowest value, and $n$-dependent otherwise. As a side
result, we provide a compact formula for $\gamma$-simplicity in arbitrary
frames. The results have applications to the current EPRL model, but also to
future research aiming at going beyond the use of fixed time gauge in spin foam
models.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:50:15 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 11:42:23 GMT""}]","2021-11-16"
"2011.13910","Mark Mirmelstein","Mark Mirmelstein, Giulio Fabbian, Antony Lewis, Julien Peloton","Instrumental systematics biases in CMB lensing reconstruction: a
  simulation-based assessment","25 pages, 15 figures","Phys. Rev. D 103, 123540 (2021)","10.1103/PhysRevD.103.123540",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Weak gravitational lensing of the cosmic microwave background (CMB) is an
important cosmological tool that allows us to learn about the structure,
composition and evolution of the Universe. Upcoming CMB experiments, such as
the Simons Observatory (SO), will provide high-resolution and low-noise CMB
measurements. We consider the impact of instrumental systematics on the
corresponding high-precision lensing reconstruction power spectrum
measurements. We simulate CMB temperature and polarization maps for an SO-like
instrument and potential scanning strategy, and explore systematics relating to
beam asymmetries and offsets, boresight pointing, polarization angle, gain
drifts, gain calibration and electric crosstalk. Our analysis shows that the
majority of the biases induced by the systematics we modeled are below a
detection level of $\sim 0.6\sigma$. We discuss potential mitigation techniques
to further reduce the impact of the more significant systematics, and pave the
way for future lensing-related systematics analyses.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:55:15 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 15:02:58 GMT""}]","2021-06-30"
"2011.13911","Nikita Nemkov Andreevich","Nikita Nemkov and Semyon Klevtsov","Liouville perturbation theory for Laughlin state and Coulomb gas","22 pages",,"10.1088/1751-8121/ac1483",,"cond-mat.str-el hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the generating functional (logarithm of the normalization factor)
of the Laughlin state on a sphere, in the limit of a large number of particles
$N$. The problem is reformulated in terms of a perturbative expansion of a 2d
QFT, resembling the Liouville field theory. We develop an analog of the
Liouville loop perturbation theory, which allows us to quantitatively study the
generating functional for an arbitrary smooth metric and an inhomogeneous
magnetic field beyond the leading orders in large $N$.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:55:19 GMT""}]","2021-09-01"
"2011.13912","Kamal Diki","Daniel Alpay, Fabrizio Colombo, Kamal Diki, Irene Sabadini","Poly slice monogenic functions, Cauchy formulas and the PS-functional
  calculus","Accepted, to appear in J. Oper. Theory",,,,"math.FA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Since 2006 the theory of slice hyperholomorphic functions and the related
spectral theory on the S-spectrum have had a very fast development. This new
spectral theory based on the S-spectrum has applications, for example, in the
formulation of quaternionic quantum mechanics, in Schur analysis and in
fractional diffusion problems. In this paper we introduce and study the theory
of poly slice monogenic functions, also proving some Cauchy type integral
formulas. Then we introduce the associated functional calculus, called
PS-functional calculus, which is the polyanalytic version of the S-functional
calculus and which is based on the notion of S-spectrum. We study some
different formulations of the calculus and we prove some of its properties,
among which the product rules.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:55:34 GMT""},{""version"":""v2"",""created"":""Fri, 12 Nov 2021 06:29:03 GMT""}]","2021-11-15"
"2011.13913","Mahmut Yurt","Mahmut Yurt, Muzaffer \""Ozbey, Salman Ul Hassan Dar, Berk T{\i}naz,
  Kader Karl{\i} O\u{g}uz, Tolga \c{C}ukur","Progressively Volumetrized Deep Generative Models for Data-Efficient
  Contextual Learning of MR Image Recovery",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic resonance imaging (MRI) offers the flexibility to image a given
anatomic volume under a multitude of tissue contrasts. Yet, scan time
considerations put stringent limits on the quality and diversity of MRI data.
The gold-standard approach to alleviate this limitation is to recover
high-quality images from data undersampled across various dimensions, most
commonly the Fourier domain or contrast sets. A primary distinction among
recovery methods is whether the anatomy is processed per volume or per
cross-section. Volumetric models offer enhanced capture of global contextual
information, but they can suffer from suboptimal learning due to elevated model
complexity. Cross-sectional models with lower complexity offer improved
learning behavior, yet they ignore contextual information across the
longitudinal dimension of the volume. Here, we introduce a novel progressive
volumetrization strategy for generative models (ProvoGAN) that serially
decomposes complex volumetric image recovery tasks into successive
cross-sectional mappings task-optimally ordered across individual rectilinear
dimensions. ProvoGAN effectively captures global context and recovers
fine-structural details across all dimensions, while maintaining low model
complexity and improved learning behaviour. Comprehensive demonstrations on
mainstream MRI reconstruction and synthesis tasks show that ProvoGAN yields
superior performance to state-of-the-art volumetric and cross-sectional models.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:55:56 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 17:48:15 GMT""},{""version"":""v3"",""created"":""Thu, 10 Mar 2022 12:04:57 GMT""},{""version"":""v4"",""created"":""Sat, 12 Mar 2022 11:36:28 GMT""}]","2022-03-15"
"2011.13914","Nicholas Milson","Nicholas Milson, Caroline Barton, and Philip D. Bennett","A Python Code to Determine Orbital Parameters of Spectroscopic Binaries","11 pages, 4 figures, submitted to the Journal of the American
  Association of Variable Star Observers (JAAVSO)",,,,"astro-ph.SR astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We present the open source Python code BinaryStarSolver that solves for the
orbital elements of a spectroscopic binary system. Given a time-series of
radial velocity measurements, six orbital parameters are determined: the
long-term mean, or systemic, radial velocity, the velocity amplitude, the
argument of periastron, the eccentricity, the epoch of periastron, and the
orbital period referred to by $\{{\gamma, K, \omega, e, T_0, P}\}$
respectively. Also returned to the user is the projected length of the
semi-major axis, $a_{1}\sin(i)$, and the mass function, $f(M)$. The
determination of spectroscopic orbits and masses is an example of another
important area of astrophysics, once the domain of professional astronomers, to
which amateurs can now make significant contributions. This code, available
from GitHub, is provided in support of that work, and should be of general use
to the amateur and professional astronomical community.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:56:31 GMT""}]","2020-11-30"
"2011.13915","Manuel Gonzalez-Lopez","Manuel Gonzalez-Lopez, Maria Herrero, Paula Martinez-Suarez","Testing anomalous $H-W$ couplings and Higgs self-couplings via double
  and triple Higgs production at $e^+e^-$ colliders","49 pages, 39 figure, 2 tables. Version published in EPJC",,"10.1140/epjc/s10052-021-09048-1",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present work we study the implications at the future $e^+e^-$
colliders of the modified interaction vertices $WWH$, $WWHH$, $HHH$ and $HHHH$
within the context of the non-linear effective field theory given by the
Electroweak Chiral Lagrangian. These vertices are given by four parameters,
$a$, $b$, $\kappa_3$ and $\kappa_4$, respectively, that are independent and
without any constraint from symmetry considerations in this non-linear
effective Lagrangian context, given the fact the Higgs field is a singlet. This
is in contrast to the Standard Model, where the vertices are related by
$V_{WWH}^{\rm SM}=v V_{WWHH}^{\rm SM}$ and $V_{HHH}^{\rm SM}=v V_{HHHH}^{\rm
SM}$, with $v=246$ GeV. We investigate the implications of the absence of these
relations in the Electroweak Chiral Lagrangian case. We explore the sensitivity
to these Higgs anomalous couplings in the two main channels at these colliders:
double and triple Higgs production (plus neutrinos). Concretely, we study the
access to $a$ and $b$ in $e^+e^- \to HH \nu \bar{\nu}$ and the access to
$\kappa_3$ and $\kappa_4$ in $e^+e^- \to HHH \nu \bar{\nu}$. Our study of the
beyond the Standard Model couplings via triple Higgs boson production at
$e^+e^-$ colliders is novel and shows for the first time the possible
accessibility to the quartic Higgs self-coupling.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:58:02 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 15:04:21 GMT""}]","2021-04-06"
"2011.13916","Honglin Li","Honglin Li, Magdalena Anita Kolanko, Shirin Enshaeifar, Severin
  Skillman, Andreas Markides, Mark Kenny, Eyal Soreq, Samaneh Kouchaki, Kirsten
  Jensen, Loren Cameron, Michael Crone, Paul Freemont, Helen Rostill, David J.
  Sharp, Ramin Nilforooshan, Payam Barnaghi","Deep Representation for Connected Health: Semi-supervised Learning for
  Analysing the Risk of Urinary Tract Infections in People with Dementia","11 pages",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Machine learning techniques combined with in-home monitoring technologies
provide a unique opportunity to automate diagnosis and early detection of
adverse health conditions in long-term conditions such as dementia. However,
accessing sufficient labelled training samples and integrating high-quality,
routinely collected data from heterogeneous in-home monitoring technologies are
main obstacles hindered utilising these technologies in real-world medicine.
This work presents a semi-supervised model that can continuously learn from
routinely collected in-home observation and measurement data. We show how our
model can process highly imbalanced and dynamic data to make robust predictions
in analysing the risk of Urinary Tract Infections (UTIs) in dementia. UTIs are
common in older adults and constitute one of the main causes of avoidable
hospital admissions in people with dementia (PwD). Health-related conditions,
such as UTI, have a lower prevalence in individuals, which classifies them as
sporadic cases (i.e. rare or scattered, yet important events). This limits the
access to sufficient training data, without which the supervised learning
models risk becoming overfitted or biased. We introduce a probabilistic
semi-supervised learning framework to address these issues. The proposed method
produces a risk analysis score for UTIs using routinely collected data by
in-home sensing technologies.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:58:05 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jan 2021 11:15:24 GMT""},{""version"":""v3"",""created"":""Sat, 3 Apr 2021 09:06:17 GMT""},{""version"":""v4"",""created"":""Wed, 28 Apr 2021 16:23:50 GMT""}]","2021-04-29"
"2011.13917","Jennifer J. Sun","Jennifer J. Sun, Ann Kennedy, Eric Zhan, David J. Anderson, Yisong
  Yue, Pietro Perona","Task Programming: Learning Data Efficient Behavior Representations","To appear in as an Oral in CVPR 2021. Code:
  https://github.com/neuroethology/TREBA. Project page:
  https://sites.google.com/view/task-programming",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Specialized domain knowledge is often necessary to accurately annotate
training sets for in-depth analysis, but can be burdensome and time-consuming
to acquire from domain experts. This issue arises prominently in automated
behavior analysis, in which agent movements or actions of interest are detected
from video tracking data. To reduce annotation effort, we present TREBA: a
method to learn annotation-sample efficient trajectory embedding for behavior
analysis, based on multi-task self-supervised learning. The tasks in our method
can be efficiently engineered by domain experts through a process we call ""task
programming"", which uses programs to explicitly encode structured knowledge
from domain experts. Total domain expert effort can be reduced by exchanging
data annotation time for the construction of a small number of programmed
tasks. We evaluate this trade-off using data from behavioral neuroscience, in
which specialized domain knowledge is used to identify behaviors. We present
experimental results in three datasets across two domains: mice and fruit
flies. Using embeddings from TREBA, we reduce annotation burden by up to a
factor of 10 without compromising accuracy compared to state-of-the-art
features. Our results thus suggest that task programming and self-supervision
can be an effective way to reduce annotation effort for domain experts.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:58:32 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 17:59:47 GMT""}]","2021-03-30"
"2011.13918","Jeff Andrews","Jeff J. Andrews, Julianne Cronin, Vicky Kalogera, Christopher Berry,
  and Andreas Zezas","Targeted modeling of GW150914's binary black hole source with dart_board","14 pages, 5 figures, 1 table, accepted for publication in ApJL",,"10.3847/2041-8213/ac00a6",,"astro-ph.HE astro-ph.SR gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new method to extract statistical constraints on the progenitor
properties and formation channels of individual gravitational-wave sources.
Although many different models have been proposed to explain the binary black
holes detected by the LIGO Scientific and Virgo Collaboration (LVC), formation
through isolated binary evolution remains the best explored channel. Under the
assumption of formation through binary evolution, we use the statistical
wrapper dart_board coupled with the rapid binary evolution code COSMIC to model
the progenitor of GW150914, the first gravitational-wave signal detected by the
LVC. Our Bayesian method combines the likelihood generated from the
gravitational-wave signal with a prior describing the population of stellar
binaries, and the Universe's star-formation and metallicity evolution. We find
that the dominant evolutionary channel for GW150914 did not involve a
common-envelope phase, but instead the system most probably (70%-90%) formed
through stable mass transfer. This result is robust against variations of
various model parameters, and it is reversed only when dynamical instability in
binaries becomes more likely when a strict condition favoring common envelopes
is adopted. Our analysis additionally provides a quantitative description of
the progenitors relevant to each channel.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:58:48 GMT""},{""version"":""v2"",""created"":""Sun, 16 May 2021 23:45:40 GMT""}]","2021-06-30"
"2011.13919","Hai Lin","Hai Lin, Yuwei Zhu","Coherent state superpositions, entanglement and gauge/gravity
  correspondence","39 pages","Journal of Mathematical Physics, 62 (2021) 5, 052301","10.1063/5.0039859",,"hep-th gr-qc math-ph math.MP quant-ph","http://creativecommons.org/licenses/by/4.0/","  We focus on two types of coherent states, the coherent states of multi
graviton states and the coherent states of giant graviton states, in the
context of gauge/gravity correspondence. We conveniently use a phase shift
operator and its actions on the superpositions of these coherent states. We
find $N$-state Schrodinger cat states which approach the one-row Young tableau
states, with fidelity between them asymptotically reaches 1 at large $N$. The
quantum Fisher information of these states is proportional to the variance of
the excitation energy of the underlying states, and characterizes the
localizability of the states in the angular direction in the phase space. We
analyze the correlation and entanglement between gravitational degrees of
freedom using different regions of the phase space plane in bubbling AdS. The
correlation between two entangled rings in the phase space plane is related to
the area of the annulus between the two rings. We also analyze two types of
noisy coherent states, which can be viewed as interpolated states that
interpolate between a pure coherent state in the noiseless limit and a
maximally mixed state in the large noise limit.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:59:15 GMT""}]","2021-05-05"
"2011.13920","Sara Sabour","Sara Sabour, Andrea Tagliasacchi, Soroosh Yazdani, Geoffrey E. Hinton,
  David J. Fleet","Unsupervised part representation by Flow Capsules",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Capsule networks aim to parse images into a hierarchy of objects, parts and
relations. While promising, they remain limited by an inability to learn
effective low level part descriptions. To address this issue we propose a way
to learn primary capsule encoders that detect atomic parts from a single image.
During training we exploit motion as a powerful perceptual cue for part
definition, with an expressive decoder for part generation within a layered
image model with occlusion. Experiments demonstrate robust part discovery in
the presence of multiple objects, cluttered backgrounds, and occlusion. The
part decoder infers the underlying shape masks, effectively filling in occluded
regions of the detected shapes. We evaluate FlowCapsules on unsupervised part
segmentation and unsupervised image classification.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:59:42 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 18:07:46 GMT""}]","2021-02-22"
"2011.13921","Juven C. Wang","Abhishodh Prakash, Juven Wang","Unwinding Fermionic SPT Phases: Supersymmetry Extension","61 pages. Sequel to arXiv:1804.11236, arXiv:1705.06728","Phys. Rev. B 103, 085130 (2021)","10.1103/PhysRevB.103.085130",,"cond-mat.str-el hep-th math-ph math.MP quant-ph","http://creativecommons.org/licenses/by/4.0/","  We show how 1+1-dimensional fermionic symmetry-protected topological states
(SPTs, i.e. nontrivial short-range entangled gapped phases of quantum matter
whose boundary exhibits 't Hooft anomaly and whose bulk cannot be deformed into
a trivial tensor product state under finite-depth local unitary transformations
only in the presence of global symmetries), indeed can be unwound to a trivial
state by enlarging the Hilbert space via adding extra degrees of freedom and
suitably extending the global symmetries. The extended projective global
symmetry on the boundary can become supersymmetric in a specific sense, i.e.,
it contains group elements that do not commute with the fermion number parity
$(-1)^F$, while the anti-unitary time-reversal symmetry becomes fractionalized.
This also means we can uplift and remove certain exotic fermionic anomalies
(e.g., ""parity"" anomaly in time-reversal or reflection symmetry) via
appropriate supersymmetry extensions in terms of group extensions. We work out
explicit examples for multi-layers of 1+1d Majorana fermion chains, then
comment on models with Sachdev-Ye-Kitaev (SYK) interactions, intrinsic
fermionic gapless SPTs protected by supersymmetry, and generalizations to
higher spacetime dimensions via a cobordism theory.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:59:50 GMT""}]","2021-02-23"
"2011.13929","Anthony Ashmore","Anthony Ashmore","Eigenvalues and eigenforms on Calabi-Yau threefolds","38 pages, 17 figures, 4 tables; v2: increased number of points in
  numerical integration; v3: updated plots, version submitted for peer review",,,,"hep-th math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a numerical algorithm for computing the spectrum of the Laplace-de
Rham operator on Calabi-Yau manifolds, extending previous work on the scalar
Laplace operator. Using an approximate Calabi-Yau metric as input, we compute
the eigenvalues and eigenforms of the Laplace operator acting on $(p,q)$-forms
for the example of the Fermat quintic threefold. We provide a check of our
algorithm by computing the spectrum of $(p,q)$-eigenforms on $\mathbb{P}^{3}$.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 20:58:22 GMT""},{""version"":""v3"",""created"":""Wed, 3 May 2023 23:19:59 GMT""}]","2023-05-05"
"2011.13930","Alex Drlica-Wagner","K. M. Stringer, A. Drlica-Wagner, L. Macri, C. E.
  Mart\'inez-V\'azquez, A. K. Vivas, P. Ferguson, A. B. Pace, A. R. Walker, E.
  Neilsen, K. Tavangar, W. Wester, T. M. C. Abbott, M. Aguena, S. Allam, D.
  Bacon, K. Bechtol, E. Bertin, D. Brooks, D. L. Burke, A. Carnero Rosell, M.
  Carrasco Kind, J. Carretero, M. Costanzi, M. Crocce, L. N. da Costa, M. E. S.
  Pereira, J. De Vicente, S. Desai, H. T. Diehl, P. Doel, I. Ferrero, J.
  Garc\'ia-Bellido, E. Gaztanaga, D. W. Gerdes, D. Gruen, R. A. Gruendl, J.
  Gschwend, G. Gutierrez, S. R. Hinton, D. L. Hollowood, K. Honscheid, B.
  Hoyle, D. J. James, K. Kuehn, N. Kuropatkin, T. S. Li, M. A. G. Maia, J. L.
  Marshall, F. Menanteau, R. Miquel, R. Morgan, R. L. C. Ogando, A. Palmese, F.
  Paz-Chinch\'on, A. A. Plazas, A. Roodman, E. Sanchez, M. Schubnell, S.
  Serrano, I. Sevilla-Noarbe, M. Smith, M. Soares-Santos, E. Suchyta, G. Tarle,
  D. Thomas, C. To, T. N. Varga, R.D. Wilkinson, Y. Zhang, the DES
  Collaboration","Identifying RR Lyrae Variable Stars in Six Years of the Dark Energy
  Survey","34 pages, 20 figures, 9 tables. Updated to match published version.
  Data products are available at
  https://des.ncsa.illinois.edu/releases/other/y6-rrl","ApJ 911, 109 (2021)","10.3847/1538-4357/abe873","FERMILAB-PUB-20-610-AE","astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present a search for RR Lyrae stars using the full six-year data set from
the Dark Energy Survey (DES) covering ~5,000 sq. deg. of the southern sky.
Using a multi-stage multi-variate classification and light curve
template-fitting scheme, we identify RR Lyrae candidates with a median of 35
observations per candidate. We detect 6,971 RR Lyrae candidates out to ~335
kpc, and we estimate that our sample is >70% complete at ~150 kpc. We find
excellent agreement with other wide-area RR Lyrae catalogs and RR Lyrae studies
targeting the Magellanic Clouds and other Milky Way satellite galaxies. We fit
the smooth stellar halo density profile using a broken-power-law model with
fixed halo flattening (q = 0.7), and we find strong evidence for a break at
$R_0 = 32.1^{+1.1}_{-0.9}$ kpc with an inner slope of $n_1 =
-2.54^{+0.09}_{-0.09}$ and an outer slope of $n_2 = -5.42^{+0.13}_{-0.14}$. We
use our catalog to perform a search for Milky Way satellite galaxies with large
sizes and low luminosities. Using a set of simulated satellite galaxies, we
find that our RR Lyrae-based search is more sensitive than those using resolved
stellar populations in the regime of large ($r_h > 500$ pc),
low-surface-brightness dwarf galaxies. A blind search for large, diffuse
satellites yields three candidate substructures. The first can be confidently
associated with the dwarf galaxy Eridanus II. The second has a similar distance
and proper motion to the ultra-faint dwarf galaxy Tucana II but is separated by
~5 deg. The third is close in projection to the globular cluster NGC 1851 but
is ~10 kpc more distant and appears to differ in proper motion.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:00 GMT""},{""version"":""v2"",""created"":""Sat, 8 May 2021 22:34:31 GMT""}]","2021-05-11"
"2011.13931","Shoji Ogawa","Shoji Ogawa, Yoshihiro Ueda, Atsushi Tanimoto, and Satoshi Yamada","Systematic Study of AGN Clumpy Tori with Broadband X-ray Spectroscopy:
  Updated Unified Picture of AGN Structure","24 pages, 6 figures, and 5 tables, accepted for publication in ApJ",,"10.3847/1538-4357/abccce",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the results of a systematic, broadband X-ray spectral analysis of
nearby active galactic nuclei (AGNs) with the X-ray clumpy torus model
(XCLUMPY; Tanimoto et al. 2019). By adding 16 AGNs newly analyzed in this
paper, we study total 28 AGNs including unabsorbed and absorbed AGNs taken from
Ichikawa et al. (2015) and Garc\'ia-Bernete et al. (2019). This is the largest
sample whose X-ray and infrared spectra are analyzed by the clumpy torus models
XCLUMPY and CLUMPY (Nenkova et al. 2008), respectively. The relation between
the Eddington ratio and the torus covering factor determined from the X-ray
torus parameters of each object follows the trend found by Ricci et al. (2017)
based on a statistical analysis. We confirm the results by Tanimoto et al.
(2020) that (1) the torus angular widths determined by the infrared data are
larger than those by the X-ray data and that (2) the ratios of the hydrogen
column density to V-band extinction ($N_{\rm H}/A_{\rm V}$) along the line of
sight in obscured AGNs are similar to the Galactic value on average. Unobscured
AGNs show apparently smaller line-of-sight $N_{\rm H}/A_{\rm V}$ ratios than
the Galactic one. Our findings can be well explained by an updated unified
picture of AGN structure including a dusty torus, dusty polar outflows, and
dust-free gas, where the inclination determines the X-ray and optical
classifications and observed torus properties in the X-ray and infrared bands.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:00 GMT""}]","2021-01-20"
"2011.13932","Carlos Nunez","Yolanda Lozano, Carlos Nunez, Anayeli Ramirez and Stefano Speziali","AdS$_2$ duals to ADHM quivers with Wilson lines","26 pages and various appendices. Many figures",,"10.1007/JHEP03(2021)145",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We discuss AdS$_2\times S^3\times{\text{CY}}_2\times I_{\rho}$ solutions to
massive Type IIA supergravity with 4 Poincar\'e supersymmetries. We propose
explicit dual quiver quantum mechanics built out of D0 and D4 colour branes
coupled to D4' and D8 flavour branes. We propose that these quivers describe
the interactions of instantons and Wilson lines in 5d gauge theories with 8
Poincar\'e supersymmetries. Using the RR Maxwell fluxes of the solutions,
conveniently put off-shell, we construct a functional from which the
holographic central charge can be derived through a geometrical extremisation
principle
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:00 GMT""}]","2021-03-31"
"2011.13933","Pablo Antonio Cano Molina-Ni\~nirola","Pablo A. Cano, Kwinten Fransen and Thomas Hertog","Novel higher-curvature variations of $R^2$ inflation","27 pages, double column, 6 figures","Phys. Rev. D 103, 103531 (2021)","10.1103/PhysRevD.103.103531",,"hep-th astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We put forward novel extensions of Starobinsky inflation, involving a class
of 'geometric' higher-curvature corrections that yield second-order
Friedmann-Lema\^itre equations and second-order-in-time linearized equations
around cosmological backgrounds. We determine the range of models within this
class that admit an extended phase of slow roll inflation as an attractor. By
embedding these theories in anti-de Sitter space, we derive holographic
'unitarity' bounds on the two dominant higher-order curvature corrections.
Finally we compute the leading corrections to the spectral properties of scalar
and tensor primordial perturbations, including the modified consistency
relation $r=-8n_{T}$. Remarkably, the range of models singled out by holography
nearly coincides with the current observational bounds on the scalar spectral
tilt. Our results indicate that future observations have the potential to
discriminate between different higher-curvature corrections considered here.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:00 GMT""}]","2021-05-26"
"2011.13934","Stefano Carrazza","Adri\'an P\'erez-Salinas, Juan Cruz-Martinez, Abdulla A. Alhajri,
  Stefano Carrazza","Determining the proton content with a quantum computer","13 pages, 14 figures, 4 tables, accepted for publication in PRD, code
  available at https://github.com/Quantum-TII/qibo","Phys. Rev. D 103, 034027 (2021)","10.1103/PhysRevD.103.034027","TIF-UNIMI-2020-30","hep-ph hep-ex quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a first attempt to design a quantum circuit for the determination
of the parton content of the proton through the estimation of parton
distribution functions (PDFs), in the context of high energy physics (HEP). The
growing interest in quantum computing and the recent developments of new
algorithms and quantum hardware devices motivates the study of methodologies
applied to HEP. In this work we identify architectures of variational quantum
circuits suitable for PDFs representation (qPDFs). We show experiments about
the deployment of qPDFs on real quantum devices, taking into consideration
current experimental limitations. Finally, we perform a global qPDF
determination from collider data using quantum computer simulation on classical
hardware and we compare the obtained partons and related phenomenological
predictions involving hadronic processes to modern PDFs.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jan 2021 21:48:31 GMT""}]","2021-03-03"
"2011.13935","Andra Stroe","Andra Stroe, Maryam Hussaini, Bernd Husemann, David Sobral and Grant
  Tremblay","The First Integral Field Unit Spectroscopic View of Shocked Cluster
  Galaxies","Published in ApJ Letters. Main results can be found in Figure 3. Data
  behind figures are available together with the journal paper","The Astrophysical Journal Letters, Volume 905, Number 2 (17 Dec
  2020)","10.3847/2041-8213/abcb04",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Galaxy clusters grow by merging with other clusters, giving rise to Mpc-wide
shock waves that travel at 1000-2500 km/s through the intra-cluster medium. To
study the effects of merger shocks on the properties of cluster galaxies, we
present the first spatially resolved spectroscopic view of 5 H$\alpha$ emitting
galaxies located in the wake of shock fronts in the low redshift (z~0.2),
massive (~2$\times10^{15}$ M$_\odot$), post-core passage merging cluster, CIZA
J2242.8+5301 (nicknamed the `Sausage'). Our Gemini/GMOS-N integral field unit
(IFU) observations, designed to capture H$\alpha$ and [NII] emission, reveal
the nebular gas distribution, kinematics and metallicities in the galaxies over
>16 kpc scales. While the galaxies show evidence for rotational support, the
flux and velocity maps have complex features like tails and gas outflows
aligned with the merger axis of the cluster. With gradients incompatible with
inside-out disk growth, the metallicity maps are consistent with sustained star
formation (SF) throughout and outside of the galactic disks. In combination
with previous results, these pilot observations provide further evidence of a
likely connection between cluster mergers and SF triggering in cluster
galaxies, a potentially fundamental discovery revealing the interaction of
galaxies with their environment.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 18 Dec 2020 14:26:52 GMT""}]","2020-12-21"
"2011.13936","Sebasti\'an C\'espedes","Sebastian Cespedes, Senarath P. de Alwis, Francesco Muia and Fernando
  Quevedo","Lorentzian Vacuum Transitions: Open or Closed Universes?","41 pages+ appendices, 15 figues. Minor rewording and references added","Phys. Rev. D 104, 026013 (2021)","10.1103/PhysRevD.104.026013",,"hep-th astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  We consider the generalisation of quantum tunneling transitions in the WKB
approximation to the time-independent functional Schr\""odinger and
Wheeler-DeWitt equations. Following a Lorentzian approach, we compute the
transition rates among different scalar field vacua and compare with those
performed by Coleman and collaborators using the Euclidean approach. For
gravity, we develop a general formalism for computing transition rates in
Wheeler's superspace. This is then applied to computing decays in flat space
and then to transitions in the presence of gravity. In the latter case we point
out the complexities arising from having non-positive definite kinetic terms
illustrating them in the simplified context of mini-superspace. This
corresponds to a generalisation of the well-known `tunneling from nothing'
scenarios. While we can obtain the leading term for the transitions obtained by
Euclidean methods we also point out some differences and ambiguities. We show
that there is no obstruction to keeping the spherically ($SO(4)$) symmetric
closed slicing for the new vacuum after a de Sitter to de Sitter transition. We
argue that this is the natural Lorentzian realisation of the Coleman-De Luccia
instanton and that a closed universe is also obtained if the mini-superspace
assumption is relaxed. This is contrary to the open universe predicted by
Coleman-De Luccia which relies on an analytic continuation performed after
bubble nucleation. Our findings may have important cosmological implications
related to the origin of inflation and to the string landscape. In particular,
they question the widespread belief that evidence for a closed universe would
rule out the string landscape.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 10 Dec 2020 09:42:55 GMT""}]","2021-08-04"
"2011.13937","Christopher White","Christopher David White and Justin H. Wilson","Mana in Haar-random states",,,,,"quant-ph cond-mat.dis-nn cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mana is a measure of the amount of non-Clifford resources required to create
a state; the mana of a mixed state on $\ell$ qudits bounded by $\le \frac 1 2
(\ell \ln d - S_2)$; $S_2$ the state's second Renyi entropy. We compute the
mana of Haar-random pure and mixed states and find that the mana is nearly
logarithmic in Hilbert space dimension: that is, extensive in number of qudits
and logarithmic in qudit dimension. In particular, the average mana of states
with less-than-maximal entropy falls short of that maximum by $\ln \pi/2$. We
then connect this result to recent work on near-Clifford approximate
$t$-designs; in doing so we point out that mana is a useful measure of
non-Clifford resources precisely because it is not differentiable.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:01 GMT""}]","2020-12-01"
"2011.13938","Subin Sahu","Subin Sahu and Michael Zwolak","Diffusion Limitations and Translocation Barriers in Atomically Thin
  Biomimetic Pores",,"Entropy 22, 1326 (2020)","10.3390/e22111326",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Ionic transport in nano- to sub-nano-scale pores is highly dependent on
translocation barriers and potential wells. These features in the free-energy
landscape are primarily the result of ion dehydration and electrostatic
interactions. For pores in atomically thin membranes, such as graphene, other
factors come into play. Ion dynamics both inside and outside the geometric
volume of the pore can be critical in determining the transport properties of
the channel due to several commensurate length scales, such as the effective
membrane thickness, radii of the first and the second hydration layers, pore
radius, and Debye length. In particular, for biomimetic pores, such as the
graphene crown ether we examine here, there are regimes where transport is
highly sensitive to the pore size due to the interplay of dehydration and
interaction with pore charge. Picometer changes in the size, e.g., due to a
minute strain, can lead to a large change in conductance. Outside of these
regimes, the small pore size itself gives a large resistance, even when
electrostatic factors and dehydration compensate each other to give a
relatively flat -- e.g., near barrierless -- free energy landscape. The
permeability, though, can still be large and ions will translocate rapidly
after they arrive within the capture radius of the pore. This, in turn, leads
to diffusion and drift effects dominating the conductance. The current thus
plateaus and becomes effectively independent of pore-free energy
characteristics. Measurement of this effect will give an estimate of the
magnitude of kinetically limiting features, and experimentally constrain the
local electromechanical conditions.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:01 GMT""}]","2020-12-01"
"2011.13939","Daniel Egana-Ugrinovic","Peizhi Du, Daniel Egana-Ugrinovic, Rouven Essig, Mukul Sholapurkar","Sources of Low-Energy Events in Low-Threshold Dark Matter and Neutrino
  Detectors","32 pages, 22 figures, 4 appendices. v2 matches the published version,
  which contains minor corrections and extends the discussion on qubit
  decoherence","Phys.Rev.X 12 (2022) 1, 011009","10.1103/PhysRevX.12.011009",,"hep-ph astro-ph.CO astro-ph.IM hep-ex quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss several low-energy backgrounds to sub-GeV dark matter searches,
which arise from high-energy particles of cosmic or radioactive origin that
interact with detector materials. We focus in particular on Cherenkov
radiation, transition radiation, and luminescence or phonons from electron-hole
pair recombination, and show that these processes are an important source of
backgrounds at both current and planned detectors. We perform detailed analyses
of these backgrounds at several existing and proposed experiments based on a
wide variety of detection strategies and levels of shielding. We find that a
large fraction of the observed single-electron events in the SENSEI 2020 run
originate from Cherenkov photons generated by high-energy events in the Skipper
Charge Coupled Device, and from recombination photons generated in a
phosphorus-doped layer of the same instrument. In a SuperCDMS HVeV 2020 run,
Cherenkov photons produced in printed-circuit-boards located near the sensor
likely explain the origin of most of the events containing 2 to 6 electrons. At
SuperCDMS SNOLAB, radioactive contaminants inside the Cirlex located inside or
on the copper side walls of their detectors will produce many Cherenkov
photons, which could dominate the low-energy backgrounds. For the EDELWEISS
experiment, Cherenkov or luminescence backgrounds are subdominant to their
observed event rate, but could still limit the sensitivity of their future
searches. We also point out that Cherenkov radiation, transition radiation, and
recombination could be a significant source of backgrounds at future
experiments aiming to detect dark-matter via scintillation or phonon signals.
We also discuss the implications of our results for the development of
superconducting qubits and low-threshold searches for coherent neutrino
scattering, and comment on design strategies that can be implemented to
mitigate these backgrounds.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 16 Feb 2022 18:47:43 GMT""}]","2022-02-18"
"2011.13940","David Jess","David B. Jess, Peter H. Keys, Marco Stangalini, Shahin Jafarzadeh","High-resolution wave dynamics in the lower solar atmosphere","16 pages, 4 figures, Introduction to the ""High-resolution wave
  dynamics in the lower solar atmosphere"" special issue of the Philosophical
  Transactions A: https://walsa.team/u/rsta",,"10.1098/rsta.2020.0169",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The magnetic and convective nature of the Sun's photosphere provides a unique
platform from which generated waves can be modelled, observed, and interpreted
across a wide breadth of spatial and temporal scales. As oscillations are
generated in-situ or emerge through the photospheric layers, the interplay
between the rapidly evolving densities, temperatures, and magnetic field
strengths provides dynamic evolution of the embedded wave modes as they
propagate into the tenuous solar chromosphere. A focused science team was
assembled to discuss the current challenges faced in wave studies in the lower
solar atmosphere, including those related to spectropolarimetry and radiative
transfer in the optically thick regions. Following the Theo Murphy
international scientific meeting held at Chicheley Hall during February 2020,
the scientific team worked collaboratively to produce 15 independent
publications for the current Special Issue, which are introduced here.
Implications from the current research efforts are discussed in terms of
upcoming next-generation observing and high performance computing facilities.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:01 GMT""}]","2020-12-01"
"2011.13941","Alejo Rossia","Fady Bishara, Stefania De Curtis, Luigi Delle Rose, Philipp Englert,
  Christophe Grojean, Marc Montull, Giuliano Panico, Alejo N. Rossia","Precision from the diphoton Zh channel at FCC-hh","32 pages, 6 figures, 9 tables. v2: a few small clarifications added,
  results and discussion unchanged, matches version published in JHEP","J. High Energ. Phys. 2021, 154 (2021)","10.1007/JHEP04(2021)154","DESY 20-200, HU-EP-20/35, ZU-TH-43/20, PSI-PR-20-20","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The future 100 TeV FCC-hh hadron collider will give access to rare but clean
final states which are out of reach of the HL-LHC. One such process is the $Zh$
production channel in the $(\nu\bar{\nu} / \ell^{+}\ell^{-})\gamma\gamma$ final
states. We study the sensitivity of this channel to the $\mathcal{O}_{\varphi
q}^{(1)}$, $\mathcal{O}_{\varphi q}^{(3)}$, $\mathcal{O}_{\varphi u}$, and
$\mathcal{O}_{\varphi d}$ SMEFT operators, which parametrize deviations of the
$W$ and $Z$ couplings to quarks, or, equivalently, anomalous trilinear gauge
couplings (aTGC). While our analysis shows that good sensitivity is only
achievable for $\mathcal{O}_{\varphi q}^{(3)}$, we demonstrate that binning in
the $Zh$ rapidity has the potential to improve the reach on
$\mathcal{O}_{\varphi q}^{(1)}$. Our estimated bounds are one order of
magnitude better than projections at HL-LHC and is better than global fits at
future lepton colliders. The sensitivity to $\mathcal{O}_{\varphi q}^{(3)}$ is
competitive with other channels that could probe the same operator at FCC-hh.
Therefore, combining the different diboson channels sizeably improves the bound
on $\mathcal{O}_{\varphi q}^{(3)}$, reaching a precision of $|\delta g_{1z}|
\lesssim 2 \times 10^{-4}$ on the deviations in the $ZWW$ interactions.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 11:02:18 GMT""}]","2021-06-30"
"2011.13942","Francesca Fragkoudi F","Francesca Fragkoudi, Robert J. J. Grand, Ruediger Pakmor, Volker
  Springel, Simon D. M. White, Federico Marinacci, Facundo A. Gomez, Julio F.
  Navarro","Revisiting the tension between fast bars and the $\Lambda$CDM paradigm","5 pages + 4 pages of appendices; 7 figures; Accepted for publication
  in A&A Letters",,"10.1051/0004-6361/202140320",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The pattern speed with which galactic bars rotate is intimately linked to the
amount of dark matter in the inner regions of their host galaxies. In
particular, dark matter haloes act to slow down bars via torques exerted
through dynamical friction. Observational studies of barred galaxies tend to
find that bars rotate fast, while hydrodynamical cosmological simulations of
galaxy formation and evolution in the $\Lambda$CDM framework have previously
found that bars slow down excessively. This has led to a growing tension
between fast bars and the $\Lambda$CDM cosmological paradigm. In this study we
revisit this issue, using the Auriga suite of high resolution,
magneto-hydrodynamical cosmological zoom-in simulations of galaxy formation and
evolution in the $\Lambda$CDM framework, finding that bars remain fast down to
$z=0$. In Auriga, bars form in galaxies that have higher stellar-to-dark matter
ratios and are more baryon-dominated than in previous cosmological simulations;
this suggests that in order for bars to remain fast, massive spiral galaxies
must lie above the commonly used abundance matching relation. While this
reduces the aforementioned tension between the rotation speed of bars and
$\Lambda$CDM, it accentuates the recently reported discrepancy between the
dynamically inferred stellar-to-dark matter ratios of massive spirals and those
inferred from abundance matching. Our results highlight the potential of using
bar dynamics to constrain models of galaxy formation and evolution.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:02 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 13:45:01 GMT""},{""version"":""v3"",""created"":""Tue, 25 May 2021 14:35:42 GMT""}]","2021-06-30"
"2011.13943","David Nidever","David L. Nidever, Knut Olsen, Yumi Choi, Tomas Ruiz-Lara, Amy E.
  Miller, L. Clifton Johnson, Cameron P. M. Bell, Robert D. Blum, Maria-Rosa L.
  Cioni, Carme Gallart, Steven R. Majewski, Nicolas F. Martin, Pol Massana,
  Antonela Monachesi, Noelia E. D. Noel, Joanna D. Sakowska, Roeland P. van der
  Marel, Alistair R. Walker, Dennis Zaritsky, Eric F. Bell, Blair C. Conn,
  Thomas J. L. de Boer, Robert A. Gruendl, Matteo Monelli, Ricardo R. Munoz,
  Abhijit Saha, A. Katherina Vivas, Edouard Bernard, Gurtina Besla, Julio A.
  Carballo-Bello, Antonio Dorta, David Martinez-Delgado, Alex Goater, Vadim
  Rusakov, and Guy S. Stringfellow","The Second Data Release of the Survey of the MAgellanic Stellar History
  (SMASH)","18 pages, 9 figures. Accepted for publication in The Astronomical
  Journal",,"10.3847/1538-3881/abceb7",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Large and Small Magellanic Clouds (LMC and SMC) are the largest satellite
galaxies of the Milky Way and close enough to allow for a detailed exploration
of their structure and formation history. The Survey of the MAgellanic Stellar
History (SMASH) is a community Dark Energy Camera (DECam) survey of the
Magellanic Clouds using $\sim$50 nights to sample over $\sim$2400 deg$^2$
centered on the Clouds at $\sim$20% filling factor (but with contiguous
coverage in the central regions) and to depths of $\sim$24th mag in $ugriz$.
The primary goals of SMASH are to map out the extended stellar peripheries of
the Clouds and uncover their complicated interaction and accretion history as
well as to derive spatially-resolved star formation histories of the central
regions and create a ""movie"" of their past star formation. Here we announce the
second SMASH public data release (DR2), which contains all 197 fully-calibrated
DECam fields including the main body fields in the central regions. The DR2
data are available through the Astro Data Lab hosted by the NSF's National
Optical-Infrared Astronomy Research Laboratory. We highlight three science
cases that make use of the SMASH DR2 data and will be published in the future:
(1) preliminary star formation histories of the LMC; (2) the search for
Magellanic star clusters using citizen scientists; and, (3) photometric
metallicities of Magellanic Cloud stars using the DECam $u$-band.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:02 GMT""}]","2021-01-27"
"2011.13944","Nora L. Eisner Miss","Nora L. Eisner, Oscar Barrag\'an, Chris Lintott, Suzanne Aigrain,
  Belinda Nicholson, Tabetha S. Boyajian, Steve B. Howell, Cole Johnston, Ben
  Lakeland, Grant Miller, Adam McMaster, Hannu Parviainen, Emily J. Safron,
  Megan E. Schwamb, Laura Trouille, Sophia Vaughan, Norbert Zicher, Campbell
  Allen, Sarah Allen, Mark Bouslog, Cliff Johnson, Molly N. Simon, Zach
  Wolfenbarger, Elisabeth M. L. Baeten, David M. Bundy and Tony Hoffman","Planet Hunters TESS II: Findings from the first two years of TESS","Accepted for publication in MNRAS (22 pages, 12 figures, 3 tables)",,"10.1093/mnras/staa3739",,"astro-ph.EP astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the results from the first two years of the Planet Hunters TESS
citizen science project, which identifies planet candidates in the TESS data by
engaging members of the general public. Over 22,000 citizen scientists from
around the world visually inspected the first 26 Sectors of TESS data in order
to help identify transit-like signals. We use a clustering algorithm to combine
these classifications into a ranked list of events for each sector, the top 500
of which are then visually vetted by the science team. We assess the detection
efficiency of this methodology by comparing our results to the list of TESS
Objects of Interest (TOIs) and show that we recover 85 % of the TOIs with radii
greater than 4 Earth radii and 51 % of those with radii between 3 and 4 Earth
radii. Additionally, we present our 90 most promising planet candidates that
had not previously been identified by other teams, 73 of which exhibit only a
single transit event in the TESS light curve, and outline our efforts to follow
these candidates up using ground-based observatories. Finally, we present
noteworthy stellar systems that were identified through the Planet Hunters TESS
project.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:02 GMT""}]","2020-12-16"
"2011.13945","Ayan Paul","Christophe Grojean, Ayan Paul, and Zhuoni Qian","Resurrecting $b\bar{b}h$ with kinematic shapes","32 pages, 9 figures and 6 tables, published version",,,"DESY 20-175, HU-EP-20/28","hep-ph hep-ex physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The associated production of a $b\bar{b}$ pair with a Higgs boson could
provide an important probe to both the size and the phase of the bottom-quark
Yukawa coupling, $y_b$. However, the signal is shrouded by several background
processes including the irreducible $Zh, Z\to b\bar{b}$ background. We show
that the analysis of kinematic shapes provides us with a concrete prescription
for separating the $y_b$-sensitive production modes from both the irreducible
and the QCD-QED backgrounds using the $b\bar{b}\gamma\gamma$ final state. We
draw a page from game theory and use Shapley values to make Boosted Decision
Trees interpretable in terms of kinematic measurables and provide physics
insights into the variances in the kinematic shapes of the different channels
that help us complete this feat. Adding interpretability to the machine
learning algorithm opens up the black-box and allows us to cherry-pick only
those kinematic variables that matter most in the analysis. We resurrect the
hope of constraining the size and, possibly, the phase of $y_b$ using kinematic
shape studies of $b\bar{b}h$ production with the full HL-LHC data and at
FCC-hh.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 11:33:35 GMT""}]","2021-05-06"
"2011.13946","Lorenzo Tancredi","Fabrizio Caola, Andreas von Manteuffel, Lorenzo Tancredi","Di-photon amplitudes in three-loop Quantum Chromodynamics","10 pages, 2 figures, results in the ancillary files","Phys. Rev. Lett. 126, 112004 (2021)","10.1103/PhysRevLett.126.112004","MSUHEP-20-018, OUTP-20-12P","hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the three-loop scattering amplitudes for the production of a pair
of photons in quark-antiquark annihilation in Quantum Chromodynamics (QCD). We
use suitably defined projectors to efficiently calculate all helicity
amplitudes. We obtain relatively compact analytic results, that we write in
terms of harmonic polylogarithms or, alternatively, multiple polylogarithms of
up to depth three. This is the first calculation of a three-loop four-point
scattering amplitude in full QCD.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:03 GMT""}]","2021-03-24"
"2011.13947","Joseph Whittingham","Joseph Whittingham, Martin Sparre, Christoph Pfrommer, R\""udiger
  Pakmor","The impact of magnetic fields on cosmological galaxy mergers. I:
  Reshaping gas and stellar discs","27 pages, 18 figures. Published in MNRAS on 19 May 2021",,"10.1093/mnras/stab1425",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Mergers play an important role in galaxy evolution. In particular, major
mergers are able to have a transformative effect on galaxy morphology. In this
paper, we investigate the role of magnetic fields in gas-rich major mergers. To
this end, we run a series of high-resolution magnetohydrodynamic (MHD) zoom-in
simulations with the moving-mesh code Arepo and compare the outcome with
hydrodynamic simulations run from the same initial conditions. This is the
first time that the effect of magnetic fields in major mergers has been
investigated in a cosmologically-consistent manner. In contrast to previous
non-cosmological simulations, we find that the inclusion of magnetic fields has
a substantial impact on the production of the merger remnant. Whilst magnetic
fields do not strongly affect global properties, such as the star formation
history, they are able to significantly influence structural properties.
Indeed, MHD simulations consistently form remnants with extended discs and
well-developed spiral structure, whilst hydrodynamic simulations form more
compact remnants that display distinctive ring morphology. We support this work
with a resolution study and show that whilst global properties are broadly
converged across resolution and physics models, morphological differences only
develop given sufficient resolution. We argue that this is due to the more
efficient excitement of a small-scale dynamo in higher resolution simulations,
resulting in a more strongly amplified field that is better able to influence
gas dynamics.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:03 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 11:00:37 GMT""}]","2022-03-22"
"2011.13948","Lea Santos","Mohamad Niknam, Lea F. Santos, David G. Cory","Experimental Detection of the Correlation R\'enyi Entropy in the Central
  Spin Model","6 pages, 4 figures","Phys. Rev. Lett. 127, 080401 (2021)","10.1103/PhysRevLett.127.080401",,"quant-ph cond-mat.stat-mech hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose and experimentally measure an entropy that quantifies the volume
of correlations among qubits. The experiment is carried out on a nearly
isolated quantum system composed of a central spin coupled and initially
uncorrelated with 15 other spins. Due to the spin-spin interactions,
information flows from the central spin to the surrounding ones forming
clusters of multi-spin correlations that grow in time. We design a nuclear
magnetic resonance experiment that directly measures the amplitudes of the
multi-spin correlations and use them to compute the evolution of what we call
correlation R\'enyi entropy. This entropy keeps growing even after the
equilibration of the entanglement entropy. We also analyze how the saturation
point and the timescale for the equilibration of the correlation R\'enyi
entropy depend on the system size.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:03 GMT""}]","2021-08-25"
"2011.13949","Noam Levi","Nathaniel Craig, Noam Levi, Alberto Mariotti, Diego Redigolo","Ripples in Spacetime from Broken Supersymmetry","66 pages latex, fifteen figures incorporated","J. High Energ. Phys. 2021, 184 (2021)","10.1007/JHEP02(2021)184",,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We initiate the study of gravitational wave (GW) signals from first-order
phase transitions in supersymmetry-breaking hidden sectors. Such phase
transitions often occur along a pseudo-flat direction universally related to
supersymmetry (SUSY) breaking in hidden sectors that spontaneously break
$R$-symmetry. The potential along this pseudo-flat direction imbues the phase
transition with a number of novel properties, including a nucleation
temperature well below the scale of heavy states (such that the temperature
dependence is captured by the low-temperature expansion) and significant
friction induced by the same heavy states as they pass through bubble walls. In
low-energy SUSY-breaking hidden sectors, the frequency of the GW signal arising
from such a phase transition is guaranteed to lie within the reach of future
interferometers given existing cosmological constraints on the gravitino
abundance. Once a mediation scheme is specified, the frequency of the GW peak
correlates with the superpartner spectrum. Current bounds on supersymmetry are
compatible with GW signals at future interferometers, while the observation of
a GW signal from a SUSY-breaking hidden sector would imply superpartners within
reach of future colliders.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:04 GMT""}]","2021-03-02"
"2011.13950","Barak Katzir","Barak A. Katzir, Ady Stern, Erez Berg and Netanel H. Lindner","Superconducting fractional quantum Hall edges via repulsive interactions","24 pages, 12 figures",,,,"cond-mat.mes-hall cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study proximity coupling between a superconductor and counter-propagating
gapless modes arising on the edges of Abelian fractional quantum Hall liquids
with filling fraction $\nu=1/m$ (with $m$ an odd integer). This setup can be
utilized to create non-Abelian parafermion zero-modes if the coupling to the
superconductor opens an energy gap in the counter-propagating modes. However,
when the coupling to the superconductor is weak an energy gap is opened only in
the presence of sufficiently strong attractive interactions between the edge
modes, which do not commonly occur in solid state experimental realizations. We
therefore investigate the possibility of obtaining a gapped phase by increasing
the strength of the proximity coupling to the superconductor. To this end, we
use an effective wire construction model for the quantum Hall liquid and employ
renormalization group methods to obtain the phase diagram of the system.
Surprisingly, at strong proximity coupling we find a gapped phase which is
stabilized for sufficiently strong repulsive interactions in the bulk of the
quantum Hall fluids. We furthermore identify a duality transformation that maps
between the weak coupling and strong coupling regimes, and use it to show that
the gapped phases in both regimes are continuously connected through an
intermediate proximity coupling regime.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:04 GMT""}]","2020-12-01"
"2011.13951","Benjamin Miller","Benjamin Kurt Miller, Alex Cole, Gilles Louppe, Christoph Weniger","Simulation-efficient marginal posterior estimation with swyft: stop
  wasting your precious time","Accepted at Machine Learning and the Physical Sciences at NeurIPS
  2020. Package: https://github.com/undark-lab/swyft/",,,,"astro-ph.IM astro-ph.CO cs.LG hep-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present algorithms (a) for nested neural likelihood-to-evidence ratio
estimation, and (b) for simulation reuse via an inhomogeneous Poisson point
process cache of parameters and corresponding simulations. Together, these
algorithms enable automatic and extremely simulator efficient estimation of
marginal and joint posteriors. The algorithms are applicable to a wide range of
physics and astronomy problems and typically offer an order of magnitude better
simulator efficiency than traditional likelihood-based sampling methods. Our
approach is an example of likelihood-free inference, thus it is also applicable
to simulators which do not offer a tractable likelihood function. Simulator
runs are never rejected and can be automatically reused in future analysis. As
functional prototype implementation we provide the open-source software package
swyft.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:07 GMT""}]","2020-12-01"
"2011.13952","Yael Raveh","Yael Raveh and Hagai B. Perets","Extreme mass-ratio gravitational-wave sources: Mass segregation and post
  binary tidal-disruption captures","9 pages, 6 figures. Accepted for publication in MNRAS",,"10.1093/mnras/staa4001",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The gravitational-wave (GW) inspirals of stellar-mass compact objects onto a
supermassive black hole (MBH), are some of the most promising GW sources
detectable by next-generation space-born GW-detectors. The rates and
characteristics of such extreme mass ratio inspirals (EMRIs) sources are highly
uncertain. They are determined by the dynamics of stars near MBHs, and the rate
at which compacts objects are driven to the close proximity of the MBH. Here we
consider weakly and strongly mass-segregated nuclear clusters, and the
evolution of stars captured into highly eccentric orbits following binary
disruptions by the MBH. We make use of a Monte-Carlo approach to model the
diffusion of both captured objects, and compact-objects brought through
two-body relaxation processes. We calculate the rates of GW-inspirals resulting
from relaxation-driven objects, and characterize EMRIs properties. We correct
previous studies and show that relaxation-driven sources produce GW-sources
with lower-eccentricity than previously found, and provide the detailed EMRI
eccentricity distribution in the weak and strong mass-segregation regimes. We
also show that binary-disruption captured-stars could introduce
low-eccentricity GW-sources of stellar black-hole EMRIs in mass-segregated
clusters. The eccentricities of the GW-sources from the capture channel,
however, are strongly affected by relaxation processes, and are significantly
higher than previously suggested. We find that both the rate and eccentricity
distribution of EMRIs could probe the dynamics near MBHs, and the contribution
of captured stars, characterize the mass-function of stellar compact objects,
and verify whether weak or strong mass-segregation processes take place near
MBHs.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:07 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jan 2021 14:04:32 GMT""}]","2021-01-05"
"2011.13953","Mikel A. Urkiola","Jose J. Blanco-Pillado, Kepa Sousa, Mikel A. Urkiola, Jeremy M.
  Wachter","Universal Class of Type-IIB Flux Vacua with Analytic Mass Spectrum","10 pages, 5 figures; v2: fixed typos, added references; v3: fixed
  typos, added appendix on estimate of the number of vacua","Phys. Rev. D 103, 106006 (2021)","10.1103/PhysRevD.103.106006",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on a new class of flux vacua generically present in Calabi-Yau
compactifications of type-IIB string theory. At these vacua, the mass spectrum
of the complete axio-dilaton/complex structure sector is given, to leading
order in $\alpha'$ and $g_s$, by a simple analytic formula independent of the
choice of Calabi-Yau. We provide a method to find these vacua, and construct an
ensemble of $17,054$ solutions for the Calabi-Yau hypersurface
$\mathbb{WP}_{[1,1,1,6,9]}^4$, where the masses of the axio-dilaton and the
$272$ complex structure fields can be explicitly computed.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:43 GMT""},{""version"":""v2"",""created"":""Tue, 22 Dec 2020 14:28:16 GMT""},{""version"":""v3"",""created"":""Wed, 28 Apr 2021 18:24:39 GMT""}]","2021-05-12"
"2011.13954","Chenxing Li","Chenxing Li, Yang Yu, Andrew Chi-Chih Yao, Da Zhang, Xiliang Zhang","An authenticated and secure accounting system for international
  emissions trading",,,,,"econ.GN cs.CR q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Expanding multi-country emissions trading system is considered as crucial to
fill the existing mitigation gap for the 2\degree C climate target. Trustworthy
emissions accounting is the cornerstone of such a system encompassing different
jurisdictions. However, traditional emissions measuring, reporting, and
verification practices that support data authenticity might not be applicable
as detailed data from large utilities and production facilities to be covered
in the multi-country emissions trading system are usually highly sensitive and
of severe national security concern. In this study, we propose a cryptographic
framework for an authenticated and secure emissions accounting system that can
resolve this data dilemma. We demonstrate that integrating a sequence of
cryptographic protocols can preserve data authenticity and security for a
stylized multi-country emissions trading system. We call for more research to
promote applications of modern cryptography in future international climate
governance to build trust and strengthen collaboration.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:44 GMT""}]","2020-12-01"
"2011.13955","Justin Feng","Sumanta Chakraborty and Justin C. Feng","Perturbations of the almost Killing equation and their implications","21 pages. Matches published version","Phys. Rev. D 103, 084020 (2021)","10.1103/PhysRevD.103.084020","Phys. Rev. D 103, 084020","gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Killing vectors play a crucial role in characterizing the symmetries of a
given spacetime. However, realistic astrophysical systems are in most cases
only approximately symmetric. Even in the case of an astrophysical black hole,
one might expect Killing symmetries to exist only in an approximate sense due
to perturbations from external matter fields. In this work, we consider the
generalized notion of Killing vectors provided by the almost Killing equation,
and study the perturbations induced by a perturbation of a background spacetime
satisfying exact Killing symmetry. To first order, we demonstrate that for
nonradiative metric perturbations (that is, metric perturbations with
nonvanishing trace) of symmetric vacuum spacetimes, the perturbed almost
Killing equation avoids the problem of an unbounded Hamiltonian for hyperbolic
parameter choices. For traceless metric perturbations, we obtain similar
results for the second-order perturbation of the almost Killing equation, with
some additional caveats. Thermodynamical implications are also explored.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:02:16 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 15:03:33 GMT""}]","2021-04-21"
"2011.13956","Ralph Blumenhagen","Ralph Blumenhagen, Christian Kneissl, Andriana Makridou","De Sitter Quantum Breaking, Swampland Conjectures and Thermal Strings","60 pages, 12 figures, v2: major revision of section 2, final version
  to appear in JHEP",,"10.1007/JHEP10(2021)157","MPP-2020-213","hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  We argue that under certain assumptions the quantum break time approach and
the trans-Planckian censorship conjecture both lead to de Sitter swampland
constraints of the same functional form. It is a well known fact that the
quantum energy-momentum tensor in the Bunch-Davies vacuum computed in the
static patch of dS breaks some of the isometries. Proposing that this is a
manifestation of quantum breaking of dS, we analyze some of its consequences.
In particular, this leads to a thermal matter component that can be generalized
to string theory in an obvious way. Imposing a censorship of quantum breaking,
we recover the no eternal inflation bound in the low temperature regime, while
the stronger bound from the dS swampland conjecture follows under a few
reasonable assumptions about the still mysterious, presumably topological,
high-temperature regime of string theory.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:02:49 GMT""},{""version"":""v2"",""created"":""Mon, 4 Oct 2021 08:52:51 GMT""}]","2021-11-10"
"2011.13957","Abolhassan Mohammadi","Abolhassan Mohammadi, Tayeb Golanbari, Jamil Enayati, Shahram
  Jalalzadeh, Khaled Saaidi","Revisiting Scalar Tensor inflation by swampland criteria and Reheating","28 pages, 14 figures",,,,"gr-qc","http://creativecommons.org/publicdomain/zero/1.0/","  The scenario of the slow-roll inflation is studied in the frame of the
scalar-tensor theory of gravity where the scalar field has a non-minimal
coupling to the geometric part. After deriving the main dynamical and
perturbation equations, the model is investigated in detail for different
functions of the potential and the coupling function. Considering the
consistency of the model with observational model results into specific ranges
for the free constants of the model. Then, the obtained ranges are reconsidered
to realize whether they satisfy the swampland criteria. It is found that the
swampland criteria impose another limitation and reduce the ranges. Using the
final outcomes for the free constants of the model, we briefly consider the
reheating phase to find out about the number of e-fold for the phase and the
reheating temperature.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:02:55 GMT""}]","2020-12-01"
"2011.13958","Christoph Sch\""onle","C. Sch\""onle, D. Jansen, F. Heidrich-Meisner, L. Vidmar","Eigenstate thermalization hypothesis through the lens of autocorrelation
  functions","v3: Data shown in figures now available as ancillary files","Phys. Rev. B 103, 235137 (2021)","10.1103/PhysRevB.103.235137",,"cond-mat.stat-mech cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Matrix elements of observables in eigenstates of generic Hamiltonians are
described by the Srednicki ansatz within the eigenstate thermalization
hypothesis (ETH). We study a quantum chaotic spin-fermion model in a
one-dimensional lattice, which consists of a spin-1/2 XX chain coupled to a
single itinerant fermion. In our study, we focus on translationally invariant
observables including the charge and energy current, thereby also connecting
the ETH with transport properties. Considering observables with a
Hilbert-Schmidt norm of one, we first perform a comprehensive analysis of ETH
in the model taking into account latest developments. A particular emphasis is
on the analysis of the structure of the offdiagonal matrix elements $|\langle
\alpha | \hat O | \beta \rangle|^2$ in the limit of small eigenstate energy
differences $\omega = E_\beta - E_\alpha$. Removing the dominant exponential
suppression of $|\langle \alpha | \hat O | \beta \rangle|^2$, we find that: (i)
the current matrix elements exhibit a system-size dependence that is different
from other observables under investigation, (ii) matrix elements of several
other observables exhibit a Drude-like structure with a Lorentzian frequency
dependence. We then show how this information can be extracted from the
autocorrelation functions as well. Finally, our study is complemented by a
numerical analysis of the fluctuation-dissipation relation for eigenstates in
the bulk of the spectrum. We identify the regime of $\omega$ in which the
well-known fluctuation-dissipation relation is valid with high accuracy for
finite systems.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:05:32 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 14:55:55 GMT""},{""version"":""v3"",""created"":""Sat, 25 Sep 2021 10:47:54 GMT""}]","2021-09-28"
"2011.13959","Shihao Song","Shihao Song and Anup Das","Design Methodologies for Reliable and Energy-efficient PCM Systems",,,,,"cs.AR","http://creativecommons.org/licenses/by/4.0/","  Phase-change memory (PCM) is a scalable and low latency non-volatile memory
(NVM) technology that has been proposed to serve as storage class memory (SCM),
providing low access latency similar to DRAM and often approaching or exceeding
the capacity of SSD. The multilevel property of PCM also enables its adoption
in neuromorphic systems to build high-density synaptic storage. We investigate
and describe two significant bottlenecks of a PCM system. First, writing to PCM
cells incurs significantly higher latency and energy penalties than reading its
content. Second, high operating voltages of PCM impacts its reliable
operations. In this work, we propose methodologies to tackle the bottlenecks,
improving performance, reliability, energy consumption, and sustainability for
a PCM system.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:05:49 GMT""}]","2020-12-01"
"2011.13960","Abhinandan Dalal","Navonil Deb, Abhinandan Dalal and Gopal Krishna Basak","Finding Optimal Cancer Treatment using Markov Decision Process to
  Improve Overall Health and Quality of Life",,,,,"stat.AP econ.GN q-bio.QM q-fin.EC stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Markov Decision Processes and Dynamic Treatment Regimes have grown
increasingly popular in the treatment of diseases, including cancer. However,
cancer treatment often impacts quality of life drastically, and people often
fail to take treatments that are sustainable, affordable and can be adhered to.
In this paper, we emphasize the usage of ambient factors like profession,
radioactive exposure, food habits on the treatment choice, keeping in mind that
the aim is not just to relieve the patient of his disease, but rather to
maximize his overall physical, social and mental well being. We delineate a
general framework which can directly incorporate a net benefit function from a
physician as well as patient's utility, and can incorporate the varying
probabilities of exposure and survival of patients of varying medical profiles.
We also show by simulations that the optimal choice of actions often is
sensitive to extraneous factors, like the financial status of a person (as a
proxy for the affordability of treatment), and that these actions should be
welcome keeping in mind the overall quality of life.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:06:04 GMT""}]","2020-12-01"
"2011.13961","Albert Pumarola","Albert Pumarola, Enric Corona, Gerard Pons-Moll, Francesc
  Moreno-Noguer","D-NeRF: Neural Radiance Fields for Dynamic Scenes",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural rendering techniques combining machine learning with geometric
reasoning have arisen as one of the most promising approaches for synthesizing
novel views of a scene from a sparse set of images. Among these, stands out the
Neural radiance fields (NeRF), which trains a deep network to map 5D input
coordinates (representing spatial location and viewing direction) into a volume
density and view-dependent emitted radiance. However, despite achieving an
unprecedented level of photorealism on the generated images, NeRF is only
applicable to static scenes, where the same spatial location can be queried
from different images. In this paper we introduce D-NeRF, a method that extends
neural radiance fields to a dynamic domain, allowing to reconstruct and render
novel images of objects under rigid and non-rigid motions from a \emph{single}
camera moving around the scene. For this purpose we consider time as an
additional input to the system, and split the learning process in two main
stages: one that encodes the scene into a canonical space and another that maps
this canonical representation into the deformed scene at a particular time.
Both mappings are simultaneously learned using fully-connected networks. Once
the networks are trained, D-NeRF can render novel images, controlling both the
camera view and the time variable, and thus, the object movement. We
demonstrate the effectiveness of our approach on scenes with objects under
rigid, articulated and non-rigid motions. Code, model weights and the dynamic
scenes dataset will be released.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:06:50 GMT""}]","2020-12-01"
"2011.13962","Michael Lieberman","Michael Lieberman, Jiri Rosicky, Sebastien Vasey","Induced and higher-dimensional stable independence",,,,,"math.LO math.CT","http://creativecommons.org/licenses/by/4.0/","  We provide several crucial technical extensions of the theory of stable
independence notions in accessible categories. In particular, we describe
circumstances under which a stable independence notion can be transferred from
a subcategory to a category as a whole, and examine a number of applications to
categories of groups and modules, extending results of [MAa]. We prove, too,
that under the hypotheses of [LRV], a stable independence notion immediately
yields higher-dimensional independence as in [SV].
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:07:47 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jan 2021 17:59:17 GMT""},{""version"":""v3"",""created"":""Sat, 5 Jun 2021 20:40:37 GMT""},{""version"":""v4"",""created"":""Thu, 20 Jan 2022 15:55:16 GMT""},{""version"":""v5"",""created"":""Wed, 6 Apr 2022 20:53:33 GMT""},{""version"":""v6"",""created"":""Sun, 28 Aug 2022 12:38:34 GMT""},{""version"":""v7"",""created"":""Tue, 30 Aug 2022 08:03:58 GMT""}]","2022-08-31"
"2011.13963","Tobias M. Schmidt","Tobias M. Schmidt, Paolo Molaro, Michael T. Murphy, Christophe Lovis,
  Guido Cupani, Stefano Cristiani, Francesco A. Pepe, Rafael Rebolo, Nuno C.
  Santos, Manuel Abreu, Vardan Adibekyan, Yann Alibert, Matteo Aliverti, Romain
  Allart, Carlos Allende Prieto, David Alves, Veronica Baldini, Christopher
  Broeg, Alexandre Cabral, Giorgio Calderone, Roberto Cirami, Jo\~ao Coelho,
  Igor Coretti, Valentina D'Odorico, Paolo Di Marcantonio, David Ehrenreich,
  Pedro Figueira, Matteo Genoni, Ricardo G\'enova Santos, Jonay I. Gonz\'alez
  Hern\'andez, Florian Kerber, Marco Landoni, Ana C. O. Leite, Jean-Louis
  Lizon, Gaspare Lo Curto, Antonio Manescau, Carlos J.A.P. Martins, Denis
  Meg\'evand, Andrea Mehner, Giuseppina Micela, Andrea Modigliani, Manuel
  Monteiro, Mario J. P. F. G. Monteiro, Eric Mueller, Nelson J. Nunes, Luca
  Oggioni, Ant\'onio Oliveira, Giorgio Pariani, Luca Pasquini, Edoardo
  Redaelli, Marco Riva, Pedro Santos, Danuta Sosnowska, S\'ergio G. Sousa,
  Alessandro Sozzetti, Alejandro Su\'arez Mascare\~no, St\'ephane Udry,
  Maria-Rosa Zapatero Osorio, Filippo Zerbi","Fundamental physics with Espresso: Towards an accurate wavelength
  calibration for a precision test of the fine-structure constant","27 pages, accepted for publication in A&A","A&A 646, A144 (2021)","10.1051/0004-6361/202039345",,"astro-ph.IM astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observations of metal absorption systems in the spectra of distant quasars
allow to constrain a possible variation of the fine-structure constant
throughout the history of the Universe. Such a test poses utmost demands on the
wavelength accuracy and previous studies were limited by systematics in the
spectrograph wavelength calibration. A substantial advance in the field is
therefore expected from the new ultra-stable high-resolution spectrograph
Espresso, recently installed at the VLT. In preparation of the fundamental
physics related part of the Espresso GTO program, we present a thorough
assessment of the Espresso wavelength accuracy and identify possible
systematics at each of the different steps involved in the wavelength
calibration process. Most importantly, we compare the default wavelength
solution, based on the combination of Thorium-Argon arc lamp spectra and a
Fabry-P\'erot interferometer, to the fully independent calibration obtained
from a laser frequency comb. We find wavelength-dependent discrepancies of up
to 24m/s. This substantially exceeds the photon noise and highlights the
presence of different sources of systematics, which we characterize in detail
as part of this study. Nevertheless, our study demonstrates the outstanding
accuracy of Espresso with respect to previously used spectrographs and we show
that constraints of a relative change of the fine-structure constant at the
$10^{-6}$ level can be obtained with Espresso without being limited by
wavelength calibration systematics.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:09:05 GMT""}]","2021-02-24"
"2011.13964","Kristian Ehlert","Kristian Ehlert (1), Rainer Weinberger (2), Christoph Pfrommer (1),
  Volker Springel (3) ((1) Leibniz Institute for Astrophysics Potsdam, (2)
  Center for Astrophysics | Harvard & Smithsonian, (3) Max-Planck-Institut
  f\""ur Astrophysik)","Connecting turbulent velocities and magnetic fields in galaxy cluster
  simulations with active galactic nuclei jets","19 pages, 9 figures, submitted to MNRS. Comments welcome!",,"10.1093/mnras/stab551",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of velocity fields of the hot gas in galaxy clusters can help to
unravel details of microphysics on small-scales and to decipher the nature of
feedback by active galactic nuclei (AGN). Likewise, magnetic fields as traced
by Faraday rotation measurements (RMs) inform about their impact on gas
dynamics as well as on cosmic ray production and transport. We investigate the
inherent relationship between large-scale gas kinematics and magnetic fields
through non-radiative magnetohydrodynamical simulations of the creation,
evolution and disruption of AGN jet-inflated lobes in an isolated Perseus-like
galaxy cluster, with and without pre-existing turbulence. In particular, we
connect cluster velocity measurements with mock RM maps to highlight their
underlying physical connection, which opens up the possibility of comparing
turbulence levels in two different observables. For single jet outbursts, we
find only a local impact on the velocity field, i.e. the associated increase in
velocity dispersion is not volume-filling. Furthermore, in a setup with
pre-existing turbulence, this increase in velocity dispersion is largely
hidden. We use mock X-ray observations to show that at arcmin resolution, the
velocity dispersion is therefore dominated by existing large-scale turbulence
and is only minimally altered by the presence of a jet. For the velocity
structure of central gas uplifted by buoyantly rising lobes, we find fast,
coherent outflows with low velocity dispersion. Our results highlight that
projected velocity distributions show complex structures which pose challenges
for the interpretation of observations.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:09:09 GMT""}]","2021-03-10"
"2011.13965","Adarsha Balaji","Adarsha Balaji and Anup Das","Compiling Spiking Neural Networks to Mitigate Neuromorphic Hardware
  Constraints",,,,,"cs.NE cs.AR","http://creativecommons.org/licenses/by/4.0/","  Spiking Neural Networks (SNNs) are efficient computation models to perform
spatio-temporal pattern recognition on {resource}- and {power}-constrained
platforms. SNNs executed on neuromorphic hardware can further reduce energy
consumption of these platforms. With increasing model size and complexity,
mapping SNN-based applications to tile-based neuromorphic hardware is becoming
increasingly challenging. This is attributed to the limitations of
neuro-synaptic cores, viz. a crossbar, to accommodate only a fixed number of
pre-synaptic connections per post-synaptic neuron. For complex SNN-based models
that have many neurons and pre-synaptic connections per neuron, (1) connections
may need to be pruned after training to fit onto the crossbar resources,
leading to a loss in model quality, e.g., accuracy, and (2) the neurons and
synapses need to be partitioned and placed on the neuro-sypatic cores of the
hardware, which could lead to increased latency and energy consumption. In this
work, we propose (1) a novel unrolling technique that decomposes a neuron
function with many pre-synaptic connections into a sequence of homogeneous
neural units to significantly improve the crossbar utilization and retain all
pre-synaptic connections, and (2) SpiNeMap, a novel methodology to map SNNs on
neuromorphic hardware with an aim to minimize energy consumption and spike
latency.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:10:23 GMT""}]","2020-12-01"
"2011.13966","Benjamin Criton Mr","Benjamin Criton, Georgios Nicolaou and Daniel Verscharen","Design and Optimization of a High-Time-Resolution Magnetic Plasma
  Analyzer (MPA)",,"Appl. Sci. 2020, 10(23), 8483","10.3390/app10238483",,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  In-situ measurements of space plasma throughout the solar system require high
time resolution to understand the plasma's kinetic fine structure and
evolution. In this context, research~is conducted to design instruments with
the capability to acquire the plasma velocity distribution and its moments with
high cadence. We study a new instrument design, using a constant magnetic field
generated by two permanent magnets, to analyze solar wind protons and
$\alpha$-particles with high time resolution. We determine the optimal
configuration of the instrument in terms of aperture size, sensor position,
pixel size and magnetic field strength. We conduct this analysis based on
analytical calculations and SIMION simulations of the particle trajectories in
our instrument. We evaluate the velocity resolution of the instrument as well
as Poisson errors associated with finite counting statistics. Our instrument is
able to resolve Maxwellian and $\kappa$-distributions for both protons and
$\alpha$-particles. This method retrieves measurements of the moments (density,
bulk speed and temperature) with a relative error below 1%. Our instrument
design achieves these results with an acquisition time of only 5 ms,
significantly faster than state-of-the-art electrostatic analyzers. Although
the instrument only acquires one-dimensional cuts of the distribution function
in velocity space, the simplicity and reliability of the presented instrument
concept are two key advantages of our new design.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:11:16 GMT""}]","2020-12-01"
"2011.13967","Zejian Liu","Zejian Liu and Meng Li","Equivalence of Convergence Rates of Posterior Distributions and Bayes
  Estimators for Functions and Nonparametric Functionals",,,,,"math.ST stat.ME stat.ML stat.TH","http://creativecommons.org/licenses/by/4.0/","  We study the posterior contraction rates of a Bayesian method with Gaussian
process priors in nonparametric regression and its plug-in property for
differential operators. For a general class of kernels, we establish
convergence rates of the posterior measure of the regression function and its
derivatives, which are both minimax optimal up to a logarithmic factor for
functions in certain classes. Our calculation shows that the rate-optimal
estimation of the regression function and its derivatives share the same choice
of hyperparameter, indicating that the Bayes procedure remarkably adapts to the
order of derivatives and enjoys a generalized plug-in property that extends
real-valued functionals to function-valued functionals. This leads to a
practically simple method for estimating the regression function and its
derivatives, whose finite sample performance is assessed using simulations.
  Our proof shows that, under certain conditions, to any convergence rate of
Bayes estimators there corresponds the same convergence rate of the posterior
distributions (i.e., posterior contraction rate), and vice versa. This
equivalence holds for a general class of Gaussian processes and covers the
regression function and its derivative functionals, under both the $L_2$ and
$L_{\infty}$ norms. In addition to connecting these two fundamental large
sample properties in Bayesian and non-Bayesian regimes, such equivalence
enables a new routine to establish posterior contraction rates by calculating
convergence rates of nonparametric point estimators.
  At the core of our argument is an operator-theoretic framework for kernel
ridge regression and equivalent kernel techniques. We derive a range of sharp
non-asymptotic bounds that are pivotal in establishing convergence rates of
nonparametric point estimators and the equivalence theory, which may be of
independent interest.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:11:56 GMT""}]","2020-12-01"
"2011.13968","Marina Garrote-L\'opez","Marta Casanellas, Jes\'us Fern\'andez-S\'anchez and Marina
  Garrote-L\'opez","SAQ: semi-algebraic quartet reconstruction method",,,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the phylogenetic quartet reconstruction method SAQ (Semi-algebraic
quartet reconstruction). SAQ is consistent with the most general Markov model
of nucleotide substitution and, in particular, it allows for rate heterogeneity
across lineages. Based on the algebraic and semi-algebraic description of
distributions that arise from the general Markov model on a quartet, the method
outputs normalized weights for the three trivalent quartets (which can be used
as input of quartet-base methods). We show that SAQ is a highly competitive
method that outperforms most of the well known reconstruction methods on data
simulated under the general Markov model on 4-taxon trees. Moreover, it also
achieves a high performance on data that violates the underlying assumptions.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:15:23 GMT""}]","2020-12-01"
"2011.13969","Nicholas Bell","Nick Bell","Counting arcs on hyperbolic surfaces","18 pages, 3 figures. Comments welcome",,,,"math.GT","http://creativecommons.org/licenses/by/4.0/","  We give the asymptotic growth of the number of (multi-)arcs of bounded length
between boundary components on complete finite-area hyperbolic surfaces with
boundary. Specifically, if $S$ has genus $g$, $n$ boundary components and $p$
punctures, then the number of orthogeodesic arcs in each pure mapping class
group orbit of length at most $L$ is asymptotic to $L^{6g-6+2(n+p)}$ times a
constant. We prove an analogous result for arcs between cusps, where we define
the length of such an arc to be the length of the sub-arc obtained by removing
certain cuspidal regions from the surface.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:17:23 GMT""}]","2020-12-01"
"2011.13970","Peter Dankelmann","Peter Dankelmann, Alex Alochukwu","Wiener index in graphs with given minimum degree and maximum degree",,"Discrete Mathematics & Theoretical Computer Science, vol. 23 no.
  1, Graph Theory (June 3, 2021) dmtcs:7533","10.46298/dmtcs.6956",,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $G$ be a connected graph of order $n$.The Wiener index $W(G)$ of $G$ is
the sum of the distances between all unordered pairs of vertices of $G$. In
this paper we show that the well-known upper bound $\big(
\frac{n}{\delta+1}+2\big) {n \choose 2}$ on the Wiener index of a graph of
order $n$ and minimum degree $\delta$ [M. Kouider, P. Winkler, Mean distance
and minimum degree. J. Graph Theory 25 no. 1 (1997)] can be improved
significantly if the graph contains also a vertex of large degree.
Specifically, we give the asymptotically sharp bound $W(G) \leq
{n-\Delta+\delta \choose 2} \frac{n+2\Delta}{\delta+1}+ 2n(n-1)$ on the Wiener
index of a graph $G$ of order $n$, minimum degree $\delta$ and maximum degree
$\Delta$. We prove a similar result for triangle-free graphs, and we determine
a bound on the Wiener index of $C_4$-free graphs of given order, minimum and
maximum degree and show that it is, in some sense, best possible.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:18:43 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 07:34:19 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 21:30:41 GMT""}]","2021-10-04"
"2011.13971","Ozan Ciga","Ozan Ciga, Tony Xu, Anne L. Martel","Self supervised contrastive learning for digital histopathology",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised learning has been a long-standing goal of machine learning and
is especially important for medical image analysis, where the learning can
compensate for the scarcity of labeled datasets. A promising subclass of
unsupervised learning is self-supervised learning, which aims to learn salient
features using the raw input as the learning signal. In this paper, we use a
contrastive self-supervised learning method called SimCLR that achieved
state-of-the-art results on natural-scene images and apply this method to
digital histopathology by collecting and pretraining on 57 histopathology
datasets without any labels. We find that combining multiple multi-organ
datasets with different types of staining and resolution properties improves
the quality of the learned features. Furthermore, we find using more images for
pretraining leads to a better performance in multiple downstream tasks. Linear
classifiers trained on top of the learned features show that networks
pretrained on digital histopathology datasets perform better than ImageNet
pretrained networks, boosting task performances by more than 28% in F1 scores
on average. These findings may also be useful when applying newer contrastive
techniques to histopathology data. Pretrained PyTorch models are made publicly
available at https://github.com/ozanciga/self-supervised-histopathology.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:18:45 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 20:02:12 GMT""}]","2021-09-09"
"2011.13972","Pradeep Kushwaha Mr","Pradeep Kushwaha, Jai Sukhatme, Ravi S. Nanjundiah","A Global Tropical Survey of Mid-Tropospheric Cyclones",,,"10.1175/MWR-D-20-0222.1",,"physics.ao-ph physics.flu-dyn physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mid-Tropospheric Cyclones (MTCs) are moist synoptic systems with distinct mid
tropospheric vorticity maxima and weak signatures in the lower troposphere.
Composites and statistics of MTCs over the tropics are constructed and compared
with monsoon lows and depressions (together, lower troposphere cyclones; LTCs).
We begin with South Asia, where tracking reveals that MTCs change character
during their life, i.e., their track is composed of MTC and LTC phases. The
highest MTC-phase density and least motion is over the Arabian Sea, followed by
the Bay of Bengal and South China Sea. A MTC-phase composite shows an east-west
tilted warm above deep cold-core temperature anomaly with maximum vorticity at
600 hPa. While the LTC-phase shows a shallow cold-core below 800 hPa and a warm
upright temperature anomaly with lower tropospheric vorticity maximum. Apart
from South Asia, systems with similar morphology are observed over the west and
central Africa, east and west Pacific in boreal summer. In boreal winter,
regions that support MTCs include northern Australia, the southern Indian
Ocean, and South Africa. Relatively, the MTC fraction is higher equatorward,
where there is a cross-equatorial low-level jet that advects oppositely signed
vorticity. Whereas the LTCs are more prevalent further poleward. Finally, a
histogram of differential vorticity (difference between middle and lower
levels) versus the height of peak vorticity for cyclonic centers is bimodal.
One peak, around 600 hPa, corresponds to MTCs while the second, around 900 hPa,
comes from LTCs. Thus, moist cyclonic systems in the tropics have a natural
tendency to reside in either the MTC or LTC category preferentially
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:20:36 GMT""}]","2021-08-25"
"2011.13973","Onat Ar{\i}soy","Onat Ar{\i}soy and \""Ozg\""ur E. M\""ustecapl{\i}o\u{g}lu","Few-qubit quantum refrigerator for cooling a multi-qubit system",,,"10.1038/s41598-021-92258-0",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose to use a few-qubit system as a compact quantum refrigerator for
cooling an interacting multi-qubit system. We specifically consider a central
qubit coupled to $N$ ancilla qubits in a so-called spin-star model as our
quantum refrigerator. We first show that if the interaction between the qubits
is of the longitudinal and ferromagnetic Ising model form, the central qubit is
colder than the environment. The colder central qubit is then proposed to be
used as the refrigerant interface of the quantum refrigerator to cool down
general quantum many-qubit systems. We discuss a simple refrigeration cycle,
considering the operation cost and cooling efficiency, which can be controlled
by $N$ and the qubit-qubit interaction strength. Besides, bounds on the
achievable temperature are established. Such few-qubit compact quantum
refrigerators can be significant to reduce dimensions of quantum technology
applications, can be easy to integrate into all-qubit systems, and can increase
the speed and power of quantum computing and thermal devices.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:25:23 GMT""}]","2021-06-23"
"2011.13974","Sidike Paheding","Uzair Khan, Paheding Sidike, Colin Elkin and Vijay Devabhaktuni","Trends in deep learning for medical hyperspectral image analysis",,"in IEEE Access, vol. 9, pp. 79534-79548, 2021","10.1109/ACCESS.2021.3068392",,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning algorithms have seen acute growth of interest in their
applications throughout several fields of interest in the last decade, with
medical hyperspectral imaging being a particularly promising domain. So far, to
the best of our knowledge, there is no review paper that discusses the
implementation of deep learning for medical hyperspectral imaging, which is
what this review paper aims to accomplish by examining publications that
currently utilize deep learning to perform effective analysis of medical
hyperspectral imagery. This paper discusses deep learning concepts that are
relevant and applicable to medical hyperspectral imaging analysis, several of
which have been implemented since the boom in deep learning. This will comprise
of reviewing the use of deep learning for classification, segmentation, and
detection in order to investigate the analysis of medical hyperspectral
imaging. Lastly, we discuss the current and future challenges pertaining to
this discipline and the possible efforts to overcome such trials.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:42:06 GMT""}]","2021-06-10"
"2011.13975","Barbora Volna","Barbora Volna","On definition of Devaney chaos for a continuous group action on a
  Hausdorff uniform space","10 pages, 1 figure",,,,"math.DS math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the existence of a dense set of periodic points for a
topologically transitive non-minimal continuous group action on a Hausdorff
uniform space with an infinite acting group does not necessarily imply a
sensitive dependence to the initial conditions in such a system. This leads to
define the chaos in the sense of Devaney for a continuous group action on a
Hausdorff uniform spaces with an infinite acting group in the original way,
i.e. a non-minimal topologically transitive and sensitive system with a dense
set of periodic points is a chaotic system in the sense of Devaney.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:43:41 GMT""}]","2020-12-01"
"2011.13976","H{\aa}kon R{\o}st","H\r{a}kon I. R{\o}st (1), Rajesh K. Chellappan (1), Frode S. Strand
  (1), Antonija Grubi\v{s}i\'c-\v{C}abo (2), Benjamen P. Reed (3), Mauricio J.
  Prieto (4), Liviu C. T\v{a}nase (4), Lucas de Souza Caldas (4), Thipusa
  Wongpinij (5), Chanan Euaruksakul (5), Thomas Schmidt (4), Anton Tadich (6),
  Bruce C. C. Cowie (6), Zheshen Li (7), Simon P. Cooil (3 and 8) and Justin W.
  Wells (1) ((1) Center for Quantum Spintronics, Department of Physics,
  Norwegian University of Science and Technology (NTNU), Norway, (2) School of
  Physics & Astronomy, Monash University, Australia, (3) Department of Physics,
  Aberystwyth University, United Kingdom, (4) Department of Interface Science,
  Fritz-Haber-Institute of the Max-Planck Society, Germany, (5) Synchrotron
  Light Research Institute, Thailand, (6) Australian Synchrotron, Australia,
  (7) Department of Physics and Astronomy, Aarhus University, Denmark, (8)
  Semiconductor Physics, Department of Physics, University of Oslo (UiO),
  Norway)","Low Temperature Growth of Graphene on Semiconductor","10 pages, 4 figures, 51 references",,"10.1021/acs.jpcc.0c10870",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The industrial realization of graphene has so far been limited by challenges
related to the quality, reproducibility, and high process temperatures required
to manufacture graphene on suitable substrates. We demonstrate that epitaxial
graphene can be grown on transition metal treated 6H-SiC(0001) surfaces, with
an onset of graphitization starting around $450-500^\circ\text{C}$. From the
chemical reaction between SiC and thin films of Fe or Ru, $\text{sp}^{3}$
carbon is liberated from the SiC crystal and converted to $\text{sp}^{2}$
carbon at the surface. The quality of the graphene is demonstrated using
angle-resolved photoemission spectroscopy and low-energy electron diffraction.
Furthermore, the orientation and placement of the graphene layers relative to
the SiC substrate is verified using angle-resolved absorption spectroscopy and
energy-dependent photoelectron spectroscopy, respectively. With subsequent
thermal treatments to higher temperatures, a steerable diffusion of the metal
layers into the bulk SiC is achieved. The result is graphene supported on
magnetic silicide or optionally, directly on semiconductor, at temperatures
ideal for further large-scale processing into graphene based device structures.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:51:34 GMT""}]","2021-03-25"
"2011.13977","Vijay  Menon","Thomas Ma, Vijay Menon, Kate Larson","Improving Welfare in One-sided Matching using Simple Threshold Queries",,,,,"cs.GT cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study one-sided matching problems where $n$ agents have preferences over
$m$ objects and each of them need to be assigned to at most one object. Most
work on such problems assume that the agents only have ordinal preferences and
usually the goal in them is to compute a matching that satisfies some notion of
economic efficiency. However, in reality, agents may have some preference
intensities or cardinal utilities that, e.g., indicate that they like an object
much more than another object, and not taking these into account can result in
a loss in welfare. While one way to potentially account for these is to
directly ask the agents for this information, such an elicitation process is
cognitively demanding. Therefore, we focus on learning more about their
cardinal preferences using simple threshold queries which ask an agent if they
value an object greater than a certain value, and use this in turn to come up
with algorithms that produce a matching that, for a particular economic notion
$X$, satisfies $X$ and also achieves a good approximation to the optimal
welfare among all matchings that satisfy $X$. We focus on several notions of
economic efficiency, and look at both adaptive and non-adaptive algorithms.
Overall, our results show how one can improve welfare by even non-adaptively
asking the agents for just one bit of extra information per object.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:02:57 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 14:36:16 GMT""}]","2021-07-13"
"2011.13978","Denis Newman-Griffis","Denis Newman-Griffis and Eric Fosler-Lussier","Automated Coding of Under-Studied Medical Concept Domains: Linking
  Physical Activity Reports to the International Classification of Functioning,
  Disability, and Health","Updated final version, published in Frontiers in Digital Health,
  https://doi.org/10.3389/fdgth.2021.620828. 34 pages (23 text + 11
  references); 9 figures, 2 tables","Frontiers in Digital Health, 3:620828 (2021)","10.3389/fdgth.2021.620828",,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Linking clinical narratives to standardized vocabularies and coding systems
is a key component of unlocking the information in medical text for analysis.
However, many domains of medical concepts lack well-developed terminologies
that can support effective coding of medical text. We present a framework for
developing natural language processing (NLP) technologies for automated coding
of under-studied types of medical information, and demonstrate its
applicability via a case study on physical mobility function. Mobility is a
component of many health measures, from post-acute care and surgical outcomes
to chronic frailty and disability, and is coded in the International
Classification of Functioning, Disability, and Health (ICF). However, mobility
and other types of functional activity remain under-studied in medical
informatics, and neither the ICF nor commonly-used medical terminologies
capture functional status terminology in practice. We investigated two
data-driven paradigms, classification and candidate selection, to link
narrative observations of mobility to standardized ICF codes, using a dataset
of clinical narratives from physical therapy encounters. Recent advances in
language modeling and word embedding were used as features for established
machine learning models and a novel deep learning approach, achieving a macro
F-1 score of 84% on linking mobility activity reports to ICF codes. Both
classification and candidate selection approaches present distinct strengths
for automated coding in under-studied domains, and we highlight that the
combination of (i) a small annotated data set; (ii) expert definitions of codes
of interest; and (iii) a representative text corpus is sufficient to produce
high-performing automated coding systems. This study has implications for the
ongoing growth of NLP tools for a variety of specialized applications in
clinical care and research.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:02:59 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 18:05:55 GMT""}]","2021-03-11"
"2011.13979","Enis Ulqinaku","Ivo Sluganovic and Enis Ulqinaku and Aritra Dhar and Daniele Lain and
  Srdjan Capkun and Ivan Martinovic","IntegriScreen: Visually Supervising Remote User Interactions on
  Compromised Clients",,,,,"cs.CR cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Remote services and applications that users access via their local clients
(laptops or desktops) usually assume that, following a successful user
authentication at the beginning of the session, all subsequent communication
reflects the user's intent. However, this is not true if the adversary gains
control of the client and can therefore manipulate what the user sees and what
is sent to the remote server.
  To protect the user's communication with the remote server despite a
potentially compromised local client, we propose the concept of continuous
visual supervision by a second device equipped with a camera. Motivated by the
rapid increase of the number of incoming devices with front-facing cameras,
such as augmented reality headsets and smart home assistants, we build upon the
core idea that the user's actual intended input is what is shown on the
client's screen, despite what ends up being sent to the remote server. A
statically positioned camera enabled device can, therefore, continuously
analyze the client's screen to enforce that the client behaves honestly despite
potentially being malicious.
  We evaluate the present-day feasibility and deployability of this concept by
developing a fully functional prototype, running a host of experimental tests
on three different mobile devices, and by conducting a user study in which we
analyze participants' use of the system during various simulated attacks.
Experimental evaluation indeed confirms the feasibility of the concept of
visual supervision, given that the system consistently detects over 98% of
evaluated attacks, while study participants with little instruction detect the
remaining attacks with high probability.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:05:29 GMT""}]","2020-12-01"
"2011.13980","Bin Hu","Bin Hu and Tua A. Tamba","Co-design of Optimal Transmission Power and Controller for Networked
  Control Systems Under State-dependent Markovian Channels",,,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers a co-design problem for industrial networked control
systems to ensure both the stability and efficiency properties of such systems.
The assurance of such properties is particularly challenging due to the fact
that wireless communications in industrial environments are not only subject to
shadow fading but also stochastically correlated with their surrounding
environments. To address such challenges, this paper first introduces a novel
state-dependent Markov channel (SD-MC) model that explicitly captures the
state-dependent features of industrial wireless communication systems by
defining the proposed model's transition probabilities as a function of both
its environment's states and transmission power. Under the proposed channel
model, sufficient conditions on Maximum Allowable Transmission Interval (MATI)
are presented to ensure both asymptotic stability in expectation and almost
sure asymptotic stability properties of a continuous nonlinear control system
with state-dependent fading channels. Based on such conditions, the co-design
problem is then formulated as a constrained polynomial optimization problem
(CPOP), which can be efficiently solved using semidefinite programming methods
for the case of a two-state state dependent Markovian channel. The solutions to
such a CPOP represent optimal control and power strategies that optimize the
average expected joint costs in an infinite time horizon while still respect
the stability constraints. For a general SD-MC model, this paper further shows
that sub-optimal solutions can be obtained from linear programming formulations
of the considered CPOP. Simulation results are given to illustrate the efficacy
of the proposed co-design scheme.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:10:47 GMT""}]","2020-12-01"
"2011.13981","Soumyadeep Chaudhuri","Soumyadeep Chaudhuri, Changha Choi, Eliezer Rabinovici","Thermal order in large N conformal gauge theories","116 pages, v4: typos have been corrected, comments and references
  have been added, version matches with the published one",,"10.1007/JHEP04(2021)203",,"hep-th cond-mat.str-el hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this work we explore the possibility of spontaneous breaking of global
symmetries at all nonzero temperatures for conformal field theories (CFTs) in
$D = 4$ space-time dimensions. We show that such a symmetry-breaking indeed
occurs in certain families of non-supersymmetric large $N$ gauge theories at a
planar limit. We also show that this phenomenon is accompanied by the system
remaining in a persistent Brout-Englert-Higgs (BEH) phase at any temperature.
These analyses are motivated by the work done in arXiv:2005.03676 where
symmetry-breaking was observed in all thermal states for certain CFTs in
fractional dimensions.
  In our case, the theories demonstrating the above features have gauge groups
which are specific products of $SO(N)$ in one family and $SU(N)$ in the other.
Working in a perturbative regime at the $N\rightarrow\infty$ limit, we show
that the beta functions in these theories yield circles of fixed points in the
space of couplings. We explicitly check this structure up to two loops and then
present a proof of its survival under all loop corrections. We show that under
certain conditions, an interval on this circle of fixed points demonstrates
both the spontaneous breaking of a global symmetry as well as a persistent BEH
phase at all nonzero temperatures. The broken global symmetry is $\mathbb{Z}_2$
in one family of theories and $U(1)$ in the other. The corresponding order
parameters are expectation values of the determinants of bifundamental scalar
fields in these theories. We characterize these symmetries as baryon-like
symmetries in the respective models.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:20:14 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jan 2021 11:59:34 GMT""},{""version"":""v3"",""created"":""Wed, 24 Feb 2021 02:46:28 GMT""},{""version"":""v4"",""created"":""Tue, 20 Apr 2021 08:00:44 GMT""}]","2021-05-12"
"2011.13982","Yu Rong","Yu Rong, Richard M. Gutierrez, Kumar Vijay Mishra and Daniel W. Bliss","Non-Contact Vital Signs Detection with UAV-Borne Radars","7 pages, 7 figures, 1 table",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Airborne radar carried on-board unmanned aerial vehicles (UAV) is serving as
the harbinger of new remote sensing applications for security and rescue in
inclement environments. The mobility and agility of UAVs along with intelligent
on-board sensors (cameras, acoustics, and radar) are more effective during the
early stages of disaster response. The ability of radars to penetrate through
objects and operate during low visibility conditions enables detection of
occluded human subjects on and under debris when other sensing modalities fail.
Recently, radars have been deployed on UAVs to measure minute human
physiological parameters such as respiratory and heart rates while sensing
through clothing and building materials. Aggregating radar measurements with
the information from other sensors is broadening the applications of drones in
life-critical situations. Signal processing techniques are critical in enabling
UAV-borne radars for human vital sign detection (VSD) in multiple operation
modes. Novel radar configurations such as in a UAV swarm and tethered UAVs are
required to facilitate multi-tasking and high endurance, respectively. This
paper provides an overview of recent advances in UAV-borne VSD with a focus on
deployment modes and processing methods.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:29:26 GMT""}]","2020-12-01"
"2011.13983","Hamed Majedi","A. Hamed Majedi","Microwave-induced inverse Faraday effect in superconductors",,"Phys. Rev. Lett. 127, 087001 (2021)","10.1103/PhysRevLett.127.087001",,"cond-mat.supr-con","http://creativecommons.org/publicdomain/zero/1.0/","  Inverse Faraday effect (IFE) in superconductors is proposed, where a static
magnetization is generated under the influence of a circularly polarized
microwave field. Classical modeling of the IFE explicitly provides
superconducting gyration coefficient in terms of its complex conductivity. IFE
is then considered as a source of nonlinearity and gyrotropy even at a
low-power microwave regime giving rise to a spectrum of phenomena and
applications. Microwave-induced gyroelectric conductivity, Hall effect,
microwave birefringence, flux quantization and vortex state are predicted and
quantitatively analyzed. Peculiar microwave birefringence in gyrotropic
superconductors due to radical response of superelectrons has been highlighted.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:30:35 GMT""}]","2021-08-25"
"2011.13984","Cain\~a de Oliveira","Cain\~a de Oliveira and Vitor de Souza","Probing UHECR production in Centaurus A using secondary neutrinos and
  gamma-rays","32 pages, 12 figures",,"10.1140/epjc/s10052-021-09278-3",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the production of neutrinos and photons by ultra high energy
cosmic rays (UHECR) interacting with the extragalactic background radiation is
studied. Centaurus A is assumed as the prime source of UHECR and the
possibility to identify this source by detecting the secondary neutrinos and
photons produced in the propagation of UHECR is investigated. Fifteen
astrophysical models regarding three extragalactic magnetic fields (EGMF) and
five composition abundances are simulated. The flux and arrival direction of
neutrinos and photons are investigated. It is shown that the detection of a
signal from Cen A with statistical significance is achievable by current
observatories in a few years and by proposed experiments in the near future.
The dependence of the results on the models is also presented.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:35:23 GMT""},{""version"":""v2"",""created"":""Fri, 9 Apr 2021 16:55:59 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 13:20:28 GMT""}]","2021-06-30"
"2011.13985","Paul Barry Dr","Paul Barry","The second production matrix of a Riordan array","12 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Riordan array is defined by its production matrix. In this paper, we
explore the notion of the second production matrix of a Riordan array,
characterizing the matrix that is generated by it. We indicate how this
procedure can be generalized to the so-called $n$-th production matrix of a
Riordan array.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:37:11 GMT""}]","2020-12-01"
"2011.13986","Johannes Schneider","Johannes Schneider and Michalis Vlachos","Reflective-Net: Learning from Explanations",,"Data Mining and Knowledge Discovery, 1-22, 2023","10.1007/s10618-023-00920-0",,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humans possess a remarkable capability to make fast, intuitive decisions, but
also to self-reflect, i.e., to explain to oneself, and to efficiently learn
from explanations by others. This work provides the first steps toward
mimicking this process by capitalizing on the explanations generated based on
existing explanation methods, i.e. Grad-CAM. Learning from explanations
combined with conventional labeled data yields significant improvements for
classification in terms of accuracy and training time.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:40:45 GMT""},{""version"":""v2"",""created"":""Sat, 18 Feb 2023 22:11:22 GMT""}]","2023-02-21"
"2011.13987","Roberto Bramati","Roberto Bramati, Paolo Ciatti, John Green, James Wright","Oscillating spectral multipliers on groups of Heisenberg type","22 Pages",,,,"math.FA math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish endpoint estimates for a class of oscillating spectral
multipliers on Lie groups of Heisenberg type. The analysis follows an earlier
argument due to the second and fourth author but requires the detailed analysis
of the wave equation on these groups due to M\""uller and Seeger. We highlight
and develop the connection between sharp bounds for oscillating multipliers and
the problem of determining the minimal amount of smoothness required for
Mihlin-H\""ormander multipliers, a problem that was solved for groups of
Heisenberg type but remains open for other groups.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:41:19 GMT""}]","2020-12-01"
"2011.13988","Katelyn Morrison","Katelyn Morrison","Reducing Discrimination in Learning Algorithms for Social Good in
  Sociotechnical Systems","3 page position paper accepted to the AI for Social Good workshop at
  The International Joint Conference on Artificial Intelligence (IJCAI). To be
  presented on January 8th, 2021",,,,"cs.LG cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sociotechnical systems within cities are now equipped with machine learning
algorithms in hopes to increase efficiency and functionality by modeling and
predicting trends. Machine learning algorithms have been applied in these
domains to address challenges such as balancing the distribution of bikes
throughout a city and identifying demand hotspots for ride sharing drivers.
However, these algorithms applied to challenges in sociotechnical systems have
exacerbated social inequalities due to previous bias in data sets or the lack
of data from marginalized communities. In this paper, I will address how smart
mobility initiatives in cities use machine learning algorithms to address
challenges. I will also address how these algorithms unintentionally
discriminate against features such as socioeconomic status to motivate the
importance of algorithmic fairness. Using the bike sharing program in
Pittsburgh, PA, I will present a position on how discrimination can be
eliminated from the pipeline using Bayesian Optimization.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:45:10 GMT""},{""version"":""v2"",""created"":""Sun, 6 Dec 2020 05:10:08 GMT""}]","2020-12-08"
"2011.13989","Eric E. Mart\'inez-Garc\'ia","Eric E. Mart\'inez-Garc\'ia, Gustavo Bruzual, Rosa A.
  Gonz\'alez-L\'opezlira and Lino H. Rodr\'iguez-Merino","On the Thermally Pulsing Asymptotic Giant Branch Contribution to the
  Light of Nearby Disk Galaxies","Published in 2021, ApJ, 908, 110",,"10.3847/1538-4357/abce68",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of the luminosity contribution from thermally pulsing asymptotic
giant branch (TP-AGB) stars to the stellar populations of galaxies is crucial
to determine their physical parameters (e.g., stellar mass and age). We use a
sample of 84 nearby disk galaxies to explore diverse stellar population
synthesis models with different luminosity contributions from TP-AGB stars. We
fit the models to optical and near-infrared (NIR) photometry, on a
pixel-bypixel basis. The statistics of the fits show a preference for a
low-luminosity contribution (i.e., high mass-to-light ratio in the NIR) from
TP-AGB stars. Nevertheless, for 30 percent to 40 percent of the pixels in our
sample a high-luminosity contribution (hence low mass-to-light ratio in the
NIR) from TP-AGB stars is favored. According to our findings, the mean TP-AGB
star luminosity contribution in nearby disk galaxies may vary with Hubble type.
This may be a consequence of the variation of the TP-AGB mass-loss rate with
metallicity, if metal-poor stars begin losing mass earlier than metal-rich
stars, because of a pre-dust wind that precedes the dust-driven wind.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:54:29 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 18:49:35 GMT""}]","2021-02-18"
"2011.13990","Hanna Mies","Hanna Mies, Christiane Scherb and Pedro Schwaller","Collider constraints on dark mediators",,,"10.1007/JHEP04(2021)049","MITP/20-068,P3H-20-069,TTK-20-41","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the constraints current collider searches place on a QCD-like dark
sector. A combination of multi-jet, multi-jet plus missing energy and emerging
jets searches is used to derive constraints on the mediator mass across the
full range of the dark meson lifetimes for the first time. The dark sector
inherits a flavour structure from the coupling between the dark quarks and the
SM quarks through the mediator. When this is taken into account, the
differently flavoured dark pions become distinguishable through their lifetime.
We show that also in these cases the above mentioned searches remain sensitive,
and we obtain limits on the mediator mass also for the flavoured scenario. We
then contrast the constraints from collider searches with direct detection
bounds on the dark matter candidate itself in both the flavoured and
unflavoured scenario. Using a simple prescription it becomes possible to
display all constraints in the dark matter and mediator mass plane. Constraints
from direct detection tend to be stronger than the collider constraints, unless
the coupling to the first generation quarks is suppressed, in which case the
collider searches place the most stringent limits on the parameter space.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 20:55:49 GMT""}]","2021-04-21"
"2011.13991","Lukas J. Furtak","Lukas J. Furtak (1), Hakim Atek (1), Matthew D. Lehnert (1), Jacopo
  Chevallard (1), St\'ephane Charlot (1) ((1) Sorbonne Universit\'e, CNRS UMR
  7095, Institut d'Astrophysique de Paris, Paris, France)","How robustly can we constrain the low-mass end of the $z\sim6-7$ stellar
  mass function? -- The limits of lensing models and stellar population
  assumptions in the Hubble Frontier Fields","Updated references","MNRAS 501 (2021) 1568","10.1093/mnras/staa3760",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new measurements of the very low-mass end of the galaxy stellar
mass function (GSMF) at $z\sim6-7$ computed from a rest-frame ultraviolet
selected sample of dropout galaxies. These galaxies lie behind the six Hubble
Frontier Fields clusters and are all gravitationally magnified. Using deep
Spitzer/IRAC and Hubble Space Telescope imaging, we derive stellar masses by
fitting galaxy spectral energy distributions and explore the impact of
different model assumptions and parameter degeneracies on the resulting GSMF.
Our sample probes stellar masses down to $M_{\star}>10^{6}\,\text{M}_{\odot}$
and we find the $z\sim6-7$ GSMF to be best parametrized by a modified Schechter
function which allows for a turnover at very low masses. Using a Monte-Carlo
Markov Chain analysis of the GSMF, including accurate treatment of lensing
uncertainties, we obtain a relatively steep low-mass end slope
$\alpha\simeq-1.96_{-0.08}^{+0.09}$ and a turnover at
$\log(M_T/\text{M}_{\odot})\simeq7.10_{-0.56}^{+0.17}$ with a curvature of
$\beta\simeq1.00_{-0.73}^{+0.87}$ for our minimum assumption model with
constant star-formation history (SFH) and low dust attenuation, $A_V\leq0.2$.
We find that the $z\sim6-7$ GSMF, in particular its very low-mass end, is
significantly affected by the assumed functional form of the star formation
history and the degeneracy between stellar mass and dust attenuation. For
example, the low-mass end slope ranges from $\alpha\simeq-1.82_{-0.07}^{+0.08}$
for an exponentially rising SFH to $\alpha\simeq-2.34_{-0.10}^{+0.11}$ when
allowing $A_V$ of up to 3.25. Future observations at longer wavelengths and
higher angular resolution with the James Webb Space Telescope are required to
break these degeneracies and to robustly constrain the stellar mass of galaxies
on the extreme low-mass end of the GSMF.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:00:13 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jan 2021 13:49:49 GMT""}]","2021-01-18"
"2011.13992","Alexander Lebedev","A. I. Lebedev and I. A. Sluchinskaya","Low-temperature phase transitions in some quaternary solid solutions of
  IV-VI semiconductors","4 pages, 4 figures","Journal of Alloys and Compounds 203, 51 (1994)","10.1016/0925-8388(94)90713-7",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Samples of PbS$_x$Se$_y$Te$_{1-x-y}$, Pb$_{1-x}$Sn$_x$Te$_{1-y}$Se$_y$, and
Pb$_{1-x}$Sn$_x$Te$_{1-y}$S$_y$ quaternary solid solutions were investigated in
the 4--200~K temperature range using electrical and X-ray methods. The regions
where low-temperature phase transitions occur were established. It was shown
that phase transitions in these solid solutions are associated with off-center
S and Sn ions. The dependence of the phase transition temperature on the
composition of solid solutions can be qualitatively described taking into
account the influence of substitutional disorder on the ordering and tunneling
of off-center ions.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:09:51 GMT""}]","2020-12-01"
"2011.13993","Daren Wang","Daren Wang, Zifeng Zhao, Rebecca Willett, Chun Yip Yau","Functional Autoregressive Processes in Reproducing Kernel Hilbert Spaces",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the estimation and prediction of functional autoregressive~(FAR)
processes, a statistical tool for modeling functional time series data. Due to
the infinite-dimensional nature of FAR processes, the existing literature
addresses its inference via dimension reduction and theoretical results therein
require the (unrealistic) assumption of fully observed functional time series.
We propose an alternative inference framework based on Reproducing Kernel
Hilbert Spaces~(RKHS). Specifically, a nuclear norm regularization method is
proposed for estimating the transition operators of the FAR process directly
from discrete samples of the functional time series. We derive a representer
theorem for the FAR process, which enables infinite-dimensional inference
without dimension reduction. Sharp theoretical guarantees are established under
the (more realistic) assumption that we only have finite discrete samples of
the FAR process. Extensive numerical experiments and a real data application of
energy consumption prediction are further conducted to illustrate the promising
performance of the proposed approach compared to the state-of-the-art methods
in the literature.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:16:48 GMT""}]","2020-12-01"
"2011.13994","Giuseppe Antonio Di Luna","Giuseppe Antonio Di Luna, Davide Italiano, Luca Massarelli, Sebastian
  Osterlund, Cristiano Giuffrida, Leonardo Querzoni","Who is Debugging the Debuggers? Exposing Debug Information Bugs in
  Optimized Binaries",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the advancements in software testing, bugs still plague deployed
software and result in crashes in production. When debugging issues --
sometimes caused by ""heisenbugs"" -- there is the need to interpret core dumps
and reproduce the issue offline on the same binary deployed. This requires the
entire toolchain (compiler, linker, debugger) to correctly generate and use
debug information. Little attention has been devoted to checking that such
information is correctly preserved by modern toolchains' optimization stages.
This is particularly important as managing debug information in optimized
production binaries is non-trivial, often leading to toolchain bugs that may
hinder post-deployment debugging efforts. In this paper, we present
Debug$^{2}$, a framework to find debug information bugs in modern toolchains.
Our framework feeds random source programs to the target toolchain and
surgically compares the debugging behavior of their optimized/unoptimized
binary variants. Such differential analysis allows Debug$^{2}$ to check
invariants at each debugging step and detect bugs from invariant violations.
Our invariants are based on the (in)consistency of common debug entities, such
as source lines, stack frames, and function arguments. We show that, while
simple, this strategy yields powerful cross-toolchain and cross-language
invariants, which can pinpoint several bugs in modern toolchains. We have used
Debug$^{2}$ to find 23 bugs in the LLVM toolchain (clang/lldb), 8 bugs in the
GNU toolchain (GCC/gdb), and 3 in the Rust toolchain (rustc/lldb) -- with 14
bugs already fixed by the developers.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:18:57 GMT""},{""version"":""v2"",""created"":""Fri, 4 Dec 2020 10:40:39 GMT""}]","2020-12-07"
"2011.13995","Hicham Agueny","Abdelmalek Taoutioui and Hicham Agueny","Infrared single-cycle pulse induced high-energy plateaus in high-order
  harmonic spectroscopy","10 pages, 5 figures, regular article",,,,"physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the emerging experiments [e.g. \textit{Z. Nie et al. Nat.
Photon. \textbf{12}, 489 (2018)}] on producing infrared (IR) single cycle
pulses in the spectral region 5 - 14 $\mu m$, we theoretically investigate
their role for controlling high-order harmonic generation (HHG) process induced
by an intense near-infrared (NIR) multi-cycle pulse ($\lambda$ = 1.27 $\mu m$).
The scenario is demonstrated for a prototype of the hydrogen atom by numerical
simulations of the time-dependent Schr\""odinger equation. In particular, we
show that the combined pulses allow one to generate even-order harmonics and
most importantly to produce high-energy plateaus and that the harmonic cutoff
is extended by a factor of 3 compared to the case with the NIR pulse alone. The
emerged high-energy plateaus is understood as a result of a vast momentum
transfer from the single-cycle field to the ionized electrons while travelling
in the NIR field, and thus leading to high-momentum electron recollisions. We
also identify the role of the IR single-cycle field for controlling the
directionality of the emitted electrons via the IR-field induced electron
displacement effect. We further show that the emerged plateaus can be
controlled by varying the relative carrier-envelope phase between the two
pulses as well as their wavelengths. Thus, our findings open up new
perspectives for time-resolved electron diffraction using an IR single-cycle
field-assisted high-harmonic spectroscopy.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:28:46 GMT""}]","2020-12-01"
"2011.13998","Alexander Schein","A. Schein, K. T. Carlberg, M. J. Zahr","Preserving general physical properties in model reduction of dynamical
  systems via constrained-optimization projection",,,"10.1002/nme.6667",,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model-reduction techniques aim to reduce the computational complexity of
simulating dynamical systems by applying a (Petrov-)Galerkin projection process
that enforces the dynamics to evolve in a low-dimensional subspace of the
original state space. Frequently, the resulting reduced-order model (ROM)
violates intrinsic physical properties of the original full-order model (FOM)
(e.g., global conservation, Lagrangian structure, state-variable bounds)
because the projection process does not generally ensure preservation of these
properties. However, in many applications, ensuring the ROM preserves such
intrinsic properties can enable the ROM to retain physical meaning and lead to
improved accuracy and stability properties. In this work, we present a general
constrained-optimization formulation for projection-based model reduction that
can be used as a template to enforce the ROM to satisfy specific properties on
the kinematics and dynamics. We introduce constrained-optimization formulations
at both the time-continuous (i.e., ODE) level, which leads to a constrained
Galerkin projection, and at the time-discrete level, which leads to a
least-squares Petrov-Galerkin (LSPG) projection, in the context of linear
multistep schemes. We demonstrate the ability of the proposed formulations to
equip ROMs with desired properties such as global energy conservation and
bounds on the total variation.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:38:20 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 09:07:00 GMT""},{""version"":""v3"",""created"":""Thu, 1 Apr 2021 12:04:27 GMT""}]","2021-04-02"
"2011.13999","Teng Bian","Teng Bian and Sabre Kais","Quantum Computing for Atomic and Molecular Resonances","To be published in J. Chem. Phys. 2021",,"10.1063/5.0040477",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The complex-scaling method can be used to calculate molecular resonances
within the Born-Oppenheimer approximation, assuming the electronic coordinates
are dilated independently of the nuclear coordinates. With this method, one
will calculate the complex energy of a non-Hermitian Hamiltonian, whose real
part is associated with the resonance position and the imaginary part is the
inverse of the lifetime. In this study, we propose techniques to simulate
resonances on a quantum computer. First, we transformed the scaled molecular
Hamiltonian to second-quantization and then used the Jordan-Wigner
transformation to transform the scaled Hamiltonian to the qubit space. To
obtain the complex eigenvalues, we introduce the Direct Measurement method,
which is applied to obtain the resonances of a simple one-dimensional model
potential that exhibits pre-dissociating resonances analogous to those found in
diatomic molecules. Finally, we applied the method to simulate the resonances
of the H$_2^-$ molecule. Numerical results from the IBM Qiskit simulators and
IBM quantum computers verify our techniques.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:39:23 GMT""},{""version"":""v2"",""created"":""Fri, 18 Dec 2020 00:40:47 GMT""},{""version"":""v3"",""created"":""Thu, 6 May 2021 04:33:10 GMT""}]","2021-06-16"
"2011.14001","Alexandre Lourdeaux","Alexandre Lourdeaux","On geometry of some pseudo-reductive groups","21 pages, Accepted by Communications in Algebra",,,,"math.GR math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on the work of Conrad-Gabber-Prasad, the paper deals with the geometry
of particular pseudo-semisimple groups, namely those which can be written as
quotient of Weil restriction of semisimple groups. We establish that these
groups are retract rational when their are split, and give results on their
Picard groups.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:44:53 GMT""},{""version"":""v2"",""created"":""Wed, 10 Feb 2021 22:33:58 GMT""},{""version"":""v3"",""created"":""Thu, 26 May 2022 18:37:05 GMT""}]","2022-05-30"
"2011.14002","Anca Radulescu","Anca Radulescu, Abraham Longbotham","Effects of local mutations in quadratic iterations","15 pages, 15 figures, 7 references",,,,"math.DS nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce mutations in replication systems, in which the intact copying
mechanism is performed by discrete iterations of a complex quadratic map. More
specifically, we consider a ""correct"" function acting on the complex plane
(representing the space of genes to be copied). A ""mutation"" is a different
(""erroneous"") map acting on a complex locus of given radius r around a mutation
focal point. The effect of the mutation is interpolated radially to eventually
recover the original map when reaching an outer radius R. We call the resulting
map a ""mutated"" map.
  In the theoretical framework of mutated iterations, we study how a mutation
(replication error) affects the temporal evolution of the system, on both a
local and global scale (from cell diffetentiation to tumor formation). We use
the Julia set of the system to quantify simultaneously the long-term behavior
of the entire space under mutated maps. We analyze how the position, timing and
size of the mutation can alter the topology of the Julia set, hence the
system's long-term evolution, its progression into disease, but also its
ability to recover or heal. In the context of genetics, mutated iterations may
help shed some light on aspects such as the importance of location, size and
type of mutation when evaluating a system's prognosis, and of customizing
intervention.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:45:01 GMT""}]","2020-12-01"
"2011.14003","Chiara Marletto","Chiara Marletto, Nicetu Tibau Vidal, Vlatko Vedral","Interference in the Heisenberg Picture of Quantum Field Theory, Local
  Elements of Reality and Fermions",,"Phys. Rev. D 104, 065013 (2021)","10.1103/PhysRevD.104.065013",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the quantum interference of a single photon in the Mach-Zehnder
interferometer using the Heisenberg picture. Our purpose is to show that the
description is local just like in the case of the classical electromagnetic
field, the only difference being that the electric and the magnetic fields are,
in the quantum case, operators (quantum observables). We then consider a
single-electron Mach-Zehnder interferometer and explain what the appropriate
Heisenberg picture treatment is in this case. Interestingly, the parity
superselection rule forces us to treat the electron differently to the photon.
A model using only local quantum observables of different fermionic modes, such
as the current operator, is nevertheless still viable to describe phase
acquisition. We discuss how to extend this local analysis to coupled fermionic
and bosonic fields within the same local formalism of quantum electrodynamics
as formulated in the Heisenberg picture.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:50:40 GMT""}]","2021-09-22"
"2011.14015","Udai Nagpal","Udai G. Nagpal, David A Knowles","Active Learning in CNNs via Expected Improvement Maximization",,,,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning models such as Convolutional Neural Networks (CNNs) have
demonstrated high levels of effectiveness in a variety of domains, including
computer vision and more recently, computational biology. However, training
effective models often requires assembling and/or labeling large datasets,
which may be prohibitively time-consuming or costly. Pool-based active learning
techniques have the potential to mitigate these issues, leveraging models
trained on limited data to selectively query unlabeled data points from a pool
in an attempt to expedite the learning process. Here we present ""Dropout-based
Expected IMprOvementS"" (DEIMOS), a flexible and computationally-efficient
approach to active learning that queries points that are expected to maximize
the model's improvement across a representative sample of points. The proposed
framework enables us to maintain a prediction covariance matrix capturing model
uncertainty, and to dynamically update this matrix in order to generate diverse
batches of points in the batch-mode setting. Our active learning results
demonstrate that DEIMOS outperforms several existing baselines across multiple
regression and classification tasks taken from computer vision and genomics.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 22:06:52 GMT""}]","2020-12-01"
"2011.14016","Alan Lindsay","Alan Lindsay, Bart Craenen, Sara Dalzel-Job, Robin L. Hill, Ronald P.
  A. Petrick","Investigating Human Response, Behaviour, and Preference in Joint-Task
  Interaction",,,,,"cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Human interaction relies on a wide range of signals, including non-verbal
cues. In order to develop effective Explainable Planning (XAIP) agents it is
important that we understand the range and utility of these communication
channels. Our starting point is existing results from joint task interaction
and their study in cognitive science. Our intention is that these lessons can
inform the design of interaction agents -- including those using planning
techniques -- whose behaviour is conditioned on the user's response, including
affective measures of the user (i.e., explicitly incorporating the user's
affective state within the planning model). We have identified several concepts
at the intersection of plan-based agent behaviour and joint task interaction
and have used these to design two agents: one reactive and the other partially
predictive. We have designed an experiment in order to examine human behaviour
and response as they interact with these agents. In this paper we present the
designed study and the key questions that are being investigated. We also
present the results from an empirical analysis where we examined the behaviour
of the two agents for simulated users.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 22:16:59 GMT""}]","2020-12-01"
"2011.14017","Laura Dumitrescu","Laura Dumitrescu and Ioana Schiopu-Kratina","Asymptotic results with estimating equations for time-evolving clustered
  data",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the existence, strong consistency and asymptotic normality of
estimators obtained from estimating functions, that are p-dimensional
martingale transforms. The problem is motivated by the analysis of evolutionary
clustered data, with distributions belonging to the exponential family, and
which may also vary in terms of other component series. Within a
quasi-likelihood approach, we construct estimating equations, which accommodate
different forms of dependency among the components of the response vector and
establish multivariate extensions of results on linear and generalized linear
models, with stochastic covariates. Furthermore, we characterize estimating
functions which are asymptotically optimal, in that they lead to confidence
regions for the regression parameters which are of minimum size,
asymptotically. Results from a simulation study and an application to a real
dataset are included.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 22:19:15 GMT""}]","2020-12-01"
"2011.14018","Andreas Rupp","Peipei Lu and Andreas Rupp and Guido Kanschat","HMG -- Homogeneous multigrid for HDG",,,"10.1093/imanum/drab055",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a homogeneous multigrid method in the sense that it uses the
same HDG discretization scheme for Poisson's equation on all levels. In
particular, we construct a stable injection operator and prove optimal
convergence of the method under the assumption of elliptic regularity.
Numerical experiments underline our analytical findings.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 22:29:35 GMT""}]","2021-08-11"
"2011.14019","Aliaksei Kachanovich","Aliaksei Kachanovich","Higgs decay into two leptons and a photon revisited","6 pages, 4 figures, contribution to: ICHEP2020",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I present new results for the Standard-Model predictions of the differential
decay rates for $H\to \ell^{+} \ell^{-} \gamma$, where $\ell=e, \mu$, and the
forward-backward asymmetries defined in terms of the flight direction of the
photon corresponding to the lepton momenta. The results dependend on the cuts
on energies and invariant masses of the final state particles. For standard
choices of these cuts the branching ratios $B(H\to e \bar e \gamma)=5.8\cdot
10^{-5}$ and $B(H\to \mu \bar \mu \gamma)=6.4\cdot 10^{-5}$ as well as the
forward-backward asymmetries $\mathcal{A}^{(e)}_{\text{FB}}=0.343$ and
$\mathcal{A}^{(\mu)}_{\text{FB}}=0.255$ have been found.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 22:30:52 GMT""}]","2020-12-01"
"2011.14020","Stephen Pietromonaco","Stephen Pietromonaco","$G$-invariant Hilbert Schemes on Abelian Surfaces and Enumerative
  Geometry of the Orbifold Kummer Surface","25 pages, comments and feedback welcomed",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  For an Abelian surface $A$ with a symplectic action by a finite group $G$,
one can define the partition function for $G$-invariant Hilbert schemes \[Z_{A,
G}(q) = \sum_{d=0}^{\infty} e(\text{Hilb}^{d}(A)^{G})q^{d}.\] We prove the
reciprocal $Z_{A,G}^{-1}$ is a modular form of weight $\frac{1}{2}e(A/G)$ for
the congruence subgroup $\Gamma_{0}(|G|)$, and give explicit expressions in
terms of eta products. Refined formulas for the $\chi_{y}$-genera of
$\text{Hilb}(A)^{G}$ are also given. For the group generated by the standard
involution $\tau : A \to A$, our formulas arise from the enumerative geometry
of the orbifold Kummer surface $[A/\tau]$. We prove that a virtual count of
curves in the stack is governed by $\chi_{y}(\text{Hilb}(A)^{\tau})$. Moreover,
the coefficients of $Z_{A, \tau}$ are true (weighted) counts of rational
curves, consistent with hyperelliptic counts of Bryan, Oberdieck,
Pandharipande, and Yin.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 22:33:06 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 18:59:13 GMT""},{""version"":""v3"",""created"":""Fri, 10 Sep 2021 03:13:25 GMT""}]","2021-09-13"
"2011.14021","Xingqian Xu","Xingqian Xu, Zhifei Zhang, Zhaowen Wang, Brian Price, Zhonghao Wang,
  Humphrey Shi","Rethinking Text Segmentation: A Novel Dataset and A Text-Specific
  Refinement Approach",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text segmentation is a prerequisite in many real-world text-related tasks,
e.g., text style transfer, and scene text removal. However, facing the lack of
high-quality datasets and dedicated investigations, this critical prerequisite
has been left as an assumption in many works, and has been largely overlooked
by current research. To bridge this gap, we proposed TextSeg, a large-scale
fine-annotated text dataset with six types of annotations: word- and
character-wise bounding polygons, masks and transcriptions. We also introduce
Text Refinement Network (TexRNet), a novel text segmentation approach that
adapts to the unique properties of text, e.g. non-convex boundary, diverse
texture, etc., which often impose burdens on traditional segmentation models.
In our TexRNet, we propose text specific network designs to address such
challenges, including key features pooling and attention-based similarity
checking. We also introduce trimap and discriminator losses that show
significant improvement on text segmentation. Extensive experiments are carried
out on both our TextSeg dataset and other existing datasets. We demonstrate
that TexRNet consistently improves text segmentation performance by nearly 2%
compared to other state-of-the-art segmentation methods. Our dataset and code
will be made available at
https://github.com/SHI-Labs/Rethinking-Text-Segmentation.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 22:50:09 GMT""}]","2020-12-01"
"2011.14022","Maria E Steinrueck","Maria E Steinrueck, Adam P. Showman, Panayotis Lavvas, Tommi Koskinen,
  Xianyu Tan, Xi Zhang","3D simulations of photochemical hazes in the atmosphere of hot Jupiter
  HD 189733b","Accepted at MNRAS. This is a pre-copyedited, author-produced version
  following peer review","Monthly Notices of the Royal Astronomical Society, Volume 504,
  Issue 2, June 2021, Pages 2783-2799","10.1093/mnras/stab1053",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photochemical hazes have been suggested as candidate for the high-altitude
aerosols observed in the transmission spectra of many hot Jupiters. We present
3D simulations of the hot Jupiter HD 189733b to study how photochemical hazes
are transported by atmospheric circulation. The model includes spherical,
constant-size hazes particles that gravitationally settle and are transported
by the winds as passive tracers, with particle radii ranging from 1 nm to 300
$\mu$m. We identify two general types of haze distribution based on particle
size: In the small-particle regime (<30 nm), gravitational settling is
unimportant, and hazes accumulate in two large mid-latitude vortices centered
on the night side that extend across the morning terminator. Therefore, small
hazes are more concentrated at the morning terminator than at the evening
terminator. In the large-particle regime (>30 nm), hazes settle out quickly on
the nightside, resulting in more hazes at the evening terminator. For small
particles, terminator differences in haze mass mixing ratio and temperature
considered individually can result in significant differences in the transit
spectra of the terminators. When combining both effects for HD189733b, however,
they largely cancel out each other, resulting in very small terminator
differences in the spectra. Transit spectra based on the GCM-derived haze
distribution fail to reproduce the steep spectral slope at short wavelengths in
the current transit observations of HD 189733b. Differing optical properties of
hazes, hotter temperatures at low pressures because of heating by hazes,
enhanced sub-grid-scale mixing, or star spots might explain the mismatch
between the model and observations.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 22:52:15 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 19:32:12 GMT""},{""version"":""v3"",""created"":""Mon, 17 May 2021 04:16:08 GMT""}]","2021-05-18"
"2011.14023","Jo\~ao Fernando Nariyoshi","Jo\~ao Fernando Nariyoshi","Critical velocity averaging lemmas","42 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove new velocity averaging lemmas for multi-dimensional
hyperbolic-parabolic partial differential equations. These theorems may be
applied to establish several compactness results for both deterministic and
stochastic convection-diffusion equations. Among the strengths of our theory is
the criticality of the source term, which may include spatial derivatives of
second order and stochastic noises.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 22:52:39 GMT""}]","2020-12-01"
"2011.14024","Chun Ouyang","Bemali Wickramanayake, Dakshi Kapugama Geeganage, Chun Ouyang, Yue Xu","A Survey of Online Card Payment Fraud Detection using Data Mining-based
  Methods",,,,,"cs.CR cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Card payment fraud is a serious problem, and a roadblock for an optimally
functioning digital economy, with cards (Debits and Credit) being the most
popular digital payment method across the globe. Despite the occurrence of
fraud could be relatively rare, the impact of fraud could be significant,
especially on the cardholder. In the research, there have been many attempts to
develop methods of detecting potentially fraudulent transactions based on data
mining techniques, predominantly exploiting the developments in the space of
machine learning over the last decade. This survey proposes a taxonomy based on
a review of existing research attempts and experiments, which mainly elaborates
the approaches taken by researchers to incorporate the (i) business impact of
fraud (and fraud detection) into their work , (ii) the feature engineering
techniques that focus on cardholder behavioural profiling to separate
fraudulent activities happening with the same card, and (iii) the adaptive
efforts taken to address the changing nature of fraud. Further, there will be a
comparative performance evaluation of classification algorithms used and
efforts of addressing class imbalance problem. Forty-five peer-reviewed papers
published in the domain of card fraud detection between 2009 and 2020 were
intensively reviewed to develop this paper.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 23:07:38 GMT""}]","2020-12-01"
"2011.14025","Chetan Dhital","C. Dhital and J. F. DiTusa","Entropic signatures of the skyrmion lattice phase in MnSi1-xAlx and
  Fe1-yCoySi","8 figures, To be published in PRB","PRB, 2020","10.1103/PhysRevB.102.224408",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The entropic signatures of magnetic phase transitions in the skyrmion lattice
host compounds MnSi0.962Al0.038 and Fe0.7Co0.3Si were investigated through low
field magnetization and ac susceptibility measurements. These data indicate
that the conical to skyrmion transition that occurs with the application of
magnetic field in MnSi0.962Al0.038 is characterized by clear discontinuity in
the magnetic entropy as expected for first order topological phase transition.
These same magnetoentropic features are negligibly small in isostructural
Fe0.7Co0.3Si due to the level of chemical substitution related disorder and
differences in the spin dynamics (range and timescales). Despite the obvious
similarities in the magnetic structures of these two compounds, the transitions
between these phases is substantially different indicating a surprising
non-universality to the magnetic phase transitions in this class of materials.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 23:08:45 GMT""}]","2020-12-11"
"2011.14026","Craig Roberts","Chen Chen, Christian S. Fischer, Craig D. Roberts and Jorge Segovia","Form Factors of the Nucleon Axial Current","8 pages, 6 figures, 2 tables. Accepted for publication in Phys. Lett.
  B",,"10.1016/j.physletb.2021.136150","NJU-INP 027/20","hep-ph hep-ex hep-lat nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A symmetry-preserving Poincar\'e-covariant quark+diquark Faddeev equation
treatment of the nucleon is used to deliver parameter-free predictions for the
nucleon's axial and induced pseudoscalar form factors, $G_A$ and $G_P$,
respectively. The result for $G_A$ can reliably be represented by a dipole form
factor characterised by an axial charge $g_A=G_A(0)=1.25(3)$ and a mass-scale
$M_A = 1.23(3) m_N$, where $m_N$ is the nucleon mass; and regarding $G_P$, the
induced pseudoscalar charge $g_p^\ast = 8.80(23)$, the ratio $g_p^\ast/g_A =
7.04(22)$, and the pion pole dominance Ansatz is found to provide a reliable
estimate of the directly computed result. The ratio of flavour-separated quark
axial charges is also calculated: $g_A^d/g_A^u=-0.16(2)$. This value expresses
a marked suppression of the size of the $d$-quark component relative to that
found in nonrelativistic quark models and owes to the presence of strong
diquark correlations in the nucleon Faddeev wave function -- both scalar and
axial-vector, with the scalar diquark being dominant. The predicted form for
$G_A$ should provide a sound foundation for analyses of the neutrino-nucleus
and antineutrino-nucleus cross-sections that are relevant to modern accelerator
neutrino experiments.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 23:13:30 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 11:19:40 GMT""}]","2021-03-17"
"2011.14027","Jack Lanchantin","Jack Lanchantin, Tianlu Wang, Vicente Ordonez, Yanjun Qi","General Multi-label Image Classification with Transformers","13 pages, 7 figures",,,,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Multi-label image classification is the task of predicting a set of labels
corresponding to objects, attributes or other entities present in an image. In
this work we propose the Classification Transformer (C-Tran), a general
framework for multi-label image classification that leverages Transformers to
exploit the complex dependencies among visual features and labels. Our approach
consists of a Transformer encoder trained to predict a set of target labels
given an input set of masked labels, and visual features from a convolutional
neural network. A key ingredient of our method is a label mask training
objective that uses a ternary encoding scheme to represent the state of the
labels as positive, negative, or unknown during training. Our model shows
state-of-the-art performance on challenging datasets such as COCO and Visual
Genome. Moreover, because our model explicitly represents the uncertainty of
labels during training, it is more general by allowing us to produce improved
results for images with partial or extra label annotations during inference. We
demonstrate this additional capability in the COCO, Visual Genome, News500, and
CUB image datasets.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 23:20:35 GMT""}]","2020-12-01"
"2011.14028","Mohammad Ali Ahmadpoor","Mohammad Ali Ahmadpoor and Marzieh Shams Yousefi","A note on the $p$-operator space structure of the $p$-analog of the
  Fourier-Stieltjes algebra",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper one of the possible $p$-operator space structures of the
$p$-analog of the Fourier-Stieltjes algebra will be introduced, and to some
extend will be studied. This special sort of operator structure will be given
from the predual of this Fourier type algebra, that is the algebra of universal
$p$-pseudofunctions. Furthermore, some applicable and expected results will be
proven.
  Current paper can be considered as a new gate into the collection of problems
around the $p$-analog of the Fourier-Stieltjes algebra, in the $p$-operator
space structure point of view.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 23:28:20 GMT""}]","2020-12-01"
"2011.14029","Hisay Lama","Hisay Lama and Ranajit Mondal","The Physics of Drying of Colloidal Dispersion: Pattern Formation and
  Desiccation Cracks","34 pages, 24 figures",,,,"cond-mat.soft","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Drying of colloidal dispersion and their consolidation into a particulate
deposit is a common phenomenon. This process involves various physical
processes such as diffusion of liquid molecules into the ambient atmosphere and
advection of dispersed particles via evaporation driven flow. The colloidal
particles forming a dried deposit exhibits distinct patterns and frequently
possess structural defects such as desiccation cracks. This chapter gives an
introductory review of the drying of colloidal dispersion and various
associated phenomena. In principle, the drying of colloid dispersion, the
process of their consolidation, and fluid-flow dynamics are all studied in
numerous drying configurations. Here we explain drying induced phenomena
concerning sessile drop drying. We begin with an introduction to colloids,
provide background on the physics of drying, and then explain the formation of
pattern and the desiccation cracks. The role of evaporation driven flows and
their influence on particle accumulation, the impact of various physical
parameters on pattern formation and cracks are all briefly illustrated.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 23:34:51 GMT""}]","2020-12-01"
"2011.14030","William McKinnon","William B. McKinnon, Christopher R. Glein, Tanguy Bertrand, Alyssa R.
  Rhoden","Formation, Composition, and History of the Pluto System: A
  Post-New-Horizons Synthesis","94 pages, 13 figures; will appear as a chapter/conference proceedings
  in the Space Science Series volume ""The Pluto System After New Horizons,""
  S.A. Stern et al., University of Arizona Press, Tucson, AZ",,"10.2458/azu_uapress_9780816540945-ch022",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Pluto-Charon system provides a broad variety of constraints on planetary
formation, composition, chemistry, and evolution. Pluto was the first body to
be discovered in what is now known as the Kuiper belt, its orbit ultimately
becoming a major clue that the giant planets underwent substantial orbital
migration early in Solar System history. This migration has been linked to an
early instability in the orbits of the giant planets and the formation of the
Kuiper belt itself, from an ancestral trans-Neptunian planetesimal disk that
included Pluto. Pluto-Charon is emblematic of what are now recognized as small
or dwarf planets. Far from being a cold, dead, battered icy relic, Pluto
displays evidence of a complex geological history, with ongoing processes
including tectonism, cryovolcanism, solid-state convection, glacial flow,
atmospheric circulation, surface-atmosphere volatile exchange, aeolian
processes, and atmospheric photochemistry, microphysics, and haze formation.
Despite Pluto's relatively modest scale, the combination of original
accretional heat, long-term internal radiogenic heat release, and external
solar forcing, when combined with sufficiently volatile (and thus mobile)
materials, yields an active world. Pluto may have inherited a large organic
mass fraction during accretion, which may responsible, in part, for its surface
and atmospheric volatiles. Charon, Pluto's major moon, displays evidence of
extensive early tectonism and cryovolcanism. Dwarf planets are thus truly
planetary in terms of satellite systems and geological and atmospheric
complexity (if not ongoing activity). What they may lack in mass is made up in
number, and the majority of the Solar System's dwarf planets remain
undiscovered.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 23:49:56 GMT""}]","2020-12-01"
"2011.14031","Fnu Devvrit","Devvrit, Minhao Cheng, Cho-Jui Hsieh, Inderjit Dhillon","Voting based ensemble improves robustness of defensive models",,,,,"cs.LG cs.CR cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Developing robust models against adversarial perturbations has been an active
area of research and many algorithms have been proposed to train individual
robust models. Taking these pretrained robust models, we aim to study whether
it is possible to create an ensemble to further improve robustness. Several
previous attempts tackled this problem by ensembling the soft-label prediction
and have been proved vulnerable based on the latest attack methods. In this
paper, we show that if the robust training loss is diverse enough, a simple
hard-label based voting ensemble can boost the robust error over each
individual model. Furthermore, given a pool of robust models, we develop a
principled way to select which models to ensemble. Finally, to verify the
improved robustness, we conduct extensive experiments to study how to attack a
voting-based ensemble and develop several new white-box attacks. On CIFAR-10
dataset, by ensembling several state-of-the-art pre-trained defense models, our
method can achieve a 59.8% robust accuracy, outperforming all the existing
defensive models without using additional data.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 00:08:45 GMT""}]","2020-12-01"
"2011.14032","Sebastiano Barbieri","Sebastiano Barbieri, Suneela Mehta, Billy Wu, Chrianna Bharat, Katrina
  Poppe, Louisa Jorm, Rod Jackson","Predicting cardiovascular risk from national administrative databases
  using a combined survival analysis and deep learning approach",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  AIMS. This study compared the performance of deep learning extensions of
survival analysis models with traditional Cox proportional hazards (CPH) models
for deriving cardiovascular disease (CVD) risk prediction equations in national
health administrative datasets. METHODS. Using individual person linkage of
multiple administrative datasets, we constructed a cohort of all New Zealand
residents aged 30-74 years who interacted with publicly funded health services
during 2012, and identified hospitalisations and deaths from CVD over five
years of follow-up. After excluding people with prior CVD or heart failure,
sex-specific deep learning and CPH models were developed to estimate the risk
of fatal or non-fatal CVD events within five years. The proportion of explained
time-to-event occurrence, calibration, and discrimination were compared between
models across the whole study population and in specific risk groups. FINDINGS.
First CVD events occurred in 61,927 of 2,164,872 people. Among diagnoses and
procedures, the largest 'local' hazard ratios were associated by the deep
learning models with tobacco use in women (2.04, 95%CI: 1.99-2.10) and with
chronic obstructive pulmonary disease with acute lower respiratory infection in
men (1.56, 95%CI: 1.50-1.62). Other identified predictors (e.g. hypertension,
chest pain, diabetes) aligned with current knowledge about CVD risk predictors.
The deep learning models significantly outperformed the CPH models on the basis
of proportion of explained time-to-event occurrence (Royston and Sauerbrei's
R-squared: 0.468 vs. 0.425 in women and 0.383 vs. 0.348 in men), calibration,
and discrimination (all p<0.0001). INTERPRETATION. Deep learning extensions of
survival analysis models can be applied to large health administrative
databases to derive interpretable CVD risk prediction equations that are more
accurate than traditional CPH models.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 00:10:25 GMT""}]","2020-12-01"
"2011.14033","Priyank Agrawal","Priyank Agrawal, Theja Tulabandhula and Vashist Avadhanula","A Tractable Online Learning Algorithm for the Multinomial Logit
  Contextual Bandit","Accepted to be published at Elsevier European Journal of Operational
  Research (EJOR)",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the contextual variant of the MNL-Bandit problem.
More specifically, we consider a dynamic set optimization problem, where a
decision-maker offers a subset (assortment) of products to a consumer and
observes the response in every round. Consumers purchase products to maximize
their utility. We assume that a set of attributes describe the products, and
the mean utility of a product is linear in the values of these attributes. We
model consumer choice behavior using the widely used Multinomial Logit (MNL)
model and consider the decision maker problem of dynamically learning the model
parameters while optimizing cumulative revenue over the selling horizon $T$.
Though this problem has attracted considerable attention in recent times, many
existing methods often involve solving an intractable non-convex optimization
problem. Their theoretical performance guarantees depend on a problem-dependent
parameter which could be prohibitively large. In particular, existing
algorithms for this problem have regret bounded by $O(\sqrt{\kappa d T})$,
where $\kappa$ is a problem-dependent constant that can have an exponential
dependency on the number of attributes. In this paper, we propose an optimistic
algorithm and show that the regret is bounded by $O(\sqrt{dT} + \kappa)$,
significantly improving the performance over existing methods. Further, we
propose a convex relaxation of the optimization step, which allows for
tractable decision-making while retaining the favourable regret guarantee.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 00:20:36 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 07:48:58 GMT""},{""version"":""v3"",""created"":""Sun, 7 Mar 2021 19:53:26 GMT""},{""version"":""v4"",""created"":""Sun, 19 Jun 2022 03:30:35 GMT""},{""version"":""v5"",""created"":""Mon, 27 Mar 2023 17:47:44 GMT""}]","2023-03-28"
"2011.14034","Yamir Moreno","Jiarong Xie, Xiangrong Wang, Ling Feng, Jin-Hua Zhao, Yamir Moreno,
  and Yanqing Hu","Induced Percolation on Networked Systems","18 pages, including 10 figures and 2 tables",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Percolation theory has been widely used to study phase transitions in complex
networked systems. It has also successfully explained several macroscopic
phenomena across different fields. Yet, the existent theoretical framework for
percolation places the focus on the direct interactions among the system's
components, while recent empirical observations have shown that indirect
interactions are common in many systems like ecological and social networks,
among others. Here, we propose a new percolation framework that accounts for
indirect interactions, which allows to generalize the current theoretical body
and understand the role of the underlying indirect influence of the components
of a networked system on its macroscopic behavior. We report a rich
phenomenology in which first-order, second-order or hybrid phase transitions
are possible depending on whether the links of the substrate network are
directed, undirected or a mix, respectively. We also present an analytical
framework to characterize the proposed induced percolation, paving the way to
further understand network dynamics with indirect interactions.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 00:24:07 GMT""}]","2020-12-01"
"2011.14035","Constantinos Chamzas","Dimitrios Chamzas, Constantinos Chamzas and Konstantinos Moustakas","cMinMax: A Fast Algorithm to Find the Corners of an N-dimensional Convex
  Polytope","Accepted in GRAPP 2021, Code available at
  https://github.com/jimas95/CMinMax and video presentation at
  https://www.youtube.com/watch?v=Ug313Nf-S-A",,"10.5220/0010259002290236",,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the last years, the emerging field of Augmented & Virtual Reality
(AR-VR) has seen tremendousgrowth. At the same time there is a trend to develop
low cost high-quality AR systems where computing poweris in demand. Feature
points are extensively used in these real-time frame-rate and 3D applications,
thereforeefficient high-speed feature detectors are necessary. Corners are such
special features and often are used as thefirst step in the marker alignment in
Augmented Reality (AR). Corners are also used in image registration
andrecognition, tracking, SLAM, robot path finding and 2D or 3D object
detection and retrieval. Therefore thereis a large number of corner detection
algorithms but most of them are too computationally intensive for use
inreal-time applications of any complexity. Many times the border of the image
is a convex polygon. For thisspecial, but quite common case, we have developed
a specific algorithm, cMinMax. The proposed algorithmis faster, approximately
by a factor of 5 compared to the widely used Harris Corner Detection algorithm.
Inaddition is highly parallelizable. The algorithm is suitable for the fast
registration of markers in augmentedreality systems and in applications where a
computationally efficient real time feature detector is necessary.The algorithm
can also be extended to N-dimensional polyhedrons.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 00:32:11 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 15:11:00 GMT""},{""version"":""v3"",""created"":""Fri, 13 May 2022 19:33:33 GMT""}]","2022-05-17"
"2011.14036","Taro Makino","Taro Makino, Stanislaw Jastrzebski, Witold Oleszkiewicz, Celin Chacko,
  Robin Ehrenpreis, Naziya Samreen, Chloe Chhor, Eric Kim, Jiyon Lee, Kristine
  Pysarenko, Beatriu Reig, Hildegard Toth, Divya Awal, Linda Du, Alice Kim,
  James Park, Daniel K. Sodickson, Laura Heacock, Linda Moy, Kyunghyun Cho,
  Krzysztof J. Geras","Differences between human and machine perception in medical diagnosis",,,,,"eess.IV cs.CV cs.CY cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) show promise in image-based medical diagnosis,
but cannot be fully trusted since their performance can be severely degraded by
dataset shifts to which human perception remains invariant. If we can better
understand the differences between human and machine perception, we can
potentially characterize and mitigate this effect. We therefore propose a
framework for comparing human and machine perception in medical diagnosis. The
two are compared with respect to their sensitivity to the removal of clinically
meaningful information, and to the regions of an image deemed most suspicious.
Drawing inspiration from the natural image domain, we frame both comparisons in
terms of perturbation robustness. The novelty of our framework is that separate
analyses are performed for subgroups with clinically meaningful differences. We
argue that this is necessary in order to avert Simpson's paradox and draw
correct conclusions. We demonstrate our framework with a case study in breast
cancer screening, and reveal significant differences between radiologists and
DNNs. We compare the two with respect to their robustness to Gaussian low-pass
filtering, performing a subgroup analysis on microcalcifications and soft
tissue lesions. For microcalcifications, DNNs use a separate set of high
frequency components than radiologists, some of which lie outside the image
regions considered most suspicious by radiologists. These features run the risk
of being spurious, but if not, could represent potential new biomarkers. For
soft tissue lesions, the divergence between radiologists and DNNs is even
starker, with DNNs relying heavily on spurious high frequency components
ignored by radiologists. Importantly, this deviation in soft tissue lesions was
only observable through subgroup analysis, which highlights the importance of
incorporating medical domain knowledge into our comparison framework.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 00:32:17 GMT""}]","2020-12-01"
"2011.14037","Jussi Karlgren","Jussi Karlgren, Renee Li, Eva M Meyersson Milgrom","Text Mining for Processing Interview Data in Computational Social
  Science",,,,,"cs.CL","http://creativecommons.org/publicdomain/zero/1.0/","  We use commercially available text analysis technology to process interview
text data from a computational social science study. We find that topical
clustering and terminological enrichment provide for convenient exploration and
quantification of the responses. This makes it possible to generate and test
hypotheses and to compare textual and non-textual variables, and saves analyst
effort. We encourage studies in social science to use text analysis, especially
for exploratory open-ended studies. We discuss how replicability requirements
are met by text analysis technology. We note that the most recent learning
models are not designed with transparency in mind, and that research requires a
model to be editable and its decisions to be explainable. The tools available
today, such as the one used in the present study, are not built for processing
interview texts. While many of the variables under consideration are
quantifiable using lexical statistics, we find that some interesting and
potentially valuable features are difficult or impossible to automatise
reliably at present. We note that there are some potentially interesting
applications for traditional natural language processing mechanisms such as
named entity recognition and anaphora resolution in this application area. We
conclude with a suggestion for language technologists to investigate the
challenge of processing interview data comprehensively, especially the
interplay between question and response, and we encourage social science
researchers not to hesitate to use text analysis tools, especially for the
exploratory phase of processing interview data.?
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 00:44:35 GMT""}]","2020-12-01"
"2011.14038","Reza Afzali","N. Ebrahimian, M. Khosrojerdi, R. Afzali","Tuning of quantum entanglement of a superconductor by Transition-metal
  and Rare-earth impurity effect and the role of potential scattering on
  quantum phase transition","21 pages, 8 Figures",,,,"cond-mat.supr-con","http://creativecommons.org/licenses/by-nc-sa/4.0/","  By considering transition-metal (Shiba-Rusinov model) and rare-earth metal
impurities (Abrikosov-Gor'kov theory) effect on a many-body system, i.e., a BCS
s-wave superconductor, quantum bipartite entanglement of two electrons of the
Cooper pairs in terms of the exchange interaction, J, the potential scattering,
V (contrary to expectations playing an important role), and the distance of two
electron spins of the Cooper pair is calculated at zero temperature by using
two-electron spin-space density matrix (Werner state). In transition-metal
case, we found new quantum phase transitions (QPTs). The changes of J, which
causes to have localized excited state, V and the pair interaction (via energy
gap) lead to the displacement of the QPTs (interactions act in the same
direction, however sometimes the pair interaction causes the competition with
other interactions), regardless of their effects on the value of concurrence.
To have the turning point, which is a QPT point, by the reduction of |J|, the
system doesn't need to have the large V. For non-magnetic and magnetic
(rare-earth) impurity cases, the concurrence versus the distance and collision
times is discussed for all finite and infinite Debye frequency. The quantum
correlation, instability of the system and what's more important QPT can be
tuned by impurity.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 00:46:24 GMT""}]","2020-12-01"
"2011.14039","Samuel Stevens","Samuel Stevens and Yu Su","An Investigation of Language Model Interpretability via Sentence Editing","12 pages, 9 figures. Accepted at EMNLP BlackboxNLP 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Pre-trained language models (PLMs) like BERT are being used for almost all
language-related tasks, but interpreting their behavior still remains a
significant challenge and many important questions remain largely unanswered.
In this work, we re-purpose a sentence editing dataset, where faithful
high-quality human rationales can be automatically extracted and compared with
extracted model rationales, as a new testbed for interpretability. This enables
us to conduct a systematic investigation on an array of questions regarding
PLMs' interpretability, including the role of pre-training procedure,
comparison of rationale extraction methods, and different layers in the PLM.
The investigation generates new insights, for example, contrary to the common
understanding, we find that attention weights correlate well with human
rationales and work better than gradient-based saliency in extracting model
rationales. Both the dataset and code are available at
https://github.com/samuelstevens/sentence-editing-interpretability to
facilitate future interpretability research.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 00:46:43 GMT""},{""version"":""v2"",""created"":""Sun, 26 Sep 2021 18:36:37 GMT""}]","2021-09-28"
"2011.14040","Li Tang","Li Tang, Xin Li, Hai-Nan Lin, Liang Liu","Model-independently calibrating the luminosity correlations of gamma-ray
  bursts using deep learning","12 pages, 7 figures","ApJ 907 (2021) 121","10.3847/1538-4357/abcd92",,"astro-ph.CO astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gamma-ray bursts (GRBs) detected at high redshift can be used to trace the
Hubble diagram of the Universe. However, the distance calibration of GRBs is
not as easily as that of type Ia supernovae (SNe Ia). For the calibrating
method based on the empirical luminosity correlations, there is an underlying
assumption that the correlations should be universal over the whole redshift
range. In this paper, we investigate the possible redshift dependence of six
luminosity correlations with a completely model-independent deep learning
method. We construct a network combining the Recurrent Neural Networks (RNN)
and the Bayesian Neural Networks (BNN), where RNN is used to reconstruct the
distance-redshift relation by training the network with the Pantheon
compilation, and BNN is used to calculate the uncertainty of the
reconstruction. Using the reconstructed distance-redshift relation of Pantheon,
we test the redshift dependence of six luminosity correlations by dividing the
full GRB sample into two subsamples (low-$z$ and high-$z$ subsamples), and find
that only the $E_p-E_{\gamma}$ relation has no evidence for redshift
dependence. We use the $E_p-E_{\gamma}$ relation to calibrate GRBs, and the
calibrated GRBs give tight constraint on the flat $\Lambda$CDM model, with the
best-fitting parameter $\Omega_{\rm M}$=0.307$^{+0.065}_{-0.073}$.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 01:13:39 GMT""}]","2021-11-23"
"2011.14041","Deng Su","Deng Su, Dehong Chong","A RGB-D SLAM Algorithm for Indoor Dynamic Scene","in Chinese",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Visual slam technology is one of the key technologies for robot to explore
unknown environment independently. Accurate estimation of camera pose based on
visual sensor is the basis of autonomous navigation and positioning. However,
most visual slam algorithms are based on static environment assumption and
cannot estimate accurate camera pose in dynamic environment. In order to solve
this problem, a visual SLAM algorithm for indoor dynamic environment is
proposed. Firstly, some moving objects are eliminated based on the depth
information of RGB-D camera, and the initial camera pose is obtained by
optimizing the luminosity and depth errors, then the moving objects are further
eliminated. and, the initial static background is used for pose estimation
again. After several iterations, the more accurate static background and more
accurate camera pose is obtained. Experimental results show that, compared with
previous research results, the proposed algorithm can achieve higher pose
estimation accuracy in both low dynamic indoor scenes and high dynamic indoor
scenes.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 01:15:14 GMT""}]","2020-12-01"
"2011.14042","Sina Kheirkhah","Sajjad Mohammadnejad, Qiang An, Patrizio Vena, Sean Yun, Sina
  Kheirkhah","Contributions of flame thickening and local extinctions to burning rate
  of intensely turbulent premixed flames",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Influences of reaction zone thickening and local extinctions on the burning
rate of extremely turbulent hydrogen-enriched methane-air flames are
investigated using simultaneous planar laser-induced fluorescence of
formaldehyde molecule and hydroxyl radical as well as separate stereoscopic
particle image velocimetry techniques. Karlovitz numbers upto 76 are examined.
It is shown that, by increasing the turbulence intensity, the preheat and
reaction zone thicknesses can increase to values that are, respectively, 6.3
and 4.9 of the corresponding laminar flames. Broadening of these zones for
intensely turbulent hydrogen-enriched methane-air flames is shown
experimentally for the first time. Broadening of the reaction zone suggests
that the flamelet assumption used for development of the burning rate
formulations may not hold. Thus, a new formulation, which does not utilize the
flamelet assumption, is developed and used to calculate the burning rate of the
tested flames. It is shown that, at small turbulence intensities, the burning
rate values follow those of the local consumption speed, which is developed in
the literature based on the flamelet assumption. However, at large turbulence
intensities, the estimated burning rate features large values, and the ratio of
this parameter to the local consumption speed is consistent with the ratio of
the global and local consumption speeds reported in the literature. It is shown
that the ratio of the normalized burning rate to the normalized local
consumption speed is correlated with the broadening of reaction zone,
suggesting that the disparity between the values of the burning rate and local
consumption speed is linked to the reaction zone thickening. It is shown,
although the flame thickening increase the burning rate, local extinctions
decrease this parameter leading to the bending behavior reported in the
literature.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 01:17:12 GMT""}]","2020-12-01"
"2011.14043","Eng Leong Tan","Eng Leong Tan","Fundamental Schemes for Efficient Unconditionally Stable Implicit
  Finite-Difference Time-Domain Methods",,"IEEE Transactions on Antennas and Propagation, Vol. 56, No. 1, pp.
  170-177, January 2008","10.1109/TAP.2007.913089",,"math.NA cs.NA cs.SY eess.SY math.AP physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents the generalized formulations of fundamental schemes for
efficient unconditionally stable implicit finite-difference time-domain (FDTD)
methods. The fundamental schemes constitute a family of implicit schemes that
feature similar fundamental updating structures, which are in simplest forms
with most efficient right-hand sides. The formulations of fundamental schemes
are presented in terms of generalized matrix operator equations pertaining to
some classical splitting formulae, including those of alternating direction
implicit, locally one-dimensional and split-step schemes. To provide further
insights into the implications and significance of fundamental schemes, the
analyses are also extended to many other schemes with distinctive splitting
formulae. Detailed algorithms are described for new efficient implementations
of the unconditionally stable implicit FDTD methods based on the fundamental
schemes. A comparative study of various implicit schemes in their original and
new implementations is carried out, which includes comparisons of their
computation costs and efficiency gains.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 01:20:26 GMT""}]","2020-12-01"
"2011.14044","Tiago Soares","Tiago Lopes Soares","A Deductive Verification Framework For Higher Order Programs",,,,,"cs.LO cs.PL","http://creativecommons.org/licenses/by/4.0/","  In this report, we present the preliminary work developed for our research
project for the APDC (\'Area Pr\'atica de Desenvolvimento Curricular) course.
The main goal of this project is to develop a framework, on top of the Why3
tool, for the verification of effectful higher-order programs. We use
defunctionalization as an intermediate transformation from higher-order OCaml
implementations into first order ones. The target for our translation is WhyML,
the Why3's programming language. We believe defunctionalization can be an
interesting route for the automated verification of higher-order programs,
since one can employ off-the-shelf automated program verifiers to prove the
correctness of the generated first-order program. This report also serves to
introduce the reader to the subject of deductive program verification and some
of the tools and concepts used to prove higher order effectful programs.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 01:22:11 GMT""}]","2020-12-02"
"2011.14045","Ran Wang","Haojing Shen, Sihong Chen, Ran Wang and Xizhao Wang","Incorporating Hidden Layer representation into Adversarial Attacks and
  Defences",,,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a defence strategy to improve adversarial
robustness by incorporating hidden layer representation. The key of this
defence strategy aims to compress or filter input information including
adversarial perturbation. And this defence strategy can be regarded as an
activation function which can be applied to any kind of neural network. We also
prove theoretically the effectiveness of this defense strategy under certain
conditions. Besides, incorporating hidden layer representation we propose three
types of adversarial attacks to generate three types of adversarial examples,
respectively. The experiments show that our defence method can significantly
improve the adversarial robustness of deep neural networks which achieves the
state-of-the-art performance even though we do not adopt adversarial training.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 01:41:57 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 03:01:08 GMT""}]","2022-06-24"
"2011.14046","Huo Chen","Huo Chen and Daniel A. Lidar","HOQST: Hamiltonian Open Quantum System Toolkit","27 pages, 4 figures","Commun. Phys. 5, 112 (2022)","10.1038/s42005-022-00887-2",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an open-source software package called ""Hamiltonian Open Quantum
System Toolkit"" (HOQST), a collection of tools for the investigation of open
quantum system dynamics in Hamiltonian quantum computing, including both
quantum annealing and the gate-model of quantum computing. It features the key
master equations (MEs) used in the field, suitable for describing the reduced
system dynamics of an arbitrary time-dependent Hamiltonian with either weak or
strong coupling to infinite-dimensional quantum baths. This includes the
Redfield ME, the polaron-transformed Redfield ME, the adiabatic ME, the
coarse-grained ME, and the universal Lindblad ME. HOQST also includes the
stochastic Schrodinger equation with spin-fluctuators. We present an overview
of the theories behind the various MEs and provide examples to illustrate
typical workflows in HOQST. We present an example that shows that HOQST can
provide order of magnitude speedups compared to QuTiP, for problems with
time-dependent Hamiltonians. The package is ready to be deployed on
high-performance computing (HPC) clusters and is aimed at providing reliable
open-system analysis tools for noisy intermediate-scale quantum (NISQ) devices.
The HOQST Github repository (https://github.com/USCqserver/OpenQuantumTools.jl)
provides the starting point for users. Detailed information can be found in the
README file.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 01:45:02 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jun 2022 23:11:51 GMT""}]","2022-07-01"
"2011.14047","Cesar F. Caiafa","Cesar F. Caiafa, Ziyao Wang, Jordi Sol\'e-Casals, Qibin Zhao","Learning from Incomplete Features by Simultaneous Training of Neural
  Networks and Sparse Coding","11 pages, 7 figures, paper accepted for presentation at L2ID Workshop
  at CVPR 2021 (19-25 June, 2021)",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  In this paper, the problem of training a classifier on a dataset with
incomplete features is addressed. We assume that different subsets of features
(random or structured) are available at each data instance. This situation
typically occurs in the applications when not all the features are collected
for every data sample. A new supervised learning method is developed to train a
general classifier, such as a logistic regression or a deep neural network,
using only a subset of features per sample, while assuming sparse
representations of data vectors on an unknown dictionary. Sufficient conditions
are identified, such that, if it is possible to train a classifier on
incomplete observations so that their reconstructions are well separated by a
hyperplane, then the same classifier also correctly separates the original
(unobserved) data samples. Extensive simulation results on synthetic and
well-known datasets are presented that validate our theoretical findings and
demonstrate the effectiveness of the proposed method compared to traditional
data imputation approaches and one state-of-the-art algorithm.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 02:20:39 GMT""},{""version"":""v2"",""created"":""Sat, 17 Apr 2021 20:09:10 GMT""}]","2021-04-20"
"2011.14048","Amrith Setlur","Amrith Setlur, Oscar Li, Virginia Smith","Is Support Set Diversity Necessary for Meta-Learning?",,"NeurIPS 2020 Workshop on Meta-learning",,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Meta-learning is a popular framework for learning with limited data in which
an algorithm is produced by training over multiple few-shot learning tasks. For
classification problems, these tasks are typically constructed by sampling a
small number of support and query examples from a subset of the classes. While
conventional wisdom is that task diversity should improve the performance of
meta-learning, in this work we find evidence to the contrary: we propose a
modification to traditional meta-learning approaches in which we keep the
support sets fixed across tasks, thus reducing task diversity. Surprisingly, we
find that not only does this modification not result in adverse effects, it
almost always improves the performance for a variety of datasets and
meta-learning methods. We also provide several initial analyses to understand
this phenomenon. Our work serves to: (i) more closely investigate the effect of
support set construction for the problem of meta-learning, and (ii) suggest a
simple, general, and competitive baseline for few-shot learning.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 02:28:42 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 17:28:31 GMT""}]","2021-10-08"
"2011.14049","Sungyong Hwang","Sungyong Hwang, Myungshin Im, Yoon Chan Taak, Insu Paek, Changsu Choi,
  Suhyun Shin, Sang-Yun Lee, Tae-Geun Ji, Soojong Pak, Hye-In Lee, Hojae Ahn,
  Jimin Han, Changgon Kim, Jennifer Marshall, Christopher M. Johns-Krull, Coyne
  A. Gibson, Luke Schmidt, Travis Prochaska","Medium-band observation of the neutrino emitting blazar, TXS 0506+056","16 pages, 10 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abcd9a",,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  TXS 0506+056 is a blazar that has been recently identified as the counterpart
of the neutrino event IceCube-170922A. Understanding blazar type of TXS
0506+056 is important to constrain the neutrino emission mechanism, but the
blazar nature of TXS 0506+056 is still uncertain. As an attempt to understand
the nature of TXS 0506+056, we report the medium-band observation results of
TXS 0506+056, covering the wavelength range of 0.575 to 1.025 $\mu$m. The use
of the medium-band filters allow us to examine if there were any significant
changes in its spectral shapes over the course of one month and give a better
constraint on the peak frequency of synchrotron radiation with
quasi-simultaneous datasets. The peak frequency is found to be $10^{14.28}$ Hz,
and our analysis shows that TXS 0506+056 is not an outlier from the blazar
sequence. As a way to determine the blazar type, we also analyzed if TXS
0506+056 is bluer-when-brighter (BL Lac type and some flat spectrum radio
quasars, FSRQs) or redder-when-brighter (found only in some FSRQs). Even though
we detect no significant variability in the spectral shape larger than
observational error during our medium-band observation period, the comparison
with a dataset taken at 2012 shows a possible redder-when-brighter behavior of
FSRQs. Our results demonstrate that medium-band observations with small to
moderate-sized telescopes can be an effective way to trace the spectral
evolution of transients such as TXS 0506+056.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 02:37:25 GMT""}]","2021-02-24"
"2011.14050","Chenxi Ma","Chenxi Ma, Daming Zheng, Dominique Demaille, Bruno Gallas, Catherine
  Schwob, Thierry Pauport\'e, Laurent Coolen","Light management in highly-textured perovskite solar cells: From
  full-device ellipsometry characterization to optical modelling for quantum
  efficiency optimization","14 pages, 5 figures",,"10.1016/j.solmat.2021.111144",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While perovskite solar cells (PSCs) are now reaching high power conversion
efficiencies (PCEs), further performance improvement requires a fine management
and an optimization of the light pathway and harvesting in the cells. These go
through an accurate understanding, characterization and modelling of the
optical processes occurring in these complex, often textured, multi-layered
systems. In the present work, we have considered a typical methylammonium lead
iodide (MAPI) solar cell built on a fluorine-doped tin oxide (FTO) electrode of
high roughness (43 nm RMS). By variable-angle spectroscopic ellipsometry (VASE)
of the full PSC device, we have been able to determine the optical constants of
all the device layers. We have designed a one-dimensional (1D) optical model of
the stacked layers where the rough texture is described as layers of
effective-medium index. We have supported the model using data extracted from
scanning electron microscopy, diffuse spectroscopy and photovoltaic efficiency
measurements. We show that the 1D model, while insufficient to describe
scattering by the FTO plate alone, gives an accurate description of the full
device optical properties. By comparison with the experimental external quantum
efficiency (EQE), we estimate the internal quantum efficiency (IQE) and the
effect of the losses related to electron transfer. Based on this work, we
finally discuss the optical losses mechanisms and the possible strategies that
can be implemented to improve light management within PSC devices and further
increase their performances.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 02:39:58 GMT""}]","2021-11-11"
"2011.14051","Jing Li","Jing Li, Ling Ren, Dongning Guo","Close Latency--Security Trade-off for the Nakamoto Consensus","This work will be presented at the ACM Conference on Advances in
  Financial Technologies. This is the authors' version of the work with
  additional details in the appendix",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bitcoin is a peer-to-peer electronic cash system invented by Nakamoto in
2008. While it has attracted much research interest, its exact latency and
security properties remain open. Existing analyses provide security and latency
(or confirmation time) guarantees that are too loose for practical use. In fact
the best known upper bounds are several orders of magnitude larger than a lower
bound due to a well-known private-mining attack. This paper describes a
continuous-time model for blockchains and develops a rigorous analysis that
yields close upper and lower bounds for the latency--security trade-off. For
example, when the adversary controls 10\% of the total mining power and the
block propagation delays are within 10 seconds, a Bitcoin block is secured with
less than $10^{-3}$ error probability if it is confirmed after four hours, or
with less than $10^{-9}$ error probability if confirmed after ten hours. These
confirmation times are about two hours away from their corresponding lower
bounds. To establish such close bounds, the blockchain security question is
reduced to a race between the Poisson adversarial mining process and a renewal
process formed by a certain species of honest blocks. The moment generation
functions of relevant renewal times are derived in closed form. The general
formulas from the analysis are then applied to study the latency--security
trade-off of several well-known proof-of-work longest-chain cryptocurrencies.
Guidance is also provided on how to set parameters for different purposes.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:09:25 GMT""},{""version"":""v2"",""created"":""Tue, 20 Apr 2021 07:29:17 GMT""},{""version"":""v3"",""created"":""Mon, 31 May 2021 21:29:24 GMT""},{""version"":""v4"",""created"":""Tue, 7 Sep 2021 07:27:15 GMT""}]","2021-09-08"
"2011.14052","Ian Roque","I. L. V. Roque, W. J. Handley, N. Razavi-Ghods","Bayesian noise wave calibration for 21-cm global experiments","9 pages, 9 figures","Monthly Notices of the Royal Astronomical Society, Volume 505,
  Issue 2, August 2021, Pages 2638-2646","10.1093/mnras/stab1453",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Detection of millikelvin-level signals from the 'Cosmic Dawn' requires an
unprecedented level of sensitivity and systematic calibration. We report the
theory behind a novel calibration algorithm developed from the formalism
introduced by the EDGES collaboration for use in 21-cm experiments.
Improvements over previous approaches are provided through the incorporation of
a Bayesian framework and machine learning techniques such as the use of
Bayesian evidence to determine the level of frequency variation of calibration
parameters that is supported by the data, the consideration of correlation
between calibration parameters when determining their values and the use of a
conjugate-prior based approach that results in a fast algorithm for application
in the field. In self-consistency tests using empirical data models of varying
complexity, our methodology is used to calibrate a 50 $\Omega$
ambient-temperature load. The RMS error between the calibration solution and
the measured temperature of the load is 8 mK, well within the 1$\sigma$ noise
level. Whilst the methods described here are more applicable to global 21-cm
experiments, they can easily be adapted and applied to other applications,
including telescopes such as HERA and the SKA.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:10:40 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 04:57:54 GMT""},{""version"":""v3"",""created"":""Thu, 29 Apr 2021 19:40:13 GMT""},{""version"":""v4"",""created"":""Tue, 1 Jun 2021 05:12:49 GMT""}]","2022-09-15"
"2011.14053","Manoj Kumar Yennapureddy","Manoj K. Yennapureddy and Fulvio Melia","Structure formation and the matter power-spectrum in the R_h=ct universe","Accepted for publication in PDU",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Inflation drives quantum fluctuations beyond the Hubble horizon, freezing
them out before the small-scale modes re-enter during the radiation dominated
epoch, and subsequently decay, while large-scale modes re-enter later during
the matter dominated epoch and grow. This distinction shapes the matter power
spectrum and provides observational evidence in support of the standard model.
In this paper, we demonstrate that another mechanism, based on the fluctuation
growth in the R_h=ct universe, itself an FLRW cosmology with the added
constraint of zero active mass (i.e., rho+3p=0), also accounts very well for
the observed matter power spectrum, so this feature is not unique to LambdaCDM.
In R_h=ct, the shape of the matter power spectrum is set by the interplay
between the more rapid decay of the gravitational potential for the smaller
mode wavelengths and the longer dynamical timescale for the larger wavelengths.
This combination produces a characteristic peak that grows in both amplitude
and mode number as a function of time. Today, that peak lies at k approx 0.02
Mpc^-1, in agreement with the Ly-alpha and Planck data. But there is no need of
an inflationary expansion, and a complicated epoch dependence as one finds in
LambdaCDM.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:16:44 GMT""}]","2020-12-01"
"2011.14054","Junru Wu","Junru Wu, Xiang Yu, Buyu Liu, Zhangyang Wang, Manmohan Chandraker","Uncertainty-Aware Physically-Guided Proxy Tasks for Unseen Domain Face
  Anti-spoofing",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Face anti-spoofing (FAS) seeks to discriminate genuine faces from fake ones
arising from any type of spoofing attack. Due to the wide varieties of attacks,
it is implausible to obtain training data that spans all attack types. We
propose to leverage physical cues to attain better generalization on unseen
domains. As a specific demonstration, we use physically guided proxy cues such
as depth, reflection, and material to complement our main anti-spoofing (a.k.a
liveness detection) task, with the intuition that genuine faces across domains
have consistent face-like geometry, minimal reflection, and skin material. We
introduce a novel uncertainty-aware attention scheme that independently learns
to weigh the relative contributions of the main and proxy tasks, preventing the
over-confident issue with traditional attention modules. Further, we propose
attribute-assisted hard negative mining to disentangle liveness-irrelevant
features with liveness features during learning. We evaluate extensively on
public benchmarks with intra-dataset and inter-dataset protocols. Our method
achieves the superior performance especially in unseen domain generalization
for FAS.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:22:26 GMT""}]","2020-12-01"
"2011.14055","Kejun Li","KJ Li, JC Xu, JL Xie, W Feng","Differential rotation of the chromosphere in the He I absorption line","Accepted for publication in APJ Letters",,"10.3847/2041-8213/abcb84",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Differential rotation is the basis of the solar dynamo theory. Synoptic maps
of He I intensity from Carrington rotations 2032 to 2135 are utilized to
investigate the differential rotation of the solar chromosphere in the He I
absorption line. The chromosphere is surprisingly found to rotate faster than
the photosphere below it. The anomalous heating of the chromosphere and corona
has been a big problem in modern astronomy. It is speculated that the
small-scale magnetic elements with magnetic flux in the range of $(2.9 -
32.0)\times 10^{18}$ Mx which are anchored in the leptocline, heat the quiet
chromosphere to present the anomalous temperature increase, causing it to
rotate at the same rate as the leptocline. The differential of rotation rate in
the chromosphere is found to be strengthened by strong magnetic fields, but in
stark contrast, at the photosphere strong magnetic fields repress the
differential of rotation rate. A plausible explanation is given for these
findings.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:25:04 GMT""}]","2020-12-23"
"2011.14056","Anthony D'Arienzo","Anthony D'Arienzo (1), Vinny Pagano (1), Ian Johnson (1) ((1)
  Princeton University Department of Mathematics)","The 2-Categorical Structure of Predicate Theories","30 pages, 1 figure",,,,"math.LO math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The equivalence of formal languages with categories has long been expounded,
notably by [10.1007/BFb0066201], relating coherent categories with predicate
logic, where coherent functors serve as translations between predicate
theories. This equivalence yielded remarkable results connecting syntax to
semantics, but the formalism relied upon category theory. Work by
[arXiv:1506.04675,arxiv:1507.02302,10.1017/9781316275603] proposed syntactical
notions of equivalence and translation of theories. In this paper, we
demonstrate that these syntactical notions are equivalent to the categorical
formalism, allowing us to present Makkai and Reyes' conceptual completeness of
coherent logic in a syntactical form and to explain and remove the required
hypotheses of the translations in [10.1017/9781316275603]. Our equivalence
elucidates the relation between categorical equivalence and Morita equivalence,
and it reveals necessary and sufficient conditions for when a theory is
intertranslatable with or Morita equivalent to a propositional theory.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:26:45 GMT""}]","2020-12-01"
"2011.14057","Hans Riess","Hans Riess, Jakob Hansen, Robert Ghrist","Multidimensional Persistence Module Classification via Lattice-Theoretic
  Convolutions",,,,,"math.AT cs.LG eess.SP","http://creativecommons.org/licenses/by/4.0/","  Multiparameter persistent homology has been largely neglected as an input to
machine learning algorithms. We consider the use of lattice-based convolutional
neural network layers as a tool for the analysis of features arising from
multiparameter persistence modules. We find that these show promise as an
alternative to convolutions for the classification of multidimensional
persistence modules.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:28:39 GMT""},{""version"":""v2"",""created"":""Wed, 31 Aug 2022 12:54:00 GMT""}]","2022-09-01"
"2011.14058","Wei He","Zhongzhan Huang, Senwei Liang, Mingfu Liang, Wei He, Haizhao Yang","Efficient Attention Network: Accelerate Attention by Searching Where to
  Plug",,,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, many plug-and-play self-attention modules are proposed to enhance
the model generalization by exploiting the internal information of deep
convolutional neural networks (CNNs). Previous works lay an emphasis on the
design of attention module for specific functionality, e.g., light-weighted or
task-oriented attention. However, they ignore the importance of where to plug
in the attention module since they connect the modules individually with each
block of the entire CNN backbone for granted, leading to incremental
computational cost and number of parameters with the growth of network depth.
Thus, we propose a framework called Efficient Attention Network (EAN) to
improve the efficiency for the existing attention modules. In EAN, we leverage
the sharing mechanism (Huang et al. 2020) to share the attention module within
the backbone and search where to connect the shared attention module via
reinforcement learning. Finally, we obtain the attention network with sparse
connections between the backbone and modules, while (1) maintaining accuracy
(2) reducing extra parameter increment and (3) accelerating inference.
Extensive experiments on widely-used benchmarks and popular attention networks
show the effectiveness of EAN. Furthermore, we empirically illustrate that our
EAN has the capacity of transferring to other tasks and capturing the
informative features. The code is available at
https://github.com/gbup-group/EAN-efficient-attention-network.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:31:08 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jul 2021 12:44:58 GMT""}]","2021-07-13"
"2011.14059","Yanhong Annie Liu","Yanhong A. Liu and Matthew Castelllana","Discrete Math with Programming: A Principled Approach",,"Proceedings of the 52nd ACM Technical Symposium on Computer
  Science Education (SIGCSE 2021), pages 1156-1162, March 2021, ACM Press","10.1145/3408877.3432537",,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Discrete mathematics is the foundation of computer science. It focuses on
concepts and reasoning methods that are studied using math notations. It has
long been argued that discrete math is better taught with programming, which
takes concepts and computing methods and turns them into executable programs.
What has been lacking is a principled approach that supports all central
concepts of discrete math -- especially predicate logic -- and that directly
and precisely connects math notations with executable programs. This paper
introduces such an approach. It is based on the use of a powerful language that
extends the Python programming language with proper logic quantification (""for
all"" and ""exists some""), as well as declarative set comprehension (also known
as set builder) and aggregation (e.g., sum and product). Math and logical
statements can be expressed precisely at a high level and be executed directly
on a computer, encouraging declarative programming together with algorithmic
programming. We describe the approach, detailed examples, experience in using
it, and the lessons learned.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:41:27 GMT""}]","2021-10-07"
"2011.14060","Man-Ling Sung","Man-Ling Sung","Unsupervised Spoken Term Discovery on Untranscribed Speech","Thesis submitted in September 2019 for the M.Phil degree in
  Electronic Engineering at The Chinese University of Hong Kong (CUHK)",,,,"eess.AS","http://creativecommons.org/licenses/by/4.0/","  (Part of the abstract) In this thesis, we investigate the use of unsupervised
spoken term discovery in tackling this problem. Unsupervised spoken term
discovery aims to discover topic-related terminologies in a speech without
knowing the phonetic properties of the language and content. It can be further
divided into two parts: Acoustic segment modelling (ASM) and unsupervised
pattern discovery. ASM learns the phonetic structures of zero-resource language
audio with no phonetic knowledge available, generating self-derived ""phonemes"".
The audio are labelled with these ""phonemes"" to obtain ""phoneme"" sequences.
Unsupervised pattern discovery searches for repetitive patterns in the
""phoneme"" sequences. The discovered patterns can be grouped to determine the
keywords of the audio. Multilingual neural network with bottleneck layer is
used for feature extraction. Experiments show that bottleneck features
facilitate the training of ASM compared to conventional features such as MFCC.
The unsupervised spoken term discovery system is experimented with online
lectures covering different topics by different speakers. It is shown that the
system learns the phonetic information of the language and can discover
frequent spoken terms that align with text transcription. By using information
retrieval technology such as word embedding and TFIDF, it is shown that the
discovered keywords can be further used for topic comparison.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:46:04 GMT""}]","2020-12-01"
"2011.14061","Xiaolei Fang","Xiaolei Fang, Renjie Jin, Jinquan Luo, Wen Ma","New Galois Hulls of GRS Codes and Application to EAQECCs",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galois hulls of linear codes have important applications in quantum coding
theory. In this paper, we construct some new classes of (extended) generalized
Reed-Solomon (GRS) codes with Galois hulls of arbitrary dimensions. We also
propose a general method on constructing GRS codes with Galois hulls of
arbitrary dimensions from special Euclidean orthogonal GRS codes. Finally, we
construct several new families of entanglement-assisted quantum
error-correcting codes (EAQECCs) and MDS EAQECCs by utilizing the above
results.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:47:39 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 08:43:06 GMT""},{""version"":""v3"",""created"":""Sat, 31 Jul 2021 02:16:47 GMT""}]","2021-08-03"
"2011.14062","Man-Ling Sung","Man-Ling Sung, Tan Lee","Unsupervised Spoken Term Discovery Based on Re-clustering of
  Hypothesized Speech Segments with Siamese and Triplet Networks",,,,,"eess.AS cs.CL cs.SD","http://creativecommons.org/licenses/by/4.0/","  Spoken term discovery from untranscribed speech audio could be achieved via a
two-stage process. In the first stage, the unlabelled speech is decoded into a
sequence of subword units that are learned and modelled in an unsupervised
manner. In the second stage, partial sequence matching and clustering are
performed on the decoded subword sequences, resulting in a set of discovered
words or phrases. A limitation of this approach is that the results of subword
decoding could be erroneous, and the errors would impact the subsequent steps.
While Siamese/Triplet network is one approach to learn segment representations
that can improve the discovery process, the challenge in spoken term discovery
under a complete unsupervised scenario is that training examples are
unavailable. In this paper, we propose to generate training examples from
initial hypothesized sequence clusters. The Siamese/Triplet network is trained
on the hypothesized examples to measure the similarity between two speech
segments and hereby perform re-clustering of all hypothesized subword sequences
to achieve spoken term discovery. Experimental results show that the proposed
approach is effective in obtaining training examples for Siamese and Triplet
networks, improving the efficacy of spoken term discovery as compared with the
original two-stage method.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:52:38 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 21:06:44 GMT""}]","2021-06-04"
"2011.14063","Nicolas Capitelli","Pablo Leandro Bonucci and Nicol\'as Ariel Capitelli","Weak harmonic labeling of graphs and multigraphs","21 pages, 16 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we introduce the notion of weak harmonic labeling of a graph,
a generalization of the concept of harmonic labeling defined recently by
Benjamini et al. that allows extension to finite graphs and graphs with leaves.
We present various families of examples and provide several constructions that
extend a given weak harmonic labeling to larger graphs. In particular, we use
finite weak models to produce new examples of (strong) harmonic labelings. As a
main result, we provide a characterization of weakly labeled graphs in terms of
harmonic subsets of the integers and use it to compute every such graphs of up
to ten vertices. In particular, we characterize harmonically labeled graphs as
defined by Benjamini et al. We further extend the definitions and main results
to the case of multigraphs and total labelings.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:54:59 GMT""}]","2020-12-01"
"2011.14064","Xuehai Huang","Xuehai Huang and Yuling Shi and Wenqing Wang","A Morley-Wang-Xu element method for a fourth order elliptic singular
  perturbation problem","22 pages",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  A Morley-Wang-Xu (MWX) element method with a simply modified right hand side
is proposed for a fourth order elliptic singular perturbation problem, in which
the discrete bilinear form is standard as usual nonconforming finite element
methods. The sharp error analysis is given for this MWX element method. And the
Nitsche's technique is applied to the MXW element method to achieve the optimal
convergence rate in the case of the boundary layers. An important feature of
the MWX element method is solver-friendly. Based on a discrete Stokes complex
in two dimensions, the MWX element method is decoupled into one Lagrange
element method of Poisson equation, two Morley element methods of Poisson
equation and one nonconforming $P_1$-$P_0$ element method of Brinkman problem,
which implies efficient and robust solvers for the MWX element method. Some
numerical examples are provided to verify the theoretical results.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 04:00:34 GMT""}]","2020-12-01"
"2011.14065","Yingying Zhou","Yingying Zhou, Zhao-Yu Li, Iulia Simion, Juntai Shen, Shude Mao, Chao
  Liu, Mingjie Jian, Jos\'e. G. Fern\'andez-Trincado","Understanding the velocity distribution of the Galactic Bulge with
  APOGEE and Gaia","17 pages,13 figures",,"10.3847/1538-4357/abd181",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the stellar velocity distribution in the Galactic bulge/bar region
with APOGEE DR16 and {\it Gaia} DR2, focusing in particular on the possible
high-velocity (HV) peaks and their physical origin. We fit the velocity
distributions with two different models, namely with Gauss-Hermite polynomial
and Gaussian mixture model (GMM). The result of the fit using Gauss-Hermite
polynomials reveals a positive correlation between the mean velocity
($\bar{V}$) and the ""skewness"" ($h_{3}$) of the velocity distribution, possibly
caused by the Galactic bar. The $n=2$ GMM fitting reveals a symmetric
longitudinal trend of $|\mu_{2}|$ and $\sigma_{2}$ (the mean velocity and the
standard deviation of the secondary component), which is inconsistent to the
$x_{2}$ orbital family predictions. Cold secondary peaks could be seen at
$|l|\sim6^\circ$. However, with the additional tangential information from {\it
Gaia}, we find that the HV stars in the bulge show similar patterns in the
radial-tangential velocity distribution ($V_{\rm R}-V_{\rm T}$), regardless of
the existence of a distinct cold HV peak. The observed $V_{\rm R}-V_{\rm T}$
(or $V_{\rm GSR}-\mu_{l}$) distributions are consistent with the predictions of
a simple MW bar model. The chemical abundances and ages inferred from ASPCAP
and CANNON suggest that the HV stars in the bulge/bar are generally as old as,
if not older than, the other stars in the bulge/bar region.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 04:07:26 GMT""}]","2021-02-17"
"2011.14066","Vatsal Shah","Vatsal Shah, Soumya Basu, Anastasios Kyrillidis, Sujay Sanghavi","On Generalization of Adaptive Methods for Over-parameterized Linear
  Regression","arXiv admin note: substantial text overlap with arXiv:1811.07055",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over-parameterization and adaptive methods have played a crucial role in the
success of deep learning in the last decade. The widespread use of
over-parameterization has forced us to rethink generalization by bringing forth
new phenomena, such as implicit regularization of optimization algorithms and
double descent with training progression. A series of recent works have started
to shed light on these areas in the quest to understand -- why do neural
networks generalize well? The setting of over-parameterized linear regression
has provided key insights into understanding this mysterious behavior of neural
networks.
  In this paper, we aim to characterize the performance of adaptive methods in
the over-parameterized linear regression setting. First, we focus on two
sub-classes of adaptive methods depending on their generalization performance.
For the first class of adaptive methods, the parameter vector remains in the
span of the data and converges to the minimum norm solution like gradient
descent (GD). On the other hand, for the second class of adaptive methods, the
gradient rotation caused by the pre-conditioner matrix results in an in-span
component of the parameter vector that converges to the minimum norm solution
and the out-of-span component that saturates. Our experiments on
over-parameterized linear regression and deep neural networks support this
theory.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 04:19:32 GMT""}]","2020-12-01"
"2011.14067","Pantea Kiaei","Pantea Kiaei, Cees-Bart Breunesse, Mohsen Ahmadi, Patrick Schaumont,
  Jasper van Woudenberg","Rewrite to Reinforce: Rewriting the Binary to Apply Countermeasures
  against Fault Injection",,,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Fault injection attacks can cause errors in software for malicious purposes.
Oftentimes, vulnerable points of a program are detected after its development.
It is therefore critical for the user of the program to be able to apply
last-minute security assurance to the executable file without having access to
the source code. In this work, we explore two methodologies based on binary
rewriting that aid in injecting countermeasures in the binary file. The first
approach injects countermeasures by reassembling the disassembly whereas the
second approach leverages a full translation to a high-level IR and lowering
that back to the target architecture.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 04:37:29 GMT""}]","2020-12-01"
"2011.14068","Xiaozhong Xu","Xiaozhong Xu, Shan Liu","Overview of Screen Content Coding in Recently Developed Video Coding
  Standards","11 pages, 10 figures and 8 tables",,,,"cs.MM eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In recent years, screen content (SC) video including computer generated text,
graphics and animations, have drawn more attention than ever, as many related
applications become very popular. To address the need for efficient coding of
such contents, a number of coding tools have been specifically developed and
achieved great advances in terms of coding efficiency. The inclusion of screen
content coding (SCC) features in all the recently developed video coding
standards (namely, HEVC SCC, VVC, AVS3, AV1 and EVC) demonstrated the
importance of supporting such features. This paper provides an overview and
comparative study of screen content coding technologies, with discussions on
the performance and complexity aspects for the tools developed in these
standards.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 04:51:16 GMT""}]","2020-12-01"
"2011.14069","Jean Bertoin","Jean Bertoin","Counterbalancing steps at random in a random walk","To appear in J.Eur.Math.Soc",,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A random walk with counterbalanced steps is a process of partial sums $\check
S(n)=\check X_1+ \cdots + \check X_n$ whose steps $\check X_n$ are given
recursively as follows. For each $n\geq 2$, with a fixed probability $p$,
$\check X_n$ is a new independent sample from some fixed law $\mu$, and with
complementary probability $1-p$, $\check X_n= -\check X_{v(n)}$ counterbalances
a previous step, with $v(n)$ a uniform random pick from $\{1, \ldots, n-1\}$.
We determine the asymptotic behavior of $\check S(n)$ in terms of $p$ and the
first two moments of $\mu$. Our approach relies on a coupling with a
reinforcement algorithm due to H.A. Simon, and on properties of random
recursive trees and Eulerian numbers, which may be of independent interest. The
method can be adapted to the situation where the step distribution $\mu$
belongs to the domain of attraction of a stable law.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 05:32:33 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jul 2022 06:39:17 GMT""}]","2022-07-05"
"2011.14070","Declan McIntosh","Declan McIntosh, Tunai Porto Marques, Alexandra Branzan Albu, Rodney
  Rountree, Fabio De Leo","Movement Tracks for the Automatic Detection of Fish Behavior in Videos","8 pages, To be published in NeurIPS 2020 Workshop Tackling Climate
  Change with Machine Learning",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Global warming is predicted to profoundly impact ocean ecosystems. Fish
behavior is an important indicator of changes in such marine environments.
Thus, the automatic identification of key fish behavior in videos represents a
much needed tool for marine researchers, enabling them to study climate
change-related phenomena. We offer a dataset of sablefish (Anoplopoma fimbria)
startle behaviors in underwater videos, and investigate the use of deep
learning (DL) methods for behavior detection on it. Our proposed detection
system identifies fish instances using DL-based frameworks, determines
trajectory tracks, derives novel behavior-specific features, and employs Long
Short-Term Memory (LSTM) networks to identify startle behavior in sablefish.
Its performance is studied by comparing it with a state-of-the-art DL-based
video event detector.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 05:51:19 GMT""}]","2020-12-01"
"2011.14071","Sekhar Baishya","Sekhar Jyoti Baishya","Counting centralizers and z-classes of some F-groups",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  A finite group $G$ is called an F-group if for every $x, y \in G \setminus
Z(G)$, $C(x) \leq C(y)$ implies that $C(x) = C(y)$. On the otherhand, two
elements of a group are said to be $z$-equivalent or in the same $z$-class if
their centralizers are conjugate in the group. In this paper, for a finite
group, we give necessary and sufficient conditions for the number of
centralizers/ $z$-classes to be equal to the index of its center. We also give
a necessary and sufficient condition for the number of $z$-classes of a finite
F-group to attain its maximal number (which extends an earlier result). Among
other results, we have computed the number of element centralizers and
$z$-classes of some finite groups and extend some previous results.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 06:09:22 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 08:57:23 GMT""},{""version"":""v3"",""created"":""Sat, 11 Dec 2021 10:10:46 GMT""}]","2021-12-14"
"2011.14072","Arvind Kumar","Rajesh Kumar and Arvind Kumar","$\eta$ mesons in hot and dense asymmetric nuclear matter","30 Pages and 9 figures","Phys. Rev. C 102, 065207 (2020)","10.1103/PhysRevC.102.065207","065207","nucl-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the $\eta N$ interactions in the hot and dense isospin asymmetric
nuclear matter using two different approaches. In the first approach, the
in-medium mass and optical potential of $\eta$-meson have been calculated in
the chiral SU(3) model, considering the effect of explicit symmetry breaking
term and range terms in the $\eta N$ interaction Lagrangian density. In the
second scenario, the conjunction of chiral perturbation theory and chiral SU(3)
model is employed. In this case, the next-to-leading order $\eta N$
interactions are evaluated from the chiral perturbation theory (ChPT), and the
in-medium contribution of scalar densities are taken as input from chiral SU(3)
model. We observe a larger negative mass-shift in the ChPT+chiral model
approach compared to the chiral SU(3) model alone as a function of nuclear
density. Moreover, the increase in the asymmetry and temperature cause a
decrease in the magnitude of mass-shift. We have also studied the impact of
$\eta N$ scattering length $a^{\eta N}$ on the $\eta$ meson mass $m^*_\eta$ and
observed that the $m^*_\eta$ decrease more for increasing the value of
scattering length.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 06:15:11 GMT""}]","2021-01-04"
"2011.14073","Animesh Yadav","Animesh Yadav and Chen Quan and Pramod K. Varshney and H. Vincent Poor","On Performance Comparison of Multi-Antenna HD-NOMA, SCMA and PD-NOMA
  Schemes","Accepted to be Published in: IEEE Wireless Communications Letters",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the uplink channel throughput performance of a
proposed novel multiple-antenna hybrid-domain non-orthogonal multiple access
(MA-HD-NOMA) scheme. This scheme combines the conventional sparse code multiple
access (SCMA) and power-domain NOMA (PD-NOMA) schemes in order to increase the
number of users served as compared to conventional NOMA schemes and uses
multiple antennas at the base station. To this end, a joint resource allocation
problem for the MA-HD-NOMA scheme is formulated that maximizes the sum rate of
the entire system. For a comprehensive comparison, the joint resource
allocation problems for the multi-antenna SCMA (MA-SCMA) and multi-antenna
PD-NOMA (MA-PD-NOMA) schemes with the same overloading factor are formulated as
well. Each of the formulated problems is a mixed-integer non-convex program,
and hence, we apply successive convex approximation (SCA)- and reweighted
$\ell_1$ minimization-based approaches to obtain rapidly converging solutions.
Numerical results reveal that the proposed MA-HD-NOMA scheme has superior
performance compared to MA-SCMA and MA-PD-NOMA.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 06:20:04 GMT""}]","2020-12-01"
"2011.14074","Jordan Mitchell Barrett","Jordan Mitchell Barrett, Valentino Vito","On Ramsey-minimal infinite graphs","14 pages, 4 figures. The published version on EJC contains a minor
  error: in the proof of Lemma 20 on p10, in the last sentence of the last
  paragraph, it says ""The induced subgraph $F := \Gamma[x_1,\ldots,x_n]$"". This
  should read ""The subgraph of $\Gamma$ induced by all edges that are incident
  to at least one of $x_1, \ldots, x_n$"", and has been corrected in this arXiv
  version","The Electronic Journal of Combinatorics 28(1) (2021), #P1.46","10.37236/10046",,"math.CO math.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  For fixed finite graphs $G$, $H$, a common problem in Ramsey theory is to
study graphs $F$ such that $F \to (G,H)$, i.e. every red-blue coloring of the
edges of $F$ produces either a red $G$ or a blue $H$. We generalize this study
to infinite graphs $G$, $H$; in particular, we want to determine if there is a
minimal such $F$. This problem has strong connections to the study of
self-embeddable graphs: infinite graphs which properly contain a copy of
themselves. We prove some compactness results relating this problem to the
finite case, then give some general conditions for a pair $(G,H)$ to have a
Ramsey-minimal graph. We use these to prove, for example, that if $G=S_\infty$
is an infinite star and $H=nK_2$, $n \ge 1$ is a matching, then the pair
$(S_\infty,nK_2)$ admits no Ramsey-minimal graphs.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 06:34:56 GMT""},{""version"":""v2"",""created"":""Fri, 12 Feb 2021 20:27:24 GMT""},{""version"":""v3"",""created"":""Thu, 11 Mar 2021 19:46:22 GMT""}]","2021-03-15"
"2011.14075","Benjamin Laufer","Benjamin Laufer","Feedback Effects in Repeat-Use Criminal Risk Assessments","10 pages. arXiv admin note: substantial text overlap with
  arXiv:2005.13404",,,,"cs.CY cs.DS cs.LG cs.SI stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the criminal legal context, risk assessment algorithms are touted as
data-driven, well-tested tools. Studies known as validation tests are typically
cited by practitioners to show that a particular risk assessment algorithm has
predictive accuracy, establishes legitimate differences between risk groups,
and maintains some measure of group fairness in treatment. To establish these
important goals, most tests use a one-shot, single-point measurement. Using a
Polya Urn model, we explore the implication of feedback effects in sequential
scoring-decision processes. We show through simulation that risk can propagate
over sequential decisions in ways that are not captured by one-shot tests. For
example, even a very small or undetectable level of bias in risk allocation can
amplify over sequential risk-based decisions, leading to observable group
differences after a number of decision iterations. Risk assessment tools
operate in a highly complex and path-dependent process, fraught with historical
inequity. We conclude from this study that these tools do not properly account
for compounding effects, and require new approaches to development and
auditing.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 06:40:05 GMT""}]","2020-12-01"
"2011.14076","Aaron Babier","Aaron Babier, Binghao Zhang, Rafid Mahmood, Kevin L. Moore, Thomas G.
  Purdie, Andrea L. McNiven, Timothy C. Y. Chan","OpenKBP: The open-access knowledge-based planning grand challenge","26 pages, 6 figures, 5 tables",,"10.1002/mp.14845",,"physics.med-ph cs.CV","http://creativecommons.org/licenses/by/4.0/","  The purpose of this work is to advance fair and consistent comparisons of
dose prediction methods for knowledge-based planning (KBP) in radiation therapy
research. We hosted OpenKBP, a 2020 AAPM Grand Challenge, and challenged
participants to develop the best method for predicting the dose of contoured CT
images. The models were evaluated according to two separate scores: (1) dose
score, which evaluates the full 3D dose distributions, and (2) dose-volume
histogram (DVH) score, which evaluates a set DVH metrics. Participants were
given the data of 340 patients who were treated for head-and-neck cancer with
radiation therapy. The data was partitioned into training (n=200), validation
(n=40), and testing (n=100) datasets. All participants performed training and
validation with the corresponding datasets during the validation phase of the
Challenge, and we ranked the models in the testing phase based on out-of-sample
performance. The Challenge attracted 195 participants from 28 countries, and 73
of those participants formed 44 teams in the validation phase, which received a
total of 1750 submissions. The testing phase garnered submissions from 28
teams. On average, over the course of the validation phase, participants
improved the dose and DVH scores of their models by a factor of 2.7 and 5.7,
respectively. In the testing phase one model achieved significantly better dose
and DVH score than the runner-up models. Lastly, many of the top performing
teams reported using generalizable techniques (e.g., ensembles) to achieve
higher performance than their competition. This is the first competition for
knowledge-based planning research, and it helped launch the first platform for
comparing KBP prediction methods fairly and consistently. The OpenKBP datasets
are available publicly to help benchmark future KBP research, which has also
democratized KBP research by making it accessible to everyone.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 06:45:06 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jan 2021 19:46:18 GMT""}]","2021-11-17"
"2011.14077","Ishfaq Ahmad Rather","I. A. Rather, A. A. Usmani, S. K. Patra","Hadron-Quark phase transition in the context of GW190814","26 pages, 7 figures, 2 tables","J. Phys. G: Nucl. Part. Phys. (2021) 48, 085201","10.1088/1361-6471/ac0129",,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  The properties of the neutron stars are calculated for the hadronic matter
within the density-dependent relativistic mean-field model (DD-RMF). The phase
transition to the quark matter is studied and the hybrid star matter properties
are systematically calculated using the Vector-Enhanced Bag model (vBag). The
maximum mass of neutron star with DD-LZ1 and DD-RMF parameter sets is found to
be around 2.55$M_{\odot}$ for pure hadronic phase and around 2$M_{\odot}$ for
hadron-quark mixed phase using both Gibbs and Maxwell construction. The tidal
deformability for the hybrid EoS at 1.4$M_{\odot}$, $\Lambda_{1.4}$, remains
unchanged from the pure hadronic EoS with Maxwell construction, but decreases
with the increasing neutron star mass for Gibbs construction. While the pure
hadron matter EoS satisfies the mass constraint from recently observed GW190814
data, implying a stiff neutron star EoS, the hadron-quark phase transition
satisfies the constraints from the recent observations GW170817. Therefore, we
cannot exclude the possibility of the secondary object in GW190814 as a neutron
star with a phase transition to the quark matter that satisfies the
2$M_{\odot}$ maximum mass limit.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 07:15:05 GMT""},{""version"":""v2"",""created"":""Sat, 16 Jan 2021 14:16:32 GMT""},{""version"":""v3"",""created"":""Sun, 4 Jul 2021 04:29:43 GMT""},{""version"":""v4"",""created"":""Wed, 8 Sep 2021 04:54:04 GMT""}]","2021-09-09"
"2011.14078","Sambaran Bandyopadhyay","Sambaran Bandyopadhyay, Vishal Peter","Unsupervised Constrained Community Detection via Self-Expressive Graph
  Neural Network","This paper has been accepted as a full research paper at UAI 2021",,,,"cs.SI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Graph neural networks (GNNs) are able to achieve promising performance on
multiple graph downstream tasks such as node classification and link
prediction. Comparatively lesser work has been done to design GNNs which can
operate directly for community detection on graphs. Traditionally, GNNs are
trained on a semi-supervised or self-supervised loss function and then
clustering algorithms are applied to detect communities. However, such
decoupled approaches are inherently sub-optimal. Designing an unsupervised loss
function to train a GNN and extract communities in an integrated manner is a
fundamental challenge. To tackle this problem, we combine the principle of
self-expressiveness with the framework of self-supervised graph neural network
for unsupervised community detection for the first time in literature. Our
solution is trained in an end-to-end fashion and achieves state-of-the-art
community detection performance on multiple publicly available datasets.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 07:17:30 GMT""},{""version"":""v2"",""created"":""Tue, 19 Oct 2021 04:01:49 GMT""}]","2021-10-20"
"2011.14079","Vladimir Mikhailenko St","V. V. Mikhailenko, V. S. Mikhailenko, H. J. Lee","The ion-acoustic turbulence in the skin layer of the inductively coupled
  plasma","8 pages",,"10.1063/5.0039691",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The theory of the nonmodal ion-acoustic instability in the skin layer of the
inductively coupled plasma (ICP) is developed. This instability has time
dependent growth rate and is driven by the current formed in the skin layer by
the accelerated motion of electrons relative to ions under the action of the
ponderomotive force. It is found that the development of the ion acoustic
turbulence (IAT) in the skin layer and the scattering of electrons by IAT are
basic nonlinear channels of the nonlinear absorption of the RF energy in the
skin layer.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 07:25:56 GMT""},{""version"":""v2"",""created"":""Mon, 28 Dec 2020 15:27:18 GMT""}]","2021-11-24"
"2011.14080","Changeez Amini","Changeez Amini, Paeiz Azmi, and Seyed Sadra Kashef","Theoretical Accuracy Analysis of RSS-Based Range Estimation for Visible
  Light Communication","14 pages, 6 figures",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  In this paper, an improved channel model of visible light communication (VLC)
for ranging in presented. For indoor channel model of VLC, distance is
estimated based on received signal strength. In this model, received shot noise
as a distance-dependent parameter is considered in range estimation accuracy.
Moreover, based on this model, the Cramer-Rao lower bound is computed as the
theoretical limits on the performance and accuracy of any unbiased estimator.
In this way, the effects of horizontal and vertical distances are investigated.
In addition, the transmitted power effect on RSN and accordingly on CRLB is
demonstrated.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 07:31:15 GMT""}]","2020-12-01"
"2011.14081","Jake Bobowski","J. S. Bobowski","The Hydraulic Analogues of Basic Circuits: Labs for Online Learning
  Environments","8 pages, 5 figures",,,,"physics.ed-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper we describe a couple of exercises that we developed for our
online first-year EM course. The labs that we describe are focused on basic
concepts from circuit analysis, namely Ohm's law and charging a capacitor with
a constant voltage source and a series resistor. To give students a visual
demonstration of these concepts and, simultaneously, provide a means for
students to collect their own unique dataset, hydraulic analogues of these
electric circuits were built and a series of videos were recorded.
Incidentally, the visual demonstrations may also help to alleviate some of the
commonly-held student misconceptions about basic circuits. For this reason,
even once in-person labs resume, we expect that the hydraulic analogue
demonstrations will continue to be useful.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 07:35:39 GMT""}]","2020-12-01"
"2011.14082","Simone Selenu Dr","S. Selenu","Quantum body in uniform magnetic fields",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this article it will be presented the first attempt made in order to
perform gauge invariant calculations of eigenstates of a quantum body in its
condensed phase, the latter reacting to an external uniform magnetic field. The
target is achieved introducing a new unitary translation operator transforming
eigenstates into a new set of eigenstates having different total linear
momentum. This new quantum representation solves the problem of calculating the
magnetic response of quantum eigenstates of finite or either infinite periodic
systems to uniform magnetic fields, where equivalence between the customarily
used representation and the new representation has been made.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 07:49:12 GMT""}]","2020-12-01"
"2011.14083","Huangwei Zhang","Guangze Li, Huangwei Zhang, Longfei Chen","LES and finite-volume CMC modelling of a turbulent lifted H2/N2 flame:
  effects of CMC mesh resolution and numerical scheme",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large eddy simulations with three-dimensional finite-volume Conditional
Moment Closure (CMC) model are performed for a hydrogen / nitrogen lifted flame
with detailed chemical meachanism. The emphasis is laid on the influences of
mesh resolution and convection scheme of finite-volume CMC model on predictions
of reactive scalar distribution and unsteady flame dynamics. The results show
that the lift-off height is underestimated and the reactive scalars (e.g.
temperature, H2 and OH) are over-predicted with coarser CMC mesh. It is also
found that further refinement of the CMC mesh would not considerably improve
the results. The time sequences of the most reactive and stoichiometric OH mass
fractions indicate that finer CMC mesh can capture more unsteady details than
coarser CMC mesh. Moreover, the coarse CMC mesh has lower conditional scalar
dissipation rate, which would promote the ealier auto-ignition of the flame
base. Besides, the effects of the convection schemes in the CMC equations on
the lifted flame characteristics are also investigated. It is shown that
different convection schemes lead to limited differences on the time-averaged
temperature, mixture fraction and species mass fractions. Moreover, the RMS
values of H2 and OH mass fractions show larger deviation from the measurements
with hybrid upwind and central differencing scheme, especially around the flame
base. Furthermore, the distributions of the numerical flux on the CMC faces
also show obvious distinction between the upwind scheme and the blending
scheme. The budget analysis of the individual CMC terms shows that a sequence
of CMC faces has comparable contributions with upwind scheme. However, with the
hybrid schemes, the instantaneous flux is dominantly from limited CMC faces.
The reactivity of a CMC cell is more easily to be affected by its neighbors
when the upwind scheme is used.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 07:57:37 GMT""}]","2020-12-01"
"2011.14084","Ke Shen","Ke Shen and Mayank Kejriwal","A Data-Driven Study of Commonsense Knowledge using the ConceptNet
  Knowledge Base",,,,,"cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  Acquiring commonsense knowledge and reasoning is recognized as an important
frontier in achieving general Artificial Intelligence (AI). Recent research in
the Natural Language Processing (NLP) community has demonstrated significant
progress in this problem setting. Despite this progress, which is mainly on
multiple-choice question answering tasks in limited settings, there is still a
lack of understanding (especially at scale) of the nature of commonsense
knowledge itself. In this paper, we propose and conduct a systematic study to
enable a deeper understanding of commonsense knowledge by doing an empirical
and structural analysis of the ConceptNet knowledge base. ConceptNet is a
freely available knowledge base containing millions of commonsense assertions
presented in natural language. Detailed experimental results on three carefully
designed research questions, using state-of-the-art unsupervised graph
representation learning ('embedding') and clustering techniques, reveal deep
substructures in ConceptNet relations, allowing us to make data-driven and
computational claims about the meaning of phenomena such as 'context' that are
traditionally discussed only in qualitative terms. Furthermore, our methodology
provides a case study in how to use data-science and computational
methodologies for understanding the nature of an everyday (yet complex)
psychological phenomenon that is an essential feature of human intelligence.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 08:08:25 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 07:21:20 GMT""}]","2021-01-20"
"2011.14085","Ching-Chia Kao","Ching-Chia Kao, Jhe-Bang Ko, Chun-Shien Lu","Deterministic Certification to Adversarial Attacks via Bernstein
  Polynomial Approximation",,,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Randomized smoothing has established state-of-the-art provable robustness
against $\ell_2$ norm adversarial attacks with high probability. However, the
introduced Gaussian data augmentation causes a severe decrease in natural
accuracy. We come up with a question, ""Is it possible to construct a smoothed
classifier without randomization while maintaining natural accuracy?"". We find
the answer is definitely yes. We study how to transform any classifier into a
certified robust classifier based on a popular and elegant mathematical tool,
Bernstein polynomial. Our method provides a deterministic algorithm for
decision boundary smoothing. We also introduce a distinctive approach of
norm-independent certified robustness via numerical solutions of nonlinear
systems of equations. Theoretical analyses and experimental results indicate
that our method is promising for classifier smoothing and robustness
certification.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 08:27:42 GMT""}]","2020-12-01"
"2011.14086","Kouichi Hagino","Ki-Seok Choi, K. S. Kim, Myung-Ki Cheoun, W. Y. So, and K. Hagino","Fusion reaction of a weakly-bound nucleus with a deformed target","7 pages, 5 figures","Phys. Rev. C 103, 034611 (2021)","10.1103/PhysRevC.103.034611","KUNS-2844","nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  We discuss the role of deformation of the target nucleus in the fusion
reaction of the $^{15}$C + $^{232}$Th system at energies around the Coulomb
barrier, for which $^{15}$C is a well-known one-neutron halo nucleus. To this
end, we construct the potential between $^{15}$C and $^{232}$Th with the double
folding procedure, assuming that the projectile nucleus is composed of the core
nucleus, $^{14}$C, and a valance neutron. By taking into account the halo
nature of the projectile nucleus as well as the deformation of the target
nucleus, we simultaneously reproduce the fusion cross sections for the $^{14}$C
+ $^{232}$Th and the $^{15}$C + $^{232}$Th systems. Our calculation indicates
that the net effect of the breakup and the transfer channels is small for this
system.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 08:30:50 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jan 2021 03:32:59 GMT""}]","2021-03-24"
"2011.14087","Paul Wimmer","Paul Wimmer, Jens Mehnert and Alexandru Condurache","FreezeNet: Full Performance by Reduced Storage Costs","Conference Paper of the Asian Conference on Computer Vision (ACCV)
  2020","ACCV (6) 2020: 685-701","10.1007/978-3-030-69544-6_41",,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pruning generates sparse networks by setting parameters to zero. In this work
we improve one-shot pruning methods, applied before training, without adding
any additional storage costs while preserving the sparse gradient computations.
The main difference to pruning is that we do not sparsify the network's weights
but learn just a few key parameters and keep the other ones fixed at their
random initialized value. This mechanism is called freezing the parameters.
Those frozen weights can be stored efficiently with a single 32bit random seed
number. The parameters to be frozen are determined one-shot by a single for-
and backward pass applied before training starts. We call the introduced method
FreezeNet. In our experiments we show that FreezeNets achieve good results,
especially for extreme freezing rates. Freezing weights preserves the gradient
flow throughout the network and consequently, FreezeNets train better and have
an increased capacity compared to their pruned counterparts. On the
classification tasks MNIST and CIFAR-10/100 we outperform SNIP, in this setting
the best reported one-shot pruning method, applied before training. On MNIST,
FreezeNet achieves 99.2% performance of the baseline LeNet-5-Caffe
architecture, while compressing the number of trained and stored parameters by
a factor of x 157.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 08:32:44 GMT""}]","2022-03-17"
"2011.14088","Yu Feng","Yu Feng, Bingyang Hu and Xiaoqian Xu","Suppression of epitaxial thin film growth by mixing","33 pages. Fixed an error in the proof of Theorem 3.8",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider following fourth-order parabolic equation with gradient
nonlinearity on the two-dimensional torus with and without advection of an
incompressible vector field in the case $2<p<3$: \begin{equation*}
  \partial_t u + (-\Delta)^2 u = -\nabla\cdot(|\nabla u|^{p-2}\nabla u).
\end{equation*} The study of this form of equations arises from mathematical
models that simulate the epitaxial growth of the thin film. We prove the local
existence of mild solutions for any initial data lies in $L^2$ in both cases.
Our main result is: in the advective case, if the imposed advection is
sufficiently mixing, then the global existence of solution can be proved, and
the solution will converge exponentially to a homogeneous mixed state. While in
the absence of advection, there exist initial data in $H^2\cap W^{1,\infty}$
such that the solution will blow up in finite time.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 08:35:43 GMT""},{""version"":""v2"",""created"":""Sun, 10 Jan 2021 06:52:58 GMT""},{""version"":""v3"",""created"":""Fri, 23 Jul 2021 02:45:41 GMT""},{""version"":""v4"",""created"":""Mon, 23 Aug 2021 15:22:12 GMT""}]","2021-08-24"
"2011.14089","Baudouin Denis de Senneville PhD","Baudouin Denis de Senneville, Chrit Moonen, Mario Ries","MRI-guided HIFU Methods for the Ablation of Liver and Renal Cancers","28 pages, 6 figures","Therapeutic Ultrasound, 2016",,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MRI-guided High Intensity Focused Ultrasound (MRI-HIFU) is a promising method
for the non-invasive ablation of pathological tissue in many organs, including
mobile organs such as liver and kidney. The possibility to locally deposit
thermal energy in a non-invasive way opens a path towards new therapeutic
strategies with improved reliability and reduced associated trauma, leading to
improved efficacy, reduced hospitalization and costs. Liver and kidney tumors
represent a major health problem because not all patients are suitable for
curative treatment with surgery. Currently, radio-frequency is the most used
method for percutaneous ablation. The development of a completely non-invasive
method based on MR guided high intensity focused ultrasound (HIFU) treatments
is of particular interest due to the associated reduced burden for the patient,
treatment related patient morbidity and complication rate. The objective of
MR-guidance is hereby to control heat deposition with HIFU within the targeted
pathological area, despite the physiological motion of these organs, in order
to provide an effective treatment with a reduced duration and an increased
level of patient safety. Regarding this, several technological challenges have
to be addressed: Firstly, the anatomical location of both organs within the
thoracic cage requires inter-costal ablation strategies, which preserve the
therapeutic efficiency, but prevent undesired tissue damage to the ribs and the
intercostal muscle. Secondly, both therapy guidance and energy deposition have
to be rendered compatible with the continuous physiological motion of the
abdomen.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:02:34 GMT""}]","2020-12-01"
"2011.14090","Tao Xiong","Tao Xiong and Wenjun Sun and Yi Shi and Peng Song","High order asymptotic preserving discontinuous Galerkin methods for gray
  radiative transfer equations",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we will develop a class of high order asymptotic preserving
(AP) discontinuous Galerkin (DG) methods for nonlinear time-dependent gray
radiative transfer equations (GRTEs). Inspired by the work
\cite{Peng2020stability}, in which stability enhanced high order AP DG methods
are proposed for linear transport equations, we propose to pernalize the
nonlinear GRTEs under the micro-macro decomposition framework by adding a
weighted linear diffusive term. In the diffusive limit, a hyperbolic, namely
$\Delta t=\mathcal{O}(h)$ where $\Delta t$ and $h$ are the time step and mesh
size respectively, instead of parabolic $\Delta t=\mathcal{O}(h^2)$ time step
restriction is obtained, which is also free from the photon mean free path. The
main new ingredient is that we further employ a Picard iteration with a
predictor-corrector procedure, to decouple the resulting global nonlinear
system to a linear system with local nonlinear algebraic equations from an
outer iterative loop. Our scheme is shown to be asymptotic preserving and
asymptotically accurate. Numerical tests for one and two spatial dimensional
problems are performed to demonstrate that our scheme is of high order,
effective and efficient.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:04:11 GMT""}]","2020-12-01"
"2011.14091","Liding Huang","Liding Huang, Jiaogen Zhang and Xi Zhang","The deformed Hermitian-Yang-Mills equation on almost Hermitian manifolds",,"SCIENCE CHINA Mathematics 2020",,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the deformed Hermitian-Yang-Mills equation on
closed almost Hermitian manifolds. In the case of hypercritical phase, we
derive a priori estimates under the existence of an admissible
$\mathcal{C}$-subsolution. As an application, we prove the existence of
solutions for the deformed Hermitian-Yang-Mills equation under the condition of
existence of a supersolution.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:06:19 GMT""}]","2020-12-01"
"2011.14092","Lei Zhang","Lei Zhang, Richard N. Manchester, Andrew D. Cameron, George Hobbs, Di
  Li, Shi Dai, Qijun Zhi, Zonghong Zhu, Jingbo Wang, Lawrence Toomey, Yi Feng,
  Shuangqiang Wang, Songbo Zhang","Wideband Monitoring Observations of PSR J1803-3002A in the Globular
  Cluster NGC 6522",,,"10.3847/2041-8213/abca40",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the first wideband monitoring observations of PSR J1803-3002A, a
relatively bright millisecond pulsar in the globular cluster NGC 6522 with a
spin period of 7.1 ms and no known binary companion. These observations were
performed using the Parkes 64-m radio telescope with the Ultra-Wideband Low
(UWL) receiver system, which covers 704 to 4032 MHz. We confirm that PSR
J1803-3002A is an isolated millisecond pulsar located near the cluster center
and probe the emission properties of the pulsar over the wide observed band.
The mean pulse profile consists of three components, with the outer components
becoming more prominent at higher frequencies, and a mean spectral index for
the pulsed emission of -1.66+/-0.07 over the observed band. The fractional
linear and circular polarization increase with increasing frequency, which is
unusual for pulsars. We determine a Faraday rotation measure of -107+/-6 rad
m-2 for the pulsar. PSR J1803-3002A is a distant pulsar in the Galactic plane,
but there is no evidence of pulse broadening due to interstellar scattering in
our observations. These results demonstrate the power of ultra-wideband
receiving and signal processing systems.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:11:05 GMT""}]","2020-12-16"
"2011.14093","Martin \v{S}vec","Ji\v{r}\'i Dole\v{z}al, Sofia Canola, Pablo Merino, Martin \v{S}vec","Exciton-trion dynamics of a single molecule in a radio-frequency cavity",,"ACS Nano 2021, 15, 7694-7699","10.1021/acsnano.1c01318",,"physics.atm-clus quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Charged optical excitations (trions) generated by charge carrier injection
are crucial for emerging optoelectronic technologies as they can be produced
and manipulated by electric fields. Trions and neutral excitons can be
efficiently induced in single molecules by means of tip-enhanced
spectromicroscopic techniques. However, little is known of the exciton-trion
dynamics at single molecule level as this requires methods permitting
simultaneous sub-nanometer and sub-nanosecond characterization. Here, we
investigate exciton-trion dynamics by phase fluorometry, combining
radio-frequency modulated scanning tunnelling luminescence with time-resolved
single photon detection. We generate excitons and trions in single Zinc
Phthalocyanine (ZnPc) molecules on NaCl/Ag(111), determine their dynamics and
trace the evolution of the system in the picosecond range with atomic
resolution. In addition, we explore dependence of effective lifetimes on bias
voltage and propose a conversion of neutral excitons into trions via charge
capture as the primary mechanism of trion formation.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:17:34 GMT""}]","2021-12-23"
"2011.14094","Demetrio Lacava","Giampiero M. Gallo, Demetrio Lacava and Edoardo Otranto","On Classifying the Effects of Policy Announcements on Volatility","23 pages, 2 figures",,,,"q-fin.GN econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  The financial turmoil surrounding the Great Recession called for
unprecedented intervention by Central Banks: unconventional policies affected
various areas in the economy, including stock market volatility. In order to
evaluate such effects, by including Markov Switching dynamics within a recent
Multiplicative Error Model, we propose a model--based classification of the
dates of a Central Bank's announcements to distinguish the cases where the
announcement implies an increase or a decrease in volatility, or no effect. In
detail, we propose two smoothed probability--based classification methods,
obtained as a by--product of the model estimation, which provide very similar
results to those coming from a classical k--means clustering procedure. The
application on four Eurozone market volatility series shows a successful
classification of 144 European Central Bank announcements.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:23:15 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 18:19:17 GMT""}]","2021-02-23"
"2011.14095","Seokchang Hong","Seokchang Hong","Global well-posedness and scattering of the energy critical
  Maxwell-Klein-Gordon system in the Lorenz gauge","20pages, Introduction is revised",,,,"math.AP","http://creativecommons.org/publicdomain/zero/1.0/","  We study initial value problem of the $(1+4)$-dimensional
Maxwell-Klein-Gordon system (MKG) in the Lorenz gauge. Since (MKG) in the
Lorenz gauge does not possess an obvious null structure, it is not easy to
handle the nonlinearity. To overcome this obstacle, we impose an additional
angular regularity. In this paper, we prove global well-posedness and
scattering of (MKG) for small data in a scale-invariant space which has extra
weighted regularity in the angular variables. Our main improvement is to attain
the scaling critical regularity exponent and prove global existence of
solutions to (MKG) in the Lorenz gauge.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:23:21 GMT""},{""version"":""v2"",""created"":""Sun, 20 Jun 2021 07:48:37 GMT""}]","2021-06-22"
"2011.14096","Shunya Saito","Shunya Saito","Tilting objects in periodic triangulated categories","23 pages, Added new and corrected an error in the previous version,
  comments welcome",,,,"math.RT math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A triangulated category $\mathcal{T}$ whose suspension functor $\Sigma$
satisfies $\Sigma^m \simeq \mathrm{Id}_{\mathcal{T}}$ as additive functors is
called an $m$-periodic triangulated category. Such a category does not have a
tilting object by the periodicity. In this paper, we introduce the notion of an
$m$-periodic tilting object in an $m$-periodic triangulated category, which is
a periodic analogue of a tilting object in a triangulated category, and prove
that an $m$-periodic triangulated category having an $m$-periodic tilting
object is triangulated equivalent to the $m$-periodic derived category of an
algebra under some homological assumptions. As an application, we construct a
triangulated equivalence between the stable category of a self-injective
algebra and the $m$-periodic derived category of a hereditary algebra.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:23:53 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 08:34:39 GMT""}]","2021-06-08"
"2011.14097","Shohreh Deldari","Shohreh Deldari, Daniel V. Smith, Hao Xue, Flora D. Salim","Time Series Change Point Detection with Self-Supervised Contrastive
  Predictive Coding","Accepted at The WEB Conference 2021 (WWW'21)",,"10.1145/3442381.3449903",,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Change Point Detection (CPD) methods identify the times associated with
changes in the trends and properties of time series data in order to describe
the underlying behaviour of the system. For instance, detecting the changes and
anomalies associated with web service usage, application usage or human
behaviour can provide valuable insights for downstream modelling tasks. We
propose a novel approach for self-supervised Time Series Change Point detection
method based onContrastivePredictive coding (TS-CP^2). TS-CP^2 is the first
approach to employ a contrastive learning strategy for CPD by learning an
embedded representation that separates pairs of embeddings of time adjacent
intervals from pairs of interval embeddings separated across time. Through
extensive experiments on three diverse, widely used time series datasets, we
demonstrate that our method outperforms five state-of-the-art CPD methods,
which include unsupervised and semi-supervisedapproaches. TS-CP^2 is shown to
improve the performance of methods that use either handcrafted statistical or
temporal features by 79.4% and deep learning-based methods by 17.0% with
respect to the F1-score averaged across the three datasets.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:36:18 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 23:21:33 GMT""},{""version"":""v3"",""created"":""Mon, 8 Feb 2021 22:26:19 GMT""},{""version"":""v4"",""created"":""Fri, 26 Feb 2021 09:20:41 GMT""},{""version"":""v5"",""created"":""Fri, 5 Mar 2021 00:24:56 GMT""}]","2021-03-08"
"2011.14098","Anke Pohl","Anke Pohl","Symbolic dynamics and transfer operators for Weyl chamber flows: a class
  of examples","22 pages",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide special cross sections for the Weyl chamber flow on a sample class
of Riemannian locally symmetric spaces of higher rank, namely the direct
product spaces of Schottky surfaces. We further present multi-parameter
transfer operator families for the discrete dynamical systems on Furstenberg
boundary that are related to these cross sections.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:36:52 GMT""}]","2020-12-01"
"2011.14099","Satoshi Aya","Jinxing Li, Hiroya Nishikawa, Junichi Kougo, Junchen Zhou, Shuqi Dai,
  Wentao Tang, Xiuhu Zhao, Yuki Hisai, Mingjun Huang, Satoshi Aya","Development of polar nematic fluids with giant-\k{appa} dielectric
  properties",,,"10.1126/sciadv.abf5047",,"cond-mat.mtrl-sci physics.optics","http://creativecommons.org/licenses/by/4.0/","  Super-high-\k{appa} materials that exhibit exceptionally high dielectric
permittivity are recognized as potential candidates for a wide range of
next-generation photonic and electronic devices. Generally, the high
dielectricity for achieving a high-\k{appa} state requires a low symmetry of
materials so that most of the discovered high-\k{appa} materials are
symmetry-broken crystals. There are scarce reports on fluidic high-\k{appa}
dielectrics. Here we demonstrate a rational molecular design, supported by
machine-learning analyses, that introduces high polarity to asymmetric
molecules, successfully realizing super-high-\k{appa} fluid materials
(dielectric permittivity, {\epsilon} > 104) and strong second harmonic
generation with macroscopic spontaneous polar ordering. The polar structures
are confirmed to be identical for all the synthesized materials. Our
experiments and computational calculation reveal the unique orientational
structures coupled with the emerging polarity. Furthermore, adopting this
strategy to high-molecular-weight systems additionally extends the novel
material category from monomer to polar polymer materials, creating polar soft
matters with spontaneous symmetry breaking.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:38:32 GMT""}]","2021-04-26"
"2011.14100","Peyman Niroomand","Afsaneh Shamsaki, Peyman Niroomand","On the triple tensor product of nilpotent Lie algebras","Some typo errors are corrected in this version. The final version
  will be published at journal of Linear and Multilinear Algebras with some
  revisions on the current version",,"10.1080/03081087.2021.1932711",,"math.RA math.AC","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we give the explicit structure of $ \otimes^{3} H $ and $
\wedge^{3} H $ where $ H $ is a generalized Heisenberg Lie algebra of rank at
most $ 2. $ Moreover, for a non-abelian nilpotent Lie algebra $ L, $ we obtain
an upper bound for the dimension of $ \otimes^{3} L.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:54:22 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 11:42:18 GMT""}]","2021-05-21"
"2011.14101","Florian Dubost","Florian Dubost, Erin Hong, Nandita Bhaskhar, Siyi Tang, Daniel Rubin,
  Christopher Lee-Messer","Semi-Supervised Learning for Sparsely-Labeled Sequential Data:
  Application to Healthcare Video Processing",,"In Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision, 2023",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Labeled data is a critical resource for training and evaluating machine
learning models. However, many real-life datasets are only partially labeled.
We propose a semi-supervised machine learning training strategy to improve
event detection performance on sequential data, such as video recordings, when
only sparse labels are available, such as event start times without their
corresponding end times. Our method uses noisy guesses of the events' end times
to train event detection models. Depending on how conservative these guesses
are, mislabeled samples may be introduced into the training set. We further
propose a mathematical model for explaining and estimating the evolution of the
classification performance for increasingly noisier end time estimates. We show
that neural networks can improve their detection performance by leveraging more
training data with less conservative approximations despite the higher
proportion of incorrect labels. We adapt sequential versions of CIFAR-10 and
MNIST, and use the Berkeley MHAD and HMBD51 video datasets to empirically
evaluate our method, and find that our risk-tolerant strategy outperforms
conservative estimates by 3.5 points of mean average precision for CIFAR, 30
points for MNIST, 3 points for MHAD, and 14 points for HMBD51. Then, we
leverage the proposed training strategy to tackle a real-life application:
processing continuous video recordings of epilepsy patients, and show that our
method outperforms baseline labeling methods by 17 points of average precision,
and reaches a classification performance similar to that of fully supervised
models. We share part of the code for this article.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:54:44 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 09:00:37 GMT""},{""version"":""v3"",""created"":""Thu, 25 Mar 2021 20:48:00 GMT""},{""version"":""v4"",""created"":""Fri, 17 Sep 2021 02:51:03 GMT""},{""version"":""v5"",""created"":""Sat, 1 Oct 2022 18:25:20 GMT""}]","2022-10-05"
"2011.14102","Hossein Aghamiry","Ali Gholami, Hossein S. Aghamiry, and Stephane Operto","Extended full waveform inversion in the time domain by the augmented
  Lagrangian method",,,"10.1190/geo2021-0186.1",,"math.NA cs.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extended full-waveform inversion (FWI) has shown promising results for
accurate estimation of subsurface parameters when the initial models are not
sufficiently accurate. Frequency-domain applications have shown that the
augmented Lagrangian (AL) method solves the inverse problem accurately with a
minimal effect of the penalty parameter choice. Applying this method in the
time domain, however, is limited by two main factors: (1) The challenge of
data-assimilated wavefield reconstruction due to the lack of an explicit
time-stepping and (2) The need to store the Lagrange multipliers, which is not
feasible for the field-scale problems. We show that these wavefields are
efficiently determined from the associated data (projection of the wavefields
onto the receivers space) by using explicit time stepping. Accordingly, based
on the augmented Lagrangian, a new algorithm is proposed which performs in
""data space"" (a lower dimensional subspace of the full space) in which the
wavefield reconstruction step is replaced by reconstruction of the associated
data, thus requiring optimization in a lower dimensional space (convenient for
handling the Lagrange multipliers). We show that this new algorithm can be
implemented efficiently in the time domain with existing solvers for the FWI
and at a cost comparable to that of the FWI while benefiting from the
robustness of the extended FWI formulation. The results obtained by numerical
examples show high-performance of the proposed method for large scale
time-domain FWI.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:57:05 GMT""}]","2021-09-16"
"2011.14103","Chuang-Shi Shen","Chuang-Shi Shen, Chun-Lin Du, Huan-Fang Wang, Chao Zhang","Cutting and tearing thin elastic sheets: two novel single-period cracks
  and the first period-doubling crack","5 pages, 7 figures",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two novel single-period cracks were observed in experiments of cutting a
folded sheet with a blunt object and tearing a thin brittle sheet under the
guidance of a meterstick. Additionally, we observed a period-doubling crack in
the tearing experiment. We cut and tore the sheet in different directions. The
experimental results suggested that the anisotropy of the thin sheet played an
important role in the formation of these two types of saw-tooth cracks. We
demonstrated that the formation of the period-doubling crack was closely
correlated with the changing of the contact region between the sheet and the
meterstick. We also showed that the growth process of crack made by cutting was
a logistic growth process (S-curve), while the cracks made by tearing
propagated in the form of approximate power-law function.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 10:22:23 GMT""},{""version"":""v2"",""created"":""Wed, 9 Dec 2020 23:22:52 GMT""}]","2020-12-11"
"2011.14104","Alexander Zlotnik","Alexander Zlotnik, Olga Kireeva","On compact 4th order finite-difference schemes for the wave equation","22 pages, 4 figures, 2 tables",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider compact finite-difference schemes of the 4th approximation order
for an initial-boundary value problem (IBVP) for the $n$-dimensional
non-homogeneous wave equation, $n\geq 1$. Their construction is accomplished by
both the classical Numerov approach and alternative technique based on
averaging of the equation, together with further necessary improvements of the
arising scheme for $n\geq 2$. The alternative technique is applicable to other
types of PDEs including parabolic and time-dependent Schr\""{o}dinger ones. The
schemes are implicit and three-point in each spatial direction and time and
include a scheme with a splitting operator for $n\geq 2$. For $n=1$ and the
mesh on characteristics, the 4th order scheme becomes explicit and close to an
exact four-point scheme. We present a conditional stability theorem covering
the cases of stability in strong and weak energy norms with respect to both
initial functions and free term in the equation. Its corollary ensures the 4th
order error bound in the case of smooth solutions to the IBVP. The main schemes
are generalized for non-uniform rectangular meshes. We also give results of
numerical experiments showing the sensitive dependence of the error orders in
three norms on the weak smoothness order of the initial functions and free term
and essential advantages over the 2nd approximation order schemes in the
non-smooth case as well.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 10:22:39 GMT""},{""version"":""v2"",""created"":""Sat, 23 Jan 2021 07:44:06 GMT""}]","2021-01-26"
"2011.14105","Haibin Shao","Chongzhi Wang, Lulu Pan, Haibin Shao, Dewei Li, Yugeng Xi","Characterizing Bipartite Consensus on Signed Matrix-Weighted Networks
  via Balancing Set",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In contrast with the scalar-weighted networks, where bipartite consensus can
be achieved if and only if the underlying signed network is structurally
balanced, the structural balance property is no longer a graph-theoretic
equivalence to the bipartite consensus in the case of signed matrix-weighted
networks. To re-establish the relationship between the network structure and
the bipartite consensus solution, the non-trivial balancing set is introduced
which is a set of edges whose sign negation can transform a structurally
imbalanced network into a structurally balanced one and the weight matrices
associated with edges in this set have a non-trivial intersection of null
spaces. We show that necessary and/or sufficient conditions for bipartite
consensus on matrix-weighted networks can be characterized by the uniqueness of
the non-trivial balancing set, while the contribution of the associated
non-trivial intersection of null spaces to the steady-state of the
matrix-weighted network is examined. Moreover, for matrix-weighted networks
with a positive-negative spanning tree, necessary and sufficient condition for
bipartite consensus using the non-trivial balancing set is obtained. Simulation
examples are provided to demonstrate the theoretical results.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 10:56:37 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 06:33:52 GMT""}]","2021-06-25"
"2011.14106","Maciej Bochenski","Maciej Boche\'nski","On semisimple standard compact Clifford-Klein forms","to appear in Journal of Lie Theory",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this paper we give the classification of standard compact Clifford-Klein
forms corresponding to triples (g,h,l) such that g = h+l and g is a sum of two
absolutely simple ideals. The classification is done using Onishchik's results
concerning semisimple decompositions of semisimple Lie algebras. Using this
classification we obtain new examples of reductive homogeneous spaces admitting
non-standard compact Clifford-Klein forms.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:06:48 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 15:37:09 GMT""},{""version"":""v3"",""created"":""Sun, 2 Jan 2022 10:08:39 GMT""},{""version"":""v4"",""created"":""Thu, 5 May 2022 15:31:53 GMT""}]","2022-05-06"
"2011.14107","Hui-Po Wang","Hui-Po Wang, Ning Yu, Mario Fritz","Hijack-GAN: Unintended-Use of Pretrained, Black-Box GANs","Accepted by CVPR 2021",,,,"cs.CV cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While Generative Adversarial Networks (GANs) show increasing performance and
the level of realism is becoming indistinguishable from natural images, this
also comes with high demands on data and computation. We show that
state-of-the-art GAN models -- such as they are being publicly released by
researchers and industry -- can be used for a range of applications beyond
unconditional image generation. We achieve this by an iterative scheme that
also allows gaining control over the image generation process despite the
highly non-linear latent spaces of the latest GAN models. We demonstrate that
this opens up the possibility to re-use state-of-the-art, difficult to train,
pre-trained GANs with a high level of control even if only black-box access is
granted. Our work also raises concerns and awareness that the use cases of a
published GAN model may well reach beyond the creators' intention, which needs
to be taken into account before a full public release. Code is available at
https://github.com/a514514772/hijackgan.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:07:36 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 13:20:00 GMT""}]","2021-03-30"
"2011.14108","Doron Gepner R","Doron Gepner","On the Free Energy of Solvable lattice Models","25 pages, no figures",,"10.1016/j.nuclphysb.2021.115532",,"hep-th math-ph math.MP","http://creativecommons.org/publicdomain/zero/1.0/","  We conjecture the inversion relations for thermalized solvable interaction
round the face (IRF) two dimensional lattice models. We base ourselves on an
ansatz for the Baxterization described by the author in the 90's. We solve
these inversion relations in the four main regimes of the models, to give the
free energy of the models, in these regimes. We use the method of Baxter in the
calculation of the free energy of the hard hexagon model. We believe these
results to be quite general, shared by most of the known IRF models. Our
results apply equally well to solvable vertex models. Using the expression for
the free energy we calculate the critical exponent $\alpha$, and from it the
dimension of the perturbing (thermal) operator in the fixed point conformal
field theory (CFT). We show that it matches either the coset ${\cal O}/{\cal
G}$ or ${\cal G}/{\cal O}$, where $\cal O$ is the original CFT used to define
the model and $\cal G$ is some unknown CFT, depending on the regime. This
agrees with known examples of such models by Huse and Jimbo et al.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:11:52 GMT""}]","2021-09-22"
"2011.14109","Umberto Martinez-Penas","Umberto Mart\'inez-Pe\~nas","A general family of MSRD codes and PMDS codes with smaller field sizes
  from extended Moore matrices",,,,,"cs.IT math.AG math.IT","http://creativecommons.org/publicdomain/zero/1.0/","  We construct six new explicit families of linear maximum sum-rank distance
(MSRD) codes, each of which has the smallest field sizes among all known MSRD
codes for some parameter regime. Using them and a previous result of the
author, we provide two new explicit families of linear partial MDS (PMDS) codes
with smaller field sizes than previous PMDS codes for some parameter regimes.
Our approach is to characterize evaluation points that turn extended Moore
matrices into the parity-check matrix of a linear MSRD code. We then produce
such sequences from codes with good Hamming-metric parameters. The six new
families of linear MSRD codes with smaller field sizes are obtained using MDS
codes, Hamming codes, BCH codes and three Algebraic-Geometry codes. The MSRD
codes based on Hamming codes, of minimum sum-rank distance $ 3 $, meet a recent
bound by Byrne et al.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:14:31 GMT""},{""version"":""v2"",""created"":""Sun, 6 Dec 2020 11:14:17 GMT""},{""version"":""v3"",""created"":""Wed, 20 Apr 2022 11:36:05 GMT""}]","2022-04-21"
"2011.14110","Filip Turobo\'s","Filip Turobo\'s","On characterization of functions preserving metric-type conditions via
  triangular and polygonal structures",,,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following the train of thought from our previous paper we revisit the
theorems of Pongsriiam and Termwuttipong by further developing their
characterization of certain property-preserving functions using the so-called
triangle triplets. We develop more general analogues of disjoint sum lemmas for
broader classes of metric-type spaces and we apply these to extend results of
Bors\`ik an Dobo\v{s} as well as those obtained by Khemaratchatakumthorn and
Pongsriiam. As a byproduct we obtain methods of generating non-trivial and
infinite strong $b$-metric spaces which are not metric.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:16:55 GMT""}]","2020-12-01"
"2011.14111","Nikita Kavokine","Nikita Kavokine, Roland R. Netz, Lyd\'eric Bocquet","Fluids at the Nanoscale: from continuum to sub-continuum transport",,"Annual Review of Fluid Mechanics, 53 (2021)","10.1146/annurev-fluid-071320-095958",,"physics.flu-dyn cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Nanofluidics has firmly established itself as a new field in fluid mechanics,
as novel properties have been shown to emerge in fluids at the nanometric
scale. Thanks to recent developments in fabrication technology, artificial
nanofluidic systems are now being designed at the scale of biological
nanopores. This ultimate step in scale reduction has pushed the development of
new experimental techniques and new theoretical tools, bridging fluid
mechanics, statistical mechanics and condensed matter physics. This review is
intended as a toolbox for fluids at the nanometre scale. After presenting the
basic equations that govern fluid behaviour in the continuum limit, we will
show how these equations break down and new properties emerge in molecular
scale confinement.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:19:39 GMT""}]","2020-12-01"
"2011.14112","Elnaz Gholipour","Elnaz Gholipour (1), B\'ela Vizv\'ari (1) and Zolt\'an Lakner (2) ((1)
  Eastern Mediterranean University, (2) St. Stephen University)","Reconstruction Rating Model of Sovereign Debt by Logical Analysis of
  Data","18 pages, 1 figure, 12 tables",,,,"econ.GN cs.NA math.NA math.OC q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sovereign debt ratings provided by rating agencies measure the solvency of a
country, as gauged by a lender or an investor. It is an indication of the risk
involved in investment, and should be determined correctly and in a well timed
manner. The present study reconstructs sovereign debt ratings through logical
analysis of data, which is based on the theory of Boolean functions. It
organizes groups of countries according to twenty World Bank defined variables
for the period 2012 till 2015. The Fitch Rating Agency, one of the three big
global rating agencies, is used as a case study. An approximate algorithm was
crucial in exploring the rating method, in correcting the agencys errors, and
in determining the estimated rating of otherwise non rated countries. The
outcome was a decision tree for each year. Each country was assigned a rating.
On average, the algorithm reached almost ninety eight percentage matched
ratings in the training set, and was verified by eighty four percentage in the
test set. This was a considerable achievement.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:21:30 GMT""}]","2020-12-01"
"2011.14113","Javier Arg\""uello-Luengo","Javier Arg\""uello-Luengo, Tao Shi, Alejandro Gonz\'alez-Tudela","Engineering analog quantum chemistry Hamiltonians using cold atoms in
  optical lattices","Accepted version of the manuscript. 30 pages, 14 figures","Phys. Rev. A 103, 043318 (2021)","10.1103/PhysRevA.103.043318",,"quant-ph cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using quantum systems to efficiently solve quantum chemistry problems is one
of the long-sought applications of near-future quantum technologies. In a
recent work, ultra-cold fermionic atoms have been proposed for these purposes
by showing us how to simulate in an analog way the quantum chemistry
Hamiltonian projected in a lattice basis set. Here, we continue exploring this
path and go beyond these first results in several ways. First, we numerically
benchmark the working conditions of the analog simulator, and find less
demanding experimental setups where chemistry-like behaviour in
three-dimensions can still be observed. We also provide a deeper understanding
of the errors of the simulation appearing due to discretization and finite size
effects and provide a way to mitigate them. Finally, we benchmark the simulator
characterizing the behaviour of two-electron atoms (He) and molecules (HeH$^+$)
beyond the example considered in the original work.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:23:06 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 19:15:53 GMT""}]","2021-04-16"
"2011.14114","Silvia Ferrario Ravasio","Silvia Ferrario Ravasio, Giovanni Limatola and Paolo Nason","Infrared Renormalons in Kinematic Distributions for Hadron Collider
  Processes","24 pages, 10 figures","JHEP 06 (2021), 018","10.1007/JHEP06(2021)018","OUTP-20-13P, IPPP/20/60","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Infrared renormalons in Quantum Chromodynamics are associated with
non-perturbative corrections to short distance observables. Linear renormalons,
i.e. such that the associated non-perturbative corrections scale like one
inverse power of the hard scale, can affect at a non-negligible level even the
very high-energy phenomena studied at the Large Hadron Collider. Using an
Abelian model, we study the presence of linear renormalons in the transverse
momentum distribution of a neutral vector boson $Z$ produced in hadronic
collisions. We consider a process where the $Z$ transverse momentum is balanced
by a sizable recoil against a coloured final state particle. One may worry that
such a colour configuration, not being azimuthally symmetric, could generate
unbalanced soft radiation, associated in turn with linear infrared renormalons
affecting the transverse momentum distribution of the vector boson. We
performed a numerical calculation of the renormalon effects for this process in
the so-called large $b_0$ limit. We found no evidence of linear renormalons in
the transverse momentum distribution of the $Z$ in the large
transverse-momentum region, irrespective of rapidity cuts.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:30:47 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 10:00:54 GMT""}]","2021-06-23"
"2011.14115","Johannes Gasteiger","Johannes Gasteiger, Shankari Giri, Johannes T. Margraf, Stephan
  G\""unnemann","Fast and Uncertainty-Aware Directional Message Passing for
  Non-Equilibrium Molecules","Published at the Machine Learning for Molecules Workshop at NeurIPS
  2020. Author name changed from Johannes Klicpera to Johannes Gasteiger",,,,"cs.LG physics.chem-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many important tasks in chemistry revolve around molecules during reactions.
This requires predictions far from the equilibrium, while most recent work in
machine learning for molecules has been focused on equilibrium or
near-equilibrium states. In this paper we aim to extend this scope in three
ways. First, we propose the DimeNet++ model, which is 8x faster and 10% more
accurate than the original DimeNet on the QM9 benchmark of equilibrium
molecules. Second, we validate DimeNet++ on highly reactive molecules by
developing the challenging COLL dataset, which contains distorted
configurations of small molecules during collisions. Finally, we investigate
ensembling and mean-variance estimation for uncertainty quantification with the
goal of accelerating the exploration of the vast space of non-equilibrium
structures. Our DimeNet++ implementation as well as the COLL dataset are
available online.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:39:42 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 12:29:05 GMT""},{""version"":""v3"",""created"":""Tue, 5 Apr 2022 11:57:23 GMT""}]","2022-04-06"
"2011.14116","Ilija Buric","Ilija Buric, Volker Schomerus and Evgeny Sobko","Crossing Symmetry for Long Multiplets in 4D $\mathcal{N}=1$ SCFTs",,,"10.1007/JHEP04(2021)130","DESY 20-205","hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  In this work we construct the crossing symmetry equations for mixed
correlators of two long and two BPS operators in 4D $\mathcal{N}=1$ SCFTs. The
analysis presented here illustrates how our general group theoretic approach to
long superblocks and tensor structures of superconformal algebras can be
applied to give explicit ready-to-use expressions. In the case at hand, we
obtain a system of four crossing symmetry equations for the relevant OPE
coefficients. One of these four equations coincides with the equation found and
analysed by Li, Meltzer and Stergiou by restricting to the superprimary
component of the long multiplets. The other three equations are new and they
provide powerful additional constraints on the same OPE data.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:45:29 GMT""}]","2021-04-28"
"2011.14117","Thomas Sutter","Thomas Sutter","Simple Spyware: Androids Invisible Foreground Services and How to
  (Ab)use Them","9 pages, 2 figures, 3 listings, BlackHat Europe 2019 see
  https://www.blackhat.com/eu-19/briefings/schedule/index.html#simple-spyware-androids-invisible-foreground-services-and-how-to-abuse-them-17738,
  WhitePaper",,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  With the releases of Android Oreo and Pie, Android introduced some background
execution limitations for apps. Google restricted the execution of background
services to save energy and to prevent apps from running endlessly in the
background. Moreover, access to the device's sensors was changed and a new
concept named foreground service has been introduced. Apps were no longer
allowed to run background services in an idle state, preventing apps from using
the device's resources like the camera. These limitations, however, would not
affect so-called foreground services because they show a permanently visible
notification to the user and could therefore be stopped by the user at any
time. Our research found out that flaws in the API exists, which allows
starting invisible foreground services, making the introduced limitations
ineffective. We will show that the found flaws allow attackers to use
foreground services as a tool for spying on users.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:57:17 GMT""}]","2020-12-01"
"2011.14118","Eberhard Bodenschatz","Freja Nordsiek and Eberhard Bodenschatz and Gholamhossein Bagheri","Risk assessment for airborne disease transmission by poly-pathogen
  aerosols","updated file with link to software on GitHub",,"10.1371/journal.pone.0248004",,"q-bio.QM physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  In the case of airborne diseases, pathogen copies are transmitted by droplets
of respiratory tract fluid that are exhaled by the infectious and, after
partial or full drying, inhaled as aerosols by the susceptible. The risk of
infection in indoor environments is typically modelled using the Wells-Riley
model or a Wells-Riley-like formulation, usually assuming the pathogen dose
follows a Poisson distribution (mono-pathogen assumption). Aerosols that hold
more than one pathogen copy, i.e. poly-pathogen aerosols, break this assumption
even if the aerosol dose itself follows a Poisson distribution. For the largest
aerosols where the number of pathogen in each aerosol can sometimes be several
hundred or several thousand, the effect is non-negligible, especially in
diseases where the risk of infection per pathogen is high. Here we report on a
generalization of the Wells-Riley model and dose-response models for
poly-pathogen aerosols by separately modeling each number of pathogen copies
per aerosol, while the aerosol dose itself follows a Poisson distribution. This
results in a model for computational risk assessment suitable for
mono-/poly-pathogen aerosols. We show that the mono-pathogen assumption
significantly overestimates the risk of infection for high pathogen
concentrations in the respiratory tract fluid. The model also includes the
aerosol removal due to filtering by the individuals which becomes significant
for poorly ventilated environments with a high density of individuals, and
systematically includes the effects of facemasks in the infectious aerosol
source and sink terms and dose calculations.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:58:01 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 12:16:16 GMT""}]","2021-06-09"
"2011.14119","Vittorino Pata","Lorenzo Fornari, Enrico Laeng and Vittorino Pata","A direct computation of a certain family of integrals",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a rather elementary method to compute a certain family of
integrals on the half line, depending on the integer parameters $n\geq q\geq
1$.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 12:07:26 GMT""}]","2020-12-01"
"2011.14120","David Dunstan","D.J. Carter, D.J. Dunstan, W. Just, O.F. Bandtlow, A. San Miguel","Softening of the Euler buckling criterion under discretisation of
  compliance","4 pages, 3 Figures, draft in preparation",,,,"cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Euler solved the problem of the collapse of tall thin columns under
unexpectedly small loads in 1744. The analogous problem of the collapse of
circular elastic rings or tubes under external pressure was mathematically
intractable and only fully solved recently. In the context of carbon nanotubes,
an additional phenomenon was found experimentally and in atomistic simulations
but not explained: the collapse pressure of smaller diameter tubes deviates
below the continuum mechanics solution [Torres-Dias et al., Carbon 123, 145
(2017)]. Here, this deviation is shown to occur in discretized straight columns
and it is fully explained in terms of the phonon dispersion curve. This reveals
an unexpected link between the static mechanical properties of discrete systems
and their dynamics described through dispersion curves.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 12:08:23 GMT""}]","2020-12-01"
"2011.14121","Evgenii Ievlev","E. Ievlev","Dynamics of non-Abelian strings in supersymmetric gauge theories","200 pages; PhD thesis, SPbSU and PNPI; English version, full text at
  go.spbu.ru/20a2711",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This thesis is devoted to studying strong coupling phenomena (and confinement
in particular) in supersymmetric gauge theories. The central object of
investigation is the non-Abelian string that is responsible for the
""instead-of-confinement"" phase for monopoles in 4D ${\mathcal N} = 2$
supersymmetric QCD with the U($N$) gauge group and $N_f$ flavors of quark
hypermultiplets, $N \leqslant N_f \leqslant 2 N$.
  Here it is shown that the non-Abelian strings and confined monopoles survive
when we transition to the ${\mathcal N} = 1$ supersymmetric QCD. To this end we
consider a mass term $\mu$ for the adjoint matter, and in the limit of large
$\mu$ the bulk theory flows to ${\mathcal N} = 1$. We consider this transition
both from the bulk point of view and from the world sheet theory, which is the
two-dimensional $\mathbb{CP}(N-1)$ model. Survival of monopoles in the
${\mathcal N} = 1$ supersymmetric QCD is important for the
""instead-of-confinement"" phase, and also for the Seiberg-Witten picture of
confinement.
  Apart from that, we also consider non-Abelian vortex strings in 4D
$\mathcal{N} = 2$ supersymmetric QCD with U$(N=2)$ gauge group and $N_f=4$
flavors of quark hypermultiplets. It has been recently shown that these
vortices behave as critical superstrings. In particular, the lowest string
state appears to be a massless BPS ""baryon."" Here we show the occurrence of
this stringy baryon using a purely field-theoretic method. Moreover, we
explicitly demonstrate the ""instead-of-confinement"" phase, when the screened
quarks and gauge bosons of weak coupling are replaced by the confined
monopole-antimonopole pairs of strong coupling.
  English version. Full text (Russian and English) is available at the official
web page https://go.spbu.ru/20a2711 .
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 12:12:51 GMT""}]","2020-12-01"
"2011.14122","Tanja Petrushevska","T. Petrushevska","Strongly Lensed Supernovae in Well-Studied Galaxy Clusters with the Vera
  C. Rubin Observatory","Accepted for publication in Symmetry, special Issue on Gravitational
  Lensing",,"10.3390/sym12121966",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Strong lensing by galaxy clusters can be used to significantly expand the
survey reach, thus allowing observation of magnified high-redshift supernovae
that otherwise would remain undetected. Strong lensing can also provide
multiple images of the galaxies that lie behind the clusters. Detection of
strongly lensed Type Ia supernovae (SNe Ia) is especially useful because of
their standardizable brightness, as they can be used to improve either cluster
lensing models or independent measurements of cosmological parameters. The
cosmological parameter, the Hubble constant, is of particular interest given
the discrepancy regarding its value from measurements with different
approaches. Here, we explore the feasibility of the Vera C. Rubin Observatory
Legacy Survey of Space and Time (LSST) of detecting strongly lensed SNe in the
field of five galaxy clusters (Abell 1689 and Hubble Frontier Fields clusters)
that have well-studied lensing models. Considering the 88 systems composed of
268 individual multiple images in the five cluster fields, we find that the
LSST will be sensitive to SNe~Ia (SNe~IIP) exploding in 41 (23) galaxy images.
The range of redshift of these galaxies is between $1.01 < z < 3.05$. During
its 10 years of operation, LSST is expected to detect $0.2\pm0.1$ SN~Ia and
$0.9\pm0.3$ core collapse SNe. However, as LSST will observe many more massive
galaxy clusters, it is likely that the expectations are higher. We stress the
importance of having an additional observing program for photometric and
spectroscopic follow-up of the strongly lensed SNe detected by LSST.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 12:22:46 GMT""}]","2020-12-01"
"2011.14123","Zhe Chu","Zhe Chu, Mengkai Hu, Xiangyu Chen","Robotic grasp detection using a novel two-stage approach",,,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, deep learning has been successfully applied to robotic grasp
detection. Based on convolutional neural networks (CNNs), there have been lots
of end-to-end detection approaches. But end-to-end approaches have strict
requirements for the dataset used for training the neural network models and
it's hard to achieve in practical use. Therefore, we proposed a two-stage
approach using particle swarm optimizer (PSO) candidate estimator and CNN to
detect the most likely grasp. Our approach achieved an accuracy of 92.8% on the
Cornell Grasp Dataset, which leaped into the front ranks of the existing
approaches and is able to run at real-time speeds. After a small change of the
approach, we can predict multiple grasps per object in the meantime so that an
object can be grasped in a variety of ways.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 12:26:35 GMT""}]","2020-12-01"
"2011.14124","Edward Lockhart","Edward Lockhart, Neil Burch, Nolan Bard, Sebastian Borgeaud, Tom
  Eccles, Lucas Smaira, Ray Smith","Human-Agent Cooperation in Bridge Bidding",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a human-compatible reinforcement-learning approach to a
cooperative game, making use of a third-party hand-coded human-compatible bot
to generate initial training data and to perform initial evaluation. Our
learning approach consists of imitation learning, search, and policy iteration.
Our trained agents achieve a new state-of-the-art for bridge bidding in three
settings: an agent playing in partnership with a copy of itself; an agent
partnering a pre-existing bot; and an agent partnering a human player.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 12:37:02 GMT""}]","2020-12-01"
"2011.14125","Weipeng Zhu","Jinlu Li, Yanghai Yu and Weipeng Zhu","Non-uniform dependence on initial data for the 2D viscous shallow water
  equations","20 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The failure of uniform dependence on the data is an interesting property of
classical solution for a hyperbolic system. In this paper, we consider the
solution map of the Cauchy problem to the 2D viscous shallow water equations
which is a hyperbolic-parabolic system. We prove that the solution map of this
problem is not uniformly continuous in Sobolev spaces $H^s\times H^{s}$ for
$s>2$.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 12:38:37 GMT""}]","2020-12-01"
"2011.14126","Zakaria Mhammedi","Zakaria Mhammedi","Risk-Monotonicity in Statistical Learning","To appear in NeurIPS 2021 as Oral presentation",,,,"cs.LG math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Acquisition of data is a difficult task in many applications of machine
learning, and it is only natural that one hopes and expects the population risk
to decrease (better performance) monotonically with increasing data points. It
turns out, somewhat surprisingly, that this is not the case even for the most
standard algorithms that minimize the empirical risk. Non-monotonic behavior of
the risk and instability in training have manifested and appeared in the
popular deep learning paradigm under the description of double descent. These
problems highlight the current lack of understanding of learning algorithms and
generalization. It is, therefore, crucial to pursue this concern and provide a
characterization of such behavior. In this paper, we derive the first
consistent and risk-monotonic (in high probability) algorithms for a general
statistical learning setting under weak assumptions, consequently answering
some questions posed by Viering et al. 2019 on how to avoid non-monotonic
behavior of risk curves. We further show that risk monotonicity need not
necessarily come at the price of worse excess risk rates. To achieve this, we
derive new empirical Bernstein-like concentration inequalities of independent
interest that hold for certain non-i.i.d.~processes such as Martingale
Difference Sequences.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 12:52:12 GMT""},{""version"":""v2"",""created"":""Wed, 16 Dec 2020 07:21:06 GMT""},{""version"":""v3"",""created"":""Thu, 24 Dec 2020 04:26:33 GMT""},{""version"":""v4"",""created"":""Tue, 9 Nov 2021 19:02:16 GMT""},{""version"":""v5"",""created"":""Sat, 15 Jan 2022 18:29:44 GMT""}]","2022-01-19"
"2011.14127","Bastien Dubail","Charles Bordenave and Bastien Dubail","Markovian linearization of random walks on groups","28 pages. Shortened version, updated references. To appear in
  International Mathematics Research Notices",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  In operator algebra, the linearization trick is a technique that reduces the
study of a non-commutative polynomial evaluated at elements of an algebra A to
the study of a polynomial of degree one, evaluated on the enlarged algebra A x
M r (C), for some integer r. We introduce a new instance of the linearization
trick which is tailored to study a finitely supported random walk on a group G
by studying instead a nearest-neighbor colored random walk on G x {1,. .. , r},
which is much simpler to analyze. As an application we extend well-known
results for nearest-neighbor walks on free groups and free products of finite
groups to colored random walks, thus showing how one can obtain explicit
formulas for the drift and entropy of a finitely supported random walk.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 13:02:58 GMT""},{""version"":""v2"",""created"":""Wed, 2 Feb 2022 12:38:46 GMT""}]","2022-02-03"
"2011.14128","Fred Diamond","Fred Diamond","Geometric weight-shifting operators on Hilbert modular forms in
  characteristic p","55 pages","J. Inst. Math. Jussieu, 2021","10.1017/S1474748021000530",,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We carry out a thorough study of weight-shifting operators on Hilbert modular
forms in characteristic $p$, generalizing the author's prior work with Sasaki
to the case where $p$ is ramified in the totally real field $F$. In particular
we use the partial Hasse invariants and Kodaira-Spencer filtrations defined by
Reduzzi and Xiao to improve on Andreatta and Goren's construction of partial
$\Theta$-operators, obtaining ones whose effect on weights is optimal from the
point of view of geometric Serre weight conjectures. Furthermore we describe
the kernels of partial $\Theta$-operators in terms of images of geometrically
constructed partial Frobenius operators. Finally we apply our results to prove
a partial positivity result for minimal weights of mod $p$ Hilbert modular
forms.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 13:14:54 GMT""},{""version"":""v2"",""created"":""Sat, 18 Sep 2021 16:41:47 GMT""}]","2021-11-22"
"2011.14129","Ga\""etan Gras","Ga\""etan Gras and Anthony Martin and Jeong Woon Choi and F\'elix
  Bussi\`eres","Quantum entropy model of an integrated QRNG chip",,"Phys. Rev. Applied 15, 054048 (2021)","10.1103/PhysRevApplied.15.054048",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the physical model for the entropy source of a quantum random
number generator chip based on the quantum fluctuations of the photon number
emitted by light-emitting diodes. This model, combined with a characterization
of the chip, estimates a quantum min-entropy of over 0.98 per bit without
post-processing. Finally, we show with our model that the performances in terms
of security are robust against fluctuations over time.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 13:19:03 GMT""}]","2021-05-26"
"2011.14130","Yong-Liang Xiao","Yong-Liang Xiao","Optical Phase Dropout in Diffractive Deep Neural Network",,,"10.1364/OL.428761",,"physics.optics cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unitary learning is a backpropagation that serves to unitary weights update
in deep complex-valued neural network with full connections, meeting a physical
unitary prior in diffractive deep neural network ([DN]2). However, the square
matrix property of unitary weights induces that the function signal has a
limited dimension that could not generalize well. To address the overfitting
problem that comes from the small samples loaded to [DN]2, an optical phase
dropout trick is implemented. Phase dropout in unitary space that is evolved
from a complex dropout and has a statistical inference is formulated for the
first time. A synthetic mask recreated from random point apertures with random
phase-shifting and its smothered modulation tailors the redundant links through
incompletely sampling the input optical field at each diffractive layer. The
physical features about the synthetic mask using different nonlinear
activations are elucidated in detail. The equivalence between digital and
diffractive model determines compound modulations that could successfully
circumvent the nonlinear activations physically implemented in [DN]2. The
numerical experiments verify the superiority of optical phase dropout in [DN]2
to enhance accuracy in 2D classification and recognition tasks-oriented.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 13:33:23 GMT""}]","2021-11-03"
"2011.14131","Christian Wahl","Christian Wahl, Marvin Hoffmann, Thilo vom Hoevel, Frank Vewinger,
  Martin Weitz","Vacuum-Ultraviolet Absorption and Emission Spectroscopy of Gaseous,
  Liquid, and Supercritical Xenon","15 pages, 6 figures","Phys. Rev. A 103, 022831 (2021)","10.1103/PhysRevA.103.022831",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bose-Einstein condensation, an effect long known for material particles as
cold atomic gases, has in recent years also been observed for photons in
microscopic optical cavitites. Here, we report absorption and emission
spectroscopic measurements on the lowest electronic transition ($5\text{p}^6
\rightarrow 5\text{p}^5 6\text{s}$) of xenon, motivated by the search for a
thermalization medium for photon Bose-Einstein condensation in the
vacuum-ultraviolet spectral regime. We have recorded pressure-broadened xenon
spectra in the 135 nm to 190 nm wavelength regime at conditions near the
critical point. The explored pressure and temperature range includes high
pressure gaseous xenon below the critical pressure and supercritical xenon at
room temperature, as well as liquid xenon close to the boiling point near the
critical pressure.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 13:41:58 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 14:33:49 GMT""}]","2021-03-10"
"2011.14132","Quan Huu Cap","Quan Huu Cap and Hitoshi Iyatomi and Atsushi Fukuda","MIINet: An Image Quality Improvement Framework for Supporting Medical
  Diagnosis","Accepted at the ICPR2020 Workshops",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Medical images have been indispensable and useful tools for supporting
medical experts in making diagnostic decisions. However, taken medical images
especially throat and endoscopy images are normally hazy, lack of focus, or
uneven illumination. Thus, these could difficult the diagnosis process for
doctors. In this paper, we propose MIINet, a novel image-to-image translation
network for improving quality of medical images by unsupervised translating
low-quality images to the high-quality clean version. Our MIINet is not only
capable of generating high-resolution clean images, but also preserving the
attributes of original images, making the diagnostic more favorable for
doctors. Experiments on dehazing 100 practical throat images show that our
MIINet largely improves the mean doctor opinion score (MDOS), which assesses
the quality and the reproducibility of the images from the baseline of 2.36 to
4.11, while dehazed images by CycleGAN got lower score of 3.83. The MIINet is
confirmed by three physicians to be satisfying in supporting throat disease
diagnostic from original low-quality images.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 13:44:42 GMT""}]","2020-12-01"
"2011.14133","Mohit Lamba","Mohit Lamba and Atul Balaji and Kaushik Mitra","Towards Fast and Light-Weight Restoration of Dark Images",,,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  The ability to capture good quality images in the dark and near-zero lux
conditions has been a long-standing pursuit of the computer vision community.
The seminal work by Chen et al. [5] has especially caused renewed interest in
this area, resulting in methods that build on top of their work in a bid to
improve the reconstruction. However, for practical utility and deployment of
low-light enhancement algorithms on edge devices such as embedded systems,
surveillance cameras, autonomous robots and smartphones, the solution must
respect additional constraints such as limited GPU memory and processing power.
With this in mind, we propose a deep neural network architecture that aims to
strike a balance between the network latency, memory utilization, model
parameters, and reconstruction quality. The key idea is to forbid computations
in the High-Resolution (HR) space and limit them to a Low-Resolution (LR)
space. However, doing the bulk of computations in the LR space causes artifacts
in the restored image. We thus propose Pack and UnPack operations, which allow
us to effectively transit between the HR and LR spaces without incurring much
artifacts in the restored image. We show that we can enhance a full resolution,
2848 x 4256, extremely dark single-image in the ballpark of 3 seconds even on a
CPU. We achieve this with 2 - 7x fewer model parameters, 2 - 3x lower memory
utilization, 5 - 20x speed up and yet maintain a competitive image
reconstruction quality compared to the state-of-the-art algorithms.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 13:53:50 GMT""}]","2020-12-01"
"2011.14134","Soumick Chatterjee","Soumick Chatterjee, Alessandro Sciarra, Max D\""unnwald, Steffen
  Oeltze-Jafra, Andreas N\""urnberger and Oliver Speck","Retrospective Motion Correction of MR Images using Prior-Assisted Deep
  Learning",,"Medical Imaging Meets NeurIPS 2020",,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In MRI, motion artefacts are among the most common types of artefacts. They
can degrade images and render them unusable for accurate diagnosis. Traditional
methods, such as prospective or retrospective motion correction, have been
proposed to avoid or alleviate motion artefacts. Recently, several other
methods based on deep learning approaches have been proposed to solve this
problem. This work proposes to enhance the performance of existing deep
learning models by the inclusion of additional information present as image
priors. The proposed approach has shown promising results and will be further
investigated for clinical validity.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 14:03:59 GMT""}]","2020-12-01"
"2011.14135","Benjamin Moster","Abhishek Malik, Benjamin P. Moster and Christian Obermeier","Exoplanet Detection using Machine Learning","10 pages, 8 figures, 4 tables, submitted to MNRAS",,"10.1093/mnras/stab3692",,"astro-ph.EP astro-ph.IM cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new machine learning based technique to detect exoplanets
using the transit method. Machine learning and deep learning techniques have
proven to be broadly applicable in various scientific research areas. We aim to
exploit some of these methods to improve the conventional algorithm based
approaches presently used in astrophysics to detect exoplanets. Using the
time-series analysis library TSFresh to analyse light curves, we extracted 789
features from each curve, which capture the information about the
characteristics of a light curve. We then used these features to train a
gradient boosting classifier using the machine learning tool lightgbm. This
approach was tested on simulated data, which showed that is more effective than
the conventional box least squares fitting (BLS) method. We further found that
our method produced comparable results to existing state-of-the-art deep
learning models, while being much more computationally efficient and without
needing folded and secondary views of the light curves. For Kepler data, the
method is able to predict a planet with an AUC of 0.948, so that 94.8 per cent
of the true planet signals are ranked higher than non-planet signals. The
resulting recall is 0.96, so that 96 per cent of real planets are classified as
planets. For the Transiting Exoplanet Survey Satellite (TESS) data, we found
our method can classify light curves with an accuracy of 0.98, and is able to
identify planets with a recall of 0.82 at a precision of 0.63.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 14:06:39 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 00:08:20 GMT""}]","2022-01-05"
"2011.14136","Huu Phuoc Le","Huu Phuoc Le, Mohab Safey El Din","Solving parametric systems of polynomial equations over the reals
  through Hermite matrices",,"Journal of Symbolic Computation, 2021","10.1016/j.jsc.2021.12.002",,"cs.SC cs.CG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We design a new algorithm for solving parametric systems having finitely many
complex solutions for generic values of the parameters. More precisely, let $f
= (f_1, \ldots, f_m)\subset \mathbb{Q}[y][x]$ with $y = (y_1, \ldots, y_t)$ and
$x = (x_1, \ldots, x_n)$, $V\subset \mathbb{C}^{t+n}$ be the algebraic set
defined by $f$ and $\pi$ be the projection $(y, x) \to y$. Under the
assumptions that $f$ admits finitely many complex roots for generic values of
$y$ and that the ideal generated by $f$ is radical, we solve the following
problem. On input $f$, we compute semi-algebraic formulas defining
semi-algebraic subsets $S_1, \ldots, S_l$ of the $y$-space such that
$\cup_{i=1}^l S_i$ is dense in $\mathbb{R}^t$ and the number of real points in
$V\cap \pi^{-1}(\eta)$ is invariant when $\eta$ varies over each $S_i$.
  This algorithm exploits properties of some well chosen monomial bases in the
algebra $\mathbb{Q}(y)[x]/I$ where $I$ is the ideal generated by $f$ in
$\mathbb{Q}(y)[x]$ and the specialization property of the so-called Hermite
matrices. This allows us to obtain compact representations of the sets $S_i$ by
means of semi-algebraic formulas encoding the signature of a symmetric matrix.
When $f$ satisfies extra genericity assumptions, we derive complexity bounds on
the number of arithmetic operations in $\mathbb{Q}$ and the degree of the
output polynomials. Let $d$ be the maximal degree of the $f_i$'s and $D =
n(d-1)d^n$, we prove that, on a generic $f=(f_1,\ldots,f_n)$, one can compute
those semi-algebraic formulas with $O^~( \binom{t+D}{t}2^{3t}n^{2t+1}
d^{3nt+2(n+t)+1})$ operations in $\mathbb{Q}$ and that the polynomials involved
have degree bounded by $D$.
  We report on practical experiments which illustrate the efficiency of our
algorithm on generic systems and systems from applications. It allows us to
solve problems which are out of reach of the state-of-the-art.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 14:09:06 GMT""},{""version"":""v2"",""created"":""Thu, 16 Dec 2021 20:07:46 GMT""}]","2021-12-22"
"2011.14137","Abdul Wahab","Abdul Wahab, Muhammad Anas Tahir, Naveed Iqbal, Faisal Shafait, Syed
  Muhammad Raza Kazmi","Short-Term Load Forecasting using Bi-directional Sequential Models and
  Feature Engineering for Small Datasets","8 pages, 13 figures, 5 tables. Submitted to IEEE Transactions on
  Power Systems, 2020",,"10.1109/ACCESS.2021.3093481",,"cs.LG cs.IR cs.NE eess.SP","http://creativecommons.org/licenses/by/4.0/","  Electricity load forecasting enables the grid operators to optimally
implement the smart grid's most essential features such as demand response and
energy efficiency. Electricity demand profiles can vary drastically from one
region to another on diurnal, seasonal and yearly scale. Hence to devise a load
forecasting technique that can yield the best estimates on diverse datasets,
specially when the training data is limited, is a big challenge. This paper
presents a deep learning architecture for short-term load forecasting based on
bidirectional sequential models in conjunction with feature engineering that
extracts the hand-crafted derived features in order to aid the model for better
learning and predictions. In the proposed architecture, named as Deep Derived
Feature Fusion (DeepDeFF), the raw input and hand-crafted features are trained
at separate levels and then their respective outputs are combined to make the
final prediction. The efficacy of the proposed methodology is evaluated on
datasets from five countries with completely different patterns. The results
demonstrate that the proposed technique is superior to the existing state of
the art.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 14:11:35 GMT""}]","2023-05-15"
"2011.14138","\.Ismail Sa\u{g}lam","\.Ismail Sa\u{g}lam","Ideal Triangulation and Disk Unfolding of a Singular Flat Surface","20 pages, 6 figures",,,,"math.MG math.GT","http://creativecommons.org/licenses/by/4.0/","  An ideal triangulation of a singular flat surface is a geodesic triangulation
such that its vertex set is equal to the set of singular points of the surface.
Using the fact that each pair of points in a surface has a finite number of
geodesics having length $\leq L$ connecting them, where $L$ is any positive
number, we prove that each singular flat surface has an ideal triangulation
provided that the surface has singular points when it has no boundary
components, or each of its boundary components has a singular point. Also, we
prove that such a surface contains a finite number of geodesics which connect
its singular points so that when we cut the surface through these arcs we get a
flat disk with a non-singular interior.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 14:12:53 GMT""}]","2020-12-01"
"2011.14139","Guillermo Ramon","Fatih Altay, Guillermo Ramon Sanchez, Yanli James, Stephen V. Faraone,
  Senem Velipasalar, Asif Salekin","Preclinical Stage Alzheimer's Disease Detection Using Magnetic Resonance
  Image Scans","10 pages, 5 figures",,,,"eess.IV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Alzheimer's disease is one of the diseases that mostly affects older people
without being a part of aging. The most common symptoms include problems with
communicating and abstract thinking, as well as disorientation. It is important
to detect Alzheimer's disease in early stages so that cognitive functioning
would be improved by medication and training. In this paper, we propose two
attention model networks for detecting Alzheimer's disease from MRI images to
help early detection efforts at the preclinical stage. We also compare the
performance of these two attention network models with a baseline model.
Recently available OASIS-3 Longitudinal Neuroimaging, Clinical, and Cognitive
Dataset is used to train, evaluate and compare our models. The novelty of this
research resides in the fact that we aim to detect Alzheimer's disease when all
the parameters, physical assessments, and clinical data state that the patient
is healthy and showing no symptoms
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 14:25:30 GMT""}]","2020-12-01"
"2011.14140","Evgeniy Viktorovich Damaskinsky","V.V. Borzov, E.V. Damaskinsky","Calculating the Mandel parameter for an oscillator-like system generated
  by generalized Chebyshev polynomials","14 pages, 2 figures",,,,"math-ph math.MP quant-ph","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we calculate the Mandel parameter $Q_M$ for an oscillator-like
system generated by generalized Chebyshev polynomials \cite{01}, \cite{02},
\cite{03}. The sign of the Mandel parameter $Q_M$ characterizes the deviation
of the excitation statistics from the Poisson one. This work is a continuation
of our works \cite{04}, \cite{05}.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 14:32:53 GMT""}]","2020-12-01"
"2011.14141","Shariq Bhat","Shariq Farooq Bhat, Ibraheem Alhashim, Peter Wonka","AdaBins: Depth Estimation using Adaptive Bins","13 pages",,"10.1109/CVPR46437.2021.00400",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We address the problem of estimating a high quality dense depth map from a
single RGB input image. We start out with a baseline encoder-decoder
convolutional neural network architecture and pose the question of how the
global processing of information can help improve overall depth estimation. To
this end, we propose a transformer-based architecture block that divides the
depth range into bins whose center value is estimated adaptively per image. The
final depth values are estimated as linear combinations of the bin centers. We
call our new building block AdaBins. Our results show a decisive improvement
over the state-of-the-art on several popular depth datasets across all metrics.
We also validate the effectiveness of the proposed block with an ablation study
and provide the code and corresponding pre-trained weights of the new
state-of-the-art model.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 14:40:45 GMT""}]","2022-03-30"
"2011.14142","Jie Ma","Jie Ma, Tianyun Tang","Minimizing cycles in tournaments and normalized $q$-norms",,,,,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Akin to the Erd\H{o}s-Rademacher problem, Linial and Morgenstern made the
following conjecture in tournaments: for any $d\in (0,1]$, among all $n$-vertex
tournaments with $d\binom{n}{3}$ many 3-cycles, the number of 4-cycles is
asymptotically minimized by a special random blow-up of a transitive
tournament. Recently, Chan, Grzesik, Kr\'al' and Noel introduced spectrum
analysis of adjacency matrices of tournaments in this study, and confirmed this
for $d\geq 1/36$.
  In this paper, we investigate the analogous problem of minimizing the number
of cycles of a given length. We prove that for integers $\ell\not\equiv 2\mod
4$, there exists some constant $c_\ell>0$ such that if $d\geq 1-c_\ell$, then
the number of $\ell$-cycles is also asymptotically minimized by the same family
of extremal examples for $4$-cycles. In doing so, we answer a question of
Linial and Morgenstern about minimizing the $q$-norm of a probabilistic vector
with given $p$-norm for any integers $q>p>1$. For integers $\ell\equiv 2\mod
4$, however the same phenomena do not hold for $\ell$-cycles, for which we can
construct an explicit family of tournaments containing fewer $\ell$-cycles for
any given number of $3$-cycles. We conclude by proposing two conjectures on the
minimization problem for general cycles in tournaments.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 14:55:13 GMT""}]","2020-12-01"
"2011.14143","Tarun Yenamandra","Tarun Yenamandra, Ayush Tewari, Florian Bernard, Hans-Peter Seidel,
  Mohamed Elgharib, Daniel Cremers, Christian Theobalt","i3DMM: Deep Implicit 3D Morphable Model of Human Heads","Project page: http://gvv.mpi-inf.mpg.de/projects/i3DMM/",,,,"cs.CV cs.GR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first deep implicit 3D morphable model (i3DMM) of full heads.
Unlike earlier morphable face models it not only captures identity-specific
geometry, texture, and expressions of the frontal face, but also models the
entire head, including hair. We collect a new dataset consisting of 64 people
with different expressions and hairstyles to train i3DMM. Our approach has the
following favorable properties: (i) It is the first full head morphable model
that includes hair. (ii) In contrast to mesh-based models it can be trained on
merely rigidly aligned scans, without requiring difficult non-rigid
registration. (iii) We design a novel architecture to decouple the shape model
into an implicit reference shape and a deformation of this reference shape.
With that, dense correspondences between shapes can be learned implicitly. (iv)
This architecture allows us to semantically disentangle the geometry and color
components, as color is learned in the reference space. Geometry is further
disentangled as identity, expressions, and hairstyle, while color is
disentangled as identity and hairstyle components. We show the merits of i3DMM
using ablation studies, comparisons to state-of-the-art models, and
applications such as semantic head editing and texture transfer. We will make
our model publicly available.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:01:53 GMT""}]","2020-12-01"
"2011.14144","Spyros Angelopoulos","Spyros Angelopoulos and Malachi Voss","Online Search with Maximum Clearance",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the setting in which a mobile agent must locate a hidden target in a
bounded or unbounded environment, with no information about the hider's
position. In particular, we consider online search, in which the performance of
the search strategy is evaluated by its worst case competitive ratio. We
introduce a multi-criteria search problem in which the searcher has a budget on
its allotted search time, and the objective is to design strategies that are
competitively efficient, respect the budget, and maximize the total searched
ground. We give analytically optimal strategies for the line and the star
environments, and efficient heuristics for general networks.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:15:34 GMT""}]","2020-12-01"
"2011.14145","Feng Bao","Richard Archibald, Feng Bao, Yanzhao Cao, and He Zhang","A Backward SDE Method for Uncertainty Quantification in Deep Learning",,,,,"cs.LG math.OC stat.ML","http://creativecommons.org/licenses/by/4.0/","  We develop a probabilistic machine learning method, which formulates a class
of stochastic neural networks by a stochastic optimal control problem. An
efficient stochastic gradient descent algorithm is introduced under the
stochastic maximum principle framework. Numerical experiments for applications
of stochastic neural networks are carried out to validate the effectiveness of
our methodology.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:19:36 GMT""},{""version"":""v2"",""created"":""Sun, 4 Apr 2021 01:42:45 GMT""}]","2021-04-06"
"2011.14146","Isa Inuwa-Dutse","Isa Inuwa-Dutse","Towards Combating Pandemic-related Misinformation in Social Media","13 pages, 5 figures",,,,"cs.SI cs.IR","http://creativecommons.org/licenses/by/4.0/","  Conventional preventive measures during pandemic include social distancing
and lockdown. Such measures in the time of social media brought about a new set
of challenges - vulnerability to the toxic impact of online misinformation is
high. A case in point is the prevailing COVID-19; as the virus propagates, so
does the associated misinformation and fake news about it leading to infodemic.
Since the outbreak, there has been a surge of studies investigating various
aspects of the pandemic. Of interest to this chapter include studies centring
on datasets from online social media platforms where the bulk of the public
discourse happen. Consequently, the main goal is to support the fight against
negative infodemic by (1) contributing a diverse set of curated relevant
datasets (2) recommending relevant areas to study using the datasets (3)
discussion on how relevant datasets, strategies and state-of-the-art IT tools
can be leveraged in managing the pandemic.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:30:14 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 02:26:25 GMT""}]","2021-02-16"
"2011.14147","Claudio Grimaldi","Claudio Grimaldi","Demography of galactic technosignatures","12 pages, 8 figures","MNRAS 500, 2278-2288 (2021)","10.1093/mnras/staa3450",,"astro-ph.EP astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Probabilistic arguments about the existence of technological life beyond
Earth traditionally refer to the Drake equation to draw possible estimates of
the number of technologically advanced civilizations releasing, either
intentionally or not, electromagnetic emissions in the Milky Way. Here, we
introduce other indicators than Drake's number $N_D$ to develop a demography of
artificial emissions populating the Galaxy. We focus on three main categories
of statistically independent signals (isotropic, narrow beams, and rotating
beacons) to calculate the average number $N_G$ of emission processes present in
the Galaxy and the average number of them crossing Earth, $\bar{k}$, which is a
quantity amenable to statistical estimation from direct observations. We show
that $\bar{k}$ coincides with $N_D$ only for isotropic emissions, while
$\bar{k}$ can be orders of magnitude smaller than $N_D$ in the case of highly
directional signals. We further show that while $N_D$ gives the number of
emissions being released at the present time, $N_G$ considers also the signals
from no longer active emitters but whose emissions still occupy the Galaxy. We
find that as long as the average longevity of the emissions is shorter than
about $10^5$ yr, $N_G$ is fully determined by the rate of emissions alone, in
contrast to $N_D$ and $\bar{k}$ which depend also on the emission longevity.
Finally, using analytic formulas of $N_G$, $N_D$, and $\bar{k}$ determined for
each type of emission processes here considered, we provide a comprehensive
overview of the values these quantities can possibly achieve as functions of
the emission birthrates, longevities, and directionality.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:36:07 GMT""}]","2020-12-01"
"2011.14148","Karena X. Cai","Karena X. Cai, Tung Phan-Minh, Soon-Jo Chung, Richard M. Murray","Rules of the Road: Safety and Liveness Guarantees for Autonomous
  Vehicles","20 pages, 10 figures",,,,"cs.MA","http://creativecommons.org/licenses/by/4.0/","  The ability to guarantee safety and progress for all vehicles is vital to the
success of the autonomous vehicle industry. We present a framework for
designing autonomous vehicle behavior in a way that is safe and guarantees
progress for all agents. In this paper, we first introduce a new game paradigm
which we term the quasi-simultaneous game. We then define an agent protocol
that all agents must use to make decisions in this quasi-simultaneous game
setting. According to the protocol, agents first select an intended action
using a behavioral profile. Then, the protocol defines whether an agent has
precedence to take its intended action or must take a sub-optimal action. The
protocol ensures safety under all traffic conditions and liveness for all
agents under `sparse' traffic conditions. We provide proofs of correctness of
the protocol and validate our results in simulation.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:37:05 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 19:45:50 GMT""}]","2021-03-25"
"2011.14149","Mateusz Wasilewski","Alexandru Chirvasitu and Mateusz Wasilewski","Random quantum graphs","25 pages + references, final version accepted for publication in
  Transactions of the AMS",,"10.1090/tran/8584",,"math.OA math.AG math.FA math.PR math.RT","http://creativecommons.org/licenses/by/4.0/","  We prove a number of results to the effect that generic quantum graphs
(defined via operator systems as in the work of Duan-Severini-Winter / Weaver)
have few symmetries: for a Zariski-dense open set of tuples $(X_1,\cdots,X_d)$
of traceless self-adjoint operators in the $n\times n$ matrix algebra the
corresponding operator system has trivial automorphism group, in the largest
possible range for the parameters: $2\le d\le n^2-3$. Moreover, the
automorphism group is generically abelian in the larger parameter range $1\le
d\le n^2-2$. This then implies that for those respective parameters the
corresponding random-quantum-graph model built on the GUE ensembles of $X_i$'s
(mimicking the Erd\H{o}s-R\'{e}nyi $G(n,p)$ model) has trivial/abelian
automorphism group almost surely.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:37:37 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 09:43:53 GMT""}]","2022-03-17"
"2011.14150","Yuhui Xu","Yuhui Xu, Lingxi Xie, Cihang Xie, Jieru Mei, Siyuan Qiao, Wei Shen,
  Hongkai Xiong, Alan Yuille","Batch Normalization with Enhanced Linear Transformation","12 pages. The code is available at
  https://github.com/yuhuixu1993/BNET",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Batch normalization (BN) is a fundamental unit in modern deep networks, in
which a linear transformation module was designed for improving BN's
flexibility of fitting complex data distributions. In this paper, we
demonstrate properly enhancing this linear transformation module can
effectively improve the ability of BN. Specifically, rather than using a single
neuron, we propose to additionally consider each neuron's neighborhood for
calculating the outputs of the linear transformation. Our method, named BNET,
can be implemented with 2-3 lines of code in most deep learning libraries.
Despite the simplicity, BNET brings consistent performance gains over a wide
range of backbones and visual benchmarks. Moreover, we verify that BNET
accelerates the convergence of network training and enhances spatial
information by assigning the important neurons with larger weights accordingly.
The code is available at https://github.com/yuhuixu1993/BNET.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:42:36 GMT""}]","2020-12-01"
"2011.14151","Philip Kennerberg","Philip Kennerberg, Magnus Wiktorsson","Stability in quadratic variation, with applications",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We show that non continuous Dirichlet processes, defined as in \cite{NonCont}
are closed under a wide family of locally Lipschitz continuous maps (similar to
the time-homogeneous variants of the maps considered in \cite{Low}) thus
extending Theorem 2.1. from that paper. We provide an It\^o formula for these
transforms and apply it to study of how $[f(X^n)-f(X)]\to 0$ when $X^n\to X$
(in some appropriate sense) for certain Dirichlet processes $\{X^n\}_n$, $X$
and certain locally Lipschitz continuous maps. We also consider how
$[f_n(X^n)-f(X)]\to 0$ for $C^1$ maps $\{f_n\}_n$, $f$ when $f_n'\to f'$
uniformly on compacts. For applications we give examples of jump removal and
stability of integrators.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:43:43 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 17:45:54 GMT""},{""version"":""v3"",""created"":""Wed, 20 Jan 2021 14:40:39 GMT""},{""version"":""v4"",""created"":""Sat, 20 Mar 2021 12:29:38 GMT""},{""version"":""v5"",""created"":""Thu, 26 Aug 2021 09:59:44 GMT""},{""version"":""v6"",""created"":""Thu, 23 Sep 2021 11:36:12 GMT""},{""version"":""v7"",""created"":""Sun, 17 Oct 2021 11:45:50 GMT""}]","2021-10-19"
"2011.14152","Gaoping Long","Gaoping Long and Chun-Yen Lin","Geometric parametrization of $SO(D+1)$ phase space of all dimensional
  loop quantum gravity",,"Phys. Rev. D 103, 086016 (2021)","10.1103/PhysRevD.103.086016",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To clarify the geometric information encoded in the $SO(D+1)$ spin-network
states for the higher dimensional loop quantum gravity, we generalize the
twisted-geometry parametrization of the $SU(2)$ phase space for $(1+3)$
dimensional loop quantum gravity to that of the $SO(D+1)$ phase space for the
all-dimensional case. The Poisson structure in terms of the twisted geometric
variables suggests a new gauge reduction procedure, with respect to the
discretized Gaussian and simplicity constraints governing the kinematics of the
theory. Endowed with the geometric meaning via the parametrization, our
reduction procedure serves to identify proper gauge freedom associated with the
anomalous discretized simplicity constraints and subsequently leads to the
desired classical state space of the (twisted) discrete ADM data.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:44:31 GMT""}]","2021-04-28"
"2011.14153","Renan Gross","Renan Gross","Brownian motion can feel the shape of a drum","16 pages, 3 figures",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the scenery reconstruction problem on the $d$-dimensional torus,
proving that a criterion on Fourier coefficients obtained by Matzinger and
Lember (2006) for discrete cycles applies also in continuous spaces. In
particular, with the right drift, Brownian motion can be used to reconstruct
any scenery. To this end, we prove an injectivity property of an infinite
Vandermonde matrix.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:55:11 GMT""}]","2020-12-01"
"2011.14154","Ryan Shifler","Lela Bones and Garrett Fowler and Lisa Schneider and Ryan M. Shifler","Conjecture $\mathcal{O}$ holds for some Horospherical Varieties of
  Picard Rank 1",,,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  Property $\mathcal{O}$ for an arbitrary complex, Fano manifold $X$, is a
statement about the eigenvalues of the linear operator obtained from the
quantum multiplication of the anticanonical class of $X$. Conjecture
$\mathcal{O}$ is a conjecture that Property $\mathcal{O}$ holds for any Fano
variety. Pasquier listed the smooth non-homogeneous horospherical varieties of
Picard rank 1 into five classes. Conjecture $\mathcal{O}$ has already been
shown to hold for the odd symplectic Grassmannians which is one of these
classes. We will show that Conjecture $\mathcal{O}$ holds for two more classes
and an example in a third class of Pasquier's list. The theory of
Perron-Frobenius reduces our proofs to be graph-theoretic in nature.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 15:55:17 GMT""}]","2020-12-01"
"2011.14822","Katharina Glock","Anne Meyer, Katharina Glock, Frank Radaschewski","Planning profitable tours for field sales forces: A unified view on
  sales analytics and mathematical optimization","40 pages, 15 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Field sales forces play an important role in direct marketing, especially for
companies offering complex products, services, or solutions in the
business-to-business context. A key task of sales representatives in
operational planning is to select the most promising customers to visit within
the next days. On an operative horizon, a key task for sales representatives is
to select the most promising customers to visit within the next days. A
strongly varying set of scoring methods predicting or approximating the
expected response exists for this customer selection phase. However, in the
case of field sales forces, the final customer selection is strongly
interrelated to the tour planning decisions. To this end, we formalize variants
of the profitable sales representatives tour problem as a multi-period team
orienteering problem, thereby providing a unified view on the customer scoring
and the tour planning phase. In an extensive computational study on real-world
instances from the retail industry, we systematically examine the impact of the
aggregation level and the content of information provided by a scoring method
and the sensitivity of the proposed models concerning prediction errors. We
show that the selection of a customer scoring and tour planning variant depends
on the available data. Furthermore, we work out where to put effort in the data
acquisition and scoring phase to get better operational tours.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 16:16:43 GMT""}]","2020-12-01"
"2011.14929","Albert Zuo","William Marshall, Nolan Miranda, Albert Zuo","Windowed Prophet Inequalities","18 pages",,,,"cs.DS cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The prophet inequalities problem has received significant study over the past
decades and has several applications such as to online auctions. In this paper,
we study two variants of the i.i.d. prophet inequalities problem, namely the
windowed prophet inequalities problem and the batched prophet inequalities
problem. For the windowed prophet inequalities problem, we show that for window
size $o(n)$, the optimal competitive ratio is $\alpha \approx 0.745$, the same
as in the non-windowed case. In the case where the window size is $n/k$ for
some constant $k$, we show that $\alpha_k < WIN_{n/k} \le \alpha_k + o_k(1)$
where $WIN_{n/k}$ is the optimal competitive ratio for the window size $n/k$
prophet inequalities problem and $\alpha_k$ is the optimal competitive ratio
for the $k$ sample i.i.d. prophet inequalities problem. Finally, we prove an
equivalence between the batched prophet inequalities problem and the i.i.d.
prophet inequalities problem.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:23:11 GMT""}]","2020-12-01"
"2012.00002","Mohammad Reza Setare","M. R. Setare and S. N. Sajadi","Phase Transition Between Flat Space Cosmology and Hot Flat Spacetimes in
  GMMG and EGMG Models","13 pages, typos corrected, main results and conclusion unchanged,
  reference and paragraph added",,"10.1088/1361-6382/ac03f7",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  Flat Space Cosmology (FSC) spacetimes are exact solutions of 3D gravity
theories. In this work, we study phase transition between FSC spacetimes and
Hot Flat Spacetimes (HFS) in general minimal massive gravity and exotic general
massive gravity. We show that similar to topological massive gravity the
tunneling occurs between two spacetimes by comparing their free energies. We
also obtain the corrections to the Bekenstein-Hawking entropy, and its effect
on the phase transition is studied.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 13:30:27 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 06:29:03 GMT""}]","2021-07-07"
"2012.00541","Andr\'e Rafael Cunha Dr.","Andr\'e Rafael Cunha, Celso Peres Fernandes, Lu\'is Orlando Emerich
  dos Santos","Geometry-Topology Duality in complex porous networks",,,,,"cond-mat.soft physics.app-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We explore the experimental observation that complex networks of porous media
exhibit the property that the porous coordination number is proportional to its
size. Based in this geometry-topology duality we developed an analytical
approach to describe the permeability transport property of the material. That
results was compared with 2D networks simulations. And we found a correlation
coefficient greater than 95%.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 04:18:38 GMT""}]","2020-12-02"
"2012.00543","Marko Kosti\'c","A. Ch\'avez, K. Khalil, M. Kosti\'c, M. Pinto","Multi-dimensional almost periodic type functions and applications",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we analyze multi-dimensional $({\mathrm R}_{X},{\mathcal
B})$-almost periodic type functions and multi-dimensional Bohr ${\mathcal
B}$-almost periodic type functions. The main structural characterizations and
composition principles for the introduced classes of almost periodic functions
are established. Several applications of our abstract theoretical results to
the abstract Volterra integro-differential equations in Banach spaces are
provided, as well.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 23:33:22 GMT""}]","2020-12-02"
"2012.00835","Andr\'e Rafael Cunha Dr.","Andr\'e Rafael Cunha, Celso Peres Fernandes, Lu\'is Orlando Emerich
  dos Santos, Denise Prado Kronbauer, Iara Frangiotti Mantovani, Anderson
  Camargo Moreira, Mayka Schmitt","A phenomenological connectivity measure for the pore space of rocks",,,,,"physics.geo-ph physics.app-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The interconnectivity of the porous space is an important characteristic in
the study of porous media and their transport properties. Hence we propose a
way to quantify it and relate it with the intrinsic permeability of rocks. We
propose a measure of connectivity based on geometric and topological
information of pore-throat network, which are models built from
microtomographic images, and we obtain an analytical method to compute that
property. The method is expanded to handle rocks that present a higher degree
of heterogenity in the porous space, which characterization requires images
from different resolutions (multiscale analysis). Trying to expand the
methodology beyond the scope of images, we also propose a new interpretation
for the experiment that generates the mercury intrusion curve and calculate the
permeability. The methodology was applied to images of 11 rocks, 3 sandstone
and 8 carbonate rock samples, and to the experimental mercury intrusion curve
of 4 tight gas sand rock samples. We observe as result the existence of a
correlation between the experimental and the predicted values. The notions of
connectivity developed in this work seek above all to characterize a porous
material before a typical macroscopic phenomenology.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 03:27:07 GMT""}]","2020-12-03"
"2012.00837","Sangram Redkar","S. Bhat, SusheelKumar CS, Sangram Redkar","Order Reduction of Nonlinear Quasi-periodic Systems Subjected to
  External Excitations",,,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  In his paper, we present order reduction techniques for nonlinear
quasi-periodic systems subjected to external excitations. The order reduction
techniques presented here are based on the Lyapunov-Perrone (L-P)
Transformation. For a class of non-resonant quasi-periodic systems, the L-P
transformation can convert a linear quasi-periodic system into a linear
time-invariant one. This Linear Time-Invariant (LTI) system retains the
dynamics of the original quasi-periodic system. Once this LTI system is
obtained, the tools and techniques available for analysis of LTI systems can be
used, and the results could be obtained for the original quasi-periodic system
via the L-P transformation. This approach is similar to using the
Lyapunov-Floquet (L-F) transformation to convert a linear time-periodic system
into an LTI system and perform analysis and control.
  Order reduction is a systematic way of constructing dynamical system models
with relatively smaller states that accurately retain large-scale systems'
essential dynamics. In this work, reduced-order modeling techniques for
nonlinear quasi-periodic systems subjected to external excitations are
presented. The methods proposed here use the L-P transformation that makes the
linear part of transformed equations time-invariant. In this work, two order
reduction techniques are suggested. The first method is simply an application
of the well-known Guyan like reduction method to nonlinear systems. The second
technique is based on the concept of an invariant manifold for quasi-periodic
systems.
  The 'quasi-periodic invariant manifold' based technique yields' reducibility
conditions.' These conditions help us to understand the various types of
resonant interactions in the system. These resonances indicate energy
interactions between the system states, nonlinearity, and external excitation.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:02:17 GMT""}]","2020-12-03"
"2012.00849","Tomoo Yokoyama","Tomoo Yokoyama","Quotient spaces and topological invariants of flows",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct topological invariants, called abstract weak orbit spaces, of
flows and homeomorphisms on topological spaces, to describe both gradient
dynamics and recurrent dynamics. In particular, the abstract weak orbit spaces
of flows on topological spaces are generalizations of both Morse graphs of
flows on compact metric spaces and Reeb graphs of Hamiltonian flows with
finitely many singular points on surfaces. Moreover, we show that the abstract
weak orbit spaces are complete and finite for several kinds of flows on
manifolds, and we state several examples whose Morse graphs are singletons but
whose abstract weak orbit spaces are not singletons. In addition, we consider
when the time-one map reconstructs the topology of the original flow. Therefore
we show that the orbit space of a Hamiltonian flow with finitely many singular
points on a compact surface is homeomorphic to the abstract weak orbit space of
the time-one map by taking an arbitrarily small reparametrization, and that the
abstract weak orbit spaces of a Morse flow on a compact manifold and the
time-one map are homeomorphic. Furthermore, the abstract weak orbit space of a
Morse flow on a closed manifold is a refinement of the CW decomposition which
consists of the unstable manifolds of singular points. Though the CW
decomposition of a Morse flow on a closed manifold is finite, the intersection
of the unstable manifold and the stable manifold of saddles of a Morse-Smale
flow on a closed manifold need not consist of finitely many connected
components (or equivalently need not consist of finitely many abstract weak
orbits). Therefore we study the finiteness of abstract weak orbit spaces of
Morse(-Smale) flow on compact manifolds.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 09:13:02 GMT""}]","2020-12-03"
"2012.01165","Chinasa Okolo","Chinasa T. Okolo","AI in the ""Real World"": Examining the Impact of AI Deployment in
  Low-Resource Contexts","Part of the Navigating the Broader Impacts of AI Research Workshop at
  NeurIPS 2020",,,,"cs.CY cs.HC","http://creativecommons.org/licenses/by/4.0/","  As AI becomes integrated throughout the world, its potential for impact
within low-resource regions around the Global South have grown. AI research
labs from tech giants like Microsoft, Google, and IBM have a significant
presence in countries such as India, Ghana, and South Africa. The work done by
these labs is often motivated by the potential impact it could have on local
populations, but the deployment of these tools has not always gone smoothly.
This paper presents a case study examining the deployment of AI by large
industry labs situated in low-resource contexts, highlights factors impacting
unanticipated deployments, and reflects on the state of AI deployment within
the Global South, providing suggestions that embrace inclusive design
methodologies within AI development that prioritize the needs of marginalized
communities and elevate their status not just as beneficiaries of AI systems
but as primary stakeholders.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 01:49:24 GMT""}]","2020-12-03"
"2012.01184","J\'er\^ome Darmont","Pegdwend\'e Sawadogo, J\'er\^ome Darmont, Fabien Duchateau","Feedback from the participants of the ADBIS, TPDL and EDA 2020 joint
  conferences","7 pages, 16 figures",,,,"cs.CY cs.DB cs.IR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper presents the way the joint ADBIS, TPDL and EDA 2020 conferences
were organized online and the results of the participant survey conducted
thereafter. We present the lessons learned from the participants' feedback.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:02:26 GMT""},{""version"":""v2"",""created"":""Sat, 19 Dec 2020 22:03:07 GMT""}]","2020-12-22"
"2012.01191","Mandana Samiei","Mandana Samiei, Caroline Weis, Larissa Schiavo, Tatjana Chavdarova,
  Fariba Yousefi","Convening during COVID-19: Lessons learnt from organizing virtual
  workshops in 2020","12 pages",,,,"cs.CY cs.LG","http://creativecommons.org/licenses/by/4.0/","  This report is an account of the authors' experiences as organizers of WiML's
""Un-Workshop"" event at ICML 2020. Un-workshops focus on participant-driven
structured discussions on a pre-selected topic. For clarity, this event was
different from the ""WiML Workshop"", which is usually co-located with NeurIPS.
In this manuscript, organizers, share their experiences with the hope that it
will help future organizers to host a successful virtual event under similar
conditions. Women in Machine Learning (WiML)'s mission is creating connections
within a small community of women working in machine learning, in order to
encourage mentorship, networking, and interchange of ideas and increase the
impact of women in the community.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 02:15:24 GMT""}]","2020-12-03"
"2012.01193","Mark Weber","Mark Weber, Mikhail Yurochkin, Sherif Botros, Vanio Markov","Black Loans Matter: Distributionally Robust Fairness for Fighting
  Subgroup Discrimination","8 pages, NeurIPS Fair AI in Finance Workshop",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Algorithmic fairness in lending today relies on group fairness metrics for
monitoring statistical parity across protected groups. This approach is
vulnerable to subgroup discrimination by proxy, carrying significant risks of
legal and reputational damage for lenders and blatantly unfair outcomes for
borrowers. Practical challenges arise from the many possible combinations and
subsets of protected groups. We motivate this problem against the backdrop of
historical and residual racism in the United States polluting all available
training data and raising public sensitivity to algorithimic bias. We review
the current regulatory compliance protocols for fairness in lending and discuss
their limitations relative to the contributions state-of-the-art fairness
methods may afford. We propose a solution for addressing subgroup
discrimination, while adhering to existing group fairness requirements, from
recent developments in individual fairness methods and corresponding fair
metric learning algorithms.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 21:04:07 GMT""}]","2020-12-03"
"2012.01260","G\'abor Tim\'ar","G\'abor Tim\'ar, Gy\""orgy Kov\'acs and Jos\'e Fernando F. Mendes","Enhanced robustness of single-layer networks with redundant dependencies","18 pages, 10 figures","Phys. Rev. E 103, 022321 (2021)","10.1103/PhysRevE.103.022321",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dependency links in single-layer networks offer a convenient way of modeling
nonlocal percolation effects in networked systems where certain pairs of nodes
are only able to function together. We study the percolation properties of the
weak variant of this model: nodes with dependency neighbours may continue to
function if at least one of their dependency neighbours is active. We show that
this relaxation of the dependency rule allows for more robust structures and a
rich variety of critical phenomena, as percolation is not determined strictly
by finite dependency clusters. We study Erd\""os-R\'enyi and random scale-free
networks with an underlying Erd\""os-R\'enyi network of dependency links. We
identify a special ""cusp"" point above which the system is always stable,
irrespective of the density of dependency links. We find continuous and
discontinuous hybrid percolation transitions, separated by a tricritical point
for Erd\""os-R\'enyi networks. For scale-free networks with a finite degree
cutoff we observe the appearance of a critical point and corresponding double
transitions in a certain range of the degree distribution exponent. We show
that at a special point in the parameter space, where the critical point
emerges, the giant viable cluster has the unusual critical singularity $S-S_c
\propto (p-p_c)^{1/4}$. We study the robustness of networks where connectivity
degrees and dependency degrees are correlated and find that scale-free networks
are able to retain their high resilience for strong enough positive
correlation, i.e., when hubs are protected by greater redundancy.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 17:44:53 GMT""},{""version"":""v2"",""created"":""Sun, 14 Mar 2021 11:09:46 GMT""}]","2021-03-16"
"2012.01928","Samet Uzun","Samet Uzun, Nazim Kemal Ure","A Probabilistic Guidance Approach to Swarm-to-Swarm Engagement Problem",,,,,"math.OC cs.MA math.DS math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a probabilistic guidance approach for the
swarm-to-swarm engagement problem. The idea is based on driving the controlled
swarm towards an adversary swarm, where the adversary swarm aims to converge to
a stationary distribution that corresponds to a defended base location. The
probabilistic approach is based on designing a Markov chain for the
distribution of the swarm to converge a stationary distribution. This approach
is decentralized, so each agent can propagate its position independently of
other agents. Our main contribution is the formulation of the swarm-to-swarm
engagement as an optimization problem where the population of each swarm decays
with each engagement and determining a desired distribution for the controlled
swarm to converge time-varying distribution and eliminate agents of the
adversary swarm until adversary swarm enters the defended base location. We
demonstrate the validity of proposed approach on several swarm engagement
scenarios.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 12:52:27 GMT""}]","2020-12-04"
"2012.01932","Catarina Bel\'em","Vladimir Balayan, Pedro Saleiro, Catarina Bel\'em, Ludwig Krippahl and
  Pedro Bizarro","Teaching the Machine to Explain Itself using Domain Knowledge",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine Learning (ML) has been increasingly used to aid humans to make better
and faster decisions. However, non-technical humans-in-the-loop struggle to
comprehend the rationale behind model predictions, hindering trust in
algorithmic decision-making systems. Considerable research work on AI
explainability attempts to win back trust in AI systems by developing
explanation methods but there is still no major breakthrough. At the same time,
popular explanation methods (e.g., LIME, and SHAP) produce explanations that
are very hard to understand for non-data scientist persona. To address this, we
present JOEL, a neural network-based framework to jointly learn a
decision-making task and associated explanations that convey domain knowledge.
JOEL is tailored to human-in-the-loop domain experts that lack deep technical
ML knowledge, providing high-level insights about the model's predictions that
very much resemble the experts' own reasoning. Moreover, we collect the domain
feedback from a pool of certified experts and use it to ameliorate the model
(human teaching), hence promoting seamless and better suited explanations.
Lastly, we resort to semantic mappings between legacy expert systems and domain
taxonomies to automatically annotate a bootstrap training set, overcoming the
absence of concept-based human annotations. We validate JOEL empirically on a
real-world fraud detection dataset. We show that JOEL can generalize the
explanations from the bootstrap dataset. Furthermore, obtained results indicate
that human teaching can further improve the explanations prediction quality by
approximately $13.57\%$.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 18:46:34 GMT""}]","2020-12-04"
"2012.02104","Manuel Francisco","Manuel Francisco and Juan Luis Castro","Discriminatory Expressions to Produce Interpretable Models in Short
  Documents",,,"10.1007/978-3-031-09037-0_26",,"cs.SI cs.AI cs.CL cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Social Networking Sites (SNS) are one of the most important ways of
communication. In particular, microblogging sites are being used as analysis
avenues due to their peculiarities (promptness, short texts...). There are
countless researches that use SNS in novel manners, but machine learning has
focused mainly in classification performance rather than interpretability
and/or other goodness metrics. Thus, state-of-the-art models are black boxes
that should not be used to solve problems that may have a social impact. When
the problem requires transparency, it is necessary to build interpretable
pipelines. Although the classifier may be interpretable, resulting models are
too complex to be considered comprehensible, making it impossible for humans to
understand the actual decisions. This paper presents a feature selection
mechanism that is able to improve comprehensibility by using less but more
meaningful features while achieving good performance in microblogging contexts
where interpretability is mandatory. Moreover, we present a ranking method to
evaluate features in terms of statistical relevance and bias. We conducted
exhaustive tests with five different datasets in order to evaluate
classification performance, generalisation capacity and complexity of the
model. Results show that our proposal is better and the most stable one in
terms of accuracy, generalisation and comprehensibility.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:00:50 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 14:25:09 GMT""}]","2022-06-28"
"2012.02255","Merab Gogberashvili Prof","Merab Gogberashvili and Alexandre Gurchumelia","Split Octonions and Triality in (4+4)-Space","14 pages, no figures, references added",,,,"math-ph hep-th math.MP","http://creativecommons.org/licenses/by/4.0/","  The known equivalence of 8-dimensional chiral spinors and vectors is
discussed for (4+4)-space within the context of the algebra of the split
octonions. It is shown that the complete algebra of hyper-complex octonionic
basis units can be recovered from the Moufang and Malcev relations for the
three vector-like elements of the split octonions. Trilinear form, which is
invariant under SO(4,4) transformations for vectors and corresponding Spin(4,4)
transformations for spinors, is explicitly written using both purely matrix and
purely octonionic representations.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 07:43:24 GMT""},{""version"":""v2"",""created"":""Sun, 13 Dec 2020 15:58:19 GMT""}]","2020-12-15"
"2012.02265","An Zou","An Zou, Shalabh C. Maroo (Department of Mechanical and Aerospace
  Engineering, Syracuse University)","Nano-Confinement Effects on Liquid Pressure","13 pages, 9 figures, Appendix available upon request, Submitting to a
  Journal","Physics of Fluids 33, 042007 (2021)","10.1063/5.0044938",,"cond-mat.soft physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  In this work, molecular dynamics simulations are performed to estimate the
equilibrium pressure of liquid confined in nanopores. The simulations show that
the pressure is highly sensitive to the pore size and can significantly change
from absolute positive to negative values for a very small (0.1 nm) change in
pore size. The contribution from the solid-liquid interaction always dominates
the pressure in the first liquid layer adjacent to the surface and the
sensitiveness of pressure on the pore size is due to the atom distribution in
the liquid layers. A surface influence number S is introduced to quantitatively
characterize the degree of the confinement. The S number decreases with
increasing pore size based on a power law function at constant system
temperature. In nanopores with large S number, the pore liquid pressure is
found to be independent of bulk liquid pressure while the pore pressure
increases with bulk pressure in nanopores with small S number.
","[{""version"":""v1"",""created"":""Fri, 27 Nov 2020 19:01:11 GMT""},{""version"":""v2"",""created"":""Sun, 24 Jan 2021 22:11:58 GMT""}]","2021-04-21"
"2012.04682","Leo Tam","Leo K. Tam and Xiaosong Wang and Daguang Xu","Transformer Query-Target Knowledge Discovery (TEND): Drug Discovery from
  CORD-19",,,,,"cs.CL cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Previous work established skip-gram word2vec models could be used to mine
knowledge in the materials science literature for the discovery of
thermoelectrics. Recent transformer architectures have shown great progress in
language modeling and associated fine-tuned tasks, but they have yet to be
adapted for drug discovery. We present a RoBERTa transformer-based method that
extends the masked language token prediction using query-target conditioning to
treat the specificity challenge. The transformer discovery method entails
several benefits over the word2vec method including domain-specific (antiviral)
analogy performance, negation handling, and flexible query analysis (specific)
and is demonstrated on influenza drug discovery. To stimulate COVID-19
research, we release an influenza clinical trials and antiviral analogies
dataset used in conjunction with the COVID-19 Open Research Dataset Challenge
(CORD-19) literature dataset in the study. We examine k-shot fine-tuning to
improve the downstream analogies performance as well as to mine analogies for
model explainability. Further, the query-target analysis is verified in a
forward chaining analysis against the influenza drug clinical trials dataset,
before adapted for COVID-19 drugs (combinations and side-effects) and on-going
clinical trials. In consideration of the present topic, we release the model,
dataset, and code.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 04:30:31 GMT""},{""version"":""v2"",""created"":""Fri, 11 Dec 2020 00:09:17 GMT""}]","2020-12-14"
"2012.07526","Haoran Xue","Letian Yu, Haoran Xue, Baile Zhang","Topological slow light via coupling chiral edge modes with flat bands","6 pages, 5 figures","Appl. Phys. Lett. 118, 071102 (2021)","10.1063/5.0039839",,"physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chiral edge modes in photonic topological insulators host great potential to
realize slow-light waveguides with topological protection. Increasing the
winding of the chiral edge mode around the Brillouin zone can lead to broadband
topological slow light with ultra-low group velocity. However, this effect
usually requires careful modifications on a relatively large area around the
lattice edge. Here we present a simple and general scheme to achieve broadband
topological slow light through coupling the chiral edge modes with flat bands.
In this approach, modifications inside the topological lattice are not
required. Instead, only several additional resonators that support the flat
bands need to be attached at the lattice edge. We demonstrate our idea
numerically using a gyromagnetic photonic crystal, which is ready to be tested
at microwave frequencies.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 11:58:49 GMT""}]","2021-03-31"
"2012.07528","Souheil Fenghour Fenghour","Souheil Fenghour, Daqing Chen, Kun Guo, Perry Xiao","Disentangling Homophemes in Lip Reading using Perplexity Analysis","17 pages",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The performance of automated lip reading using visemes as a classification
schema has achieved less success compared with the use of ASCII characters and
words largely due to the problem of different words sharing identical visemes.
The Generative Pre-Training transformer is an effective autoregressive language
model used for many tasks in Natural Language Processing, including sentence
prediction and text classification.
  This paper proposes a new application for this model and applies it in the
context of lip reading, where it serves as a language model to convert visual
speech in the form of visemes, to language in the form of words and sentences.
The network uses the search for optimal perplexity to perform the
viseme-to-word mapping and is thus a solution to the one-to-many mapping
problem that exists whereby various words that sound different when spoken look
identical. This paper proposes a method to tackle the one-to-many mapping
problem when performing automated lip reading using solely visual cues in two
separate scenarios: the first scenario is where the word boundary, that is, the
beginning and the ending of a word, is unknown; and the second scenario is
where the boundary is known.
  Sentences from the benchmark BBC dataset ""Lip Reading Sentences in the
Wild""(LRS2), are classified with a character error rate of 10.7% and a word
error rate of 18.0%. The main contribution of this paper is to propose a method
of predicting words through the use of perplexity analysis when only visual
cues are present, using an autoregressive language model.
","[{""version"":""v1"",""created"":""Sat, 28 Nov 2020 12:12:17 GMT""}]","2020-12-15"
